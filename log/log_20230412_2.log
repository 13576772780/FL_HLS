nohup: 忽略输入
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.413, Test loss: 1.276, Test accuracy: 51.12 

Round   0, Global train loss: 1.413, Global test loss: 2.092, Global test accuracy: 14.64 

Round   1, Train loss: 1.083, Test loss: 1.515, Test accuracy: 53.08 

Round   1, Global train loss: 1.083, Global test loss: 2.207, Global test accuracy: 12.04 

Round   2, Train loss: 0.920, Test loss: 1.225, Test accuracy: 60.12 

Round   2, Global train loss: 0.920, Global test loss: 2.191, Global test accuracy: 12.76 

Round   3, Train loss: 0.760, Test loss: 1.102, Test accuracy: 62.60 

Round   3, Global train loss: 0.760, Global test loss: 2.292, Global test accuracy: 12.00 

Round   4, Train loss: 0.667, Test loss: 1.180, Test accuracy: 63.84 

Round   4, Global train loss: 0.667, Global test loss: 2.281, Global test accuracy: 12.20 

Round   5, Train loss: 0.555, Test loss: 1.225, Test accuracy: 64.44 

Round   5, Global train loss: 0.555, Global test loss: 2.447, Global test accuracy: 12.08 

Round   6, Train loss: 0.466, Test loss: 1.277, Test accuracy: 65.84 

Round   6, Global train loss: 0.466, Global test loss: 2.433, Global test accuracy: 12.00 

Round   7, Train loss: 0.397, Test loss: 1.348, Test accuracy: 67.12 

Round   7, Global train loss: 0.397, Global test loss: 2.350, Global test accuracy: 12.00 

Round   8, Train loss: 0.335, Test loss: 1.199, Test accuracy: 70.32 

Round   8, Global train loss: 0.335, Global test loss: 2.374, Global test accuracy: 12.12 

Round   9, Train loss: 0.284, Test loss: 1.268, Test accuracy: 68.56 

Round   9, Global train loss: 0.284, Global test loss: 2.405, Global test accuracy: 12.08 

Round  10, Train loss: 0.232, Test loss: 1.436, Test accuracy: 68.36 

Round  10, Global train loss: 0.232, Global test loss: 2.480, Global test accuracy: 12.00 

Round  11, Train loss: 0.197, Test loss: 1.442, Test accuracy: 68.76 

Round  11, Global train loss: 0.197, Global test loss: 2.431, Global test accuracy: 12.00 

Round  12, Train loss: 0.166, Test loss: 1.370, Test accuracy: 70.08 

Round  12, Global train loss: 0.166, Global test loss: 2.522, Global test accuracy: 12.00 

Round  13, Train loss: 0.158, Test loss: 1.487, Test accuracy: 68.20 

Round  13, Global train loss: 0.158, Global test loss: 2.558, Global test accuracy: 12.00 

Round  14, Train loss: 0.135, Test loss: 1.693, Test accuracy: 67.92 

Round  14, Global train loss: 0.135, Global test loss: 2.414, Global test accuracy: 12.08 

Round  15, Train loss: 0.117, Test loss: 1.341, Test accuracy: 72.36 

Round  15, Global train loss: 0.117, Global test loss: 2.528, Global test accuracy: 12.00 

Round  16, Train loss: 0.096, Test loss: 1.439, Test accuracy: 71.44 

Round  16, Global train loss: 0.096, Global test loss: 2.493, Global test accuracy: 12.00 

Round  17, Train loss: 0.072, Test loss: 1.407, Test accuracy: 72.64 

Round  17, Global train loss: 0.072, Global test loss: 2.448, Global test accuracy: 12.00 

Round  18, Train loss: 0.070, Test loss: 1.487, Test accuracy: 71.04 

Round  18, Global train loss: 0.070, Global test loss: 2.463, Global test accuracy: 12.00 

Round  19, Train loss: 0.077, Test loss: 1.635, Test accuracy: 69.56 

Round  19, Global train loss: 0.077, Global test loss: 2.470, Global test accuracy: 12.00 

Round  20, Train loss: 0.069, Test loss: 1.505, Test accuracy: 72.00 

Round  20, Global train loss: 0.069, Global test loss: 2.463, Global test accuracy: 12.00 

Round  21, Train loss: 0.066, Test loss: 1.457, Test accuracy: 71.68 

Round  21, Global train loss: 0.066, Global test loss: 2.428, Global test accuracy: 12.04 

Round  22, Train loss: 0.045, Test loss: 1.473, Test accuracy: 72.36 

Round  22, Global train loss: 0.045, Global test loss: 2.422, Global test accuracy: 12.00 

Round  23, Train loss: 0.045, Test loss: 1.495, Test accuracy: 72.16 

Round  23, Global train loss: 0.045, Global test loss: 2.432, Global test accuracy: 12.04 

Round  24, Train loss: 0.055, Test loss: 1.570, Test accuracy: 71.20 

Round  24, Global train loss: 0.055, Global test loss: 2.422, Global test accuracy: 12.00 

Round  25, Train loss: 0.038, Test loss: 1.445, Test accuracy: 73.36 

Round  25, Global train loss: 0.038, Global test loss: 2.438, Global test accuracy: 12.04 

Round  26, Train loss: 0.021, Test loss: 1.623, Test accuracy: 72.12 

Round  26, Global train loss: 0.021, Global test loss: 2.383, Global test accuracy: 12.16 

Round  27, Train loss: 0.029, Test loss: 1.546, Test accuracy: 72.68 

Round  27, Global train loss: 0.029, Global test loss: 2.515, Global test accuracy: 12.00 

Round  28, Train loss: 0.029, Test loss: 1.555, Test accuracy: 71.80 

Round  28, Global train loss: 0.029, Global test loss: 2.510, Global test accuracy: 12.00 

Round  29, Train loss: 0.035, Test loss: 1.501, Test accuracy: 72.72 

Round  29, Global train loss: 0.035, Global test loss: 2.491, Global test accuracy: 12.00 

Round  30, Train loss: 0.023, Test loss: 1.734, Test accuracy: 71.12 

Round  30, Global train loss: 0.023, Global test loss: 2.492, Global test accuracy: 12.00 

Round  31, Train loss: 0.027, Test loss: 1.731, Test accuracy: 72.80 

Round  31, Global train loss: 0.027, Global test loss: 2.392, Global test accuracy: 12.28 

Round  32, Train loss: 0.028, Test loss: 1.514, Test accuracy: 73.04 

Round  32, Global train loss: 0.028, Global test loss: 2.397, Global test accuracy: 12.08 

Round  33, Train loss: 0.029, Test loss: 1.567, Test accuracy: 72.48 

Round  33, Global train loss: 0.029, Global test loss: 2.378, Global test accuracy: 12.04 

Round  34, Train loss: 0.021, Test loss: 1.533, Test accuracy: 73.08 

Round  34, Global train loss: 0.021, Global test loss: 2.371, Global test accuracy: 12.08 

Final Round, Train loss: 0.024, Test loss: 1.571, Test accuracy: 71.84 

Final Round, Global train loss: 0.024, Global test loss: 2.371, Global test accuracy: 12.08 

Average accuracy final 10 rounds: 72.52000000000001 

Average global accuracy final 10 rounds: 12.068000000000001 

1156.8129034042358
[7.395541191101074, 13.234793424606323, 19.335041284561157, 25.630173921585083, 31.24436664581299, 36.90814757347107, 42.703333616256714, 48.72646498680115, 54.76837372779846, 60.51185083389282, 66.31895542144775, 72.12202334403992, 77.70324230194092, 83.22986721992493, 88.80688691139221, 94.42905497550964, 100.07251906394958, 105.68792963027954, 111.38906788825989, 117.1346025466919, 122.86372351646423, 128.484525680542, 134.36934971809387, 140.19859552383423, 145.71412754058838, 151.4561357498169, 157.04229617118835, 162.73013710975647, 168.39169001579285, 174.07821559906006, 179.67408156394958, 185.4458258152008, 190.9549720287323, 196.46535062789917, 202.32680487632751, 213.33951258659363]
[51.12, 53.08, 60.12, 62.6, 63.84, 64.44, 65.84, 67.12, 70.32, 68.56, 68.36, 68.76, 70.08, 68.2, 67.92, 72.36, 71.44, 72.64, 71.04, 69.56, 72.0, 71.68, 72.36, 72.16, 71.2, 73.36, 72.12, 72.68, 71.8, 72.72, 71.12, 72.8, 73.04, 72.48, 73.08, 71.84]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.436, Test loss: 1.352, Test accuracy: 52.96 

Round   0, Global train loss: 1.436, Global test loss: 2.103, Global test accuracy: 22.88 

Round   1, Train loss: 1.283, Test loss: 1.290, Test accuracy: 53.24 

Round   1, Global train loss: 1.283, Global test loss: 1.731, Global test accuracy: 36.68 

Round   2, Train loss: 1.133, Test loss: 1.119, Test accuracy: 58.84 

Round   2, Global train loss: 1.133, Global test loss: 1.586, Global test accuracy: 42.32 

Round   3, Train loss: 1.013, Test loss: 1.168, Test accuracy: 60.72 

Round   3, Global train loss: 1.013, Global test loss: 1.486, Global test accuracy: 47.60 

Round   4, Train loss: 0.926, Test loss: 1.038, Test accuracy: 63.68 

Round   4, Global train loss: 0.926, Global test loss: 1.372, Global test accuracy: 49.72 

Round   5, Train loss: 0.833, Test loss: 1.025, Test accuracy: 65.28 

Round   5, Global train loss: 0.833, Global test loss: 1.294, Global test accuracy: 52.48 

Round   6, Train loss: 0.775, Test loss: 1.002, Test accuracy: 66.92 

Round   6, Global train loss: 0.775, Global test loss: 1.176, Global test accuracy: 58.28 

Round   7, Train loss: 0.702, Test loss: 0.884, Test accuracy: 70.44 

Round   7, Global train loss: 0.702, Global test loss: 1.172, Global test accuracy: 59.08 

Round   8, Train loss: 0.638, Test loss: 0.941, Test accuracy: 69.92 

Round   8, Global train loss: 0.638, Global test loss: 1.106, Global test accuracy: 61.16 

Round   9, Train loss: 0.589, Test loss: 0.930, Test accuracy: 70.48 

Round   9, Global train loss: 0.589, Global test loss: 1.138, Global test accuracy: 60.16 

Round  10, Train loss: 0.536, Test loss: 0.915, Test accuracy: 73.08 

Round  10, Global train loss: 0.536, Global test loss: 1.177, Global test accuracy: 60.04 

Round  11, Train loss: 0.501, Test loss: 0.996, Test accuracy: 71.12 

Round  11, Global train loss: 0.501, Global test loss: 1.044, Global test accuracy: 63.48 

Round  12, Train loss: 0.464, Test loss: 0.888, Test accuracy: 73.76 

Round  12, Global train loss: 0.464, Global test loss: 1.058, Global test accuracy: 63.16 

Round  13, Train loss: 0.429, Test loss: 0.998, Test accuracy: 71.16 

Round  13, Global train loss: 0.429, Global test loss: 0.996, Global test accuracy: 66.36 

Round  14, Train loss: 0.391, Test loss: 0.818, Test accuracy: 74.60 

Round  14, Global train loss: 0.391, Global test loss: 0.988, Global test accuracy: 65.76 

Round  15, Train loss: 0.358, Test loss: 0.791, Test accuracy: 77.08 

Round  15, Global train loss: 0.358, Global test loss: 0.972, Global test accuracy: 66.52 

Round  16, Train loss: 0.329, Test loss: 0.869, Test accuracy: 76.56 

Round  16, Global train loss: 0.329, Global test loss: 0.962, Global test accuracy: 67.16 

Round  17, Train loss: 0.297, Test loss: 0.894, Test accuracy: 77.24 

Round  17, Global train loss: 0.297, Global test loss: 1.041, Global test accuracy: 66.52 

Round  18, Train loss: 0.294, Test loss: 1.328, Test accuracy: 70.44 

Round  18, Global train loss: 0.294, Global test loss: 0.943, Global test accuracy: 68.24 

Round  19, Train loss: 0.272, Test loss: 0.982, Test accuracy: 75.08 

Round  19, Global train loss: 0.272, Global test loss: 1.006, Global test accuracy: 67.72 

Round  20, Train loss: 0.251, Test loss: 1.059, Test accuracy: 75.64 

Round  20, Global train loss: 0.251, Global test loss: 0.946, Global test accuracy: 68.80 

Round  21, Train loss: 0.232, Test loss: 1.013, Test accuracy: 75.32 

Round  21, Global train loss: 0.232, Global test loss: 0.996, Global test accuracy: 68.44 

Round  22, Train loss: 0.229, Test loss: 0.809, Test accuracy: 78.16 

Round  22, Global train loss: 0.229, Global test loss: 0.972, Global test accuracy: 68.96 

Round  23, Train loss: 0.211, Test loss: 1.022, Test accuracy: 75.20 

Round  23, Global train loss: 0.211, Global test loss: 0.924, Global test accuracy: 70.56 

Round  24, Train loss: 0.177, Test loss: 1.049, Test accuracy: 74.80 

Round  24, Global train loss: 0.177, Global test loss: 0.940, Global test accuracy: 69.60 

Round  25, Train loss: 0.168, Test loss: 0.820, Test accuracy: 79.68 

Round  25, Global train loss: 0.168, Global test loss: 0.931, Global test accuracy: 70.52 

Round  26, Train loss: 0.165, Test loss: 1.013, Test accuracy: 76.96 

Round  26, Global train loss: 0.165, Global test loss: 0.938, Global test accuracy: 70.08 

Round  27, Train loss: 0.155, Test loss: 0.835, Test accuracy: 79.20 

Round  27, Global train loss: 0.155, Global test loss: 0.944, Global test accuracy: 70.56 

Round  28, Train loss: 0.146, Test loss: 0.976, Test accuracy: 76.24 

Round  28, Global train loss: 0.146, Global test loss: 0.932, Global test accuracy: 70.32 

Round  29, Train loss: 0.140, Test loss: 0.832, Test accuracy: 79.16 

Round  29, Global train loss: 0.140, Global test loss: 0.920, Global test accuracy: 71.56 

Round  30, Train loss: 0.135, Test loss: 0.996, Test accuracy: 78.08 

Round  30, Global train loss: 0.135, Global test loss: 0.932, Global test accuracy: 71.28 

Round  31, Train loss: 0.118, Test loss: 0.863, Test accuracy: 79.32 

Round  31, Global train loss: 0.118, Global test loss: 0.934, Global test accuracy: 71.52 

Round  32, Train loss: 0.092, Test loss: 0.947, Test accuracy: 78.28 

Round  32, Global train loss: 0.092, Global test loss: 0.964, Global test accuracy: 71.36 

Round  33, Train loss: 0.120, Test loss: 0.927, Test accuracy: 78.72 

Round  33, Global train loss: 0.120, Global test loss: 0.917, Global test accuracy: 72.80 

Round  34, Train loss: 0.082, Test loss: 0.865, Test accuracy: 79.12 

Round  34, Global train loss: 0.082, Global test loss: 0.916, Global test accuracy: 71.64 

Round  35, Train loss: 0.082, Test loss: 0.946, Test accuracy: 80.08 

Round  35, Global train loss: 0.082, Global test loss: 0.922, Global test accuracy: 72.04 

Round  36, Train loss: 0.094, Test loss: 0.970, Test accuracy: 78.96 

Round  36, Global train loss: 0.094, Global test loss: 0.927, Global test accuracy: 72.64 

Round  37, Train loss: 0.068, Test loss: 0.847, Test accuracy: 79.76 

Round  37, Global train loss: 0.068, Global test loss: 0.931, Global test accuracy: 71.84 

Round  38, Train loss: 0.103, Test loss: 1.026, Test accuracy: 77.88 

Round  38, Global train loss: 0.103, Global test loss: 0.963, Global test accuracy: 71.20 

Round  39, Train loss: 0.074, Test loss: 1.052, Test accuracy: 78.20 

Round  39, Global train loss: 0.074, Global test loss: 0.933, Global test accuracy: 71.16 

Round  40, Train loss: 0.062, Test loss: 0.921, Test accuracy: 81.32 

Round  40, Global train loss: 0.062, Global test loss: 0.904, Global test accuracy: 72.16 

Round  41, Train loss: 0.041, Test loss: 0.811, Test accuracy: 81.92 

Round  41, Global train loss: 0.041, Global test loss: 0.891, Global test accuracy: 72.04 

Round  42, Train loss: 0.066, Test loss: 1.005, Test accuracy: 79.40 

Round  42, Global train loss: 0.066, Global test loss: 0.996, Global test accuracy: 71.00 

Round  43, Train loss: 0.072, Test loss: 0.918, Test accuracy: 79.88 

Round  43, Global train loss: 0.072, Global test loss: 0.955, Global test accuracy: 71.60 

Round  44, Train loss: 0.051, Test loss: 0.936, Test accuracy: 80.08 

Round  44, Global train loss: 0.051, Global test loss: 0.966, Global test accuracy: 71.76 

Round  45, Train loss: 0.073, Test loss: 0.920, Test accuracy: 79.80 

Round  45, Global train loss: 0.073, Global test loss: 0.955, Global test accuracy: 71.84 

Round  46, Train loss: 0.050, Test loss: 0.841, Test accuracy: 81.20 

Round  46, Global train loss: 0.050, Global test loss: 0.912, Global test accuracy: 72.08 

Round  47, Train loss: 0.027, Test loss: 0.793, Test accuracy: 82.08 

Round  47, Global train loss: 0.027, Global test loss: 0.910, Global test accuracy: 72.20 

Round  48, Train loss: 0.040, Test loss: 0.838, Test accuracy: 81.00 

Round  48, Global train loss: 0.040, Global test loss: 0.937, Global test accuracy: 72.60 

Round  49, Train loss: 0.055, Test loss: 0.948, Test accuracy: 79.08 

Round  49, Global train loss: 0.055, Global test loss: 0.930, Global test accuracy: 72.72 

Final Round, Train loss: 0.047, Test loss: 0.930, Test accuracy: 79.60 

Final Round, Global train loss: 0.047, Global test loss: 0.930, Global test accuracy: 72.72 

Average accuracy final 10 rounds: 80.57599999999998 

Average global accuracy final 10 rounds: 72.0 

1668.27015042305
[7.769278287887573, 13.577556371688843, 19.18515682220459, 25.34662413597107, 31.1268413066864, 36.957844495773315, 42.71265006065369, 48.37561297416687, 54.2557270526886, 60.122817039489746, 65.93255591392517, 71.72528767585754, 77.59047770500183, 83.54807114601135, 89.48953413963318, 95.38843488693237, 101.09042716026306, 106.84680986404419, 112.62954306602478, 118.41757488250732, 124.36692094802856, 130.40220522880554, 136.18266582489014, 142.05854678153992, 147.81826853752136, 153.9020357131958, 159.9076828956604, 166.2631378173828, 172.23264455795288, 177.98373246192932, 183.66754627227783, 189.4084689617157, 195.43787789344788, 201.36857533454895, 207.1435582637787, 213.1710979938507, 219.05842471122742, 224.86332416534424, 230.70460724830627, 236.69412183761597, 242.6828534603119, 248.4741506576538, 254.41878819465637, 260.32174921035767, 266.1265263557434, 271.97959661483765, 277.7386360168457, 283.5684998035431, 289.3015048503876, 295.08326172828674, 306.6337025165558]
[52.96, 53.24, 58.84, 60.72, 63.68, 65.28, 66.92, 70.44, 69.92, 70.48, 73.08, 71.12, 73.76, 71.16, 74.6, 77.08, 76.56, 77.24, 70.44, 75.08, 75.64, 75.32, 78.16, 75.2, 74.8, 79.68, 76.96, 79.2, 76.24, 79.16, 78.08, 79.32, 78.28, 78.72, 79.12, 80.08, 78.96, 79.76, 77.88, 78.2, 81.32, 81.92, 79.4, 79.88, 80.08, 79.8, 81.2, 82.08, 81.0, 79.08, 79.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.532, Test loss: 1.763, Test accuracy: 30.40 

Round   1, Train loss: 1.320, Test loss: 1.477, Test accuracy: 36.32 

Round   2, Train loss: 1.154, Test loss: 1.127, Test accuracy: 53.72 

Round   3, Train loss: 1.047, Test loss: 1.079, Test accuracy: 57.00 

Round   4, Train loss: 0.964, Test loss: 0.911, Test accuracy: 63.32 

Round   5, Train loss: 0.903, Test loss: 0.947, Test accuracy: 61.96 

Round   6, Train loss: 0.856, Test loss: 0.816, Test accuracy: 68.16 

Round   7, Train loss: 0.797, Test loss: 0.883, Test accuracy: 65.72 

Round   8, Train loss: 0.736, Test loss: 0.856, Test accuracy: 67.08 

Round   9, Train loss: 0.689, Test loss: 0.750, Test accuracy: 71.88 

Round  10, Train loss: 0.655, Test loss: 0.714, Test accuracy: 73.32 

Round  11, Train loss: 0.623, Test loss: 0.730, Test accuracy: 72.56 

Round  12, Train loss: 0.570, Test loss: 0.688, Test accuracy: 74.76 

Round  13, Train loss: 0.537, Test loss: 0.720, Test accuracy: 75.16 

Round  14, Train loss: 0.505, Test loss: 0.661, Test accuracy: 76.40 

Round  15, Train loss: 0.467, Test loss: 0.587, Test accuracy: 78.96 

Round  16, Train loss: 0.438, Test loss: 0.642, Test accuracy: 77.24 

Round  17, Train loss: 0.427, Test loss: 0.560, Test accuracy: 79.56 

Round  18, Train loss: 0.394, Test loss: 0.569, Test accuracy: 79.04 

Round  19, Train loss: 0.363, Test loss: 0.587, Test accuracy: 79.36 

Round  20, Train loss: 0.346, Test loss: 0.581, Test accuracy: 79.32 

Round  21, Train loss: 0.309, Test loss: 0.589, Test accuracy: 80.32 

Round  22, Train loss: 0.305, Test loss: 0.588, Test accuracy: 79.56 

Round  23, Train loss: 0.281, Test loss: 0.589, Test accuracy: 80.16 

Round  24, Train loss: 0.262, Test loss: 0.558, Test accuracy: 82.08 

Round  25, Train loss: 0.254, Test loss: 0.550, Test accuracy: 81.32 

Round  26, Train loss: 0.243, Test loss: 0.578, Test accuracy: 80.92 

Round  27, Train loss: 0.217, Test loss: 0.568, Test accuracy: 80.96 

Round  28, Train loss: 0.207, Test loss: 0.566, Test accuracy: 81.00 

Round  29, Train loss: 0.201, Test loss: 0.593, Test accuracy: 80.72 

Round  30, Train loss: 0.184, Test loss: 0.599, Test accuracy: 81.88 

Round  31, Train loss: 0.169, Test loss: 0.568, Test accuracy: 82.68 

Round  32, Train loss: 0.159, Test loss: 0.567, Test accuracy: 82.32 

Round  33, Train loss: 0.148, Test loss: 0.610, Test accuracy: 81.96 

Round  34, Train loss: 0.140, Test loss: 0.578, Test accuracy: 81.92 

Round  35, Train loss: 0.120, Test loss: 0.574, Test accuracy: 82.04 

Round  36, Train loss: 0.118, Test loss: 0.569, Test accuracy: 82.60 

Round  37, Train loss: 0.112, Test loss: 0.580, Test accuracy: 82.68 

Round  38, Train loss: 0.113, Test loss: 0.576, Test accuracy: 82.08 

Round  39, Train loss: 0.107, Test loss: 0.539, Test accuracy: 83.60 

Round  40, Train loss: 0.087, Test loss: 0.603, Test accuracy: 82.52 

Round  41, Train loss: 0.080, Test loss: 0.572, Test accuracy: 82.72 

Round  42, Train loss: 0.099, Test loss: 0.574, Test accuracy: 82.36 

Round  43, Train loss: 0.084, Test loss: 0.568, Test accuracy: 83.24 

Round  44, Train loss: 0.078, Test loss: 0.566, Test accuracy: 83.40 

Round  45, Train loss: 0.075, Test loss: 0.595, Test accuracy: 82.96 

Round  46, Train loss: 0.064, Test loss: 0.578, Test accuracy: 83.60 

Round  47, Train loss: 0.063, Test loss: 0.596, Test accuracy: 82.96 

Round  48, Train loss: 0.062, Test loss: 0.566, Test accuracy: 84.44 

Round  49, Train loss: 0.055, Test loss: 0.593, Test accuracy: 84.08 

Final Round, Train loss: 0.031, Test loss: 0.588, Test accuracy: 83.92 

Average accuracy final 10 rounds: 83.22800000000001 

1197.46182847023
[6.183910846710205, 10.817195892333984, 15.21188735961914, 19.584715366363525, 24.06439471244812, 28.53514003753662, 33.131208419799805, 37.50127124786377, 42.175949573516846, 46.666449546813965, 51.10797595977783, 55.61983776092529, 60.1661434173584, 64.67260122299194, 69.12464046478271, 73.51240849494934, 77.90260148048401, 82.2565016746521, 86.73976278305054, 91.49126529693604, 96.15677428245544, 100.69130373001099, 105.00469613075256, 109.74336957931519, 114.61091375350952, 119.12416648864746, 123.66276836395264, 128.01301622390747, 132.5136342048645, 137.17619633674622, 141.63048815727234, 146.07077860832214, 150.31143999099731, 154.7568941116333, 159.72812724113464, 164.1754150390625, 168.69565200805664, 173.28747987747192, 177.74281072616577, 182.09109044075012, 186.43227529525757, 190.92741179466248, 195.33781576156616, 199.6829273700714, 204.0263831615448, 208.49740481376648, 212.91701412200928, 217.79235696792603, 222.41666793823242, 226.93983387947083, 232.14532089233398]
[30.4, 36.32, 53.72, 57.0, 63.32, 61.96, 68.16, 65.72, 67.08, 71.88, 73.32, 72.56, 74.76, 75.16, 76.4, 78.96, 77.24, 79.56, 79.04, 79.36, 79.32, 80.32, 79.56, 80.16, 82.08, 81.32, 80.92, 80.96, 81.0, 80.72, 81.88, 82.68, 82.32, 81.96, 81.92, 82.04, 82.6, 82.68, 82.08, 83.6, 82.52, 82.72, 82.36, 83.24, 83.4, 82.96, 83.6, 82.96, 84.44, 84.08, 83.92]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.551, Test loss: 1.723, Test accuracy: 28.92
Round   1, Train loss: 1.319, Test loss: 1.464, Test accuracy: 38.24
Round   2, Train loss: 1.175, Test loss: 1.294, Test accuracy: 46.12
Round   3, Train loss: 1.065, Test loss: 1.049, Test accuracy: 57.56
Round   4, Train loss: 0.996, Test loss: 1.085, Test accuracy: 53.28
Round   5, Train loss: 0.925, Test loss: 0.864, Test accuracy: 66.48
Round   6, Train loss: 0.862, Test loss: 0.872, Test accuracy: 66.76
Round   7, Train loss: 0.814, Test loss: 0.870, Test accuracy: 68.32
Round   8, Train loss: 0.760, Test loss: 0.755, Test accuracy: 71.20
Round   9, Train loss: 0.722, Test loss: 0.844, Test accuracy: 68.16
Round  10, Train loss: 0.659, Test loss: 0.707, Test accuracy: 73.36
Round  11, Train loss: 0.641, Test loss: 0.690, Test accuracy: 72.80
Round  12, Train loss: 0.601, Test loss: 0.711, Test accuracy: 74.08
Round  13, Train loss: 0.573, Test loss: 0.804, Test accuracy: 71.08
Round  14, Train loss: 0.536, Test loss: 0.703, Test accuracy: 75.12
Round  15, Train loss: 0.496, Test loss: 0.661, Test accuracy: 76.84
Round  16, Train loss: 0.473, Test loss: 0.661, Test accuracy: 76.52
Round  17, Train loss: 0.447, Test loss: 0.644, Test accuracy: 76.72
Round  18, Train loss: 0.408, Test loss: 0.624, Test accuracy: 77.48
Round  19, Train loss: 0.390, Test loss: 0.635, Test accuracy: 77.56
Round  20, Train loss: 0.367, Test loss: 0.602, Test accuracy: 78.84
Round  21, Train loss: 0.362, Test loss: 0.615, Test accuracy: 79.44
Round  22, Train loss: 0.333, Test loss: 0.577, Test accuracy: 80.08
Round  23, Train loss: 0.312, Test loss: 0.605, Test accuracy: 79.60
Round  24, Train loss: 0.291, Test loss: 0.610, Test accuracy: 79.88
Round  25, Train loss: 0.271, Test loss: 0.612, Test accuracy: 79.68
Round  26, Train loss: 0.261, Test loss: 0.539, Test accuracy: 81.44
Round  27, Train loss: 0.231, Test loss: 0.594, Test accuracy: 80.08
Round  28, Train loss: 0.215, Test loss: 0.585, Test accuracy: 80.44
Round  29, Train loss: 0.214, Test loss: 0.594, Test accuracy: 80.96
Round  30, Train loss: 0.205, Test loss: 0.570, Test accuracy: 81.36
Round  31, Train loss: 0.188, Test loss: 0.595, Test accuracy: 81.20
Round  32, Train loss: 0.172, Test loss: 0.573, Test accuracy: 81.48
Round  33, Train loss: 0.163, Test loss: 0.587, Test accuracy: 81.96
Round  34, Train loss: 0.154, Test loss: 0.588, Test accuracy: 82.08
Round  35, Train loss: 0.142, Test loss: 0.596, Test accuracy: 82.00
Round  36, Train loss: 0.141, Test loss: 0.587, Test accuracy: 82.20
Round  37, Train loss: 0.125, Test loss: 0.595, Test accuracy: 82.04
Round  38, Train loss: 0.113, Test loss: 0.600, Test accuracy: 82.80
Round  39, Train loss: 0.112, Test loss: 0.600, Test accuracy: 81.92
Round  40, Train loss: 0.103, Test loss: 0.599, Test accuracy: 82.12
Round  41, Train loss: 0.096, Test loss: 0.604, Test accuracy: 82.40
Round  42, Train loss: 0.104, Test loss: 0.639, Test accuracy: 81.08
Round  43, Train loss: 0.085, Test loss: 0.599, Test accuracy: 83.08
Round  44, Train loss: 0.088, Test loss: 0.592, Test accuracy: 82.96
Round  45, Train loss: 0.072, Test loss: 0.617, Test accuracy: 82.32
Round  46, Train loss: 0.082, Test loss: 0.601, Test accuracy: 83.08
Round  47, Train loss: 0.068, Test loss: 0.615, Test accuracy: 82.92
Round  48, Train loss: 0.057, Test loss: 0.619, Test accuracy: 82.96
Round  49, Train loss: 0.064, Test loss: 0.619, Test accuracy: 82.92
Final Round, Train loss: 0.031, Test loss: 0.630, Test accuracy: 82.84
Average accuracy final 10 rounds: 82.584
1348.8233766555786
[6.882428407669067, 11.835763454437256, 16.97615122795105, 22.14562439918518, 27.267882823944092, 32.18301606178284, 37.38852095603943, 42.482678174972534, 47.69202160835266, 53.08873391151428, 58.37440085411072, 63.434969425201416, 68.33710193634033, 73.40169787406921, 78.43695402145386, 83.44085836410522, 88.4151725769043, 93.63399767875671, 98.48586392402649, 103.66313171386719, 108.78221774101257, 113.75125312805176, 118.83012914657593, 123.88780903816223, 128.96260738372803, 133.9561734199524, 139.23281002044678, 144.35925698280334, 149.29745030403137, 154.39237189292908, 159.29236698150635, 164.1412136554718, 169.14895510673523, 174.27048993110657, 179.4793677330017, 184.69023990631104, 189.73692893981934, 194.8323585987091, 200.01784539222717, 205.21941232681274, 210.2935345172882, 215.3728859424591, 220.73799085617065, 225.9496648311615, 231.01409649848938, 235.98388004302979, 241.0146827697754, 246.79937767982483, 251.98602056503296, 256.8866641521454, 261.92957615852356]
[28.92, 38.24, 46.12, 57.56, 53.28, 66.48, 66.76, 68.32, 71.2, 68.16, 73.36, 72.8, 74.08, 71.08, 75.12, 76.84, 76.52, 76.72, 77.48, 77.56, 78.84, 79.44, 80.08, 79.6, 79.88, 79.68, 81.44, 80.08, 80.44, 80.96, 81.36, 81.2, 81.48, 81.96, 82.08, 82.0, 82.2, 82.04, 82.8, 81.92, 82.12, 82.4, 81.08, 83.08, 82.96, 82.32, 83.08, 82.92, 82.96, 82.92, 82.84]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 0.982, Train accuracy: 59.200, Test loss: 1.197, Test accuracy: 48.60 

        train local model (freeze embeding):client   0,  Train loss: 0.849, Train accuracy: 64.400, Test loss: 1.141, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.893, Train accuracy: 63.200, Test loss: 1.197, Test accuracy: 51.40 

Round   0, Train loss: 0.893, Test loss: 1.197, Test accuracy: 51.40 

        train local model (freeze embeding):client   0,  Train loss: 1.004, Train accuracy: 58.600, Test loss: 1.190, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.877, Train accuracy: 65.400, Test loss: 1.155, Test accuracy: 51.80 

Round   1, Train loss: 0.877, Test loss: 1.155, Test accuracy: 51.80 

        train local model (freeze embeding):client   0,  Train loss: 0.790, Train accuracy: 68.600, Test loss: 1.177, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.754, Train accuracy: 69.000, Test loss: 1.190, Test accuracy: 55.60 

Round   2, Train loss: 0.754, Test loss: 1.190, Test accuracy: 55.60 

        train local model (freeze embeding):client   0,  Train loss: 0.672, Train accuracy: 74.600, Test loss: 1.117, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.723, Train accuracy: 71.000, Test loss: 1.207, Test accuracy: 58.60 

Round   3, Train loss: 0.723, Test loss: 1.207, Test accuracy: 58.60 

        train local model (freeze embeding):client   0,  Train loss: 0.592, Train accuracy: 78.000, Test loss: 1.074, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.570, Train accuracy: 76.600, Test loss: 1.123, Test accuracy: 58.80 

Round   4, Train loss: 0.570, Test loss: 1.123, Test accuracy: 58.80 

        train local model (freeze embeding):client   0,  Train loss: 0.456, Train accuracy: 82.600, Test loss: 1.070, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.571, Train accuracy: 78.000, Test loss: 1.090, Test accuracy: 57.80 

Round   5, Train loss: 0.571, Test loss: 1.090, Test accuracy: 57.80 

        train local model (freeze embeding):client   0,  Train loss: 0.442, Train accuracy: 82.600, Test loss: 1.085, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.530, Train accuracy: 79.600, Test loss: 1.344, Test accuracy: 56.40 

Round   6, Train loss: 0.530, Test loss: 1.344, Test accuracy: 56.40 

        train local model (freeze embeding):client   0,  Train loss: 0.466, Train accuracy: 82.000, Test loss: 1.237, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.339, Train accuracy: 89.800, Test loss: 1.145, Test accuracy: 61.80 

Round   7, Train loss: 0.339, Test loss: 1.145, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.282, Train accuracy: 88.800, Test loss: 1.186, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.517, Train accuracy: 80.600, Test loss: 1.474, Test accuracy: 54.40 

Round   8, Train loss: 0.517, Test loss: 1.474, Test accuracy: 54.40 

        train local model (freeze embeding):client   0,  Train loss: 0.365, Train accuracy: 87.800, Test loss: 1.205, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.299, Train accuracy: 88.200, Test loss: 1.179, Test accuracy: 61.60 

Round   9, Train loss: 0.299, Test loss: 1.179, Test accuracy: 61.60 

        train local model (freeze embeding):client   0,  Train loss: 0.236, Train accuracy: 93.200, Test loss: 1.157, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.220, Train accuracy: 93.400, Test loss: 1.306, Test accuracy: 63.60 

Round  10, Train loss: 0.220, Test loss: 1.306, Test accuracy: 63.60 

        train local model (freeze embeding):client   0,  Train loss: 0.198, Train accuracy: 92.000, Test loss: 1.312, Test accuracy: 64.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.161, Train accuracy: 95.400, Test loss: 1.373, Test accuracy: 59.40 

Round  11, Train loss: 0.161, Test loss: 1.373, Test accuracy: 59.40 

        train local model (freeze embeding):client   0,  Train loss: 0.121, Train accuracy: 96.000, Test loss: 1.313, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.176, Train accuracy: 94.000, Test loss: 1.415, Test accuracy: 60.40 

Round  12, Train loss: 0.176, Test loss: 1.415, Test accuracy: 60.40 

        train local model (freeze embeding):client   0,  Train loss: 0.106, Train accuracy: 97.800, Test loss: 1.448, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.175, Train accuracy: 93.800, Test loss: 1.714, Test accuracy: 56.60 

Round  13, Train loss: 0.175, Test loss: 1.714, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.076, Train accuracy: 98.000, Test loss: 1.473, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.171, Train accuracy: 93.800, Test loss: 1.460, Test accuracy: 59.60 

Round  14, Train loss: 0.171, Test loss: 1.460, Test accuracy: 59.60 

        train local model (freeze embeding):client   0,  Train loss: 0.116, Train accuracy: 96.600, Test loss: 1.424, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.134, Train accuracy: 95.000, Test loss: 1.779, Test accuracy: 56.40 

Round  15, Train loss: 0.134, Test loss: 1.779, Test accuracy: 56.40 

        train local model (freeze embeding):client   0,  Train loss: 0.082, Train accuracy: 98.200, Test loss: 1.645, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.221, Train accuracy: 93.000, Test loss: 1.891, Test accuracy: 57.00 

Round  16, Train loss: 0.221, Test loss: 1.891, Test accuracy: 57.00 

        train local model (freeze embeding):client   0,  Train loss: 0.053, Train accuracy: 98.800, Test loss: 1.565, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.061, Train accuracy: 98.000, Test loss: 1.731, Test accuracy: 60.80 

Round  17, Train loss: 0.061, Test loss: 1.731, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.047, Train accuracy: 98.600, Test loss: 1.694, Test accuracy: 61.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.115, Train accuracy: 95.800, Test loss: 1.782, Test accuracy: 60.60 

Round  18, Train loss: 0.115, Test loss: 1.782, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.064, Train accuracy: 98.400, Test loss: 1.561, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.074, Train accuracy: 98.200, Test loss: 2.026, Test accuracy: 58.80 

Round  19, Train loss: 0.074, Test loss: 2.026, Test accuracy: 58.80 

        train local model (freeze embeding):client   0,  Train loss: 0.042, Train accuracy: 98.800, Test loss: 1.896, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 100.000, Test loss: 1.749, Test accuracy: 62.80 

Final Round, Train loss: 0.022, Test loss: 1.863, Test accuracy: 60.40 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 0.773, Train accuracy: 69.400, Test loss: 0.972, Test accuracy: 61.00 

        train local model (freeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.000, Test loss: 1.852, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.068, Train accuracy: 98.600, Test loss: 1.891, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 0.745, Train accuracy: 70.400, Test loss: 0.977, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.379, Train accuracy: 86.600, Test loss: 0.974, Test accuracy: 65.60 

Round   0, Train loss: 0.224, Test loss: 1.281, Test accuracy: 64.40 

        train local model (freeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.000, Test loss: 1.795, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.053, Train accuracy: 98.400, Test loss: 1.890, Test accuracy: 61.60 

        train local model (freeze embeding):client   1,  Train loss: 0.469, Train accuracy: 81.600, Test loss: 0.914, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.220, Train accuracy: 93.000, Test loss: 1.077, Test accuracy: 69.20 

Round   1, Train loss: 0.136, Test loss: 1.291, Test accuracy: 65.60 

        train local model (freeze embeding):client   0,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 1.716, Test accuracy: 64.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.200, Test loss: 2.066, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.333, Train accuracy: 88.200, Test loss: 0.948, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.293, Train accuracy: 90.600, Test loss: 1.135, Test accuracy: 67.80 

Round   2, Train loss: 0.163, Test loss: 1.352, Test accuracy: 67.00 

        train local model (freeze embeding):client   0,  Train loss: 0.031, Train accuracy: 99.400, Test loss: 1.690, Test accuracy: 64.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.111, Train accuracy: 96.600, Test loss: 1.898, Test accuracy: 62.40 

        train local model (freeze embeding):client   1,  Train loss: 0.245, Train accuracy: 91.000, Test loss: 0.965, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.305, Train accuracy: 87.600, Test loss: 1.105, Test accuracy: 68.60 

Round   3, Train loss: 0.208, Test loss: 1.206, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.029, Train accuracy: 99.000, Test loss: 1.617, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.600, Test loss: 1.671, Test accuracy: 61.40 

        train local model (freeze embeding):client   1,  Train loss: 0.195, Train accuracy: 93.000, Test loss: 0.914, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.297, Train accuracy: 89.000, Test loss: 1.191, Test accuracy: 67.00 

Round   4, Train loss: 0.161, Test loss: 1.213, Test accuracy: 67.70 

        train local model (freeze embeding):client   0,  Train loss: 0.032, Train accuracy: 99.000, Test loss: 1.464, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.030, Train accuracy: 99.200, Test loss: 1.710, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.154, Train accuracy: 94.800, Test loss: 0.964, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.212, Train accuracy: 92.200, Test loss: 1.307, Test accuracy: 68.80 

Round   5, Train loss: 0.121, Test loss: 1.286, Test accuracy: 68.20 

        train local model (freeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.000, Test loss: 1.480, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.000, Test loss: 1.706, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.121, Train accuracy: 96.400, Test loss: 1.030, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.126, Train accuracy: 94.800, Test loss: 1.404, Test accuracy: 70.60 

Round   6, Train loss: 0.076, Test loss: 1.303, Test accuracy: 68.40 

        train local model (freeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.609, Test accuracy: 65.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.040, Train accuracy: 98.400, Test loss: 1.801, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.082, Train accuracy: 97.600, Test loss: 1.037, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.082, Train accuracy: 97.400, Test loss: 1.222, Test accuracy: 69.40 

Round   7, Train loss: 0.061, Test loss: 1.335, Test accuracy: 68.60 

        train local model (freeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.601, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.033, Train accuracy: 99.200, Test loss: 1.922, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.072, Train accuracy: 97.200, Test loss: 1.110, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.182, Train accuracy: 93.800, Test loss: 1.573, Test accuracy: 67.20 

Round   8, Train loss: 0.108, Test loss: 1.461, Test accuracy: 68.20 

        train local model (freeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.619, Test accuracy: 66.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 100.000, Test loss: 1.688, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.098, Train accuracy: 96.400, Test loss: 1.122, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.092, Train accuracy: 96.800, Test loss: 1.146, Test accuracy: 72.20 

Round   9, Train loss: 0.055, Test loss: 1.278, Test accuracy: 68.30 

        train local model (freeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.600, Test accuracy: 65.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.038, Train accuracy: 98.400, Test loss: 2.370, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.050, Train accuracy: 99.000, Test loss: 1.015, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.083, Train accuracy: 97.600, Test loss: 1.400, Test accuracy: 69.80 

Round  10, Train loss: 0.060, Test loss: 1.437, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 1.657, Test accuracy: 67.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 99.200, Test loss: 1.757, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.031, Train accuracy: 99.000, Test loss: 1.012, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.129, Train accuracy: 97.000, Test loss: 1.718, Test accuracy: 66.20 

Round  11, Train loss: 0.082, Test loss: 1.378, Test accuracy: 68.50 

        train local model (freeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 1.533, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.200, Test loss: 2.298, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 0.024, Train accuracy: 100.000, Test loss: 1.122, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.072, Train accuracy: 98.000, Test loss: 1.447, Test accuracy: 72.00 

Round  12, Train loss: 0.049, Test loss: 1.572, Test accuracy: 69.40 

        train local model (freeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.805, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 2.003, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 0.023, Train accuracy: 99.600, Test loss: 1.180, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.061, Train accuracy: 97.800, Test loss: 1.384, Test accuracy: 71.80 

Round  13, Train loss: 0.039, Test loss: 1.498, Test accuracy: 70.00 

        train local model (freeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.755, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.035, Train accuracy: 99.200, Test loss: 2.075, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 0.020, Train accuracy: 99.400, Test loss: 1.177, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.128, Train accuracy: 95.800, Test loss: 1.488, Test accuracy: 69.00 

Round  14, Train loss: 0.081, Test loss: 1.401, Test accuracy: 69.30 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.660, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.400, Test loss: 2.365, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.024, Train accuracy: 99.600, Test loss: 1.077, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.167, Train accuracy: 93.600, Test loss: 1.650, Test accuracy: 70.00 

Round  15, Train loss: 0.089, Test loss: 1.655, Test accuracy: 69.00 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.976, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.053, Train accuracy: 98.400, Test loss: 1.732, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.181, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.148, Train accuracy: 94.800, Test loss: 1.573, Test accuracy: 69.20 

Round  16, Train loss: 0.100, Test loss: 1.304, Test accuracy: 72.20 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.528, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.726, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 0.025, Train accuracy: 99.400, Test loss: 1.076, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.056, Train accuracy: 98.200, Test loss: 1.340, Test accuracy: 73.80 

Round  17, Train loss: 0.042, Test loss: 1.316, Test accuracy: 70.10 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.584, Test accuracy: 66.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.200, Test loss: 1.832, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 0.024, Train accuracy: 99.400, Test loss: 1.053, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.043, Train accuracy: 98.600, Test loss: 1.159, Test accuracy: 72.40 

Round  18, Train loss: 0.033, Test loss: 1.309, Test accuracy: 71.70 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.556, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.047, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.076, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.240, Test accuracy: 76.40 

Round  19, Train loss: 0.005, Test loss: 1.449, Test accuracy: 71.60 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.745, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.922, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.162, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 1.408, Test accuracy: 72.80 

Final Round, Train loss: 0.017, Test loss: 1.435, Test accuracy: 71.30 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 0.603, Train accuracy: 76.800, Test loss: 0.849, Test accuracy: 68.00 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.696, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.039, Train accuracy: 98.600, Test loss: 2.000, Test accuracy: 61.80 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.151, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.281, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.566, Train accuracy: 79.400, Test loss: 0.804, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.286, Train accuracy: 89.400, Test loss: 1.004, Test accuracy: 68.00 

Round   0, Train loss: 0.111, Test loss: 1.159, Test accuracy: 71.27 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.573, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.000, Test loss: 2.120, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.036, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.044, Train accuracy: 98.600, Test loss: 1.496, Test accuracy: 70.00 

        train local model (freeze embeding):client   2,  Train loss: 0.369, Train accuracy: 87.400, Test loss: 0.823, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.237, Train accuracy: 91.000, Test loss: 0.978, Test accuracy: 70.40 

Round   1, Train loss: 0.102, Test loss: 1.140, Test accuracy: 72.20 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.554, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 2.021, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.078, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.528, Test accuracy: 72.60 

        train local model (freeze embeding):client   2,  Train loss: 0.250, Train accuracy: 92.200, Test loss: 0.816, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.283, Train accuracy: 91.000, Test loss: 1.029, Test accuracy: 69.00 

Round   2, Train loss: 0.111, Test loss: 1.183, Test accuracy: 71.20 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.635, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 2.070, Test accuracy: 63.20 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.127, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.030, Train accuracy: 99.200, Test loss: 1.563, Test accuracy: 70.60 

        train local model (freeze embeding):client   2,  Train loss: 0.193, Train accuracy: 94.000, Test loss: 0.829, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.203, Train accuracy: 93.000, Test loss: 1.047, Test accuracy: 73.60 

Round   3, Train loss: 0.085, Test loss: 1.142, Test accuracy: 73.40 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.593, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.035, Train accuracy: 99.000, Test loss: 1.930, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.099, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.022, Train accuracy: 99.600, Test loss: 1.449, Test accuracy: 72.80 

        train local model (freeze embeding):client   2,  Train loss: 0.131, Train accuracy: 96.600, Test loss: 0.813, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.180, Train accuracy: 93.800, Test loss: 1.098, Test accuracy: 71.00 

Round   4, Train loss: 0.079, Test loss: 1.122, Test accuracy: 72.93 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.497, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.000, Test loss: 1.665, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.124, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.206, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.122, Train accuracy: 96.600, Test loss: 0.866, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.141, Train accuracy: 93.400, Test loss: 0.959, Test accuracy: 72.20 

Round   5, Train loss: 0.060, Test loss: 1.099, Test accuracy: 73.87 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.373, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.200, Test loss: 1.961, Test accuracy: 68.40 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.042, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.067, Train accuracy: 96.800, Test loss: 1.510, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.086, Train accuracy: 97.800, Test loss: 0.833, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.158, Train accuracy: 95.400, Test loss: 1.231, Test accuracy: 70.80 

Round   6, Train loss: 0.081, Test loss: 1.187, Test accuracy: 72.13 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.585, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.072, Train accuracy: 97.200, Test loss: 1.792, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.083, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.062, Train accuracy: 98.000, Test loss: 1.452, Test accuracy: 72.40 

        train local model (freeze embeding):client   2,  Train loss: 0.083, Train accuracy: 98.000, Test loss: 0.924, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.060, Train accuracy: 98.200, Test loss: 1.151, Test accuracy: 72.80 

Round   7, Train loss: 0.065, Test loss: 1.129, Test accuracy: 73.80 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.407, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 98.800, Test loss: 1.804, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.018, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.323, Test accuracy: 73.60 

        train local model (freeze embeding):client   2,  Train loss: 0.059, Train accuracy: 99.200, Test loss: 0.920, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.151, Train accuracy: 93.800, Test loss: 1.369, Test accuracy: 67.80 

Round   8, Train loss: 0.060, Test loss: 1.191, Test accuracy: 72.53 

        train local model (freeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.400, Test loss: 1.509, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.026, Train accuracy: 99.200, Test loss: 1.836, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.049, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.275, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.033, Train accuracy: 99.400, Test loss: 0.950, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.103, Train accuracy: 95.200, Test loss: 1.248, Test accuracy: 71.00 

Round   9, Train loss: 0.044, Test loss: 1.162, Test accuracy: 73.53 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.535, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.037, Train accuracy: 99.000, Test loss: 1.944, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.069, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.326, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.028, Train accuracy: 99.400, Test loss: 0.971, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.057, Train accuracy: 98.800, Test loss: 1.075, Test accuracy: 75.20 

Round  10, Train loss: 0.034, Test loss: 1.106, Test accuracy: 74.73 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.420, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.760, Test accuracy: 67.20 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.035, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.431, Test accuracy: 72.40 

        train local model (freeze embeding):client   2,  Train loss: 0.018, Train accuracy: 99.800, Test loss: 0.939, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.286, Train accuracy: 90.400, Test loss: 1.477, Test accuracy: 67.80 

Round  11, Train loss: 0.113, Test loss: 1.094, Test accuracy: 73.87 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.415, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.828, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.016, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.329, Test accuracy: 76.00 

        train local model (freeze embeding):client   2,  Train loss: 0.038, Train accuracy: 99.200, Test loss: 0.985, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.061, Train accuracy: 98.000, Test loss: 1.154, Test accuracy: 73.80 

Round  12, Train loss: 0.025, Test loss: 1.156, Test accuracy: 74.67 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.515, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.606, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.090, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.028, Train accuracy: 98.600, Test loss: 1.548, Test accuracy: 74.00 

        train local model (freeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 0.922, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.055, Train accuracy: 98.200, Test loss: 1.138, Test accuracy: 75.20 

Round  13, Train loss: 0.033, Test loss: 1.184, Test accuracy: 73.53 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.511, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.600, Test loss: 1.741, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.074, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.266, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.023, Train accuracy: 99.200, Test loss: 0.948, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.070, Train accuracy: 97.600, Test loss: 1.275, Test accuracy: 73.60 

Round  14, Train loss: 0.033, Test loss: 1.172, Test accuracy: 74.93 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.598, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.751, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.096, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.315, Test accuracy: 73.60 

        train local model (freeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.000, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.033, Train accuracy: 99.400, Test loss: 1.373, Test accuracy: 70.60 

Round  15, Train loss: 0.022, Test loss: 1.162, Test accuracy: 73.60 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.444, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.804, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.036, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.280, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.020, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.096, Train accuracy: 97.200, Test loss: 1.319, Test accuracy: 68.80 

Round  16, Train loss: 0.037, Test loss: 1.193, Test accuracy: 73.60 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.513, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.492, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.027, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.400, Test loss: 1.470, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 1.021, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.207, Test accuracy: 74.20 

Round  17, Train loss: 0.013, Test loss: 1.172, Test accuracy: 73.33 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.521, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 98.800, Test loss: 1.791, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.091, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.044, Train accuracy: 98.200, Test loss: 1.491, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.049, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.034, Train accuracy: 99.000, Test loss: 1.152, Test accuracy: 75.00 

Round  18, Train loss: 0.038, Test loss: 1.154, Test accuracy: 75.47 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.535, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.697, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.078, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.174, Train accuracy: 94.200, Test loss: 1.750, Test accuracy: 70.00 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.041, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.022, Train accuracy: 99.600, Test loss: 1.268, Test accuracy: 73.60 

Round  19, Train loss: 0.066, Test loss: 1.205, Test accuracy: 73.67 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.600, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.865, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.075, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.235, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.955, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.174, Train accuracy: 95.200, Test loss: 1.639, Test accuracy: 70.00 

Final Round, Train loss: 0.065, Test loss: 1.180, Test accuracy: 74.53 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 0.645, Train accuracy: 73.800, Test loss: 0.737, Test accuracy: 71.00 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.605, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.491, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.048, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.400, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.019, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.047, Train accuracy: 98.800, Test loss: 1.349, Test accuracy: 71.00 

        train local model (freeze embeding):client   3,  Train loss: 0.578, Train accuracy: 75.400, Test loss: 0.703, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.225, Train accuracy: 92.200, Test loss: 0.772, Test accuracy: 76.20 

Round   0, Train loss: 0.069, Test loss: 1.056, Test accuracy: 75.50 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.364, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.644, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.040, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.200, Test loss: 1.308, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.005, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.157, Test accuracy: 75.40 

        train local model (freeze embeding):client   3,  Train loss: 0.375, Train accuracy: 85.400, Test loss: 0.656, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.204, Train accuracy: 92.000, Test loss: 0.951, Test accuracy: 69.40 

Round   1, Train loss: 0.060, Test loss: 1.030, Test accuracy: 76.15 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.417, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.682, Test accuracy: 70.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.079, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.165, Test accuracy: 78.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.923, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.079, Train accuracy: 97.800, Test loss: 1.181, Test accuracy: 74.60 

        train local model (freeze embeding):client   3,  Train loss: 0.247, Train accuracy: 91.400, Test loss: 0.651, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.132, Train accuracy: 95.600, Test loss: 0.775, Test accuracy: 77.40 

Round   2, Train loss: 0.055, Test loss: 1.001, Test accuracy: 76.55 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.406, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.823, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.056, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.248, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.952, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.035, Train accuracy: 99.400, Test loss: 1.179, Test accuracy: 73.40 

        train local model (freeze embeding):client   3,  Train loss: 0.185, Train accuracy: 93.000, Test loss: 0.659, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.252, Train accuracy: 91.000, Test loss: 1.161, Test accuracy: 71.00 

Round   3, Train loss: 0.072, Test loss: 1.034, Test accuracy: 75.25 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.414, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.752, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.057, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.561, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.975, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.096, Train accuracy: 96.000, Test loss: 1.564, Test accuracy: 69.40 

        train local model (freeze embeding):client   3,  Train loss: 0.129, Train accuracy: 96.600, Test loss: 0.732, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.159, Train accuracy: 94.400, Test loss: 1.060, Test accuracy: 72.40 

Round   4, Train loss: 0.068, Test loss: 1.008, Test accuracy: 77.15 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.381, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.825, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.017, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.119, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.974, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.028, Train accuracy: 99.400, Test loss: 1.401, Test accuracy: 74.60 

        train local model (freeze embeding):client   3,  Train loss: 0.100, Train accuracy: 98.200, Test loss: 0.720, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.079, Train accuracy: 97.200, Test loss: 1.002, Test accuracy: 72.00 

Round   5, Train loss: 0.034, Test loss: 0.998, Test accuracy: 76.70 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.311, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.756, Test accuracy: 67.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.995, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.022, Train accuracy: 99.400, Test loss: 1.254, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 0.926, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.059, Train accuracy: 98.200, Test loss: 1.424, Test accuracy: 71.20 

        train local model (freeze embeding):client   3,  Train loss: 0.068, Train accuracy: 98.200, Test loss: 0.710, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.154, Train accuracy: 94.000, Test loss: 0.977, Test accuracy: 72.60 

Round   6, Train loss: 0.063, Test loss: 0.976, Test accuracy: 76.00 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.268, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.600, Test loss: 1.551, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.954, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.158, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 0.937, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.051, Train accuracy: 98.200, Test loss: 1.172, Test accuracy: 75.00 

        train local model (freeze embeding):client   3,  Train loss: 0.062, Train accuracy: 99.200, Test loss: 0.683, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.266, Train accuracy: 90.000, Test loss: 1.351, Test accuracy: 69.40 

Round   7, Train loss: 0.083, Test loss: 0.987, Test accuracy: 76.85 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.320, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.082, Train accuracy: 97.200, Test loss: 1.684, Test accuracy: 69.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.989, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.073, Train accuracy: 98.400, Test loss: 1.474, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.909, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.063, Train accuracy: 98.200, Test loss: 1.207, Test accuracy: 75.00 

        train local model (freeze embeding):client   3,  Train loss: 0.042, Train accuracy: 99.400, Test loss: 0.755, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.125, Train accuracy: 95.000, Test loss: 1.073, Test accuracy: 72.80 

Round   8, Train loss: 0.086, Test loss: 0.961, Test accuracy: 77.35 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.282, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.200, Test loss: 1.741, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.871, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.153, Test accuracy: 79.20 

        train local model (freeze embeding):client   2,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 0.867, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.050, Train accuracy: 98.400, Test loss: 1.259, Test accuracy: 74.80 

        train local model (freeze embeding):client   3,  Train loss: 0.044, Train accuracy: 99.200, Test loss: 0.772, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.052, Train accuracy: 98.600, Test loss: 1.079, Test accuracy: 73.80 

Round   9, Train loss: 0.031, Test loss: 0.991, Test accuracy: 77.00 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.309, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 99.200, Test loss: 1.928, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.880, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.205, Test accuracy: 80.20 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.876, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.112, Test accuracy: 77.20 

        train local model (freeze embeding):client   3,  Train loss: 0.027, Train accuracy: 99.800, Test loss: 0.826, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.205, Train accuracy: 92.600, Test loss: 1.263, Test accuracy: 71.80 

Round  10, Train loss: 0.063, Test loss: 1.031, Test accuracy: 77.50 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.461, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.053, Train accuracy: 98.400, Test loss: 1.847, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.909, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.029, Train accuracy: 99.400, Test loss: 1.069, Test accuracy: 78.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.947, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.091, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.014, Train accuracy: 100.000, Test loss: 0.753, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.082, Train accuracy: 97.000, Test loss: 0.941, Test accuracy: 75.40 

Round  11, Train loss: 0.042, Test loss: 0.982, Test accuracy: 77.95 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.391, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.709, Test accuracy: 70.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.898, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.116, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.910, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.107, Train accuracy: 96.600, Test loss: 1.449, Test accuracy: 73.00 

        train local model (freeze embeding):client   3,  Train loss: 0.016, Train accuracy: 100.000, Test loss: 0.759, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.052, Train accuracy: 97.800, Test loss: 0.951, Test accuracy: 77.20 

Round  12, Train loss: 0.041, Test loss: 1.021, Test accuracy: 78.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.373, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.524, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.959, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.039, Train accuracy: 98.600, Test loss: 1.159, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.943, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.144, Test accuracy: 75.80 

        train local model (freeze embeding):client   3,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 0.835, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.090, Train accuracy: 97.000, Test loss: 1.052, Test accuracy: 76.00 

Round  13, Train loss: 0.038, Test loss: 0.960, Test accuracy: 77.60 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.207, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.029, Train accuracy: 99.000, Test loss: 1.501, Test accuracy: 70.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.912, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.048, Test accuracy: 80.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.893, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.102, Test accuracy: 77.40 

        train local model (freeze embeding):client   3,  Train loss: 0.014, Train accuracy: 100.000, Test loss: 0.768, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.207, Train accuracy: 92.000, Test loss: 1.611, Test accuracy: 67.80 

Round  14, Train loss: 0.063, Test loss: 0.984, Test accuracy: 78.15 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.281, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.635, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.898, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.082, Test accuracy: 80.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.944, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.153, Test accuracy: 75.20 

        train local model (freeze embeding):client   3,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 0.811, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.089, Train accuracy: 97.600, Test loss: 1.254, Test accuracy: 74.00 

Round  15, Train loss: 0.027, Test loss: 1.042, Test accuracy: 77.65 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.329, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.466, Test accuracy: 71.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.935, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.121, Test accuracy: 75.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.993, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.065, Train accuracy: 97.400, Test loss: 0.950, Test accuracy: 76.60 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 0.906, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.094, Train accuracy: 97.400, Test loss: 1.243, Test accuracy: 75.60 

Round  16, Train loss: 0.044, Test loss: 0.937, Test accuracy: 77.95 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.251, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.457, Test accuracy: 74.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 0.870, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.093, Train accuracy: 97.200, Test loss: 1.303, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.891, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.993, Test accuracy: 80.00 

        train local model (freeze embeding):client   3,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 0.795, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.045, Train accuracy: 98.800, Test loss: 1.053, Test accuracy: 74.80 

Round  17, Train loss: 0.035, Test loss: 0.999, Test accuracy: 78.10 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.351, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.487, Test accuracy: 71.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.914, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.106, Test accuracy: 79.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.961, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.081, Train accuracy: 98.000, Test loss: 1.194, Test accuracy: 73.80 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.821, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.110, Train accuracy: 96.200, Test loss: 1.242, Test accuracy: 73.20 

Round  18, Train loss: 0.048, Test loss: 1.011, Test accuracy: 77.85 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.281, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.649, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.942, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.113, Test accuracy: 80.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.939, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.021, Test accuracy: 79.40 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 0.801, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.067, Train accuracy: 98.000, Test loss: 1.335, Test accuracy: 73.20 

Round  19, Train loss: 0.018, Test loss: 1.034, Test accuracy: 77.95 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.400, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.525, Test accuracy: 74.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.947, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.213, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.954, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.017, Test accuracy: 77.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.832, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.031, Train accuracy: 99.000, Test loss: 1.188, Test accuracy: 76.00 

Final Round, Train loss: 0.009, Test loss: 1.022, Test accuracy: 78.15 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.434, Train accuracy: 84.600, Test loss: 0.643, Test accuracy: 78.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.354, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.502, Test accuracy: 72.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.945, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.173, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.930, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.976, Test accuracy: 79.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.840, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.028, Train accuracy: 98.800, Test loss: 1.303, Test accuracy: 73.20 

        train local model (freeze embeding):client   4,  Train loss: 0.444, Train accuracy: 83.000, Test loss: 0.627, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.170, Train accuracy: 92.200, Test loss: 0.834, Test accuracy: 73.80 

Round   0, Train loss: 0.040, Test loss: 0.946, Test accuracy: 78.96 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.359, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.063, Train accuracy: 98.000, Test loss: 2.083, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.947, Test accuracy: 82.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.065, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.958, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.052, Test accuracy: 78.20 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.019, Train accuracy: 99.600, Test loss: 1.026, Test accuracy: 75.60 

        train local model (freeze embeding):client   4,  Train loss: 0.297, Train accuracy: 89.200, Test loss: 0.623, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.110, Train accuracy: 96.000, Test loss: 0.700, Test accuracy: 78.60 

Round   1, Train loss: 0.043, Test loss: 0.897, Test accuracy: 79.52 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.289, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.549, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.898, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.021, Test accuracy: 81.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.920, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.078, Test accuracy: 79.60 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.787, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.065, Train accuracy: 97.200, Test loss: 1.172, Test accuracy: 74.40 

        train local model (freeze embeding):client   4,  Train loss: 0.205, Train accuracy: 94.000, Test loss: 0.628, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.149, Train accuracy: 95.400, Test loss: 0.792, Test accuracy: 79.40 

Round   2, Train loss: 0.043, Test loss: 0.898, Test accuracy: 79.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.234, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.030, Train accuracy: 99.000, Test loss: 1.577, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.891, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.043, Test accuracy: 79.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.903, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.116, Train accuracy: 96.600, Test loss: 1.335, Test accuracy: 71.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.823, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.072, Train accuracy: 97.200, Test loss: 1.688, Test accuracy: 70.20 

        train local model (freeze embeding):client   4,  Train loss: 0.155, Train accuracy: 94.800, Test loss: 0.670, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.096, Train accuracy: 96.800, Test loss: 0.780, Test accuracy: 78.20 

Round   3, Train loss: 0.063, Test loss: 0.885, Test accuracy: 78.96 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.191, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.119, Train accuracy: 96.400, Test loss: 2.058, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.121, Train accuracy: 95.600, Test loss: 1.278, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.883, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.046, Train accuracy: 98.200, Test loss: 1.138, Test accuracy: 75.00 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 0.801, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.921, Test accuracy: 81.40 

        train local model (freeze embeding):client   4,  Train loss: 0.122, Train accuracy: 96.800, Test loss: 0.657, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.143, Train accuracy: 94.600, Test loss: 0.989, Test accuracy: 73.00 

Round   4, Train loss: 0.086, Test loss: 0.910, Test accuracy: 79.32 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.283, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.315, Test accuracy: 76.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.940, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.316, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.932, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.153, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 0.830, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.115, Train accuracy: 95.200, Test loss: 1.350, Test accuracy: 70.60 

        train local model (freeze embeding):client   4,  Train loss: 0.083, Train accuracy: 98.000, Test loss: 0.688, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.086, Train accuracy: 97.600, Test loss: 1.045, Test accuracy: 74.20 

Round   5, Train loss: 0.042, Test loss: 0.932, Test accuracy: 78.72 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.197, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.200, Test loss: 1.799, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.887, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.082, Train accuracy: 96.800, Test loss: 1.428, Test accuracy: 71.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.944, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.029, Train accuracy: 99.000, Test loss: 1.029, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.836, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.177, Train accuracy: 93.600, Test loss: 1.218, Test accuracy: 73.00 

        train local model (freeze embeding):client   4,  Train loss: 0.059, Train accuracy: 98.200, Test loss: 0.729, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.062, Train accuracy: 98.600, Test loss: 1.004, Test accuracy: 75.80 

Round   6, Train loss: 0.075, Test loss: 0.867, Test accuracy: 78.60 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.138, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.537, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.797, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.989, Test accuracy: 81.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.910, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.040, Train accuracy: 98.600, Test loss: 1.095, Test accuracy: 73.80 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 0.816, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.120, Train accuracy: 95.800, Test loss: 1.282, Test accuracy: 74.40 

        train local model (freeze embeding):client   4,  Train loss: 0.055, Train accuracy: 98.800, Test loss: 0.717, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.063, Train accuracy: 98.600, Test loss: 1.203, Test accuracy: 74.00 

Round   7, Train loss: 0.045, Test loss: 0.898, Test accuracy: 79.68 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.213, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.333, Test accuracy: 72.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.849, Test accuracy: 82.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.016, Test accuracy: 82.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.949, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.131, Test accuracy: 77.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.787, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.112, Train accuracy: 96.600, Test loss: 1.318, Test accuracy: 74.60 

        train local model (freeze embeding):client   4,  Train loss: 0.039, Train accuracy: 99.400, Test loss: 0.723, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.062, Train accuracy: 98.600, Test loss: 0.925, Test accuracy: 78.20 

Round   8, Train loss: 0.036, Test loss: 0.915, Test accuracy: 79.76 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.210, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.844, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.846, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.046, Train accuracy: 98.200, Test loss: 1.217, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.956, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.049, Train accuracy: 98.600, Test loss: 1.203, Test accuracy: 77.00 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.867, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.021, Train accuracy: 99.200, Test loss: 1.314, Test accuracy: 75.60 

        train local model (freeze embeding):client   4,  Train loss: 0.023, Train accuracy: 99.800, Test loss: 0.757, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.108, Train accuracy: 96.800, Test loss: 0.976, Test accuracy: 76.00 

Round   9, Train loss: 0.047, Test loss: 0.938, Test accuracy: 79.68 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.231, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.528, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.856, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.016, Test accuracy: 81.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.953, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.200, Test loss: 1.302, Test accuracy: 74.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.896, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.130, Train accuracy: 94.800, Test loss: 1.395, Test accuracy: 71.40 

        train local model (freeze embeding):client   4,  Train loss: 0.021, Train accuracy: 100.000, Test loss: 0.765, Test accuracy: 82.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.028, Train accuracy: 99.800, Test loss: 0.885, Test accuracy: 77.00 

Round  10, Train loss: 0.036, Test loss: 0.922, Test accuracy: 79.08 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.210, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.519, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.868, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 98.800, Test loss: 1.381, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.003, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.082, Train accuracy: 97.200, Test loss: 1.625, Test accuracy: 72.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.862, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.917, Test accuracy: 79.20 

        train local model (freeze embeding):client   4,  Train loss: 0.019, Train accuracy: 99.800, Test loss: 0.765, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.100, Train accuracy: 96.400, Test loss: 0.958, Test accuracy: 78.00 

Round  11, Train loss: 0.046, Test loss: 0.932, Test accuracy: 79.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.185, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.530, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.823, Test accuracy: 82.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.213, Test accuracy: 75.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.048, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.115, Test accuracy: 77.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.872, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.941, Test accuracy: 78.40 

        train local model (freeze embeding):client   4,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 0.792, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.035, Train accuracy: 99.400, Test loss: 0.866, Test accuracy: 76.80 

Round  12, Train loss: 0.012, Test loss: 0.912, Test accuracy: 79.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.166, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.000, Test loss: 1.619, Test accuracy: 68.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.902, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.155, Test accuracy: 76.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.997, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.052, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.851, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.060, Train accuracy: 98.000, Test loss: 1.429, Test accuracy: 73.40 

        train local model (freeze embeding):client   4,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 0.750, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.025, Train accuracy: 99.400, Test loss: 1.152, Test accuracy: 75.00 

Round  13, Train loss: 0.025, Test loss: 0.939, Test accuracy: 79.48 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.211, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.353, Test accuracy: 72.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 0.870, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.878, Test accuracy: 83.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.945, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.064, Test accuracy: 78.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.865, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.038, Test accuracy: 78.40 

        train local model (freeze embeding):client   4,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 0.798, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.050, Train accuracy: 98.200, Test loss: 1.183, Test accuracy: 77.80 

Round  14, Train loss: 0.017, Test loss: 0.967, Test accuracy: 79.96 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.198, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.330, Test accuracy: 73.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 83.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.938, Test accuracy: 83.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.974, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.091, Train accuracy: 97.400, Test loss: 1.321, Test accuracy: 73.60 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.897, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.049, Train accuracy: 98.000, Test loss: 1.337, Test accuracy: 72.00 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.862, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.105, Train accuracy: 96.400, Test loss: 1.173, Test accuracy: 75.40 

Round  15, Train loss: 0.049, Test loss: 0.959, Test accuracy: 79.68 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.275, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.000, Test loss: 1.408, Test accuracy: 74.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.873, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.936, Test accuracy: 84.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.984, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.033, Train accuracy: 99.000, Test loss: 1.316, Test accuracy: 73.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.947, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.057, Train accuracy: 97.200, Test loss: 1.495, Test accuracy: 72.00 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.848, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.045, Train accuracy: 98.000, Test loss: 1.064, Test accuracy: 77.40 

Round  16, Train loss: 0.031, Test loss: 0.964, Test accuracy: 80.00 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.221, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.377, Test accuracy: 73.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.834, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.062, Test accuracy: 79.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.067, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.132, Test accuracy: 77.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.894, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.196, Train accuracy: 93.000, Test loss: 1.472, Test accuracy: 68.60 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.883, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 0.981, Test accuracy: 79.40 

Round  17, Train loss: 0.043, Test loss: 0.950, Test accuracy: 80.04 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.230, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.587, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.836, Test accuracy: 83.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.179, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.976, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.038, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.904, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.034, Train accuracy: 98.600, Test loss: 1.113, Test accuracy: 75.20 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.825, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.074, Train accuracy: 96.800, Test loss: 1.204, Test accuracy: 73.40 

Round  18, Train loss: 0.026, Test loss: 0.950, Test accuracy: 79.88 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.186, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.343, Test accuracy: 73.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.877, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.168, Test accuracy: 78.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.968, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.007, Train accuracy: 99.400, Test loss: 1.109, Test accuracy: 77.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.927, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.028, Train accuracy: 99.200, Test loss: 1.150, Test accuracy: 73.00 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.862, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.063, Train accuracy: 97.400, Test loss: 1.266, Test accuracy: 75.40 

Round  19, Train loss: 0.021, Test loss: 0.964, Test accuracy: 79.32 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.152, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.030, Train accuracy: 99.200, Test loss: 1.469, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.816, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.972, Test accuracy: 81.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.972, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.048, Test accuracy: 78.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.861, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.945, Test accuracy: 78.80 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.868, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.980, Test accuracy: 80.60 

Final Round, Train loss: 0.007, Test loss: 0.932, Test accuracy: 80.04 

Average accuracy final 10 rounds: 361.2240000000001 

3159.7084362506866
[9.502334356307983, 18.859412908554077, 28.47997283935547, 37.896504640579224, 47.63748836517334, 57.24020338058472, 66.26825189590454, 75.3357458114624, 84.65962195396423, 94.69562435150146, 104.03727197647095, 113.05645275115967, 122.27024531364441, 132.0533320903778, 141.3618245124817, 151.24042630195618, 160.0533800125122, 169.8166642189026, 179.2434241771698, 188.80167651176453, 198.15642786026, 207.31611585617065, 216.58091950416565, 226.35419940948486, 235.73853254318237, 245.37223029136658, 254.74244856834412, 264.10555267333984, 273.5012638568878, 282.9470183849335, 293.08938002586365, 302.30549788475037, 311.59371280670166, 321.8398611545563, 331.6735472679138, 341.7262644767761, 351.8452687263489, 361.22493529319763, 371.0042462348938, 380.9415624141693, 390.79174518585205, 400.62917160987854, 410.35294938087463, 420.19983553886414, 429.9271123409271, 439.27322912216187, 448.908056974411, 459.13673400878906, 468.89803290367126, 479.07569217681885, 488.8169775009155, 498.7302813529968, 508.3420126438141, 518.2374603748322, 528.3326382637024, 538.0748648643494, 547.7618591785431, 557.3924434185028, 566.8537545204163, 576.5204095840454, 586.1011915206909, 596.2018191814423, 606.0438277721405, 615.9297723770142, 625.5393187999725, 635.3497774600983, 645.4012613296509, 655.1708786487579, 664.8949861526489, 674.3859820365906, 684.0511796474457, 693.6921467781067, 703.5702753067017, 713.1276280879974, 723.025554895401, 733.0144696235657, 742.8108372688293, 752.4967629909515, 762.1432309150696, 772.1480882167816, 782.2183780670166, 792.2959761619568, 801.9065489768982, 811.8966996669769, 821.4656717777252, 831.0710062980652, 840.6320023536682, 850.4009835720062, 860.591903924942, 870.5341665744781, 880.4738984107971, 890.4970328807831, 900.337338924408, 909.9739971160889, 920.2893807888031, 930.1467394828796, 939.9319593906403, 949.6951158046722, 959.8536951541901, 970.0881700515747, 979.9891223907471, 989.7362713813782, 999.8445334434509, 1009.6254696846008, 1019.1809194087982]
[51.4, 51.8, 55.6, 58.6, 58.8, 57.8, 56.4, 61.8, 54.4, 61.6, 63.6, 59.4, 60.4, 56.6, 59.6, 56.4, 57.0, 60.8, 60.6, 58.8, 60.4, 64.4, 65.6, 67.0, 69.9, 67.7, 68.2, 68.4, 68.6, 68.2, 68.3, 69.9, 68.5, 69.4, 70.0, 69.3, 69.0, 72.2, 70.1, 71.7, 71.6, 71.3, 71.26666666666667, 72.2, 71.2, 73.4, 72.93333333333334, 73.86666666666666, 72.13333333333334, 73.8, 72.53333333333333, 73.53333333333333, 74.73333333333333, 73.86666666666666, 74.66666666666667, 73.53333333333333, 74.93333333333334, 73.6, 73.6, 73.33333333333333, 75.46666666666667, 73.66666666666667, 74.53333333333333, 75.5, 76.15, 76.55, 75.25, 77.15, 76.7, 76.0, 76.85, 77.35, 77.0, 77.5, 77.95, 78.2, 77.6, 78.15, 77.65, 77.95, 78.1, 77.85, 77.95, 78.15, 78.96, 79.52, 79.4, 78.96, 79.32, 78.72, 78.6, 79.68, 79.76, 79.68, 79.08, 79.8, 79.8, 79.48, 79.96, 79.68, 80.0, 80.04, 79.88, 79.32, 80.04]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.431, Test loss: 1.346, Test accuracy: 48.44 

Round   0, Global train loss: 1.431, Global test loss: 2.603, Global test accuracy: 17.16 

Round   1, Train loss: 1.112, Test loss: 1.147, Test accuracy: 56.60 

Round   1, Global train loss: 1.112, Global test loss: 2.851, Global test accuracy: 16.44 

Round   2, Train loss: 0.964, Test loss: 1.207, Test accuracy: 58.56 

Round   2, Global train loss: 0.964, Global test loss: 2.922, Global test accuracy: 16.44 

Round   3, Train loss: 0.840, Test loss: 1.271, Test accuracy: 59.48 

Round   3, Global train loss: 0.840, Global test loss: 2.907, Global test accuracy: 16.44 

Round   4, Train loss: 0.727, Test loss: 1.445, Test accuracy: 58.08 

Round   4, Global train loss: 0.727, Global test loss: 2.974, Global test accuracy: 16.20 

Round   5, Train loss: 0.627, Test loss: 1.324, Test accuracy: 61.84 

Round   5, Global train loss: 0.627, Global test loss: 3.173, Global test accuracy: 16.16 

Round   6, Train loss: 0.531, Test loss: 1.388, Test accuracy: 62.36 

Round   6, Global train loss: 0.531, Global test loss: 2.927, Global test accuracy: 16.12 

Round   7, Train loss: 0.470, Test loss: 1.721, Test accuracy: 56.84 

Round   7, Global train loss: 0.470, Global test loss: 3.073, Global test accuracy: 16.44 

Round   8, Train loss: 0.384, Test loss: 1.444, Test accuracy: 64.76 

Round   8, Global train loss: 0.384, Global test loss: 3.201, Global test accuracy: 16.04 

Round   9, Train loss: 0.331, Test loss: 1.488, Test accuracy: 62.96 

Round   9, Global train loss: 0.331, Global test loss: 3.113, Global test accuracy: 16.24 

Round  10, Train loss: 0.269, Test loss: 1.749, Test accuracy: 62.64 

Round  10, Global train loss: 0.269, Global test loss: 3.288, Global test accuracy: 16.04 

Round  11, Train loss: 0.259, Test loss: 1.607, Test accuracy: 65.16 

Round  11, Global train loss: 0.259, Global test loss: 3.282, Global test accuracy: 16.00 

Round  12, Train loss: 0.207, Test loss: 1.739, Test accuracy: 64.48 

Round  12, Global train loss: 0.207, Global test loss: 3.186, Global test accuracy: 16.04 

Round  13, Train loss: 0.178, Test loss: 1.661, Test accuracy: 64.96 

Round  13, Global train loss: 0.178, Global test loss: 3.267, Global test accuracy: 16.04 

Round  14, Train loss: 0.153, Test loss: 1.674, Test accuracy: 65.56 

Round  14, Global train loss: 0.153, Global test loss: 3.278, Global test accuracy: 16.00 

Round  15, Train loss: 0.173, Test loss: 1.605, Test accuracy: 66.40 

Round  15, Global train loss: 0.173, Global test loss: 3.197, Global test accuracy: 16.00 

Round  16, Train loss: 0.129, Test loss: 1.751, Test accuracy: 66.08 

Round  16, Global train loss: 0.129, Global test loss: 3.051, Global test accuracy: 16.00 

Round  17, Train loss: 0.102, Test loss: 1.721, Test accuracy: 66.12 

Round  17, Global train loss: 0.102, Global test loss: 3.216, Global test accuracy: 16.00 

Round  18, Train loss: 0.085, Test loss: 1.644, Test accuracy: 67.48 

Round  18, Global train loss: 0.085, Global test loss: 3.315, Global test accuracy: 16.04 

Round  19, Train loss: 0.081, Test loss: 1.830, Test accuracy: 65.60 

Round  19, Global train loss: 0.081, Global test loss: 3.300, Global test accuracy: 16.04 

Round  20, Train loss: 0.089, Test loss: 1.726, Test accuracy: 67.36 

Round  20, Global train loss: 0.089, Global test loss: 3.268, Global test accuracy: 16.00 

Round  21, Train loss: 0.065, Test loss: 1.710, Test accuracy: 67.96 

Round  21, Global train loss: 0.065, Global test loss: 3.443, Global test accuracy: 16.00 

Round  22, Train loss: 0.052, Test loss: 1.786, Test accuracy: 67.00 

Round  22, Global train loss: 0.052, Global test loss: 3.352, Global test accuracy: 16.00 

Round  23, Train loss: 0.062, Test loss: 1.871, Test accuracy: 65.76 

Round  23, Global train loss: 0.062, Global test loss: 3.223, Global test accuracy: 16.00 

Round  24, Train loss: 0.084, Test loss: 1.828, Test accuracy: 66.36 

Round  24, Global train loss: 0.084, Global test loss: 3.258, Global test accuracy: 16.00 

Round  25, Train loss: 0.055, Test loss: 1.658, Test accuracy: 69.20 

Round  25, Global train loss: 0.055, Global test loss: 3.178, Global test accuracy: 16.00 

Round  26, Train loss: 0.037, Test loss: 1.750, Test accuracy: 68.36 

Round  26, Global train loss: 0.037, Global test loss: 3.183, Global test accuracy: 16.00 

Round  27, Train loss: 0.045, Test loss: 1.872, Test accuracy: 67.28 

Round  27, Global train loss: 0.045, Global test loss: 3.270, Global test accuracy: 16.00 

Round  28, Train loss: 0.038, Test loss: 1.715, Test accuracy: 69.48 

Round  28, Global train loss: 0.038, Global test loss: 3.289, Global test accuracy: 16.00 

Round  29, Train loss: 0.032, Test loss: 1.833, Test accuracy: 68.12 

Round  29, Global train loss: 0.032, Global test loss: 3.266, Global test accuracy: 16.00 

Round  30, Train loss: 0.025, Test loss: 1.758, Test accuracy: 68.96 

Round  30, Global train loss: 0.025, Global test loss: 3.221, Global test accuracy: 16.00 

Round  31, Train loss: 0.036, Test loss: 1.912, Test accuracy: 68.08 

Round  31, Global train loss: 0.036, Global test loss: 3.285, Global test accuracy: 16.00 

Round  32, Train loss: 0.030, Test loss: 1.810, Test accuracy: 68.12 

Round  32, Global train loss: 0.030, Global test loss: 3.306, Global test accuracy: 16.00 

Round  33, Train loss: 0.028, Test loss: 1.758, Test accuracy: 68.88 

Round  33, Global train loss: 0.028, Global test loss: 3.225, Global test accuracy: 16.00 

Round  34, Train loss: 0.024, Test loss: 1.796, Test accuracy: 69.16 

Round  34, Global train loss: 0.024, Global test loss: 3.173, Global test accuracy: 16.00 

Final Round, Train loss: 0.021, Test loss: 1.758, Test accuracy: 69.20 

Final Round, Global train loss: 0.021, Global test loss: 3.173, Global test accuracy: 16.00 

Average accuracy final 10 rounds: 68.564 

Average global accuracy final 10 rounds: 15.999999999999998 

1159.0241470336914
[7.609616041183472, 13.32658314704895, 18.977429151535034, 24.54658532142639, 30.18646478652954, 36.0107147693634, 41.973337173461914, 47.9658522605896, 53.76949763298035, 59.50127172470093, 65.1390290260315, 71.14965891838074, 76.75275802612305, 82.4392557144165, 88.04235982894897, 93.64704036712646, 99.20514297485352, 104.78830480575562, 110.71747875213623, 116.44166707992554, 122.18680238723755, 127.85800313949585, 133.53216004371643, 139.23716974258423, 144.79797101020813, 150.43703436851501, 155.97787189483643, 161.68025279045105, 167.61465716362, 173.28914332389832, 179.03782486915588, 184.71405291557312, 190.27454900741577, 196.4110643863678, 202.05720829963684, 213.49755263328552]
[48.44, 56.6, 58.56, 59.48, 58.08, 61.84, 62.36, 56.84, 64.76, 62.96, 62.64, 65.16, 64.48, 64.96, 65.56, 66.4, 66.08, 66.12, 67.48, 65.6, 67.36, 67.96, 67.0, 65.76, 66.36, 69.2, 68.36, 67.28, 69.48, 68.12, 68.96, 68.08, 68.12, 68.88, 69.16, 69.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.440, Test loss: 1.324, Test accuracy: 48.44 

Round   0, Global train loss: 1.440, Global test loss: 2.596, Global test accuracy: 16.68 

Round   1, Train loss: 1.332, Test loss: 1.169, Test accuracy: 54.04 

Round   1, Global train loss: 1.332, Global test loss: 2.068, Global test accuracy: 28.88 

Round   2, Train loss: 1.183, Test loss: 1.082, Test accuracy: 57.48 

Round   2, Global train loss: 1.183, Global test loss: 1.697, Global test accuracy: 41.80 

Round   3, Train loss: 1.076, Test loss: 1.055, Test accuracy: 60.76 

Round   3, Global train loss: 1.076, Global test loss: 1.632, Global test accuracy: 47.00 

Round   4, Train loss: 0.974, Test loss: 1.075, Test accuracy: 59.76 

Round   4, Global train loss: 0.974, Global test loss: 1.481, Global test accuracy: 51.52 

Round   5, Train loss: 0.913, Test loss: 1.010, Test accuracy: 63.84 

Round   5, Global train loss: 0.913, Global test loss: 1.457, Global test accuracy: 52.72 

Round   6, Train loss: 0.834, Test loss: 0.935, Test accuracy: 66.96 

Round   6, Global train loss: 0.834, Global test loss: 1.491, Global test accuracy: 52.32 

Round   7, Train loss: 0.776, Test loss: 1.083, Test accuracy: 64.56 

Round   7, Global train loss: 0.776, Global test loss: 1.401, Global test accuracy: 52.92 

Round   8, Train loss: 0.735, Test loss: 1.015, Test accuracy: 67.68 

Round   8, Global train loss: 0.735, Global test loss: 1.362, Global test accuracy: 54.28 

Round   9, Train loss: 0.654, Test loss: 1.058, Test accuracy: 68.00 

Round   9, Global train loss: 0.654, Global test loss: 1.304, Global test accuracy: 56.32 

Round  10, Train loss: 0.624, Test loss: 1.102, Test accuracy: 65.24 

Round  10, Global train loss: 0.624, Global test loss: 1.255, Global test accuracy: 57.52 

Round  11, Train loss: 0.569, Test loss: 0.932, Test accuracy: 71.08 

Round  11, Global train loss: 0.569, Global test loss: 1.268, Global test accuracy: 58.68 

Round  12, Train loss: 0.524, Test loss: 1.107, Test accuracy: 70.12 

Round  12, Global train loss: 0.524, Global test loss: 1.399, Global test accuracy: 56.08 

Round  13, Train loss: 0.506, Test loss: 0.960, Test accuracy: 70.40 

Round  13, Global train loss: 0.506, Global test loss: 1.191, Global test accuracy: 61.24 

Round  14, Train loss: 0.461, Test loss: 1.026, Test accuracy: 69.20 

Round  14, Global train loss: 0.461, Global test loss: 1.331, Global test accuracy: 58.24 

Round  15, Train loss: 0.423, Test loss: 1.027, Test accuracy: 70.96 

Round  15, Global train loss: 0.423, Global test loss: 1.206, Global test accuracy: 62.36 

Round  16, Train loss: 0.409, Test loss: 0.886, Test accuracy: 73.92 

Round  16, Global train loss: 0.409, Global test loss: 1.218, Global test accuracy: 62.64 

Round  17, Train loss: 0.374, Test loss: 1.069, Test accuracy: 70.96 

Round  17, Global train loss: 0.374, Global test loss: 1.217, Global test accuracy: 62.20 

Round  18, Train loss: 0.358, Test loss: 1.199, Test accuracy: 69.48 

Round  18, Global train loss: 0.358, Global test loss: 1.229, Global test accuracy: 63.04 

Round  19, Train loss: 0.325, Test loss: 0.990, Test accuracy: 72.36 

Round  19, Global train loss: 0.325, Global test loss: 1.145, Global test accuracy: 65.44 

Round  20, Train loss: 0.309, Test loss: 0.962, Test accuracy: 73.68 

Round  20, Global train loss: 0.309, Global test loss: 1.090, Global test accuracy: 66.24 

Round  21, Train loss: 0.303, Test loss: 1.198, Test accuracy: 71.32 

Round  21, Global train loss: 0.303, Global test loss: 1.172, Global test accuracy: 65.12 

Round  22, Train loss: 0.273, Test loss: 1.016, Test accuracy: 74.56 

Round  22, Global train loss: 0.273, Global test loss: 1.141, Global test accuracy: 66.04 

Round  23, Train loss: 0.242, Test loss: 1.157, Test accuracy: 73.00 

Round  23, Global train loss: 0.242, Global test loss: 1.090, Global test accuracy: 67.40 

Round  24, Train loss: 0.237, Test loss: 1.028, Test accuracy: 74.60 

Round  24, Global train loss: 0.237, Global test loss: 1.168, Global test accuracy: 66.00 

Round  25, Train loss: 0.223, Test loss: 1.097, Test accuracy: 74.08 

Round  25, Global train loss: 0.223, Global test loss: 1.227, Global test accuracy: 64.72 

Round  26, Train loss: 0.207, Test loss: 0.992, Test accuracy: 74.08 

Round  26, Global train loss: 0.207, Global test loss: 1.133, Global test accuracy: 67.52 

Round  27, Train loss: 0.177, Test loss: 0.988, Test accuracy: 76.28 

Round  27, Global train loss: 0.177, Global test loss: 1.170, Global test accuracy: 67.12 

Round  28, Train loss: 0.189, Test loss: 0.973, Test accuracy: 75.96 

Round  28, Global train loss: 0.189, Global test loss: 1.144, Global test accuracy: 67.44 

Round  29, Train loss: 0.175, Test loss: 1.094, Test accuracy: 73.88 

Round  29, Global train loss: 0.175, Global test loss: 1.148, Global test accuracy: 67.68 

Round  30, Train loss: 0.149, Test loss: 1.011, Test accuracy: 75.72 

Round  30, Global train loss: 0.149, Global test loss: 1.103, Global test accuracy: 68.40 

Round  31, Train loss: 0.156, Test loss: 0.972, Test accuracy: 76.56 

Round  31, Global train loss: 0.156, Global test loss: 1.103, Global test accuracy: 68.24 

Round  32, Train loss: 0.152, Test loss: 0.948, Test accuracy: 76.56 

Round  32, Global train loss: 0.152, Global test loss: 1.070, Global test accuracy: 69.32 

Round  33, Train loss: 0.129, Test loss: 1.118, Test accuracy: 74.96 

Round  33, Global train loss: 0.129, Global test loss: 1.124, Global test accuracy: 68.32 

Round  34, Train loss: 0.130, Test loss: 0.883, Test accuracy: 77.64 

Round  34, Global train loss: 0.130, Global test loss: 1.049, Global test accuracy: 69.56 

Round  35, Train loss: 0.096, Test loss: 1.029, Test accuracy: 76.36 

Round  35, Global train loss: 0.096, Global test loss: 1.154, Global test accuracy: 68.40 

Round  36, Train loss: 0.122, Test loss: 1.045, Test accuracy: 76.64 

Round  36, Global train loss: 0.122, Global test loss: 1.184, Global test accuracy: 68.76 

Round  37, Train loss: 0.107, Test loss: 1.212, Test accuracy: 75.92 

Round  37, Global train loss: 0.107, Global test loss: 1.131, Global test accuracy: 69.60 

Round  38, Train loss: 0.113, Test loss: 1.138, Test accuracy: 74.84 

Round  38, Global train loss: 0.113, Global test loss: 1.111, Global test accuracy: 69.64 

Round  39, Train loss: 0.099, Test loss: 0.944, Test accuracy: 79.12 

Round  39, Global train loss: 0.099, Global test loss: 1.061, Global test accuracy: 69.52 

Round  40, Train loss: 0.069, Test loss: 0.910, Test accuracy: 79.28 

Round  40, Global train loss: 0.069, Global test loss: 1.142, Global test accuracy: 69.40 

Round  41, Train loss: 0.094, Test loss: 0.988, Test accuracy: 78.08 

Round  41, Global train loss: 0.094, Global test loss: 1.058, Global test accuracy: 70.44 

Round  42, Train loss: 0.092, Test loss: 1.095, Test accuracy: 77.60 

Round  42, Global train loss: 0.092, Global test loss: 1.142, Global test accuracy: 70.92 

Round  43, Train loss: 0.087, Test loss: 1.063, Test accuracy: 76.60 

Round  43, Global train loss: 0.087, Global test loss: 1.067, Global test accuracy: 70.52 

Round  44, Train loss: 0.068, Test loss: 1.016, Test accuracy: 77.76 

Round  44, Global train loss: 0.068, Global test loss: 1.064, Global test accuracy: 70.96 

Round  45, Train loss: 0.071, Test loss: 1.054, Test accuracy: 76.88 

Round  45, Global train loss: 0.071, Global test loss: 1.111, Global test accuracy: 70.52 

Round  46, Train loss: 0.069, Test loss: 1.210, Test accuracy: 74.72 

Round  46, Global train loss: 0.069, Global test loss: 1.136, Global test accuracy: 70.20 

Round  47, Train loss: 0.059, Test loss: 1.001, Test accuracy: 79.08 

Round  47, Global train loss: 0.059, Global test loss: 1.201, Global test accuracy: 69.64 

Round  48, Train loss: 0.060, Test loss: 0.985, Test accuracy: 78.48 

Round  48, Global train loss: 0.060, Global test loss: 1.067, Global test accuracy: 71.28 

Round  49, Train loss: 0.040, Test loss: 0.974, Test accuracy: 79.92 

Round  49, Global train loss: 0.040, Global test loss: 1.134, Global test accuracy: 70.56 

Final Round, Train loss: 0.073, Test loss: 1.124, Test accuracy: 77.32 

Final Round, Global train loss: 0.073, Global test loss: 1.134, Global test accuracy: 70.56 

Average accuracy final 10 rounds: 77.84000000000002 

Average global accuracy final 10 rounds: 70.444 

1631.1964015960693
[7.877418756484985, 13.503634691238403, 19.16973042488098, 24.821528673171997, 30.586838483810425, 36.19271779060364, 41.7235963344574, 47.2899124622345, 52.95343279838562, 58.59438157081604, 64.35270023345947, 70.08248496055603, 75.89210438728333, 81.7862799167633, 87.84845924377441, 93.57485222816467, 99.5733323097229, 105.118008852005, 110.83542728424072, 116.62827014923096, 122.47002339363098, 128.0986669063568, 133.7030427455902, 139.22599267959595, 144.83110737800598, 150.78433775901794, 157.2781753540039, 163.0355885028839, 168.98212909698486, 174.74497151374817, 180.32716870307922, 186.07446217536926, 191.8811056613922, 197.95826601982117, 203.66944456100464, 209.33454060554504, 215.0255789756775, 220.77397441864014, 226.58445167541504, 232.2619068622589, 237.88564085960388, 243.4615614414215, 249.1268937587738, 254.7645456790924, 260.4029395580292, 265.9382266998291, 271.7059323787689, 277.9708819389343, 283.8849883079529, 289.6658425331116, 300.95457339286804]
[48.44, 54.04, 57.48, 60.76, 59.76, 63.84, 66.96, 64.56, 67.68, 68.0, 65.24, 71.08, 70.12, 70.4, 69.2, 70.96, 73.92, 70.96, 69.48, 72.36, 73.68, 71.32, 74.56, 73.0, 74.6, 74.08, 74.08, 76.28, 75.96, 73.88, 75.72, 76.56, 76.56, 74.96, 77.64, 76.36, 76.64, 75.92, 74.84, 79.12, 79.28, 78.08, 77.6, 76.6, 77.76, 76.88, 74.72, 79.08, 78.48, 79.92, 77.32]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.519, Test loss: 2.145, Test accuracy: 21.60 

Round   1, Train loss: 1.375, Test loss: 1.906, Test accuracy: 26.56 

Round   2, Train loss: 1.207, Test loss: 1.276, Test accuracy: 47.88 

Round   3, Train loss: 1.101, Test loss: 1.079, Test accuracy: 54.84 

Round   4, Train loss: 1.019, Test loss: 1.072, Test accuracy: 59.32 

Round   5, Train loss: 0.964, Test loss: 0.904, Test accuracy: 63.08 

Round   6, Train loss: 0.895, Test loss: 0.891, Test accuracy: 63.52 

Round   7, Train loss: 0.862, Test loss: 0.870, Test accuracy: 65.72 

Round   8, Train loss: 0.797, Test loss: 0.815, Test accuracy: 68.44 

Round   9, Train loss: 0.759, Test loss: 0.825, Test accuracy: 67.48 

Round  10, Train loss: 0.740, Test loss: 0.849, Test accuracy: 67.96 

Round  11, Train loss: 0.701, Test loss: 0.791, Test accuracy: 69.44 

Round  12, Train loss: 0.653, Test loss: 0.753, Test accuracy: 71.04 

Round  13, Train loss: 0.615, Test loss: 0.767, Test accuracy: 72.32 

Round  14, Train loss: 0.570, Test loss: 0.759, Test accuracy: 71.08 

Round  15, Train loss: 0.550, Test loss: 0.745, Test accuracy: 72.64 

Round  16, Train loss: 0.517, Test loss: 0.764, Test accuracy: 72.92 

Round  17, Train loss: 0.501, Test loss: 0.719, Test accuracy: 73.20 

Round  18, Train loss: 0.459, Test loss: 0.711, Test accuracy: 74.20 

Round  19, Train loss: 0.442, Test loss: 0.733, Test accuracy: 75.08 

Round  20, Train loss: 0.408, Test loss: 0.662, Test accuracy: 75.60 

Round  21, Train loss: 0.398, Test loss: 0.668, Test accuracy: 75.68 

Round  22, Train loss: 0.369, Test loss: 0.687, Test accuracy: 76.00 

Round  23, Train loss: 0.338, Test loss: 0.656, Test accuracy: 77.28 

Round  24, Train loss: 0.326, Test loss: 0.653, Test accuracy: 77.96 

Round  25, Train loss: 0.301, Test loss: 0.689, Test accuracy: 77.24 

Round  26, Train loss: 0.293, Test loss: 0.692, Test accuracy: 77.80 

Round  27, Train loss: 0.275, Test loss: 0.691, Test accuracy: 76.56 

Round  28, Train loss: 0.256, Test loss: 0.680, Test accuracy: 77.84 

Round  29, Train loss: 0.242, Test loss: 0.659, Test accuracy: 78.36 

Round  30, Train loss: 0.223, Test loss: 0.639, Test accuracy: 79.56 

Round  31, Train loss: 0.221, Test loss: 0.705, Test accuracy: 77.68 

Round  32, Train loss: 0.213, Test loss: 0.666, Test accuracy: 79.28 

Round  33, Train loss: 0.193, Test loss: 0.684, Test accuracy: 78.20 

Round  34, Train loss: 0.178, Test loss: 0.695, Test accuracy: 78.40 

Round  35, Train loss: 0.166, Test loss: 0.679, Test accuracy: 79.04 

Round  36, Train loss: 0.160, Test loss: 0.690, Test accuracy: 79.52 

Round  37, Train loss: 0.156, Test loss: 0.702, Test accuracy: 78.44 

Round  38, Train loss: 0.142, Test loss: 0.672, Test accuracy: 79.36 

Round  39, Train loss: 0.135, Test loss: 0.671, Test accuracy: 79.12 

Round  40, Train loss: 0.135, Test loss: 0.692, Test accuracy: 80.20 

Round  41, Train loss: 0.115, Test loss: 0.718, Test accuracy: 79.60 

Round  42, Train loss: 0.104, Test loss: 0.701, Test accuracy: 80.20 

Round  43, Train loss: 0.109, Test loss: 0.659, Test accuracy: 79.84 

Round  44, Train loss: 0.094, Test loss: 0.668, Test accuracy: 80.08 

Round  45, Train loss: 0.095, Test loss: 0.694, Test accuracy: 80.44 

Round  46, Train loss: 0.077, Test loss: 0.684, Test accuracy: 81.04 

Round  47, Train loss: 0.087, Test loss: 0.682, Test accuracy: 80.52 

Round  48, Train loss: 0.092, Test loss: 0.723, Test accuracy: 79.00 

Round  49, Train loss: 0.076, Test loss: 0.716, Test accuracy: 80.80 

Final Round, Train loss: 0.044, Test loss: 0.721, Test accuracy: 80.48 

Average accuracy final 10 rounds: 80.17200000000001 

1198.26353764534
[6.235519886016846, 10.824056386947632, 15.228719472885132, 19.63407611846924, 24.160889387130737, 28.59444761276245, 33.157392740249634, 37.74424934387207, 42.16583228111267, 46.58626985549927, 51.340765953063965, 55.80221629142761, 60.728837728500366, 65.1276524066925, 69.58161902427673, 74.10677742958069, 78.60339856147766, 83.06817650794983, 87.3651852607727, 92.00341963768005, 96.40839886665344, 100.75716614723206, 105.12919211387634, 109.71062302589417, 114.13968896865845, 118.7633306980133, 123.13986396789551, 127.6267557144165, 132.00809049606323, 136.46973276138306, 140.98617720603943, 145.3646800518036, 149.82263278961182, 154.29381394386292, 158.90769219398499, 163.21410393714905, 167.62322402000427, 172.01900601387024, 176.44440817832947, 180.74393439292908, 184.99398612976074, 189.2391300201416, 193.92938828468323, 198.88668727874756, 203.36481165885925, 207.8965106010437, 212.31598782539368, 216.77163410186768, 221.42594504356384, 225.98588514328003, 231.0431752204895]
[21.6, 26.56, 47.88, 54.84, 59.32, 63.08, 63.52, 65.72, 68.44, 67.48, 67.96, 69.44, 71.04, 72.32, 71.08, 72.64, 72.92, 73.2, 74.2, 75.08, 75.6, 75.68, 76.0, 77.28, 77.96, 77.24, 77.8, 76.56, 77.84, 78.36, 79.56, 77.68, 79.28, 78.2, 78.4, 79.04, 79.52, 78.44, 79.36, 79.12, 80.2, 79.6, 80.2, 79.84, 80.08, 80.44, 81.04, 80.52, 79.0, 80.8, 80.48]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.553, Test loss: 2.058, Test accuracy: 20.88
Round   1, Train loss: 1.352, Test loss: 1.586, Test accuracy: 31.92
Round   2, Train loss: 1.194, Test loss: 1.115, Test accuracy: 52.28
Round   3, Train loss: 1.102, Test loss: 1.084, Test accuracy: 54.92
Round   4, Train loss: 1.028, Test loss: 0.980, Test accuracy: 58.88
Round   5, Train loss: 0.963, Test loss: 0.932, Test accuracy: 61.64
Round   6, Train loss: 0.909, Test loss: 0.891, Test accuracy: 63.60
Round   7, Train loss: 0.856, Test loss: 0.916, Test accuracy: 64.16
Round   8, Train loss: 0.817, Test loss: 0.876, Test accuracy: 65.80
Round   9, Train loss: 0.779, Test loss: 0.791, Test accuracy: 68.32
Round  10, Train loss: 0.737, Test loss: 0.722, Test accuracy: 70.52
Round  11, Train loss: 0.685, Test loss: 0.752, Test accuracy: 71.60
Round  12, Train loss: 0.665, Test loss: 0.736, Test accuracy: 71.16
Round  13, Train loss: 0.618, Test loss: 0.691, Test accuracy: 73.56
Round  14, Train loss: 0.585, Test loss: 0.733, Test accuracy: 72.72
Round  15, Train loss: 0.555, Test loss: 0.697, Test accuracy: 74.12
Round  16, Train loss: 0.520, Test loss: 0.701, Test accuracy: 74.36
Round  17, Train loss: 0.501, Test loss: 0.655, Test accuracy: 76.24
Round  18, Train loss: 0.465, Test loss: 0.660, Test accuracy: 75.88
Round  19, Train loss: 0.447, Test loss: 0.660, Test accuracy: 76.20
Round  20, Train loss: 0.417, Test loss: 0.640, Test accuracy: 77.04
Round  21, Train loss: 0.404, Test loss: 0.630, Test accuracy: 77.20
Round  22, Train loss: 0.370, Test loss: 0.646, Test accuracy: 77.48
Round  23, Train loss: 0.339, Test loss: 0.692, Test accuracy: 76.84
Round  24, Train loss: 0.325, Test loss: 0.652, Test accuracy: 78.64
Round  25, Train loss: 0.316, Test loss: 0.668, Test accuracy: 77.72
Round  26, Train loss: 0.300, Test loss: 0.634, Test accuracy: 79.20
Round  27, Train loss: 0.275, Test loss: 0.612, Test accuracy: 79.44
Round  28, Train loss: 0.267, Test loss: 0.633, Test accuracy: 78.36
Round  29, Train loss: 0.250, Test loss: 0.651, Test accuracy: 79.60
Round  30, Train loss: 0.230, Test loss: 0.618, Test accuracy: 79.96
Round  31, Train loss: 0.222, Test loss: 0.664, Test accuracy: 78.84
Round  32, Train loss: 0.201, Test loss: 0.646, Test accuracy: 80.40
Round  33, Train loss: 0.206, Test loss: 0.655, Test accuracy: 79.20
Round  34, Train loss: 0.188, Test loss: 0.653, Test accuracy: 79.16
Round  35, Train loss: 0.167, Test loss: 0.676, Test accuracy: 79.08
Round  36, Train loss: 0.171, Test loss: 0.640, Test accuracy: 80.16
Round  37, Train loss: 0.151, Test loss: 0.677, Test accuracy: 79.36
Round  38, Train loss: 0.136, Test loss: 0.661, Test accuracy: 79.84
Round  39, Train loss: 0.137, Test loss: 0.658, Test accuracy: 80.08
Round  40, Train loss: 0.124, Test loss: 0.640, Test accuracy: 80.76
Round  41, Train loss: 0.121, Test loss: 0.646, Test accuracy: 81.36
Round  42, Train loss: 0.123, Test loss: 0.670, Test accuracy: 80.56
Round  43, Train loss: 0.108, Test loss: 0.641, Test accuracy: 80.56
Round  44, Train loss: 0.101, Test loss: 0.674, Test accuracy: 80.16
Round  45, Train loss: 0.104, Test loss: 0.673, Test accuracy: 80.96
Round  46, Train loss: 0.097, Test loss: 0.686, Test accuracy: 80.48
Round  47, Train loss: 0.086, Test loss: 0.652, Test accuracy: 81.16
Round  48, Train loss: 0.077, Test loss: 0.702, Test accuracy: 80.00
Round  49, Train loss: 0.081, Test loss: 0.664, Test accuracy: 81.08
Final Round, Train loss: 0.042, Test loss: 0.669, Test accuracy: 81.36
Average accuracy final 10 rounds: 80.708
1349.0132293701172
[6.9130659103393555, 12.338078260421753, 17.69346022605896, 22.730799436569214, 27.55854558944702, 33.264480113983154, 38.53735017776489, 43.62467312812805, 48.657487869262695, 53.77000665664673, 58.977132081985474, 63.961976528167725, 69.30297231674194, 74.50079464912415, 79.83697724342346, 84.75278282165527, 89.83512091636658, 94.82593870162964, 99.71032404899597, 104.71002864837646, 109.63880753517151, 114.61066603660583, 119.78632235527039, 124.82792115211487, 130.0596685409546, 135.16667008399963, 140.24372696876526, 145.27539944648743, 150.44570136070251, 155.5871660709381, 160.7190761566162, 165.72055840492249, 170.92404985427856, 175.7845675945282, 180.8897864818573, 186.18844938278198, 191.24096083641052, 196.33986449241638, 201.23364448547363, 206.41134357452393, 211.36366057395935, 216.71972489356995, 221.9187331199646, 227.14341688156128, 232.12641882896423, 237.16976356506348, 242.1390917301178, 247.04342460632324, 252.18468594551086, 257.54880452156067, 262.65037655830383]
[20.88, 31.92, 52.28, 54.92, 58.88, 61.64, 63.6, 64.16, 65.8, 68.32, 70.52, 71.6, 71.16, 73.56, 72.72, 74.12, 74.36, 76.24, 75.88, 76.2, 77.04, 77.2, 77.48, 76.84, 78.64, 77.72, 79.2, 79.44, 78.36, 79.6, 79.96, 78.84, 80.4, 79.2, 79.16, 79.08, 80.16, 79.36, 79.84, 80.08, 80.76, 81.36, 80.56, 80.56, 80.16, 80.96, 80.48, 81.16, 80.0, 81.08, 81.36]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 1.029, Train accuracy: 58.400, Test loss: 1.208, Test accuracy: 53.00 

        train local model (freeze embeding):client   0,  Train loss: 0.890, Train accuracy: 62.000, Test loss: 1.069, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.883, Train accuracy: 62.200, Test loss: 1.151, Test accuracy: 59.40 

Round   0, Train loss: 0.883, Test loss: 1.151, Test accuracy: 59.40 

        train local model (freeze embeding):client   0,  Train loss: 0.811, Train accuracy: 65.000, Test loss: 1.084, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.859, Train accuracy: 68.000, Test loss: 1.259, Test accuracy: 57.80 

Round   1, Train loss: 0.859, Test loss: 1.259, Test accuracy: 57.80 

        train local model (freeze embeding):client   0,  Train loss: 0.713, Train accuracy: 72.800, Test loss: 1.132, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.779, Train accuracy: 68.200, Test loss: 1.090, Test accuracy: 54.80 

Round   2, Train loss: 0.779, Test loss: 1.090, Test accuracy: 54.80 

        train local model (freeze embeding):client   0,  Train loss: 0.678, Train accuracy: 73.600, Test loss: 1.063, Test accuracy: 59.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.743, Train accuracy: 68.800, Test loss: 1.169, Test accuracy: 55.60 

Round   3, Train loss: 0.743, Test loss: 1.169, Test accuracy: 55.60 

        train local model (freeze embeding):client   0,  Train loss: 0.614, Train accuracy: 77.200, Test loss: 1.081, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.855, Train accuracy: 68.400, Test loss: 1.187, Test accuracy: 60.60 

Round   4, Train loss: 0.855, Test loss: 1.187, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.610, Train accuracy: 79.200, Test loss: 1.012, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.545, Train accuracy: 80.000, Test loss: 1.005, Test accuracy: 63.80 

Round   5, Train loss: 0.545, Test loss: 1.005, Test accuracy: 63.80 

        train local model (freeze embeding):client   0,  Train loss: 0.480, Train accuracy: 81.600, Test loss: 1.010, Test accuracy: 64.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.604, Train accuracy: 76.600, Test loss: 1.210, Test accuracy: 58.20 

Round   6, Train loss: 0.604, Test loss: 1.210, Test accuracy: 58.20 

        train local model (freeze embeding):client   0,  Train loss: 0.475, Train accuracy: 82.200, Test loss: 1.098, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.580, Train accuracy: 80.600, Test loss: 1.460, Test accuracy: 55.60 

Round   7, Train loss: 0.580, Test loss: 1.460, Test accuracy: 55.60 

        train local model (freeze embeding):client   0,  Train loss: 0.336, Train accuracy: 87.200, Test loss: 1.166, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.441, Train accuracy: 81.600, Test loss: 1.303, Test accuracy: 60.60 

Round   8, Train loss: 0.441, Test loss: 1.303, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.342, Train accuracy: 88.200, Test loss: 1.180, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.285, Train accuracy: 91.200, Test loss: 1.239, Test accuracy: 65.40 

Round   9, Train loss: 0.285, Test loss: 1.239, Test accuracy: 65.40 

        train local model (freeze embeding):client   0,  Train loss: 0.253, Train accuracy: 92.400, Test loss: 1.256, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.406, Train accuracy: 82.400, Test loss: 1.224, Test accuracy: 62.00 

Round  10, Train loss: 0.406, Test loss: 1.224, Test accuracy: 62.00 

        train local model (freeze embeding):client   0,  Train loss: 0.252, Train accuracy: 91.600, Test loss: 1.142, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.245, Train accuracy: 91.200, Test loss: 1.481, Test accuracy: 59.60 

Round  11, Train loss: 0.245, Test loss: 1.481, Test accuracy: 59.60 

        train local model (freeze embeding):client   0,  Train loss: 0.177, Train accuracy: 93.400, Test loss: 1.359, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.403, Train accuracy: 83.000, Test loss: 1.435, Test accuracy: 60.60 

Round  12, Train loss: 0.403, Test loss: 1.435, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.199, Train accuracy: 92.800, Test loss: 1.289, Test accuracy: 65.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.534, Train accuracy: 82.600, Test loss: 1.695, Test accuracy: 57.60 

Round  13, Train loss: 0.534, Test loss: 1.695, Test accuracy: 57.60 

        train local model (freeze embeding):client   0,  Train loss: 0.200, Train accuracy: 92.600, Test loss: 1.358, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.202, Train accuracy: 94.200, Test loss: 1.702, Test accuracy: 59.00 

Round  14, Train loss: 0.202, Test loss: 1.702, Test accuracy: 59.00 

        train local model (freeze embeding):client   0,  Train loss: 0.121, Train accuracy: 96.000, Test loss: 1.437, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.167, Train accuracy: 93.400, Test loss: 1.730, Test accuracy: 60.00 

Round  15, Train loss: 0.167, Test loss: 1.730, Test accuracy: 60.00 

        train local model (freeze embeding):client   0,  Train loss: 0.089, Train accuracy: 97.800, Test loss: 1.562, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.124, Train accuracy: 95.600, Test loss: 1.572, Test accuracy: 58.40 

Round  16, Train loss: 0.124, Test loss: 1.572, Test accuracy: 58.40 

        train local model (freeze embeding):client   0,  Train loss: 0.098, Train accuracy: 97.600, Test loss: 1.502, Test accuracy: 59.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.072, Train accuracy: 98.000, Test loss: 1.573, Test accuracy: 60.80 

Round  17, Train loss: 0.072, Test loss: 1.573, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.049, Train accuracy: 98.400, Test loss: 1.622, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.080, Train accuracy: 97.200, Test loss: 1.532, Test accuracy: 60.60 

Round  18, Train loss: 0.080, Test loss: 1.532, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.052, Train accuracy: 98.600, Test loss: 1.555, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.059, Train accuracy: 98.400, Test loss: 1.729, Test accuracy: 61.60 

Round  19, Train loss: 0.059, Test loss: 1.729, Test accuracy: 61.60 

        train local model (freeze embeding):client   0,  Train loss: 0.039, Train accuracy: 98.600, Test loss: 1.602, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.046, Train accuracy: 98.600, Test loss: 1.702, Test accuracy: 62.20 

Final Round, Train loss: 0.046, Test loss: 1.654, Test accuracy: 62.60 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 0.846, Train accuracy: 67.000, Test loss: 0.979, Test accuracy: 65.80 

        train local model (freeze embeding):client   0,  Train loss: 0.042, Train accuracy: 98.600, Test loss: 1.670, Test accuracy: 64.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.038, Train accuracy: 99.000, Test loss: 1.676, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.800, Train accuracy: 67.800, Test loss: 0.963, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.533, Train accuracy: 76.000, Test loss: 0.910, Test accuracy: 67.20 

Round   0, Train loss: 0.286, Test loss: 1.072, Test accuracy: 67.70 

        train local model (freeze embeding):client   0,  Train loss: 0.045, Train accuracy: 98.600, Test loss: 1.279, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.043, Train accuracy: 98.800, Test loss: 1.719, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 0.634, Train accuracy: 74.200, Test loss: 0.963, Test accuracy: 64.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.355, Train accuracy: 86.200, Test loss: 0.910, Test accuracy: 67.80 

Round   1, Train loss: 0.199, Test loss: 1.088, Test accuracy: 68.00 

        train local model (freeze embeding):client   0,  Train loss: 0.038, Train accuracy: 99.200, Test loss: 1.357, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 99.600, Test loss: 1.708, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.439, Train accuracy: 84.000, Test loss: 0.927, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.394, Train accuracy: 84.600, Test loss: 1.226, Test accuracy: 65.80 

Round   2, Train loss: 0.215, Test loss: 1.178, Test accuracy: 68.40 

        train local model (freeze embeding):client   0,  Train loss: 0.043, Train accuracy: 98.800, Test loss: 1.369, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.045, Train accuracy: 98.800, Test loss: 1.627, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.345, Train accuracy: 86.400, Test loss: 0.944, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.539, Train accuracy: 81.800, Test loss: 1.533, Test accuracy: 56.20 

Round   3, Train loss: 0.292, Test loss: 1.292, Test accuracy: 66.30 

        train local model (freeze embeding):client   0,  Train loss: 0.037, Train accuracy: 98.800, Test loss: 1.357, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.400, Test loss: 1.687, Test accuracy: 62.00 

        train local model (freeze embeding):client   1,  Train loss: 0.281, Train accuracy: 90.400, Test loss: 0.975, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.302, Train accuracy: 88.600, Test loss: 1.199, Test accuracy: 64.80 

Round   4, Train loss: 0.165, Test loss: 1.175, Test accuracy: 66.40 

        train local model (freeze embeding):client   0,  Train loss: 0.035, Train accuracy: 98.600, Test loss: 1.409, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.044, Train accuracy: 98.200, Test loss: 1.834, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.191, Train accuracy: 94.800, Test loss: 1.039, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.144, Train accuracy: 96.400, Test loss: 1.111, Test accuracy: 68.00 

Round   5, Train loss: 0.094, Test loss: 1.236, Test accuracy: 68.90 

        train local model (freeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.455, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.052, Train accuracy: 98.800, Test loss: 1.792, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 0.148, Train accuracy: 96.200, Test loss: 1.108, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.299, Train accuracy: 89.800, Test loss: 1.560, Test accuracy: 63.40 

Round   6, Train loss: 0.175, Test loss: 1.331, Test accuracy: 67.40 

        train local model (freeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.437, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 98.400, Test loss: 1.879, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.115, Train accuracy: 96.800, Test loss: 1.190, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.311, Train accuracy: 88.800, Test loss: 1.416, Test accuracy: 63.00 

Round   7, Train loss: 0.173, Test loss: 1.292, Test accuracy: 67.80 

        train local model (freeze embeding):client   0,  Train loss: 0.033, Train accuracy: 99.000, Test loss: 1.424, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.070, Train accuracy: 97.400, Test loss: 2.059, Test accuracy: 61.60 

        train local model (freeze embeding):client   1,  Train loss: 0.151, Train accuracy: 96.600, Test loss: 1.118, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.200, Train accuracy: 92.800, Test loss: 1.883, Test accuracy: 60.60 

Round   8, Train loss: 0.135, Test loss: 1.482, Test accuracy: 65.10 

        train local model (freeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.669, Test accuracy: 66.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.057, Train accuracy: 98.000, Test loss: 2.210, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 0.075, Train accuracy: 98.800, Test loss: 1.246, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.163, Train accuracy: 94.800, Test loss: 1.312, Test accuracy: 66.00 

Round   9, Train loss: 0.110, Test loss: 1.430, Test accuracy: 68.50 

        train local model (freeze embeding):client   0,  Train loss: 0.035, Train accuracy: 99.000, Test loss: 1.559, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.098, Train accuracy: 97.000, Test loss: 2.208, Test accuracy: 60.40 

        train local model (freeze embeding):client   1,  Train loss: 0.058, Train accuracy: 99.000, Test loss: 1.264, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.061, Train accuracy: 98.600, Test loss: 1.394, Test accuracy: 67.80 

Round  10, Train loss: 0.080, Test loss: 1.471, Test accuracy: 68.30 

        train local model (freeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.400, Test loss: 1.532, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.029, Train accuracy: 98.600, Test loss: 2.139, Test accuracy: 61.80 

        train local model (freeze embeding):client   1,  Train loss: 0.052, Train accuracy: 98.800, Test loss: 1.296, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.198, Train accuracy: 93.000, Test loss: 1.843, Test accuracy: 64.20 

Round  11, Train loss: 0.113, Test loss: 1.541, Test accuracy: 67.10 

        train local model (freeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.400, Test loss: 1.646, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.048, Train accuracy: 98.600, Test loss: 1.870, Test accuracy: 65.60 

        train local model (freeze embeding):client   1,  Train loss: 0.060, Train accuracy: 98.800, Test loss: 1.320, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.066, Train accuracy: 98.000, Test loss: 1.711, Test accuracy: 67.40 

Round  12, Train loss: 0.057, Test loss: 1.451, Test accuracy: 69.00 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.398, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.056, Train accuracy: 98.200, Test loss: 1.816, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.046, Train accuracy: 99.200, Test loss: 1.415, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.071, Train accuracy: 97.600, Test loss: 1.469, Test accuracy: 68.80 

Round  13, Train loss: 0.064, Test loss: 1.346, Test accuracy: 69.80 

        train local model (freeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.427, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.096, Train accuracy: 97.200, Test loss: 1.877, Test accuracy: 63.20 

        train local model (freeze embeding):client   1,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.313, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.135, Train accuracy: 95.800, Test loss: 1.278, Test accuracy: 67.20 

Round  14, Train loss: 0.116, Test loss: 1.252, Test accuracy: 67.10 

        train local model (freeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.800, Test loss: 1.309, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.029, Train accuracy: 99.400, Test loss: 1.716, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.043, Train accuracy: 99.600, Test loss: 1.182, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.044, Train accuracy: 98.200, Test loss: 1.820, Test accuracy: 67.60 

Round  15, Train loss: 0.037, Test loss: 1.466, Test accuracy: 68.70 

        train local model (freeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.519, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.053, Train accuracy: 98.200, Test loss: 1.744, Test accuracy: 65.60 

        train local model (freeze embeding):client   1,  Train loss: 0.044, Train accuracy: 99.400, Test loss: 1.446, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 98.600, Test loss: 1.888, Test accuracy: 65.80 

Round  16, Train loss: 0.045, Test loss: 1.478, Test accuracy: 67.80 

        train local model (freeze embeding):client   0,  Train loss: 0.020, Train accuracy: 99.200, Test loss: 1.521, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.038, Train accuracy: 98.200, Test loss: 1.873, Test accuracy: 63.20 

        train local model (freeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.446, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.042, Train accuracy: 98.600, Test loss: 1.693, Test accuracy: 67.60 

Round  17, Train loss: 0.040, Test loss: 1.484, Test accuracy: 69.10 

        train local model (freeze embeding):client   0,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.598, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.971, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 0.021, Train accuracy: 99.800, Test loss: 1.485, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.203, Train accuracy: 95.000, Test loss: 2.011, Test accuracy: 64.40 

Round  18, Train loss: 0.103, Test loss: 1.545, Test accuracy: 67.50 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.600, Test loss: 1.497, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.400, Test loss: 1.930, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.021, Train accuracy: 99.600, Test loss: 1.450, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.073, Train accuracy: 98.200, Test loss: 1.461, Test accuracy: 66.00 

Round  19, Train loss: 0.046, Test loss: 1.457, Test accuracy: 67.20 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.542, Test accuracy: 65.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.942, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.335, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.138, Train accuracy: 94.400, Test loss: 1.738, Test accuracy: 58.60 

Final Round, Train loss: 0.083, Test loss: 1.429, Test accuracy: 68.00 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 0.665, Train accuracy: 74.600, Test loss: 0.861, Test accuracy: 67.40 

        train local model (freeze embeding):client   0,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 1.529, Test accuracy: 65.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.000, Test loss: 1.774, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.314, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.035, Train accuracy: 99.000, Test loss: 1.558, Test accuracy: 68.40 

        train local model (freeze embeding):client   2,  Train loss: 0.641, Train accuracy: 76.600, Test loss: 0.770, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.219, Train accuracy: 92.800, Test loss: 0.778, Test accuracy: 75.00 

Round   0, Train loss: 0.093, Test loss: 1.166, Test accuracy: 70.20 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.385, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.849, Test accuracy: 65.60 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.422, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.436, Test accuracy: 69.20 

        train local model (freeze embeding):client   2,  Train loss: 0.384, Train accuracy: 85.400, Test loss: 0.778, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.230, Train accuracy: 91.800, Test loss: 0.944, Test accuracy: 71.60 

Round   1, Train loss: 0.091, Test loss: 1.139, Test accuracy: 72.00 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.377, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.032, Train accuracy: 99.200, Test loss: 1.932, Test accuracy: 62.20 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.600, Test loss: 1.384, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.024, Train accuracy: 99.600, Test loss: 1.716, Test accuracy: 68.60 

        train local model (freeze embeding):client   2,  Train loss: 0.315, Train accuracy: 87.600, Test loss: 0.814, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.191, Train accuracy: 93.400, Test loss: 0.976, Test accuracy: 72.60 

Round   2, Train loss: 0.082, Test loss: 1.164, Test accuracy: 72.27 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.396, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.972, Test accuracy: 68.60 

        train local model (freeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 1.348, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.520, Test accuracy: 68.60 

        train local model (freeze embeding):client   2,  Train loss: 0.179, Train accuracy: 94.800, Test loss: 0.808, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.308, Train accuracy: 88.800, Test loss: 1.103, Test accuracy: 72.20 

Round   3, Train loss: 0.112, Test loss: 1.282, Test accuracy: 72.53 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.361, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.400, Test loss: 2.149, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.510, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.034, Train accuracy: 99.200, Test loss: 1.650, Test accuracy: 66.40 

        train local model (freeze embeding):client   2,  Train loss: 0.136, Train accuracy: 95.600, Test loss: 0.752, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.197, Train accuracy: 93.000, Test loss: 1.161, Test accuracy: 72.40 

Round   4, Train loss: 0.084, Test loss: 1.249, Test accuracy: 72.27 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.484, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 2.047, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.467, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.053, Train accuracy: 98.200, Test loss: 1.626, Test accuracy: 68.40 

        train local model (freeze embeding):client   2,  Train loss: 0.108, Train accuracy: 96.800, Test loss: 0.800, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.121, Train accuracy: 95.600, Test loss: 1.102, Test accuracy: 75.20 

Round   5, Train loss: 0.059, Test loss: 1.272, Test accuracy: 72.07 

        train local model (freeze embeding):client   0,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.560, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.000, Test loss: 1.717, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.457, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.065, Train accuracy: 98.000, Test loss: 1.480, Test accuracy: 68.60 

        train local model (freeze embeding):client   2,  Train loss: 0.071, Train accuracy: 98.000, Test loss: 0.894, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.055, Train accuracy: 97.800, Test loss: 1.045, Test accuracy: 77.20 

Round   6, Train loss: 0.049, Test loss: 1.199, Test accuracy: 72.00 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.399, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.680, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.350, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.400, Test loss: 1.662, Test accuracy: 68.20 

        train local model (freeze embeding):client   2,  Train loss: 0.070, Train accuracy: 98.200, Test loss: 0.870, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.099, Train accuracy: 97.000, Test loss: 1.151, Test accuracy: 73.00 

Round   7, Train loss: 0.042, Test loss: 1.224, Test accuracy: 73.53 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.456, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.070, Train accuracy: 98.400, Test loss: 2.163, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.324, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.798, Test accuracy: 67.60 

        train local model (freeze embeding):client   2,  Train loss: 0.037, Train accuracy: 99.400, Test loss: 0.903, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.095, Train accuracy: 95.600, Test loss: 1.217, Test accuracy: 72.20 

Round   8, Train loss: 0.057, Test loss: 1.383, Test accuracy: 72.07 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.623, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.041, Train accuracy: 98.600, Test loss: 1.987, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.582, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.046, Train accuracy: 98.000, Test loss: 1.825, Test accuracy: 67.00 

        train local model (freeze embeding):client   2,  Train loss: 0.026, Train accuracy: 99.600, Test loss: 0.997, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.069, Train accuracy: 97.800, Test loss: 1.294, Test accuracy: 71.80 

Round   9, Train loss: 0.052, Test loss: 1.279, Test accuracy: 72.00 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.491, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 98.800, Test loss: 1.542, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.365, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.047, Train accuracy: 98.400, Test loss: 1.639, Test accuracy: 67.60 

        train local model (freeze embeding):client   2,  Train loss: 0.032, Train accuracy: 99.600, Test loss: 0.984, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.050, Train accuracy: 98.600, Test loss: 1.200, Test accuracy: 74.40 

Round  10, Train loss: 0.043, Test loss: 1.183, Test accuracy: 71.93 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.399, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.200, Test loss: 1.964, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.400, Test loss: 1.363, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.049, Train accuracy: 98.600, Test loss: 2.056, Test accuracy: 67.40 

        train local model (freeze embeding):client   2,  Train loss: 0.025, Train accuracy: 99.800, Test loss: 0.930, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.064, Train accuracy: 98.200, Test loss: 1.375, Test accuracy: 72.60 

Round  11, Train loss: 0.044, Test loss: 1.390, Test accuracy: 71.33 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.493, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.600, Test loss: 1.828, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.487, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.024, Train accuracy: 99.200, Test loss: 1.548, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 1.005, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.062, Train accuracy: 98.400, Test loss: 1.110, Test accuracy: 74.60 

Round  12, Train loss: 0.036, Test loss: 1.244, Test accuracy: 72.33 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.397, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 98.800, Test loss: 2.007, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.436, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.182, Train accuracy: 93.400, Test loss: 2.175, Test accuracy: 64.20 

        train local model (freeze embeding):client   2,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 0.969, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.103, Train accuracy: 97.200, Test loss: 1.315, Test accuracy: 73.00 

Round  13, Train loss: 0.107, Test loss: 1.307, Test accuracy: 72.33 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.385, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.778, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.310, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.600, Test loss: 1.877, Test accuracy: 66.20 

        train local model (freeze embeding):client   2,  Train loss: 0.026, Train accuracy: 99.600, Test loss: 0.912, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.109, Train accuracy: 95.800, Test loss: 1.391, Test accuracy: 70.20 

Round  14, Train loss: 0.046, Test loss: 1.310, Test accuracy: 71.73 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.421, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.631, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.500, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.070, Train accuracy: 97.800, Test loss: 1.945, Test accuracy: 65.60 

        train local model (freeze embeding):client   2,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.049, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.049, Train accuracy: 99.200, Test loss: 1.341, Test accuracy: 75.00 

Round  15, Train loss: 0.042, Test loss: 1.302, Test accuracy: 72.87 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.422, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.971, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.385, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.611, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.134, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.048, Train accuracy: 98.400, Test loss: 1.198, Test accuracy: 75.20 

Round  16, Train loss: 0.020, Test loss: 1.339, Test accuracy: 72.73 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.534, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.828, Test accuracy: 68.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.458, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.670, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.061, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.053, Train accuracy: 97.600, Test loss: 1.276, Test accuracy: 72.20 

Round  17, Train loss: 0.024, Test loss: 1.342, Test accuracy: 72.80 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.611, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 2.165, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.518, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.752, Test accuracy: 70.20 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.041, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.079, Train accuracy: 96.200, Test loss: 1.696, Test accuracy: 67.60 

Round  18, Train loss: 0.033, Test loss: 1.509, Test accuracy: 71.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.780, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.111, Train accuracy: 96.200, Test loss: 2.155, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.632, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.738, Test accuracy: 70.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.231, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.082, Train accuracy: 97.400, Test loss: 1.224, Test accuracy: 73.00 

Round  19, Train loss: 0.067, Test loss: 1.360, Test accuracy: 73.60 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.459, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.741, Test accuracy: 68.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.545, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.054, Train accuracy: 98.800, Test loss: 1.573, Test accuracy: 67.20 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.146, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.112, Train accuracy: 95.400, Test loss: 1.254, Test accuracy: 71.20 

Final Round, Train loss: 0.058, Test loss: 1.353, Test accuracy: 73.40 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 0.679, Train accuracy: 74.000, Test loss: 0.852, Test accuracy: 68.40 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.438, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.200, Test loss: 1.948, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.539, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.041, Train accuracy: 98.400, Test loss: 1.715, Test accuracy: 71.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.127, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.062, Train accuracy: 98.400, Test loss: 1.468, Test accuracy: 71.80 

        train local model (freeze embeding):client   3,  Train loss: 0.581, Train accuracy: 78.000, Test loss: 0.794, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.265, Train accuracy: 91.600, Test loss: 0.911, Test accuracy: 70.00 

Round   0, Train loss: 0.097, Test loss: 1.176, Test accuracy: 72.70 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.445, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 1.642, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.485, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.783, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.021, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.015, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 73.00 

        train local model (freeze embeding):client   3,  Train loss: 0.428, Train accuracy: 84.200, Test loss: 0.789, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.216, Train accuracy: 92.600, Test loss: 0.881, Test accuracy: 69.40 

Round   1, Train loss: 0.063, Test loss: 1.111, Test accuracy: 73.65 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.443, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.876, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.448, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.041, Train accuracy: 98.600, Test loss: 1.860, Test accuracy: 67.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.003, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.129, Train accuracy: 95.800, Test loss: 1.791, Test accuracy: 69.40 

        train local model (freeze embeding):client   3,  Train loss: 0.334, Train accuracy: 89.200, Test loss: 0.749, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.248, Train accuracy: 92.800, Test loss: 1.096, Test accuracy: 67.60 

Round   2, Train loss: 0.107, Test loss: 1.165, Test accuracy: 73.80 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.430, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.774, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.384, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.026, Train accuracy: 99.200, Test loss: 1.718, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.085, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.418, Test accuracy: 76.60 

        train local model (freeze embeding):client   3,  Train loss: 0.234, Train accuracy: 92.200, Test loss: 0.799, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.280, Train accuracy: 90.000, Test loss: 1.073, Test accuracy: 68.40 

Round   3, Train loss: 0.083, Test loss: 1.208, Test accuracy: 73.35 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.326, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.632, Test accuracy: 68.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.412, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.059, Train accuracy: 99.000, Test loss: 1.676, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.072, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.066, Train accuracy: 97.400, Test loss: 1.405, Test accuracy: 71.20 

        train local model (freeze embeding):client   3,  Train loss: 0.152, Train accuracy: 96.400, Test loss: 0.826, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.147, Train accuracy: 95.200, Test loss: 1.028, Test accuracy: 67.20 

Round   4, Train loss: 0.069, Test loss: 1.115, Test accuracy: 74.05 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.459, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.200, Test loss: 1.831, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.323, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.751, Test accuracy: 73.00 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.031, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.082, Train accuracy: 97.200, Test loss: 1.404, Test accuracy: 70.20 

        train local model (freeze embeding):client   3,  Train loss: 0.115, Train accuracy: 96.800, Test loss: 0.841, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.208, Train accuracy: 92.600, Test loss: 1.199, Test accuracy: 68.40 

Round   5, Train loss: 0.080, Test loss: 1.160, Test accuracy: 74.20 

        train local model (freeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.403, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.037, Train accuracy: 99.000, Test loss: 1.820, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 0.030, Train accuracy: 99.600, Test loss: 1.416, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.400, Test loss: 1.879, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.024, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.140, Train accuracy: 95.400, Test loss: 1.467, Test accuracy: 66.60 

        train local model (freeze embeding):client   3,  Train loss: 0.115, Train accuracy: 97.000, Test loss: 0.879, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.158, Train accuracy: 94.000, Test loss: 1.334, Test accuracy: 65.60 

Round   6, Train loss: 0.087, Test loss: 1.169, Test accuracy: 73.85 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.454, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.967, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.311, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.020, Train accuracy: 99.200, Test loss: 1.686, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.996, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.288, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.078, Train accuracy: 98.800, Test loss: 0.865, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.485, Train accuracy: 84.200, Test loss: 1.590, Test accuracy: 67.00 

Round   7, Train loss: 0.134, Test loss: 1.152, Test accuracy: 75.00 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.347, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.648, Test accuracy: 72.20 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.338, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.400, Test loss: 1.573, Test accuracy: 72.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.992, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.033, Train accuracy: 98.800, Test loss: 1.322, Test accuracy: 74.80 

        train local model (freeze embeding):client   3,  Train loss: 0.054, Train accuracy: 99.200, Test loss: 0.868, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.200, Train accuracy: 93.200, Test loss: 1.350, Test accuracy: 66.40 

Round   8, Train loss: 0.061, Test loss: 1.178, Test accuracy: 74.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.397, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.029, Train accuracy: 99.400, Test loss: 1.939, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.332, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.033, Train accuracy: 98.800, Test loss: 1.648, Test accuracy: 71.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.022, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.032, Train accuracy: 98.800, Test loss: 1.307, Test accuracy: 75.00 

        train local model (freeze embeding):client   3,  Train loss: 0.038, Train accuracy: 99.600, Test loss: 0.951, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.135, Train accuracy: 95.600, Test loss: 1.328, Test accuracy: 69.60 

Round   9, Train loss: 0.057, Test loss: 1.141, Test accuracy: 75.15 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.309, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.774, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.305, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.031, Train accuracy: 98.800, Test loss: 1.663, Test accuracy: 71.00 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.991, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.041, Train accuracy: 99.200, Test loss: 1.411, Test accuracy: 74.40 

        train local model (freeze embeding):client   3,  Train loss: 0.034, Train accuracy: 99.400, Test loss: 0.975, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.135, Train accuracy: 95.000, Test loss: 1.257, Test accuracy: 67.20 

Round  10, Train loss: 0.054, Test loss: 1.143, Test accuracy: 75.00 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.283, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.714, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.312, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.560, Test accuracy: 72.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.025, Train accuracy: 99.200, Test loss: 1.465, Test accuracy: 75.00 

        train local model (freeze embeding):client   3,  Train loss: 0.028, Train accuracy: 99.200, Test loss: 0.938, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.115, Train accuracy: 95.400, Test loss: 1.207, Test accuracy: 69.00 

Round  11, Train loss: 0.036, Test loss: 1.224, Test accuracy: 75.25 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.389, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.029, Train accuracy: 98.800, Test loss: 1.821, Test accuracy: 70.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.339, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.053, Train accuracy: 98.800, Test loss: 1.934, Test accuracy: 69.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.159, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.056, Train accuracy: 97.200, Test loss: 1.479, Test accuracy: 71.00 

        train local model (freeze embeding):client   3,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.039, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.050, Train accuracy: 98.200, Test loss: 1.221, Test accuracy: 71.00 

Round  12, Train loss: 0.047, Test loss: 1.195, Test accuracy: 74.45 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.410, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.400, Test loss: 1.840, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.358, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.655, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.062, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.474, Test accuracy: 75.80 

        train local model (freeze embeding):client   3,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.034, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.157, Train accuracy: 94.800, Test loss: 1.182, Test accuracy: 69.80 

Round  13, Train loss: 0.049, Test loss: 1.112, Test accuracy: 74.90 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.353, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.000, Test loss: 1.684, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.244, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.507, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.052, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.099, Train accuracy: 96.000, Test loss: 1.758, Test accuracy: 70.40 

        train local model (freeze embeding):client   3,  Train loss: 0.017, Train accuracy: 100.000, Test loss: 0.995, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.117, Train accuracy: 96.400, Test loss: 1.398, Test accuracy: 67.40 

Round  14, Train loss: 0.063, Test loss: 1.189, Test accuracy: 73.85 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.437, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.200, Test loss: 1.716, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.269, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.764, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.085, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.279, Test accuracy: 78.20 

        train local model (freeze embeding):client   3,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.080, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.159, Train accuracy: 94.200, Test loss: 1.748, Test accuracy: 64.80 

Round  15, Train loss: 0.052, Test loss: 1.222, Test accuracy: 74.15 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.450, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.600, Test loss: 1.813, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.372, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.034, Train accuracy: 98.800, Test loss: 1.604, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.113, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.054, Train accuracy: 98.800, Test loss: 1.414, Test accuracy: 72.20 

        train local model (freeze embeding):client   3,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.075, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.078, Train accuracy: 98.000, Test loss: 1.409, Test accuracy: 67.60 

Round  16, Train loss: 0.047, Test loss: 1.192, Test accuracy: 73.75 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.367, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.200, Test loss: 2.095, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.287, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.549, Test accuracy: 73.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.072, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.191, Test accuracy: 78.60 

        train local model (freeze embeding):client   3,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.040, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.081, Train accuracy: 97.400, Test loss: 1.449, Test accuracy: 68.80 

Round  17, Train loss: 0.027, Test loss: 1.295, Test accuracy: 74.30 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.459, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.400, Test loss: 1.937, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.355, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.862, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.094, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.032, Train accuracy: 99.200, Test loss: 1.199, Test accuracy: 75.60 

        train local model (freeze embeding):client   3,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.072, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.225, Test accuracy: 72.40 

Round  18, Train loss: 0.016, Test loss: 1.245, Test accuracy: 74.70 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.495, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.587, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.398, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.763, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.089, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.054, Train accuracy: 98.200, Test loss: 1.467, Test accuracy: 71.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.025, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.092, Train accuracy: 96.800, Test loss: 1.422, Test accuracy: 69.80 

Round  19, Train loss: 0.042, Test loss: 1.209, Test accuracy: 74.40 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.321, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.940, Test accuracy: 67.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.335, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.400, Test loss: 1.527, Test accuracy: 72.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.014, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.088, Train accuracy: 97.200, Test loss: 1.459, Test accuracy: 72.20 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.026, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.118, Train accuracy: 96.000, Test loss: 1.684, Test accuracy: 69.40 

Final Round, Train loss: 0.057, Test loss: 1.185, Test accuracy: 75.10 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.408, Train accuracy: 82.400, Test loss: 0.583, Test accuracy: 76.40 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.339, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.054, Train accuracy: 97.800, Test loss: 2.051, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.350, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.519, Test accuracy: 71.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.990, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.107, Test accuracy: 79.60 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.014, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.051, Train accuracy: 98.600, Test loss: 1.348, Test accuracy: 70.20 

        train local model (freeze embeding):client   4,  Train loss: 0.406, Train accuracy: 84.400, Test loss: 0.638, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.147, Train accuracy: 96.000, Test loss: 0.764, Test accuracy: 77.20 

Round   0, Train loss: 0.051, Test loss: 1.056, Test accuracy: 76.52 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.314, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.070, Train accuracy: 98.200, Test loss: 1.903, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.346, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.548, Test accuracy: 73.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.000, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.114, Test accuracy: 79.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.431, Train accuracy: 91.200, Test loss: 2.094, Test accuracy: 63.60 

        train local model (freeze embeding):client   4,  Train loss: 0.293, Train accuracy: 89.200, Test loss: 0.651, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.123, Train accuracy: 96.800, Test loss: 0.897, Test accuracy: 78.20 

Round   1, Train loss: 0.125, Test loss: 1.075, Test accuracy: 76.32 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.346, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.161, Train accuracy: 95.200, Test loss: 2.092, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.269, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.506, Test accuracy: 74.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.995, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.261, Test accuracy: 76.60 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.061, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.068, Train accuracy: 97.000, Test loss: 1.583, Test accuracy: 67.00 

        train local model (freeze embeding):client   4,  Train loss: 0.167, Train accuracy: 95.200, Test loss: 0.630, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.203, Train accuracy: 93.800, Test loss: 1.057, Test accuracy: 73.40 

Round   2, Train loss: 0.088, Test loss: 1.104, Test accuracy: 76.12 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.321, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.400, Test loss: 2.142, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.257, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.034, Train accuracy: 99.400, Test loss: 1.546, Test accuracy: 72.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.057, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.291, Test accuracy: 75.40 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.037, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.111, Train accuracy: 96.200, Test loss: 1.540, Test accuracy: 68.60 

        train local model (freeze embeding):client   4,  Train loss: 0.133, Train accuracy: 95.200, Test loss: 0.624, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.066, Train accuracy: 98.200, Test loss: 0.703, Test accuracy: 79.40 

Round   3, Train loss: 0.048, Test loss: 1.069, Test accuracy: 76.44 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.366, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.731, Test accuracy: 72.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.255, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.415, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.065, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.046, Train accuracy: 98.400, Test loss: 1.411, Test accuracy: 77.00 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.079, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.307, Train accuracy: 90.200, Test loss: 1.903, Test accuracy: 65.80 

        train local model (freeze embeding):client   4,  Train loss: 0.095, Train accuracy: 97.600, Test loss: 0.623, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.067, Train accuracy: 97.600, Test loss: 0.925, Test accuracy: 76.40 

Round   4, Train loss: 0.087, Test loss: 1.101, Test accuracy: 76.92 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.317, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.057, Train accuracy: 98.800, Test loss: 1.871, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.254, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.026, Train accuracy: 99.000, Test loss: 1.604, Test accuracy: 71.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.067, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.039, Train accuracy: 98.400, Test loss: 1.390, Test accuracy: 76.20 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.025, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.355, Test accuracy: 71.60 

        train local model (freeze embeding):client   4,  Train loss: 0.080, Train accuracy: 97.000, Test loss: 0.665, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.081, Train accuracy: 96.200, Test loss: 0.840, Test accuracy: 79.20 

Round   5, Train loss: 0.042, Test loss: 1.039, Test accuracy: 76.72 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.410, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 1.833, Test accuracy: 69.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.335, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.669, Test accuracy: 71.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.996, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.240, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.114, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.206, Train accuracy: 92.800, Test loss: 1.756, Test accuracy: 62.60 

        train local model (freeze embeding):client   4,  Train loss: 0.047, Train accuracy: 99.800, Test loss: 0.651, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.139, Train accuracy: 95.000, Test loss: 0.882, Test accuracy: 76.20 

Round   6, Train loss: 0.074, Test loss: 1.009, Test accuracy: 76.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.296, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.527, Test accuracy: 73.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.277, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.470, Test accuracy: 74.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.966, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.496, Test accuracy: 75.20 

        train local model (freeze embeding):client   3,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 0.973, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.039, Train accuracy: 99.200, Test loss: 1.424, Test accuracy: 69.60 

        train local model (freeze embeding):client   4,  Train loss: 0.045, Train accuracy: 99.400, Test loss: 0.620, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.051, Train accuracy: 98.600, Test loss: 0.865, Test accuracy: 75.60 

Round   7, Train loss: 0.023, Test loss: 1.080, Test accuracy: 76.00 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.267, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.595, Test accuracy: 72.40 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.268, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.409, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.114, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.060, Train accuracy: 98.400, Test loss: 1.553, Test accuracy: 74.20 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.079, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.083, Train accuracy: 97.800, Test loss: 1.540, Test accuracy: 68.40 

        train local model (freeze embeding):client   4,  Train loss: 0.034, Train accuracy: 99.400, Test loss: 0.673, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.091, Train accuracy: 96.600, Test loss: 1.062, Test accuracy: 76.20 

Round   8, Train loss: 0.047, Test loss: 1.049, Test accuracy: 76.88 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.305, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.507, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.286, Test accuracy: 74.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.048, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.123, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.103, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.300, Train accuracy: 91.800, Test loss: 1.678, Test accuracy: 67.60 

        train local model (freeze embeding):client   4,  Train loss: 0.019, Train accuracy: 100.000, Test loss: 0.651, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.135, Train accuracy: 95.800, Test loss: 1.124, Test accuracy: 74.80 

Round   9, Train loss: 0.095, Test loss: 0.981, Test accuracy: 77.16 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.134, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.804, Test accuracy: 70.80 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.143, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.509, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.976, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.096, Test accuracy: 80.20 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.016, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.052, Train accuracy: 98.800, Test loss: 1.537, Test accuracy: 69.20 

        train local model (freeze embeding):client   4,  Train loss: 0.025, Train accuracy: 99.800, Test loss: 0.667, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.059, Train accuracy: 98.200, Test loss: 0.985, Test accuracy: 77.60 

Round  10, Train loss: 0.027, Test loss: 1.103, Test accuracy: 76.56 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.410, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.821, Test accuracy: 70.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.264, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.135, Train accuracy: 95.600, Test loss: 2.034, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.059, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.131, Test accuracy: 75.40 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.137, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.067, Train accuracy: 97.800, Test loss: 1.414, Test accuracy: 70.40 

        train local model (freeze embeding):client   4,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 0.720, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.078, Train accuracy: 97.400, Test loss: 1.029, Test accuracy: 76.40 

Round  11, Train loss: 0.061, Test loss: 1.036, Test accuracy: 76.88 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.282, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.786, Test accuracy: 70.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.257, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.400, Test loss: 1.626, Test accuracy: 71.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.000, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.433, Test accuracy: 73.80 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.015, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.125, Train accuracy: 95.200, Test loss: 1.543, Test accuracy: 68.00 

        train local model (freeze embeding):client   4,  Train loss: 0.016, Train accuracy: 100.000, Test loss: 0.706, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.044, Train accuracy: 98.600, Test loss: 0.929, Test accuracy: 76.60 

Round  12, Train loss: 0.041, Test loss: 1.057, Test accuracy: 76.40 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.322, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.742, Test accuracy: 71.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.243, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.364, Test accuracy: 76.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.001, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.361, Test accuracy: 76.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.060, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.124, Train accuracy: 96.400, Test loss: 1.575, Test accuracy: 67.20 

        train local model (freeze embeding):client   4,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 0.664, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.123, Train accuracy: 96.400, Test loss: 1.008, Test accuracy: 75.60 

Round  13, Train loss: 0.050, Test loss: 1.044, Test accuracy: 77.00 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.354, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.604, Test accuracy: 70.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.182, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.031, Train accuracy: 99.000, Test loss: 1.947, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.003, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 1.114, Test accuracy: 76.80 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.011, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.274, Test accuracy: 73.80 

        train local model (freeze embeding):client   4,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 0.731, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.038, Train accuracy: 98.600, Test loss: 1.018, Test accuracy: 76.00 

Round  14, Train loss: 0.019, Test loss: 1.083, Test accuracy: 76.48 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.335, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.621, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.276, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 1.446, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.054, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 1.397, Test accuracy: 77.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.102, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.162, Train accuracy: 94.600, Test loss: 1.834, Test accuracy: 67.60 

        train local model (freeze embeding):client   4,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 0.767, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.032, Train accuracy: 98.800, Test loss: 1.000, Test accuracy: 77.00 

Round  15, Train loss: 0.046, Test loss: 1.090, Test accuracy: 76.92 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.319, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.032, Train accuracy: 98.800, Test loss: 1.766, Test accuracy: 71.40 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.284, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.100, Train accuracy: 97.000, Test loss: 1.613, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.049, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.199, Test accuracy: 79.60 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.100, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.040, Train accuracy: 98.800, Test loss: 1.466, Test accuracy: 71.60 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.718, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.092, Train accuracy: 97.000, Test loss: 1.181, Test accuracy: 75.60 

Round  16, Train loss: 0.054, Test loss: 1.021, Test accuracy: 77.84 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.280, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.102, Train accuracy: 97.800, Test loss: 1.885, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.213, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.371, Test accuracy: 75.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.021, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.138, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.054, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.370, Test accuracy: 72.60 

        train local model (freeze embeding):client   4,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 0.730, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.028, Train accuracy: 99.400, Test loss: 0.942, Test accuracy: 78.60 

Round  17, Train loss: 0.028, Test loss: 1.087, Test accuracy: 77.20 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.384, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.671, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.214, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.038, Train accuracy: 98.600, Test loss: 1.315, Test accuracy: 74.20 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.067, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.052, Train accuracy: 98.200, Test loss: 1.139, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.063, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.425, Test accuracy: 73.20 

        train local model (freeze embeding):client   4,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.735, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.105, Train accuracy: 96.000, Test loss: 1.056, Test accuracy: 75.00 

Round  18, Train loss: 0.042, Test loss: 1.018, Test accuracy: 77.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.678, Test accuracy: 73.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.108, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.273, Test accuracy: 74.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.963, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.146, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.066, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.456, Test accuracy: 71.60 

        train local model (freeze embeding):client   4,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 0.732, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.041, Train accuracy: 98.400, Test loss: 1.079, Test accuracy: 77.40 

Round  19, Train loss: 0.014, Test loss: 1.090, Test accuracy: 77.08 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.494, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 98.600, Test loss: 1.510, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.171, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.058, Train accuracy: 97.800, Test loss: 1.482, Test accuracy: 72.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.072, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.255, Test accuracy: 77.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.145, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.430, Test accuracy: 73.60 

        train local model (freeze embeding):client   4,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.720, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.026, Train accuracy: 99.000, Test loss: 0.961, Test accuracy: 79.00 

Final Round, Train loss: 0.026, Test loss: 1.077, Test accuracy: 76.96 

Average accuracy final 10 rounds: 351.93766666666676 

3156.0606677532196
[9.588768005371094, 18.963643312454224, 28.769679069519043, 38.4546537399292, 48.49846959114075, 58.016119718551636, 67.49133896827698, 76.78182649612427, 86.43422818183899, 95.68666434288025, 105.15155839920044, 114.35979795455933, 123.22841548919678, 132.44514322280884, 141.6573567390442, 151.07390213012695, 160.29628682136536, 169.23394870758057, 178.17939281463623, 187.65503191947937, 197.25977635383606, 206.82886052131653, 216.35821342468262, 226.37561345100403, 236.15918803215027, 246.08177065849304, 256.25562381744385, 265.5586450099945, 275.44914627075195, 285.02292490005493, 294.43748021125793, 304.5505847930908, 314.3222029209137, 324.0192606449127, 333.6175708770752, 343.0920021533966, 352.2655448913574, 361.6883268356323, 371.21071791648865, 380.68635272979736, 389.89370012283325, 399.3785045146942, 408.77855706214905, 418.0043075084686, 428.1149125099182, 437.745263338089, 447.5431156158447, 457.1792678833008, 466.8951539993286, 477.11511969566345, 487.1169250011444, 496.693630695343, 506.385502576828, 516.1178500652313, 525.6996915340424, 535.4925084114075, 545.1791088581085, 554.6042604446411, 564.7417109012604, 574.1626908779144, 584.3802206516266, 593.7522563934326, 603.3748414516449, 613.9078364372253, 624.2050230503082, 633.4301404953003, 643.0095021724701, 652.8897414207458, 662.3843491077423, 672.2644877433777, 681.9828412532806, 691.7700669765472, 701.6560332775116, 711.4358820915222, 721.3615143299103, 731.1482322216034, 741.5795154571533, 751.5645773410797, 761.484201669693, 771.4005880355835, 781.6860091686249, 791.5958693027496, 801.0625998973846, 810.5426104068756, 820.3395276069641, 830.0306668281555, 840.2080314159393, 849.677102804184, 860.1741096973419, 870.1731824874878, 879.9171388149261, 889.7733495235443, 899.5521297454834, 909.3579096794128, 919.2043650150299, 929.5088260173798, 939.2542378902435, 948.8821110725403, 958.7301862239838, 968.686600446701, 978.2672066688538, 988.026967048645, 997.9757730960846, 1007.6507706642151, 1017.6825168132782]
[59.4, 57.8, 54.8, 55.6, 60.6, 63.8, 58.2, 55.6, 60.6, 65.4, 62.0, 59.6, 60.6, 57.6, 59.0, 60.0, 58.4, 60.8, 60.6, 61.6, 62.6, 67.7, 68.0, 68.4, 66.3, 66.4, 68.9, 67.4, 67.8, 65.1, 68.5, 68.3, 67.1, 69.0, 69.8, 67.1, 68.7, 67.8, 69.1, 67.5, 67.2, 68.0, 70.2, 72.0, 72.26666666666667, 72.53333333333333, 72.26666666666667, 72.06666666666666, 72.0, 73.53333333333333, 72.06666666666666, 72.0, 71.93333333333334, 71.33333333333333, 72.33333333333333, 72.33333333333333, 71.73333333333333, 72.86666666666666, 72.73333333333333, 72.8, 71.6, 73.6, 73.4, 72.7, 73.65, 73.8, 73.35, 74.05, 74.2, 73.85, 75.0, 74.8, 75.15, 75.0, 75.25, 74.45, 74.9, 73.85, 74.15, 73.75, 74.3, 74.7, 74.4, 75.1, 76.52, 76.32, 76.12, 76.44, 76.92, 76.72, 76.2, 76.0, 76.88, 77.16, 76.56, 76.88, 76.4, 77.0, 76.48, 76.92, 77.84, 77.2, 77.2, 77.08, 76.96]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.643, Test loss: 0.607, Test accuracy: 77.40 

Round   0, Global train loss: 0.643, Global test loss: 0.745, Global test accuracy: 50.70 

Round   1, Train loss: 0.451, Test loss: 0.478, Test accuracy: 83.30 

Round   1, Global train loss: 0.451, Global test loss: 0.821, Global test accuracy: 50.00 

Round   2, Train loss: 0.394, Test loss: 0.412, Test accuracy: 85.30 

Round   2, Global train loss: 0.394, Global test loss: 0.947, Global test accuracy: 50.00 

Round   3, Train loss: 0.332, Test loss: 0.412, Test accuracy: 85.10 

Round   3, Global train loss: 0.332, Global test loss: 1.011, Global test accuracy: 50.00 

Round   4, Train loss: 0.300, Test loss: 0.440, Test accuracy: 83.30 

Round   4, Global train loss: 0.300, Global test loss: 1.065, Global test accuracy: 50.00 

Round   5, Train loss: 0.251, Test loss: 0.483, Test accuracy: 84.50 

Round   5, Global train loss: 0.251, Global test loss: 0.909, Global test accuracy: 50.00 

Round   6, Train loss: 0.204, Test loss: 0.529, Test accuracy: 82.30 

Round   6, Global train loss: 0.204, Global test loss: 1.136, Global test accuracy: 50.00 

Round   7, Train loss: 0.193, Test loss: 0.408, Test accuracy: 85.80 

Round   7, Global train loss: 0.193, Global test loss: 1.032, Global test accuracy: 50.00 

Round   8, Train loss: 0.155, Test loss: 0.504, Test accuracy: 85.20 

Round   8, Global train loss: 0.155, Global test loss: 1.003, Global test accuracy: 50.00 

Round   9, Train loss: 0.154, Test loss: 0.586, Test accuracy: 84.60 

Round   9, Global train loss: 0.154, Global test loss: 1.087, Global test accuracy: 50.00 

Round  10, Train loss: 0.121, Test loss: 0.493, Test accuracy: 86.00 

Round  10, Global train loss: 0.121, Global test loss: 1.129, Global test accuracy: 50.00 

Round  11, Train loss: 0.130, Test loss: 0.471, Test accuracy: 85.40 

Round  11, Global train loss: 0.130, Global test loss: 1.056, Global test accuracy: 50.00 

Round  12, Train loss: 0.098, Test loss: 0.491, Test accuracy: 86.80 

Round  12, Global train loss: 0.098, Global test loss: 0.975, Global test accuracy: 50.00 

Round  13, Train loss: 0.091, Test loss: 0.427, Test accuracy: 87.10 

Round  13, Global train loss: 0.091, Global test loss: 1.193, Global test accuracy: 50.00 

Round  14, Train loss: 0.074, Test loss: 0.483, Test accuracy: 86.60 

Round  14, Global train loss: 0.074, Global test loss: 1.178, Global test accuracy: 50.00 

Round  15, Train loss: 0.090, Test loss: 0.453, Test accuracy: 87.50 

Round  15, Global train loss: 0.090, Global test loss: 1.225, Global test accuracy: 50.00 

Round  16, Train loss: 0.063, Test loss: 0.490, Test accuracy: 87.00 

Round  16, Global train loss: 0.063, Global test loss: 1.342, Global test accuracy: 50.00 

Round  17, Train loss: 0.063, Test loss: 0.627, Test accuracy: 84.60 

Round  17, Global train loss: 0.063, Global test loss: 1.281, Global test accuracy: 50.00 

Round  18, Train loss: 0.061, Test loss: 0.421, Test accuracy: 88.90 

Round  18, Global train loss: 0.061, Global test loss: 1.213, Global test accuracy: 50.00 

Round  19, Train loss: 0.048, Test loss: 0.451, Test accuracy: 88.50 

Round  19, Global train loss: 0.048, Global test loss: 1.304, Global test accuracy: 50.00 

Round  20, Train loss: 0.048, Test loss: 0.511, Test accuracy: 87.50 

Round  20, Global train loss: 0.048, Global test loss: 1.330, Global test accuracy: 50.00 

Round  21, Train loss: 0.041, Test loss: 0.594, Test accuracy: 87.10 

Round  21, Global train loss: 0.041, Global test loss: 1.412, Global test accuracy: 50.00 

Round  22, Train loss: 0.060, Test loss: 0.505, Test accuracy: 88.00 

Round  22, Global train loss: 0.060, Global test loss: 1.432, Global test accuracy: 50.00 

Round  23, Train loss: 0.046, Test loss: 0.589, Test accuracy: 86.10 

Round  23, Global train loss: 0.046, Global test loss: 1.614, Global test accuracy: 50.00 

Round  24, Train loss: 0.035, Test loss: 0.481, Test accuracy: 89.00 

Round  24, Global train loss: 0.035, Global test loss: 1.560, Global test accuracy: 50.00 

Round  25, Train loss: 0.025, Test loss: 0.546, Test accuracy: 88.60 

Round  25, Global train loss: 0.025, Global test loss: 1.554, Global test accuracy: 50.00 

Round  26, Train loss: 0.018, Test loss: 0.556, Test accuracy: 88.90 

Round  26, Global train loss: 0.018, Global test loss: 1.586, Global test accuracy: 50.00 

Round  27, Train loss: 0.018, Test loss: 0.569, Test accuracy: 87.90 

Round  27, Global train loss: 0.018, Global test loss: 1.573, Global test accuracy: 50.00 

Round  28, Train loss: 0.041, Test loss: 0.480, Test accuracy: 87.90 

Round  28, Global train loss: 0.041, Global test loss: 1.425, Global test accuracy: 50.00 

Round  29, Train loss: 0.019, Test loss: 0.511, Test accuracy: 87.20 

Round  29, Global train loss: 0.019, Global test loss: 1.491, Global test accuracy: 50.00 

Round  30, Train loss: 0.005, Test loss: 0.511, Test accuracy: 88.20 

Round  30, Global train loss: 0.005, Global test loss: 1.572, Global test accuracy: 50.00 

Round  31, Train loss: 0.022, Test loss: 0.545, Test accuracy: 87.20 

Round  31, Global train loss: 0.022, Global test loss: 1.577, Global test accuracy: 50.00 

Round  32, Train loss: 0.020, Test loss: 0.471, Test accuracy: 88.00 

Round  32, Global train loss: 0.020, Global test loss: 1.484, Global test accuracy: 50.00 

Round  33, Train loss: 0.029, Test loss: 0.478, Test accuracy: 88.00 

Round  33, Global train loss: 0.029, Global test loss: 1.495, Global test accuracy: 50.00 

Round  34, Train loss: 0.027, Test loss: 0.525, Test accuracy: 86.70 

Round  34, Global train loss: 0.027, Global test loss: 1.552, Global test accuracy: 50.00 

Final Round, Train loss: 0.025, Test loss: 0.550, Test accuracy: 88.40 

Final Round, Global train loss: 0.025, Global test loss: 1.552, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 87.86 

Average global accuracy final 10 rounds: 50.0 

473.2488942146301
[4.397479772567749, 6.7786195278167725, 9.053995370864868, 11.318872928619385, 13.681171655654907, 15.922497987747192, 18.175028800964355, 20.418269395828247, 22.751871824264526, 25.027936458587646, 27.429954528808594, 29.70131015777588, 31.960958003997803, 34.31215691566467, 36.74873614311218, 39.07404327392578, 41.39482808113098, 43.803653955459595, 46.19065237045288, 48.56770372390747, 50.830169677734375, 53.15551018714905, 55.424954891204834, 57.747201442718506, 60.152032136917114, 62.495309829711914, 64.80252408981323, 67.10549879074097, 69.33690476417542, 71.66490411758423, 73.93851113319397, 76.23111653327942, 78.6894474029541, 81.01007270812988, 83.31566309928894, 88.14292025566101]
[77.4, 83.3, 85.3, 85.1, 83.3, 84.5, 82.3, 85.8, 85.2, 84.6, 86.0, 85.4, 86.8, 87.1, 86.6, 87.5, 87.0, 84.6, 88.9, 88.5, 87.5, 87.1, 88.0, 86.1, 89.0, 88.6, 88.9, 87.9, 87.9, 87.2, 88.2, 87.2, 88.0, 88.0, 86.7, 88.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.657, Test loss: 0.460, Test accuracy: 81.10 

Round   0, Global train loss: 0.657, Global test loss: 0.719, Global test accuracy: 50.00 

Round   1, Train loss: 0.566, Test loss: 0.533, Test accuracy: 76.20 

Round   1, Global train loss: 0.566, Global test loss: 1.061, Global test accuracy: 49.90 

Round   2, Train loss: 0.532, Test loss: 0.423, Test accuracy: 82.70 

Round   2, Global train loss: 0.532, Global test loss: 0.751, Global test accuracy: 57.60 

Round   3, Train loss: 0.483, Test loss: 0.441, Test accuracy: 81.50 

Round   3, Global train loss: 0.483, Global test loss: 0.782, Global test accuracy: 57.00 

Round   4, Train loss: 0.456, Test loss: 0.436, Test accuracy: 84.30 

Round   4, Global train loss: 0.456, Global test loss: 0.922, Global test accuracy: 54.70 

Round   5, Train loss: 0.425, Test loss: 0.550, Test accuracy: 81.30 

Round   5, Global train loss: 0.425, Global test loss: 0.857, Global test accuracy: 60.00 

Round   6, Train loss: 0.376, Test loss: 0.497, Test accuracy: 80.90 

Round   6, Global train loss: 0.376, Global test loss: 0.700, Global test accuracy: 63.50 

Round   7, Train loss: 0.380, Test loss: 0.571, Test accuracy: 82.90 

Round   7, Global train loss: 0.380, Global test loss: 0.755, Global test accuracy: 62.70 

Round   8, Train loss: 0.349, Test loss: 0.515, Test accuracy: 82.10 

Round   8, Global train loss: 0.349, Global test loss: 1.101, Global test accuracy: 57.30 

Round   9, Train loss: 0.331, Test loss: 0.449, Test accuracy: 82.70 

Round   9, Global train loss: 0.331, Global test loss: 0.751, Global test accuracy: 66.20 

Round  10, Train loss: 0.304, Test loss: 0.490, Test accuracy: 82.70 

Round  10, Global train loss: 0.304, Global test loss: 0.885, Global test accuracy: 62.40 

Round  11, Train loss: 0.293, Test loss: 0.474, Test accuracy: 86.90 

Round  11, Global train loss: 0.293, Global test loss: 0.759, Global test accuracy: 66.40 

Round  12, Train loss: 0.253, Test loss: 0.365, Test accuracy: 85.80 

Round  12, Global train loss: 0.253, Global test loss: 0.950, Global test accuracy: 60.90 

Round  13, Train loss: 0.287, Test loss: 0.421, Test accuracy: 84.60 

Round  13, Global train loss: 0.287, Global test loss: 0.745, Global test accuracy: 65.60 

Round  14, Train loss: 0.255, Test loss: 0.383, Test accuracy: 86.80 

Round  14, Global train loss: 0.255, Global test loss: 0.730, Global test accuracy: 65.30 

Round  15, Train loss: 0.239, Test loss: 0.448, Test accuracy: 84.10 

Round  15, Global train loss: 0.239, Global test loss: 0.883, Global test accuracy: 62.80 

Round  16, Train loss: 0.228, Test loss: 0.368, Test accuracy: 88.50 

Round  16, Global train loss: 0.228, Global test loss: 0.771, Global test accuracy: 65.80 

Round  17, Train loss: 0.231, Test loss: 0.447, Test accuracy: 84.70 

Round  17, Global train loss: 0.231, Global test loss: 0.767, Global test accuracy: 64.80 

Round  18, Train loss: 0.218, Test loss: 0.657, Test accuracy: 83.10 

Round  18, Global train loss: 0.218, Global test loss: 0.794, Global test accuracy: 65.90 

Round  19, Train loss: 0.198, Test loss: 0.462, Test accuracy: 85.60 

Round  19, Global train loss: 0.198, Global test loss: 0.742, Global test accuracy: 66.90 

Round  20, Train loss: 0.191, Test loss: 0.380, Test accuracy: 88.50 

Round  20, Global train loss: 0.191, Global test loss: 0.922, Global test accuracy: 65.40 

Round  21, Train loss: 0.191, Test loss: 0.481, Test accuracy: 85.90 

Round  21, Global train loss: 0.191, Global test loss: 0.708, Global test accuracy: 67.00 

Round  22, Train loss: 0.181, Test loss: 0.386, Test accuracy: 86.20 

Round  22, Global train loss: 0.181, Global test loss: 0.774, Global test accuracy: 66.00 

Round  23, Train loss: 0.167, Test loss: 0.507, Test accuracy: 85.50 

Round  23, Global train loss: 0.167, Global test loss: 0.812, Global test accuracy: 66.60 

Round  24, Train loss: 0.158, Test loss: 0.392, Test accuracy: 87.00 

Round  24, Global train loss: 0.158, Global test loss: 0.844, Global test accuracy: 66.80 

Round  25, Train loss: 0.160, Test loss: 0.373, Test accuracy: 87.70 

Round  25, Global train loss: 0.160, Global test loss: 0.916, Global test accuracy: 65.20 

Round  26, Train loss: 0.128, Test loss: 0.452, Test accuracy: 87.20 

Round  26, Global train loss: 0.128, Global test loss: 0.992, Global test accuracy: 65.60 

Round  27, Train loss: 0.153, Test loss: 0.439, Test accuracy: 85.60 

Round  27, Global train loss: 0.153, Global test loss: 0.822, Global test accuracy: 66.70 

Round  28, Train loss: 0.135, Test loss: 0.421, Test accuracy: 87.70 

Round  28, Global train loss: 0.135, Global test loss: 1.108, Global test accuracy: 62.80 

Round  29, Train loss: 0.122, Test loss: 0.397, Test accuracy: 87.30 

Round  29, Global train loss: 0.122, Global test loss: 1.077, Global test accuracy: 65.70 

Round  30, Train loss: 0.117, Test loss: 0.484, Test accuracy: 87.40 

Round  30, Global train loss: 0.117, Global test loss: 0.985, Global test accuracy: 66.30 

Round  31, Train loss: 0.113, Test loss: 0.403, Test accuracy: 87.10 

Round  31, Global train loss: 0.113, Global test loss: 0.995, Global test accuracy: 66.70 

Round  32, Train loss: 0.117, Test loss: 0.533, Test accuracy: 86.30 

Round  32, Global train loss: 0.117, Global test loss: 0.881, Global test accuracy: 66.70 

Round  33, Train loss: 0.101, Test loss: 0.472, Test accuracy: 85.20 

Round  33, Global train loss: 0.101, Global test loss: 0.762, Global test accuracy: 69.70 

Round  34, Train loss: 0.094, Test loss: 0.429, Test accuracy: 86.90 

Round  34, Global train loss: 0.094, Global test loss: 1.042, Global test accuracy: 65.20 

Final Round, Train loss: 0.077, Test loss: 0.444, Test accuracy: 87.40 

Final Round, Global train loss: 0.077, Global test loss: 1.042, Global test accuracy: 65.20 

Average accuracy final 10 rounds: 86.83999999999999 

Average global accuracy final 10 rounds: 66.06 

478.3955512046814
[4.061957597732544, 6.35231876373291, 8.656232118606567, 11.113381147384644, 13.51255989074707, 15.805382251739502, 18.170599699020386, 20.658924102783203, 22.973248720169067, 25.316136598587036, 27.552271604537964, 29.88321089744568, 32.18689680099487, 34.50676488876343, 36.83238744735718, 39.135008811950684, 41.52463936805725, 43.855862617492676, 46.13746929168701, 48.62769937515259, 50.91296458244324, 53.263248920440674, 55.62771558761597, 58.1560218334198, 60.465590715408325, 62.77073812484741, 65.01533842086792, 67.5159547328949, 69.87548589706421, 72.26846313476562, 74.65712690353394, 77.05082082748413, 79.4644980430603, 81.80971598625183, 84.13593792915344, 89.09036207199097]
[81.1, 76.2, 82.7, 81.5, 84.3, 81.3, 80.9, 82.9, 82.1, 82.7, 82.7, 86.9, 85.8, 84.6, 86.8, 84.1, 88.5, 84.7, 83.1, 85.6, 88.5, 85.9, 86.2, 85.5, 87.0, 87.7, 87.2, 85.6, 87.7, 87.3, 87.4, 87.1, 86.3, 85.2, 86.9, 87.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.791, Test loss: 0.945, Test accuracy: 52.20 

Round   1, Train loss: 0.645, Test loss: 0.887, Test accuracy: 52.80 

Round   2, Train loss: 0.592, Test loss: 0.693, Test accuracy: 65.20 

Round   3, Train loss: 0.562, Test loss: 0.853, Test accuracy: 62.80 

Round   4, Train loss: 0.509, Test loss: 0.635, Test accuracy: 68.40 

Round   5, Train loss: 0.476, Test loss: 0.605, Test accuracy: 73.70 

Round   6, Train loss: 0.476, Test loss: 0.724, Test accuracy: 70.10 

Round   7, Train loss: 0.427, Test loss: 0.543, Test accuracy: 75.90 

Round   8, Train loss: 0.412, Test loss: 0.550, Test accuracy: 77.20 

Round   9, Train loss: 0.390, Test loss: 0.435, Test accuracy: 80.90 

Round  10, Train loss: 0.397, Test loss: 0.514, Test accuracy: 75.80 

Round  11, Train loss: 0.378, Test loss: 0.416, Test accuracy: 80.10 

Round  12, Train loss: 0.361, Test loss: 0.519, Test accuracy: 81.00 

Round  13, Train loss: 0.366, Test loss: 0.800, Test accuracy: 74.90 

Round  14, Train loss: 0.349, Test loss: 0.420, Test accuracy: 81.50 

Round  15, Train loss: 0.300, Test loss: 0.475, Test accuracy: 80.30 

Round  16, Train loss: 0.295, Test loss: 0.411, Test accuracy: 83.00 

Round  17, Train loss: 0.281, Test loss: 0.455, Test accuracy: 81.50 

Round  18, Train loss: 0.288, Test loss: 0.375, Test accuracy: 85.30 

Round  19, Train loss: 0.286, Test loss: 0.638, Test accuracy: 78.30 

Round  20, Train loss: 0.264, Test loss: 0.329, Test accuracy: 86.60 

Round  21, Train loss: 0.246, Test loss: 0.429, Test accuracy: 84.40 

Round  22, Train loss: 0.234, Test loss: 0.328, Test accuracy: 87.50 

Round  23, Train loss: 0.232, Test loss: 0.366, Test accuracy: 85.50 

Round  24, Train loss: 0.215, Test loss: 0.332, Test accuracy: 86.80 

Round  25, Train loss: 0.220, Test loss: 0.369, Test accuracy: 86.80 

Round  26, Train loss: 0.199, Test loss: 0.437, Test accuracy: 83.00 

Round  27, Train loss: 0.199, Test loss: 0.366, Test accuracy: 86.40 

Round  28, Train loss: 0.195, Test loss: 0.339, Test accuracy: 88.10 

Round  29, Train loss: 0.181, Test loss: 0.362, Test accuracy: 87.10 

Round  30, Train loss: 0.191, Test loss: 0.385, Test accuracy: 86.00 

Round  31, Train loss: 0.167, Test loss: 0.321, Test accuracy: 87.10 

Round  32, Train loss: 0.185, Test loss: 0.399, Test accuracy: 85.60 

Round  33, Train loss: 0.137, Test loss: 0.357, Test accuracy: 86.80 

Round  34, Train loss: 0.153, Test loss: 0.349, Test accuracy: 88.90 

Round  35, Train loss: 0.142, Test loss: 0.373, Test accuracy: 87.00 

Round  36, Train loss: 0.139, Test loss: 0.356, Test accuracy: 87.80 

Round  37, Train loss: 0.128, Test loss: 0.405, Test accuracy: 86.70 

Round  38, Train loss: 0.142, Test loss: 0.398, Test accuracy: 87.50 

Round  39, Train loss: 0.118, Test loss: 0.364, Test accuracy: 87.70 

Round  40, Train loss: 0.121, Test loss: 0.376, Test accuracy: 87.70 

Round  41, Train loss: 0.103, Test loss: 0.356, Test accuracy: 88.50 

Round  42, Train loss: 0.097, Test loss: 0.350, Test accuracy: 89.00 

Round  43, Train loss: 0.097, Test loss: 0.366, Test accuracy: 88.00 

Round  44, Train loss: 0.111, Test loss: 0.344, Test accuracy: 87.90 

Round  45, Train loss: 0.080, Test loss: 0.364, Test accuracy: 88.20 

Round  46, Train loss: 0.095, Test loss: 0.409, Test accuracy: 86.90 

Round  47, Train loss: 0.098, Test loss: 0.438, Test accuracy: 86.90 

Round  48, Train loss: 0.072, Test loss: 0.387, Test accuracy: 87.10 

Round  49, Train loss: 0.096, Test loss: 0.366, Test accuracy: 87.80 

Final Round, Train loss: 0.051, Test loss: 0.388, Test accuracy: 88.20 

Average accuracy final 10 rounds: 87.79999999999998 

489.6064672470093
[3.8506007194519043, 5.599132299423218, 7.434268474578857, 9.251572608947754, 11.071775913238525, 12.959798812866211, 14.830108880996704, 16.76678729057312, 18.585408210754395, 20.465179681777954, 22.255162477493286, 24.13620924949646, 25.952120542526245, 27.744311809539795, 29.548094034194946, 31.612954139709473, 33.51069498062134, 35.36826276779175, 37.208925008773804, 39.01546359062195, 40.81901431083679, 42.63303804397583, 44.617809772491455, 46.45742750167847, 48.292237758636475, 50.113839626312256, 51.8234224319458, 53.719894886016846, 55.591861963272095, 57.35368847846985, 59.16394639015198, 60.980605125427246, 62.80576825141907, 64.61669993400574, 66.39756059646606, 68.28867602348328, 70.13257145881653, 72.13854336738586, 74.11388802528381, 75.99957084655762, 77.83972096443176, 79.65902161598206, 81.43193793296814, 83.22575664520264, 84.98414635658264, 86.82092308998108, 88.65489292144775, 90.45703101158142, 92.34352469444275, 94.22317266464233, 96.395024061203]
[52.2, 52.8, 65.2, 62.8, 68.4, 73.7, 70.1, 75.9, 77.2, 80.9, 75.8, 80.1, 81.0, 74.9, 81.5, 80.3, 83.0, 81.5, 85.3, 78.3, 86.6, 84.4, 87.5, 85.5, 86.8, 86.8, 83.0, 86.4, 88.1, 87.1, 86.0, 87.1, 85.6, 86.8, 88.9, 87.0, 87.8, 86.7, 87.5, 87.7, 87.7, 88.5, 89.0, 88.0, 87.9, 88.2, 86.9, 86.9, 87.1, 87.8, 88.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.769, Test loss: 1.153, Test accuracy: 50.00
Round   1, Train loss: 0.635, Test loss: 0.955, Test accuracy: 54.10
Round   2, Train loss: 0.575, Test loss: 0.713, Test accuracy: 67.10
Round   3, Train loss: 0.556, Test loss: 0.913, Test accuracy: 67.70
Round   4, Train loss: 0.499, Test loss: 0.585, Test accuracy: 71.90
Round   5, Train loss: 0.465, Test loss: 0.461, Test accuracy: 75.70
Round   6, Train loss: 0.474, Test loss: 0.934, Test accuracy: 61.90
Round   7, Train loss: 0.420, Test loss: 0.437, Test accuracy: 80.70
Round   8, Train loss: 0.389, Test loss: 0.407, Test accuracy: 79.40
Round   9, Train loss: 0.381, Test loss: 0.501, Test accuracy: 77.80
Round  10, Train loss: 0.354, Test loss: 0.336, Test accuracy: 84.60
Round  11, Train loss: 0.359, Test loss: 0.400, Test accuracy: 82.70
Round  12, Train loss: 0.323, Test loss: 0.362, Test accuracy: 85.00
Round  13, Train loss: 0.295, Test loss: 0.309, Test accuracy: 87.40
Round  14, Train loss: 0.282, Test loss: 0.443, Test accuracy: 80.80
Round  15, Train loss: 0.277, Test loss: 0.354, Test accuracy: 84.20
Round  16, Train loss: 0.269, Test loss: 0.383, Test accuracy: 83.80
Round  17, Train loss: 0.254, Test loss: 0.375, Test accuracy: 85.10
Round  18, Train loss: 0.234, Test loss: 0.284, Test accuracy: 87.50
Round  19, Train loss: 0.217, Test loss: 0.333, Test accuracy: 85.90
Round  20, Train loss: 0.232, Test loss: 0.273, Test accuracy: 89.10
Round  21, Train loss: 0.209, Test loss: 0.311, Test accuracy: 87.90
Round  22, Train loss: 0.184, Test loss: 0.250, Test accuracy: 90.40
Round  23, Train loss: 0.174, Test loss: 0.296, Test accuracy: 88.20
Round  24, Train loss: 0.181, Test loss: 0.300, Test accuracy: 88.30
Round  25, Train loss: 0.170, Test loss: 0.260, Test accuracy: 88.50
Round  26, Train loss: 0.151, Test loss: 0.294, Test accuracy: 88.40
Round  27, Train loss: 0.158, Test loss: 0.267, Test accuracy: 89.20
Round  28, Train loss: 0.143, Test loss: 0.286, Test accuracy: 88.80
Round  29, Train loss: 0.150, Test loss: 0.284, Test accuracy: 88.80
Round  30, Train loss: 0.152, Test loss: 0.269, Test accuracy: 88.90
Round  31, Train loss: 0.117, Test loss: 0.294, Test accuracy: 88.50
Round  32, Train loss: 0.117, Test loss: 0.272, Test accuracy: 89.70
Round  33, Train loss: 0.111, Test loss: 0.293, Test accuracy: 88.30
Round  34, Train loss: 0.098, Test loss: 0.307, Test accuracy: 88.60
Round  35, Train loss: 0.117, Test loss: 0.332, Test accuracy: 87.60
Round  36, Train loss: 0.104, Test loss: 0.303, Test accuracy: 89.30
Round  37, Train loss: 0.085, Test loss: 0.295, Test accuracy: 89.60
Round  38, Train loss: 0.076, Test loss: 0.286, Test accuracy: 89.90
Round  39, Train loss: 0.087, Test loss: 0.294, Test accuracy: 90.20
Round  40, Train loss: 0.072, Test loss: 0.291, Test accuracy: 89.80
Round  41, Train loss: 0.086, Test loss: 0.295, Test accuracy: 89.00
Round  42, Train loss: 0.091, Test loss: 0.299, Test accuracy: 89.00
Round  43, Train loss: 0.065, Test loss: 0.297, Test accuracy: 89.60
Round  44, Train loss: 0.084, Test loss: 0.286, Test accuracy: 90.10
Round  45, Train loss: 0.074, Test loss: 0.321, Test accuracy: 88.90
Round  46, Train loss: 0.051, Test loss: 0.304, Test accuracy: 89.80
Round  47, Train loss: 0.051, Test loss: 0.338, Test accuracy: 89.50
Round  48, Train loss: 0.061, Test loss: 0.317, Test accuracy: 90.00
Round  49, Train loss: 0.039, Test loss: 0.302, Test accuracy: 90.30
Final Round, Train loss: 0.029, Test loss: 0.307, Test accuracy: 90.80
Average accuracy final 10 rounds: 89.60000000000001
550.3084986209869
[4.108490228652954, 6.09868597984314, 8.249033212661743, 10.293958187103271, 12.378870487213135, 14.449328422546387, 16.602442264556885, 18.708061456680298, 20.672407150268555, 22.76525592803955, 24.86644983291626, 26.980279684066772, 29.105507850646973, 31.100348949432373, 33.15568208694458, 35.360544204711914, 37.375245332717896, 39.45672535896301, 41.49527311325073, 43.53105711936951, 45.68625092506409, 47.719619035720825, 49.825379610061646, 51.94882845878601, 53.982948780059814, 55.97186017036438, 58.03671932220459, 60.09033942222595, 62.20292830467224, 64.37838816642761, 66.38802814483643, 68.47036004066467, 70.49389433860779, 72.51935982704163, 74.54320287704468, 76.67888259887695, 78.86579203605652, 80.99845123291016, 83.08007645606995, 85.24559164047241, 87.45168232917786, 89.67503118515015, 91.72012615203857, 93.93449401855469, 96.03582882881165, 98.16111540794373, 100.1685688495636, 102.20543646812439, 104.3054838180542, 106.366286277771, 108.78612494468689]
[50.0, 54.1, 67.1, 67.7, 71.9, 75.7, 61.9, 80.7, 79.4, 77.8, 84.6, 82.7, 85.0, 87.4, 80.8, 84.2, 83.8, 85.1, 87.5, 85.9, 89.1, 87.9, 90.4, 88.2, 88.3, 88.5, 88.4, 89.2, 88.8, 88.8, 88.9, 88.5, 89.7, 88.3, 88.6, 87.6, 89.3, 89.6, 89.9, 90.2, 89.8, 89.0, 89.0, 89.6, 90.1, 88.9, 89.8, 89.5, 90.0, 90.3, 90.8]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.576, Test loss: 0.377, Test accuracy: 83.40 

Round   0, Global train loss: 0.576, Global test loss: 0.775, Global test accuracy: 50.10 

Round   1, Train loss: 0.364, Test loss: 0.452, Test accuracy: 84.70 

Round   1, Global train loss: 0.364, Global test loss: 0.868, Global test accuracy: 50.00 

Round   2, Train loss: 0.285, Test loss: 0.358, Test accuracy: 88.80 

Round   2, Global train loss: 0.285, Global test loss: 0.811, Global test accuracy: 50.00 

Round   3, Train loss: 0.242, Test loss: 0.446, Test accuracy: 86.80 

Round   3, Global train loss: 0.242, Global test loss: 0.848, Global test accuracy: 50.00 

Round   4, Train loss: 0.217, Test loss: 0.378, Test accuracy: 85.70 

Round   4, Global train loss: 0.217, Global test loss: 0.795, Global test accuracy: 50.00 

Round   5, Train loss: 0.179, Test loss: 0.301, Test accuracy: 89.80 

Round   5, Global train loss: 0.179, Global test loss: 0.869, Global test accuracy: 50.00 

Round   6, Train loss: 0.149, Test loss: 0.361, Test accuracy: 87.40 

Round   6, Global train loss: 0.149, Global test loss: 0.880, Global test accuracy: 50.00 

Round   7, Train loss: 0.118, Test loss: 0.444, Test accuracy: 87.90 

Round   7, Global train loss: 0.118, Global test loss: 0.848, Global test accuracy: 50.00 

Round   8, Train loss: 0.127, Test loss: 0.313, Test accuracy: 88.90 

Round   8, Global train loss: 0.127, Global test loss: 0.876, Global test accuracy: 50.00 

Round   9, Train loss: 0.103, Test loss: 0.421, Test accuracy: 88.00 

Round   9, Global train loss: 0.103, Global test loss: 0.898, Global test accuracy: 50.00 

Round  10, Train loss: 0.056, Test loss: 0.334, Test accuracy: 91.00 

Round  10, Global train loss: 0.056, Global test loss: 0.970, Global test accuracy: 50.00 

Round  11, Train loss: 0.062, Test loss: 0.397, Test accuracy: 90.40 

Round  11, Global train loss: 0.062, Global test loss: 1.004, Global test accuracy: 50.00 

Round  12, Train loss: 0.105, Test loss: 0.372, Test accuracy: 88.10 

Round  12, Global train loss: 0.105, Global test loss: 0.887, Global test accuracy: 50.00 

Round  13, Train loss: 0.056, Test loss: 0.307, Test accuracy: 91.10 

Round  13, Global train loss: 0.056, Global test loss: 0.804, Global test accuracy: 50.00 

Round  14, Train loss: 0.058, Test loss: 0.419, Test accuracy: 89.40 

Round  14, Global train loss: 0.058, Global test loss: 1.015, Global test accuracy: 50.00 

Round  15, Train loss: 0.046, Test loss: 0.440, Test accuracy: 88.10 

Round  15, Global train loss: 0.046, Global test loss: 0.836, Global test accuracy: 50.10 

Round  16, Train loss: 0.052, Test loss: 0.457, Test accuracy: 87.00 

Round  16, Global train loss: 0.052, Global test loss: 0.888, Global test accuracy: 50.00 

Round  17, Train loss: 0.038, Test loss: 0.325, Test accuracy: 92.10 

Round  17, Global train loss: 0.038, Global test loss: 0.946, Global test accuracy: 50.00 

Round  18, Train loss: 0.039, Test loss: 0.392, Test accuracy: 90.00 

Round  18, Global train loss: 0.039, Global test loss: 0.949, Global test accuracy: 50.00 

Round  19, Train loss: 0.027, Test loss: 0.379, Test accuracy: 90.50 

Round  19, Global train loss: 0.027, Global test loss: 0.891, Global test accuracy: 50.00 

Round  20, Train loss: 0.033, Test loss: 0.354, Test accuracy: 91.60 

Round  20, Global train loss: 0.033, Global test loss: 0.904, Global test accuracy: 50.00 

Round  21, Train loss: 0.008, Test loss: 0.370, Test accuracy: 91.60 

Round  21, Global train loss: 0.008, Global test loss: 0.894, Global test accuracy: 50.00 

Round  22, Train loss: 0.029, Test loss: 0.380, Test accuracy: 91.10 

Round  22, Global train loss: 0.029, Global test loss: 0.934, Global test accuracy: 50.00 

Round  23, Train loss: 0.015, Test loss: 0.368, Test accuracy: 91.00 

Round  23, Global train loss: 0.015, Global test loss: 0.974, Global test accuracy: 50.00 

Round  24, Train loss: 0.016, Test loss: 0.370, Test accuracy: 91.60 

Round  24, Global train loss: 0.016, Global test loss: 0.971, Global test accuracy: 50.00 

Round  25, Train loss: 0.028, Test loss: 0.582, Test accuracy: 89.30 

Round  25, Global train loss: 0.028, Global test loss: 0.969, Global test accuracy: 50.00 

Round  26, Train loss: 0.024, Test loss: 0.588, Test accuracy: 86.80 

Round  26, Global train loss: 0.024, Global test loss: 0.942, Global test accuracy: 50.00 

Round  27, Train loss: 0.018, Test loss: 0.450, Test accuracy: 89.70 

Round  27, Global train loss: 0.018, Global test loss: 1.147, Global test accuracy: 50.00 

Round  28, Train loss: 0.023, Test loss: 0.378, Test accuracy: 90.50 

Round  28, Global train loss: 0.023, Global test loss: 1.105, Global test accuracy: 50.00 

Round  29, Train loss: 0.026, Test loss: 0.364, Test accuracy: 90.70 

Round  29, Global train loss: 0.026, Global test loss: 0.979, Global test accuracy: 50.00 

Round  30, Train loss: 0.004, Test loss: 0.376, Test accuracy: 91.20 

Round  30, Global train loss: 0.004, Global test loss: 1.034, Global test accuracy: 50.00 

Round  31, Train loss: 0.004, Test loss: 0.427, Test accuracy: 90.80 

Round  31, Global train loss: 0.004, Global test loss: 0.995, Global test accuracy: 50.00 

Round  32, Train loss: 0.004, Test loss: 0.465, Test accuracy: 90.00 

Round  32, Global train loss: 0.004, Global test loss: 0.953, Global test accuracy: 50.00 

Round  33, Train loss: 0.003, Test loss: 0.424, Test accuracy: 91.90 

Round  33, Global train loss: 0.003, Global test loss: 1.041, Global test accuracy: 50.00 

Round  34, Train loss: 0.020, Test loss: 0.365, Test accuracy: 91.40 

Round  34, Global train loss: 0.020, Global test loss: 0.919, Global test accuracy: 50.00 

Final Round, Train loss: 0.008, Test loss: 0.362, Test accuracy: 91.70 

Final Round, Global train loss: 0.008, Global test loss: 0.919, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 90.22999999999999 

Average global accuracy final 10 rounds: 50.0 

475.82202100753784
[4.445704460144043, 6.8135247230529785, 9.095213890075684, 11.418910026550293, 13.715294361114502, 16.011964559555054, 18.342819213867188, 20.632689714431763, 22.98048162460327, 25.373773097991943, 27.690343856811523, 29.983444452285767, 32.47910928726196, 34.71272015571594, 37.058653116226196, 39.39668679237366, 41.87401604652405, 44.105918884277344, 46.56659245491028, 48.8980815410614, 51.33252143859863, 53.666603803634644, 55.98188138008118, 58.30307102203369, 60.58042573928833, 62.93137288093567, 65.25311303138733, 67.61429333686829, 69.93401551246643, 72.25148105621338, 74.56770253181458, 76.95188641548157, 79.25630736351013, 81.56388092041016, 83.86561322212219, 88.749342918396]
[83.4, 84.7, 88.8, 86.8, 85.7, 89.8, 87.4, 87.9, 88.9, 88.0, 91.0, 90.4, 88.1, 91.1, 89.4, 88.1, 87.0, 92.1, 90.0, 90.5, 91.6, 91.6, 91.1, 91.0, 91.6, 89.3, 86.8, 89.7, 90.5, 90.7, 91.2, 90.8, 90.0, 91.9, 91.4, 91.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.553, Test loss: 0.515, Test accuracy: 82.60 

Round   0, Global train loss: 0.553, Global test loss: 0.774, Global test accuracy: 49.90 

Round   1, Train loss: 0.478, Test loss: 0.409, Test accuracy: 81.10 

Round   1, Global train loss: 0.478, Global test loss: 0.779, Global test accuracy: 61.50 

Round   2, Train loss: 0.403, Test loss: 0.608, Test accuracy: 85.10 

Round   2, Global train loss: 0.403, Global test loss: 0.818, Global test accuracy: 67.40 

Round   3, Train loss: 0.390, Test loss: 0.507, Test accuracy: 76.40 

Round   3, Global train loss: 0.390, Global test loss: 0.841, Global test accuracy: 64.30 

Round   4, Train loss: 0.357, Test loss: 0.390, Test accuracy: 85.00 

Round   4, Global train loss: 0.357, Global test loss: 0.713, Global test accuracy: 69.20 

Round   5, Train loss: 0.316, Test loss: 0.299, Test accuracy: 88.30 

Round   5, Global train loss: 0.316, Global test loss: 0.775, Global test accuracy: 68.90 

Round   6, Train loss: 0.314, Test loss: 0.309, Test accuracy: 88.90 

Round   6, Global train loss: 0.314, Global test loss: 0.674, Global test accuracy: 71.20 

Round   7, Train loss: 0.281, Test loss: 0.523, Test accuracy: 83.10 

Round   7, Global train loss: 0.281, Global test loss: 0.754, Global test accuracy: 68.50 

Round   8, Train loss: 0.249, Test loss: 0.305, Test accuracy: 89.10 

Round   8, Global train loss: 0.249, Global test loss: 0.945, Global test accuracy: 69.20 

Round   9, Train loss: 0.243, Test loss: 0.344, Test accuracy: 89.10 

Round   9, Global train loss: 0.243, Global test loss: 0.834, Global test accuracy: 67.60 

Round  10, Train loss: 0.248, Test loss: 0.354, Test accuracy: 88.10 

Round  10, Global train loss: 0.248, Global test loss: 0.794, Global test accuracy: 68.60 

Round  11, Train loss: 0.217, Test loss: 0.517, Test accuracy: 82.80 

Round  11, Global train loss: 0.217, Global test loss: 0.850, Global test accuracy: 68.70 

Round  12, Train loss: 0.215, Test loss: 0.347, Test accuracy: 88.50 

Round  12, Global train loss: 0.215, Global test loss: 0.813, Global test accuracy: 69.30 

Round  13, Train loss: 0.183, Test loss: 0.339, Test accuracy: 89.10 

Round  13, Global train loss: 0.183, Global test loss: 0.880, Global test accuracy: 68.50 

Round  14, Train loss: 0.188, Test loss: 0.321, Test accuracy: 88.80 

Round  14, Global train loss: 0.188, Global test loss: 0.775, Global test accuracy: 68.40 

Round  15, Train loss: 0.175, Test loss: 0.300, Test accuracy: 89.80 

Round  15, Global train loss: 0.175, Global test loss: 0.899, Global test accuracy: 67.70 

Round  16, Train loss: 0.159, Test loss: 0.365, Test accuracy: 88.10 

Round  16, Global train loss: 0.159, Global test loss: 0.956, Global test accuracy: 69.60 

Round  17, Train loss: 0.159, Test loss: 0.278, Test accuracy: 90.70 

Round  17, Global train loss: 0.159, Global test loss: 0.869, Global test accuracy: 69.90 

Round  18, Train loss: 0.140, Test loss: 0.344, Test accuracy: 88.30 

Round  18, Global train loss: 0.140, Global test loss: 0.885, Global test accuracy: 67.90 

Round  19, Train loss: 0.169, Test loss: 0.318, Test accuracy: 89.90 

Round  19, Global train loss: 0.169, Global test loss: 0.789, Global test accuracy: 70.10 

Round  20, Train loss: 0.132, Test loss: 0.332, Test accuracy: 90.10 

Round  20, Global train loss: 0.132, Global test loss: 0.802, Global test accuracy: 69.90 

Round  21, Train loss: 0.121, Test loss: 0.335, Test accuracy: 89.30 

Round  21, Global train loss: 0.121, Global test loss: 0.924, Global test accuracy: 70.50 

Round  22, Train loss: 0.112, Test loss: 0.374, Test accuracy: 88.20 

Round  22, Global train loss: 0.112, Global test loss: 0.893, Global test accuracy: 69.40 

Round  23, Train loss: 0.113, Test loss: 0.396, Test accuracy: 88.70 

Round  23, Global train loss: 0.113, Global test loss: 0.931, Global test accuracy: 71.50 

Round  24, Train loss: 0.120, Test loss: 0.326, Test accuracy: 91.30 

Round  24, Global train loss: 0.120, Global test loss: 0.859, Global test accuracy: 70.40 

Round  25, Train loss: 0.086, Test loss: 0.352, Test accuracy: 91.40 

Round  25, Global train loss: 0.086, Global test loss: 1.001, Global test accuracy: 71.00 

Round  26, Train loss: 0.110, Test loss: 0.503, Test accuracy: 88.20 

Round  26, Global train loss: 0.110, Global test loss: 0.882, Global test accuracy: 70.30 

Round  27, Train loss: 0.094, Test loss: 0.345, Test accuracy: 90.40 

Round  27, Global train loss: 0.094, Global test loss: 0.873, Global test accuracy: 69.40 

Round  28, Train loss: 0.096, Test loss: 0.365, Test accuracy: 90.60 

Round  28, Global train loss: 0.096, Global test loss: 1.026, Global test accuracy: 70.80 

Round  29, Train loss: 0.096, Test loss: 0.322, Test accuracy: 90.70 

Round  29, Global train loss: 0.096, Global test loss: 0.966, Global test accuracy: 70.70 

Round  30, Train loss: 0.085, Test loss: 0.452, Test accuracy: 86.40 

Round  30, Global train loss: 0.085, Global test loss: 1.010, Global test accuracy: 69.50 

Round  31, Train loss: 0.091, Test loss: 0.413, Test accuracy: 88.70 

Round  31, Global train loss: 0.091, Global test loss: 0.877, Global test accuracy: 71.10 

Round  32, Train loss: 0.062, Test loss: 0.428, Test accuracy: 89.90 

Round  32, Global train loss: 0.062, Global test loss: 1.133, Global test accuracy: 70.10 

Round  33, Train loss: 0.058, Test loss: 0.305, Test accuracy: 91.80 

Round  33, Global train loss: 0.058, Global test loss: 0.875, Global test accuracy: 70.90 

Round  34, Train loss: 0.069, Test loss: 0.392, Test accuracy: 89.00 

Round  34, Global train loss: 0.069, Global test loss: 1.027, Global test accuracy: 70.90 

Final Round, Train loss: 0.065, Test loss: 0.379, Test accuracy: 89.70 

Final Round, Global train loss: 0.065, Global test loss: 1.027, Global test accuracy: 70.90 

Average accuracy final 10 rounds: 89.71000000000001 

Average global accuracy final 10 rounds: 70.47 

481.1025621891022
[4.413795471191406, 6.736493110656738, 9.02713656425476, 11.363133430480957, 13.688406705856323, 15.980978727340698, 18.270475387573242, 20.63544225692749, 22.93222713470459, 25.18981623649597, 27.52947998046875, 30.106083631515503, 32.685606956481934, 35.096510887145996, 37.571789026260376, 39.984519958496094, 42.31205654144287, 44.63850235939026, 46.99199295043945, 49.27822971343994, 51.63985896110535, 53.966376543045044, 56.27955436706543, 58.60040831565857, 60.96579027175903, 63.342464208602905, 65.62114191055298, 67.93992161750793, 70.30776858329773, 72.61162281036377, 75.0642352104187, 77.4378776550293, 79.76777243614197, 82.26645612716675, 84.5515878200531, 89.22512793540955]
[82.6, 81.1, 85.1, 76.4, 85.0, 88.3, 88.9, 83.1, 89.1, 89.1, 88.1, 82.8, 88.5, 89.1, 88.8, 89.8, 88.1, 90.7, 88.3, 89.9, 90.1, 89.3, 88.2, 88.7, 91.3, 91.4, 88.2, 90.4, 90.6, 90.7, 86.4, 88.7, 89.9, 91.8, 89.0, 89.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.686, Test loss: 1.003, Test accuracy: 55.60 

Round   1, Train loss: 0.542, Test loss: 0.929, Test accuracy: 59.30 

Round   2, Train loss: 0.440, Test loss: 0.434, Test accuracy: 82.30 

Round   3, Train loss: 0.417, Test loss: 0.592, Test accuracy: 77.80 

Round   4, Train loss: 0.409, Test loss: 0.560, Test accuracy: 78.70 

Round   5, Train loss: 0.359, Test loss: 0.445, Test accuracy: 82.90 

Round   6, Train loss: 0.371, Test loss: 0.447, Test accuracy: 83.40 

Round   7, Train loss: 0.343, Test loss: 0.366, Test accuracy: 84.70 

Round   8, Train loss: 0.298, Test loss: 0.332, Test accuracy: 85.30 

Round   9, Train loss: 0.290, Test loss: 0.388, Test accuracy: 84.40 

Round  10, Train loss: 0.296, Test loss: 0.416, Test accuracy: 84.20 

Round  11, Train loss: 0.272, Test loss: 0.397, Test accuracy: 85.20 

Round  12, Train loss: 0.255, Test loss: 0.307, Test accuracy: 86.80 

Round  13, Train loss: 0.255, Test loss: 0.354, Test accuracy: 84.60 

Round  14, Train loss: 0.253, Test loss: 0.367, Test accuracy: 86.20 

Round  15, Train loss: 0.245, Test loss: 0.508, Test accuracy: 83.30 

Round  16, Train loss: 0.202, Test loss: 0.303, Test accuracy: 88.20 

Round  17, Train loss: 0.220, Test loss: 0.306, Test accuracy: 87.70 

Round  18, Train loss: 0.196, Test loss: 0.355, Test accuracy: 85.90 

Round  19, Train loss: 0.187, Test loss: 0.295, Test accuracy: 88.30 

Round  20, Train loss: 0.181, Test loss: 0.289, Test accuracy: 88.20 

Round  21, Train loss: 0.174, Test loss: 0.324, Test accuracy: 88.00 

Round  22, Train loss: 0.154, Test loss: 0.295, Test accuracy: 88.90 

Round  23, Train loss: 0.166, Test loss: 0.292, Test accuracy: 88.60 

Round  24, Train loss: 0.148, Test loss: 0.368, Test accuracy: 86.80 

Round  25, Train loss: 0.143, Test loss: 0.325, Test accuracy: 88.60 

Round  26, Train loss: 0.131, Test loss: 0.289, Test accuracy: 89.20 

Round  27, Train loss: 0.124, Test loss: 0.298, Test accuracy: 89.70 

Round  28, Train loss: 0.119, Test loss: 0.329, Test accuracy: 88.60 

Round  29, Train loss: 0.117, Test loss: 0.326, Test accuracy: 88.50 

Round  30, Train loss: 0.108, Test loss: 0.303, Test accuracy: 90.20 

Round  31, Train loss: 0.129, Test loss: 0.379, Test accuracy: 87.00 

Round  32, Train loss: 0.103, Test loss: 0.303, Test accuracy: 89.80 

Round  33, Train loss: 0.096, Test loss: 0.283, Test accuracy: 89.80 

Round  34, Train loss: 0.106, Test loss: 0.290, Test accuracy: 89.30 

Round  35, Train loss: 0.090, Test loss: 0.341, Test accuracy: 88.80 

Round  36, Train loss: 0.081, Test loss: 0.330, Test accuracy: 88.90 

Round  37, Train loss: 0.069, Test loss: 0.326, Test accuracy: 89.10 

Round  38, Train loss: 0.074, Test loss: 0.411, Test accuracy: 87.90 

Round  39, Train loss: 0.071, Test loss: 0.297, Test accuracy: 90.10 

Round  40, Train loss: 0.070, Test loss: 0.361, Test accuracy: 88.60 

Round  41, Train loss: 0.061, Test loss: 0.322, Test accuracy: 88.30 

Round  42, Train loss: 0.064, Test loss: 0.313, Test accuracy: 89.20 

Round  43, Train loss: 0.058, Test loss: 0.339, Test accuracy: 89.80 

Round  44, Train loss: 0.050, Test loss: 0.361, Test accuracy: 89.20 

Round  45, Train loss: 0.055, Test loss: 0.394, Test accuracy: 88.30 

Round  46, Train loss: 0.041, Test loss: 0.321, Test accuracy: 89.80 

Round  47, Train loss: 0.048, Test loss: 0.338, Test accuracy: 89.50 

Round  48, Train loss: 0.046, Test loss: 0.342, Test accuracy: 90.20 

Round  49, Train loss: 0.048, Test loss: 0.330, Test accuracy: 89.80 

Final Round, Train loss: 0.032, Test loss: 0.345, Test accuracy: 88.90 

Average accuracy final 10 rounds: 89.27000000000001 

492.0632047653198
[3.75989031791687, 5.676654100418091, 7.514168977737427, 9.368682861328125, 11.348296165466309, 13.15183973312378, 15.055646181106567, 16.89511203765869, 18.603607654571533, 20.410229444503784, 22.251015186309814, 24.112244129180908, 25.983790397644043, 27.863800525665283, 29.758929014205933, 31.581735134124756, 33.512418270111084, 35.37929821014404, 37.115395307540894, 38.99724316596985, 40.711151123046875, 42.49946069717407, 44.27868604660034, 46.102389097213745, 47.92729997634888, 49.74676704406738, 51.60269498825073, 53.63571500778198, 55.46301603317261, 57.31490683555603, 59.12386131286621, 60.87670683860779, 62.787806272506714, 64.62084317207336, 66.5608184337616, 68.408207654953, 70.23408031463623, 72.02073335647583, 73.81977891921997, 75.56335663795471, 77.34957790374756, 79.13908362388611, 81.01057767868042, 82.84775614738464, 84.6296558380127, 86.4033579826355, 88.25144481658936, 89.99502062797546, 92.11419916152954, 94.30049347877502, 96.56072521209717]
[55.6, 59.3, 82.3, 77.8, 78.7, 82.9, 83.4, 84.7, 85.3, 84.4, 84.2, 85.2, 86.8, 84.6, 86.2, 83.3, 88.2, 87.7, 85.9, 88.3, 88.2, 88.0, 88.9, 88.6, 86.8, 88.6, 89.2, 89.7, 88.6, 88.5, 90.2, 87.0, 89.8, 89.8, 89.3, 88.8, 88.9, 89.1, 87.9, 90.1, 88.6, 88.3, 89.2, 89.8, 89.2, 88.3, 89.8, 89.5, 90.2, 89.8, 88.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.630, Test loss: 1.054, Test accuracy: 50.30
Round   1, Train loss: 0.563, Test loss: 1.041, Test accuracy: 57.80
Round   2, Train loss: 0.531, Test loss: 0.971, Test accuracy: 62.60
Round   3, Train loss: 0.445, Test loss: 0.436, Test accuracy: 79.70
Round   4, Train loss: 0.417, Test loss: 0.498, Test accuracy: 74.40
Round   5, Train loss: 0.380, Test loss: 0.548, Test accuracy: 78.90
Round   6, Train loss: 0.355, Test loss: 0.435, Test accuracy: 81.80
Round   7, Train loss: 0.347, Test loss: 0.452, Test accuracy: 79.60
Round   8, Train loss: 0.346, Test loss: 0.456, Test accuracy: 81.10
Round   9, Train loss: 0.299, Test loss: 0.343, Test accuracy: 86.90
Round  10, Train loss: 0.275, Test loss: 0.384, Test accuracy: 84.70
Round  11, Train loss: 0.283, Test loss: 0.395, Test accuracy: 83.80
Round  12, Train loss: 0.258, Test loss: 0.376, Test accuracy: 85.40
Round  13, Train loss: 0.257, Test loss: 0.343, Test accuracy: 85.30
Round  14, Train loss: 0.255, Test loss: 0.339, Test accuracy: 86.40
Round  15, Train loss: 0.233, Test loss: 0.269, Test accuracy: 88.50
Round  16, Train loss: 0.215, Test loss: 0.415, Test accuracy: 85.50
Round  17, Train loss: 0.203, Test loss: 0.333, Test accuracy: 87.00
Round  18, Train loss: 0.180, Test loss: 0.334, Test accuracy: 87.10
Round  19, Train loss: 0.184, Test loss: 0.292, Test accuracy: 88.70
Round  20, Train loss: 0.178, Test loss: 0.293, Test accuracy: 88.00
Round  21, Train loss: 0.171, Test loss: 0.261, Test accuracy: 89.70
Round  22, Train loss: 0.161, Test loss: 0.252, Test accuracy: 90.10
Round  23, Train loss: 0.155, Test loss: 0.289, Test accuracy: 89.20
Round  24, Train loss: 0.142, Test loss: 0.260, Test accuracy: 90.40
Round  25, Train loss: 0.156, Test loss: 0.326, Test accuracy: 86.60
Round  26, Train loss: 0.131, Test loss: 0.293, Test accuracy: 89.10
Round  27, Train loss: 0.123, Test loss: 0.324, Test accuracy: 87.50
Round  28, Train loss: 0.108, Test loss: 0.263, Test accuracy: 89.70
Round  29, Train loss: 0.104, Test loss: 0.264, Test accuracy: 90.30
Round  30, Train loss: 0.098, Test loss: 0.276, Test accuracy: 90.00
Round  31, Train loss: 0.080, Test loss: 0.320, Test accuracy: 89.30
Round  32, Train loss: 0.096, Test loss: 0.267, Test accuracy: 90.10
Round  33, Train loss: 0.077, Test loss: 0.283, Test accuracy: 90.70
Round  34, Train loss: 0.073, Test loss: 0.288, Test accuracy: 89.90
Round  35, Train loss: 0.060, Test loss: 0.293, Test accuracy: 90.00
Round  36, Train loss: 0.082, Test loss: 0.307, Test accuracy: 89.40
Round  37, Train loss: 0.064, Test loss: 0.278, Test accuracy: 90.90
Round  38, Train loss: 0.069, Test loss: 0.272, Test accuracy: 91.30
Round  39, Train loss: 0.052, Test loss: 0.268, Test accuracy: 91.20
Round  40, Train loss: 0.061, Test loss: 0.302, Test accuracy: 90.50
Round  41, Train loss: 0.050, Test loss: 0.288, Test accuracy: 91.30
Round  42, Train loss: 0.047, Test loss: 0.293, Test accuracy: 90.50
Round  43, Train loss: 0.051, Test loss: 0.344, Test accuracy: 89.40
Round  44, Train loss: 0.032, Test loss: 0.305, Test accuracy: 90.10
Round  45, Train loss: 0.036, Test loss: 0.322, Test accuracy: 90.90
Round  46, Train loss: 0.036, Test loss: 0.311, Test accuracy: 90.70
Round  47, Train loss: 0.040, Test loss: 0.317, Test accuracy: 90.30
Round  48, Train loss: 0.032, Test loss: 0.309, Test accuracy: 90.70
Round  49, Train loss: 0.028, Test loss: 0.330, Test accuracy: 89.50
Final Round, Train loss: 0.020, Test loss: 0.325, Test accuracy: 90.40
Average accuracy final 10 rounds: 90.39
553.0534455776215
[4.1018898487091064, 6.1774818897247314, 8.164102792739868, 10.317699909210205, 12.386122941970825, 14.328277826309204, 16.408526182174683, 18.435584545135498, 20.460821390151978, 22.401193618774414, 24.473308086395264, 26.655752897262573, 28.708909273147583, 30.758549451828003, 32.91878271102905, 35.1713547706604, 37.41114783287048, 39.53313207626343, 41.63250708580017, 43.765865325927734, 45.77432823181152, 47.897889137268066, 49.92477226257324, 52.056047677993774, 54.19772934913635, 56.249069929122925, 58.34507489204407, 60.40635275840759, 62.49729514122009, 64.63547444343567, 66.64213371276855, 68.7445638179779, 70.80041265487671, 72.95514678955078, 75.23247504234314, 77.36211371421814, 79.57796216011047, 81.80036425590515, 83.89070320129395, 86.01887726783752, 88.16325664520264, 90.19109320640564, 92.3196656703949, 94.30174422264099, 96.33189463615417, 98.45334339141846, 100.62411212921143, 102.73846745491028, 104.8364667892456, 107.13884210586548, 109.61483955383301]
[50.3, 57.8, 62.6, 79.7, 74.4, 78.9, 81.8, 79.6, 81.1, 86.9, 84.7, 83.8, 85.4, 85.3, 86.4, 88.5, 85.5, 87.0, 87.1, 88.7, 88.0, 89.7, 90.1, 89.2, 90.4, 86.6, 89.1, 87.5, 89.7, 90.3, 90.0, 89.3, 90.1, 90.7, 89.9, 90.0, 89.4, 90.9, 91.3, 91.2, 90.5, 91.3, 90.5, 89.4, 90.1, 90.9, 90.7, 90.3, 90.7, 89.5, 90.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.465, Test loss: 1.391, Test accuracy: 43.90 

Round   0, Global train loss: 1.465, Global test loss: 1.634, Global test accuracy: 20.80 

Round   1, Train loss: 1.207, Test loss: 1.254, Test accuracy: 48.80 

Round   1, Global train loss: 1.207, Global test loss: 1.652, Global test accuracy: 24.00 

Round   2, Train loss: 1.045, Test loss: 1.240, Test accuracy: 52.70 

Round   2, Global train loss: 1.045, Global test loss: 1.511, Global test accuracy: 32.40 

Round   3, Train loss: 0.925, Test loss: 1.237, Test accuracy: 55.30 

Round   3, Global train loss: 0.925, Global test loss: 1.638, Global test accuracy: 26.90 

Round   4, Train loss: 0.826, Test loss: 1.366, Test accuracy: 55.30 

Round   4, Global train loss: 0.826, Global test loss: 1.543, Global test accuracy: 35.80 

Round   5, Train loss: 0.715, Test loss: 1.295, Test accuracy: 58.40 

Round   5, Global train loss: 0.715, Global test loss: 1.563, Global test accuracy: 38.20 

Round   6, Train loss: 0.609, Test loss: 1.737, Test accuracy: 53.30 

Round   6, Global train loss: 0.609, Global test loss: 1.697, Global test accuracy: 34.50 

Round   7, Train loss: 0.548, Test loss: 1.607, Test accuracy: 55.70 

Round   7, Global train loss: 0.548, Global test loss: 1.609, Global test accuracy: 35.00 

Round   8, Train loss: 0.459, Test loss: 1.456, Test accuracy: 59.00 

Round   8, Global train loss: 0.459, Global test loss: 1.532, Global test accuracy: 33.20 

Round   9, Train loss: 0.402, Test loss: 1.594, Test accuracy: 60.40 

Round   9, Global train loss: 0.402, Global test loss: 1.804, Global test accuracy: 34.00 

Round  10, Train loss: 0.339, Test loss: 1.685, Test accuracy: 57.60 

Round  10, Global train loss: 0.339, Global test loss: 1.960, Global test accuracy: 27.00 

Round  11, Train loss: 0.278, Test loss: 2.111, Test accuracy: 56.30 

Round  11, Global train loss: 0.278, Global test loss: 2.049, Global test accuracy: 23.20 

Round  12, Train loss: 0.268, Test loss: 2.150, Test accuracy: 59.40 

Round  12, Global train loss: 0.268, Global test loss: 1.807, Global test accuracy: 35.00 

Round  13, Train loss: 0.211, Test loss: 1.826, Test accuracy: 60.30 

Round  13, Global train loss: 0.211, Global test loss: 2.142, Global test accuracy: 25.70 

Round  14, Train loss: 0.188, Test loss: 2.075, Test accuracy: 57.60 

Round  14, Global train loss: 0.188, Global test loss: 1.918, Global test accuracy: 24.20 

Round  15, Train loss: 0.143, Test loss: 1.991, Test accuracy: 59.80 

Round  15, Global train loss: 0.143, Global test loss: 1.946, Global test accuracy: 28.30 

Round  16, Train loss: 0.145, Test loss: 2.157, Test accuracy: 59.40 

Round  16, Global train loss: 0.145, Global test loss: 2.083, Global test accuracy: 28.00 

Round  17, Train loss: 0.135, Test loss: 1.943, Test accuracy: 62.10 

Round  17, Global train loss: 0.135, Global test loss: 1.974, Global test accuracy: 31.70 

Round  18, Train loss: 0.086, Test loss: 1.958, Test accuracy: 61.90 

Round  18, Global train loss: 0.086, Global test loss: 1.882, Global test accuracy: 29.40 

Round  19, Train loss: 0.091, Test loss: 1.999, Test accuracy: 62.50 

Round  19, Global train loss: 0.091, Global test loss: 2.166, Global test accuracy: 31.30 

Round  20, Train loss: 0.095, Test loss: 1.939, Test accuracy: 63.70 

Round  20, Global train loss: 0.095, Global test loss: 2.000, Global test accuracy: 32.70 

Round  21, Train loss: 0.049, Test loss: 2.020, Test accuracy: 64.20 

Round  21, Global train loss: 0.049, Global test loss: 2.023, Global test accuracy: 33.00 

Round  22, Train loss: 0.049, Test loss: 2.027, Test accuracy: 63.80 

Round  22, Global train loss: 0.049, Global test loss: 2.097, Global test accuracy: 34.10 

Round  23, Train loss: 0.060, Test loss: 2.172, Test accuracy: 62.60 

Round  23, Global train loss: 0.060, Global test loss: 2.349, Global test accuracy: 26.80 

Round  24, Train loss: 0.063, Test loss: 2.016, Test accuracy: 64.60 

Round  24, Global train loss: 0.063, Global test loss: 1.990, Global test accuracy: 33.20 

Round  25, Train loss: 0.077, Test loss: 2.419, Test accuracy: 59.40 

Round  25, Global train loss: 0.077, Global test loss: 2.286, Global test accuracy: 29.50 

Round  26, Train loss: 0.065, Test loss: 2.173, Test accuracy: 60.00 

Round  26, Global train loss: 0.065, Global test loss: 2.107, Global test accuracy: 29.20 

Round  27, Train loss: 0.055, Test loss: 1.951, Test accuracy: 64.30 

Round  27, Global train loss: 0.055, Global test loss: 2.126, Global test accuracy: 28.90 

Round  28, Train loss: 0.058, Test loss: 2.052, Test accuracy: 64.70 

Round  28, Global train loss: 0.058, Global test loss: 2.043, Global test accuracy: 28.10 

Round  29, Train loss: 0.034, Test loss: 2.240, Test accuracy: 63.00 

Round  29, Global train loss: 0.034, Global test loss: 2.088, Global test accuracy: 28.40 

Round  30, Train loss: 0.042, Test loss: 2.150, Test accuracy: 63.40 

Round  30, Global train loss: 0.042, Global test loss: 2.443, Global test accuracy: 23.20 

Round  31, Train loss: 0.050, Test loss: 2.043, Test accuracy: 62.10 

Round  31, Global train loss: 0.050, Global test loss: 2.091, Global test accuracy: 27.40 

Round  32, Train loss: 0.057, Test loss: 2.030, Test accuracy: 63.80 

Round  32, Global train loss: 0.057, Global test loss: 2.168, Global test accuracy: 28.50 

Round  33, Train loss: 0.039, Test loss: 2.090, Test accuracy: 62.10 

Round  33, Global train loss: 0.039, Global test loss: 1.933, Global test accuracy: 30.80 

Round  34, Train loss: 0.016, Test loss: 2.122, Test accuracy: 63.30 

Round  34, Global train loss: 0.016, Global test loss: 1.988, Global test accuracy: 29.20 

Final Round, Train loss: 0.007, Test loss: 2.034, Test accuracy: 66.30 

Final Round, Global train loss: 0.007, Global test loss: 1.988, Global test accuracy: 29.20 

Average accuracy final 10 rounds: 62.61 

Average global accuracy final 10 rounds: 28.32 

464.4304184913635
[7.634875774383545, 13.41110873222351, 19.06097722053528, 24.705347061157227, 30.425360202789307, 36.124417543411255, 41.810545921325684, 47.39137291908264, 52.914204597473145, 58.52326011657715, 64.09903120994568, 69.54181504249573, 74.99568200111389, 80.54133033752441, 86.2052354812622, 91.84377217292786, 97.37866401672363, 102.72861838340759, 108.29042100906372, 114.02872705459595, 119.48729705810547, 125.28644299507141, 130.96790528297424, 136.53051662445068, 142.3924913406372, 148.02085709571838, 153.53747630119324, 159.23059344291687, 165.01967525482178, 170.50658059120178, 176.09400057792664, 181.58700442314148, 187.21909475326538, 192.95482635498047, 198.5069944858551, 209.35630226135254]
[43.9, 48.8, 52.7, 55.3, 55.3, 58.4, 53.3, 55.7, 59.0, 60.4, 57.6, 56.3, 59.4, 60.3, 57.6, 59.8, 59.4, 62.1, 61.9, 62.5, 63.7, 64.2, 63.8, 62.6, 64.6, 59.4, 60.0, 64.3, 64.7, 63.0, 63.4, 62.1, 63.8, 62.1, 63.3, 66.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.503, Test loss: 1.252, Test accuracy: 48.20 

Round   0, Global train loss: 1.503, Global test loss: 1.535, Global test accuracy: 31.10 

Round   1, Train loss: 1.281, Test loss: 1.347, Test accuracy: 48.80 

Round   1, Global train loss: 1.281, Global test loss: 1.392, Global test accuracy: 39.70 

Round   2, Train loss: 1.168, Test loss: 1.287, Test accuracy: 51.40 

Round   2, Global train loss: 1.168, Global test loss: 1.346, Global test accuracy: 44.20 

Round   3, Train loss: 1.039, Test loss: 1.386, Test accuracy: 51.00 

Round   3, Global train loss: 1.039, Global test loss: 1.331, Global test accuracy: 47.50 

Round   4, Train loss: 0.968, Test loss: 1.240, Test accuracy: 55.90 

Round   4, Global train loss: 0.968, Global test loss: 1.298, Global test accuracy: 49.50 

Round   5, Train loss: 0.897, Test loss: 1.219, Test accuracy: 57.50 

Round   5, Global train loss: 0.897, Global test loss: 1.285, Global test accuracy: 49.90 

Round   6, Train loss: 0.787, Test loss: 1.239, Test accuracy: 57.10 

Round   6, Global train loss: 0.787, Global test loss: 1.330, Global test accuracy: 49.60 

Round   7, Train loss: 0.726, Test loss: 1.367, Test accuracy: 57.70 

Round   7, Global train loss: 0.726, Global test loss: 1.532, Global test accuracy: 49.40 

Round   8, Train loss: 0.645, Test loss: 1.523, Test accuracy: 58.60 

Round   8, Global train loss: 0.645, Global test loss: 1.543, Global test accuracy: 49.70 

Round   9, Train loss: 0.598, Test loss: 1.333, Test accuracy: 61.80 

Round   9, Global train loss: 0.598, Global test loss: 1.520, Global test accuracy: 52.70 

Round  10, Train loss: 0.517, Test loss: 1.431, Test accuracy: 60.10 

Round  10, Global train loss: 0.517, Global test loss: 1.564, Global test accuracy: 52.40 

Round  11, Train loss: 0.454, Test loss: 1.551, Test accuracy: 62.10 

Round  11, Global train loss: 0.454, Global test loss: 1.690, Global test accuracy: 53.90 

Round  12, Train loss: 0.420, Test loss: 1.625, Test accuracy: 61.50 

Round  12, Global train loss: 0.420, Global test loss: 1.721, Global test accuracy: 52.40 

Round  13, Train loss: 0.367, Test loss: 1.553, Test accuracy: 61.80 

Round  13, Global train loss: 0.367, Global test loss: 1.721, Global test accuracy: 52.90 

Round  14, Train loss: 0.333, Test loss: 1.533, Test accuracy: 61.60 

Round  14, Global train loss: 0.333, Global test loss: 1.763, Global test accuracy: 52.70 

Round  15, Train loss: 0.293, Test loss: 1.690, Test accuracy: 61.40 

Round  15, Global train loss: 0.293, Global test loss: 1.642, Global test accuracy: 56.00 

Round  16, Train loss: 0.258, Test loss: 1.746, Test accuracy: 61.50 

Round  16, Global train loss: 0.258, Global test loss: 1.635, Global test accuracy: 55.90 

Round  17, Train loss: 0.226, Test loss: 1.516, Test accuracy: 64.40 

Round  17, Global train loss: 0.226, Global test loss: 1.790, Global test accuracy: 55.70 

Round  18, Train loss: 0.214, Test loss: 1.790, Test accuracy: 62.00 

Round  18, Global train loss: 0.214, Global test loss: 1.914, Global test accuracy: 55.30 

Round  19, Train loss: 0.205, Test loss: 1.970, Test accuracy: 59.00 

Round  19, Global train loss: 0.205, Global test loss: 1.816, Global test accuracy: 55.80 

Round  20, Train loss: 0.158, Test loss: 1.749, Test accuracy: 63.00 

Round  20, Global train loss: 0.158, Global test loss: 1.911, Global test accuracy: 54.60 

Round  21, Train loss: 0.136, Test loss: 1.736, Test accuracy: 63.40 

Round  21, Global train loss: 0.136, Global test loss: 2.074, Global test accuracy: 54.30 

Round  22, Train loss: 0.140, Test loss: 1.782, Test accuracy: 63.60 

Round  22, Global train loss: 0.140, Global test loss: 1.985, Global test accuracy: 56.10 

Round  23, Train loss: 0.127, Test loss: 1.980, Test accuracy: 62.30 

Round  23, Global train loss: 0.127, Global test loss: 1.970, Global test accuracy: 54.70 

Round  24, Train loss: 0.111, Test loss: 1.838, Test accuracy: 63.40 

Round  24, Global train loss: 0.111, Global test loss: 2.037, Global test accuracy: 56.10 

Round  25, Train loss: 0.116, Test loss: 1.743, Test accuracy: 65.20 

Round  25, Global train loss: 0.116, Global test loss: 2.146, Global test accuracy: 56.60 

Round  26, Train loss: 0.099, Test loss: 1.771, Test accuracy: 64.20 

Round  26, Global train loss: 0.099, Global test loss: 2.180, Global test accuracy: 53.30 

Round  27, Train loss: 0.082, Test loss: 1.960, Test accuracy: 65.00 

Round  27, Global train loss: 0.082, Global test loss: 2.299, Global test accuracy: 55.80 

Round  28, Train loss: 0.078, Test loss: 1.699, Test accuracy: 67.30 

Round  28, Global train loss: 0.078, Global test loss: 2.018, Global test accuracy: 57.40 

Round  29, Train loss: 0.090, Test loss: 2.102, Test accuracy: 63.30 

Round  29, Global train loss: 0.090, Global test loss: 2.085, Global test accuracy: 56.30 

Round  30, Train loss: 0.120, Test loss: 2.104, Test accuracy: 63.30 

Round  30, Global train loss: 0.120, Global test loss: 2.173, Global test accuracy: 55.40 

Round  31, Train loss: 0.073, Test loss: 2.134, Test accuracy: 60.80 

Round  31, Global train loss: 0.073, Global test loss: 2.269, Global test accuracy: 55.00 

Round  32, Train loss: 0.071, Test loss: 1.901, Test accuracy: 65.00 

Round  32, Global train loss: 0.071, Global test loss: 2.013, Global test accuracy: 58.60 

Round  33, Train loss: 0.055, Test loss: 1.941, Test accuracy: 64.60 

Round  33, Global train loss: 0.055, Global test loss: 2.245, Global test accuracy: 56.00 

Round  34, Train loss: 0.064, Test loss: 2.032, Test accuracy: 63.50 

Round  34, Global train loss: 0.064, Global test loss: 2.117, Global test accuracy: 57.50 

Final Round, Train loss: 0.042, Test loss: 2.137, Test accuracy: 62.80 

Final Round, Global train loss: 0.042, Global test loss: 2.117, Global test accuracy: 57.50 

Average accuracy final 10 rounds: 64.22 

Average global accuracy final 10 rounds: 56.190000000000005 

467.4604549407959
[7.771146774291992, 13.6623375415802, 19.103151559829712, 24.70811915397644, 30.404519081115723, 36.20092821121216, 41.82701349258423, 47.87177896499634, 53.426679611206055, 58.933536767959595, 64.48471760749817, 70.10044860839844, 75.81943321228027, 81.39134573936462, 87.08833575248718, 92.81313443183899, 98.55719995498657, 104.23842811584473, 109.86987042427063, 115.38699245452881, 120.65385890007019, 126.58546090126038, 132.19228434562683, 137.96825408935547, 143.72398591041565, 149.12646007537842, 154.54105710983276, 160.06900668144226, 165.7365596294403, 171.40124702453613, 176.99478268623352, 182.69848823547363, 188.2796492576599, 194.15124559402466, 199.5230872631073, 210.75063109397888]
[48.2, 48.8, 51.4, 51.0, 55.9, 57.5, 57.1, 57.7, 58.6, 61.8, 60.1, 62.1, 61.5, 61.8, 61.6, 61.4, 61.5, 64.4, 62.0, 59.0, 63.0, 63.4, 63.6, 62.3, 63.4, 65.2, 64.2, 65.0, 67.3, 63.3, 63.3, 60.8, 65.0, 64.6, 63.5, 62.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.536, Test loss: 1.700, Test accuracy: 25.20 

Round   1, Train loss: 1.332, Test loss: 1.435, Test accuracy: 40.10 

Round   2, Train loss: 1.198, Test loss: 1.059, Test accuracy: 53.30 

Round   3, Train loss: 1.120, Test loss: 1.179, Test accuracy: 52.30 

Round   4, Train loss: 1.032, Test loss: 1.102, Test accuracy: 54.50 

Round   5, Train loss: 0.966, Test loss: 1.165, Test accuracy: 52.30 

Round   6, Train loss: 0.879, Test loss: 1.129, Test accuracy: 55.50 

Round   7, Train loss: 0.807, Test loss: 1.064, Test accuracy: 58.20 

Round   8, Train loss: 0.735, Test loss: 1.136, Test accuracy: 57.30 

Round   9, Train loss: 0.709, Test loss: 1.174, Test accuracy: 54.80 

Round  10, Train loss: 0.659, Test loss: 1.197, Test accuracy: 57.80 

Round  11, Train loss: 0.599, Test loss: 1.099, Test accuracy: 59.30 

Round  12, Train loss: 0.556, Test loss: 1.068, Test accuracy: 60.90 

Round  13, Train loss: 0.491, Test loss: 1.176, Test accuracy: 59.90 

Round  14, Train loss: 0.442, Test loss: 1.179, Test accuracy: 62.70 

Round  15, Train loss: 0.396, Test loss: 1.267, Test accuracy: 61.30 

Round  16, Train loss: 0.373, Test loss: 1.222, Test accuracy: 60.50 

Round  17, Train loss: 0.348, Test loss: 1.264, Test accuracy: 62.70 

Round  18, Train loss: 0.307, Test loss: 1.227, Test accuracy: 62.30 

Round  19, Train loss: 0.304, Test loss: 1.205, Test accuracy: 63.30 

Round  20, Train loss: 0.240, Test loss: 1.218, Test accuracy: 64.40 

Round  21, Train loss: 0.221, Test loss: 1.266, Test accuracy: 63.90 

Round  22, Train loss: 0.215, Test loss: 1.329, Test accuracy: 64.50 

Round  23, Train loss: 0.162, Test loss: 1.350, Test accuracy: 64.20 

Round  24, Train loss: 0.178, Test loss: 1.524, Test accuracy: 60.70 

Round  25, Train loss: 0.155, Test loss: 1.419, Test accuracy: 62.90 

Round  26, Train loss: 0.149, Test loss: 1.500, Test accuracy: 61.80 

Round  27, Train loss: 0.153, Test loss: 1.472, Test accuracy: 64.40 

Round  28, Train loss: 0.149, Test loss: 1.491, Test accuracy: 60.80 

Round  29, Train loss: 0.149, Test loss: 1.318, Test accuracy: 65.80 

Round  30, Train loss: 0.109, Test loss: 1.437, Test accuracy: 64.30 

Round  31, Train loss: 0.087, Test loss: 1.495, Test accuracy: 65.10 

Round  32, Train loss: 0.094, Test loss: 1.430, Test accuracy: 63.90 

Round  33, Train loss: 0.077, Test loss: 1.439, Test accuracy: 66.70 

Round  34, Train loss: 0.058, Test loss: 1.606, Test accuracy: 65.40 

Round  35, Train loss: 0.055, Test loss: 1.628, Test accuracy: 62.80 

Round  36, Train loss: 0.061, Test loss: 1.576, Test accuracy: 65.30 

Round  37, Train loss: 0.060, Test loss: 1.684, Test accuracy: 64.00 

Round  38, Train loss: 0.053, Test loss: 1.687, Test accuracy: 65.60 

Round  39, Train loss: 0.074, Test loss: 1.568, Test accuracy: 65.50 

Final Round, Train loss: 0.036, Test loss: 1.526, Test accuracy: 66.40 

Average accuracy final 10 rounds: 64.86 

388.042275428772
[6.778625249862671, 11.031738042831421, 15.532874822616577, 20.00245428085327, 24.37366008758545, 28.73644781112671, 33.091081619262695, 37.4550986289978, 41.66865944862366, 46.00637602806091, 50.40102434158325, 54.63895797729492, 59.16190433502197, 63.7269082069397, 67.95307898521423, 72.56882929801941, 76.89200615882874, 81.70225644111633, 86.11370372772217, 90.38923001289368, 94.7778594493866, 99.29874563217163, 103.6561062335968, 108.0692229270935, 112.35204935073853, 116.80574989318848, 121.34204316139221, 125.44857382774353, 129.70303010940552, 133.86656141281128, 138.3660044670105, 142.72628617286682, 147.12753701210022, 151.55579352378845, 155.9057228565216, 160.15880012512207, 164.5881450176239, 168.89415740966797, 173.25848817825317, 177.74000000953674, 182.3665006160736]
[25.2, 40.1, 53.3, 52.3, 54.5, 52.3, 55.5, 58.2, 57.3, 54.8, 57.8, 59.3, 60.9, 59.9, 62.7, 61.3, 60.5, 62.7, 62.3, 63.3, 64.4, 63.9, 64.5, 64.2, 60.7, 62.9, 61.8, 64.4, 60.8, 65.8, 64.3, 65.1, 63.9, 66.7, 65.4, 62.8, 65.3, 64.0, 65.6, 65.5, 66.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.620, Test loss: 1.704, Test accuracy: 25.50
Round   1, Train loss: 1.377, Test loss: 1.331, Test accuracy: 38.80
Round   2, Train loss: 1.254, Test loss: 1.186, Test accuracy: 46.10
Round   3, Train loss: 1.156, Test loss: 1.223, Test accuracy: 49.90
Round   4, Train loss: 1.082, Test loss: 1.082, Test accuracy: 54.60
Round   5, Train loss: 1.034, Test loss: 1.078, Test accuracy: 55.40
Round   6, Train loss: 0.978, Test loss: 1.095, Test accuracy: 56.10
Round   7, Train loss: 0.914, Test loss: 1.146, Test accuracy: 53.00
Round   8, Train loss: 0.860, Test loss: 1.174, Test accuracy: 55.40
Round   9, Train loss: 0.812, Test loss: 1.149, Test accuracy: 55.40
Round  10, Train loss: 0.761, Test loss: 1.046, Test accuracy: 60.30
Round  11, Train loss: 0.705, Test loss: 1.071, Test accuracy: 58.70
Round  12, Train loss: 0.646, Test loss: 1.059, Test accuracy: 61.10
Round  13, Train loss: 0.598, Test loss: 1.102, Test accuracy: 60.40
Round  14, Train loss: 0.559, Test loss: 1.171, Test accuracy: 58.90
Round  15, Train loss: 0.527, Test loss: 1.136, Test accuracy: 61.60
Round  16, Train loss: 0.482, Test loss: 1.170, Test accuracy: 59.60
Round  17, Train loss: 0.430, Test loss: 1.185, Test accuracy: 60.90
Round  18, Train loss: 0.405, Test loss: 1.149, Test accuracy: 63.70
Round  19, Train loss: 0.368, Test loss: 1.302, Test accuracy: 60.60
Round  20, Train loss: 0.332, Test loss: 1.181, Test accuracy: 60.70
Round  21, Train loss: 0.307, Test loss: 1.155, Test accuracy: 63.50
Round  22, Train loss: 0.277, Test loss: 1.144, Test accuracy: 64.20
Round  23, Train loss: 0.258, Test loss: 1.236, Test accuracy: 64.70
Round  24, Train loss: 0.221, Test loss: 1.222, Test accuracy: 64.70
Round  25, Train loss: 0.203, Test loss: 1.380, Test accuracy: 62.10
Round  26, Train loss: 0.186, Test loss: 1.382, Test accuracy: 63.80
Round  27, Train loss: 0.169, Test loss: 1.359, Test accuracy: 63.20
Round  28, Train loss: 0.169, Test loss: 1.350, Test accuracy: 64.70
Round  29, Train loss: 0.148, Test loss: 1.401, Test accuracy: 63.10
Round  30, Train loss: 0.159, Test loss: 1.285, Test accuracy: 65.20
Round  31, Train loss: 0.127, Test loss: 1.461, Test accuracy: 63.00
Round  32, Train loss: 0.138, Test loss: 1.434, Test accuracy: 64.10
Round  33, Train loss: 0.110, Test loss: 1.404, Test accuracy: 63.30
Round  34, Train loss: 0.106, Test loss: 1.544, Test accuracy: 63.60
Round  35, Train loss: 0.094, Test loss: 1.312, Test accuracy: 65.80
Round  36, Train loss: 0.070, Test loss: 1.425, Test accuracy: 64.70
Round  37, Train loss: 0.090, Test loss: 1.401, Test accuracy: 64.80
Round  38, Train loss: 0.068, Test loss: 1.569, Test accuracy: 63.50
Round  39, Train loss: 0.055, Test loss: 1.529, Test accuracy: 64.00
Final Round, Train loss: 0.034, Test loss: 1.525, Test accuracy: 65.00
Average accuracy final 10 rounds: 64.2
438.32997846603394
[7.046702861785889, 11.919309616088867, 16.923506498336792, 21.86390781402588, 26.77583384513855, 31.803359031677246, 36.9235098361969, 41.789698362350464, 46.69601225852966, 51.68848204612732, 56.986090421676636, 62.10119962692261, 67.13007164001465, 72.07491159439087, 77.04536581039429, 81.97872734069824, 86.92290139198303, 91.8828980922699, 96.93092012405396, 101.89432764053345, 106.8951907157898, 111.79030227661133, 116.87303161621094, 121.76422500610352, 126.68111252784729, 131.36587023735046, 136.15553045272827, 141.65013074874878, 146.58681511878967, 151.3119866847992, 156.08012413978577, 161.36542081832886, 166.6270067691803, 171.72357082366943, 176.7242522239685, 181.62366890907288, 186.81382703781128, 191.69827556610107, 196.7973952293396, 202.14020776748657, 207.41371750831604]
[25.5, 38.8, 46.1, 49.9, 54.6, 55.4, 56.1, 53.0, 55.4, 55.4, 60.3, 58.7, 61.1, 60.4, 58.9, 61.6, 59.6, 60.9, 63.7, 60.6, 60.7, 63.5, 64.2, 64.7, 64.7, 62.1, 63.8, 63.2, 64.7, 63.1, 65.2, 63.0, 64.1, 63.3, 63.6, 65.8, 64.7, 64.8, 63.5, 64.0, 65.0]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.456, Test loss: 1.295, Test accuracy: 52.00 

Round   0, Global train loss: 1.456, Global test loss: 1.553, Global test accuracy: 34.00 

Round   1, Train loss: 1.156, Test loss: 1.152, Test accuracy: 53.40 

Round   1, Global train loss: 1.156, Global test loss: 1.548, Global test accuracy: 29.70 

Round   2, Train loss: 0.995, Test loss: 1.124, Test accuracy: 58.70 

Round   2, Global train loss: 0.995, Global test loss: 1.628, Global test accuracy: 28.00 

Round   3, Train loss: 0.891, Test loss: 1.121, Test accuracy: 60.00 

Round   3, Global train loss: 0.891, Global test loss: 1.714, Global test accuracy: 25.80 

Round   4, Train loss: 0.761, Test loss: 1.163, Test accuracy: 60.70 

Round   4, Global train loss: 0.761, Global test loss: 1.871, Global test accuracy: 24.40 

Round   5, Train loss: 0.670, Test loss: 1.328, Test accuracy: 59.20 

Round   5, Global train loss: 0.670, Global test loss: 1.995, Global test accuracy: 22.00 

Round   6, Train loss: 0.559, Test loss: 1.286, Test accuracy: 62.10 

Round   6, Global train loss: 0.559, Global test loss: 1.848, Global test accuracy: 22.50 

Round   7, Train loss: 0.488, Test loss: 1.559, Test accuracy: 61.00 

Round   7, Global train loss: 0.488, Global test loss: 2.405, Global test accuracy: 20.10 

Round   8, Train loss: 0.410, Test loss: 1.497, Test accuracy: 61.70 

Round   8, Global train loss: 0.410, Global test loss: 2.220, Global test accuracy: 20.70 

Round   9, Train loss: 0.392, Test loss: 1.458, Test accuracy: 62.20 

Round   9, Global train loss: 0.392, Global test loss: 2.182, Global test accuracy: 20.90 

Round  10, Train loss: 0.305, Test loss: 1.568, Test accuracy: 60.70 

Round  10, Global train loss: 0.305, Global test loss: 2.438, Global test accuracy: 20.50 

Round  11, Train loss: 0.265, Test loss: 1.473, Test accuracy: 67.10 

Round  11, Global train loss: 0.265, Global test loss: 2.160, Global test accuracy: 21.20 

Round  12, Train loss: 0.230, Test loss: 1.711, Test accuracy: 63.30 

Round  12, Global train loss: 0.230, Global test loss: 2.143, Global test accuracy: 26.10 

Round  13, Train loss: 0.164, Test loss: 1.911, Test accuracy: 63.00 

Round  13, Global train loss: 0.164, Global test loss: 2.576, Global test accuracy: 22.40 

Round  14, Train loss: 0.180, Test loss: 1.684, Test accuracy: 63.10 

Round  14, Global train loss: 0.180, Global test loss: 2.477, Global test accuracy: 21.10 

Round  15, Train loss: 0.099, Test loss: 1.801, Test accuracy: 65.50 

Round  15, Global train loss: 0.099, Global test loss: 2.418, Global test accuracy: 21.20 

Round  16, Train loss: 0.130, Test loss: 1.877, Test accuracy: 64.20 

Round  16, Global train loss: 0.130, Global test loss: 2.365, Global test accuracy: 21.50 

Round  17, Train loss: 0.123, Test loss: 1.710, Test accuracy: 66.80 

Round  17, Global train loss: 0.123, Global test loss: 2.589, Global test accuracy: 20.40 

Round  18, Train loss: 0.098, Test loss: 1.615, Test accuracy: 66.50 

Round  18, Global train loss: 0.098, Global test loss: 2.310, Global test accuracy: 22.90 

Round  19, Train loss: 0.084, Test loss: 1.861, Test accuracy: 65.70 

Round  19, Global train loss: 0.084, Global test loss: 2.295, Global test accuracy: 21.50 

Round  20, Train loss: 0.084, Test loss: 1.988, Test accuracy: 65.90 

Round  20, Global train loss: 0.084, Global test loss: 2.341, Global test accuracy: 21.20 

Round  21, Train loss: 0.047, Test loss: 1.809, Test accuracy: 66.40 

Round  21, Global train loss: 0.047, Global test loss: 2.709, Global test accuracy: 20.70 

Round  22, Train loss: 0.065, Test loss: 1.796, Test accuracy: 65.70 

Round  22, Global train loss: 0.065, Global test loss: 2.227, Global test accuracy: 21.70 

Round  23, Train loss: 0.066, Test loss: 2.099, Test accuracy: 64.50 

Round  23, Global train loss: 0.066, Global test loss: 2.644, Global test accuracy: 21.60 

Round  24, Train loss: 0.074, Test loss: 1.688, Test accuracy: 68.10 

Round  24, Global train loss: 0.074, Global test loss: 2.682, Global test accuracy: 21.40 

Round  25, Train loss: 0.038, Test loss: 1.946, Test accuracy: 67.80 

Round  25, Global train loss: 0.038, Global test loss: 2.517, Global test accuracy: 20.80 

Round  26, Train loss: 0.039, Test loss: 1.693, Test accuracy: 69.00 

Round  26, Global train loss: 0.039, Global test loss: 2.510, Global test accuracy: 21.00 

Round  27, Train loss: 0.036, Test loss: 1.798, Test accuracy: 68.80 

Round  27, Global train loss: 0.036, Global test loss: 2.527, Global test accuracy: 21.50 

Round  28, Train loss: 0.021, Test loss: 1.795, Test accuracy: 68.80 

Round  28, Global train loss: 0.021, Global test loss: 2.541, Global test accuracy: 22.20 

Round  29, Train loss: 0.029, Test loss: 1.782, Test accuracy: 69.30 

Round  29, Global train loss: 0.029, Global test loss: 2.473, Global test accuracy: 22.00 

Round  30, Train loss: 0.028, Test loss: 1.746, Test accuracy: 70.70 

Round  30, Global train loss: 0.028, Global test loss: 2.654, Global test accuracy: 22.10 

Round  31, Train loss: 0.025, Test loss: 1.869, Test accuracy: 68.10 

Round  31, Global train loss: 0.025, Global test loss: 2.579, Global test accuracy: 21.70 

Round  32, Train loss: 0.036, Test loss: 2.016, Test accuracy: 67.90 

Round  32, Global train loss: 0.036, Global test loss: 2.665, Global test accuracy: 20.50 

Round  33, Train loss: 0.032, Test loss: 2.005, Test accuracy: 65.80 

Round  33, Global train loss: 0.032, Global test loss: 3.280, Global test accuracy: 20.00 

Round  34, Train loss: 0.028, Test loss: 1.875, Test accuracy: 67.50 

Round  34, Global train loss: 0.028, Global test loss: 2.775, Global test accuracy: 21.80 

Final Round, Train loss: 0.029, Test loss: 1.830, Test accuracy: 67.80 

Final Round, Global train loss: 0.029, Global test loss: 2.775, Global test accuracy: 21.80 

Average accuracy final 10 rounds: 68.37 

Average global accuracy final 10 rounds: 21.36 

468.7210204601288
[7.727784633636475, 13.225873708724976, 18.74658751487732, 24.444089651107788, 30.017760276794434, 35.36634683609009, 40.822014808654785, 46.4143488407135, 51.780349016189575, 57.371145248413086, 63.00629448890686, 68.56180906295776, 74.16934776306152, 79.75115180015564, 85.24267029762268, 90.87469482421875, 96.42900347709656, 102.10054755210876, 107.67023348808289, 113.2275984287262, 119.02094960212708, 124.95917105674744, 130.9815559387207, 136.7328395843506, 142.56321263313293, 148.2071990966797, 153.86069130897522, 159.61759161949158, 165.48923420906067, 171.155615568161, 176.97731375694275, 182.6455054283142, 188.12002825737, 193.7302589416504, 199.2639799118042, 211.53312730789185]
[52.0, 53.4, 58.7, 60.0, 60.7, 59.2, 62.1, 61.0, 61.7, 62.2, 60.7, 67.1, 63.3, 63.0, 63.1, 65.5, 64.2, 66.8, 66.5, 65.7, 65.9, 66.4, 65.7, 64.5, 68.1, 67.8, 69.0, 68.8, 68.8, 69.3, 70.7, 68.1, 67.9, 65.8, 67.5, 67.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.442, Test loss: 1.193, Test accuracy: 51.90 

Round   0, Global train loss: 1.442, Global test loss: 1.595, Global test accuracy: 32.40 

Round   1, Train loss: 1.249, Test loss: 1.112, Test accuracy: 57.60 

Round   1, Global train loss: 1.249, Global test loss: 1.426, Global test accuracy: 41.70 

Round   2, Train loss: 1.111, Test loss: 1.325, Test accuracy: 50.00 

Round   2, Global train loss: 1.111, Global test loss: 1.499, Global test accuracy: 39.00 

Round   3, Train loss: 1.026, Test loss: 1.375, Test accuracy: 51.80 

Round   3, Global train loss: 1.026, Global test loss: 1.501, Global test accuracy: 42.00 

Round   4, Train loss: 0.920, Test loss: 1.179, Test accuracy: 54.40 

Round   4, Global train loss: 0.920, Global test loss: 1.424, Global test accuracy: 44.90 

Round   5, Train loss: 0.796, Test loss: 1.256, Test accuracy: 59.90 

Round   5, Global train loss: 0.796, Global test loss: 1.629, Global test accuracy: 45.60 

Round   6, Train loss: 0.733, Test loss: 1.246, Test accuracy: 61.60 

Round   6, Global train loss: 0.733, Global test loss: 1.549, Global test accuracy: 46.60 

Round   7, Train loss: 0.683, Test loss: 1.254, Test accuracy: 59.80 

Round   7, Global train loss: 0.683, Global test loss: 1.597, Global test accuracy: 47.00 

Round   8, Train loss: 0.586, Test loss: 1.462, Test accuracy: 59.00 

Round   8, Global train loss: 0.586, Global test loss: 1.972, Global test accuracy: 45.10 

Round   9, Train loss: 0.522, Test loss: 1.607, Test accuracy: 57.00 

Round   9, Global train loss: 0.522, Global test loss: 1.864, Global test accuracy: 44.10 

Round  10, Train loss: 0.469, Test loss: 1.349, Test accuracy: 63.10 

Round  10, Global train loss: 0.469, Global test loss: 1.791, Global test accuracy: 46.80 

Round  11, Train loss: 0.440, Test loss: 1.482, Test accuracy: 62.40 

Round  11, Global train loss: 0.440, Global test loss: 1.858, Global test accuracy: 48.10 

Round  12, Train loss: 0.366, Test loss: 1.567, Test accuracy: 62.80 

Round  12, Global train loss: 0.366, Global test loss: 1.909, Global test accuracy: 47.20 

Round  13, Train loss: 0.332, Test loss: 1.516, Test accuracy: 64.40 

Round  13, Global train loss: 0.332, Global test loss: 1.928, Global test accuracy: 50.80 

Round  14, Train loss: 0.323, Test loss: 1.422, Test accuracy: 66.90 

Round  14, Global train loss: 0.323, Global test loss: 1.808, Global test accuracy: 50.90 

Round  15, Train loss: 0.261, Test loss: 1.899, Test accuracy: 59.40 

Round  15, Global train loss: 0.261, Global test loss: 1.947, Global test accuracy: 50.10 

Round  16, Train loss: 0.246, Test loss: 1.411, Test accuracy: 68.60 

Round  16, Global train loss: 0.246, Global test loss: 1.903, Global test accuracy: 52.50 

Round  17, Train loss: 0.236, Test loss: 1.503, Test accuracy: 65.30 

Round  17, Global train loss: 0.236, Global test loss: 1.933, Global test accuracy: 50.60 

Round  18, Train loss: 0.181, Test loss: 1.501, Test accuracy: 65.80 

Round  18, Global train loss: 0.181, Global test loss: 2.088, Global test accuracy: 49.00 

Round  19, Train loss: 0.150, Test loss: 1.578, Test accuracy: 66.40 

Round  19, Global train loss: 0.150, Global test loss: 1.968, Global test accuracy: 52.40 

Round  20, Train loss: 0.167, Test loss: 1.491, Test accuracy: 67.50 

Round  20, Global train loss: 0.167, Global test loss: 1.895, Global test accuracy: 51.80 

Round  21, Train loss: 0.135, Test loss: 1.496, Test accuracy: 67.80 

Round  21, Global train loss: 0.135, Global test loss: 2.129, Global test accuracy: 51.70 

Round  22, Train loss: 0.134, Test loss: 1.657, Test accuracy: 65.30 

Round  22, Global train loss: 0.134, Global test loss: 2.071, Global test accuracy: 50.40 

Round  23, Train loss: 0.082, Test loss: 1.650, Test accuracy: 66.40 

Round  23, Global train loss: 0.082, Global test loss: 2.273, Global test accuracy: 51.30 

Round  24, Train loss: 0.151, Test loss: 1.703, Test accuracy: 66.10 

Round  24, Global train loss: 0.151, Global test loss: 1.936, Global test accuracy: 54.30 

Round  25, Train loss: 0.074, Test loss: 1.619, Test accuracy: 66.80 

Round  25, Global train loss: 0.074, Global test loss: 2.079, Global test accuracy: 52.80 

Round  26, Train loss: 0.104, Test loss: 1.493, Test accuracy: 69.60 

Round  26, Global train loss: 0.104, Global test loss: 2.094, Global test accuracy: 52.50 

Round  27, Train loss: 0.094, Test loss: 1.625, Test accuracy: 67.00 

Round  27, Global train loss: 0.094, Global test loss: 2.071, Global test accuracy: 52.90 

Round  28, Train loss: 0.073, Test loss: 1.750, Test accuracy: 66.90 

Round  28, Global train loss: 0.073, Global test loss: 2.326, Global test accuracy: 53.00 

Round  29, Train loss: 0.085, Test loss: 1.645, Test accuracy: 66.10 

Round  29, Global train loss: 0.085, Global test loss: 2.129, Global test accuracy: 52.60 

Round  30, Train loss: 0.064, Test loss: 1.605, Test accuracy: 69.10 

Round  30, Global train loss: 0.064, Global test loss: 2.159, Global test accuracy: 55.20 

Round  31, Train loss: 0.076, Test loss: 1.826, Test accuracy: 64.90 

Round  31, Global train loss: 0.076, Global test loss: 2.320, Global test accuracy: 53.10 

Round  32, Train loss: 0.057, Test loss: 1.589, Test accuracy: 67.20 

Round  32, Global train loss: 0.057, Global test loss: 2.288, Global test accuracy: 53.80 

Round  33, Train loss: 0.050, Test loss: 1.818, Test accuracy: 65.20 

Round  33, Global train loss: 0.050, Global test loss: 2.519, Global test accuracy: 51.90 

Round  34, Train loss: 0.044, Test loss: 1.638, Test accuracy: 67.90 

Round  34, Global train loss: 0.044, Global test loss: 2.265, Global test accuracy: 54.00 

Final Round, Train loss: 0.072, Test loss: 1.600, Test accuracy: 68.20 

Final Round, Global train loss: 0.072, Global test loss: 2.265, Global test accuracy: 54.00 

Average accuracy final 10 rounds: 67.07000000000001 

Average global accuracy final 10 rounds: 53.18 

470.04843759536743
[7.871678829193115, 13.532474994659424, 19.358864784240723, 25.022258520126343, 30.734190464019775, 36.173001527786255, 41.74132037162781, 47.6900475025177, 53.20534706115723, 58.67297959327698, 64.31625127792358, 69.96672487258911, 75.62761855125427, 81.1351387500763, 86.60177993774414, 92.27171039581299, 98.0522849559784, 103.63553643226624, 109.12437963485718, 114.80654692649841, 120.78201508522034, 126.40125513076782, 132.1102135181427, 137.73555994033813, 143.5081832408905, 149.16861581802368, 154.85792136192322, 160.5361099243164, 166.31093978881836, 171.94918704032898, 177.41299748420715, 183.43768692016602, 189.24044799804688, 194.94173312187195, 200.53561878204346, 211.6330225467682]
[51.9, 57.6, 50.0, 51.8, 54.4, 59.9, 61.6, 59.8, 59.0, 57.0, 63.1, 62.4, 62.8, 64.4, 66.9, 59.4, 68.6, 65.3, 65.8, 66.4, 67.5, 67.8, 65.3, 66.4, 66.1, 66.8, 69.6, 67.0, 66.9, 66.1, 69.1, 64.9, 67.2, 65.2, 67.9, 68.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.548, Test loss: 1.714, Test accuracy: 25.80 

Round   1, Train loss: 1.334, Test loss: 1.385, Test accuracy: 40.90 

Round   2, Train loss: 1.181, Test loss: 1.187, Test accuracy: 49.80 

Round   3, Train loss: 1.092, Test loss: 1.061, Test accuracy: 57.30 

Round   4, Train loss: 0.987, Test loss: 1.007, Test accuracy: 57.00 

Round   5, Train loss: 0.923, Test loss: 0.995, Test accuracy: 58.60 

Round   6, Train loss: 0.862, Test loss: 1.020, Test accuracy: 59.90 

Round   7, Train loss: 0.794, Test loss: 1.059, Test accuracy: 59.60 

Round   8, Train loss: 0.735, Test loss: 1.023, Test accuracy: 64.00 

Round   9, Train loss: 0.657, Test loss: 0.960, Test accuracy: 63.80 

Round  10, Train loss: 0.603, Test loss: 1.042, Test accuracy: 63.80 

Round  11, Train loss: 0.565, Test loss: 1.123, Test accuracy: 61.80 

Round  12, Train loss: 0.529, Test loss: 1.053, Test accuracy: 63.40 

Round  13, Train loss: 0.467, Test loss: 1.159, Test accuracy: 62.20 

Round  14, Train loss: 0.428, Test loss: 1.205, Test accuracy: 59.90 

Round  15, Train loss: 0.380, Test loss: 1.035, Test accuracy: 66.60 

Round  16, Train loss: 0.343, Test loss: 0.967, Test accuracy: 68.20 

Round  17, Train loss: 0.329, Test loss: 1.088, Test accuracy: 67.20 

Round  18, Train loss: 0.291, Test loss: 1.149, Test accuracy: 64.70 

Round  19, Train loss: 0.243, Test loss: 1.061, Test accuracy: 68.20 

Round  20, Train loss: 0.243, Test loss: 1.144, Test accuracy: 66.20 

Round  21, Train loss: 0.201, Test loss: 1.055, Test accuracy: 68.00 

Round  22, Train loss: 0.200, Test loss: 1.165, Test accuracy: 67.20 

Round  23, Train loss: 0.187, Test loss: 1.220, Test accuracy: 67.40 

Round  24, Train loss: 0.197, Test loss: 1.333, Test accuracy: 67.20 

Round  25, Train loss: 0.137, Test loss: 1.192, Test accuracy: 68.80 

Round  26, Train loss: 0.141, Test loss: 1.181, Test accuracy: 68.00 

Round  27, Train loss: 0.129, Test loss: 1.381, Test accuracy: 66.90 

Round  28, Train loss: 0.129, Test loss: 1.249, Test accuracy: 68.50 

Round  29, Train loss: 0.087, Test loss: 1.255, Test accuracy: 68.30 

Round  30, Train loss: 0.103, Test loss: 1.294, Test accuracy: 67.80 

Round  31, Train loss: 0.085, Test loss: 1.303, Test accuracy: 68.20 

Round  32, Train loss: 0.083, Test loss: 1.310, Test accuracy: 66.40 

Round  33, Train loss: 0.069, Test loss: 1.305, Test accuracy: 69.30 

Round  34, Train loss: 0.079, Test loss: 1.286, Test accuracy: 69.40 

Round  35, Train loss: 0.057, Test loss: 1.369, Test accuracy: 67.20 

Round  36, Train loss: 0.063, Test loss: 1.379, Test accuracy: 68.20 

Round  37, Train loss: 0.063, Test loss: 1.349, Test accuracy: 69.30 

Round  38, Train loss: 0.058, Test loss: 1.460, Test accuracy: 65.70 

Round  39, Train loss: 0.050, Test loss: 1.447, Test accuracy: 68.90 

Final Round, Train loss: 0.030, Test loss: 1.403, Test accuracy: 69.40 

Average accuracy final 10 rounds: 68.03999999999999 

391.3818233013153
[6.300947427749634, 10.790224075317383, 15.18413496017456, 19.533595323562622, 23.892860412597656, 28.288763999938965, 32.697075843811035, 36.87353301048279, 41.44834899902344, 45.68374705314636, 50.264667987823486, 54.55564522743225, 59.11910581588745, 63.574644804000854, 67.94927787780762, 72.28735089302063, 76.88751697540283, 81.27243065834045, 85.68151497840881, 90.00618624687195, 94.60687184333801, 99.07331609725952, 103.47710108757019, 107.96989274024963, 112.32422113418579, 116.6882712841034, 121.34418749809265, 125.47412657737732, 129.95989727973938, 134.3707537651062, 138.8106598854065, 143.27814722061157, 147.63342952728271, 152.11280798912048, 156.69242310523987, 161.3306782245636, 165.70790815353394, 170.12563490867615, 174.42497086524963, 178.82342624664307, 183.91781067848206]
[25.8, 40.9, 49.8, 57.3, 57.0, 58.6, 59.9, 59.6, 64.0, 63.8, 63.8, 61.8, 63.4, 62.2, 59.9, 66.6, 68.2, 67.2, 64.7, 68.2, 66.2, 68.0, 67.2, 67.4, 67.2, 68.8, 68.0, 66.9, 68.5, 68.3, 67.8, 68.2, 66.4, 69.3, 69.4, 67.2, 68.2, 69.3, 65.7, 68.9, 69.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.552, Test loss: 1.581, Test accuracy: 31.80
Round   1, Train loss: 1.348, Test loss: 1.227, Test accuracy: 46.20
Round   2, Train loss: 1.207, Test loss: 1.114, Test accuracy: 52.60
Round   3, Train loss: 1.148, Test loss: 1.092, Test accuracy: 56.90
Round   4, Train loss: 1.039, Test loss: 1.387, Test accuracy: 47.80
Round   5, Train loss: 0.965, Test loss: 1.173, Test accuracy: 53.90
Round   6, Train loss: 0.885, Test loss: 0.989, Test accuracy: 60.10
Round   7, Train loss: 0.798, Test loss: 0.993, Test accuracy: 62.60
Round   8, Train loss: 0.766, Test loss: 1.006, Test accuracy: 62.20
Round   9, Train loss: 0.698, Test loss: 0.992, Test accuracy: 62.20
Round  10, Train loss: 0.644, Test loss: 1.031, Test accuracy: 63.70
Round  11, Train loss: 0.615, Test loss: 0.982, Test accuracy: 65.60
Round  12, Train loss: 0.561, Test loss: 1.011, Test accuracy: 64.70
Round  13, Train loss: 0.493, Test loss: 1.037, Test accuracy: 64.30
Round  14, Train loss: 0.457, Test loss: 1.028, Test accuracy: 68.00
Round  15, Train loss: 0.417, Test loss: 1.160, Test accuracy: 64.30
Round  16, Train loss: 0.387, Test loss: 1.066, Test accuracy: 65.60
Round  17, Train loss: 0.335, Test loss: 1.129, Test accuracy: 63.50
Round  18, Train loss: 0.336, Test loss: 1.095, Test accuracy: 66.20
Round  19, Train loss: 0.288, Test loss: 1.300, Test accuracy: 62.30
Round  20, Train loss: 0.274, Test loss: 1.166, Test accuracy: 67.20
Round  21, Train loss: 0.242, Test loss: 1.221, Test accuracy: 64.70
Round  22, Train loss: 0.222, Test loss: 1.215, Test accuracy: 66.50
Round  23, Train loss: 0.198, Test loss: 1.211, Test accuracy: 66.80
Round  24, Train loss: 0.197, Test loss: 1.274, Test accuracy: 64.00
Round  25, Train loss: 0.164, Test loss: 1.263, Test accuracy: 67.50
Round  26, Train loss: 0.167, Test loss: 1.284, Test accuracy: 67.10
Round  27, Train loss: 0.141, Test loss: 1.184, Test accuracy: 67.60
Round  28, Train loss: 0.116, Test loss: 1.248, Test accuracy: 69.40
Round  29, Train loss: 0.097, Test loss: 1.343, Test accuracy: 67.30
Round  30, Train loss: 0.097, Test loss: 1.392, Test accuracy: 65.90
Round  31, Train loss: 0.108, Test loss: 1.341, Test accuracy: 67.00
Round  32, Train loss: 0.102, Test loss: 1.352, Test accuracy: 68.60
Round  33, Train loss: 0.072, Test loss: 1.347, Test accuracy: 67.30
Round  34, Train loss: 0.072, Test loss: 1.334, Test accuracy: 67.10
Round  35, Train loss: 0.086, Test loss: 1.313, Test accuracy: 67.90
Round  36, Train loss: 0.066, Test loss: 1.312, Test accuracy: 68.60
Round  37, Train loss: 0.073, Test loss: 1.385, Test accuracy: 67.80
Round  38, Train loss: 0.050, Test loss: 1.425, Test accuracy: 68.10
Round  39, Train loss: 0.057, Test loss: 1.325, Test accuracy: 68.40
Final Round, Train loss: 0.041, Test loss: 1.339, Test accuracy: 69.20
Average accuracy final 10 rounds: 67.67
440.24941301345825
[6.976335287094116, 11.757808685302734, 16.90972089767456, 21.74674105644226, 26.504419565200806, 31.56689739227295, 36.39856743812561, 41.70645236968994, 46.81460881233215, 51.96877145767212, 57.20673441886902, 62.58037614822388, 67.75762701034546, 72.8250663280487, 77.79200792312622, 83.53198337554932, 88.38022470474243, 93.52466940879822, 98.38996696472168, 103.16849088668823, 108.24196434020996, 113.34383153915405, 118.36774516105652, 123.35630083084106, 128.10948300361633, 133.0767526626587, 138.19916248321533, 143.1371054649353, 148.07359051704407, 153.1075315475464, 157.9621832370758, 163.0495879650116, 168.1572597026825, 173.06313514709473, 178.09720754623413, 182.9563045501709, 188.3283121585846, 193.35973930358887, 198.5035264492035, 203.58964037895203, 209.07898950576782]
[31.8, 46.2, 52.6, 56.9, 47.8, 53.9, 60.1, 62.6, 62.2, 62.2, 63.7, 65.6, 64.7, 64.3, 68.0, 64.3, 65.6, 63.5, 66.2, 62.3, 67.2, 64.7, 66.5, 66.8, 64.0, 67.5, 67.1, 67.6, 69.4, 67.3, 65.9, 67.0, 68.6, 67.3, 67.1, 67.9, 68.6, 67.8, 68.1, 68.4, 69.2]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
./start_train: 第 48 行:printf: --: 无效选项
printf: 用法:printf [-v var] 格式 [参数]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.443, Test loss: 1.397, Test accuracy: 49.92 

Round   0, Global train loss: 1.443, Global test loss: 2.128, Global test accuracy: 26.86 

Round   1, Train loss: 1.124, Test loss: 1.343, Test accuracy: 52.70 

Round   1, Global train loss: 1.124, Global test loss: 2.192, Global test accuracy: 23.46 

Round   2, Train loss: 0.966, Test loss: 1.365, Test accuracy: 55.88 

Round   2, Global train loss: 0.966, Global test loss: 2.273, Global test accuracy: 24.06 

Round   3, Train loss: 0.849, Test loss: 1.257, Test accuracy: 57.70 

Round   3, Global train loss: 0.849, Global test loss: 2.164, Global test accuracy: 27.78 

Round   4, Train loss: 0.734, Test loss: 1.209, Test accuracy: 60.72 

Round   4, Global train loss: 0.734, Global test loss: 2.170, Global test accuracy: 28.64 

Round   5, Train loss: 0.631, Test loss: 1.349, Test accuracy: 59.06 

Round   5, Global train loss: 0.631, Global test loss: 2.224, Global test accuracy: 26.54 

Round   6, Train loss: 0.533, Test loss: 1.363, Test accuracy: 61.96 

Round   6, Global train loss: 0.533, Global test loss: 2.271, Global test accuracy: 24.34 

Round   7, Train loss: 0.460, Test loss: 1.645, Test accuracy: 58.36 

Round   7, Global train loss: 0.460, Global test loss: 2.232, Global test accuracy: 22.38 

Round   8, Train loss: 0.400, Test loss: 1.664, Test accuracy: 58.48 

Round   8, Global train loss: 0.400, Global test loss: 2.324, Global test accuracy: 26.06 

Round   9, Train loss: 0.320, Test loss: 1.627, Test accuracy: 60.48 

Round   9, Global train loss: 0.320, Global test loss: 2.321, Global test accuracy: 22.92 

Round  10, Train loss: 0.290, Test loss: 1.543, Test accuracy: 62.80 

Round  10, Global train loss: 0.290, Global test loss: 2.416, Global test accuracy: 22.24 

Round  11, Train loss: 0.260, Test loss: 1.609, Test accuracy: 63.00 

Round  11, Global train loss: 0.260, Global test loss: 2.473, Global test accuracy: 24.64 

Round  12, Train loss: 0.219, Test loss: 1.726, Test accuracy: 61.94 

Round  12, Global train loss: 0.219, Global test loss: 2.421, Global test accuracy: 24.76 

Round  13, Train loss: 0.182, Test loss: 1.737, Test accuracy: 62.72 

Round  13, Global train loss: 0.182, Global test loss: 2.381, Global test accuracy: 24.10 

Round  14, Train loss: 0.158, Test loss: 1.675, Test accuracy: 64.68 

Round  14, Global train loss: 0.158, Global test loss: 2.454, Global test accuracy: 22.88 

Round  15, Train loss: 0.143, Test loss: 1.804, Test accuracy: 63.36 

Round  15, Global train loss: 0.143, Global test loss: 2.478, Global test accuracy: 22.12 

Round  16, Train loss: 0.129, Test loss: 1.817, Test accuracy: 63.40 

Round  16, Global train loss: 0.129, Global test loss: 2.459, Global test accuracy: 22.48 

Round  17, Train loss: 0.118, Test loss: 1.846, Test accuracy: 64.20 

Round  17, Global train loss: 0.118, Global test loss: 2.379, Global test accuracy: 23.44 

Round  18, Train loss: 0.088, Test loss: 1.945, Test accuracy: 63.34 

Round  18, Global train loss: 0.088, Global test loss: 2.402, Global test accuracy: 21.98 

Round  19, Train loss: 0.091, Test loss: 1.902, Test accuracy: 63.32 

Round  19, Global train loss: 0.091, Global test loss: 2.554, Global test accuracy: 21.92 

Round  20, Train loss: 0.090, Test loss: 1.907, Test accuracy: 64.26 

Round  20, Global train loss: 0.090, Global test loss: 2.412, Global test accuracy: 22.70 

Round  21, Train loss: 0.059, Test loss: 2.015, Test accuracy: 63.70 

Round  21, Global train loss: 0.059, Global test loss: 2.483, Global test accuracy: 21.16 

Round  22, Train loss: 0.084, Test loss: 1.875, Test accuracy: 65.68 

Round  22, Global train loss: 0.084, Global test loss: 2.486, Global test accuracy: 25.66 

Round  23, Train loss: 0.065, Test loss: 1.864, Test accuracy: 65.42 

Round  23, Global train loss: 0.065, Global test loss: 2.539, Global test accuracy: 23.78 

Round  24, Train loss: 0.053, Test loss: 2.013, Test accuracy: 64.40 

Round  24, Global train loss: 0.053, Global test loss: 2.500, Global test accuracy: 23.72 

Round  25, Train loss: 0.044, Test loss: 1.958, Test accuracy: 64.80 

Round  25, Global train loss: 0.044, Global test loss: 2.513, Global test accuracy: 23.14 

Round  26, Train loss: 0.044, Test loss: 1.857, Test accuracy: 65.74 

Round  26, Global train loss: 0.044, Global test loss: 2.496, Global test accuracy: 23.58 

Round  27, Train loss: 0.050, Test loss: 2.073, Test accuracy: 64.10 

Round  27, Global train loss: 0.050, Global test loss: 2.535, Global test accuracy: 23.08 

Round  28, Train loss: 0.038, Test loss: 1.942, Test accuracy: 65.12 

Round  28, Global train loss: 0.038, Global test loss: 2.469, Global test accuracy: 24.50 

Round  29, Train loss: 0.035, Test loss: 1.891, Test accuracy: 65.70 

Round  29, Global train loss: 0.035, Global test loss: 2.512, Global test accuracy: 25.18 

Round  30, Train loss: 0.032, Test loss: 2.044, Test accuracy: 64.22 

Round  30, Global train loss: 0.032, Global test loss: 2.469, Global test accuracy: 22.86 

Round  31, Train loss: 0.034, Test loss: 2.099, Test accuracy: 64.86 

Round  31, Global train loss: 0.034, Global test loss: 2.501, Global test accuracy: 23.98 

Round  32, Train loss: 0.024, Test loss: 2.022, Test accuracy: 64.92 

Round  32, Global train loss: 0.024, Global test loss: 2.515, Global test accuracy: 23.92 

Round  33, Train loss: 0.025, Test loss: 2.003, Test accuracy: 65.62 

Round  33, Global train loss: 0.025, Global test loss: 2.539, Global test accuracy: 23.18 

Round  34, Train loss: 0.028, Test loss: 2.089, Test accuracy: 64.16 

Round  34, Global train loss: 0.028, Global test loss: 2.578, Global test accuracy: 25.20 

Final Round, Train loss: 0.027, Test loss: 2.064, Test accuracy: 64.78 

Final Round, Global train loss: 0.027, Global test loss: 2.578, Global test accuracy: 25.20 

Average accuracy final 10 rounds: 64.92399999999999 

Average global accuracy final 10 rounds: 23.862000000000002 

1290.5224423408508
[8.196947574615479, 13.921169757843018, 19.906744956970215, 25.597771644592285, 31.340524435043335, 37.14502930641174, 43.45921063423157, 49.382933378219604, 55.23623561859131, 60.934656381607056, 66.80631709098816, 72.55468964576721, 78.32357692718506, 84.05453586578369, 89.85778784751892, 95.70418238639832, 101.40614151954651, 107.26847219467163, 112.88937664031982, 119.2051146030426, 124.97114753723145, 130.65436959266663, 136.3073046207428, 142.0854594707489, 148.27200841903687, 154.02946710586548, 159.86354446411133, 165.5495092868805, 171.3261866569519, 177.41255521774292, 183.0675802230835, 188.7923707962036, 194.594979763031, 200.2750380039215, 206.0399067401886, 217.6084713935852]
[49.92, 52.7, 55.88, 57.7, 60.72, 59.06, 61.96, 58.36, 58.48, 60.48, 62.8, 63.0, 61.94, 62.72, 64.68, 63.36, 63.4, 64.2, 63.34, 63.32, 64.26, 63.7, 65.68, 65.42, 64.4, 64.8, 65.74, 64.1, 65.12, 65.7, 64.22, 64.86, 64.92, 65.62, 64.16, 64.78]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.458, Test loss: 1.716, Test accuracy: 47.34 

Round   0, Global train loss: 1.458, Global test loss: 2.151, Global test accuracy: 20.54 

Round   1, Train loss: 1.322, Test loss: 1.344, Test accuracy: 51.94 

Round   1, Global train loss: 1.322, Global test loss: 1.723, Global test accuracy: 44.98 

Round   2, Train loss: 1.202, Test loss: 1.064, Test accuracy: 58.50 

Round   2, Global train loss: 1.202, Global test loss: 1.677, Global test accuracy: 46.00 

Round   3, Train loss: 1.078, Test loss: 1.043, Test accuracy: 59.76 

Round   3, Global train loss: 1.078, Global test loss: 1.693, Global test accuracy: 47.10 

Round   4, Train loss: 0.995, Test loss: 1.372, Test accuracy: 54.78 

Round   4, Global train loss: 0.995, Global test loss: 1.648, Global test accuracy: 47.50 

Round   5, Train loss: 0.941, Test loss: 1.115, Test accuracy: 60.46 

Round   5, Global train loss: 0.941, Global test loss: 1.632, Global test accuracy: 48.68 

Round   6, Train loss: 0.873, Test loss: 1.097, Test accuracy: 62.12 

Round   6, Global train loss: 0.873, Global test loss: 1.497, Global test accuracy: 51.04 

Round   7, Train loss: 0.808, Test loss: 1.295, Test accuracy: 58.02 

Round   7, Global train loss: 0.808, Global test loss: 1.573, Global test accuracy: 50.72 

Round   8, Train loss: 0.757, Test loss: 1.082, Test accuracy: 63.22 

Round   8, Global train loss: 0.757, Global test loss: 1.471, Global test accuracy: 52.12 

Round   9, Train loss: 0.694, Test loss: 1.178, Test accuracy: 62.16 

Round   9, Global train loss: 0.694, Global test loss: 1.449, Global test accuracy: 52.60 

Round  10, Train loss: 0.663, Test loss: 1.126, Test accuracy: 63.64 

Round  10, Global train loss: 0.663, Global test loss: 1.453, Global test accuracy: 54.48 

Round  11, Train loss: 0.617, Test loss: 0.980, Test accuracy: 68.32 

Round  11, Global train loss: 0.617, Global test loss: 1.363, Global test accuracy: 55.34 

Round  12, Train loss: 0.572, Test loss: 1.178, Test accuracy: 64.10 

Round  12, Global train loss: 0.572, Global test loss: 1.365, Global test accuracy: 55.88 

Round  13, Train loss: 0.539, Test loss: 1.050, Test accuracy: 67.48 

Round  13, Global train loss: 0.539, Global test loss: 1.328, Global test accuracy: 57.68 

Round  14, Train loss: 0.504, Test loss: 1.208, Test accuracy: 65.66 

Round  14, Global train loss: 0.504, Global test loss: 1.383, Global test accuracy: 56.92 

Round  15, Train loss: 0.484, Test loss: 1.153, Test accuracy: 67.26 

Round  15, Global train loss: 0.484, Global test loss: 1.476, Global test accuracy: 55.98 

Round  16, Train loss: 0.446, Test loss: 1.096, Test accuracy: 68.00 

Round  16, Global train loss: 0.446, Global test loss: 1.396, Global test accuracy: 57.60 

Round  17, Train loss: 0.417, Test loss: 1.171, Test accuracy: 67.86 

Round  17, Global train loss: 0.417, Global test loss: 1.295, Global test accuracy: 59.52 

Round  18, Train loss: 0.384, Test loss: 1.088, Test accuracy: 69.06 

Round  18, Global train loss: 0.384, Global test loss: 1.314, Global test accuracy: 59.16 

Round  19, Train loss: 0.361, Test loss: 1.245, Test accuracy: 66.98 

Round  19, Global train loss: 0.361, Global test loss: 1.332, Global test accuracy: 59.64 

Round  20, Train loss: 0.345, Test loss: 1.220, Test accuracy: 67.38 

Round  20, Global train loss: 0.345, Global test loss: 1.326, Global test accuracy: 59.56 

Round  21, Train loss: 0.326, Test loss: 1.218, Test accuracy: 68.42 

Round  21, Global train loss: 0.326, Global test loss: 1.417, Global test accuracy: 59.26 

Round  22, Train loss: 0.302, Test loss: 1.211, Test accuracy: 69.38 

Round  22, Global train loss: 0.302, Global test loss: 1.404, Global test accuracy: 59.74 

Round  23, Train loss: 0.281, Test loss: 1.109, Test accuracy: 70.84 

Round  23, Global train loss: 0.281, Global test loss: 1.343, Global test accuracy: 60.84 

Round  24, Train loss: 0.259, Test loss: 1.227, Test accuracy: 69.10 

Round  24, Global train loss: 0.259, Global test loss: 1.379, Global test accuracy: 60.78 

Round  25, Train loss: 0.260, Test loss: 1.161, Test accuracy: 71.22 

Round  25, Global train loss: 0.260, Global test loss: 1.284, Global test accuracy: 62.30 

Round  26, Train loss: 0.235, Test loss: 1.317, Test accuracy: 69.44 

Round  26, Global train loss: 0.235, Global test loss: 1.319, Global test accuracy: 62.34 

Round  27, Train loss: 0.222, Test loss: 1.277, Test accuracy: 70.04 

Round  27, Global train loss: 0.222, Global test loss: 1.254, Global test accuracy: 62.90 

Round  28, Train loss: 0.190, Test loss: 1.297, Test accuracy: 70.44 

Round  28, Global train loss: 0.190, Global test loss: 1.337, Global test accuracy: 62.68 

Round  29, Train loss: 0.203, Test loss: 1.421, Test accuracy: 70.40 

Round  29, Global train loss: 0.203, Global test loss: 1.195, Global test accuracy: 65.24 

Round  30, Train loss: 0.170, Test loss: 1.322, Test accuracy: 70.28 

Round  30, Global train loss: 0.170, Global test loss: 1.359, Global test accuracy: 63.24 

Round  31, Train loss: 0.196, Test loss: 1.219, Test accuracy: 71.22 

Round  31, Global train loss: 0.196, Global test loss: 1.319, Global test accuracy: 63.26 

Round  32, Train loss: 0.155, Test loss: 1.450, Test accuracy: 69.26 

Round  32, Global train loss: 0.155, Global test loss: 1.326, Global test accuracy: 64.30 

Round  33, Train loss: 0.149, Test loss: 1.208, Test accuracy: 71.90 

Round  33, Global train loss: 0.149, Global test loss: 1.337, Global test accuracy: 64.10 

Round  34, Train loss: 0.132, Test loss: 1.242, Test accuracy: 72.50 

Round  34, Global train loss: 0.132, Global test loss: 1.319, Global test accuracy: 64.50 

Round  35, Train loss: 0.139, Test loss: 1.329, Test accuracy: 70.30 

Round  35, Global train loss: 0.139, Global test loss: 1.361, Global test accuracy: 63.80 

Round  36, Train loss: 0.124, Test loss: 1.477, Test accuracy: 70.80 

Round  36, Global train loss: 0.124, Global test loss: 1.335, Global test accuracy: 65.14 

Round  37, Train loss: 0.146, Test loss: 1.335, Test accuracy: 70.04 

Round  37, Global train loss: 0.146, Global test loss: 1.336, Global test accuracy: 63.66 

Round  38, Train loss: 0.116, Test loss: 1.176, Test accuracy: 73.00 

Round  38, Global train loss: 0.116, Global test loss: 1.365, Global test accuracy: 64.94 

Round  39, Train loss: 0.099, Test loss: 1.384, Test accuracy: 72.10 

Round  39, Global train loss: 0.099, Global test loss: 1.417, Global test accuracy: 65.16 

Round  40, Train loss: 0.115, Test loss: 1.386, Test accuracy: 71.18 

Round  40, Global train loss: 0.115, Global test loss: 1.303, Global test accuracy: 65.90 

Round  41, Train loss: 0.102, Test loss: 1.239, Test accuracy: 73.22 

Round  41, Global train loss: 0.102, Global test loss: 1.295, Global test accuracy: 66.16 

Round  42, Train loss: 0.089, Test loss: 1.404, Test accuracy: 71.30 

Round  42, Global train loss: 0.089, Global test loss: 1.257, Global test accuracy: 66.44 

Round  43, Train loss: 0.065, Test loss: 1.285, Test accuracy: 72.92 

Round  43, Global train loss: 0.065, Global test loss: 1.312, Global test accuracy: 66.56 

Round  44, Train loss: 0.092, Test loss: 1.413, Test accuracy: 71.10 

Round  44, Global train loss: 0.092, Global test loss: 1.317, Global test accuracy: 65.78 

Round  45, Train loss: 0.102, Test loss: 1.458, Test accuracy: 70.32 

Round  45, Global train loss: 0.102, Global test loss: 1.387, Global test accuracy: 64.92 

Round  46, Train loss: 0.086, Test loss: 1.421, Test accuracy: 70.84 

Round  46, Global train loss: 0.086, Global test loss: 1.397, Global test accuracy: 65.44 

Round  47, Train loss: 0.079, Test loss: 1.278, Test accuracy: 73.64 

Round  47, Global train loss: 0.079, Global test loss: 1.385, Global test accuracy: 65.54 

Round  48, Train loss: 0.049, Test loss: 1.190, Test accuracy: 74.16 

Round  48, Global train loss: 0.049, Global test loss: 1.289, Global test accuracy: 67.28 

Round  49, Train loss: 0.072, Test loss: 1.338, Test accuracy: 72.90 

Round  49, Global train loss: 0.072, Global test loss: 1.419, Global test accuracy: 65.74 

Final Round, Train loss: 0.066, Test loss: 1.289, Test accuracy: 74.30 

Final Round, Global train loss: 0.066, Global test loss: 1.419, Global test accuracy: 65.74 

Average accuracy final 10 rounds: 72.158 

Average global accuracy final 10 rounds: 65.976 

1793.3802711963654
[7.94023871421814, 13.706465482711792, 19.426898956298828, 25.135950565338135, 30.685354709625244, 36.78406262397766, 42.53723382949829, 48.11608290672302, 53.77113890647888, 59.77181816101074, 65.49772357940674, 71.26920294761658, 76.92768979072571, 82.4771614074707, 88.1147186756134, 94.03189635276794, 99.7248785495758, 105.29593086242676, 110.99048972129822, 116.75701594352722, 122.34850358963013, 127.8763678073883, 133.75966477394104, 139.39757180213928, 145.06219148635864, 150.77924489974976, 156.5810730457306, 162.35839533805847, 167.98695588111877, 173.523264169693, 179.4288728237152, 185.4985113143921, 191.297771692276, 197.13542795181274, 202.70444536209106, 208.49923276901245, 214.24904012680054, 219.86217546463013, 225.51062273979187, 231.28011655807495, 237.1194076538086, 242.8788764476776, 248.57249450683594, 254.336275100708, 260.0691683292389, 265.6852502822876, 271.4983787536621, 277.4779918193817, 283.23027443885803, 288.84961891174316, 300.1691007614136]
[47.34, 51.94, 58.5, 59.76, 54.78, 60.46, 62.12, 58.02, 63.22, 62.16, 63.64, 68.32, 64.1, 67.48, 65.66, 67.26, 68.0, 67.86, 69.06, 66.98, 67.38, 68.42, 69.38, 70.84, 69.1, 71.22, 69.44, 70.04, 70.44, 70.4, 70.28, 71.22, 69.26, 71.9, 72.5, 70.3, 70.8, 70.04, 73.0, 72.1, 71.18, 73.22, 71.3, 72.92, 71.1, 70.32, 70.84, 73.64, 74.16, 72.9, 74.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.536, Test loss: 1.830, Test accuracy: 25.46 

Round   1, Train loss: 1.340, Test loss: 1.381, Test accuracy: 42.76 

Round   2, Train loss: 1.231, Test loss: 1.156, Test accuracy: 51.24 

Round   3, Train loss: 1.133, Test loss: 1.276, Test accuracy: 49.64 

Round   4, Train loss: 1.059, Test loss: 1.068, Test accuracy: 56.34 

Round   5, Train loss: 1.003, Test loss: 1.103, Test accuracy: 55.54 

Round   6, Train loss: 0.938, Test loss: 0.922, Test accuracy: 61.70 

Round   7, Train loss: 0.887, Test loss: 0.991, Test accuracy: 61.04 

Round   8, Train loss: 0.842, Test loss: 0.898, Test accuracy: 64.30 

Round   9, Train loss: 0.807, Test loss: 0.903, Test accuracy: 64.92 

Round  10, Train loss: 0.769, Test loss: 0.870, Test accuracy: 66.82 

Round  11, Train loss: 0.715, Test loss: 0.899, Test accuracy: 65.64 

Round  12, Train loss: 0.688, Test loss: 0.870, Test accuracy: 66.60 

Round  13, Train loss: 0.649, Test loss: 0.826, Test accuracy: 68.04 

Round  14, Train loss: 0.621, Test loss: 0.806, Test accuracy: 69.60 

Round  15, Train loss: 0.588, Test loss: 0.800, Test accuracy: 70.06 

Round  16, Train loss: 0.564, Test loss: 0.819, Test accuracy: 69.78 

Round  17, Train loss: 0.527, Test loss: 0.808, Test accuracy: 69.98 

Round  18, Train loss: 0.509, Test loss: 0.807, Test accuracy: 70.22 

Round  19, Train loss: 0.475, Test loss: 0.797, Test accuracy: 70.94 

Round  20, Train loss: 0.442, Test loss: 0.761, Test accuracy: 72.36 

Round  21, Train loss: 0.432, Test loss: 0.775, Test accuracy: 72.42 

Round  22, Train loss: 0.411, Test loss: 0.852, Test accuracy: 71.16 

Round  23, Train loss: 0.384, Test loss: 0.803, Test accuracy: 72.34 

Round  24, Train loss: 0.352, Test loss: 0.777, Test accuracy: 72.86 

Round  25, Train loss: 0.347, Test loss: 0.816, Test accuracy: 72.54 

Round  26, Train loss: 0.316, Test loss: 0.815, Test accuracy: 73.18 

Round  27, Train loss: 0.309, Test loss: 0.807, Test accuracy: 72.58 

Round  28, Train loss: 0.303, Test loss: 0.799, Test accuracy: 72.82 

Round  29, Train loss: 0.288, Test loss: 0.811, Test accuracy: 72.14 

Round  30, Train loss: 0.254, Test loss: 0.839, Test accuracy: 72.90 

Round  31, Train loss: 0.242, Test loss: 0.824, Test accuracy: 72.98 

Round  32, Train loss: 0.232, Test loss: 0.800, Test accuracy: 73.46 

Round  33, Train loss: 0.225, Test loss: 0.813, Test accuracy: 73.70 

Round  34, Train loss: 0.200, Test loss: 0.814, Test accuracy: 74.36 

Round  35, Train loss: 0.204, Test loss: 0.792, Test accuracy: 74.52 

Round  36, Train loss: 0.178, Test loss: 0.817, Test accuracy: 74.20 

Round  37, Train loss: 0.175, Test loss: 0.833, Test accuracy: 74.54 

Round  38, Train loss: 0.165, Test loss: 0.836, Test accuracy: 74.02 

Round  39, Train loss: 0.160, Test loss: 0.820, Test accuracy: 74.92 

Round  40, Train loss: 0.143, Test loss: 0.869, Test accuracy: 74.72 

Round  41, Train loss: 0.131, Test loss: 0.856, Test accuracy: 74.78 

Round  42, Train loss: 0.130, Test loss: 0.884, Test accuracy: 73.86 

Round  43, Train loss: 0.123, Test loss: 0.898, Test accuracy: 74.92 

Round  44, Train loss: 0.129, Test loss: 0.890, Test accuracy: 74.42 

Round  45, Train loss: 0.113, Test loss: 0.871, Test accuracy: 74.80 

Round  46, Train loss: 0.103, Test loss: 0.914, Test accuracy: 74.06 

Round  47, Train loss: 0.109, Test loss: 0.919, Test accuracy: 74.20 

Round  48, Train loss: 0.085, Test loss: 0.913, Test accuracy: 75.42 

Round  49, Train loss: 0.099, Test loss: 0.890, Test accuracy: 75.12 

Final Round, Train loss: 0.055, Test loss: 0.900, Test accuracy: 74.70 

Average accuracy final 10 rounds: 74.63 

1273.5494139194489
[6.461232662200928, 10.909523487091064, 15.425244569778442, 19.939868211746216, 24.272401809692383, 28.672703504562378, 33.206992864608765, 37.59424352645874, 41.98826718330383, 46.531567096710205, 50.875364780426025, 55.31297016143799, 59.728861570358276, 64.06177711486816, 68.73085045814514, 73.37965440750122, 77.73881387710571, 82.0434844493866, 86.68551230430603, 91.3122034072876, 95.76279401779175, 100.09262657165527, 104.53794693946838, 108.88803195953369, 113.27151393890381, 117.545095205307, 121.94261646270752, 126.2288773059845, 130.64171934127808, 135.12211155891418, 139.61339855194092, 144.3073182106018, 148.78979587554932, 153.325519323349, 157.9609251022339, 162.3449821472168, 166.96756649017334, 171.3624176979065, 176.0368583202362, 180.45103645324707, 184.80991053581238, 189.29168319702148, 193.88475346565247, 198.26754212379456, 202.61355900764465, 207.30954885482788, 211.60948538780212, 215.91842699050903, 220.35950255393982, 224.61665034294128, 229.31294703483582]
[25.46, 42.76, 51.24, 49.64, 56.34, 55.54, 61.7, 61.04, 64.3, 64.92, 66.82, 65.64, 66.6, 68.04, 69.6, 70.06, 69.78, 69.98, 70.22, 70.94, 72.36, 72.42, 71.16, 72.34, 72.86, 72.54, 73.18, 72.58, 72.82, 72.14, 72.9, 72.98, 73.46, 73.7, 74.36, 74.52, 74.2, 74.54, 74.02, 74.92, 74.72, 74.78, 73.86, 74.92, 74.42, 74.8, 74.06, 74.2, 75.42, 75.12, 74.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.565, Test loss: 1.894, Test accuracy: 25.08
Round   1, Train loss: 1.359, Test loss: 1.647, Test accuracy: 34.08
Round   2, Train loss: 1.257, Test loss: 1.269, Test accuracy: 48.94
Round   3, Train loss: 1.149, Test loss: 1.229, Test accuracy: 49.92
Round   4, Train loss: 1.066, Test loss: 1.068, Test accuracy: 56.64
Round   5, Train loss: 1.022, Test loss: 1.179, Test accuracy: 54.60
Round   6, Train loss: 0.971, Test loss: 1.049, Test accuracy: 57.66
Round   7, Train loss: 0.909, Test loss: 0.946, Test accuracy: 61.24
Round   8, Train loss: 0.873, Test loss: 0.934, Test accuracy: 63.18
Round   9, Train loss: 0.836, Test loss: 0.917, Test accuracy: 64.56
Round  10, Train loss: 0.800, Test loss: 0.940, Test accuracy: 62.74
Round  11, Train loss: 0.750, Test loss: 0.855, Test accuracy: 66.16
Round  12, Train loss: 0.732, Test loss: 0.885, Test accuracy: 66.46
Round  13, Train loss: 0.690, Test loss: 0.823, Test accuracy: 68.50
Round  14, Train loss: 0.651, Test loss: 0.851, Test accuracy: 68.40
Round  15, Train loss: 0.639, Test loss: 0.875, Test accuracy: 67.80
Round  16, Train loss: 0.589, Test loss: 0.806, Test accuracy: 70.30
Round  17, Train loss: 0.566, Test loss: 0.808, Test accuracy: 70.64
Round  18, Train loss: 0.533, Test loss: 0.780, Test accuracy: 71.70
Round  19, Train loss: 0.513, Test loss: 0.796, Test accuracy: 71.70
Round  20, Train loss: 0.483, Test loss: 0.760, Test accuracy: 72.86
Round  21, Train loss: 0.456, Test loss: 0.796, Test accuracy: 71.40
Round  22, Train loss: 0.430, Test loss: 0.768, Test accuracy: 72.92
Round  23, Train loss: 0.410, Test loss: 0.756, Test accuracy: 73.52
Round  24, Train loss: 0.394, Test loss: 0.795, Test accuracy: 73.08
Round  25, Train loss: 0.370, Test loss: 0.853, Test accuracy: 72.72
Round  26, Train loss: 0.340, Test loss: 0.768, Test accuracy: 74.16
Round  27, Train loss: 0.326, Test loss: 0.778, Test accuracy: 74.14
Round  28, Train loss: 0.315, Test loss: 0.765, Test accuracy: 74.66
Round  29, Train loss: 0.292, Test loss: 0.791, Test accuracy: 75.06
Round  30, Train loss: 0.273, Test loss: 0.770, Test accuracy: 74.54
Round  31, Train loss: 0.259, Test loss: 0.791, Test accuracy: 74.98
Round  32, Train loss: 0.243, Test loss: 0.783, Test accuracy: 75.42
Round  33, Train loss: 0.234, Test loss: 0.803, Test accuracy: 74.78
Round  34, Train loss: 0.221, Test loss: 0.817, Test accuracy: 74.34
Round  35, Train loss: 0.210, Test loss: 0.801, Test accuracy: 75.84
Round  36, Train loss: 0.206, Test loss: 0.806, Test accuracy: 75.88
Round  37, Train loss: 0.195, Test loss: 0.825, Test accuracy: 74.48
Round  38, Train loss: 0.183, Test loss: 0.826, Test accuracy: 74.92
Round  39, Train loss: 0.175, Test loss: 0.814, Test accuracy: 75.38
Round  40, Train loss: 0.161, Test loss: 0.849, Test accuracy: 75.14
Round  41, Train loss: 0.157, Test loss: 0.830, Test accuracy: 75.86
Round  42, Train loss: 0.147, Test loss: 0.817, Test accuracy: 75.94
Round  43, Train loss: 0.145, Test loss: 0.820, Test accuracy: 76.10
Round  44, Train loss: 0.118, Test loss: 0.856, Test accuracy: 75.90
Round  45, Train loss: 0.127, Test loss: 0.854, Test accuracy: 76.28
Round  46, Train loss: 0.102, Test loss: 0.870, Test accuracy: 75.62
Round  47, Train loss: 0.110, Test loss: 0.880, Test accuracy: 75.50
Round  48, Train loss: 0.109, Test loss: 0.856, Test accuracy: 76.02
Round  49, Train loss: 0.093, Test loss: 0.860, Test accuracy: 76.48
Final Round, Train loss: 0.060, Test loss: 0.867, Test accuracy: 76.26
Average accuracy final 10 rounds: 75.884
1429.8927521705627
[7.44794774055481, 12.693243026733398, 17.994699239730835, 23.204062461853027, 28.360764503479004, 33.60247302055359, 38.708173990249634, 43.67752814292908, 48.5933301448822, 53.60717439651489, 58.60161733627319, 64.16708970069885, 69.28697347640991, 74.54854035377502, 79.65665173530579, 84.83079624176025, 89.77739405632019, 94.78632402420044, 99.93461108207703, 104.7774600982666, 109.71250557899475, 114.63080096244812, 119.79134964942932, 124.97153234481812, 130.23467683792114, 135.29221725463867, 140.57274723052979, 145.84029722213745, 151.04856324195862, 156.14413785934448, 161.1917426586151, 166.33958840370178, 171.45458507537842, 176.69781804084778, 181.84493780136108, 186.87014746665955, 191.7991533279419, 196.72017121315002, 201.64278388023376, 206.6379144191742, 211.57367205619812, 216.58103489875793, 221.67396569252014, 226.7592625617981, 231.86007022857666, 236.91308212280273, 242.13968348503113, 247.19403100013733, 252.12249660491943, 257.14251017570496, 262.24026703834534]
[25.08, 34.08, 48.94, 49.92, 56.64, 54.6, 57.66, 61.24, 63.18, 64.56, 62.74, 66.16, 66.46, 68.5, 68.4, 67.8, 70.3, 70.64, 71.7, 71.7, 72.86, 71.4, 72.92, 73.52, 73.08, 72.72, 74.16, 74.14, 74.66, 75.06, 74.54, 74.98, 75.42, 74.78, 74.34, 75.84, 75.88, 74.48, 74.92, 75.38, 75.14, 75.86, 75.94, 76.1, 75.9, 76.28, 75.62, 75.5, 76.02, 76.48, 76.26]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 1.075, Train accuracy: 58.800, Test loss: 1.563, Test accuracy: 38.40 

        train local model (freeze embeding):client   0,  Train loss: 0.773, Train accuracy: 70.200, Test loss: 1.176, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.723, Train accuracy: 74.400, Test loss: 1.276, Test accuracy: 54.80 

Round   0, Train loss: 0.723, Test loss: 1.239, Test accuracy: 54.60 

        train local model (freeze embeding):client   0,  Train loss: 0.713, Train accuracy: 74.000, Test loss: 1.365, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.629, Train accuracy: 76.400, Test loss: 1.188, Test accuracy: 61.00 

Round   1, Train loss: 0.629, Test loss: 1.248, Test accuracy: 55.60 

        train local model (freeze embeding):client   0,  Train loss: 0.589, Train accuracy: 78.200, Test loss: 1.251, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.548, Train accuracy: 79.600, Test loss: 1.216, Test accuracy: 55.40 

Round   2, Train loss: 0.548, Test loss: 1.139, Test accuracy: 58.90 

        train local model (freeze embeding):client   0,  Train loss: 0.495, Train accuracy: 84.400, Test loss: 1.223, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.637, Train accuracy: 76.600, Test loss: 1.329, Test accuracy: 62.40 

Round   3, Train loss: 0.637, Test loss: 1.356, Test accuracy: 55.20 

        train local model (freeze embeding):client   0,  Train loss: 0.526, Train accuracy: 80.800, Test loss: 1.263, Test accuracy: 60.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.573, Train accuracy: 79.400, Test loss: 1.316, Test accuracy: 55.60 

Round   4, Train loss: 0.573, Test loss: 1.302, Test accuracy: 56.20 

        train local model (freeze embeding):client   0,  Train loss: 0.454, Train accuracy: 84.600, Test loss: 1.362, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.431, Train accuracy: 83.200, Test loss: 1.207, Test accuracy: 59.40 

Round   5, Train loss: 0.431, Test loss: 1.245, Test accuracy: 58.30 

        train local model (freeze embeding):client   0,  Train loss: 0.351, Train accuracy: 87.400, Test loss: 1.315, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.352, Train accuracy: 86.800, Test loss: 1.793, Test accuracy: 50.20 

Round   6, Train loss: 0.352, Test loss: 1.452, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 0.255, Train accuracy: 90.600, Test loss: 1.612, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.330, Train accuracy: 87.200, Test loss: 1.269, Test accuracy: 61.60 

Round   7, Train loss: 0.330, Test loss: 1.306, Test accuracy: 61.00 

        train local model (freeze embeding):client   0,  Train loss: 0.245, Train accuracy: 91.200, Test loss: 1.383, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.401, Train accuracy: 84.400, Test loss: 1.500, Test accuracy: 63.20 

Round   8, Train loss: 0.401, Test loss: 1.606, Test accuracy: 60.10 

        train local model (freeze embeding):client   0,  Train loss: 0.278, Train accuracy: 91.000, Test loss: 1.661, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.286, Train accuracy: 88.600, Test loss: 1.444, Test accuracy: 67.40 

Round   9, Train loss: 0.286, Test loss: 1.538, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.169, Train accuracy: 94.400, Test loss: 1.652, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.224, Train accuracy: 91.200, Test loss: 2.243, Test accuracy: 49.20 

Round  10, Train loss: 0.224, Test loss: 1.678, Test accuracy: 60.20 

        train local model (freeze embeding):client   0,  Train loss: 0.137, Train accuracy: 95.800, Test loss: 1.559, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.136, Train accuracy: 94.600, Test loss: 2.098, Test accuracy: 55.00 

Round  11, Train loss: 0.136, Test loss: 1.657, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.118, Train accuracy: 95.600, Test loss: 1.907, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.309, Train accuracy: 90.600, Test loss: 1.877, Test accuracy: 62.40 

Round  12, Train loss: 0.309, Test loss: 2.110, Test accuracy: 57.80 

        train local model (freeze embeding):client   0,  Train loss: 0.131, Train accuracy: 95.200, Test loss: 1.796, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.108, Train accuracy: 96.200, Test loss: 1.717, Test accuracy: 61.00 

Round  13, Train loss: 0.108, Test loss: 1.605, Test accuracy: 61.20 

        train local model (freeze embeding):client   0,  Train loss: 0.092, Train accuracy: 97.200, Test loss: 1.633, Test accuracy: 64.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.119, Train accuracy: 95.800, Test loss: 1.903, Test accuracy: 63.20 

Round  14, Train loss: 0.119, Test loss: 1.842, Test accuracy: 61.60 

        train local model (freeze embeding):client   0,  Train loss: 0.082, Train accuracy: 97.400, Test loss: 1.827, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.208, Train accuracy: 91.200, Test loss: 1.750, Test accuracy: 66.20 

Round  15, Train loss: 0.208, Test loss: 1.855, Test accuracy: 62.20 

        train local model (freeze embeding):client   0,  Train loss: 0.076, Train accuracy: 97.800, Test loss: 2.085, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.075, Train accuracy: 97.400, Test loss: 2.335, Test accuracy: 55.40 

Round  16, Train loss: 0.075, Test loss: 1.957, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.060, Train accuracy: 97.800, Test loss: 2.184, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.062, Train accuracy: 98.200, Test loss: 2.182, Test accuracy: 62.80 

Round  17, Train loss: 0.062, Test loss: 2.085, Test accuracy: 63.00 

        train local model (freeze embeding):client   0,  Train loss: 0.043, Train accuracy: 98.400, Test loss: 2.212, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.136, Train accuracy: 95.000, Test loss: 1.626, Test accuracy: 69.40 

Round  18, Train loss: 0.136, Test loss: 2.240, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.046, Train accuracy: 98.400, Test loss: 1.833, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.400, Test loss: 2.111, Test accuracy: 61.60 

Round  19, Train loss: 0.023, Test loss: 1.849, Test accuracy: 64.40 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.981, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.400, Test loss: 2.281, Test accuracy: 65.40 

Final Round, Train loss: 0.022, Test loss: 1.825, Test accuracy: 64.80 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 0.927, Train accuracy: 61.600, Test loss: 0.972, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 2.093, Test accuracy: 62.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.400, Test loss: 1.996, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.891, Train accuracy: 62.200, Test loss: 0.831, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.697, Train accuracy: 73.200, Test loss: 1.069, Test accuracy: 67.80 

Round   0, Train loss: 0.361, Test loss: 1.363, Test accuracy: 63.45 

        train local model (freeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.600, Test loss: 1.792, Test accuracy: 66.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.078, Train accuracy: 97.400, Test loss: 2.100, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.633, Train accuracy: 75.000, Test loss: 0.966, Test accuracy: 64.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.529, Train accuracy: 79.200, Test loss: 0.861, Test accuracy: 72.00 

Round   1, Train loss: 0.303, Test loss: 1.393, Test accuracy: 62.35 

        train local model (freeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.400, Test loss: 1.791, Test accuracy: 65.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.295, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.445, Train accuracy: 83.800, Test loss: 0.996, Test accuracy: 66.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.540, Train accuracy: 80.200, Test loss: 0.922, Test accuracy: 72.20 

Round   2, Train loss: 0.272, Test loss: 1.438, Test accuracy: 63.75 

        train local model (freeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 2.054, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 2.497, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.369, Train accuracy: 86.400, Test loss: 1.010, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.433, Train accuracy: 85.200, Test loss: 1.634, Test accuracy: 54.00 

Round   3, Train loss: 0.222, Test loss: 1.461, Test accuracy: 63.70 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 2.077, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.200, Test loss: 2.228, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 0.267, Train accuracy: 91.200, Test loss: 1.106, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.418, Train accuracy: 85.600, Test loss: 1.635, Test accuracy: 57.60 

Round   4, Train loss: 0.226, Test loss: 1.416, Test accuracy: 63.85 

        train local model (freeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.400, Test loss: 1.851, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.104, Train accuracy: 96.400, Test loss: 2.288, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.235, Train accuracy: 93.400, Test loss: 1.058, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.280, Train accuracy: 90.800, Test loss: 1.498, Test accuracy: 64.40 

Round   5, Train loss: 0.192, Test loss: 1.510, Test accuracy: 64.65 

        train local model (freeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.882, Test accuracy: 64.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.059, Train accuracy: 97.400, Test loss: 2.596, Test accuracy: 53.00 

        train local model (freeze embeding):client   1,  Train loss: 0.178, Train accuracy: 94.800, Test loss: 1.240, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.275, Train accuracy: 89.800, Test loss: 1.701, Test accuracy: 62.60 

Round   6, Train loss: 0.167, Test loss: 1.469, Test accuracy: 64.70 

        train local model (freeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.600, Test loss: 1.774, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.032, Train accuracy: 99.000, Test loss: 1.828, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.172, Train accuracy: 94.800, Test loss: 1.264, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.385, Train accuracy: 88.800, Test loss: 1.495, Test accuracy: 69.20 

Round   7, Train loss: 0.209, Test loss: 1.545, Test accuracy: 64.25 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.731, Test accuracy: 65.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 2.280, Test accuracy: 59.40 

        train local model (freeze embeding):client   1,  Train loss: 0.153, Train accuracy: 95.600, Test loss: 1.193, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.247, Train accuracy: 89.600, Test loss: 1.641, Test accuracy: 63.00 

Round   8, Train loss: 0.133, Test loss: 1.590, Test accuracy: 62.80 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.879, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 2.268, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 0.099, Train accuracy: 97.800, Test loss: 1.131, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.317, Train accuracy: 88.400, Test loss: 1.746, Test accuracy: 65.40 

Round   9, Train loss: 0.164, Test loss: 1.673, Test accuracy: 64.45 

        train local model (freeze embeding):client   0,  Train loss: 0.025, Train accuracy: 99.000, Test loss: 1.995, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.000, Test loss: 2.543, Test accuracy: 60.60 

        train local model (freeze embeding):client   1,  Train loss: 0.059, Train accuracy: 98.600, Test loss: 1.138, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.186, Train accuracy: 94.400, Test loss: 1.704, Test accuracy: 62.20 

Round  10, Train loss: 0.110, Test loss: 1.665, Test accuracy: 64.60 

        train local model (freeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 2.204, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 2.118, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.046, Train accuracy: 99.400, Test loss: 1.361, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.459, Train accuracy: 86.400, Test loss: 1.993, Test accuracy: 63.20 

Round  11, Train loss: 0.238, Test loss: 1.877, Test accuracy: 63.20 

        train local model (freeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.972, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.054, Train accuracy: 98.400, Test loss: 2.982, Test accuracy: 55.20 

        train local model (freeze embeding):client   1,  Train loss: 0.052, Train accuracy: 98.600, Test loss: 1.315, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.152, Train accuracy: 94.000, Test loss: 1.582, Test accuracy: 61.20 

Round  12, Train loss: 0.103, Test loss: 1.612, Test accuracy: 64.95 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.993, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.042, Train accuracy: 98.800, Test loss: 2.578, Test accuracy: 62.00 

        train local model (freeze embeding):client   1,  Train loss: 0.045, Train accuracy: 99.200, Test loss: 1.336, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.201, Train accuracy: 91.800, Test loss: 2.162, Test accuracy: 52.80 

Round  13, Train loss: 0.122, Test loss: 1.707, Test accuracy: 64.80 

        train local model (freeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.933, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.033, Train accuracy: 99.200, Test loss: 1.786, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.028, Train accuracy: 99.800, Test loss: 1.421, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.179, Train accuracy: 92.800, Test loss: 2.603, Test accuracy: 48.40 

Round  14, Train loss: 0.106, Test loss: 1.690, Test accuracy: 65.00 

        train local model (freeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.851, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.020, Train accuracy: 99.000, Test loss: 2.279, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.022, Train accuracy: 99.800, Test loss: 1.446, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.126, Train accuracy: 96.000, Test loss: 1.425, Test accuracy: 69.40 

Round  15, Train loss: 0.073, Test loss: 1.856, Test accuracy: 65.20 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.057, Test accuracy: 64.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 2.625, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 0.016, Train accuracy: 100.000, Test loss: 1.406, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.066, Train accuracy: 97.800, Test loss: 1.536, Test accuracy: 69.80 

Round  16, Train loss: 0.036, Test loss: 1.808, Test accuracy: 66.05 

        train local model (freeze embeding):client   0,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.870, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.942, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.592, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.228, Train accuracy: 92.400, Test loss: 1.990, Test accuracy: 66.60 

Round  17, Train loss: 0.122, Test loss: 1.992, Test accuracy: 64.25 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 2.026, Test accuracy: 64.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.032, Train accuracy: 98.600, Test loss: 1.966, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 1.312, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.096, Train accuracy: 96.600, Test loss: 2.288, Test accuracy: 58.00 

Round  18, Train loss: 0.064, Test loss: 1.712, Test accuracy: 65.20 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.970, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 2.546, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 1.592, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.689, Test accuracy: 71.40 

Round  19, Train loss: 0.012, Test loss: 1.972, Test accuracy: 66.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.352, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.564, Test accuracy: 59.80 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.499, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.138, Train accuracy: 95.600, Test loss: 2.228, Test accuracy: 60.60 

Final Round, Train loss: 0.072, Test loss: 1.931, Test accuracy: 66.50 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 0.634, Train accuracy: 76.200, Test loss: 0.976, Test accuracy: 66.80 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 2.345, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.200, Test loss: 2.060, Test accuracy: 70.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.395, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.093, Train accuracy: 97.000, Test loss: 1.437, Test accuracy: 67.40 

        train local model (freeze embeding):client   2,  Train loss: 0.575, Train accuracy: 75.800, Test loss: 0.789, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.278, Train accuracy: 91.800, Test loss: 1.016, Test accuracy: 69.80 

Round   0, Train loss: 0.131, Test loss: 1.467, Test accuracy: 68.90 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.215, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.420, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.370, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.024, Train accuracy: 99.600, Test loss: 2.164, Test accuracy: 67.60 

        train local model (freeze embeding):client   2,  Train loss: 0.416, Train accuracy: 84.600, Test loss: 0.902, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.223, Train accuracy: 92.800, Test loss: 1.018, Test accuracy: 71.20 

Round   1, Train loss: 0.083, Test loss: 1.490, Test accuracy: 68.73 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.989, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.400, Test loss: 2.343, Test accuracy: 62.20 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.707, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.063, Train accuracy: 97.600, Test loss: 1.822, Test accuracy: 63.20 

        train local model (freeze embeding):client   2,  Train loss: 0.275, Train accuracy: 90.400, Test loss: 0.883, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.192, Train accuracy: 94.000, Test loss: 1.264, Test accuracy: 69.40 

Round   2, Train loss: 0.089, Test loss: 1.449, Test accuracy: 68.73 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 2.054, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.000, Test loss: 2.578, Test accuracy: 57.40 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.407, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.098, Train accuracy: 96.400, Test loss: 2.482, Test accuracy: 59.60 

        train local model (freeze embeding):client   2,  Train loss: 0.188, Train accuracy: 94.200, Test loss: 0.960, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.161, Train accuracy: 93.600, Test loss: 1.178, Test accuracy: 71.20 

Round   3, Train loss: 0.094, Test loss: 1.484, Test accuracy: 68.67 

        train local model (freeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.400, Test loss: 1.949, Test accuracy: 65.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.080, Train accuracy: 97.400, Test loss: 1.662, Test accuracy: 71.40 

        train local model (freeze embeding):client   1,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.476, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.057, Train accuracy: 98.600, Test loss: 1.311, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.173, Train accuracy: 94.000, Test loss: 0.998, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.265, Train accuracy: 92.600, Test loss: 1.241, Test accuracy: 68.00 

Round   4, Train loss: 0.134, Test loss: 1.428, Test accuracy: 69.33 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.795, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.079, Train accuracy: 97.400, Test loss: 2.726, Test accuracy: 56.00 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.320, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.175, Train accuracy: 95.600, Test loss: 2.597, Test accuracy: 61.80 

        train local model (freeze embeding):client   2,  Train loss: 0.130, Train accuracy: 96.000, Test loss: 0.939, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.161, Train accuracy: 94.200, Test loss: 1.176, Test accuracy: 72.40 

Round   5, Train loss: 0.138, Test loss: 1.474, Test accuracy: 69.27 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 2.040, Test accuracy: 64.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.040, Train accuracy: 98.400, Test loss: 2.296, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.455, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.088, Train accuracy: 97.400, Test loss: 2.438, Test accuracy: 59.20 

        train local model (freeze embeding):client   2,  Train loss: 0.116, Train accuracy: 97.400, Test loss: 0.959, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.156, Train accuracy: 93.600, Test loss: 1.226, Test accuracy: 73.00 

Round   6, Train loss: 0.095, Test loss: 1.479, Test accuracy: 69.23 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.891, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.076, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.411, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.069, Train accuracy: 97.200, Test loss: 2.001, Test accuracy: 69.00 

        train local model (freeze embeding):client   2,  Train loss: 0.062, Train accuracy: 98.800, Test loss: 0.999, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.245, Train accuracy: 91.800, Test loss: 1.797, Test accuracy: 59.00 

Round   7, Train loss: 0.106, Test loss: 1.529, Test accuracy: 69.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.079, Test accuracy: 67.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.037, Train accuracy: 99.000, Test loss: 1.942, Test accuracy: 70.40 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.371, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.063, Train accuracy: 97.000, Test loss: 1.908, Test accuracy: 68.40 

        train local model (freeze embeding):client   2,  Train loss: 0.060, Train accuracy: 98.600, Test loss: 1.115, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.104, Train accuracy: 96.600, Test loss: 1.652, Test accuracy: 65.00 

Round   8, Train loss: 0.068, Test loss: 1.604, Test accuracy: 68.63 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.848, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.019, Train accuracy: 99.600, Test loss: 2.325, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.777, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.232, Train accuracy: 93.600, Test loss: 2.170, Test accuracy: 63.40 

        train local model (freeze embeding):client   2,  Train loss: 0.028, Train accuracy: 99.800, Test loss: 1.145, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.067, Train accuracy: 98.000, Test loss: 1.339, Test accuracy: 69.40 

Round   9, Train loss: 0.106, Test loss: 1.590, Test accuracy: 69.47 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.908, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.239, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.590, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.400, Test loss: 2.009, Test accuracy: 67.40 

        train local model (freeze embeding):client   2,  Train loss: 0.032, Train accuracy: 99.800, Test loss: 1.058, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.128, Train accuracy: 96.200, Test loss: 1.328, Test accuracy: 69.60 

Round  10, Train loss: 0.050, Test loss: 1.545, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.949, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.200, Test loss: 2.012, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.558, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.072, Train accuracy: 97.400, Test loss: 1.652, Test accuracy: 70.00 

        train local model (freeze embeding):client   2,  Train loss: 0.027, Train accuracy: 100.000, Test loss: 1.104, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.082, Train accuracy: 96.800, Test loss: 1.555, Test accuracy: 67.80 

Round  11, Train loss: 0.059, Test loss: 1.558, Test accuracy: 70.37 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.940, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.177, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.419, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.112, Train accuracy: 96.200, Test loss: 1.750, Test accuracy: 71.80 

        train local model (freeze embeding):client   2,  Train loss: 0.018, Train accuracy: 100.000, Test loss: 1.223, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.059, Train accuracy: 98.000, Test loss: 1.419, Test accuracy: 70.20 

Round  12, Train loss: 0.057, Test loss: 1.620, Test accuracy: 69.83 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.965, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.896, Test accuracy: 68.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.419, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.049, Train accuracy: 98.000, Test loss: 1.537, Test accuracy: 72.20 

        train local model (freeze embeding):client   2,  Train loss: 0.014, Train accuracy: 100.000, Test loss: 1.287, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.104, Train accuracy: 97.800, Test loss: 1.198, Test accuracy: 74.80 

Round  13, Train loss: 0.053, Test loss: 1.554, Test accuracy: 70.10 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.861, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 2.147, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.484, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.039, Train accuracy: 98.600, Test loss: 1.602, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.019, Train accuracy: 99.600, Test loss: 1.119, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.088, Train accuracy: 97.600, Test loss: 1.917, Test accuracy: 60.60 

Round  14, Train loss: 0.048, Test loss: 1.495, Test accuracy: 69.77 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.634, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 2.088, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.458, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.077, Train accuracy: 97.200, Test loss: 2.745, Test accuracy: 56.00 

        train local model (freeze embeding):client   2,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 1.183, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.050, Train accuracy: 98.200, Test loss: 1.472, Test accuracy: 72.20 

Round  15, Train loss: 0.045, Test loss: 1.576, Test accuracy: 69.60 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.884, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.999, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.547, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.831, Test accuracy: 67.40 

        train local model (freeze embeding):client   2,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 1.263, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.023, Train accuracy: 99.000, Test loss: 1.724, Test accuracy: 66.00 

Round  16, Train loss: 0.018, Test loss: 1.677, Test accuracy: 70.63 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.971, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 2.472, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.674, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 2.037, Test accuracy: 68.00 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.314, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.032, Train accuracy: 99.200, Test loss: 1.390, Test accuracy: 69.80 

Round  17, Train loss: 0.020, Test loss: 1.642, Test accuracy: 69.60 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 2.201, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 2.349, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.624, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.087, Train accuracy: 96.600, Test loss: 1.281, Test accuracy: 74.00 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.235, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.035, Train accuracy: 98.600, Test loss: 1.279, Test accuracy: 73.00 

Round  18, Train loss: 0.042, Test loss: 1.632, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.800, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.952, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.552, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.581, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.311, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.045, Train accuracy: 98.800, Test loss: 1.480, Test accuracy: 67.20 

Round  19, Train loss: 0.019, Test loss: 1.573, Test accuracy: 70.00 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.896, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.600, Test loss: 2.294, Test accuracy: 68.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.399, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.803, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.175, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.035, Train accuracy: 99.000, Test loss: 1.433, Test accuracy: 72.80 

Final Round, Train loss: 0.016, Test loss: 1.554, Test accuracy: 69.80 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 0.624, Train accuracy: 74.400, Test loss: 0.959, Test accuracy: 61.20 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 2.030, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.937, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.338, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.899, Test accuracy: 67.60 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.228, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.071, Train accuracy: 98.200, Test loss: 2.057, Test accuracy: 64.00 

        train local model (freeze embeding):client   3,  Train loss: 0.661, Train accuracy: 75.200, Test loss: 1.004, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.300, Train accuracy: 88.000, Test loss: 0.997, Test accuracy: 63.80 

Round   0, Train loss: 0.094, Test loss: 1.413, Test accuracy: 69.85 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.782, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.330, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.409, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.734, Test accuracy: 73.20 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.295, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.399, Test accuracy: 72.40 

        train local model (freeze embeding):client   3,  Train loss: 0.450, Train accuracy: 82.200, Test loss: 0.899, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.287, Train accuracy: 90.600, Test loss: 1.574, Test accuracy: 49.00 

Round   1, Train loss: 0.075, Test loss: 1.466, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.128, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 2.220, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.546, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.028, Train accuracy: 99.200, Test loss: 1.825, Test accuracy: 66.60 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.280, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.007, Train accuracy: 99.600, Test loss: 1.430, Test accuracy: 73.40 

        train local model (freeze embeding):client   3,  Train loss: 0.337, Train accuracy: 87.200, Test loss: 1.066, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.295, Train accuracy: 89.600, Test loss: 1.816, Test accuracy: 50.00 

Round   2, Train loss: 0.086, Test loss: 1.429, Test accuracy: 68.97 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.907, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.400, Test loss: 1.992, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.448, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 2.020, Test accuracy: 68.80 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.218, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.642, Test accuracy: 70.40 

        train local model (freeze embeding):client   3,  Train loss: 0.235, Train accuracy: 93.600, Test loss: 1.385, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.276, Train accuracy: 90.000, Test loss: 2.176, Test accuracy: 49.20 

Round   3, Train loss: 0.080, Test loss: 1.431, Test accuracy: 68.70 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.966, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 2.199, Test accuracy: 63.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.572, Test accuracy: 71.80 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.209, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.105, Train accuracy: 96.400, Test loss: 1.802, Test accuracy: 63.40 

        train local model (freeze embeding):client   3,  Train loss: 0.200, Train accuracy: 93.200, Test loss: 1.105, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.272, Train accuracy: 90.800, Test loss: 1.756, Test accuracy: 54.20 

Round   4, Train loss: 0.099, Test loss: 1.418, Test accuracy: 69.08 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.642, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.226, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.275, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.157, Train accuracy: 94.800, Test loss: 2.522, Test accuracy: 64.00 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.182, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.444, Test accuracy: 71.00 

        train local model (freeze embeding):client   3,  Train loss: 0.145, Train accuracy: 96.000, Test loss: 1.149, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.166, Train accuracy: 94.800, Test loss: 1.655, Test accuracy: 56.60 

Round   5, Train loss: 0.085, Test loss: 1.474, Test accuracy: 69.53 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.872, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 2.335, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.532, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.890, Test accuracy: 68.40 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.254, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.030, Train accuracy: 99.200, Test loss: 1.353, Test accuracy: 71.80 

        train local model (freeze embeding):client   3,  Train loss: 0.121, Train accuracy: 96.600, Test loss: 1.281, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.131, Train accuracy: 96.000, Test loss: 1.637, Test accuracy: 57.60 

Round   6, Train loss: 0.046, Test loss: 1.408, Test accuracy: 69.62 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.797, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 2.406, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.451, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.041, Train accuracy: 98.600, Test loss: 1.556, Test accuracy: 72.00 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.220, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.411, Test accuracy: 72.20 

        train local model (freeze embeding):client   3,  Train loss: 0.093, Train accuracy: 97.400, Test loss: 1.434, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.173, Train accuracy: 94.200, Test loss: 2.571, Test accuracy: 43.40 

Round   7, Train loss: 0.057, Test loss: 1.471, Test accuracy: 69.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.910, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.798, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.589, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.144, Train accuracy: 95.200, Test loss: 3.056, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.212, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.049, Train accuracy: 98.000, Test loss: 1.817, Test accuracy: 67.20 

        train local model (freeze embeding):client   3,  Train loss: 0.070, Train accuracy: 98.200, Test loss: 1.231, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.239, Train accuracy: 90.600, Test loss: 1.972, Test accuracy: 53.80 

Round   8, Train loss: 0.108, Test loss: 1.405, Test accuracy: 69.40 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.697, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.720, Test accuracy: 71.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.459, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.043, Train accuracy: 98.600, Test loss: 1.513, Test accuracy: 69.60 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.246, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.400, Test loss: 1.635, Test accuracy: 70.60 

        train local model (freeze embeding):client   3,  Train loss: 0.065, Train accuracy: 99.200, Test loss: 1.406, Test accuracy: 59.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.057, Train accuracy: 98.400, Test loss: 1.556, Test accuracy: 58.40 

Round   9, Train loss: 0.029, Test loss: 1.392, Test accuracy: 69.92 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.681, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.782, Test accuracy: 70.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.392, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.050, Train accuracy: 98.000, Test loss: 2.014, Test accuracy: 65.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.164, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.659, Test accuracy: 71.00 

        train local model (freeze embeding):client   3,  Train loss: 0.035, Train accuracy: 99.600, Test loss: 1.451, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.128, Train accuracy: 96.400, Test loss: 2.276, Test accuracy: 49.80 

Round  10, Train loss: 0.046, Test loss: 1.472, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.714, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.600, Test loss: 1.813, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.555, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.054, Train accuracy: 98.200, Test loss: 1.546, Test accuracy: 71.20 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.231, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.430, Test accuracy: 73.00 

        train local model (freeze embeding):client   3,  Train loss: 0.025, Train accuracy: 99.600, Test loss: 1.470, Test accuracy: 62.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.457, Train accuracy: 85.400, Test loss: 2.275, Test accuracy: 59.80 

Round  11, Train loss: 0.133, Test loss: 1.438, Test accuracy: 70.35 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.733, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 2.083, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.404, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.040, Train accuracy: 99.000, Test loss: 2.176, Test accuracy: 65.40 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.208, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.021, Train accuracy: 99.800, Test loss: 1.575, Test accuracy: 68.80 

        train local model (freeze embeding):client   3,  Train loss: 0.031, Train accuracy: 99.400, Test loss: 1.368, Test accuracy: 64.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.077, Train accuracy: 97.200, Test loss: 1.663, Test accuracy: 62.40 

Round  12, Train loss: 0.036, Test loss: 1.517, Test accuracy: 69.92 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.620, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.044, Train accuracy: 98.800, Test loss: 1.974, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.408, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.137, Train accuracy: 95.000, Test loss: 1.320, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.226, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.071, Train accuracy: 97.400, Test loss: 1.537, Test accuracy: 69.60 

        train local model (freeze embeding):client   3,  Train loss: 0.021, Train accuracy: 100.000, Test loss: 1.491, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.196, Train accuracy: 92.800, Test loss: 1.940, Test accuracy: 58.40 

Round  13, Train loss: 0.112, Test loss: 1.537, Test accuracy: 69.42 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.764, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.088, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.479, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.450, Test accuracy: 73.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.348, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.027, Train accuracy: 99.000, Test loss: 1.459, Test accuracy: 72.00 

        train local model (freeze embeding):client   3,  Train loss: 0.019, Train accuracy: 100.000, Test loss: 1.342, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.162, Train accuracy: 93.800, Test loss: 2.268, Test accuracy: 52.80 

Round  14, Train loss: 0.051, Test loss: 1.440, Test accuracy: 70.25 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.698, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.774, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.113, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.033, Train accuracy: 98.800, Test loss: 1.944, Test accuracy: 67.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.253, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.361, Train accuracy: 90.600, Test loss: 1.523, Test accuracy: 74.40 

        train local model (freeze embeding):client   3,  Train loss: 0.025, Train accuracy: 99.600, Test loss: 1.405, Test accuracy: 64.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.080, Train accuracy: 97.600, Test loss: 1.992, Test accuracy: 58.20 

Round  15, Train loss: 0.118, Test loss: 1.492, Test accuracy: 70.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.720, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.292, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.311, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.895, Test accuracy: 68.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.210, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.392, Test accuracy: 72.20 

        train local model (freeze embeding):client   3,  Train loss: 0.019, Train accuracy: 99.800, Test loss: 1.497, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.066, Train accuracy: 97.800, Test loss: 2.514, Test accuracy: 50.00 

Round  16, Train loss: 0.020, Test loss: 1.486, Test accuracy: 70.03 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.778, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 2.367, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.255, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.512, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.268, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.537, Test accuracy: 73.40 

        train local model (freeze embeding):client   3,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.534, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.109, Train accuracy: 96.200, Test loss: 1.820, Test accuracy: 60.60 

Round  17, Train loss: 0.033, Test loss: 1.537, Test accuracy: 70.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.936, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.282, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.416, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.796, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.234, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.063, Train accuracy: 97.800, Test loss: 1.350, Test accuracy: 73.40 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.620, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.207, Train accuracy: 92.600, Test loss: 1.908, Test accuracy: 61.20 

Round  18, Train loss: 0.071, Test loss: 1.560, Test accuracy: 70.03 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.854, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 2.141, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.417, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.664, Test accuracy: 73.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.254, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.317, Test accuracy: 75.80 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.469, Test accuracy: 65.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.152, Train accuracy: 94.200, Test loss: 3.086, Test accuracy: 49.40 

Round  19, Train loss: 0.041, Test loss: 1.583, Test accuracy: 70.12 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.886, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 2.129, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.291, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.528, Test accuracy: 72.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.272, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.015, Train accuracy: 100.000, Test loss: 1.326, Test accuracy: 74.60 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.608, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.055, Train accuracy: 98.000, Test loss: 2.032, Test accuracy: 56.20 

Final Round, Train loss: 0.024, Test loss: 1.573, Test accuracy: 70.35 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.548, Train accuracy: 77.800, Test loss: 1.112, Test accuracy: 62.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 2.018, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.947, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.341, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.055, Train accuracy: 98.400, Test loss: 1.487, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.245, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.018, Train accuracy: 99.200, Test loss: 1.460, Test accuracy: 73.20 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.619, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.044, Train accuracy: 99.400, Test loss: 2.598, Test accuracy: 52.60 

        train local model (freeze embeding):client   4,  Train loss: 0.545, Train accuracy: 78.800, Test loss: 1.015, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.204, Train accuracy: 91.800, Test loss: 1.232, Test accuracy: 63.80 

Round   0, Train loss: 0.070, Test loss: 1.348, Test accuracy: 71.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.668, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.060, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.605, Test accuracy: 72.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.142, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.352, Test accuracy: 74.40 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.732, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.110, Train accuracy: 96.200, Test loss: 1.785, Test accuracy: 60.20 

        train local model (freeze embeding):client   4,  Train loss: 0.322, Train accuracy: 87.000, Test loss: 0.803, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.249, Train accuracy: 91.400, Test loss: 1.374, Test accuracy: 63.00 

Round   1, Train loss: 0.073, Test loss: 1.319, Test accuracy: 71.86 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.860, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 2.020, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.227, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.194, Train accuracy: 92.600, Test loss: 0.967, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.212, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.454, Test accuracy: 72.20 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.641, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.797, Test accuracy: 63.20 

        train local model (freeze embeding):client   4,  Train loss: 0.244, Train accuracy: 89.800, Test loss: 1.035, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.178, Train accuracy: 92.800, Test loss: 1.064, Test accuracy: 73.20 

Round   2, Train loss: 0.078, Test loss: 1.365, Test accuracy: 71.38 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.686, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.944, Test accuracy: 72.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.263, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.803, Test accuracy: 70.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.222, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.022, Train accuracy: 99.800, Test loss: 1.496, Test accuracy: 72.60 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.657, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.073, Train accuracy: 98.200, Test loss: 2.068, Test accuracy: 57.40 

        train local model (freeze embeding):client   4,  Train loss: 0.166, Train accuracy: 95.800, Test loss: 0.765, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.296, Train accuracy: 88.400, Test loss: 1.501, Test accuracy: 62.20 

Round   3, Train loss: 0.082, Test loss: 1.320, Test accuracy: 71.86 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.744, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.066, Train accuracy: 97.400, Test loss: 1.732, Test accuracy: 71.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.423, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.264, Test accuracy: 75.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.293, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.532, Test accuracy: 71.40 

        train local model (freeze embeding):client   3,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.637, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.028, Train accuracy: 98.800, Test loss: 2.605, Test accuracy: 52.60 

        train local model (freeze embeding):client   4,  Train loss: 0.115, Train accuracy: 97.800, Test loss: 0.911, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.333, Train accuracy: 87.600, Test loss: 1.679, Test accuracy: 65.40 

Round   4, Train loss: 0.088, Test loss: 1.331, Test accuracy: 71.66 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.668, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.834, Test accuracy: 72.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.218, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.074, Train accuracy: 97.800, Test loss: 2.558, Test accuracy: 59.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.233, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.567, Test accuracy: 71.40 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.649, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.225, Train accuracy: 92.600, Test loss: 2.760, Test accuracy: 52.20 

        train local model (freeze embeding):client   4,  Train loss: 0.083, Train accuracy: 98.600, Test loss: 0.959, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.123, Train accuracy: 96.400, Test loss: 1.329, Test accuracy: 65.80 

Round   5, Train loss: 0.087, Test loss: 1.316, Test accuracy: 72.24 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.512, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.690, Test accuracy: 73.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.276, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.468, Test accuracy: 74.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.164, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.031, Train accuracy: 98.600, Test loss: 1.462, Test accuracy: 72.20 

        train local model (freeze embeding):client   3,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.607, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.057, Train accuracy: 98.000, Test loss: 2.089, Test accuracy: 53.80 

        train local model (freeze embeding):client   4,  Train loss: 0.070, Train accuracy: 98.800, Test loss: 1.058, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.092, Train accuracy: 97.200, Test loss: 1.313, Test accuracy: 68.80 

Round   6, Train loss: 0.037, Test loss: 1.319, Test accuracy: 72.78 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.661, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.837, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.238, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.458, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.201, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.441, Test accuracy: 72.60 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.842, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.073, Train accuracy: 96.800, Test loss: 2.428, Test accuracy: 54.00 

        train local model (freeze embeding):client   4,  Train loss: 0.042, Train accuracy: 99.800, Test loss: 0.956, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.174, Train accuracy: 93.200, Test loss: 0.968, Test accuracy: 74.80 

Round   7, Train loss: 0.052, Test loss: 1.343, Test accuracy: 72.78 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.644, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 2.033, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.337, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 98.000, Test loss: 1.557, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.241, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.039, Train accuracy: 99.000, Test loss: 1.710, Test accuracy: 67.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.666, Test accuracy: 66.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.189, Train accuracy: 93.600, Test loss: 2.138, Test accuracy: 59.80 

        train local model (freeze embeding):client   4,  Train loss: 0.028, Train accuracy: 100.000, Test loss: 1.014, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.086, Train accuracy: 97.400, Test loss: 1.342, Test accuracy: 65.80 

Round   8, Train loss: 0.071, Test loss: 1.339, Test accuracy: 71.94 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.696, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 2.109, Test accuracy: 68.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.239, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 98.600, Test loss: 1.876, Test accuracy: 69.60 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.076, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.245, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.617, Test accuracy: 64.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.061, Train accuracy: 98.400, Test loss: 2.588, Test accuracy: 51.40 

        train local model (freeze embeding):client   4,  Train loss: 0.033, Train accuracy: 99.600, Test loss: 1.012, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.139, Train accuracy: 94.000, Test loss: 1.829, Test accuracy: 56.60 

Round   9, Train loss: 0.052, Test loss: 1.319, Test accuracy: 71.82 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.608, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.788, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.111, Train accuracy: 97.200, Test loss: 1.293, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.160, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.053, Train accuracy: 98.600, Test loss: 1.715, Test accuracy: 65.00 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.538, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.069, Train accuracy: 97.800, Test loss: 2.110, Test accuracy: 58.00 

        train local model (freeze embeding):client   4,  Train loss: 0.031, Train accuracy: 99.600, Test loss: 1.012, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.106, Train accuracy: 96.800, Test loss: 1.173, Test accuracy: 71.20 

Round  10, Train loss: 0.068, Test loss: 1.307, Test accuracy: 71.62 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.611, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.889, Test accuracy: 67.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.246, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.471, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.196, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.307, Test accuracy: 74.40 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.585, Test accuracy: 64.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.034, Train accuracy: 98.600, Test loss: 2.141, Test accuracy: 59.20 

        train local model (freeze embeding):client   4,  Train loss: 0.023, Train accuracy: 100.000, Test loss: 1.012, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.103, Train accuracy: 96.000, Test loss: 1.270, Test accuracy: 70.40 

Round  11, Train loss: 0.033, Test loss: 1.333, Test accuracy: 72.18 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.657, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 2.368, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.266, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.139, Train accuracy: 96.400, Test loss: 2.690, Test accuracy: 58.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.114, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.184, Test accuracy: 77.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.621, Test accuracy: 64.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 2.204, Test accuracy: 59.80 

        train local model (freeze embeding):client   4,  Train loss: 0.021, Train accuracy: 100.000, Test loss: 1.106, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.067, Train accuracy: 98.000, Test loss: 1.315, Test accuracy: 67.00 

Round  12, Train loss: 0.048, Test loss: 1.344, Test accuracy: 72.22 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.585, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.870, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.340, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.525, Test accuracy: 74.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.193, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.320, Test accuracy: 75.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.592, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.244, Train accuracy: 92.800, Test loss: 2.313, Test accuracy: 54.60 

        train local model (freeze embeding):client   4,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.046, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.116, Train accuracy: 95.800, Test loss: 1.787, Test accuracy: 64.80 

Round  13, Train loss: 0.077, Test loss: 1.319, Test accuracy: 72.24 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.717, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.200, Test loss: 2.168, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.324, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.493, Test accuracy: 73.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.199, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.303, Test accuracy: 76.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.723, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.007, Train accuracy: 99.600, Test loss: 2.106, Test accuracy: 60.60 

        train local model (freeze embeding):client   4,  Train loss: 0.018, Train accuracy: 99.800, Test loss: 1.003, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.158, Train accuracy: 95.800, Test loss: 1.977, Test accuracy: 63.00 

Round  14, Train loss: 0.038, Test loss: 1.335, Test accuracy: 72.10 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.688, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 2.068, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.243, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.400, Test loss: 1.785, Test accuracy: 67.20 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.184, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.030, Train accuracy: 99.000, Test loss: 1.425, Test accuracy: 74.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.683, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.075, Train accuracy: 97.400, Test loss: 2.530, Test accuracy: 57.20 

        train local model (freeze embeding):client   4,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 0.965, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.048, Train accuracy: 98.400, Test loss: 1.347, Test accuracy: 68.20 

Round  15, Train loss: 0.036, Test loss: 1.315, Test accuracy: 72.40 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.582, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.928, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.274, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.200, Test loss: 1.523, Test accuracy: 72.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.190, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.341, Test accuracy: 75.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.637, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 2.076, Test accuracy: 61.40 

        train local model (freeze embeding):client   4,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 0.967, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.092, Train accuracy: 96.600, Test loss: 1.416, Test accuracy: 70.20 

Round  16, Train loss: 0.022, Test loss: 1.376, Test accuracy: 71.84 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.719, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.728, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.250, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.767, Test accuracy: 70.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.204, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.031, Train accuracy: 98.600, Test loss: 1.865, Test accuracy: 68.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.669, Test accuracy: 63.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.008, Train accuracy: 99.600, Test loss: 2.365, Test accuracy: 62.60 

        train local model (freeze embeding):client   4,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.028, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.061, Train accuracy: 97.600, Test loss: 1.807, Test accuracy: 65.00 

Round  17, Train loss: 0.021, Test loss: 1.358, Test accuracy: 72.00 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.693, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.805, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.326, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.080, Train accuracy: 98.000, Test loss: 1.250, Test accuracy: 74.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.235, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.657, Test accuracy: 72.60 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.579, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 2.023, Test accuracy: 58.20 

        train local model (freeze embeding):client   4,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.112, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.033, Train accuracy: 98.800, Test loss: 1.289, Test accuracy: 72.60 

Round  18, Train loss: 0.026, Test loss: 1.381, Test accuracy: 71.82 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.690, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.648, Test accuracy: 73.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.172, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.029, Train accuracy: 99.000, Test loss: 1.237, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.191, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.285, Test accuracy: 73.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.713, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.019, Train accuracy: 99.000, Test loss: 2.433, Test accuracy: 56.40 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.158, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.099, Train accuracy: 96.600, Test loss: 1.107, Test accuracy: 73.40 

Round  19, Train loss: 0.030, Test loss: 1.304, Test accuracy: 72.66 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.459, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.782, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.337, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.381, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.114, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.023, Train accuracy: 99.800, Test loss: 1.416, Test accuracy: 75.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.591, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.035, Train accuracy: 99.400, Test loss: 2.772, Test accuracy: 54.40 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.017, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 2.155, Test accuracy: 61.80 

Final Round, Train loss: 0.016, Test loss: 1.303, Test accuracy: 72.64 

Average accuracy final 10 rounds: 338.57550000000003 

3264.6327698230743
[9.421820163726807, 18.988485097885132, 28.490373134613037, 37.363497257232666, 46.13603138923645, 55.41904044151306, 65.32262301445007, 74.734543800354, 83.83645486831665, 93.284503698349, 102.83964014053345, 111.75443935394287, 121.23465871810913, 130.91951370239258, 141.22760248184204, 151.5172336101532, 160.77592206001282, 170.22745871543884, 179.98144125938416, 189.07057571411133, 198.46880316734314, 208.12602281570435, 217.64852118492126, 227.51396822929382, 237.55793809890747, 247.15622186660767, 256.5133903026581, 265.8414158821106, 275.6362416744232, 285.0433032512665, 294.5347135066986, 304.2549555301666, 314.14265513420105, 323.3767247200012, 332.9194622039795, 342.5101251602173, 351.8502449989319, 361.6826980113983, 371.40816259384155, 380.5721650123596, 390.0932881832123, 399.6261432170868, 409.44651675224304, 419.1519179344177, 429.2689845561981, 439.4866564273834, 449.6280677318573, 460.1789028644562, 470.0371196269989, 479.69592571258545, 489.4558615684509, 498.93200635910034, 508.99696254730225, 518.8197557926178, 528.3065283298492, 537.6418235301971, 546.9935948848724, 556.6278970241547, 566.7435395717621, 576.9625043869019, 586.6113743782043, 596.70281291008, 606.8626160621643, 616.9672107696533, 626.7493607997894, 636.3482542037964, 645.9187009334564, 655.563202381134, 665.5556678771973, 675.2375910282135, 684.8282034397125, 694.4649999141693, 704.5293169021606, 714.6141862869263, 724.7728629112244, 734.572122335434, 744.2688436508179, 754.0107548236847, 764.0332252979279, 773.8977334499359, 783.4543387889862, 793.5290005207062, 803.5052859783173, 813.3025588989258, 823.1864337921143, 832.8433828353882, 842.3739078044891, 852.1648483276367, 861.889151096344, 871.0168640613556, 880.4410316944122, 890.3898811340332, 900.2422173023224, 910.0267879962921, 919.3144094944, 929.2072556018829, 939.2716474533081, 949.1022381782532, 958.5154955387115, 968.8978028297424, 979.2438173294067, 989.1490378379822, 998.9987504482269, 1008.880676984787, 1018.7265043258667]
[54.6, 55.6, 58.9, 55.2, 56.2, 58.3, 57.4, 61.0, 60.1, 61.8, 60.2, 61.8, 57.8, 61.2, 61.6, 62.2, 61.8, 63.0, 60.8, 64.4, 64.8, 63.45, 62.35, 63.75, 63.7, 63.85, 64.65, 64.7, 64.25, 62.8, 64.45, 64.6, 63.2, 64.95, 64.8, 65.0, 65.2, 66.05, 64.25, 65.2, 66.2, 66.5, 68.9, 68.73333333333333, 68.73333333333333, 68.66666666666667, 69.33333333333333, 69.26666666666667, 69.23333333333333, 69.5, 68.63333333333334, 69.46666666666667, 69.9, 70.36666666666666, 69.83333333333333, 70.1, 69.76666666666667, 69.6, 70.63333333333334, 69.6, 69.9, 70.0, 69.8, 69.85, 69.9, 68.975, 68.7, 69.075, 69.525, 69.625, 69.4, 69.4, 69.925, 69.9, 70.35, 69.925, 69.425, 70.25, 70.2, 70.025, 70.5, 70.025, 70.125, 70.35, 71.5, 71.86, 71.38, 71.86, 71.66, 72.24, 72.78, 72.78, 71.94, 71.82, 71.62, 72.18, 72.22, 72.24, 72.1, 72.4, 71.84, 72.0, 71.82, 72.66, 72.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.459, Test loss: 1.416, Test accuracy: 46.02 

Round   0, Global train loss: 1.459, Global test loss: 2.435, Global test accuracy: 18.20 

Round   1, Train loss: 1.139, Test loss: 1.254, Test accuracy: 53.48 

Round   1, Global train loss: 1.139, Global test loss: 2.516, Global test accuracy: 18.10 

Round   2, Train loss: 0.973, Test loss: 1.222, Test accuracy: 56.64 

Round   2, Global train loss: 0.973, Global test loss: 2.563, Global test accuracy: 16.64 

Round   3, Train loss: 0.841, Test loss: 1.292, Test accuracy: 57.20 

Round   3, Global train loss: 0.841, Global test loss: 2.748, Global test accuracy: 16.00 

Round   4, Train loss: 0.730, Test loss: 1.305, Test accuracy: 58.94 

Round   4, Global train loss: 0.730, Global test loss: 2.709, Global test accuracy: 16.10 

Round   5, Train loss: 0.636, Test loss: 1.270, Test accuracy: 61.80 

Round   5, Global train loss: 0.636, Global test loss: 2.623, Global test accuracy: 16.10 

Round   6, Train loss: 0.537, Test loss: 1.341, Test accuracy: 61.26 

Round   6, Global train loss: 0.537, Global test loss: 2.731, Global test accuracy: 16.00 

Round   7, Train loss: 0.450, Test loss: 1.743, Test accuracy: 58.70 

Round   7, Global train loss: 0.450, Global test loss: 2.615, Global test accuracy: 16.04 

Round   8, Train loss: 0.410, Test loss: 1.527, Test accuracy: 62.20 

Round   8, Global train loss: 0.410, Global test loss: 2.750, Global test accuracy: 16.00 

Round   9, Train loss: 0.326, Test loss: 1.853, Test accuracy: 60.72 

Round   9, Global train loss: 0.326, Global test loss: 2.788, Global test accuracy: 16.00 

Round  10, Train loss: 0.273, Test loss: 1.776, Test accuracy: 61.24 

Round  10, Global train loss: 0.273, Global test loss: 2.854, Global test accuracy: 16.00 

Round  11, Train loss: 0.242, Test loss: 1.667, Test accuracy: 62.46 

Round  11, Global train loss: 0.242, Global test loss: 2.843, Global test accuracy: 16.00 

Round  12, Train loss: 0.213, Test loss: 1.757, Test accuracy: 62.70 

Round  12, Global train loss: 0.213, Global test loss: 2.811, Global test accuracy: 16.00 

Round  13, Train loss: 0.176, Test loss: 1.861, Test accuracy: 62.04 

Round  13, Global train loss: 0.176, Global test loss: 2.906, Global test accuracy: 16.00 

Round  14, Train loss: 0.148, Test loss: 1.708, Test accuracy: 64.54 

Round  14, Global train loss: 0.148, Global test loss: 2.718, Global test accuracy: 16.00 

Round  15, Train loss: 0.153, Test loss: 1.683, Test accuracy: 65.30 

Round  15, Global train loss: 0.153, Global test loss: 2.713, Global test accuracy: 16.00 

Round  16, Train loss: 0.110, Test loss: 1.838, Test accuracy: 65.32 

Round  16, Global train loss: 0.110, Global test loss: 2.689, Global test accuracy: 16.02 

Round  17, Train loss: 0.086, Test loss: 1.892, Test accuracy: 64.72 

Round  17, Global train loss: 0.086, Global test loss: 2.755, Global test accuracy: 16.00 

Round  18, Train loss: 0.087, Test loss: 1.791, Test accuracy: 66.14 

Round  18, Global train loss: 0.087, Global test loss: 2.613, Global test accuracy: 16.00 

Round  19, Train loss: 0.081, Test loss: 2.028, Test accuracy: 63.88 

Round  19, Global train loss: 0.081, Global test loss: 2.784, Global test accuracy: 16.00 

Round  20, Train loss: 0.093, Test loss: 1.728, Test accuracy: 66.92 

Round  20, Global train loss: 0.093, Global test loss: 2.767, Global test accuracy: 16.00 

Round  21, Train loss: 0.057, Test loss: 1.733, Test accuracy: 67.30 

Round  21, Global train loss: 0.057, Global test loss: 2.835, Global test accuracy: 16.00 

Round  22, Train loss: 0.071, Test loss: 2.114, Test accuracy: 64.00 

Round  22, Global train loss: 0.071, Global test loss: 2.777, Global test accuracy: 16.00 

Round  23, Train loss: 0.074, Test loss: 1.915, Test accuracy: 66.00 

Round  23, Global train loss: 0.074, Global test loss: 2.735, Global test accuracy: 16.00 

Round  24, Train loss: 0.053, Test loss: 1.807, Test accuracy: 66.64 

Round  24, Global train loss: 0.053, Global test loss: 2.726, Global test accuracy: 16.00 

Round  25, Train loss: 0.049, Test loss: 1.831, Test accuracy: 66.66 

Round  25, Global train loss: 0.049, Global test loss: 2.747, Global test accuracy: 16.00 

Round  26, Train loss: 0.036, Test loss: 1.788, Test accuracy: 68.00 

Round  26, Global train loss: 0.036, Global test loss: 2.693, Global test accuracy: 16.00 

Round  27, Train loss: 0.037, Test loss: 1.829, Test accuracy: 67.60 

Round  27, Global train loss: 0.037, Global test loss: 2.689, Global test accuracy: 16.04 

Round  28, Train loss: 0.041, Test loss: 1.832, Test accuracy: 67.40 

Round  28, Global train loss: 0.041, Global test loss: 2.712, Global test accuracy: 16.00 

Round  29, Train loss: 0.035, Test loss: 1.912, Test accuracy: 67.48 

Round  29, Global train loss: 0.035, Global test loss: 2.656, Global test accuracy: 16.10 

Round  30, Train loss: 0.027, Test loss: 1.918, Test accuracy: 67.06 

Round  30, Global train loss: 0.027, Global test loss: 2.714, Global test accuracy: 16.00 

Round  31, Train loss: 0.029, Test loss: 1.928, Test accuracy: 66.68 

Round  31, Global train loss: 0.029, Global test loss: 2.722, Global test accuracy: 16.00 

Round  32, Train loss: 0.034, Test loss: 1.915, Test accuracy: 66.64 

Round  32, Global train loss: 0.034, Global test loss: 2.653, Global test accuracy: 16.02 

Round  33, Train loss: 0.035, Test loss: 1.913, Test accuracy: 66.92 

Round  33, Global train loss: 0.035, Global test loss: 2.669, Global test accuracy: 16.00 

Round  34, Train loss: 0.028, Test loss: 1.887, Test accuracy: 66.58 

Round  34, Global train loss: 0.028, Global test loss: 2.754, Global test accuracy: 16.00 

Final Round, Train loss: 0.031, Test loss: 1.937, Test accuracy: 67.38 

Final Round, Global train loss: 0.031, Global test loss: 2.754, Global test accuracy: 16.00 

Average accuracy final 10 rounds: 67.102 

Average global accuracy final 10 rounds: 16.016 

1266.3338868618011
[7.77231240272522, 13.26902961730957, 18.975908994674683, 24.583040714263916, 30.087862253189087, 35.621495485305786, 41.16226077079773, 46.69266629219055, 52.43265438079834, 58.47659659385681, 64.172527551651, 69.94287514686584, 75.79840111732483, 81.54659986495972, 87.24857592582703, 92.89454126358032, 98.3945198059082, 104.00616025924683, 109.63975977897644, 115.3644347190857, 120.97841548919678, 126.56898856163025, 132.61506485939026, 138.38124179840088, 144.5681688785553, 150.25577068328857, 155.89730787277222, 161.4004406929016, 167.10380506515503, 172.84343791007996, 178.53209042549133, 184.2894949913025, 189.92314100265503, 195.91204404830933, 201.60250973701477, 212.7045783996582]
[46.02, 53.48, 56.64, 57.2, 58.94, 61.8, 61.26, 58.7, 62.2, 60.72, 61.24, 62.46, 62.7, 62.04, 64.54, 65.3, 65.32, 64.72, 66.14, 63.88, 66.92, 67.3, 64.0, 66.0, 66.64, 66.66, 68.0, 67.6, 67.4, 67.48, 67.06, 66.68, 66.64, 66.92, 66.58, 67.38]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.477, Test loss: 1.270, Test accuracy: 48.92 

Round   0, Global train loss: 1.477, Global test loss: 2.382, Global test accuracy: 26.84 

Round   1, Train loss: 1.355, Test loss: 1.501, Test accuracy: 46.14 

Round   1, Global train loss: 1.355, Global test loss: 2.140, Global test accuracy: 31.26 

Round   2, Train loss: 1.224, Test loss: 1.217, Test accuracy: 53.44 

Round   2, Global train loss: 1.224, Global test loss: 2.232, Global test accuracy: 34.66 

Round   3, Train loss: 1.109, Test loss: 1.066, Test accuracy: 60.36 

Round   3, Global train loss: 1.109, Global test loss: 2.348, Global test accuracy: 36.70 

Round   4, Train loss: 1.025, Test loss: 1.343, Test accuracy: 55.82 

Round   4, Global train loss: 1.025, Global test loss: 2.268, Global test accuracy: 37.16 

Round   5, Train loss: 0.951, Test loss: 1.264, Test accuracy: 58.06 

Round   5, Global train loss: 0.951, Global test loss: 1.956, Global test accuracy: 43.62 

Round   6, Train loss: 0.855, Test loss: 1.081, Test accuracy: 63.20 

Round   6, Global train loss: 0.855, Global test loss: 1.830, Global test accuracy: 46.10 

Round   7, Train loss: 0.795, Test loss: 1.188, Test accuracy: 62.74 

Round   7, Global train loss: 0.795, Global test loss: 1.860, Global test accuracy: 46.52 

Round   8, Train loss: 0.737, Test loss: 1.147, Test accuracy: 63.94 

Round   8, Global train loss: 0.737, Global test loss: 1.680, Global test accuracy: 50.26 

Round   9, Train loss: 0.654, Test loss: 1.124, Test accuracy: 66.06 

Round   9, Global train loss: 0.654, Global test loss: 1.721, Global test accuracy: 50.08 

Round  10, Train loss: 0.626, Test loss: 1.364, Test accuracy: 63.54 

Round  10, Global train loss: 0.626, Global test loss: 1.488, Global test accuracy: 54.88 

Round  11, Train loss: 0.571, Test loss: 1.156, Test accuracy: 66.04 

Round  11, Global train loss: 0.571, Global test loss: 1.621, Global test accuracy: 53.28 

Round  12, Train loss: 0.530, Test loss: 1.085, Test accuracy: 69.40 

Round  12, Global train loss: 0.530, Global test loss: 1.678, Global test accuracy: 54.82 

Round  13, Train loss: 0.490, Test loss: 1.148, Test accuracy: 68.44 

Round  13, Global train loss: 0.490, Global test loss: 1.363, Global test accuracy: 59.08 

Round  14, Train loss: 0.452, Test loss: 1.270, Test accuracy: 66.58 

Round  14, Global train loss: 0.452, Global test loss: 1.558, Global test accuracy: 57.32 

Round  15, Train loss: 0.425, Test loss: 1.187, Test accuracy: 68.12 

Round  15, Global train loss: 0.425, Global test loss: 1.240, Global test accuracy: 62.20 

Round  16, Train loss: 0.399, Test loss: 1.191, Test accuracy: 69.70 

Round  16, Global train loss: 0.399, Global test loss: 1.368, Global test accuracy: 59.18 

Round  17, Train loss: 0.367, Test loss: 1.113, Test accuracy: 71.50 

Round  17, Global train loss: 0.367, Global test loss: 1.390, Global test accuracy: 60.08 

Round  18, Train loss: 0.342, Test loss: 1.037, Test accuracy: 72.28 

Round  18, Global train loss: 0.342, Global test loss: 1.352, Global test accuracy: 61.04 

Round  19, Train loss: 0.310, Test loss: 1.169, Test accuracy: 70.02 

Round  19, Global train loss: 0.310, Global test loss: 1.352, Global test accuracy: 60.68 

Round  20, Train loss: 0.303, Test loss: 1.106, Test accuracy: 71.78 

Round  20, Global train loss: 0.303, Global test loss: 1.384, Global test accuracy: 61.76 

Round  21, Train loss: 0.279, Test loss: 1.053, Test accuracy: 73.62 

Round  21, Global train loss: 0.279, Global test loss: 1.304, Global test accuracy: 63.14 

Round  22, Train loss: 0.263, Test loss: 1.013, Test accuracy: 74.14 

Round  22, Global train loss: 0.263, Global test loss: 1.356, Global test accuracy: 62.16 

Round  23, Train loss: 0.237, Test loss: 1.042, Test accuracy: 73.98 

Round  23, Global train loss: 0.237, Global test loss: 1.365, Global test accuracy: 62.82 

Round  24, Train loss: 0.224, Test loss: 1.101, Test accuracy: 73.70 

Round  24, Global train loss: 0.224, Global test loss: 1.350, Global test accuracy: 63.16 

Round  25, Train loss: 0.221, Test loss: 1.050, Test accuracy: 74.30 

Round  25, Global train loss: 0.221, Global test loss: 1.377, Global test accuracy: 62.86 

Round  26, Train loss: 0.208, Test loss: 1.068, Test accuracy: 74.06 

Round  26, Global train loss: 0.208, Global test loss: 1.369, Global test accuracy: 63.44 

Round  27, Train loss: 0.188, Test loss: 1.041, Test accuracy: 74.70 

Round  27, Global train loss: 0.188, Global test loss: 1.287, Global test accuracy: 64.10 

Round  28, Train loss: 0.172, Test loss: 1.144, Test accuracy: 74.70 

Round  28, Global train loss: 0.172, Global test loss: 1.241, Global test accuracy: 65.90 

Round  29, Train loss: 0.168, Test loss: 1.141, Test accuracy: 75.14 

Round  29, Global train loss: 0.168, Global test loss: 1.394, Global test accuracy: 64.36 

Round  30, Train loss: 0.176, Test loss: 1.340, Test accuracy: 71.26 

Round  30, Global train loss: 0.176, Global test loss: 1.477, Global test accuracy: 62.90 

Round  31, Train loss: 0.140, Test loss: 1.148, Test accuracy: 75.86 

Round  31, Global train loss: 0.140, Global test loss: 1.230, Global test accuracy: 66.90 

Round  32, Train loss: 0.139, Test loss: 1.045, Test accuracy: 75.98 

Round  32, Global train loss: 0.139, Global test loss: 1.299, Global test accuracy: 65.80 

Round  33, Train loss: 0.138, Test loss: 1.232, Test accuracy: 73.68 

Round  33, Global train loss: 0.138, Global test loss: 1.271, Global test accuracy: 65.94 

Round  34, Train loss: 0.117, Test loss: 1.130, Test accuracy: 74.74 

Round  34, Global train loss: 0.117, Global test loss: 1.253, Global test accuracy: 67.54 

Round  35, Train loss: 0.138, Test loss: 1.057, Test accuracy: 75.46 

Round  35, Global train loss: 0.138, Global test loss: 1.272, Global test accuracy: 66.82 

Round  36, Train loss: 0.098, Test loss: 1.181, Test accuracy: 74.44 

Round  36, Global train loss: 0.098, Global test loss: 1.354, Global test accuracy: 66.36 

Round  37, Train loss: 0.109, Test loss: 1.285, Test accuracy: 74.30 

Round  37, Global train loss: 0.109, Global test loss: 1.337, Global test accuracy: 66.90 

Round  38, Train loss: 0.107, Test loss: 1.191, Test accuracy: 75.84 

Round  38, Global train loss: 0.107, Global test loss: 1.338, Global test accuracy: 67.10 

Round  39, Train loss: 0.099, Test loss: 1.183, Test accuracy: 75.62 

Round  39, Global train loss: 0.099, Global test loss: 1.319, Global test accuracy: 67.26 

Round  40, Train loss: 0.104, Test loss: 1.366, Test accuracy: 73.30 

Round  40, Global train loss: 0.104, Global test loss: 1.209, Global test accuracy: 68.54 

Round  41, Train loss: 0.096, Test loss: 1.070, Test accuracy: 76.72 

Round  41, Global train loss: 0.096, Global test loss: 1.315, Global test accuracy: 67.40 

Round  42, Train loss: 0.066, Test loss: 1.134, Test accuracy: 75.82 

Round  42, Global train loss: 0.066, Global test loss: 1.330, Global test accuracy: 67.14 

Round  43, Train loss: 0.083, Test loss: 1.171, Test accuracy: 76.04 

Round  43, Global train loss: 0.083, Global test loss: 1.214, Global test accuracy: 68.42 

Round  44, Train loss: 0.085, Test loss: 1.196, Test accuracy: 74.42 

Round  44, Global train loss: 0.085, Global test loss: 1.351, Global test accuracy: 66.62 

Round  45, Train loss: 0.070, Test loss: 1.136, Test accuracy: 76.94 

Round  45, Global train loss: 0.070, Global test loss: 1.371, Global test accuracy: 66.80 

Round  46, Train loss: 0.070, Test loss: 1.100, Test accuracy: 76.54 

Round  46, Global train loss: 0.070, Global test loss: 1.281, Global test accuracy: 68.50 

Round  47, Train loss: 0.078, Test loss: 1.052, Test accuracy: 77.30 

Round  47, Global train loss: 0.078, Global test loss: 1.306, Global test accuracy: 67.48 

Round  48, Train loss: 0.065, Test loss: 1.142, Test accuracy: 76.30 

Round  48, Global train loss: 0.065, Global test loss: 1.347, Global test accuracy: 67.54 

Round  49, Train loss: 0.056, Test loss: 1.166, Test accuracy: 76.68 

Round  49, Global train loss: 0.056, Global test loss: 1.349, Global test accuracy: 67.16 

Final Round, Train loss: 0.069, Test loss: 1.128, Test accuracy: 76.70 

Final Round, Global train loss: 0.069, Global test loss: 1.349, Global test accuracy: 67.16 

Average accuracy final 10 rounds: 76.006 

Average global accuracy final 10 rounds: 67.55999999999999 

1779.4601571559906
[7.831376552581787, 13.484658479690552, 19.102294445037842, 24.886919260025024, 30.438570261001587, 36.471806049346924, 42.22342038154602, 47.78381681442261, 53.675503969192505, 59.22014808654785, 64.84857273101807, 70.37985062599182, 76.04101967811584, 81.62400341033936, 87.48963856697083, 93.12966585159302, 99.07819533348083, 104.7132339477539, 110.40733289718628, 116.1128294467926, 121.8496162891388, 127.45522713661194, 133.12871408462524, 138.81537103652954, 144.50709199905396, 150.145977973938, 155.80173659324646, 161.318350315094, 167.2359721660614, 172.78522753715515, 178.47945499420166, 184.09713077545166, 190.0662682056427, 195.97256898880005, 201.6222367286682, 207.38138389587402, 213.20263600349426, 218.8468689918518, 224.57492089271545, 230.2402057647705, 235.88755679130554, 241.5310091972351, 247.1877887248993, 252.9137523174286, 258.4591636657715, 264.2185871601105, 269.7831904888153, 275.49975395202637, 281.0770766735077, 286.6764123439789, 297.90171122550964]
[48.92, 46.14, 53.44, 60.36, 55.82, 58.06, 63.2, 62.74, 63.94, 66.06, 63.54, 66.04, 69.4, 68.44, 66.58, 68.12, 69.7, 71.5, 72.28, 70.02, 71.78, 73.62, 74.14, 73.98, 73.7, 74.3, 74.06, 74.7, 74.7, 75.14, 71.26, 75.86, 75.98, 73.68, 74.74, 75.46, 74.44, 74.3, 75.84, 75.62, 73.3, 76.72, 75.82, 76.04, 74.42, 76.94, 76.54, 77.3, 76.3, 76.68, 76.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.569, Test loss: 1.759, Test accuracy: 26.82 

Round   1, Train loss: 1.421, Test loss: 1.682, Test accuracy: 32.56 

Round   2, Train loss: 1.277, Test loss: 1.170, Test accuracy: 50.64 

Round   3, Train loss: 1.169, Test loss: 1.253, Test accuracy: 48.18 

Round   4, Train loss: 1.091, Test loss: 1.074, Test accuracy: 57.28 

Round   5, Train loss: 1.033, Test loss: 1.062, Test accuracy: 55.98 

Round   6, Train loss: 0.974, Test loss: 1.022, Test accuracy: 58.42 

Round   7, Train loss: 0.914, Test loss: 1.021, Test accuracy: 61.54 

Round   8, Train loss: 0.864, Test loss: 0.977, Test accuracy: 61.32 

Round   9, Train loss: 0.828, Test loss: 0.916, Test accuracy: 64.42 

Round  10, Train loss: 0.768, Test loss: 0.852, Test accuracy: 66.92 

Round  11, Train loss: 0.744, Test loss: 0.884, Test accuracy: 66.06 

Round  12, Train loss: 0.696, Test loss: 0.863, Test accuracy: 67.70 

Round  13, Train loss: 0.648, Test loss: 0.774, Test accuracy: 71.12 

Round  14, Train loss: 0.613, Test loss: 0.751, Test accuracy: 71.60 

Round  15, Train loss: 0.578, Test loss: 0.900, Test accuracy: 67.42 

Round  16, Train loss: 0.563, Test loss: 0.791, Test accuracy: 72.62 

Round  17, Train loss: 0.511, Test loss: 0.815, Test accuracy: 70.86 

Round  18, Train loss: 0.491, Test loss: 0.815, Test accuracy: 71.60 

Round  19, Train loss: 0.476, Test loss: 0.735, Test accuracy: 74.42 

Round  20, Train loss: 0.432, Test loss: 0.719, Test accuracy: 74.66 

Round  21, Train loss: 0.411, Test loss: 0.746, Test accuracy: 73.58 

Round  22, Train loss: 0.388, Test loss: 0.743, Test accuracy: 74.18 

Round  23, Train loss: 0.368, Test loss: 0.750, Test accuracy: 75.42 

Round  24, Train loss: 0.341, Test loss: 0.758, Test accuracy: 74.28 

Round  25, Train loss: 0.321, Test loss: 0.753, Test accuracy: 74.90 

Round  26, Train loss: 0.325, Test loss: 0.788, Test accuracy: 74.90 

Round  27, Train loss: 0.291, Test loss: 0.739, Test accuracy: 75.08 

Round  28, Train loss: 0.283, Test loss: 0.771, Test accuracy: 75.50 

Round  29, Train loss: 0.266, Test loss: 0.728, Test accuracy: 76.36 

Round  30, Train loss: 0.242, Test loss: 0.747, Test accuracy: 76.32 

Round  31, Train loss: 0.226, Test loss: 0.735, Test accuracy: 77.20 

Round  32, Train loss: 0.217, Test loss: 0.754, Test accuracy: 76.70 

Round  33, Train loss: 0.200, Test loss: 0.762, Test accuracy: 76.62 

Round  34, Train loss: 0.198, Test loss: 0.743, Test accuracy: 77.00 

Round  35, Train loss: 0.168, Test loss: 0.762, Test accuracy: 76.88 

Round  36, Train loss: 0.174, Test loss: 0.744, Test accuracy: 77.14 

Round  37, Train loss: 0.163, Test loss: 0.750, Test accuracy: 77.12 

Round  38, Train loss: 0.143, Test loss: 0.759, Test accuracy: 77.28 

Round  39, Train loss: 0.137, Test loss: 0.801, Test accuracy: 77.04 

Round  40, Train loss: 0.145, Test loss: 0.774, Test accuracy: 76.90 

Round  41, Train loss: 0.124, Test loss: 0.793, Test accuracy: 77.34 

Round  42, Train loss: 0.113, Test loss: 0.797, Test accuracy: 77.56 

Round  43, Train loss: 0.110, Test loss: 0.794, Test accuracy: 77.52 

Round  44, Train loss: 0.105, Test loss: 0.779, Test accuracy: 77.66 

Round  45, Train loss: 0.113, Test loss: 0.782, Test accuracy: 77.86 

Round  46, Train loss: 0.094, Test loss: 0.811, Test accuracy: 77.40 

Round  47, Train loss: 0.065, Test loss: 0.809, Test accuracy: 77.38 

Round  48, Train loss: 0.075, Test loss: 0.784, Test accuracy: 77.32 

Round  49, Train loss: 0.085, Test loss: 0.806, Test accuracy: 77.70 

Final Round, Train loss: 0.049, Test loss: 0.830, Test accuracy: 77.30 

Average accuracy final 10 rounds: 77.464 

1300.817446231842
[6.3085644245147705, 10.699783563613892, 15.299410820007324, 19.820488214492798, 24.276795148849487, 28.887524127960205, 33.482725858688354, 37.897807598114014, 42.3351309299469, 46.83591651916504, 51.39725089073181, 55.696017026901245, 60.792632818222046, 65.33659720420837, 69.74589443206787, 74.15854525566101, 78.77773880958557, 83.22848987579346, 87.62848138809204, 92.26198959350586, 96.80556130409241, 101.31634473800659, 106.13671350479126, 110.59237742424011, 115.02196788787842, 119.60457706451416, 124.28315496444702, 128.92387652397156, 133.7182629108429, 138.2386393547058, 143.12782263755798, 147.50789856910706, 151.79577445983887, 156.24507308006287, 160.74525618553162, 165.42887473106384, 169.89503073692322, 174.3642327785492, 178.77573370933533, 183.29405236244202, 187.91053557395935, 192.3567988872528, 197.1004467010498, 201.84913444519043, 206.42903780937195, 210.8269805908203, 215.56866931915283, 220.14757323265076, 224.752685546875, 229.17574882507324, 233.76003050804138]
[26.82, 32.56, 50.64, 48.18, 57.28, 55.98, 58.42, 61.54, 61.32, 64.42, 66.92, 66.06, 67.7, 71.12, 71.6, 67.42, 72.62, 70.86, 71.6, 74.42, 74.66, 73.58, 74.18, 75.42, 74.28, 74.9, 74.9, 75.08, 75.5, 76.36, 76.32, 77.2, 76.7, 76.62, 77.0, 76.88, 77.14, 77.12, 77.28, 77.04, 76.9, 77.34, 77.56, 77.52, 77.66, 77.86, 77.4, 77.38, 77.32, 77.7, 77.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.575, Test loss: 1.849, Test accuracy: 24.76
Round   1, Train loss: 1.371, Test loss: 1.644, Test accuracy: 32.04
Round   2, Train loss: 1.248, Test loss: 1.392, Test accuracy: 41.84
Round   3, Train loss: 1.148, Test loss: 1.292, Test accuracy: 46.66
Round   4, Train loss: 1.077, Test loss: 1.113, Test accuracy: 54.84
Round   5, Train loss: 1.026, Test loss: 1.109, Test accuracy: 55.84
Round   6, Train loss: 0.964, Test loss: 1.012, Test accuracy: 59.60
Round   7, Train loss: 0.917, Test loss: 1.043, Test accuracy: 58.44
Round   8, Train loss: 0.865, Test loss: 0.903, Test accuracy: 63.90
Round   9, Train loss: 0.820, Test loss: 0.857, Test accuracy: 66.14
Round  10, Train loss: 0.766, Test loss: 0.843, Test accuracy: 67.08
Round  11, Train loss: 0.711, Test loss: 0.813, Test accuracy: 68.18
Round  12, Train loss: 0.673, Test loss: 0.868, Test accuracy: 66.76
Round  13, Train loss: 0.639, Test loss: 0.789, Test accuracy: 70.14
Round  14, Train loss: 0.600, Test loss: 0.782, Test accuracy: 70.60
Round  15, Train loss: 0.551, Test loss: 0.781, Test accuracy: 71.04
Round  16, Train loss: 0.541, Test loss: 0.717, Test accuracy: 73.60
Round  17, Train loss: 0.514, Test loss: 0.821, Test accuracy: 70.52
Round  18, Train loss: 0.478, Test loss: 0.787, Test accuracy: 72.42
Round  19, Train loss: 0.446, Test loss: 0.748, Test accuracy: 73.76
Round  20, Train loss: 0.415, Test loss: 0.681, Test accuracy: 75.80
Round  21, Train loss: 0.403, Test loss: 0.774, Test accuracy: 73.84
Round  22, Train loss: 0.385, Test loss: 0.668, Test accuracy: 76.42
Round  23, Train loss: 0.348, Test loss: 0.719, Test accuracy: 74.76
Round  24, Train loss: 0.334, Test loss: 0.705, Test accuracy: 75.84
Round  25, Train loss: 0.313, Test loss: 0.721, Test accuracy: 75.92
Round  26, Train loss: 0.306, Test loss: 0.703, Test accuracy: 76.24
Round  27, Train loss: 0.288, Test loss: 0.720, Test accuracy: 76.08
Round  28, Train loss: 0.252, Test loss: 0.689, Test accuracy: 77.28
Round  29, Train loss: 0.251, Test loss: 0.697, Test accuracy: 77.04
Round  30, Train loss: 0.249, Test loss: 0.704, Test accuracy: 77.12
Round  31, Train loss: 0.214, Test loss: 0.683, Test accuracy: 77.96
Round  32, Train loss: 0.205, Test loss: 0.719, Test accuracy: 77.08
Round  33, Train loss: 0.200, Test loss: 0.696, Test accuracy: 77.80
Round  34, Train loss: 0.181, Test loss: 0.690, Test accuracy: 78.34
Round  35, Train loss: 0.174, Test loss: 0.686, Test accuracy: 78.44
Round  36, Train loss: 0.158, Test loss: 0.687, Test accuracy: 78.80
Round  37, Train loss: 0.155, Test loss: 0.702, Test accuracy: 78.32
Round  38, Train loss: 0.144, Test loss: 0.730, Test accuracy: 77.92
Round  39, Train loss: 0.141, Test loss: 0.728, Test accuracy: 77.68
Round  40, Train loss: 0.127, Test loss: 0.719, Test accuracy: 78.68
Round  41, Train loss: 0.124, Test loss: 0.705, Test accuracy: 78.92
Round  42, Train loss: 0.112, Test loss: 0.739, Test accuracy: 78.86
Round  43, Train loss: 0.101, Test loss: 0.736, Test accuracy: 78.44
Round  44, Train loss: 0.105, Test loss: 0.742, Test accuracy: 78.32
Round  45, Train loss: 0.086, Test loss: 0.726, Test accuracy: 79.02
Round  46, Train loss: 0.082, Test loss: 0.744, Test accuracy: 78.84
Round  47, Train loss: 0.077, Test loss: 0.763, Test accuracy: 78.58
Round  48, Train loss: 0.106, Test loss: 0.731, Test accuracy: 78.96
Round  49, Train loss: 0.077, Test loss: 0.742, Test accuracy: 79.24
Final Round, Train loss: 0.041, Test loss: 0.729, Test accuracy: 79.30
Average accuracy final 10 rounds: 78.786
1430.2007024288177
[6.805386066436768, 11.801088571548462, 16.828428745269775, 21.887386560440063, 27.16110897064209, 32.284968852996826, 37.08956432342529, 42.20206308364868, 47.753384828567505, 53.048377990722656, 58.098591566085815, 63.08314847946167, 68.07233667373657, 73.3606390953064, 78.31309723854065, 83.32930111885071, 88.46402859687805, 93.39071273803711, 98.58957195281982, 103.52736282348633, 108.5242109298706, 114.0298490524292, 119.60626482963562, 124.84431767463684, 130.18386554718018, 135.30588293075562, 140.40271043777466, 145.4595181941986, 150.53334307670593, 155.59276914596558, 160.69531893730164, 165.6890151500702, 170.84422850608826, 175.78906297683716, 181.28851628303528, 186.5420503616333, 191.49769639968872, 196.41006422042847, 201.5032947063446, 206.60452890396118, 211.74235439300537, 216.98645114898682, 221.97629261016846, 227.15847373008728, 232.28176712989807, 237.49318432807922, 242.31734037399292, 247.4202914237976, 252.29134273529053, 257.1591703891754, 262.08780431747437]
[24.76, 32.04, 41.84, 46.66, 54.84, 55.84, 59.6, 58.44, 63.9, 66.14, 67.08, 68.18, 66.76, 70.14, 70.6, 71.04, 73.6, 70.52, 72.42, 73.76, 75.8, 73.84, 76.42, 74.76, 75.84, 75.92, 76.24, 76.08, 77.28, 77.04, 77.12, 77.96, 77.08, 77.8, 78.34, 78.44, 78.8, 78.32, 77.92, 77.68, 78.68, 78.92, 78.86, 78.44, 78.32, 79.02, 78.84, 78.58, 78.96, 79.24, 79.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 1.113, Train accuracy: 52.000, Test loss: 0.977, Test accuracy: 64.40 

        train local model (freeze embeding):client   0,  Train loss: 1.073, Train accuracy: 54.000, Test loss: 1.101, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.950, Train accuracy: 59.200, Test loss: 1.324, Test accuracy: 50.80 

Round   0, Train loss: 0.950, Test loss: 1.226, Test accuracy: 51.90 

        train local model (freeze embeding):client   0,  Train loss: 0.911, Train accuracy: 60.600, Test loss: 1.201, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.962, Train accuracy: 62.600, Test loss: 1.559, Test accuracy: 37.00 

Round   1, Train loss: 0.962, Test loss: 1.238, Test accuracy: 52.20 

        train local model (freeze embeding):client   0,  Train loss: 0.869, Train accuracy: 64.200, Test loss: 1.293, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.883, Train accuracy: 64.600, Test loss: 1.057, Test accuracy: 60.00 

Round   2, Train loss: 0.883, Test loss: 1.171, Test accuracy: 52.50 

        train local model (freeze embeding):client   0,  Train loss: 0.823, Train accuracy: 66.600, Test loss: 1.343, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.825, Train accuracy: 65.200, Test loss: 1.372, Test accuracy: 52.00 

Round   3, Train loss: 0.825, Test loss: 1.282, Test accuracy: 54.00 

        train local model (freeze embeding):client   0,  Train loss: 0.732, Train accuracy: 67.200, Test loss: 0.991, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.669, Train accuracy: 73.200, Test loss: 1.087, Test accuracy: 60.00 

Round   4, Train loss: 0.669, Test loss: 1.169, Test accuracy: 55.00 

        train local model (freeze embeding):client   0,  Train loss: 0.591, Train accuracy: 77.000, Test loss: 1.184, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.789, Train accuracy: 70.400, Test loss: 1.871, Test accuracy: 42.00 

Round   5, Train loss: 0.789, Test loss: 1.459, Test accuracy: 50.90 

        train local model (freeze embeding):client   0,  Train loss: 0.551, Train accuracy: 78.800, Test loss: 1.036, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.773, Train accuracy: 69.000, Test loss: 1.186, Test accuracy: 60.40 

Round   6, Train loss: 0.773, Test loss: 1.364, Test accuracy: 54.50 

        train local model (freeze embeding):client   0,  Train loss: 0.570, Train accuracy: 79.400, Test loss: 1.175, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.467, Train accuracy: 81.800, Test loss: 1.440, Test accuracy: 56.80 

Round   7, Train loss: 0.467, Test loss: 1.271, Test accuracy: 59.70 

        train local model (freeze embeding):client   0,  Train loss: 0.355, Train accuracy: 86.800, Test loss: 1.067, Test accuracy: 65.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.498, Train accuracy: 84.800, Test loss: 1.252, Test accuracy: 60.80 

Round   8, Train loss: 0.498, Test loss: 1.509, Test accuracy: 52.20 

        train local model (freeze embeding):client   0,  Train loss: 0.429, Train accuracy: 85.200, Test loss: 1.117, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.321, Train accuracy: 90.000, Test loss: 1.402, Test accuracy: 57.40 

Round   9, Train loss: 0.321, Test loss: 1.383, Test accuracy: 57.00 

        train local model (freeze embeding):client   0,  Train loss: 0.240, Train accuracy: 93.200, Test loss: 1.225, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.331, Train accuracy: 87.600, Test loss: 1.174, Test accuracy: 61.40 

Round  10, Train loss: 0.331, Test loss: 1.417, Test accuracy: 56.40 

        train local model (freeze embeding):client   0,  Train loss: 0.264, Train accuracy: 90.200, Test loss: 1.359, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.369, Train accuracy: 89.000, Test loss: 1.527, Test accuracy: 59.80 

Round  11, Train loss: 0.369, Test loss: 1.448, Test accuracy: 59.50 

        train local model (freeze embeding):client   0,  Train loss: 0.272, Train accuracy: 92.000, Test loss: 1.532, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.573, Train accuracy: 78.200, Test loss: 2.694, Test accuracy: 42.60 

Round  12, Train loss: 0.573, Test loss: 1.913, Test accuracy: 54.10 

        train local model (freeze embeding):client   0,  Train loss: 0.163, Train accuracy: 95.600, Test loss: 1.277, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.217, Train accuracy: 93.000, Test loss: 1.674, Test accuracy: 55.20 

Round  13, Train loss: 0.217, Test loss: 1.526, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 0.135, Train accuracy: 96.200, Test loss: 1.185, Test accuracy: 66.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.213, Train accuracy: 91.200, Test loss: 1.738, Test accuracy: 58.80 

Round  14, Train loss: 0.213, Test loss: 1.791, Test accuracy: 56.30 

        train local model (freeze embeding):client   0,  Train loss: 0.145, Train accuracy: 95.800, Test loss: 1.528, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.164, Train accuracy: 94.400, Test loss: 1.337, Test accuracy: 65.60 

Round  15, Train loss: 0.164, Test loss: 1.696, Test accuracy: 62.30 

        train local model (freeze embeding):client   0,  Train loss: 0.094, Train accuracy: 97.400, Test loss: 1.295, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.169, Train accuracy: 93.400, Test loss: 1.568, Test accuracy: 61.40 

Round  16, Train loss: 0.169, Test loss: 1.632, Test accuracy: 59.10 

        train local model (freeze embeding):client   0,  Train loss: 0.087, Train accuracy: 96.800, Test loss: 1.647, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.074, Train accuracy: 97.600, Test loss: 1.420, Test accuracy: 70.00 

Round  17, Train loss: 0.074, Test loss: 1.772, Test accuracy: 62.00 

        train local model (freeze embeding):client   0,  Train loss: 0.044, Train accuracy: 98.200, Test loss: 1.528, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.113, Train accuracy: 96.000, Test loss: 1.887, Test accuracy: 59.40 

Round  18, Train loss: 0.113, Test loss: 1.923, Test accuracy: 58.70 

        train local model (freeze embeding):client   0,  Train loss: 0.059, Train accuracy: 98.400, Test loss: 1.861, Test accuracy: 59.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.103, Train accuracy: 98.000, Test loss: 1.757, Test accuracy: 59.00 

Round  19, Train loss: 0.103, Test loss: 1.717, Test accuracy: 60.40 

        train local model (freeze embeding):client   0,  Train loss: 0.074, Train accuracy: 98.200, Test loss: 1.548, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.116, Train accuracy: 95.800, Test loss: 1.491, Test accuracy: 65.20 

Final Round, Train loss: 0.116, Test loss: 1.618, Test accuracy: 63.00 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 0.952, Train accuracy: 58.400, Test loss: 1.032, Test accuracy: 59.80 

        train local model (freeze embeding):client   0,  Train loss: 0.073, Train accuracy: 98.400, Test loss: 1.377, Test accuracy: 66.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.064, Train accuracy: 98.400, Test loss: 1.749, Test accuracy: 62.20 

        train local model (freeze embeding):client   1,  Train loss: 0.909, Train accuracy: 61.600, Test loss: 0.944, Test accuracy: 65.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.610, Train accuracy: 74.400, Test loss: 1.203, Test accuracy: 59.00 

Round   0, Train loss: 0.337, Test loss: 1.264, Test accuracy: 62.75 

        train local model (freeze embeding):client   0,  Train loss: 0.044, Train accuracy: 99.000, Test loss: 1.252, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.111, Train accuracy: 96.200, Test loss: 1.584, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 0.662, Train accuracy: 74.000, Test loss: 1.071, Test accuracy: 65.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.507, Train accuracy: 79.400, Test loss: 0.926, Test accuracy: 73.60 

Round   1, Train loss: 0.309, Test loss: 1.298, Test accuracy: 62.85 

        train local model (freeze embeding):client   0,  Train loss: 0.047, Train accuracy: 98.400, Test loss: 1.361, Test accuracy: 65.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.093, Train accuracy: 96.600, Test loss: 1.720, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.552, Train accuracy: 78.400, Test loss: 0.954, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.625, Train accuracy: 77.000, Test loss: 1.128, Test accuracy: 65.40 

Round   2, Train loss: 0.359, Test loss: 1.366, Test accuracy: 62.85 

        train local model (freeze embeding):client   0,  Train loss: 0.044, Train accuracy: 99.200, Test loss: 1.523, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.149, Train accuracy: 94.800, Test loss: 1.621, Test accuracy: 68.00 

        train local model (freeze embeding):client   1,  Train loss: 0.443, Train accuracy: 85.200, Test loss: 0.871, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.360, Train accuracy: 86.200, Test loss: 1.222, Test accuracy: 68.40 

Round   3, Train loss: 0.255, Test loss: 1.465, Test accuracy: 64.30 

        train local model (freeze embeding):client   0,  Train loss: 0.036, Train accuracy: 99.000, Test loss: 1.640, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.057, Train accuracy: 98.400, Test loss: 1.571, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.343, Train accuracy: 88.200, Test loss: 1.059, Test accuracy: 65.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.482, Train accuracy: 84.400, Test loss: 1.092, Test accuracy: 72.20 

Round   4, Train loss: 0.269, Test loss: 1.376, Test accuracy: 63.55 

        train local model (freeze embeding):client   0,  Train loss: 0.027, Train accuracy: 99.800, Test loss: 1.377, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.091, Train accuracy: 97.400, Test loss: 2.295, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.264, Train accuracy: 92.000, Test loss: 0.926, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.317, Train accuracy: 87.400, Test loss: 1.153, Test accuracy: 69.20 

Round   5, Train loss: 0.204, Test loss: 1.436, Test accuracy: 63.50 

        train local model (freeze embeding):client   0,  Train loss: 0.031, Train accuracy: 99.600, Test loss: 1.389, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.032, Train accuracy: 99.200, Test loss: 1.947, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 0.202, Train accuracy: 94.200, Test loss: 1.126, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.242, Train accuracy: 90.600, Test loss: 1.733, Test accuracy: 60.60 

Round   6, Train loss: 0.137, Test loss: 1.512, Test accuracy: 63.80 

        train local model (freeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 1.841, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.600, Test loss: 1.698, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.173, Train accuracy: 94.800, Test loss: 1.296, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.228, Train accuracy: 92.600, Test loss: 1.356, Test accuracy: 67.80 

Round   7, Train loss: 0.128, Test loss: 1.496, Test accuracy: 63.95 

        train local model (freeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.695, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.083, Train accuracy: 97.800, Test loss: 1.735, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.123, Train accuracy: 98.200, Test loss: 1.189, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.146, Train accuracy: 94.600, Test loss: 1.161, Test accuracy: 69.20 

Round   8, Train loss: 0.114, Test loss: 1.432, Test accuracy: 64.90 

        train local model (freeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.600, Test loss: 1.585, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.039, Train accuracy: 98.800, Test loss: 1.605, Test accuracy: 63.40 

        train local model (freeze embeding):client   1,  Train loss: 0.105, Train accuracy: 97.800, Test loss: 1.185, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.180, Train accuracy: 94.200, Test loss: 1.879, Test accuracy: 61.60 

Round   9, Train loss: 0.109, Test loss: 1.448, Test accuracy: 64.45 

        train local model (freeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.452, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.042, Train accuracy: 98.600, Test loss: 1.674, Test accuracy: 63.40 

        train local model (freeze embeding):client   1,  Train loss: 0.120, Train accuracy: 96.400, Test loss: 1.227, Test accuracy: 68.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.195, Train accuracy: 92.200, Test loss: 1.290, Test accuracy: 67.80 

Round  10, Train loss: 0.118, Test loss: 1.524, Test accuracy: 63.65 

        train local model (freeze embeding):client   0,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.460, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.070, Train accuracy: 98.000, Test loss: 1.634, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.081, Train accuracy: 98.400, Test loss: 1.309, Test accuracy: 66.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.213, Train accuracy: 92.000, Test loss: 1.443, Test accuracy: 65.60 

Round  11, Train loss: 0.142, Test loss: 1.443, Test accuracy: 64.40 

        train local model (freeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.400, Test loss: 1.557, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.200, Test loss: 1.772, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.087, Train accuracy: 98.600, Test loss: 1.096, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.108, Train accuracy: 97.000, Test loss: 1.360, Test accuracy: 71.80 

Round  12, Train loss: 0.063, Test loss: 1.547, Test accuracy: 65.70 

        train local model (freeze embeding):client   0,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 1.617, Test accuracy: 66.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.600, Test loss: 1.692, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 0.043, Train accuracy: 99.000, Test loss: 1.381, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.181, Train accuracy: 93.600, Test loss: 1.163, Test accuracy: 76.00 

Round  13, Train loss: 0.096, Test loss: 1.582, Test accuracy: 66.40 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.471, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.046, Train accuracy: 98.800, Test loss: 2.513, Test accuracy: 59.20 

        train local model (freeze embeding):client   1,  Train loss: 0.043, Train accuracy: 98.800, Test loss: 1.411, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.131, Train accuracy: 96.200, Test loss: 1.133, Test accuracy: 77.80 

Round  14, Train loss: 0.089, Test loss: 1.760, Test accuracy: 65.15 

        train local model (freeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.720, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.468, Test accuracy: 69.80 

        train local model (freeze embeding):client   1,  Train loss: 0.032, Train accuracy: 99.400, Test loss: 1.311, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.066, Train accuracy: 97.800, Test loss: 1.611, Test accuracy: 68.60 

Round  15, Train loss: 0.039, Test loss: 1.721, Test accuracy: 65.45 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.664, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.067, Train accuracy: 97.800, Test loss: 2.979, Test accuracy: 53.40 

        train local model (freeze embeding):client   1,  Train loss: 0.034, Train accuracy: 98.800, Test loss: 1.777, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.125, Train accuracy: 95.200, Test loss: 2.346, Test accuracy: 57.00 

Round  16, Train loss: 0.096, Test loss: 1.716, Test accuracy: 64.80 

        train local model (freeze embeding):client   0,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 1.686, Test accuracy: 66.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.200, Test loss: 2.388, Test accuracy: 58.80 

        train local model (freeze embeding):client   1,  Train loss: 0.027, Train accuracy: 99.600, Test loss: 1.663, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.057, Train accuracy: 98.200, Test loss: 1.522, Test accuracy: 72.60 

Round  17, Train loss: 0.040, Test loss: 1.776, Test accuracy: 64.80 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.773, Test accuracy: 66.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.030, Train accuracy: 99.200, Test loss: 2.023, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 1.501, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.175, Train accuracy: 93.800, Test loss: 1.301, Test accuracy: 70.80 

Round  18, Train loss: 0.103, Test loss: 1.688, Test accuracy: 65.55 

        train local model (freeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.554, Test accuracy: 67.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 2.552, Test accuracy: 59.20 

        train local model (freeze embeding):client   1,  Train loss: 0.023, Train accuracy: 99.400, Test loss: 1.369, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.118, Train accuracy: 96.400, Test loss: 1.745, Test accuracy: 70.20 

Round  19, Train loss: 0.068, Test loss: 1.801, Test accuracy: 65.10 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.604, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.613, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.021, Train accuracy: 99.600, Test loss: 1.385, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.033, Train accuracy: 98.800, Test loss: 2.336, Test accuracy: 67.80 

Final Round, Train loss: 0.031, Test loss: 1.727, Test accuracy: 65.80 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 0.717, Train accuracy: 71.800, Test loss: 1.190, Test accuracy: 52.20 

        train local model (freeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.815, Test accuracy: 65.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.837, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.020, Train accuracy: 99.800, Test loss: 1.363, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.052, Train accuracy: 98.200, Test loss: 1.818, Test accuracy: 66.60 

        train local model (freeze embeding):client   2,  Train loss: 0.695, Train accuracy: 70.800, Test loss: 1.262, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.408, Train accuracy: 86.400, Test loss: 1.541, Test accuracy: 55.40 

Round   0, Train loss: 0.155, Test loss: 1.416, Test accuracy: 66.80 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.519, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.053, Train accuracy: 97.600, Test loss: 1.517, Test accuracy: 74.80 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 1.463, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.065, Train accuracy: 97.800, Test loss: 1.553, Test accuracy: 68.80 

        train local model (freeze embeding):client   2,  Train loss: 0.415, Train accuracy: 85.200, Test loss: 1.273, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.233, Train accuracy: 92.800, Test loss: 1.334, Test accuracy: 59.80 

Round   1, Train loss: 0.117, Test loss: 1.357, Test accuracy: 67.97 

        train local model (freeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.452, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.043, Train accuracy: 98.200, Test loss: 2.160, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.349, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.072, Train accuracy: 97.200, Test loss: 1.622, Test accuracy: 66.40 

        train local model (freeze embeding):client   2,  Train loss: 0.296, Train accuracy: 88.200, Test loss: 1.310, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.224, Train accuracy: 91.800, Test loss: 1.387, Test accuracy: 59.40 

Round   2, Train loss: 0.113, Test loss: 1.402, Test accuracy: 68.30 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.425, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.262, Test accuracy: 73.80 

        train local model (freeze embeding):client   1,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 1.311, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.056, Train accuracy: 98.400, Test loss: 1.572, Test accuracy: 72.40 

        train local model (freeze embeding):client   2,  Train loss: 0.240, Train accuracy: 92.800, Test loss: 1.205, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.152, Train accuracy: 94.800, Test loss: 1.825, Test accuracy: 58.00 

Round   3, Train loss: 0.073, Test loss: 1.342, Test accuracy: 68.03 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.649, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.056, Train accuracy: 98.400, Test loss: 2.483, Test accuracy: 60.60 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.215, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.178, Train accuracy: 92.800, Test loss: 2.355, Test accuracy: 61.00 

        train local model (freeze embeding):client   2,  Train loss: 0.138, Train accuracy: 96.800, Test loss: 1.296, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.168, Train accuracy: 95.200, Test loss: 1.258, Test accuracy: 67.80 

Round   4, Train loss: 0.134, Test loss: 1.478, Test accuracy: 67.80 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.487, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.683, Test accuracy: 69.00 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.049, Train accuracy: 98.000, Test loss: 1.712, Test accuracy: 72.40 

        train local model (freeze embeding):client   2,  Train loss: 0.111, Train accuracy: 97.000, Test loss: 1.211, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.118, Train accuracy: 94.800, Test loss: 1.615, Test accuracy: 61.00 

Round   5, Train loss: 0.059, Test loss: 1.409, Test accuracy: 68.57 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.497, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.000, Test loss: 1.991, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.345, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.102, Train accuracy: 96.600, Test loss: 2.282, Test accuracy: 64.20 

        train local model (freeze embeding):client   2,  Train loss: 0.065, Train accuracy: 99.000, Test loss: 1.097, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.061, Train accuracy: 98.400, Test loss: 1.344, Test accuracy: 68.40 

Round   6, Train loss: 0.062, Test loss: 1.446, Test accuracy: 68.77 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.702, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.080, Train accuracy: 97.400, Test loss: 2.261, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.565, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 100.000, Test loss: 2.051, Test accuracy: 66.20 

        train local model (freeze embeding):client   2,  Train loss: 0.051, Train accuracy: 99.000, Test loss: 1.276, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.155, Train accuracy: 95.400, Test loss: 2.229, Test accuracy: 55.00 

Round   7, Train loss: 0.084, Test loss: 1.479, Test accuracy: 68.00 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.571, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.041, Train accuracy: 98.400, Test loss: 1.549, Test accuracy: 73.60 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.338, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.059, Train accuracy: 98.600, Test loss: 1.162, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.038, Train accuracy: 99.600, Test loss: 1.340, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.086, Train accuracy: 96.800, Test loss: 1.623, Test accuracy: 64.20 

Round   8, Train loss: 0.062, Test loss: 1.392, Test accuracy: 69.60 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.348, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.053, Train accuracy: 97.800, Test loss: 1.991, Test accuracy: 60.00 

        train local model (freeze embeding):client   1,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.352, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.191, Train accuracy: 93.600, Test loss: 2.117, Test accuracy: 61.80 

        train local model (freeze embeding):client   2,  Train loss: 0.035, Train accuracy: 99.200, Test loss: 1.439, Test accuracy: 64.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.059, Train accuracy: 98.000, Test loss: 1.651, Test accuracy: 66.60 

Round   9, Train loss: 0.101, Test loss: 1.328, Test accuracy: 69.40 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.338, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.000, Test loss: 1.744, Test accuracy: 70.40 

        train local model (freeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.333, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.042, Train accuracy: 98.200, Test loss: 1.403, Test accuracy: 71.20 

        train local model (freeze embeding):client   2,  Train loss: 0.032, Train accuracy: 99.400, Test loss: 1.283, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.117, Train accuracy: 96.400, Test loss: 2.318, Test accuracy: 57.40 

Round  10, Train loss: 0.061, Test loss: 1.492, Test accuracy: 69.57 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.661, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.000, Test loss: 1.697, Test accuracy: 69.60 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.400, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.038, Train accuracy: 98.600, Test loss: 2.571, Test accuracy: 62.60 

        train local model (freeze embeding):client   2,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.499, Test accuracy: 67.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.085, Train accuracy: 97.000, Test loss: 1.815, Test accuracy: 62.20 

Round  11, Train loss: 0.049, Test loss: 1.524, Test accuracy: 69.90 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.548, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.751, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.336, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.024, Train accuracy: 99.200, Test loss: 1.678, Test accuracy: 72.60 

        train local model (freeze embeding):client   2,  Train loss: 0.021, Train accuracy: 99.600, Test loss: 1.224, Test accuracy: 69.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.141, Train accuracy: 95.400, Test loss: 2.102, Test accuracy: 62.60 

Round  12, Train loss: 0.059, Test loss: 1.604, Test accuracy: 69.10 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.788, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.716, Test accuracy: 70.60 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.692, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 99.000, Test loss: 2.051, Test accuracy: 62.60 

        train local model (freeze embeding):client   2,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.488, Test accuracy: 64.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.060, Train accuracy: 98.000, Test loss: 1.393, Test accuracy: 70.60 

Round  13, Train loss: 0.036, Test loss: 1.497, Test accuracy: 69.40 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.607, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.993, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.270, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.055, Train accuracy: 98.400, Test loss: 2.034, Test accuracy: 68.40 

        train local model (freeze embeding):client   2,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.251, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.051, Train accuracy: 98.600, Test loss: 1.897, Test accuracy: 58.20 

Round  14, Train loss: 0.036, Test loss: 1.506, Test accuracy: 69.73 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.729, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.031, Train accuracy: 98.800, Test loss: 2.282, Test accuracy: 61.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.562, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.044, Train accuracy: 98.600, Test loss: 1.773, Test accuracy: 71.40 

        train local model (freeze embeding):client   2,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.350, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.058, Train accuracy: 98.200, Test loss: 1.636, Test accuracy: 67.40 

Round  15, Train loss: 0.044, Test loss: 1.580, Test accuracy: 68.87 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.858, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.735, Test accuracy: 69.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.531, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.038, Train accuracy: 99.000, Test loss: 1.371, Test accuracy: 72.20 

        train local model (freeze embeding):client   2,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.227, Test accuracy: 67.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 1.411, Test accuracy: 69.60 

Round  16, Train loss: 0.020, Test loss: 1.451, Test accuracy: 70.03 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.656, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.052, Train accuracy: 97.600, Test loss: 2.274, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.486, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.817, Test accuracy: 71.80 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.465, Test accuracy: 66.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.046, Train accuracy: 98.800, Test loss: 2.609, Test accuracy: 54.60 

Round  17, Train loss: 0.034, Test loss: 1.660, Test accuracy: 69.17 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.814, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.881, Test accuracy: 72.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.614, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.063, Train accuracy: 97.600, Test loss: 1.888, Test accuracy: 68.20 

        train local model (freeze embeding):client   2,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.575, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.038, Train accuracy: 98.600, Test loss: 1.640, Test accuracy: 63.00 

Round  18, Train loss: 0.035, Test loss: 1.523, Test accuracy: 69.83 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.741, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.797, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.488, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.800, Test accuracy: 70.40 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.209, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.588, Test accuracy: 69.40 

Round  19, Train loss: 0.005, Test loss: 1.589, Test accuracy: 70.13 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.684, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.400, Test loss: 2.169, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.520, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.023, Train accuracy: 99.400, Test loss: 1.807, Test accuracy: 67.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.383, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.064, Train accuracy: 97.600, Test loss: 2.118, Test accuracy: 64.60 

Final Round, Train loss: 0.036, Test loss: 1.582, Test accuracy: 70.30 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 0.586, Train accuracy: 76.200, Test loss: 0.941, Test accuracy: 67.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.727, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.917, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.428, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 2.330, Test accuracy: 67.00 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.578, Test accuracy: 65.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.641, Test accuracy: 69.40 

        train local model (freeze embeding):client   3,  Train loss: 0.573, Train accuracy: 77.400, Test loss: 0.846, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.307, Train accuracy: 90.800, Test loss: 1.324, Test accuracy: 60.20 

Round   0, Train loss: 0.082, Test loss: 1.427, Test accuracy: 70.35 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.592, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.043, Train accuracy: 99.200, Test loss: 2.082, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.409, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.400, Test loss: 2.315, Test accuracy: 66.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.311, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.061, Train accuracy: 98.200, Test loss: 1.545, Test accuracy: 66.80 

        train local model (freeze embeding):client   3,  Train loss: 0.345, Train accuracy: 86.200, Test loss: 1.025, Test accuracy: 65.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.260, Train accuracy: 90.000, Test loss: 1.266, Test accuracy: 66.60 

Round   1, Train loss: 0.095, Test loss: 1.295, Test accuracy: 70.67 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.486, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.885, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.365, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.033, Train accuracy: 99.400, Test loss: 1.803, Test accuracy: 71.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.237, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.650, Test accuracy: 68.00 

        train local model (freeze embeding):client   3,  Train loss: 0.260, Train accuracy: 91.800, Test loss: 0.995, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.257, Train accuracy: 92.200, Test loss: 1.703, Test accuracy: 57.00 

Round   2, Train loss: 0.076, Test loss: 1.336, Test accuracy: 70.42 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.851, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.026, Train accuracy: 99.600, Test loss: 2.215, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.573, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.070, Train accuracy: 97.000, Test loss: 2.025, Test accuracy: 66.20 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.194, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.755, Test accuracy: 67.00 

        train local model (freeze embeding):client   3,  Train loss: 0.180, Train accuracy: 94.600, Test loss: 1.013, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.208, Train accuracy: 92.200, Test loss: 1.210, Test accuracy: 69.00 

Round   3, Train loss: 0.080, Test loss: 1.353, Test accuracy: 70.55 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.584, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.598, Test accuracy: 73.40 

        train local model (freeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.597, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.047, Train accuracy: 98.400, Test loss: 1.403, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.039, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.592, Test accuracy: 68.80 

        train local model (freeze embeding):client   3,  Train loss: 0.139, Train accuracy: 95.800, Test loss: 1.066, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.181, Train accuracy: 94.400, Test loss: 1.814, Test accuracy: 57.60 

Round   4, Train loss: 0.059, Test loss: 1.306, Test accuracy: 71.72 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.625, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.756, Test accuracy: 63.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.744, Test accuracy: 68.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.035, Train accuracy: 99.000, Test loss: 1.872, Test accuracy: 65.40 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.063, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 1.360, Test accuracy: 72.80 

        train local model (freeze embeding):client   3,  Train loss: 0.087, Train accuracy: 98.200, Test loss: 1.153, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.199, Train accuracy: 93.800, Test loss: 0.968, Test accuracy: 73.40 

Round   5, Train loss: 0.067, Test loss: 1.243, Test accuracy: 71.90 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.599, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 2.176, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.476, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.770, Test accuracy: 71.60 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.028, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.051, Train accuracy: 98.400, Test loss: 1.092, Test accuracy: 74.60 

        train local model (freeze embeding):client   3,  Train loss: 0.080, Train accuracy: 98.400, Test loss: 1.051, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.093, Train accuracy: 96.800, Test loss: 1.381, Test accuracy: 69.40 

Round   6, Train loss: 0.041, Test loss: 1.275, Test accuracy: 72.00 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.533, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.048, Train accuracy: 98.200, Test loss: 1.736, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.462, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.049, Train accuracy: 98.400, Test loss: 1.951, Test accuracy: 68.00 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.068, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.031, Train accuracy: 99.400, Test loss: 2.065, Test accuracy: 63.80 

        train local model (freeze embeding):client   3,  Train loss: 0.056, Train accuracy: 98.800, Test loss: 1.079, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.073, Train accuracy: 97.000, Test loss: 1.054, Test accuracy: 75.80 

Round   7, Train loss: 0.050, Test loss: 1.286, Test accuracy: 71.28 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.628, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.043, Train accuracy: 98.800, Test loss: 2.191, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.437, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.083, Train accuracy: 97.800, Test loss: 2.221, Test accuracy: 68.60 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.024, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.588, Test accuracy: 70.60 

        train local model (freeze embeding):client   3,  Train loss: 0.048, Train accuracy: 99.400, Test loss: 0.994, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.092, Train accuracy: 96.600, Test loss: 1.354, Test accuracy: 65.80 

Round   8, Train loss: 0.057, Test loss: 1.282, Test accuracy: 72.53 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.646, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.694, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.486, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.607, Test accuracy: 72.20 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.137, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 99.600, Test loss: 1.462, Test accuracy: 70.60 

        train local model (freeze embeding):client   3,  Train loss: 0.030, Train accuracy: 99.800, Test loss: 1.001, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.142, Train accuracy: 95.000, Test loss: 1.469, Test accuracy: 64.80 

Round   9, Train loss: 0.041, Test loss: 1.323, Test accuracy: 72.67 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.570, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.026, Train accuracy: 99.200, Test loss: 1.331, Test accuracy: 75.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.450, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.084, Train accuracy: 97.000, Test loss: 2.376, Test accuracy: 63.20 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.169, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.026, Train accuracy: 99.000, Test loss: 1.211, Test accuracy: 73.80 

        train local model (freeze embeding):client   3,  Train loss: 0.021, Train accuracy: 99.800, Test loss: 1.051, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.080, Train accuracy: 97.600, Test loss: 1.516, Test accuracy: 66.20 

Round  10, Train loss: 0.054, Test loss: 1.321, Test accuracy: 72.15 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.377, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.036, Train accuracy: 98.800, Test loss: 2.625, Test accuracy: 60.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.564, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.048, Train accuracy: 98.200, Test loss: 2.229, Test accuracy: 62.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.130, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.401, Test accuracy: 71.00 

        train local model (freeze embeding):client   3,  Train loss: 0.023, Train accuracy: 99.800, Test loss: 1.147, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.061, Train accuracy: 97.600, Test loss: 1.412, Test accuracy: 68.20 

Round  11, Train loss: 0.037, Test loss: 1.319, Test accuracy: 72.67 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.459, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.600, Test loss: 1.698, Test accuracy: 69.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.548, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.519, Test accuracy: 73.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.071, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.063, Train accuracy: 96.800, Test loss: 2.052, Test accuracy: 63.40 

        train local model (freeze embeding):client   3,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.161, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.097, Train accuracy: 96.400, Test loss: 1.499, Test accuracy: 68.60 

Round  12, Train loss: 0.043, Test loss: 1.313, Test accuracy: 72.92 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.481, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.584, Test accuracy: 72.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.554, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.400, Test loss: 2.405, Test accuracy: 64.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.154, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.517, Test accuracy: 70.60 

        train local model (freeze embeding):client   3,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.140, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.071, Train accuracy: 97.800, Test loss: 1.182, Test accuracy: 71.40 

Round  13, Train loss: 0.025, Test loss: 1.295, Test accuracy: 72.80 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.620, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 2.198, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.427, Test accuracy: 71.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.869, Test accuracy: 70.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.032, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.744, Test accuracy: 66.80 

        train local model (freeze embeding):client   3,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 1.052, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.187, Train accuracy: 94.000, Test loss: 1.814, Test accuracy: 58.40 

Round  14, Train loss: 0.055, Test loss: 1.352, Test accuracy: 71.72 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.525, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.400, Test loss: 1.816, Test accuracy: 71.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.422, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.927, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.209, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.175, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 1.199, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.045, Train accuracy: 98.400, Test loss: 1.628, Test accuracy: 63.20 

Round  15, Train loss: 0.017, Test loss: 1.376, Test accuracy: 72.35 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.529, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.046, Train accuracy: 98.600, Test loss: 1.636, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.605, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.043, Train accuracy: 98.600, Test loss: 1.276, Test accuracy: 75.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.348, Test accuracy: 74.60 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.138, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 1.244, Test accuracy: 75.00 

Round  16, Train loss: 0.027, Test loss: 1.302, Test accuracy: 73.25 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.500, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.538, Test accuracy: 74.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.511, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.843, Test accuracy: 70.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.199, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.375, Test accuracy: 73.00 

        train local model (freeze embeding):client   3,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.133, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.065, Train accuracy: 97.800, Test loss: 1.142, Test accuracy: 73.40 

Round  17, Train loss: 0.017, Test loss: 1.351, Test accuracy: 73.55 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.499, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 2.022, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.635, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.662, Test accuracy: 71.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.134, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.053, Train accuracy: 98.200, Test loss: 1.633, Test accuracy: 65.80 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.109, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.241, Train accuracy: 91.200, Test loss: 1.853, Test accuracy: 66.20 

Round  18, Train loss: 0.075, Test loss: 1.374, Test accuracy: 72.38 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.654, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.411, Test accuracy: 77.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.609, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.600, Test loss: 1.848, Test accuracy: 67.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.205, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.983, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.280, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.035, Train accuracy: 98.800, Test loss: 1.767, Test accuracy: 68.40 

Round  19, Train loss: 0.014, Test loss: 1.411, Test accuracy: 73.00 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.599, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.744, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.780, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.055, Test accuracy: 68.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.101, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.177, Test accuracy: 75.20 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.214, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.071, Train accuracy: 97.400, Test loss: 1.258, Test accuracy: 73.60 

Final Round, Train loss: 0.019, Test loss: 1.390, Test accuracy: 73.45 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.500, Train accuracy: 80.400, Test loss: 0.845, Test accuracy: 67.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.533, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.760, Test accuracy: 70.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.867, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 1.941, Test accuracy: 70.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.162, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.067, Train accuracy: 97.000, Test loss: 1.878, Test accuracy: 65.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.257, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.286, Test accuracy: 73.00 

        train local model (freeze embeding):client   4,  Train loss: 0.426, Train accuracy: 84.200, Test loss: 0.667, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.131, Train accuracy: 96.600, Test loss: 0.748, Test accuracy: 75.20 

Round   0, Train loss: 0.047, Test loss: 1.212, Test accuracy: 74.12 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.697, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.765, Test accuracy: 68.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.629, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.733, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.210, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.187, Test accuracy: 76.60 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.199, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.115, Train accuracy: 97.200, Test loss: 2.126, Test accuracy: 65.80 

        train local model (freeze embeding):client   4,  Train loss: 0.315, Train accuracy: 87.600, Test loss: 0.759, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.195, Train accuracy: 93.800, Test loss: 0.917, Test accuracy: 71.80 

Round   1, Train loss: 0.065, Test loss: 1.187, Test accuracy: 74.56 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.575, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.820, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.747, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.979, Test accuracy: 69.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.071, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.183, Test accuracy: 76.00 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.181, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.120, Train accuracy: 96.000, Test loss: 1.516, Test accuracy: 67.00 

        train local model (freeze embeding):client   4,  Train loss: 0.245, Train accuracy: 90.400, Test loss: 0.610, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.268, Train accuracy: 90.000, Test loss: 0.897, Test accuracy: 75.40 

Round   2, Train loss: 0.089, Test loss: 1.152, Test accuracy: 74.52 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.454, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.903, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.624, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.036, Train accuracy: 99.000, Test loss: 1.883, Test accuracy: 65.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.101, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.024, Train accuracy: 98.800, Test loss: 1.298, Test accuracy: 71.80 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.011, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.043, Train accuracy: 99.000, Test loss: 1.333, Test accuracy: 71.20 

        train local model (freeze embeding):client   4,  Train loss: 0.147, Train accuracy: 95.400, Test loss: 0.676, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.110, Train accuracy: 96.200, Test loss: 0.871, Test accuracy: 74.00 

Round   3, Train loss: 0.043, Test loss: 1.075, Test accuracy: 75.38 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.332, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.614, Test accuracy: 72.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.478, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.742, Test accuracy: 72.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.998, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.966, Test accuracy: 79.40 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.014, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.346, Test accuracy: 73.60 

        train local model (freeze embeding):client   4,  Train loss: 0.118, Train accuracy: 97.800, Test loss: 0.749, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.190, Train accuracy: 93.600, Test loss: 1.696, Test accuracy: 61.20 

Round   4, Train loss: 0.042, Test loss: 1.215, Test accuracy: 75.30 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.542, Test accuracy: 74.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 99.200, Test loss: 1.571, Test accuracy: 70.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.761, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.099, Train accuracy: 97.200, Test loss: 2.777, Test accuracy: 60.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.031, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.158, Test accuracy: 75.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.021, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.150, Train accuracy: 94.600, Test loss: 1.532, Test accuracy: 71.20 

        train local model (freeze embeding):client   4,  Train loss: 0.066, Train accuracy: 98.800, Test loss: 0.811, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.171, Train accuracy: 93.400, Test loss: 1.548, Test accuracy: 62.60 

Round   5, Train loss: 0.092, Test loss: 1.149, Test accuracy: 74.74 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.367, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.869, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.600, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.648, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.069, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.133, Test accuracy: 76.40 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.055, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 0.877, Test accuracy: 80.60 

        train local model (freeze embeding):client   4,  Train loss: 0.074, Train accuracy: 98.600, Test loss: 0.786, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.068, Train accuracy: 98.600, Test loss: 1.257, Test accuracy: 68.80 

Round   6, Train loss: 0.020, Test loss: 1.188, Test accuracy: 75.14 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.450, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.684, Test accuracy: 71.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.708, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.649, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.036, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.096, Test accuracy: 80.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.080, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.128, Train accuracy: 95.000, Test loss: 1.352, Test accuracy: 70.60 

        train local model (freeze embeding):client   4,  Train loss: 0.039, Train accuracy: 99.600, Test loss: 0.908, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.087, Train accuracy: 97.400, Test loss: 1.068, Test accuracy: 74.60 

Round   7, Train loss: 0.045, Test loss: 1.182, Test accuracy: 75.06 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.698, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.045, Train accuracy: 98.200, Test loss: 3.098, Test accuracy: 60.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.674, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.054, Train accuracy: 98.000, Test loss: 2.368, Test accuracy: 63.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.875, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.020, Train accuracy: 99.400, Test loss: 1.457, Test accuracy: 73.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.029, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.057, Train accuracy: 98.200, Test loss: 1.544, Test accuracy: 69.00 

        train local model (freeze embeding):client   4,  Train loss: 0.029, Train accuracy: 99.800, Test loss: 0.834, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.127, Train accuracy: 94.800, Test loss: 1.594, Test accuracy: 67.60 

Round   8, Train loss: 0.060, Test loss: 1.159, Test accuracy: 75.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.489, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.770, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.681, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.066, Train accuracy: 97.200, Test loss: 1.836, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.010, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.176, Test accuracy: 75.40 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.924, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.047, Train accuracy: 99.000, Test loss: 1.156, Test accuracy: 70.80 

        train local model (freeze embeding):client   4,  Train loss: 0.029, Train accuracy: 100.000, Test loss: 0.933, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.101, Train accuracy: 96.600, Test loss: 1.533, Test accuracy: 64.60 

Round   9, Train loss: 0.043, Test loss: 1.167, Test accuracy: 75.02 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.379, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.086, Train accuracy: 97.200, Test loss: 2.008, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.664, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.400, Test loss: 1.760, Test accuracy: 72.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.002, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.092, Test accuracy: 78.20 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.972, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.055, Train accuracy: 98.600, Test loss: 1.168, Test accuracy: 74.20 

        train local model (freeze embeding):client   4,  Train loss: 0.023, Train accuracy: 99.600, Test loss: 0.825, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.042, Train accuracy: 98.800, Test loss: 1.062, Test accuracy: 74.00 

Round  10, Train loss: 0.041, Test loss: 1.171, Test accuracy: 75.14 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.454, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.027, Train accuracy: 98.600, Test loss: 2.319, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.756, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.405, Train accuracy: 87.600, Test loss: 1.839, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.940, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 0.972, Test accuracy: 78.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.991, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.023, Train accuracy: 99.400, Test loss: 1.495, Test accuracy: 70.80 

        train local model (freeze embeding):client   4,  Train loss: 0.018, Train accuracy: 99.800, Test loss: 0.816, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.320, Train accuracy: 89.600, Test loss: 3.083, Test accuracy: 53.00 

Round  11, Train loss: 0.157, Test loss: 1.250, Test accuracy: 74.40 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.540, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.706, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.524, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.568, Test accuracy: 73.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.913, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.988, Test accuracy: 77.00 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.127, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.510, Test accuracy: 71.60 

        train local model (freeze embeding):client   4,  Train loss: 0.015, Train accuracy: 100.000, Test loss: 0.870, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.096, Train accuracy: 97.000, Test loss: 1.118, Test accuracy: 74.80 

Round  12, Train loss: 0.025, Test loss: 1.170, Test accuracy: 75.18 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.473, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.385, Test accuracy: 71.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.709, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.356, Test accuracy: 76.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.868, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.016, Test accuracy: 78.80 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.040, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.063, Train accuracy: 97.800, Test loss: 1.563, Test accuracy: 68.80 

        train local model (freeze embeding):client   4,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 0.915, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.161, Train accuracy: 94.400, Test loss: 1.757, Test accuracy: 68.20 

Round  13, Train loss: 0.049, Test loss: 1.179, Test accuracy: 75.36 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.418, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.562, Test accuracy: 72.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.477, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.046, Train accuracy: 98.800, Test loss: 1.722, Test accuracy: 68.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.007, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.094, Train accuracy: 97.400, Test loss: 1.218, Test accuracy: 77.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.105, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.069, Test accuracy: 76.80 

        train local model (freeze embeding):client   4,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 0.913, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.047, Train accuracy: 99.200, Test loss: 1.226, Test accuracy: 71.40 

Round  14, Train loss: 0.038, Test loss: 1.162, Test accuracy: 75.24 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.401, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.768, Test accuracy: 72.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.544, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.565, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.895, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.310, Test accuracy: 74.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.064, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.029, Train accuracy: 99.400, Test loss: 1.706, Test accuracy: 67.40 

        train local model (freeze embeding):client   4,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 0.977, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.050, Train accuracy: 98.400, Test loss: 1.311, Test accuracy: 72.60 

Round  15, Train loss: 0.024, Test loss: 1.179, Test accuracy: 75.30 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.576, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.046, Train accuracy: 99.000, Test loss: 1.579, Test accuracy: 72.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.427, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.903, Test accuracy: 70.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.994, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 0.970, Test accuracy: 78.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.031, Train accuracy: 98.400, Test loss: 1.316, Test accuracy: 73.00 

        train local model (freeze embeding):client   4,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 0.907, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.153, Train accuracy: 95.600, Test loss: 1.177, Test accuracy: 71.80 

Round  16, Train loss: 0.050, Test loss: 1.155, Test accuracy: 75.52 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.478, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.449, Test accuracy: 73.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.645, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.887, Test accuracy: 69.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.829, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.300, Test accuracy: 73.60 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.998, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.006, Test accuracy: 81.20 

        train local model (freeze embeding):client   4,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 0.982, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.029, Train accuracy: 99.000, Test loss: 1.214, Test accuracy: 72.80 

Round  17, Train loss: 0.008, Test loss: 1.202, Test accuracy: 75.86 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.477, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.679, Test accuracy: 71.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.733, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 2.141, Test accuracy: 65.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.002, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.907, Test accuracy: 81.60 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.027, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.021, Train accuracy: 99.200, Test loss: 1.029, Test accuracy: 80.20 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.016, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.284, Test accuracy: 74.80 

Round  18, Train loss: 0.011, Test loss: 1.259, Test accuracy: 75.22 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.646, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 2.050, Test accuracy: 67.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.701, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 2.398, Test accuracy: 66.60 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.990, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.908, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.156, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.149, Test accuracy: 78.40 

        train local model (freeze embeding):client   4,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 0.961, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.049, Train accuracy: 98.400, Test loss: 1.535, Test accuracy: 69.20 

Round  19, Train loss: 0.014, Test loss: 1.232, Test accuracy: 76.08 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.634, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.054, Train accuracy: 97.600, Test loss: 2.776, Test accuracy: 58.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.772, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.469, Test accuracy: 72.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.919, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.295, Test accuracy: 76.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.165, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.125, Test accuracy: 79.40 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.965, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.102, Train accuracy: 96.200, Test loss: 1.452, Test accuracy: 70.00 

Final Round, Train loss: 0.035, Test loss: 1.225, Test accuracy: 76.34 

Average accuracy final 10 rounds: 341.30333333333334 

3269.1656744480133
[9.14384937286377, 18.71950125694275, 28.12131142616272, 37.4916570186615, 46.69406867027283, 55.968525409698486, 65.42023515701294, 74.7130856513977, 84.77001523971558, 93.9224762916565, 102.97387552261353, 112.38304901123047, 121.99987268447876, 130.87245202064514, 140.6837456226349, 150.38095879554749, 159.711567401886, 169.85723400115967, 178.5627157688141, 188.06659507751465, 197.04960703849792, 206.44135856628418, 216.14679288864136, 225.90994596481323, 235.59709930419922, 245.66273379325867, 255.16571927070618, 265.1754868030548, 274.17034006118774, 283.7725169658661, 293.38468050956726, 302.93080973625183, 312.7043209075928, 322.68311762809753, 332.4963047504425, 342.1061587333679, 351.2713575363159, 360.69230580329895, 369.81246519088745, 379.2893431186676, 388.5803396701813, 398.27492356300354, 408.39896941185, 418.1653847694397, 427.79544138908386, 437.3674683570862, 447.4418923854828, 456.5635757446289, 465.9363679885864, 475.84563755989075, 485.7419755458832, 495.60849118232727, 505.6477200984955, 515.8537971973419, 525.5474338531494, 535.5317664146423, 545.5761168003082, 555.6777589321136, 565.4600324630737, 575.0725092887878, 584.8959853649139, 595.105283498764, 605.0629329681396, 614.931658744812, 624.7558240890503, 634.2845985889435, 644.1454725265503, 653.8120787143707, 663.7805812358856, 673.6930685043335, 683.7178063392639, 693.9324190616608, 703.4804031848907, 713.1949143409729, 722.8281981945038, 732.2948932647705, 742.0268225669861, 751.4575247764587, 761.1140220165253, 771.0767998695374, 780.3482406139374, 790.4334321022034, 800.0578372478485, 810.062628030777, 820.0467686653137, 830.0396404266357, 839.8270137310028, 849.432968378067, 859.8692407608032, 869.8596410751343, 880.1283764839172, 889.7539660930634, 899.6393747329712, 909.5979993343353, 919.279946565628, 928.9549071788788, 938.3684170246124, 948.2276811599731, 958.4336740970612, 968.5501208305359, 978.3701257705688, 988.441987991333, 998.1010398864746, 1008.268458366394, 1018.2206475734711]
[51.9, 52.2, 52.5, 54.0, 55.0, 50.9, 54.5, 59.7, 52.2, 57.0, 56.4, 59.5, 54.1, 57.4, 56.3, 62.3, 59.1, 62.0, 58.7, 60.4, 63.0, 62.75, 62.85, 62.85, 64.3, 63.55, 63.5, 63.8, 63.95, 64.9, 64.45, 63.65, 64.4, 65.7, 66.4, 65.15, 65.45, 64.8, 64.8, 65.55, 65.1, 65.8, 66.8, 67.96666666666667, 68.3, 68.03333333333333, 67.8, 68.56666666666666, 68.76666666666667, 68.0, 69.6, 69.4, 69.56666666666666, 69.9, 69.1, 69.4, 69.73333333333333, 68.86666666666666, 70.03333333333333, 69.16666666666667, 69.83333333333333, 70.13333333333334, 70.3, 70.35, 70.675, 70.425, 70.55, 71.725, 71.9, 72.0, 71.275, 72.525, 72.675, 72.15, 72.675, 72.925, 72.8, 71.725, 72.35, 73.25, 73.55, 72.375, 73.0, 73.45, 74.12, 74.56, 74.52, 75.38, 75.3, 74.74, 75.14, 75.06, 75.2, 75.02, 75.14, 74.4, 75.18, 75.36, 75.24, 75.3, 75.52, 75.86, 75.22, 76.08, 76.34]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.619, Test loss: 0.537, Test accuracy: 78.70 

Round   0, Global train loss: 0.619, Global test loss: 0.651, Global test accuracy: 62.90 

Round   1, Train loss: 0.441, Test loss: 0.446, Test accuracy: 82.05 

Round   1, Global train loss: 0.441, Global test loss: 0.705, Global test accuracy: 50.40 

Round   2, Train loss: 0.365, Test loss: 0.482, Test accuracy: 82.30 

Round   2, Global train loss: 0.365, Global test loss: 0.676, Global test accuracy: 52.35 

Round   3, Train loss: 0.320, Test loss: 0.422, Test accuracy: 83.95 

Round   3, Global train loss: 0.320, Global test loss: 0.687, Global test accuracy: 50.80 

Round   4, Train loss: 0.253, Test loss: 0.419, Test accuracy: 85.30 

Round   4, Global train loss: 0.253, Global test loss: 0.703, Global test accuracy: 50.25 

Round   5, Train loss: 0.233, Test loss: 0.442, Test accuracy: 85.95 

Round   5, Global train loss: 0.233, Global test loss: 0.691, Global test accuracy: 50.70 

Round   6, Train loss: 0.186, Test loss: 0.409, Test accuracy: 86.10 

Round   6, Global train loss: 0.186, Global test loss: 0.688, Global test accuracy: 50.90 

Round   7, Train loss: 0.159, Test loss: 0.517, Test accuracy: 84.75 

Round   7, Global train loss: 0.159, Global test loss: 0.721, Global test accuracy: 50.30 

Round   8, Train loss: 0.141, Test loss: 0.453, Test accuracy: 85.80 

Round   8, Global train loss: 0.141, Global test loss: 0.717, Global test accuracy: 50.30 

Round   9, Train loss: 0.114, Test loss: 0.488, Test accuracy: 85.35 

Round   9, Global train loss: 0.114, Global test loss: 0.735, Global test accuracy: 50.10 

Round  10, Train loss: 0.105, Test loss: 0.486, Test accuracy: 85.75 

Round  10, Global train loss: 0.105, Global test loss: 0.742, Global test accuracy: 50.10 

Round  11, Train loss: 0.076, Test loss: 0.453, Test accuracy: 88.45 

Round  11, Global train loss: 0.076, Global test loss: 0.726, Global test accuracy: 50.25 

Round  12, Train loss: 0.074, Test loss: 0.493, Test accuracy: 87.40 

Round  12, Global train loss: 0.074, Global test loss: 0.761, Global test accuracy: 50.20 

Round  13, Train loss: 0.064, Test loss: 0.562, Test accuracy: 86.85 

Round  13, Global train loss: 0.064, Global test loss: 0.741, Global test accuracy: 50.25 

Round  14, Train loss: 0.048, Test loss: 0.621, Test accuracy: 87.25 

Round  14, Global train loss: 0.048, Global test loss: 0.794, Global test accuracy: 50.05 

Round  15, Train loss: 0.054, Test loss: 0.445, Test accuracy: 87.90 

Round  15, Global train loss: 0.054, Global test loss: 0.804, Global test accuracy: 50.00 

Round  16, Train loss: 0.038, Test loss: 0.458, Test accuracy: 88.75 

Round  16, Global train loss: 0.038, Global test loss: 0.801, Global test accuracy: 50.10 

Round  17, Train loss: 0.024, Test loss: 0.518, Test accuracy: 87.85 

Round  17, Global train loss: 0.024, Global test loss: 0.757, Global test accuracy: 50.20 

Round  18, Train loss: 0.035, Test loss: 0.526, Test accuracy: 87.75 

Round  18, Global train loss: 0.035, Global test loss: 0.830, Global test accuracy: 50.00 

Round  19, Train loss: 0.019, Test loss: 0.563, Test accuracy: 87.70 

Round  19, Global train loss: 0.019, Global test loss: 0.816, Global test accuracy: 50.30 

Round  20, Train loss: 0.036, Test loss: 0.539, Test accuracy: 87.30 

Round  20, Global train loss: 0.036, Global test loss: 0.865, Global test accuracy: 50.00 

Round  21, Train loss: 0.029, Test loss: 0.492, Test accuracy: 88.05 

Round  21, Global train loss: 0.029, Global test loss: 0.849, Global test accuracy: 50.00 

Round  22, Train loss: 0.017, Test loss: 0.541, Test accuracy: 88.10 

Round  22, Global train loss: 0.017, Global test loss: 0.848, Global test accuracy: 50.00 

Round  23, Train loss: 0.027, Test loss: 0.539, Test accuracy: 87.80 

Round  23, Global train loss: 0.027, Global test loss: 0.815, Global test accuracy: 50.15 

Round  24, Train loss: 0.026, Test loss: 0.514, Test accuracy: 87.45 

Round  24, Global train loss: 0.026, Global test loss: 0.897, Global test accuracy: 50.00 

Round  25, Train loss: 0.012, Test loss: 0.539, Test accuracy: 87.10 

Round  25, Global train loss: 0.012, Global test loss: 0.891, Global test accuracy: 50.00 

Round  26, Train loss: 0.015, Test loss: 0.494, Test accuracy: 88.50 

Round  26, Global train loss: 0.015, Global test loss: 0.809, Global test accuracy: 50.05 

Round  27, Train loss: 0.010, Test loss: 0.512, Test accuracy: 88.15 

Round  27, Global train loss: 0.010, Global test loss: 0.854, Global test accuracy: 50.00 

Round  28, Train loss: 0.023, Test loss: 0.504, Test accuracy: 88.95 

Round  28, Global train loss: 0.023, Global test loss: 0.861, Global test accuracy: 50.00 

Round  29, Train loss: 0.010, Test loss: 0.567, Test accuracy: 87.25 

Round  29, Global train loss: 0.010, Global test loss: 0.832, Global test accuracy: 50.05 

Round  30, Train loss: 0.020, Test loss: 0.515, Test accuracy: 88.35 

Round  30, Global train loss: 0.020, Global test loss: 0.934, Global test accuracy: 50.00 

Round  31, Train loss: 0.007, Test loss: 0.515, Test accuracy: 88.35 

Round  31, Global train loss: 0.007, Global test loss: 0.918, Global test accuracy: 50.00 

Round  32, Train loss: 0.007, Test loss: 0.540, Test accuracy: 88.35 

Round  32, Global train loss: 0.007, Global test loss: 0.873, Global test accuracy: 50.00 

Round  33, Train loss: 0.007, Test loss: 0.568, Test accuracy: 88.25 

Round  33, Global train loss: 0.007, Global test loss: 0.922, Global test accuracy: 50.00 

Round  34, Train loss: 0.008, Test loss: 0.508, Test accuracy: 89.05 

Round  34, Global train loss: 0.008, Global test loss: 0.868, Global test accuracy: 50.00 

Final Round, Train loss: 0.006, Test loss: 0.516, Test accuracy: 88.80 

Final Round, Global train loss: 0.006, Global test loss: 0.868, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 88.23 

Average global accuracy final 10 rounds: 50.01 

922.7557244300842
[6.5192413330078125, 11.299158573150635, 15.770284652709961, 20.370981216430664, 25.023479461669922, 29.56361746788025, 34.67340803146362, 39.228638887405396, 43.722068786621094, 48.16631603240967, 52.86583852767944, 57.41963458061218, 61.83094000816345, 66.26429462432861, 70.77676844596863, 75.34086394309998, 80.01273965835571, 84.46711230278015, 89.01662468910217, 93.71472597122192, 98.45063376426697, 102.96246409416199, 107.58918118476868, 112.1257312297821, 116.65674018859863, 121.16690826416016, 125.63688468933105, 130.28364944458008, 134.93818545341492, 139.40634536743164, 144.00957584381104, 148.6517996788025, 153.11694025993347, 157.59808540344238, 162.12113571166992, 171.3792700767517]
[78.7, 82.05, 82.3, 83.95, 85.3, 85.95, 86.1, 84.75, 85.8, 85.35, 85.75, 88.45, 87.4, 86.85, 87.25, 87.9, 88.75, 87.85, 87.75, 87.7, 87.3, 88.05, 88.1, 87.8, 87.45, 87.1, 88.5, 88.15, 88.95, 87.25, 88.35, 88.35, 88.35, 88.25, 89.05, 88.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.599, Test loss: 0.511, Test accuracy: 78.35 

Round   0, Global train loss: 0.599, Global test loss: 0.674, Global test accuracy: 52.80 

Round   1, Train loss: 0.538, Test loss: 0.587, Test accuracy: 76.65 

Round   1, Global train loss: 0.538, Global test loss: 0.576, Global test accuracy: 70.60 

Round   2, Train loss: 0.462, Test loss: 0.362, Test accuracy: 85.80 

Round   2, Global train loss: 0.462, Global test loss: 0.574, Global test accuracy: 70.70 

Round   3, Train loss: 0.411, Test loss: 0.442, Test accuracy: 82.50 

Round   3, Global train loss: 0.411, Global test loss: 0.597, Global test accuracy: 72.45 

Round   4, Train loss: 0.372, Test loss: 0.619, Test accuracy: 79.75 

Round   4, Global train loss: 0.372, Global test loss: 0.555, Global test accuracy: 74.55 

Round   5, Train loss: 0.347, Test loss: 0.342, Test accuracy: 86.95 

Round   5, Global train loss: 0.347, Global test loss: 0.589, Global test accuracy: 74.75 

Round   6, Train loss: 0.315, Test loss: 0.469, Test accuracy: 82.90 

Round   6, Global train loss: 0.315, Global test loss: 0.564, Global test accuracy: 75.30 

Round   7, Train loss: 0.292, Test loss: 0.340, Test accuracy: 87.80 

Round   7, Global train loss: 0.292, Global test loss: 0.592, Global test accuracy: 75.30 

Round   8, Train loss: 0.273, Test loss: 0.415, Test accuracy: 86.10 

Round   8, Global train loss: 0.273, Global test loss: 0.607, Global test accuracy: 76.65 

Round   9, Train loss: 0.262, Test loss: 0.419, Test accuracy: 86.10 

Round   9, Global train loss: 0.262, Global test loss: 0.562, Global test accuracy: 77.30 

Round  10, Train loss: 0.237, Test loss: 0.460, Test accuracy: 85.70 

Round  10, Global train loss: 0.237, Global test loss: 0.589, Global test accuracy: 76.60 

Round  11, Train loss: 0.217, Test loss: 0.363, Test accuracy: 86.80 

Round  11, Global train loss: 0.217, Global test loss: 0.597, Global test accuracy: 76.15 

Round  12, Train loss: 0.210, Test loss: 0.447, Test accuracy: 85.75 

Round  12, Global train loss: 0.210, Global test loss: 0.621, Global test accuracy: 76.65 

Round  13, Train loss: 0.198, Test loss: 0.377, Test accuracy: 87.65 

Round  13, Global train loss: 0.198, Global test loss: 0.647, Global test accuracy: 77.00 

Round  14, Train loss: 0.190, Test loss: 0.381, Test accuracy: 87.70 

Round  14, Global train loss: 0.190, Global test loss: 0.647, Global test accuracy: 76.05 

Round  15, Train loss: 0.169, Test loss: 0.541, Test accuracy: 84.30 

Round  15, Global train loss: 0.169, Global test loss: 0.633, Global test accuracy: 76.10 

Round  16, Train loss: 0.158, Test loss: 0.367, Test accuracy: 88.15 

Round  16, Global train loss: 0.158, Global test loss: 0.602, Global test accuracy: 78.20 

Round  17, Train loss: 0.152, Test loss: 0.386, Test accuracy: 88.65 

Round  17, Global train loss: 0.152, Global test loss: 0.650, Global test accuracy: 76.65 

Round  18, Train loss: 0.139, Test loss: 0.423, Test accuracy: 87.50 

Round  18, Global train loss: 0.139, Global test loss: 0.693, Global test accuracy: 76.55 

Round  19, Train loss: 0.133, Test loss: 0.451, Test accuracy: 86.40 

Round  19, Global train loss: 0.133, Global test loss: 0.707, Global test accuracy: 77.10 

Round  20, Train loss: 0.128, Test loss: 0.510, Test accuracy: 85.45 

Round  20, Global train loss: 0.128, Global test loss: 0.676, Global test accuracy: 76.25 

Round  21, Train loss: 0.113, Test loss: 0.320, Test accuracy: 89.95 

Round  21, Global train loss: 0.113, Global test loss: 0.680, Global test accuracy: 76.25 

Round  22, Train loss: 0.112, Test loss: 0.383, Test accuracy: 88.30 

Round  22, Global train loss: 0.112, Global test loss: 0.705, Global test accuracy: 76.70 

Round  23, Train loss: 0.110, Test loss: 0.514, Test accuracy: 86.65 

Round  23, Global train loss: 0.110, Global test loss: 0.715, Global test accuracy: 76.65 

Round  24, Train loss: 0.099, Test loss: 0.443, Test accuracy: 87.80 

Round  24, Global train loss: 0.099, Global test loss: 0.673, Global test accuracy: 77.85 

Round  25, Train loss: 0.104, Test loss: 0.408, Test accuracy: 88.10 

Round  25, Global train loss: 0.104, Global test loss: 0.697, Global test accuracy: 75.70 

Round  26, Train loss: 0.082, Test loss: 0.384, Test accuracy: 88.80 

Round  26, Global train loss: 0.082, Global test loss: 0.705, Global test accuracy: 77.00 

Round  27, Train loss: 0.080, Test loss: 0.457, Test accuracy: 88.15 

Round  27, Global train loss: 0.080, Global test loss: 0.778, Global test accuracy: 78.00 

Round  28, Train loss: 0.084, Test loss: 0.391, Test accuracy: 89.30 

Round  28, Global train loss: 0.084, Global test loss: 0.707, Global test accuracy: 76.85 

Round  29, Train loss: 0.078, Test loss: 0.382, Test accuracy: 89.20 

Round  29, Global train loss: 0.078, Global test loss: 0.783, Global test accuracy: 76.35 

Round  30, Train loss: 0.073, Test loss: 0.382, Test accuracy: 89.40 

Round  30, Global train loss: 0.073, Global test loss: 0.713, Global test accuracy: 77.85 

Round  31, Train loss: 0.066, Test loss: 0.476, Test accuracy: 87.35 

Round  31, Global train loss: 0.066, Global test loss: 0.787, Global test accuracy: 77.35 

Round  32, Train loss: 0.062, Test loss: 0.501, Test accuracy: 88.10 

Round  32, Global train loss: 0.062, Global test loss: 0.744, Global test accuracy: 77.80 

Round  33, Train loss: 0.056, Test loss: 0.399, Test accuracy: 88.80 

Round  33, Global train loss: 0.056, Global test loss: 0.788, Global test accuracy: 77.75 

Round  34, Train loss: 0.058, Test loss: 0.434, Test accuracy: 89.85 

Round  34, Global train loss: 0.058, Global test loss: 0.740, Global test accuracy: 77.50 

Final Round, Train loss: 0.043, Test loss: 0.436, Test accuracy: 89.35 

Final Round, Global train loss: 0.043, Global test loss: 0.740, Global test accuracy: 77.50 

Average accuracy final 10 rounds: 88.705 

Average global accuracy final 10 rounds: 77.215 

916.7345108985901
[6.924834966659546, 11.622672319412231, 16.304245710372925, 20.796772480010986, 25.2161386013031, 29.68135404586792, 34.13120889663696, 38.5269718170166, 42.98576021194458, 47.39403820037842, 51.851924896240234, 56.31576442718506, 60.8117196559906, 65.4106695652008, 70.0558648109436, 74.48212623596191, 78.96112895011902, 83.49452257156372, 88.29390859603882, 92.68288445472717, 97.12271904945374, 101.5961754322052, 106.09537553787231, 110.51780319213867, 115.19201683998108, 119.91498970985413, 124.27929592132568, 128.80848097801208, 133.19624280929565, 137.80460453033447, 142.26468658447266, 146.82147765159607, 151.38227367401123, 155.80863070487976, 160.26239132881165, 169.30619168281555]
[78.35, 76.65, 85.8, 82.5, 79.75, 86.95, 82.9, 87.8, 86.1, 86.1, 85.7, 86.8, 85.75, 87.65, 87.7, 84.3, 88.15, 88.65, 87.5, 86.4, 85.45, 89.95, 88.3, 86.65, 87.8, 88.1, 88.8, 88.15, 89.3, 89.2, 89.4, 87.35, 88.1, 88.8, 89.85, 89.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.682, Test loss: 0.829, Test accuracy: 50.00 

Round   1, Train loss: 0.620, Test loss: 0.838, Test accuracy: 59.60 

Round   2, Train loss: 0.574, Test loss: 0.604, Test accuracy: 72.75 

Round   3, Train loss: 0.513, Test loss: 0.487, Test accuracy: 77.05 

Round   4, Train loss: 0.484, Test loss: 0.584, Test accuracy: 72.40 

Round   5, Train loss: 0.449, Test loss: 0.588, Test accuracy: 72.90 

Round   6, Train loss: 0.418, Test loss: 0.596, Test accuracy: 76.05 

Round   7, Train loss: 0.393, Test loss: 0.662, Test accuracy: 73.95 

Round   8, Train loss: 0.361, Test loss: 0.396, Test accuracy: 81.95 

Round   9, Train loss: 0.343, Test loss: 0.440, Test accuracy: 80.65 

Round  10, Train loss: 0.313, Test loss: 0.321, Test accuracy: 86.30 

Round  11, Train loss: 0.297, Test loss: 0.408, Test accuracy: 83.30 

Round  12, Train loss: 0.280, Test loss: 0.324, Test accuracy: 85.60 

Round  13, Train loss: 0.262, Test loss: 0.346, Test accuracy: 85.75 

Round  14, Train loss: 0.258, Test loss: 0.611, Test accuracy: 78.85 

Round  15, Train loss: 0.237, Test loss: 0.366, Test accuracy: 85.20 

Round  16, Train loss: 0.224, Test loss: 0.356, Test accuracy: 85.15 

Round  17, Train loss: 0.215, Test loss: 0.352, Test accuracy: 85.75 

Round  18, Train loss: 0.202, Test loss: 0.315, Test accuracy: 87.80 

Round  19, Train loss: 0.201, Test loss: 0.322, Test accuracy: 86.80 

Round  20, Train loss: 0.181, Test loss: 0.310, Test accuracy: 87.20 

Round  21, Train loss: 0.175, Test loss: 0.313, Test accuracy: 87.75 

Round  22, Train loss: 0.160, Test loss: 0.347, Test accuracy: 86.95 

Round  23, Train loss: 0.151, Test loss: 0.275, Test accuracy: 88.30 

Round  24, Train loss: 0.143, Test loss: 0.297, Test accuracy: 88.15 

Round  25, Train loss: 0.132, Test loss: 0.293, Test accuracy: 88.30 

Round  26, Train loss: 0.128, Test loss: 0.313, Test accuracy: 88.05 

Round  27, Train loss: 0.122, Test loss: 0.314, Test accuracy: 88.10 

Round  28, Train loss: 0.117, Test loss: 0.300, Test accuracy: 88.20 

Round  29, Train loss: 0.105, Test loss: 0.311, Test accuracy: 89.30 

Round  30, Train loss: 0.093, Test loss: 0.292, Test accuracy: 89.25 

Round  31, Train loss: 0.101, Test loss: 0.300, Test accuracy: 88.75 

Round  32, Train loss: 0.091, Test loss: 0.295, Test accuracy: 89.10 

Round  33, Train loss: 0.079, Test loss: 0.292, Test accuracy: 89.45 

Round  34, Train loss: 0.077, Test loss: 0.366, Test accuracy: 88.65 

Round  35, Train loss: 0.071, Test loss: 0.317, Test accuracy: 88.70 

Round  36, Train loss: 0.070, Test loss: 0.329, Test accuracy: 89.00 

Round  37, Train loss: 0.060, Test loss: 0.348, Test accuracy: 88.75 

Round  38, Train loss: 0.057, Test loss: 0.313, Test accuracy: 89.10 

Round  39, Train loss: 0.060, Test loss: 0.298, Test accuracy: 89.60 

Round  40, Train loss: 0.058, Test loss: 0.318, Test accuracy: 89.05 

Round  41, Train loss: 0.049, Test loss: 0.300, Test accuracy: 89.85 

Round  42, Train loss: 0.051, Test loss: 0.325, Test accuracy: 89.65 

Round  43, Train loss: 0.034, Test loss: 0.306, Test accuracy: 90.10 

Round  44, Train loss: 0.040, Test loss: 0.317, Test accuracy: 89.35 

Round  45, Train loss: 0.033, Test loss: 0.308, Test accuracy: 89.55 

Round  46, Train loss: 0.038, Test loss: 0.345, Test accuracy: 89.00 

Round  47, Train loss: 0.031, Test loss: 0.315, Test accuracy: 90.10 

Round  48, Train loss: 0.036, Test loss: 0.313, Test accuracy: 89.85 

Round  49, Train loss: 0.027, Test loss: 0.323, Test accuracy: 90.05 

Final Round, Train loss: 0.018, Test loss: 0.326, Test accuracy: 90.05 

Average accuracy final 10 rounds: 89.65499999999999 

981.9937145709991
[5.711588621139526, 9.352837085723877, 13.02303957939148, 16.790309190750122, 20.371014833450317, 24.17796802520752, 27.95494556427002, 31.503328323364258, 35.0510094165802, 38.71175026893616, 42.33785557746887, 45.878933906555176, 49.43087553977966, 52.94282388687134, 56.557265520095825, 60.34445261955261, 64.02984714508057, 67.93392634391785, 71.65224695205688, 75.23332977294922, 78.84953618049622, 82.46824955940247, 86.22283673286438, 89.88224911689758, 93.65621399879456, 97.30737566947937, 100.99856948852539, 104.68036127090454, 108.36010813713074, 112.01487636566162, 115.69932579994202, 119.73703002929688, 123.3347737789154, 127.47807288169861, 131.03657364845276, 134.82140064239502, 138.43832874298096, 142.1120629310608, 145.83066248893738, 149.60395908355713, 153.09272861480713, 156.67460656166077, 160.36052441596985, 163.94181847572327, 167.6466155052185, 171.46492195129395, 175.08105087280273, 178.73444819450378, 182.42548322677612, 186.1078155040741, 190.02867245674133]
[50.0, 59.6, 72.75, 77.05, 72.4, 72.9, 76.05, 73.95, 81.95, 80.65, 86.3, 83.3, 85.6, 85.75, 78.85, 85.2, 85.15, 85.75, 87.8, 86.8, 87.2, 87.75, 86.95, 88.3, 88.15, 88.3, 88.05, 88.1, 88.2, 89.3, 89.25, 88.75, 89.1, 89.45, 88.65, 88.7, 89.0, 88.75, 89.1, 89.6, 89.05, 89.85, 89.65, 90.1, 89.35, 89.55, 89.0, 90.1, 89.85, 90.05, 90.05]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.718, Test loss: 0.859, Test accuracy: 53.40
Round   1, Train loss: 0.639, Test loss: 0.931, Test accuracy: 55.90
Round   2, Train loss: 0.574, Test loss: 0.572, Test accuracy: 70.60
Round   3, Train loss: 0.522, Test loss: 0.996, Test accuracy: 54.75
Round   4, Train loss: 0.470, Test loss: 0.481, Test accuracy: 77.05
Round   5, Train loss: 0.427, Test loss: 0.642, Test accuracy: 73.55
Round   6, Train loss: 0.393, Test loss: 0.406, Test accuracy: 81.30
Round   7, Train loss: 0.388, Test loss: 0.395, Test accuracy: 82.00
Round   8, Train loss: 0.353, Test loss: 0.371, Test accuracy: 83.25
Round   9, Train loss: 0.329, Test loss: 0.434, Test accuracy: 81.05
Round  10, Train loss: 0.327, Test loss: 0.544, Test accuracy: 78.45
Round  11, Train loss: 0.292, Test loss: 0.317, Test accuracy: 87.15
Round  12, Train loss: 0.281, Test loss: 0.359, Test accuracy: 84.70
Round  13, Train loss: 0.262, Test loss: 0.342, Test accuracy: 85.65
Round  14, Train loss: 0.245, Test loss: 0.311, Test accuracy: 87.55
Round  15, Train loss: 0.225, Test loss: 0.378, Test accuracy: 85.05
Round  16, Train loss: 0.213, Test loss: 0.318, Test accuracy: 87.65
Round  17, Train loss: 0.212, Test loss: 0.358, Test accuracy: 86.35
Round  18, Train loss: 0.196, Test loss: 0.309, Test accuracy: 87.75
Round  19, Train loss: 0.187, Test loss: 0.316, Test accuracy: 87.70
Round  20, Train loss: 0.190, Test loss: 0.386, Test accuracy: 86.10
Round  21, Train loss: 0.173, Test loss: 0.281, Test accuracy: 89.10
Round  22, Train loss: 0.171, Test loss: 0.374, Test accuracy: 85.55
Round  23, Train loss: 0.156, Test loss: 0.288, Test accuracy: 88.60
Round  24, Train loss: 0.142, Test loss: 0.286, Test accuracy: 88.60
Round  25, Train loss: 0.140, Test loss: 0.318, Test accuracy: 87.55
Round  26, Train loss: 0.130, Test loss: 0.292, Test accuracy: 88.65
Round  27, Train loss: 0.124, Test loss: 0.268, Test accuracy: 89.60
Round  28, Train loss: 0.115, Test loss: 0.272, Test accuracy: 89.75
Round  29, Train loss: 0.099, Test loss: 0.274, Test accuracy: 89.80
Round  30, Train loss: 0.098, Test loss: 0.273, Test accuracy: 89.65
Round  31, Train loss: 0.095, Test loss: 0.290, Test accuracy: 89.25
Round  32, Train loss: 0.098, Test loss: 0.347, Test accuracy: 87.35
Round  33, Train loss: 0.086, Test loss: 0.279, Test accuracy: 89.90
Round  34, Train loss: 0.079, Test loss: 0.292, Test accuracy: 89.20
Round  35, Train loss: 0.079, Test loss: 0.291, Test accuracy: 90.25
Round  36, Train loss: 0.076, Test loss: 0.297, Test accuracy: 89.60
Round  37, Train loss: 0.060, Test loss: 0.285, Test accuracy: 90.10
Round  38, Train loss: 0.062, Test loss: 0.303, Test accuracy: 89.40
Round  39, Train loss: 0.071, Test loss: 0.291, Test accuracy: 89.90
Round  40, Train loss: 0.058, Test loss: 0.292, Test accuracy: 90.05
Round  41, Train loss: 0.051, Test loss: 0.285, Test accuracy: 89.60
Round  42, Train loss: 0.054, Test loss: 0.308, Test accuracy: 89.70
Round  43, Train loss: 0.039, Test loss: 0.296, Test accuracy: 90.40
Round  44, Train loss: 0.042, Test loss: 0.315, Test accuracy: 90.15
Round  45, Train loss: 0.043, Test loss: 0.304, Test accuracy: 89.85
Round  46, Train loss: 0.037, Test loss: 0.320, Test accuracy: 90.55
Round  47, Train loss: 0.040, Test loss: 0.308, Test accuracy: 90.55
Round  48, Train loss: 0.045, Test loss: 0.327, Test accuracy: 89.85
Round  49, Train loss: 0.035, Test loss: 0.324, Test accuracy: 90.85
Final Round, Train loss: 0.019, Test loss: 0.330, Test accuracy: 90.70
Average accuracy final 10 rounds: 90.15499999999999
1077.3994855880737
[5.936821222305298, 10.026434659957886, 14.058942079544067, 18.139466524124146, 22.243489265441895, 26.227938413619995, 30.37569499015808, 34.32033181190491, 38.230772972106934, 42.272613763809204, 46.39670729637146, 50.570189476013184, 54.76484155654907, 58.79729628562927, 62.79767918586731, 66.84819865226746, 70.88079977035522, 74.94086337089539, 78.93339490890503, 82.92117404937744, 86.99483728408813, 90.99907970428467, 95.05931305885315, 99.0895504951477, 103.31810283660889, 107.47660446166992, 111.51078987121582, 115.54952716827393, 119.73139119148254, 123.76689553260803, 127.92483901977539, 132.06474018096924, 136.04298496246338, 140.06452775001526, 144.1959948539734, 148.24290680885315, 152.28202962875366, 156.39852333068848, 160.51636266708374, 164.5336103439331, 168.66906690597534, 172.66724371910095, 176.59447860717773, 180.5840654373169, 184.5945496559143, 188.90741539001465, 193.0114185810089, 197.1783938407898, 201.2904713153839, 205.2354438304901, 209.6628601551056]
[53.4, 55.9, 70.6, 54.75, 77.05, 73.55, 81.3, 82.0, 83.25, 81.05, 78.45, 87.15, 84.7, 85.65, 87.55, 85.05, 87.65, 86.35, 87.75, 87.7, 86.1, 89.1, 85.55, 88.6, 88.6, 87.55, 88.65, 89.6, 89.75, 89.8, 89.65, 89.25, 87.35, 89.9, 89.2, 90.25, 89.6, 90.1, 89.4, 89.9, 90.05, 89.6, 89.7, 90.4, 90.15, 89.85, 90.55, 90.55, 89.85, 90.85, 90.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.514, Test loss: 0.407, Test accuracy: 84.95 

Round   0, Global train loss: 0.514, Global test loss: 0.742, Global test accuracy: 50.00 

Round   1, Train loss: 0.350, Test loss: 0.360, Test accuracy: 86.15 

Round   1, Global train loss: 0.350, Global test loss: 0.763, Global test accuracy: 50.00 

Round   2, Train loss: 0.290, Test loss: 0.373, Test accuracy: 86.10 

Round   2, Global train loss: 0.290, Global test loss: 0.722, Global test accuracy: 50.00 

Round   3, Train loss: 0.248, Test loss: 0.388, Test accuracy: 86.30 

Round   3, Global train loss: 0.248, Global test loss: 0.713, Global test accuracy: 50.00 

Round   4, Train loss: 0.224, Test loss: 0.378, Test accuracy: 85.45 

Round   4, Global train loss: 0.224, Global test loss: 0.732, Global test accuracy: 50.00 

Round   5, Train loss: 0.192, Test loss: 0.382, Test accuracy: 87.35 

Round   5, Global train loss: 0.192, Global test loss: 0.713, Global test accuracy: 50.00 

Round   6, Train loss: 0.174, Test loss: 0.339, Test accuracy: 88.60 

Round   6, Global train loss: 0.174, Global test loss: 0.713, Global test accuracy: 50.00 

Round   7, Train loss: 0.154, Test loss: 0.366, Test accuracy: 87.25 

Round   7, Global train loss: 0.154, Global test loss: 0.710, Global test accuracy: 50.00 

Round   8, Train loss: 0.142, Test loss: 0.356, Test accuracy: 88.75 

Round   8, Global train loss: 0.142, Global test loss: 0.701, Global test accuracy: 50.00 

Round   9, Train loss: 0.113, Test loss: 0.416, Test accuracy: 87.95 

Round   9, Global train loss: 0.113, Global test loss: 0.724, Global test accuracy: 50.00 

Round  10, Train loss: 0.096, Test loss: 0.411, Test accuracy: 88.35 

Round  10, Global train loss: 0.096, Global test loss: 0.719, Global test accuracy: 50.00 

Round  11, Train loss: 0.083, Test loss: 0.420, Test accuracy: 88.95 

Round  11, Global train loss: 0.083, Global test loss: 0.728, Global test accuracy: 50.00 

Round  12, Train loss: 0.080, Test loss: 0.350, Test accuracy: 90.30 

Round  12, Global train loss: 0.080, Global test loss: 0.701, Global test accuracy: 50.00 

Round  13, Train loss: 0.084, Test loss: 0.542, Test accuracy: 87.15 

Round  13, Global train loss: 0.084, Global test loss: 0.695, Global test accuracy: 50.00 

Round  14, Train loss: 0.071, Test loss: 0.398, Test accuracy: 88.55 

Round  14, Global train loss: 0.071, Global test loss: 0.700, Global test accuracy: 50.00 

Round  15, Train loss: 0.050, Test loss: 0.568, Test accuracy: 87.30 

Round  15, Global train loss: 0.050, Global test loss: 0.730, Global test accuracy: 50.00 

Round  16, Train loss: 0.055, Test loss: 0.394, Test accuracy: 89.65 

Round  16, Global train loss: 0.055, Global test loss: 0.701, Global test accuracy: 50.00 

Round  17, Train loss: 0.036, Test loss: 0.391, Test accuracy: 90.25 

Round  17, Global train loss: 0.036, Global test loss: 0.692, Global test accuracy: 50.00 

Round  18, Train loss: 0.043, Test loss: 0.436, Test accuracy: 88.85 

Round  18, Global train loss: 0.043, Global test loss: 0.698, Global test accuracy: 50.00 

Round  19, Train loss: 0.041, Test loss: 0.558, Test accuracy: 86.90 

Round  19, Global train loss: 0.041, Global test loss: 0.693, Global test accuracy: 50.00 

Round  20, Train loss: 0.036, Test loss: 0.417, Test accuracy: 90.50 

Round  20, Global train loss: 0.036, Global test loss: 0.706, Global test accuracy: 50.00 

Round  21, Train loss: 0.037, Test loss: 0.417, Test accuracy: 90.20 

Round  21, Global train loss: 0.037, Global test loss: 0.705, Global test accuracy: 50.00 

Round  22, Train loss: 0.026, Test loss: 0.428, Test accuracy: 89.70 

Round  22, Global train loss: 0.026, Global test loss: 0.694, Global test accuracy: 50.00 

Round  23, Train loss: 0.031, Test loss: 0.401, Test accuracy: 90.25 

Round  23, Global train loss: 0.031, Global test loss: 0.712, Global test accuracy: 50.00 

Round  24, Train loss: 0.017, Test loss: 0.425, Test accuracy: 90.20 

Round  24, Global train loss: 0.017, Global test loss: 0.707, Global test accuracy: 50.00 

Round  25, Train loss: 0.022, Test loss: 0.394, Test accuracy: 90.85 

Round  25, Global train loss: 0.022, Global test loss: 0.701, Global test accuracy: 50.00 

Round  26, Train loss: 0.017, Test loss: 0.393, Test accuracy: 90.55 

Round  26, Global train loss: 0.017, Global test loss: 0.712, Global test accuracy: 50.00 

Round  27, Train loss: 0.017, Test loss: 0.409, Test accuracy: 90.85 

Round  27, Global train loss: 0.017, Global test loss: 0.699, Global test accuracy: 50.00 

Round  28, Train loss: 0.014, Test loss: 0.421, Test accuracy: 90.50 

Round  28, Global train loss: 0.014, Global test loss: 0.722, Global test accuracy: 50.00 

Round  29, Train loss: 0.013, Test loss: 0.409, Test accuracy: 90.40 

Round  29, Global train loss: 0.013, Global test loss: 0.737, Global test accuracy: 50.00 

Round  30, Train loss: 0.020, Test loss: 0.393, Test accuracy: 90.95 

Round  30, Global train loss: 0.020, Global test loss: 0.701, Global test accuracy: 50.00 

Round  31, Train loss: 0.021, Test loss: 0.399, Test accuracy: 90.85 

Round  31, Global train loss: 0.021, Global test loss: 0.731, Global test accuracy: 50.00 

Round  32, Train loss: 0.011, Test loss: 0.445, Test accuracy: 90.15 

Round  32, Global train loss: 0.011, Global test loss: 0.708, Global test accuracy: 50.00 

Round  33, Train loss: 0.008, Test loss: 0.456, Test accuracy: 90.45 

Round  33, Global train loss: 0.008, Global test loss: 0.693, Global test accuracy: 50.00 

Round  34, Train loss: 0.009, Test loss: 0.476, Test accuracy: 89.35 

Round  34, Global train loss: 0.009, Global test loss: 0.692, Global test accuracy: 50.00 

Final Round, Train loss: 0.010, Test loss: 0.467, Test accuracy: 90.35 

Final Round, Global train loss: 0.010, Global test loss: 0.692, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 90.49000000000001 

Average global accuracy final 10 rounds: 50.0 

937.309504032135
[6.765969514846802, 11.688749074935913, 16.454622507095337, 21.062324285507202, 25.753477334976196, 30.37079954147339, 34.85035562515259, 39.39045596122742, 43.91443204879761, 48.50580024719238, 52.96441578865051, 57.532395362854004, 62.24930119514465, 66.97930908203125, 71.65584826469421, 76.20565509796143, 80.7877049446106, 85.29560279846191, 89.7501962184906, 94.54213380813599, 99.05633664131165, 103.92613434791565, 108.41046833992004, 112.93638205528259, 117.45091390609741, 122.10457158088684, 127.01381874084473, 131.9556164741516, 136.43367886543274, 140.9470236301422, 145.4994513988495, 149.95936179161072, 154.47447419166565, 159.0625467300415, 163.56373238563538, 172.7635519504547]
[84.95, 86.15, 86.1, 86.3, 85.45, 87.35, 88.6, 87.25, 88.75, 87.95, 88.35, 88.95, 90.3, 87.15, 88.55, 87.3, 89.65, 90.25, 88.85, 86.9, 90.5, 90.2, 89.7, 90.25, 90.2, 90.85, 90.55, 90.85, 90.5, 90.4, 90.95, 90.85, 90.15, 90.45, 89.35, 90.35]
./start_train: 行 77: 36065 已终止               python main_fedrep.py --alg fedavg --epochs 35 --num_users 5 --shard_per_user 2 --limit_local_output 1 --local_rep_ep 3 --local_only 0 --is_reset_dataset 0 --is_concept_shift 0 --frac 1 --dataset cifar10 --model resnet18 --moment 0.5 --is_reset_model 0 --gpu 0 --nums_per_class 200
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Traceback (most recent call last):
  File "main_fedrep.py", line 97, in <module>
    net_glob.load_state_dict(torch.load(model_init_save_path))
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1672, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ResNet:
	size mismatch for linear.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).
	size mismatch for linear.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([2]).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 98, in <module>
    net_glob.load_state_dict(torch.load(model_init_save_path))
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1672, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ResNet:
	size mismatch for linear.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).
	size mismatch for linear.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([2]).
