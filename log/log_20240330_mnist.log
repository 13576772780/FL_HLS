nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.590, Test loss: 1.550, Test accuracy: 77.22
Round   0, Global train loss: 1.590, Global test loss: 1.550, Global test accuracy: 78.31
Round   1, Train loss: 1.333, Test loss: 1.184, Test accuracy: 89.04
Round   1, Global train loss: 1.333, Global test loss: 1.064, Global test accuracy: 93.26
Round   2, Train loss: 1.107, Test loss: 1.100, Test accuracy: 91.62
Round   2, Global train loss: 1.107, Global test loss: 0.985, Global test accuracy: 95.54
Round   3, Train loss: 1.026, Test loss: 1.056, Test accuracy: 92.80
Round   3, Global train loss: 1.026, Global test loss: 0.962, Global test accuracy: 96.59
Round   4, Train loss: 1.019, Test loss: 1.025, Test accuracy: 94.21
Round   4, Global train loss: 1.019, Global test loss: 0.958, Global test accuracy: 96.69
Round   5, Train loss: 1.032, Test loss: 0.985, Test accuracy: 95.06
Round   5, Global train loss: 1.032, Global test loss: 0.970, Global test accuracy: 95.83
Round   6, Train loss: 0.942, Test loss: 0.976, Test accuracy: 95.33
Round   6, Global train loss: 0.942, Global test loss: 0.951, Global test accuracy: 96.62
Round   7, Train loss: 0.946, Test loss: 0.969, Test accuracy: 95.79
Round   7, Global train loss: 0.946, Global test loss: 0.950, Global test accuracy: 96.75
Round   8, Train loss: 0.947, Test loss: 0.959, Test accuracy: 96.06
Round   8, Global train loss: 0.947, Global test loss: 0.949, Global test accuracy: 96.85
Round   9, Train loss: 0.927, Test loss: 0.959, Test accuracy: 96.01
Round   9, Global train loss: 0.927, Global test loss: 0.943, Global test accuracy: 96.93
Round  10, Train loss: 0.925, Test loss: 0.957, Test accuracy: 96.00
Round  10, Global train loss: 0.925, Global test loss: 0.946, Global test accuracy: 96.76
Round  11, Train loss: 0.930, Test loss: 0.955, Test accuracy: 96.09
Round  11, Global train loss: 0.930, Global test loss: 0.947, Global test accuracy: 96.75
Round  12, Train loss: 0.926, Test loss: 0.953, Test accuracy: 96.15
Round  12, Global train loss: 0.926, Global test loss: 0.944, Global test accuracy: 97.20
Round  13, Train loss: 0.924, Test loss: 0.952, Test accuracy: 96.19
Round  13, Global train loss: 0.924, Global test loss: 0.943, Global test accuracy: 96.95
Round  14, Train loss: 0.917, Test loss: 0.952, Test accuracy: 96.20
Round  14, Global train loss: 0.917, Global test loss: 0.941, Global test accuracy: 97.06
Round  15, Train loss: 0.920, Test loss: 0.951, Test accuracy: 96.22
Round  15, Global train loss: 0.920, Global test loss: 0.939, Global test accuracy: 97.30
Round  16, Train loss: 0.917, Test loss: 0.951, Test accuracy: 96.22
Round  16, Global train loss: 0.917, Global test loss: 0.939, Global test accuracy: 97.22
Round  17, Train loss: 0.918, Test loss: 0.950, Test accuracy: 96.24
Round  17, Global train loss: 0.918, Global test loss: 0.941, Global test accuracy: 96.98
Round  18, Train loss: 0.915, Test loss: 0.950, Test accuracy: 96.26
Round  18, Global train loss: 0.915, Global test loss: 0.939, Global test accuracy: 97.09
Round  19, Train loss: 0.913, Test loss: 0.949, Test accuracy: 96.27
Round  19, Global train loss: 0.913, Global test loss: 0.939, Global test accuracy: 97.27
Round  20, Train loss: 0.916, Test loss: 0.949, Test accuracy: 96.21
Round  20, Global train loss: 0.916, Global test loss: 0.940, Global test accuracy: 97.06
Round  21, Train loss: 0.915, Test loss: 0.949, Test accuracy: 96.23
Round  21, Global train loss: 0.915, Global test loss: 0.937, Global test accuracy: 97.40
Round  22, Train loss: 0.915, Test loss: 0.949, Test accuracy: 96.20
Round  22, Global train loss: 0.915, Global test loss: 0.940, Global test accuracy: 97.13
Round  23, Train loss: 0.912, Test loss: 0.949, Test accuracy: 96.21
Round  23, Global train loss: 0.912, Global test loss: 0.937, Global test accuracy: 97.21
Round  24, Train loss: 0.913, Test loss: 0.948, Test accuracy: 96.25
Round  24, Global train loss: 0.913, Global test loss: 0.938, Global test accuracy: 97.37
Round  25, Train loss: 0.912, Test loss: 0.948, Test accuracy: 96.27
Round  25, Global train loss: 0.912, Global test loss: 0.941, Global test accuracy: 96.89
Round  26, Train loss: 0.912, Test loss: 0.948, Test accuracy: 96.23
Round  26, Global train loss: 0.912, Global test loss: 0.940, Global test accuracy: 97.04
Round  27, Train loss: 0.914, Test loss: 0.948, Test accuracy: 96.24
Round  27, Global train loss: 0.914, Global test loss: 0.938, Global test accuracy: 97.03
Round  28, Train loss: 0.913, Test loss: 0.948, Test accuracy: 96.26
Round  28, Global train loss: 0.913, Global test loss: 0.937, Global test accuracy: 97.18
Round  29, Train loss: 0.913, Test loss: 0.948, Test accuracy: 96.24
Round  29, Global train loss: 0.913, Global test loss: 0.937, Global test accuracy: 97.15
Round  30, Train loss: 0.911, Test loss: 0.947, Test accuracy: 96.24
Round  30, Global train loss: 0.911, Global test loss: 0.939, Global test accuracy: 97.08
Round  31, Train loss: 0.913, Test loss: 0.948, Test accuracy: 96.20
Round  31, Global train loss: 0.913, Global test loss: 0.938, Global test accuracy: 97.27
Round  32, Train loss: 0.912, Test loss: 0.947, Test accuracy: 96.22
Round  32, Global train loss: 0.912, Global test loss: 0.939, Global test accuracy: 96.91
Round  33, Train loss: 0.909, Test loss: 0.947, Test accuracy: 96.22
Round  33, Global train loss: 0.909, Global test loss: 0.937, Global test accuracy: 97.24
Round  34, Train loss: 0.910, Test loss: 0.947, Test accuracy: 96.18
Round  34, Global train loss: 0.910, Global test loss: 0.940, Global test accuracy: 96.89
Round  35, Train loss: 0.913, Test loss: 0.947, Test accuracy: 96.16
Round  35, Global train loss: 0.913, Global test loss: 0.938, Global test accuracy: 96.95
Round  36, Train loss: 0.909, Test loss: 0.947, Test accuracy: 96.21
Round  36, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.27
Round  37, Train loss: 0.911, Test loss: 0.947, Test accuracy: 96.19
Round  37, Global train loss: 0.911, Global test loss: 0.938, Global test accuracy: 96.96
Round  38, Train loss: 0.912, Test loss: 0.947, Test accuracy: 96.20
Round  38, Global train loss: 0.912, Global test loss: 0.937, Global test accuracy: 97.21
Round  39, Train loss: 0.911, Test loss: 0.947, Test accuracy: 96.18
Round  39, Global train loss: 0.911, Global test loss: 0.936, Global test accuracy: 97.25
Round  40, Train loss: 0.911, Test loss: 0.947, Test accuracy: 96.15
Round  40, Global train loss: 0.911, Global test loss: 0.936, Global test accuracy: 97.24
Round  41, Train loss: 0.911, Test loss: 0.946, Test accuracy: 96.19
Round  41, Global train loss: 0.911, Global test loss: 0.936, Global test accuracy: 97.25
Round  42, Train loss: 0.911, Test loss: 0.946, Test accuracy: 96.23
Round  42, Global train loss: 0.911, Global test loss: 0.936, Global test accuracy: 97.48
Round  43, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.24
Round  43, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.20
Round  44, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.26
Round  44, Global train loss: 0.910, Global test loss: 0.934, Global test accuracy: 97.50
Round  45, Train loss: 0.912, Test loss: 0.946, Test accuracy: 96.26
Round  45, Global train loss: 0.912, Global test loss: 0.934, Global test accuracy: 97.41
Round  46, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.27
Round  46, Global train loss: 0.910, Global test loss: 0.937, Global test accuracy: 97.19
Round  47, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.25
Round  47, Global train loss: 0.910, Global test loss: 0.936, Global test accuracy: 97.28
Round  48, Train loss: 0.912, Test loss: 0.946, Test accuracy: 96.25
Round  48, Global train loss: 0.912, Global test loss: 0.935, Global test accuracy: 97.51
Round  49, Train loss: 0.912, Test loss: 0.946, Test accuracy: 96.25
Round  49, Global train loss: 0.912, Global test loss: 0.936, Global test accuracy: 97.21
Round  50, Train loss: 0.913, Test loss: 0.946, Test accuracy: 96.23
Round  50, Global train loss: 0.913, Global test loss: 0.936, Global test accuracy: 97.22
Round  51, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.23
Round  51, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.29
Round  52, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.22
Round  52, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.29
Round  53, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.22
Round  53, Global train loss: 0.909, Global test loss: 0.934, Global test accuracy: 97.36
Round  54, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.23
Round  54, Global train loss: 0.910, Global test loss: 0.935, Global test accuracy: 97.31
Round  55, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.22
Round  55, Global train loss: 0.910, Global test loss: 0.939, Global test accuracy: 96.95
Round  56, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.20
Round  56, Global train loss: 0.908, Global test loss: 0.935, Global test accuracy: 97.32
Round  57, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.20
Round  57, Global train loss: 0.910, Global test loss: 0.935, Global test accuracy: 97.25
Round  58, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.21
Round  58, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.32
Round  59, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.18
Round  59, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.24
Round  60, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.18
Round  60, Global train loss: 0.909, Global test loss: 0.934, Global test accuracy: 97.35
Round  61, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.16
Round  61, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.18
Round  62, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.16
Round  62, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.30
Round  63, Train loss: 0.911, Test loss: 0.946, Test accuracy: 96.17
Round  63, Global train loss: 0.911, Global test loss: 0.935, Global test accuracy: 97.23
Round  64, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.15
Round  64, Global train loss: 0.910, Global test loss: 0.937, Global test accuracy: 97.10
Round  65, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.18
Round  65, Global train loss: 0.910, Global test loss: 0.935, Global test accuracy: 97.44
Round  66, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.19
Round  66, Global train loss: 0.908, Global test loss: 0.933, Global test accuracy: 97.51
Round  67, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.21
Round  67, Global train loss: 0.909, Global test loss: 0.933, Global test accuracy: 97.32
Round  68, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.20
Round  68, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.35
Round  69, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.17
Round  69, Global train loss: 0.910, Global test loss: 0.934, Global test accuracy: 97.36
Round  70, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.17
Round  70, Global train loss: 0.910, Global test loss: 0.937, Global test accuracy: 96.91
Round  71, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.16
Round  71, Global train loss: 0.910, Global test loss: 0.935, Global test accuracy: 97.42
Round  72, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.17
Round  72, Global train loss: 0.910, Global test loss: 0.934, Global test accuracy: 97.28
Round  73, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.17
Round  73, Global train loss: 0.908, Global test loss: 0.935, Global test accuracy: 97.36
Round  74, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.18
Round  74, Global train loss: 0.909, Global test loss: 0.934, Global test accuracy: 97.30
Round  75, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.18
Round  75, Global train loss: 0.910, Global test loss: 0.935, Global test accuracy: 97.38
Round  76, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.18
Round  76, Global train loss: 0.908, Global test loss: 0.934, Global test accuracy: 97.26
Round  77, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.18
Round  77, Global train loss: 0.908, Global test loss: 0.935, Global test accuracy: 97.10
Round  78, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.18
Round  78, Global train loss: 0.908, Global test loss: 0.934, Global test accuracy: 97.33
Round  79, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.16
Round  79, Global train loss: 0.910, Global test loss: 0.934, Global test accuracy: 97.34
Round  80, Train loss: 0.908, Test loss: 0.946, Test accuracy: 96.15
Round  80, Global train loss: 0.908, Global test loss: 0.935, Global test accuracy: 97.30
Round  81, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.15
Round  81, Global train loss: 0.910, Global test loss: 0.934, Global test accuracy: 97.31
Round  82, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.15
Round  82, Global train loss: 0.910, Global test loss: 0.937, Global test accuracy: 97.11
Round  83, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.15
Round  83, Global train loss: 0.910, Global test loss: 0.933, Global test accuracy: 97.50
Round  84, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.15
Round  84, Global train loss: 0.910, Global test loss: 0.933, Global test accuracy: 97.43
Round  85, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.15
Round  85, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.35
Round  86, Train loss: 0.910, Test loss: 0.946, Test accuracy: 96.15
Round  86, Global train loss: 0.910, Global test loss: 0.934, Global test accuracy: 97.37
Round  87, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.15
Round  87, Global train loss: 0.909, Global test loss: 0.933, Global test accuracy: 97.49
Round  88, Train loss: 0.909, Test loss: 0.946, Test accuracy: 96.15
Round  88, Global train loss: 0.909, Global test loss: 0.936, Global test accuracy: 97.09
Round  89, Train loss: 0.909, Test loss: 0.945, Test accuracy: 96.14
Round  89, Global train loss: 0.909, Global test loss: 0.934, Global test accuracy: 97.36
Round  90, Train loss: 0.909, Test loss: 0.945, Test accuracy: 96.13
Round  90, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.08
Round  91, Train loss: 0.910, Test loss: 0.945, Test accuracy: 96.14
Round  91, Global train loss: 0.910, Global test loss: 0.935, Global test accuracy: 97.24
Round  92, Train loss: 0.909, Test loss: 0.945, Test accuracy: 96.14
Round  92, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.29
Round  93, Train loss: 0.908, Test loss: 0.945, Test accuracy: 96.13
Round  93, Global train loss: 0.908, Global test loss: 0.934, Global test accuracy: 97.45
Round  94, Train loss: 0.911, Test loss: 0.945, Test accuracy: 96.10
Round  94, Global train loss: 0.911, Global test loss: 0.934, Global test accuracy: 97.27
Round  95, Train loss: 0.908, Test loss: 0.945, Test accuracy: 96.12
Round  95, Global train loss: 0.908, Global test loss: 0.935, Global test accuracy: 97.32/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.909, Test loss: 0.945, Test accuracy: 96.12
Round  96, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.13
Round  97, Train loss: 0.908, Test loss: 0.945, Test accuracy: 96.11
Round  97, Global train loss: 0.908, Global test loss: 0.932, Global test accuracy: 97.54
Round  98, Train loss: 0.910, Test loss: 0.945, Test accuracy: 96.11
Round  98, Global train loss: 0.910, Global test loss: 0.937, Global test accuracy: 96.97
Round  99, Train loss: 0.909, Test loss: 0.945, Test accuracy: 96.11
Round  99, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.31
Final Round, Train loss: 0.909, Test loss: 0.945, Test accuracy: 96.12
Final Round, Global train loss: 0.909, Global test loss: 0.935, Global test accuracy: 97.31
Average accuracy final 10 rounds: 96.12100000000001 

Average global accuracy final 10 rounds: 97.26 

1177.570641040802
[0.8605928421020508, 1.7211856842041016, 2.381195306777954, 3.0412049293518066, 3.704468011856079, 4.367731094360352, 5.09572434425354, 5.8237175941467285, 6.507359266281128, 7.191000938415527, 7.8925440311431885, 8.59408712387085, 9.329149007797241, 10.064210891723633, 10.771769046783447, 11.479327201843262, 12.205169439315796, 12.93101167678833, 13.669947147369385, 14.40888261795044, 15.139842748641968, 15.870802879333496, 16.587830781936646, 17.304858684539795, 18.005576848983765, 18.706295013427734, 19.444516897201538, 20.182738780975342, 20.917213201522827, 21.651687622070312, 22.389549732208252, 23.12741184234619, 23.843881130218506, 24.56035041809082, 25.259803295135498, 25.959256172180176, 26.708117246627808, 27.45697832107544, 28.214112043380737, 28.971245765686035, 29.71084690093994, 30.450448036193848, 31.16860032081604, 31.886752605438232, 32.59271264076233, 33.298672676086426, 34.017653942108154, 34.73663520812988, 35.46777653694153, 36.198917865753174, 36.92924427986145, 37.65957069396973, 38.40266442298889, 39.14575815200806, 39.87835717201233, 40.6109561920166, 41.30963492393494, 42.00831365585327, 42.75730538368225, 43.50629711151123, 44.2501118183136, 44.99392652511597, 45.74471616744995, 46.495505809783936, 47.20566248893738, 47.91581916809082, 48.61731195449829, 49.31880474090576, 50.080472469329834, 50.842140197753906, 51.61914086341858, 52.39614152908325, 53.164201498031616, 53.93226146697998, 54.64486479759216, 55.357468128204346, 56.13771343231201, 56.91795873641968, 57.678330183029175, 58.43870162963867, 59.190747022628784, 59.9427924156189, 60.67947769165039, 61.416162967681885, 62.14384579658508, 62.87152862548828, 63.59613490104675, 64.32074117660522, 65.05239248275757, 65.78404378890991, 66.52494740486145, 67.26585102081299, 67.99304723739624, 68.72024345397949, 69.42872333526611, 70.13720321655273, 70.83935236930847, 71.54150152206421, 72.2921211719513, 73.04274082183838, 73.78404664993286, 74.52535247802734, 75.26525378227234, 76.00515508651733, 76.73264479637146, 77.46013450622559, 78.18180537223816, 78.90347623825073, 79.69166398048401, 80.47985172271729, 81.23850965499878, 81.99716758728027, 82.7422821521759, 83.48739671707153, 84.23068833351135, 84.97397994995117, 85.70900249481201, 86.44402503967285, 87.13781118392944, 87.83159732818604, 88.53888869285583, 89.24618005752563, 89.99505686759949, 90.74393367767334, 91.4912497997284, 92.23856592178345, 92.9528419971466, 93.66711807250977, 94.38325357437134, 95.09938907623291, 95.82957243919373, 96.55975580215454, 97.30108547210693, 98.04241514205933, 98.85360169410706, 99.66478824615479, 100.38626718521118, 101.10774612426758, 101.82638573646545, 102.54502534866333, 103.27651071548462, 104.00799608230591, 104.73626518249512, 105.46453428268433, 106.19148826599121, 106.9184422492981, 107.64948439598083, 108.38052654266357, 109.1163878440857, 109.85224914550781, 110.57534098625183, 111.29843282699585, 112.0378770828247, 112.77732133865356, 113.52228331565857, 114.26724529266357, 115.00425863265991, 115.74127197265625, 116.4703540802002, 117.19943618774414, 117.90926671028137, 118.6190972328186, 119.34410047531128, 120.06910371780396, 120.80725932121277, 121.54541492462158, 122.28295707702637, 123.02049922943115, 123.75431156158447, 124.4881238937378, 125.20737528800964, 125.9266266822815, 126.65502166748047, 127.38341665267944, 128.11937761306763, 128.8553385734558, 129.58558201789856, 130.3158254623413, 131.03323078155518, 131.75063610076904, 132.4683074951172, 133.18597888946533, 133.9148108959198, 134.64364290237427, 135.3825080394745, 136.1213731765747, 136.8537311553955, 137.5860891342163, 138.30431127548218, 139.02253341674805, 139.756605386734, 140.49067735671997, 141.2239830493927, 141.95728874206543, 142.69249558448792, 143.4277024269104, 144.1479070186615, 144.8681116104126, 145.58478116989136, 146.30145072937012, 147.7555844783783, 149.20971822738647]
[77.22, 77.22, 89.04, 89.04, 91.62, 91.62, 92.8, 92.8, 94.21, 94.21, 95.06, 95.06, 95.33, 95.33, 95.79, 95.79, 96.06, 96.06, 96.01, 96.01, 96.0, 96.0, 96.09, 96.09, 96.15, 96.15, 96.19, 96.19, 96.2, 96.2, 96.22, 96.22, 96.22, 96.22, 96.24, 96.24, 96.26, 96.26, 96.27, 96.27, 96.21, 96.21, 96.23, 96.23, 96.2, 96.2, 96.21, 96.21, 96.25, 96.25, 96.27, 96.27, 96.23, 96.23, 96.24, 96.24, 96.26, 96.26, 96.24, 96.24, 96.24, 96.24, 96.2, 96.2, 96.22, 96.22, 96.22, 96.22, 96.18, 96.18, 96.16, 96.16, 96.21, 96.21, 96.19, 96.19, 96.2, 96.2, 96.18, 96.18, 96.15, 96.15, 96.19, 96.19, 96.23, 96.23, 96.24, 96.24, 96.26, 96.26, 96.26, 96.26, 96.27, 96.27, 96.25, 96.25, 96.25, 96.25, 96.25, 96.25, 96.23, 96.23, 96.23, 96.23, 96.22, 96.22, 96.22, 96.22, 96.23, 96.23, 96.22, 96.22, 96.2, 96.2, 96.2, 96.2, 96.21, 96.21, 96.18, 96.18, 96.18, 96.18, 96.16, 96.16, 96.16, 96.16, 96.17, 96.17, 96.15, 96.15, 96.18, 96.18, 96.19, 96.19, 96.21, 96.21, 96.2, 96.2, 96.17, 96.17, 96.17, 96.17, 96.16, 96.16, 96.17, 96.17, 96.17, 96.17, 96.18, 96.18, 96.18, 96.18, 96.18, 96.18, 96.18, 96.18, 96.18, 96.18, 96.16, 96.16, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.15, 96.14, 96.14, 96.13, 96.13, 96.14, 96.14, 96.14, 96.14, 96.13, 96.13, 96.1, 96.1, 96.12, 96.12, 96.12, 96.12, 96.11, 96.11, 96.11, 96.11, 96.11, 96.11, 96.12, 96.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.582, Test loss: 1.514, Test accuracy: 78.29
Round   0, Global train loss: 1.582, Global test loss: 1.514, Global test accuracy: 79.68
Round   1, Train loss: 1.234, Test loss: 1.096, Test accuracy: 91.03
Round   1, Global train loss: 1.234, Global test loss: 1.017, Global test accuracy: 95.19
Round   2, Train loss: 0.976, Test loss: 1.061, Test accuracy: 91.70
Round   2, Global train loss: 0.976, Global test loss: 0.959, Global test accuracy: 96.28
Round   3, Train loss: 0.947, Test loss: 1.020, Test accuracy: 93.39
Round   3, Global train loss: 0.947, Global test loss: 0.946, Global test accuracy: 96.84
Round   4, Train loss: 0.945, Test loss: 0.989, Test accuracy: 95.13
Round   4, Global train loss: 0.945, Global test loss: 0.940, Global test accuracy: 97.30
Round   5, Train loss: 0.932, Test loss: 0.976, Test accuracy: 95.54
Round   5, Global train loss: 0.932, Global test loss: 0.937, Global test accuracy: 97.33
Round   6, Train loss: 0.933, Test loss: 0.947, Test accuracy: 96.59
Round   6, Global train loss: 0.933, Global test loss: 0.935, Global test accuracy: 97.42
Round   7, Train loss: 0.931, Test loss: 0.941, Test accuracy: 96.89
Round   7, Global train loss: 0.931, Global test loss: 0.932, Global test accuracy: 97.70
Round   8, Train loss: 0.930, Test loss: 0.939, Test accuracy: 97.07
Round   8, Global train loss: 0.930, Global test loss: 0.931, Global test accuracy: 97.72
Round   9, Train loss: 0.926, Test loss: 0.937, Test accuracy: 97.13
Round   9, Global train loss: 0.926, Global test loss: 0.931, Global test accuracy: 97.82
Round  10, Train loss: 0.925, Test loss: 0.937, Test accuracy: 97.14
Round  10, Global train loss: 0.925, Global test loss: 0.930, Global test accuracy: 97.75
Round  11, Train loss: 0.925, Test loss: 0.936, Test accuracy: 97.23
Round  11, Global train loss: 0.925, Global test loss: 0.929, Global test accuracy: 97.89
Round  12, Train loss: 0.920, Test loss: 0.934, Test accuracy: 97.27
Round  12, Global train loss: 0.920, Global test loss: 0.928, Global test accuracy: 97.78
Round  13, Train loss: 0.921, Test loss: 0.933, Test accuracy: 97.36
Round  13, Global train loss: 0.921, Global test loss: 0.928, Global test accuracy: 97.89
Round  14, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.47
Round  14, Global train loss: 0.920, Global test loss: 0.928, Global test accuracy: 97.85
Round  15, Train loss: 0.924, Test loss: 0.931, Test accuracy: 97.50
Round  15, Global train loss: 0.924, Global test loss: 0.928, Global test accuracy: 97.88
Round  16, Train loss: 0.920, Test loss: 0.931, Test accuracy: 97.52
Round  16, Global train loss: 0.920, Global test loss: 0.927, Global test accuracy: 98.00
Round  17, Train loss: 0.920, Test loss: 0.930, Test accuracy: 97.60
Round  17, Global train loss: 0.920, Global test loss: 0.926, Global test accuracy: 98.10
Round  18, Train loss: 0.918, Test loss: 0.930, Test accuracy: 97.64
Round  18, Global train loss: 0.918, Global test loss: 0.926, Global test accuracy: 98.03
Round  19, Train loss: 0.920, Test loss: 0.930, Test accuracy: 97.62
Round  19, Global train loss: 0.920, Global test loss: 0.926, Global test accuracy: 98.09
Round  20, Train loss: 0.917, Test loss: 0.930, Test accuracy: 97.71
Round  20, Global train loss: 0.917, Global test loss: 0.926, Global test accuracy: 98.16
Round  21, Train loss: 0.916, Test loss: 0.929, Test accuracy: 97.79
Round  21, Global train loss: 0.916, Global test loss: 0.925, Global test accuracy: 98.07
Round  22, Train loss: 0.916, Test loss: 0.929, Test accuracy: 97.81
Round  22, Global train loss: 0.916, Global test loss: 0.925, Global test accuracy: 98.08
Round  23, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.83
Round  23, Global train loss: 0.917, Global test loss: 0.924, Global test accuracy: 98.13
Round  24, Train loss: 0.916, Test loss: 0.928, Test accuracy: 97.86
Round  24, Global train loss: 0.916, Global test loss: 0.924, Global test accuracy: 98.04
Round  25, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.85
Round  25, Global train loss: 0.917, Global test loss: 0.924, Global test accuracy: 98.24
Round  26, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.86
Round  26, Global train loss: 0.918, Global test loss: 0.924, Global test accuracy: 98.20
Round  27, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.91
Round  27, Global train loss: 0.917, Global test loss: 0.924, Global test accuracy: 98.16
Round  28, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.98
Round  28, Global train loss: 0.916, Global test loss: 0.924, Global test accuracy: 98.17
Round  29, Train loss: 0.914, Test loss: 0.926, Test accuracy: 98.00
Round  29, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.24
Round  30, Train loss: 0.915, Test loss: 0.926, Test accuracy: 97.96
Round  30, Global train loss: 0.915, Global test loss: 0.924, Global test accuracy: 98.19
Round  31, Train loss: 0.917, Test loss: 0.926, Test accuracy: 97.99
Round  31, Global train loss: 0.917, Global test loss: 0.924, Global test accuracy: 98.22
Round  32, Train loss: 0.914, Test loss: 0.926, Test accuracy: 98.00
Round  32, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.21
Round  33, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.02
Round  33, Global train loss: 0.915, Global test loss: 0.924, Global test accuracy: 98.17
Round  34, Train loss: 0.912, Test loss: 0.926, Test accuracy: 98.03
Round  34, Global train loss: 0.912, Global test loss: 0.923, Global test accuracy: 98.18
Round  35, Train loss: 0.913, Test loss: 0.926, Test accuracy: 98.02
Round  35, Global train loss: 0.913, Global test loss: 0.923, Global test accuracy: 98.31
Round  36, Train loss: 0.913, Test loss: 0.926, Test accuracy: 98.03
Round  36, Global train loss: 0.913, Global test loss: 0.923, Global test accuracy: 98.27
Round  37, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.03
Round  37, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.28
Round  38, Train loss: 0.910, Test loss: 0.925, Test accuracy: 98.04
Round  38, Global train loss: 0.910, Global test loss: 0.923, Global test accuracy: 98.28
Round  39, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.05
Round  39, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.24
Round  40, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.09
Round  40, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.36
Round  41, Train loss: 0.916, Test loss: 0.925, Test accuracy: 98.09
Round  41, Global train loss: 0.916, Global test loss: 0.923, Global test accuracy: 98.12
Round  42, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.12
Round  42, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.19
Round  43, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.12
Round  43, Global train loss: 0.912, Global test loss: 0.923, Global test accuracy: 98.20
Round  44, Train loss: 0.914, Test loss: 0.924, Test accuracy: 98.16
Round  44, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.17
Round  45, Train loss: 0.916, Test loss: 0.924, Test accuracy: 98.15
Round  45, Global train loss: 0.916, Global test loss: 0.922, Global test accuracy: 98.26
Round  46, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.15
Round  46, Global train loss: 0.912, Global test loss: 0.923, Global test accuracy: 98.29
Round  47, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.16
Round  47, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.34
Round  48, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.17
Round  48, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.39
Round  49, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.18
Round  49, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.31
Round  50, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.20
Round  50, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.27
Round  51, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.21
Round  51, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.36
Round  52, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.18
Round  52, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.25
Round  53, Train loss: 0.911, Test loss: 0.923, Test accuracy: 98.18
Round  53, Global train loss: 0.911, Global test loss: 0.921, Global test accuracy: 98.42
Round  54, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.21
Round  54, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.28
Round  55, Train loss: 0.915, Test loss: 0.923, Test accuracy: 98.20
Round  55, Global train loss: 0.915, Global test loss: 0.921, Global test accuracy: 98.43
Round  56, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.19
Round  56, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.41
Round  57, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.22
Round  57, Global train loss: 0.910, Global test loss: 0.921, Global test accuracy: 98.31
Round  58, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.22
Round  58, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.23
Round  59, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.24
Round  59, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.39
Round  60, Train loss: 0.911, Test loss: 0.923, Test accuracy: 98.25
Round  60, Global train loss: 0.911, Global test loss: 0.921, Global test accuracy: 98.46
Round  61, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.29
Round  61, Global train loss: 0.913, Global test loss: 0.921, Global test accuracy: 98.48
Round  62, Train loss: 0.915, Test loss: 0.924, Test accuracy: 98.19
Round  62, Global train loss: 0.915, Global test loss: 0.921, Global test accuracy: 98.56
Round  63, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.26
Round  63, Global train loss: 0.913, Global test loss: 0.921, Global test accuracy: 98.51
Round  64, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.26
Round  64, Global train loss: 0.913, Global test loss: 0.921, Global test accuracy: 98.52
Round  65, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.25
Round  65, Global train loss: 0.910, Global test loss: 0.921, Global test accuracy: 98.35
Round  66, Train loss: 0.914, Test loss: 0.923, Test accuracy: 98.20
Round  66, Global train loss: 0.914, Global test loss: 0.921, Global test accuracy: 98.58
Round  67, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.17
Round  67, Global train loss: 0.912, Global test loss: 0.921, Global test accuracy: 98.42
Round  68, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.18
Round  68, Global train loss: 0.910, Global test loss: 0.921, Global test accuracy: 98.45
Round  69, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.23
Round  69, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.57
Round  70, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.25
Round  70, Global train loss: 0.913, Global test loss: 0.920, Global test accuracy: 98.59
Round  71, Train loss: 0.910, Test loss: 0.922, Test accuracy: 98.25
Round  71, Global train loss: 0.910, Global test loss: 0.920, Global test accuracy: 98.48
Round  72, Train loss: 0.909, Test loss: 0.922, Test accuracy: 98.27
Round  72, Global train loss: 0.909, Global test loss: 0.920, Global test accuracy: 98.47
Round  73, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.26
Round  73, Global train loss: 0.913, Global test loss: 0.921, Global test accuracy: 98.34
Round  74, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.25
Round  74, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.63
Round  75, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.28
Round  75, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.59
Round  76, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.28
Round  76, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.59
Round  77, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.29
Round  77, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.59
Round  78, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.27
Round  78, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.56
Round  79, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.30
Round  79, Global train loss: 0.913, Global test loss: 0.920, Global test accuracy: 98.58
Round  80, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.31
Round  80, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.52
Round  81, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.34
Round  81, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.60
Round  82, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.33
Round  82, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.58
Round  83, Train loss: 0.910, Test loss: 0.922, Test accuracy: 98.33
Round  83, Global train loss: 0.910, Global test loss: 0.920, Global test accuracy: 98.55
Round  84, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.33
Round  84, Global train loss: 0.913, Global test loss: 0.920, Global test accuracy: 98.56
Round  85, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.34
Round  85, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.56
Round  86, Train loss: 0.912, Test loss: 0.921, Test accuracy: 98.35
Round  86, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.59
Round  87, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.34
Round  87, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.52
Round  88, Train loss: 0.912, Test loss: 0.921, Test accuracy: 98.34
Round  88, Global train loss: 0.912, Global test loss: 0.920, Global test accuracy: 98.57
Round  89, Train loss: 0.909, Test loss: 0.921, Test accuracy: 98.36
Round  89, Global train loss: 0.909, Global test loss: 0.920, Global test accuracy: 98.56
Round  90, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.38
Round  90, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.61
Round  91, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.36
Round  91, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.51
Round  92, Train loss: 0.910, Test loss: 0.921, Test accuracy: 98.35
Round  92, Global train loss: 0.910, Global test loss: 0.920, Global test accuracy: 98.48
Round  93, Train loss: 0.913, Test loss: 0.921, Test accuracy: 98.36
Round  93, Global train loss: 0.913, Global test loss: 0.920, Global test accuracy: 98.60
Round  94, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.37
Round  94, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.45
Round  95, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.38
Round  95, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.60/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.910, Test loss: 0.921, Test accuracy: 98.39
Round  96, Global train loss: 0.910, Global test loss: 0.920, Global test accuracy: 98.63
Round  97, Train loss: 0.910, Test loss: 0.921, Test accuracy: 98.41
Round  97, Global train loss: 0.910, Global test loss: 0.920, Global test accuracy: 98.57
Round  98, Train loss: 0.908, Test loss: 0.921, Test accuracy: 98.41
Round  98, Global train loss: 0.908, Global test loss: 0.920, Global test accuracy: 98.57
Round  99, Train loss: 0.909, Test loss: 0.921, Test accuracy: 98.42
Round  99, Global train loss: 0.909, Global test loss: 0.920, Global test accuracy: 98.57
Final Round, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.38
Final Round, Global train loss: 0.911, Global test loss: 0.920, Global test accuracy: 98.57
Average accuracy final 10 rounds: 98.383 

Average global accuracy final 10 rounds: 98.559 

1148.2946617603302
[0.7955567836761475, 1.591113567352295, 2.300147294998169, 3.009181022644043, 3.7097482681274414, 4.41031551361084, 5.119298219680786, 5.828280925750732, 6.52721643447876, 7.226151943206787, 7.936005353927612, 8.645858764648438, 9.364280223846436, 10.082701683044434, 10.80352783203125, 11.524353981018066, 12.245712518692017, 12.967071056365967, 13.670795202255249, 14.374519348144531, 15.098076343536377, 15.821633338928223, 16.541438579559326, 17.26124382019043, 17.959476709365845, 18.65770959854126, 19.364772081375122, 20.071834564208984, 20.77244520187378, 21.473055839538574, 22.183252573013306, 22.893449306488037, 23.58394193649292, 24.274434566497803, 24.97126340866089, 25.668092250823975, 26.378361225128174, 27.088630199432373, 27.820778369903564, 28.552926540374756, 29.262427806854248, 29.97192907333374, 30.695037364959717, 31.418145656585693, 32.1453275680542, 32.872509479522705, 33.6078405380249, 34.3431715965271, 35.03122591972351, 35.71928024291992, 36.4240608215332, 37.128841400146484, 37.8529634475708, 38.57708549499512, 39.32245945930481, 40.0678334236145, 40.780606746673584, 41.493380069732666, 42.18231201171875, 42.871243953704834, 43.58737540245056, 44.30350685119629, 45.02183938026428, 45.740171909332275, 46.458149671554565, 47.176127433776855, 47.904712200164795, 48.633296966552734, 49.336408853530884, 50.03952074050903, 50.75048065185547, 51.461440563201904, 52.1993989944458, 52.9373574256897, 53.65797424316406, 54.37859106063843, 55.08121728897095, 55.78384351730347, 56.51555895805359, 57.24727439880371, 57.9946768283844, 58.74207925796509, 59.476409912109375, 60.21074056625366, 61.004401445388794, 61.798062324523926, 62.47985863685608, 63.16165494918823, 63.897247552871704, 64.63284015655518, 65.37585163116455, 66.11886310577393, 66.83185839653015, 67.54485368728638, 68.24707055091858, 68.94928741455078, 69.66352725028992, 70.37776708602905, 71.0989933013916, 71.82021951675415, 72.5446298122406, 73.26904010772705, 73.98689866065979, 74.70475721359253, 75.42663741111755, 76.14851760864258, 76.84286832809448, 77.53721904754639, 78.25701856613159, 78.9768180847168, 79.68768978118896, 80.39856147766113, 81.08967757225037, 81.7807936668396, 82.48428964614868, 83.18778562545776, 83.88981795310974, 84.59185028076172, 85.30743050575256, 86.02301073074341, 86.75694870948792, 87.49088668823242, 88.2118513584137, 88.93281602859497, 89.616544008255, 90.30027198791504, 90.97756385803223, 91.65485572814941, 92.3967297077179, 93.13860368728638, 93.87765216827393, 94.61670064926147, 95.3360743522644, 96.05544805526733, 96.7435028553009, 97.43155765533447, 98.13641142845154, 98.8412652015686, 99.56786632537842, 100.29446744918823, 101.01113629341125, 101.72780513763428, 102.42178535461426, 103.11576557159424, 103.79607439041138, 104.47638320922852, 105.17162489891052, 105.86686658859253, 106.6016902923584, 107.33651399612427, 108.07252907752991, 108.80854415893555, 109.51555895805359, 110.22257375717163, 110.93656134605408, 111.65054893493652, 112.35681080818176, 113.063072681427, 113.79203677177429, 114.52100086212158, 115.2661874294281, 116.01137399673462, 116.7427933216095, 117.47421264648438, 118.1569836139679, 118.83975458145142, 119.5575954914093, 120.27543640136719, 121.01924514770508, 121.76305389404297, 122.4961895942688, 123.22932529449463, 123.94920754432678, 124.66908979415894, 125.35760927200317, 126.04612874984741, 126.78750324249268, 127.52887773513794, 128.2744152545929, 129.01995277404785, 129.7463037967682, 130.47265481948853, 131.14221382141113, 131.81177282333374, 132.50922870635986, 133.206684589386, 133.95037007331848, 134.69405555725098, 135.43164324760437, 136.16923093795776, 136.88606643676758, 137.6029019355774, 138.28820776939392, 138.97351360321045, 139.69000816345215, 140.40650272369385, 141.14117765426636, 141.87585258483887, 142.60148549079895, 143.32711839675903, 144.77798891067505, 146.22885942459106]
[78.29, 78.29, 91.03, 91.03, 91.7, 91.7, 93.39, 93.39, 95.13, 95.13, 95.54, 95.54, 96.59, 96.59, 96.89, 96.89, 97.07, 97.07, 97.13, 97.13, 97.14, 97.14, 97.23, 97.23, 97.27, 97.27, 97.36, 97.36, 97.47, 97.47, 97.5, 97.5, 97.52, 97.52, 97.6, 97.6, 97.64, 97.64, 97.62, 97.62, 97.71, 97.71, 97.79, 97.79, 97.81, 97.81, 97.83, 97.83, 97.86, 97.86, 97.85, 97.85, 97.86, 97.86, 97.91, 97.91, 97.98, 97.98, 98.0, 98.0, 97.96, 97.96, 97.99, 97.99, 98.0, 98.0, 98.02, 98.02, 98.03, 98.03, 98.02, 98.02, 98.03, 98.03, 98.03, 98.03, 98.04, 98.04, 98.05, 98.05, 98.09, 98.09, 98.09, 98.09, 98.12, 98.12, 98.12, 98.12, 98.16, 98.16, 98.15, 98.15, 98.15, 98.15, 98.16, 98.16, 98.17, 98.17, 98.18, 98.18, 98.2, 98.2, 98.21, 98.21, 98.18, 98.18, 98.18, 98.18, 98.21, 98.21, 98.2, 98.2, 98.19, 98.19, 98.22, 98.22, 98.22, 98.22, 98.24, 98.24, 98.25, 98.25, 98.29, 98.29, 98.19, 98.19, 98.26, 98.26, 98.26, 98.26, 98.25, 98.25, 98.2, 98.2, 98.17, 98.17, 98.18, 98.18, 98.23, 98.23, 98.25, 98.25, 98.25, 98.25, 98.27, 98.27, 98.26, 98.26, 98.25, 98.25, 98.28, 98.28, 98.28, 98.28, 98.29, 98.29, 98.27, 98.27, 98.3, 98.3, 98.31, 98.31, 98.34, 98.34, 98.33, 98.33, 98.33, 98.33, 98.33, 98.33, 98.34, 98.34, 98.35, 98.35, 98.34, 98.34, 98.34, 98.34, 98.36, 98.36, 98.38, 98.38, 98.36, 98.36, 98.35, 98.35, 98.36, 98.36, 98.37, 98.37, 98.38, 98.38, 98.39, 98.39, 98.41, 98.41, 98.41, 98.41, 98.42, 98.42, 98.38, 98.38]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.606, Test loss: 1.597, Test accuracy: 60.55
Round   1, Train loss: 1.588, Test loss: 1.560, Test accuracy: 84.97
Round   2, Train loss: 1.503, Test loss: 1.366, Test accuracy: 81.27
Round   3, Train loss: 1.232, Test loss: 1.103, Test accuracy: 92.70
Round   4, Train loss: 1.029, Test loss: 1.019, Test accuracy: 94.86
Round   5, Train loss: 0.994, Test loss: 0.984, Test accuracy: 96.06
Round   6, Train loss: 0.973, Test loss: 0.969, Test accuracy: 96.61
Round   7, Train loss: 0.965, Test loss: 0.957, Test accuracy: 96.83
Round   8, Train loss: 0.953, Test loss: 0.951, Test accuracy: 96.99
Round   9, Train loss: 0.956, Test loss: 0.946, Test accuracy: 97.20
Round  10, Train loss: 0.944, Test loss: 0.944, Test accuracy: 97.25
Round  11, Train loss: 0.945, Test loss: 0.941, Test accuracy: 97.34
Round  12, Train loss: 0.942, Test loss: 0.940, Test accuracy: 97.29
Round  13, Train loss: 0.943, Test loss: 0.939, Test accuracy: 97.38
Round  14, Train loss: 0.941, Test loss: 0.938, Test accuracy: 97.37
Round  15, Train loss: 0.937, Test loss: 0.937, Test accuracy: 97.33
Round  16, Train loss: 0.938, Test loss: 0.936, Test accuracy: 97.31
Round  17, Train loss: 0.934, Test loss: 0.936, Test accuracy: 97.31
Round  18, Train loss: 0.935, Test loss: 0.935, Test accuracy: 97.39
Round  19, Train loss: 0.932, Test loss: 0.935, Test accuracy: 97.50
Round  20, Train loss: 0.930, Test loss: 0.934, Test accuracy: 97.41
Round  21, Train loss: 0.931, Test loss: 0.934, Test accuracy: 97.44
Round  22, Train loss: 0.931, Test loss: 0.933, Test accuracy: 97.43
Round  23, Train loss: 0.930, Test loss: 0.933, Test accuracy: 97.50
Round  24, Train loss: 0.929, Test loss: 0.932, Test accuracy: 97.56
Round  25, Train loss: 0.927, Test loss: 0.932, Test accuracy: 97.53
Round  26, Train loss: 0.928, Test loss: 0.932, Test accuracy: 97.52
Round  27, Train loss: 0.925, Test loss: 0.932, Test accuracy: 97.54
Round  28, Train loss: 0.928, Test loss: 0.932, Test accuracy: 97.54
Round  29, Train loss: 0.927, Test loss: 0.931, Test accuracy: 97.53
Round  30, Train loss: 0.928, Test loss: 0.931, Test accuracy: 97.52
Round  31, Train loss: 0.923, Test loss: 0.931, Test accuracy: 97.62
Round  32, Train loss: 0.925, Test loss: 0.931, Test accuracy: 97.59
Round  33, Train loss: 0.920, Test loss: 0.931, Test accuracy: 97.53
Round  34, Train loss: 0.925, Test loss: 0.931, Test accuracy: 97.50
Round  35, Train loss: 0.924, Test loss: 0.931, Test accuracy: 97.47
Round  36, Train loss: 0.923, Test loss: 0.931, Test accuracy: 97.43
Round  37, Train loss: 0.924, Test loss: 0.931, Test accuracy: 97.48
Round  38, Train loss: 0.923, Test loss: 0.930, Test accuracy: 97.58
Round  39, Train loss: 0.922, Test loss: 0.930, Test accuracy: 97.60
Round  40, Train loss: 0.920, Test loss: 0.930, Test accuracy: 97.59
Round  41, Train loss: 0.922, Test loss: 0.930, Test accuracy: 97.63
Round  42, Train loss: 0.924, Test loss: 0.930, Test accuracy: 97.62
Round  43, Train loss: 0.922, Test loss: 0.929, Test accuracy: 97.62
Round  44, Train loss: 0.918, Test loss: 0.930, Test accuracy: 97.58
Round  45, Train loss: 0.921, Test loss: 0.930, Test accuracy: 97.63
Round  46, Train loss: 0.922, Test loss: 0.929, Test accuracy: 97.63
Round  47, Train loss: 0.920, Test loss: 0.929, Test accuracy: 97.63
Round  48, Train loss: 0.919, Test loss: 0.930, Test accuracy: 97.60
Round  49, Train loss: 0.919, Test loss: 0.929, Test accuracy: 97.62
Round  50, Train loss: 0.921, Test loss: 0.929, Test accuracy: 97.64
Round  51, Train loss: 0.918, Test loss: 0.929, Test accuracy: 97.67
Round  52, Train loss: 0.919, Test loss: 0.929, Test accuracy: 97.65
Round  53, Train loss: 0.920, Test loss: 0.929, Test accuracy: 97.65
Round  54, Train loss: 0.919, Test loss: 0.929, Test accuracy: 97.63
Round  55, Train loss: 0.917, Test loss: 0.929, Test accuracy: 97.65
Round  56, Train loss: 0.917, Test loss: 0.929, Test accuracy: 97.66
Round  57, Train loss: 0.918, Test loss: 0.929, Test accuracy: 97.59
Round  58, Train loss: 0.916, Test loss: 0.929, Test accuracy: 97.60
Round  59, Train loss: 0.918, Test loss: 0.929, Test accuracy: 97.56
Round  60, Train loss: 0.922, Test loss: 0.929, Test accuracy: 97.68
Round  61, Train loss: 0.922, Test loss: 0.928, Test accuracy: 97.72
Round  62, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.74
Round  63, Train loss: 0.921, Test loss: 0.928, Test accuracy: 97.67
Round  64, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.67
Round  65, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.68
Round  66, Train loss: 0.915, Test loss: 0.928, Test accuracy: 97.67
Round  67, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.72
Round  68, Train loss: 0.916, Test loss: 0.928, Test accuracy: 97.72
Round  69, Train loss: 0.915, Test loss: 0.928, Test accuracy: 97.74
Round  70, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.71
Round  71, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.71
Round  72, Train loss: 0.916, Test loss: 0.928, Test accuracy: 97.74
Round  73, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.80
Round  74, Train loss: 0.916, Test loss: 0.928, Test accuracy: 97.80
Round  75, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.83
Round  76, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.84
Round  77, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.85
Round  78, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.80
Round  79, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.81
Round  80, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.84
Round  81, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.82
Round  82, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.80
Round  83, Train loss: 0.915, Test loss: 0.928, Test accuracy: 97.75
Round  84, Train loss: 0.916, Test loss: 0.928, Test accuracy: 97.72
Round  85, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.80
Round  86, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.82
Round  87, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.83
Round  88, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.81
Round  89, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.81
Round  90, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.81
Round  91, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.76
Round  92, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.73
Round  93, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.77
Round  94, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.74
Round  95, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.75
Round  96, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.72
Round  97, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.76
Round  98, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.77
Round  99, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.82
Round 100, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.78
Round 101, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.79
Round 102, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.81
Round 103, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.80
Round 104, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.80
Round 105, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.83
Round 106, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.84
Round 107, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.83
Round 108, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.87
Round 109, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.86
Round 110, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.85
Round 111, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.85
Round 112, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.84
Round 113, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.84
Round 114, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.80
Round 115, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.80
Round 116, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.82
Round 117, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.82
Round 118, Train loss: 0.911, Test loss: 0.927, Test accuracy: 97.81
Round 119, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.80
Round 120, Train loss: 0.911, Test loss: 0.927, Test accuracy: 97.81
Round 121, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.82
Round 122, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.85
Round 123, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.86
Round 124, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.84
Round 125, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.89
Round 126, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.81
Round 127, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.82
Round 128, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.85
Round 129, Train loss: 0.911, Test loss: 0.927, Test accuracy: 97.85
Round 130, Train loss: 0.911, Test loss: 0.927, Test accuracy: 97.84
Round 131, Train loss: 0.911, Test loss: 0.927, Test accuracy: 97.80
Round 132, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.77
Round 133, Train loss: 0.911, Test loss: 0.927, Test accuracy: 97.81
Round 134, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.83
Round 135, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.80
Round 136, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.81
Round 137, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.78
Round 138, Train loss: 0.914, Test loss: 0.927, Test accuracy: 97.81
Round 139, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.80
Round 140, Train loss: 0.912, Test loss: 0.927, Test accuracy: 97.81
Round 141, Train loss: 0.910, Test loss: 0.926, Test accuracy: 97.82
Round 142, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.87
Round 143, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.86
Round 144, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.86
Round 145, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.86
Round 146, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.84
Round 147, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.86
Round 148, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.84
Round 149, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.86
Round 150, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.86
Round 151, Train loss: 0.910, Test loss: 0.926, Test accuracy: 97.86
Round 152, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.88
Round 153, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.88
Round 154, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.88
Round 155, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.87
Round 156, Train loss: 0.910, Test loss: 0.926, Test accuracy: 97.89
Round 157, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.87
Round 158, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.87
Round 159, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.90
Round 160, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.87
Round 161, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.89
Round 162, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.89
Round 163, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.89
Round 164, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.89
Round 165, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.89
Round 166, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.89
Round 167, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.89
Round 168, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.90
Round 169, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.89
Round 170, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.88
Round 171, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.89
Round 172, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.89
Round 173, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.87
Round 174, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.87
Round 175, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.88
Round 176, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.88
Round 177, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.89
Round 178, Train loss: 0.910, Test loss: 0.926, Test accuracy: 97.88
Round 179, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.88
Round 180, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.88
Round 181, Train loss: 0.909, Test loss: 0.926, Test accuracy: 97.88
Round 182, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.91
Round 183, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.91
Round 184, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.92
Round 185, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.92
Round 186, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.92
Round 187, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.91
Round 188, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.92
Round 189, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.91
Round 190, Train loss: 0.910, Test loss: 0.926, Test accuracy: 97.92
Round 191, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.92
Round 192, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.93
Round 193, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.92
Round 194, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.92
Round 195, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.92
Round 196, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.93
Round 197, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.93
Round 198, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.93
Round 199, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.94
Final Round, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.94
Average accuracy final 10 rounds: 97.92600000000002 

1760.425969362259
[0.8723464012145996, 1.7446928024291992, 2.435230016708374, 3.125767230987549, 3.8170742988586426, 4.508381366729736, 5.2414233684539795, 5.974465370178223, 6.668140411376953, 7.361815452575684, 8.076860666275024, 8.791905879974365, 9.491323709487915, 10.190741539001465, 10.8981192111969, 11.605496883392334, 12.303127527236938, 13.000758171081543, 13.694949626922607, 14.389141082763672, 15.106053590774536, 15.8229660987854, 16.53238868713379, 17.241811275482178, 17.929343223571777, 18.616875171661377, 19.314369440078735, 20.011863708496094, 20.69597339630127, 21.380083084106445, 22.0824613571167, 22.784839630126953, 23.484575271606445, 24.184310913085938, 24.886701107025146, 25.589091300964355, 26.30673599243164, 27.024380683898926, 27.721399784088135, 28.418418884277344, 29.12008810043335, 29.821757316589355, 30.51217007637024, 31.202582836151123, 31.892361402511597, 32.58213996887207, 33.27891182899475, 33.97568368911743, 34.66640853881836, 35.35713338851929, 36.037190437316895, 36.7172474861145, 37.419283866882324, 38.12132024765015, 38.79728722572327, 39.47325420379639, 40.16411733627319, 40.85498046875, 41.55523657798767, 42.25549268722534, 42.93171167373657, 43.6079306602478, 44.31989932060242, 45.03186798095703, 45.69687604904175, 46.361884117126465, 47.037731647491455, 47.713579177856445, 48.42058539390564, 49.127591609954834, 49.79014253616333, 50.452693462371826, 51.13466167449951, 51.8166298866272, 52.50334405899048, 53.19005823135376, 53.868884801864624, 54.54771137237549, 55.24012207984924, 55.932532787323, 56.59187960624695, 57.2512264251709, 57.95525908470154, 58.65929174423218, 59.35448694229126, 60.04968214035034, 60.715561866760254, 61.381441593170166, 62.09649324417114, 62.81154489517212, 63.48252749443054, 64.15351009368896, 64.84313774108887, 65.53276538848877, 66.23677825927734, 66.94079113006592, 67.60103583335876, 68.26128053665161, 68.95513725280762, 69.64899396896362, 70.28863525390625, 70.92827653884888, 71.60366773605347, 72.27905893325806, 72.97451138496399, 73.66996383666992, 74.33654999732971, 75.0031361579895, 75.70526480674744, 76.40739345550537, 77.10946273803711, 77.81153202056885, 78.47528839111328, 79.13904476165771, 79.84743428230286, 80.555823802948, 81.22970342636108, 81.90358304977417, 82.62178015708923, 83.3399772644043, 84.0320029258728, 84.72402858734131, 85.41137671470642, 86.09872484207153, 86.8071174621582, 87.51551008224487, 88.20280337333679, 88.89009666442871, 89.56988263130188, 90.24966859817505, 90.92988753318787, 91.61010646820068, 92.26668047904968, 92.92325448989868, 93.57618236541748, 94.22911024093628, 94.92115879058838, 95.61320734024048, 96.28607106208801, 96.95893478393555, 97.6358962059021, 98.31285762786865, 98.98788285255432, 99.66290807723999, 100.35774803161621, 101.05258798599243, 101.76034688949585, 102.46810579299927, 103.1925916671753, 103.91707754135132, 104.63748002052307, 105.35788249969482, 106.0451500415802, 106.73241758346558, 107.441077709198, 108.14973783493042, 108.8647129535675, 109.57968807220459, 110.27279663085938, 110.96590518951416, 111.62462425231934, 112.28334331512451, 112.99826908111572, 113.71319484710693, 114.38354349136353, 115.05389213562012, 115.73654890060425, 116.41920566558838, 117.10448288917542, 117.78976011276245, 118.46703100204468, 119.1443018913269, 119.85807681083679, 120.57185173034668, 121.23018264770508, 121.88851356506348, 122.58715748786926, 123.28580141067505, 123.9950942993164, 124.70438718795776, 125.37897419929504, 126.05356121063232, 126.80566906929016, 127.557776927948, 128.22381258010864, 128.8898482322693, 129.5718560218811, 130.25386381149292, 130.94893336296082, 131.6440029144287, 132.32626867294312, 133.00853443145752, 133.73232913017273, 134.45612382888794, 135.11612486839294, 135.77612590789795, 136.48476839065552, 137.1934108734131, 137.88639450073242, 138.57937812805176, 139.29229760169983, 140.0052170753479, 140.71221899986267, 141.41922092437744, 142.07458186149597, 142.7299427986145, 143.43105483055115, 144.1321668624878, 144.83368849754333, 145.53521013259888, 146.24160027503967, 146.94799041748047, 147.66825914382935, 148.38852787017822, 149.03552198410034, 149.68251609802246, 150.39500045776367, 151.10748481750488, 151.7855634689331, 152.46364212036133, 153.16582870483398, 153.86801528930664, 154.5657970905304, 155.26357889175415, 155.92161631584167, 156.5796537399292, 157.2885024547577, 157.99735116958618, 158.6745843887329, 159.35181760787964, 160.0408411026001, 160.72986459732056, 161.42902421951294, 162.12818384170532, 162.81412768363953, 163.50007152557373, 164.2262463569641, 164.9524211883545, 165.5997200012207, 166.2470188140869, 166.95750379562378, 167.66798877716064, 168.38800048828125, 169.10801219940186, 169.77108645439148, 170.4341607093811, 171.13942313194275, 171.8446855545044, 172.4878032207489, 173.1309208869934, 173.84860014915466, 174.56627941131592, 175.27183747291565, 175.97739553451538, 176.6483678817749, 177.31934022903442, 178.0166563987732, 178.71397256851196, 179.37033915519714, 180.02670574188232, 180.7262408733368, 181.42577600479126, 182.14582204818726, 182.86586809158325, 183.5205066204071, 184.17514514923096, 184.8804087638855, 185.58567237854004, 186.23146200180054, 186.87725162506104, 187.58012342453003, 188.28299522399902, 189.00363492965698, 189.72427463531494, 190.37700986862183, 191.0297451019287, 191.7352430820465, 192.4407410621643, 193.10045957565308, 193.76017808914185, 194.4800088405609, 195.19983959197998, 195.90672945976257, 196.61361932754517, 197.24963092803955, 197.88564252853394, 198.59586381912231, 199.3060851097107, 199.9683485031128, 200.6306118965149, 201.33796763420105, 202.0453233718872, 202.7424476146698, 203.4395718574524, 204.12735748291016, 204.81514310836792, 205.5389666557312, 206.26279020309448, 206.9324290752411, 207.6020679473877, 208.3092679977417, 209.0164680480957, 209.6811752319336, 210.34588241577148, 211.17624163627625, 212.006600856781, 212.72536754608154, 213.44413423538208, 214.09435319900513, 214.74457216262817, 215.4539656639099, 216.16335916519165, 216.84666776657104, 217.52997636795044, 218.2302122116089, 218.93044805526733, 219.63550853729248, 220.34056901931763, 220.99116969108582, 221.641770362854, 222.33646059036255, 223.0311508178711, 223.7380518913269, 224.44495296478271, 225.12750124931335, 225.810049533844, 226.5136058330536, 227.21716213226318, 227.85550379753113, 228.49384546279907, 229.20569610595703, 229.917546749115, 230.63028860092163, 231.34303045272827, 232.02099657058716, 232.69896268844604, 233.40084886550903, 234.10273504257202, 234.75897240638733, 235.41520977020264, 236.11545515060425, 236.81570053100586, 237.5030689239502, 238.19043731689453, 238.88473463058472, 239.5790319442749, 240.2814040184021, 240.9837760925293, 241.64985489845276, 242.31593370437622, 243.02119874954224, 243.72646379470825, 244.39612126350403, 245.0657787322998, 245.7756702899933, 246.48556184768677, 247.19232630729675, 247.89909076690674, 248.57188272476196, 249.2446746826172, 249.94080758094788, 250.63694047927856, 251.2858109474182, 251.93468141555786, 252.63659644126892, 253.33851146697998, 254.03245043754578, 254.72638940811157, 255.39612436294556, 256.06585931777954, 256.7781732082367, 257.49048709869385, 258.1395752429962, 258.7886633872986, 259.4943628311157, 260.20006227493286, 260.9022204875946, 261.60437870025635, 262.2729001045227, 262.94142150878906, 263.6411008834839, 264.3407802581787, 264.9979524612427, 265.65512466430664, 266.3698239326477, 267.08452320098877, 267.7918610572815, 268.4991989135742, 269.16566705703735, 269.8321352005005, 270.5160048007965, 271.19987440109253, 271.86894035339355, 272.5380063056946, 273.2471034526825, 273.9562005996704, 274.6510055065155, 275.3458104133606, 276.01592564582825, 276.6860408782959, 278.0553984642029, 279.42475605010986]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[60.55, 60.55, 84.97, 84.97, 81.27, 81.27, 92.7, 92.7, 94.86, 94.86, 96.06, 96.06, 96.61, 96.61, 96.83, 96.83, 96.99, 96.99, 97.2, 97.2, 97.25, 97.25, 97.34, 97.34, 97.29, 97.29, 97.38, 97.38, 97.37, 97.37, 97.33, 97.33, 97.31, 97.31, 97.31, 97.31, 97.39, 97.39, 97.5, 97.5, 97.41, 97.41, 97.44, 97.44, 97.43, 97.43, 97.5, 97.5, 97.56, 97.56, 97.53, 97.53, 97.52, 97.52, 97.54, 97.54, 97.54, 97.54, 97.53, 97.53, 97.52, 97.52, 97.62, 97.62, 97.59, 97.59, 97.53, 97.53, 97.5, 97.5, 97.47, 97.47, 97.43, 97.43, 97.48, 97.48, 97.58, 97.58, 97.6, 97.6, 97.59, 97.59, 97.63, 97.63, 97.62, 97.62, 97.62, 97.62, 97.58, 97.58, 97.63, 97.63, 97.63, 97.63, 97.63, 97.63, 97.6, 97.6, 97.62, 97.62, 97.64, 97.64, 97.67, 97.67, 97.65, 97.65, 97.65, 97.65, 97.63, 97.63, 97.65, 97.65, 97.66, 97.66, 97.59, 97.59, 97.6, 97.6, 97.56, 97.56, 97.68, 97.68, 97.72, 97.72, 97.74, 97.74, 97.67, 97.67, 97.67, 97.67, 97.68, 97.68, 97.67, 97.67, 97.72, 97.72, 97.72, 97.72, 97.74, 97.74, 97.71, 97.71, 97.71, 97.71, 97.74, 97.74, 97.8, 97.8, 97.8, 97.8, 97.83, 97.83, 97.84, 97.84, 97.85, 97.85, 97.8, 97.8, 97.81, 97.81, 97.84, 97.84, 97.82, 97.82, 97.8, 97.8, 97.75, 97.75, 97.72, 97.72, 97.8, 97.8, 97.82, 97.82, 97.83, 97.83, 97.81, 97.81, 97.81, 97.81, 97.81, 97.81, 97.76, 97.76, 97.73, 97.73, 97.77, 97.77, 97.74, 97.74, 97.75, 97.75, 97.72, 97.72, 97.76, 97.76, 97.77, 97.77, 97.82, 97.82, 97.78, 97.78, 97.79, 97.79, 97.81, 97.81, 97.8, 97.8, 97.8, 97.8, 97.83, 97.83, 97.84, 97.84, 97.83, 97.83, 97.87, 97.87, 97.86, 97.86, 97.85, 97.85, 97.85, 97.85, 97.84, 97.84, 97.84, 97.84, 97.8, 97.8, 97.8, 97.8, 97.82, 97.82, 97.82, 97.82, 97.81, 97.81, 97.8, 97.8, 97.81, 97.81, 97.82, 97.82, 97.85, 97.85, 97.86, 97.86, 97.84, 97.84, 97.89, 97.89, 97.81, 97.81, 97.82, 97.82, 97.85, 97.85, 97.85, 97.85, 97.84, 97.84, 97.8, 97.8, 97.77, 97.77, 97.81, 97.81, 97.83, 97.83, 97.8, 97.8, 97.81, 97.81, 97.78, 97.78, 97.81, 97.81, 97.8, 97.8, 97.81, 97.81, 97.82, 97.82, 97.87, 97.87, 97.86, 97.86, 97.86, 97.86, 97.86, 97.86, 97.84, 97.84, 97.86, 97.86, 97.84, 97.84, 97.86, 97.86, 97.86, 97.86, 97.86, 97.86, 97.88, 97.88, 97.88, 97.88, 97.88, 97.88, 97.87, 97.87, 97.89, 97.89, 97.87, 97.87, 97.87, 97.87, 97.9, 97.9, 97.87, 97.87, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.89, 97.9, 97.9, 97.89, 97.89, 97.88, 97.88, 97.89, 97.89, 97.89, 97.89, 97.87, 97.87, 97.87, 97.87, 97.88, 97.88, 97.88, 97.88, 97.89, 97.89, 97.88, 97.88, 97.88, 97.88, 97.88, 97.88, 97.88, 97.88, 97.91, 97.91, 97.91, 97.91, 97.92, 97.92, 97.92, 97.92, 97.92, 97.92, 97.91, 97.91, 97.92, 97.92, 97.91, 97.91, 97.92, 97.92, 97.92, 97.92, 97.93, 97.93, 97.92, 97.92, 97.92, 97.92, 97.92, 97.92, 97.93, 97.93, 97.93, 97.93, 97.93, 97.93, 97.94, 97.94, 97.94, 97.94]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 200, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.587, Test loss: 1.537, Test accuracy: 75.00
Round   1, Train loss: 1.289, Test loss: 1.069, Test accuracy: 93.45
Round   2, Train loss: 0.987, Test loss: 0.979, Test accuracy: 95.98
Round   3, Train loss: 0.959, Test loss: 0.960, Test accuracy: 96.55
Round   4, Train loss: 0.946, Test loss: 0.952, Test accuracy: 96.85
Round   5, Train loss: 0.942, Test loss: 0.946, Test accuracy: 97.09
Round   6, Train loss: 0.941, Test loss: 0.942, Test accuracy: 97.18
Round   7, Train loss: 0.937, Test loss: 0.940, Test accuracy: 97.32
Round   8, Train loss: 0.934, Test loss: 0.938, Test accuracy: 97.45
Round   9, Train loss: 0.932, Test loss: 0.935, Test accuracy: 97.59
Round  10, Train loss: 0.927, Test loss: 0.934, Test accuracy: 97.59
Round  11, Train loss: 0.927, Test loss: 0.933, Test accuracy: 97.48
Round  12, Train loss: 0.929, Test loss: 0.932, Test accuracy: 97.60
Round  13, Train loss: 0.927, Test loss: 0.931, Test accuracy: 97.62
Round  14, Train loss: 0.926, Test loss: 0.931, Test accuracy: 97.61
Round  15, Train loss: 0.926, Test loss: 0.930, Test accuracy: 97.70
Round  16, Train loss: 0.923, Test loss: 0.931, Test accuracy: 97.59
Round  17, Train loss: 0.922, Test loss: 0.930, Test accuracy: 97.73
Round  18, Train loss: 0.922, Test loss: 0.930, Test accuracy: 97.61
Round  19, Train loss: 0.919, Test loss: 0.929, Test accuracy: 97.63
Round  20, Train loss: 0.925, Test loss: 0.929, Test accuracy: 97.76
Round  21, Train loss: 0.920, Test loss: 0.929, Test accuracy: 97.69
Round  22, Train loss: 0.920, Test loss: 0.929, Test accuracy: 97.70
Round  23, Train loss: 0.922, Test loss: 0.929, Test accuracy: 97.71
Round  24, Train loss: 0.920, Test loss: 0.928, Test accuracy: 97.73
Round  25, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.73
Round  26, Train loss: 0.921, Test loss: 0.927, Test accuracy: 97.82
Round  27, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.82
Round  28, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.76
Round  29, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.75
Round  30, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.79
Round  31, Train loss: 0.917, Test loss: 0.928, Test accuracy: 97.75
Round  32, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.81
Round  33, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.75
Round  34, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.87
Round  35, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.92
Round  36, Train loss: 0.915, Test loss: 0.927, Test accuracy: 97.89
Round  37, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.78
Round  38, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.79
Round  39, Train loss: 0.913, Test loss: 0.927, Test accuracy: 97.85
Round  40, Train loss: 0.918, Test loss: 0.926, Test accuracy: 97.84
Round  41, Train loss: 0.917, Test loss: 0.926, Test accuracy: 97.89
Round  42, Train loss: 0.917, Test loss: 0.926, Test accuracy: 97.95
Round  43, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.91
Round  44, Train loss: 0.915, Test loss: 0.926, Test accuracy: 97.95
Round  45, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.94
Round  46, Train loss: 0.915, Test loss: 0.926, Test accuracy: 97.98
Round  47, Train loss: 0.912, Test loss: 0.926, Test accuracy: 97.92
Round  48, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.93
Round  49, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.92
Round  50, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.92
Round  51, Train loss: 0.918, Test loss: 0.926, Test accuracy: 97.90
Round  52, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.90
Round  53, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.89
Round  54, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.87
Round  55, Train loss: 0.914, Test loss: 0.926, Test accuracy: 97.92
Round  56, Train loss: 0.913, Test loss: 0.926, Test accuracy: 97.90
Round  57, Train loss: 0.912, Test loss: 0.925, Test accuracy: 97.90
Round  58, Train loss: 0.911, Test loss: 0.926, Test accuracy: 97.96
Round  59, Train loss: 0.912, Test loss: 0.925, Test accuracy: 97.96
Round  60, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.01
Round  61, Train loss: 0.912, Test loss: 0.925, Test accuracy: 97.99
Round  62, Train loss: 0.915, Test loss: 0.925, Test accuracy: 97.93
Round  63, Train loss: 0.914, Test loss: 0.925, Test accuracy: 97.94
Round  64, Train loss: 0.911, Test loss: 0.925, Test accuracy: 97.96
Round  65, Train loss: 0.914, Test loss: 0.925, Test accuracy: 97.97
Round  66, Train loss: 0.911, Test loss: 0.925, Test accuracy: 97.95
Round  67, Train loss: 0.912, Test loss: 0.925, Test accuracy: 97.97
Round  68, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.02
Round  69, Train loss: 0.913, Test loss: 0.925, Test accuracy: 98.00
Round  70, Train loss: 0.910, Test loss: 0.925, Test accuracy: 98.02
Round  71, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.03
Round  72, Train loss: 0.913, Test loss: 0.925, Test accuracy: 98.00
Round  73, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.03
Round  74, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.03
Round  75, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.04
Round  76, Train loss: 0.910, Test loss: 0.925, Test accuracy: 97.98
Round  77, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.00
Round  78, Train loss: 0.911, Test loss: 0.925, Test accuracy: 97.97
Round  79, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.01
Round  80, Train loss: 0.910, Test loss: 0.925, Test accuracy: 98.01
Round  81, Train loss: 0.914, Test loss: 0.925, Test accuracy: 97.99
Round  82, Train loss: 0.912, Test loss: 0.925, Test accuracy: 97.98
Round  83, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.02
Round  84, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.00
Round  85, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.02
Round  86, Train loss: 0.910, Test loss: 0.925, Test accuracy: 98.01
Round  87, Train loss: 0.914, Test loss: 0.924, Test accuracy: 98.10
Round  88, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.00
Round  89, Train loss: 0.909, Test loss: 0.925, Test accuracy: 98.00
Round  90, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.01
Round  91, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.04
Round  92, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.05
Round  93, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.03
Round  94, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.05
Round  95, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.07
Round  96, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.05
Round  97, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.07
Round  98, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.07
Round  99, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.09
Round 100, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.10
Round 101, Train loss: 0.914, Test loss: 0.924, Test accuracy: 98.09
Round 102, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 103, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.11
Round 104, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.09
Round 105, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.10
Round 106, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.09
Round 107, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.07
Round 108, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.08
Round 109, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.02
Round 110, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.04
Round 111, Train loss: 0.915, Test loss: 0.924, Test accuracy: 98.07
Round 112, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.07
Round 113, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.08
Round 114, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.08
Round 115, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.07
Round 116, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.06
Round 117, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.07
Round 118, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.05
Round 119, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.08
Round 120, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.06
Round 121, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.07
Round 122, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.07
Round 123, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.11
Round 124, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.12
Round 125, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Round 126, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.10
Round 127, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.12
Round 128, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 129, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.12
Round 130, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.09
Round 131, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.11
Round 132, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.10
Round 133, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.09
Round 134, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.10
Round 135, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.12
Round 136, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.13
Round 137, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.11
Round 138, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.11
Round 139, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.11
Round 140, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.12
Round 141, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.12
Round 142, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.11
Round 143, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Round 144, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.08
Round 145, Train loss: 0.908, Test loss: 0.924, Test accuracy: 98.11
Round 146, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.08
Round 147, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.11
Round 148, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.09
Round 149, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.10
Round 150, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Round 151, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.10
Round 152, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.09
Round 153, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.10
Round 154, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.10
Round 155, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.09
Round 156, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.09
Round 157, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.09
Round 158, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 159, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Round 160, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.08
Round 161, Train loss: 0.914, Test loss: 0.924, Test accuracy: 98.12
Round 162, Train loss: 0.914, Test loss: 0.924, Test accuracy: 98.14
Round 163, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.08
Round 164, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.09
Round 165, Train loss: 0.915, Test loss: 0.924, Test accuracy: 98.14
Round 166, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.13
Round 167, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.14
Round 168, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.12
Round 169, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.11
Round 170, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.10
Round 171, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.13
Round 172, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.13
Round 173, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.09
Round 174, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.12
Round 175, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.13
Round 176, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.12
Round 177, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.13
Round 178, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.15
Round 179, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.12
Round 180, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.13
Round 181, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.10
Round 182, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.12
Round 183, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 184, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.08
Round 185, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.09
Round 186, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.11
Round 187, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.10
Round 188, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.10
Round 189, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.13
Round 190, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 191, Train loss: 0.910, Test loss: 0.924, Test accuracy: 98.12
Round 192, Train loss: 0.909, Test loss: 0.924, Test accuracy: 98.12
Round 193, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 194, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.13
Round 195, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.15
Round 196, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 197, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Round 198, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.11
Round 199, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Final Round, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.08
Average accuracy final 10 rounds: 98.11600000000001 

1900.5645840168
[0.9683976173400879, 1.9367952346801758, 2.7901031970977783, 3.643411159515381, 4.493590831756592, 5.343770503997803, 6.175014019012451, 7.0062575340271, 7.831402540206909, 8.656547546386719, 9.482116460800171, 10.307685375213623, 11.155376434326172, 12.00306749343872, 12.854589462280273, 13.706111431121826, 14.511695146560669, 15.317278861999512, 16.165059566497803, 17.012840270996094, 17.810643672943115, 18.608447074890137, 19.439130783081055, 20.269814491271973, 21.09206795692444, 21.914321422576904, 22.695663452148438, 23.47700548171997, 24.335167407989502, 25.193329334259033, 26.037508249282837, 26.88168716430664, 27.726475477218628, 28.571263790130615, 29.384734869003296, 30.198205947875977, 30.971487760543823, 31.74476957321167, 32.523033618927, 33.301297664642334, 34.10386610031128, 34.906434535980225, 35.710184812545776, 36.51393508911133, 37.342120885849, 38.17030668258667, 39.015730142593384, 39.8611536026001, 40.65999174118042, 41.45882987976074, 42.24860191345215, 43.038373947143555, 43.89744997024536, 44.75652599334717, 45.59012222290039, 46.42371845245361, 47.25401735305786, 48.08431625366211, 48.9039409160614, 49.72356557846069, 50.51322388648987, 51.30288219451904, 52.169727087020874, 53.036571979522705, 53.88159251213074, 54.72661304473877, 55.593716621398926, 56.46082019805908, 57.34388470649719, 58.2269492149353, 59.10553574562073, 59.98412227630615, 60.824037313461304, 61.663952350616455, 62.48901343345642, 63.31407451629639, 64.16519331932068, 65.01631212234497, 65.91035676002502, 66.80440139770508, 67.68898034095764, 68.5735592842102, 69.43023896217346, 70.28691864013672, 71.16674280166626, 72.0465669631958, 72.85035610198975, 73.65414524078369, 74.48523187637329, 75.31631851196289, 76.18384218215942, 77.05136585235596, 77.89915180206299, 78.74693775177002, 79.57497000694275, 80.40300226211548, 81.2620370388031, 82.12107181549072, 82.94788646697998, 83.77470111846924, 84.63917255401611, 85.50364398956299, 86.35626578330994, 87.20888757705688, 88.05661964416504, 88.9043517112732, 89.67365145683289, 90.44295120239258, 91.15807151794434, 91.8731918334961, 92.63683485984802, 93.40047788619995, 94.12328577041626, 94.84609365463257, 95.58710312843323, 96.32811260223389, 97.07666087150574, 97.82520914077759, 98.56207275390625, 99.29893636703491, 100.01242756843567, 100.72591876983643, 101.45169687271118, 102.17747497558594, 102.94268465042114, 103.70789432525635, 104.435702085495, 105.16350984573364, 105.91155529022217, 106.6596007347107, 107.40630197525024, 108.1530032157898, 108.8550956249237, 109.55718803405762, 110.29296612739563, 111.02874422073364, 111.76042866706848, 112.49211311340332, 113.26721119880676, 114.0423092842102, 114.77363586425781, 115.50496244430542, 116.23480486869812, 116.96464729309082, 117.69445276260376, 118.4242582321167, 119.15058612823486, 119.87691402435303, 120.62558126449585, 121.37424850463867, 122.09608697891235, 122.81792545318604, 123.53063178062439, 124.24333810806274, 124.97156023979187, 125.699782371521, 126.43504476547241, 127.17030715942383, 127.88680839538574, 128.60330963134766, 129.34957551956177, 130.09584140777588, 130.84579205513, 131.59574270248413, 132.33753991127014, 133.07933712005615, 133.80094838142395, 134.52255964279175, 135.23905611038208, 135.9555525779724, 136.68063592910767, 137.40571928024292, 138.12220335006714, 138.83868741989136, 139.5917091369629, 140.34473085403442, 141.0791096687317, 141.81348848342896, 142.56202292442322, 143.31055736541748, 144.03616070747375, 144.76176404953003, 145.5082025527954, 146.2546410560608, 147.00899004936218, 147.76333904266357, 148.5092363357544, 149.25513362884521, 150.01104426383972, 150.76695489883423, 151.50823378562927, 152.24951267242432, 152.99373054504395, 153.73794841766357, 154.49127554893494, 155.2446026802063, 156.0168914794922, 156.78918027877808, 157.53256678581238, 158.27595329284668, 159.0310389995575, 159.7861247062683, 160.54975938796997, 161.31339406967163, 162.05398440361023, 162.79457473754883, 163.56647038459778, 164.33836603164673, 165.0871548652649, 165.83594369888306, 166.5731279850006, 167.31031227111816, 168.05686330795288, 168.8034143447876, 169.56636381149292, 170.32931327819824, 171.07840514183044, 171.82749700546265, 172.55887961387634, 173.29026222229004, 174.03245377540588, 174.77464532852173, 175.5353057384491, 176.29596614837646, 177.0690999031067, 177.8422336578369, 178.60187578201294, 179.36151790618896, 180.123272895813, 180.885027885437, 181.62099647521973, 182.35696506500244, 183.12891387939453, 183.90086269378662, 184.64595866203308, 185.39105463027954, 186.14031529426575, 186.88957595825195, 187.6291160583496, 188.36865615844727, 189.15759468078613, 189.946533203125, 190.72371435165405, 191.5008955001831, 192.2665514945984, 193.03220748901367, 193.807537317276, 194.58286714553833, 195.31616044044495, 196.04945373535156, 196.80315160751343, 197.5568494796753, 198.3166823387146, 199.0765151977539, 199.83830046653748, 200.60008573532104, 201.37423133850098, 202.1483769416809, 202.89291548728943, 203.63745403289795, 204.41078543663025, 205.18411684036255, 205.95529747009277, 206.726478099823, 207.50703287124634, 208.28758764266968, 209.02858328819275, 209.76957893371582, 210.49589586257935, 211.22221279144287, 211.9729700088501, 212.72372722625732, 213.49834942817688, 214.27297163009644, 215.03783631324768, 215.80270099639893, 216.55395317077637, 217.3052053451538, 218.03693294525146, 218.76866054534912, 219.5326476097107, 220.29663467407227, 221.05622816085815, 221.81582164764404, 222.56417536735535, 223.31252908706665, 224.04614520072937, 224.7797613143921, 225.532564163208, 226.28536701202393, 227.05031991004944, 227.81527280807495, 228.56985902786255, 229.32444524765015, 230.0764079093933, 230.82837057113647, 231.54614925384521, 232.26392793655396, 233.0145423412323, 233.76515674591064, 234.52228689193726, 235.27941703796387, 236.02136874198914, 236.7633204460144, 237.5085427761078, 238.25376510620117, 239.0055341720581, 239.75730323791504, 240.53759932518005, 241.31789541244507, 242.08257699012756, 242.84725856781006, 243.60581421852112, 244.36436986923218, 245.09037590026855, 245.81638193130493, 246.58392596244812, 247.3514699935913, 248.13202333450317, 248.91257667541504, 249.6941511631012, 250.47572565078735, 251.22956466674805, 251.98340368270874, 252.72193145751953, 253.46045923233032, 254.26020169258118, 255.05994415283203, 255.83051180839539, 256.60107946395874, 257.37038230895996, 258.1396851539612, 258.8875231742859, 259.6353611946106, 260.41107749938965, 261.1867938041687, 261.9750611782074, 262.7633285522461, 263.5276439189911, 264.2919592857361, 265.0625641345978, 265.8331689834595, 266.58567357063293, 267.3381781578064, 268.08135199546814, 268.8245258331299, 269.5961158275604, 270.36770582199097, 271.138117313385, 271.90852880477905, 272.6672842502594, 273.42603969573975, 274.17266631126404, 274.91929292678833, 275.6892669200897, 276.4592409133911, 277.22905254364014, 277.99886417388916, 278.79075288772583, 279.5826416015625, 280.3667974472046, 281.1509532928467, 281.9112205505371, 282.67148780822754, 283.40875148773193, 284.1460151672363, 284.92494225502014, 285.70386934280396, 286.4581913948059, 287.21251344680786, 287.97623682022095, 288.73996019363403, 289.50041365623474, 290.26086711883545, 291.0490288734436, 291.83719062805176, 292.62950348854065, 293.42181634902954, 294.2115080356598, 295.00119972229004, 295.77663588523865, 296.55207204818726, 297.27221298217773, 297.9923539161682, 298.74092864990234, 299.4895033836365, 300.27799367904663, 301.0664839744568, 301.8321011066437, 302.59771823883057, 303.36119651794434, 304.1246747970581, 304.8679437637329, 305.6112127304077, 306.38610100746155, 307.1609892845154, 307.92334961891174, 308.6857099533081, 309.4560925960541, 310.22647523880005, 311.6584429740906, 313.0904107093811]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[75.0, 75.0, 93.45, 93.45, 95.98, 95.98, 96.55, 96.55, 96.85, 96.85, 97.09, 97.09, 97.18, 97.18, 97.32, 97.32, 97.45, 97.45, 97.59, 97.59, 97.59, 97.59, 97.48, 97.48, 97.6, 97.6, 97.62, 97.62, 97.61, 97.61, 97.7, 97.7, 97.59, 97.59, 97.73, 97.73, 97.61, 97.61, 97.63, 97.63, 97.76, 97.76, 97.69, 97.69, 97.7, 97.7, 97.71, 97.71, 97.73, 97.73, 97.73, 97.73, 97.82, 97.82, 97.82, 97.82, 97.76, 97.76, 97.75, 97.75, 97.79, 97.79, 97.75, 97.75, 97.81, 97.81, 97.75, 97.75, 97.87, 97.87, 97.92, 97.92, 97.89, 97.89, 97.78, 97.78, 97.79, 97.79, 97.85, 97.85, 97.84, 97.84, 97.89, 97.89, 97.95, 97.95, 97.91, 97.91, 97.95, 97.95, 97.94, 97.94, 97.98, 97.98, 97.92, 97.92, 97.93, 97.93, 97.92, 97.92, 97.92, 97.92, 97.9, 97.9, 97.9, 97.9, 97.89, 97.89, 97.87, 97.87, 97.92, 97.92, 97.9, 97.9, 97.9, 97.9, 97.96, 97.96, 97.96, 97.96, 98.01, 98.01, 97.99, 97.99, 97.93, 97.93, 97.94, 97.94, 97.96, 97.96, 97.97, 97.97, 97.95, 97.95, 97.97, 97.97, 98.02, 98.02, 98.0, 98.0, 98.02, 98.02, 98.03, 98.03, 98.0, 98.0, 98.03, 98.03, 98.03, 98.03, 98.04, 98.04, 97.98, 97.98, 98.0, 98.0, 97.97, 97.97, 98.01, 98.01, 98.01, 98.01, 97.99, 97.99, 97.98, 97.98, 98.02, 98.02, 98.0, 98.0, 98.02, 98.02, 98.01, 98.01, 98.1, 98.1, 98.0, 98.0, 98.0, 98.0, 98.01, 98.01, 98.04, 98.04, 98.05, 98.05, 98.03, 98.03, 98.05, 98.05, 98.07, 98.07, 98.05, 98.05, 98.07, 98.07, 98.07, 98.07, 98.09, 98.09, 98.1, 98.1, 98.09, 98.09, 98.11, 98.11, 98.11, 98.11, 98.09, 98.09, 98.1, 98.1, 98.09, 98.09, 98.07, 98.07, 98.08, 98.08, 98.02, 98.02, 98.04, 98.04, 98.07, 98.07, 98.07, 98.07, 98.08, 98.08, 98.08, 98.08, 98.07, 98.07, 98.06, 98.06, 98.07, 98.07, 98.05, 98.05, 98.08, 98.08, 98.06, 98.06, 98.07, 98.07, 98.07, 98.07, 98.11, 98.11, 98.12, 98.12, 98.1, 98.1, 98.1, 98.1, 98.12, 98.12, 98.11, 98.11, 98.12, 98.12, 98.09, 98.09, 98.11, 98.11, 98.1, 98.1, 98.09, 98.09, 98.1, 98.1, 98.12, 98.12, 98.13, 98.13, 98.11, 98.11, 98.11, 98.11, 98.11, 98.11, 98.12, 98.12, 98.12, 98.12, 98.11, 98.11, 98.1, 98.1, 98.08, 98.08, 98.11, 98.11, 98.08, 98.08, 98.11, 98.11, 98.09, 98.09, 98.1, 98.1, 98.1, 98.1, 98.1, 98.1, 98.09, 98.09, 98.1, 98.1, 98.1, 98.1, 98.09, 98.09, 98.09, 98.09, 98.09, 98.09, 98.11, 98.11, 98.1, 98.1, 98.08, 98.08, 98.12, 98.12, 98.14, 98.14, 98.08, 98.08, 98.09, 98.09, 98.14, 98.14, 98.13, 98.13, 98.14, 98.14, 98.12, 98.12, 98.11, 98.11, 98.1, 98.1, 98.13, 98.13, 98.13, 98.13, 98.09, 98.09, 98.12, 98.12, 98.13, 98.13, 98.12, 98.12, 98.13, 98.13, 98.15, 98.15, 98.12, 98.12, 98.13, 98.13, 98.1, 98.1, 98.12, 98.12, 98.11, 98.11, 98.08, 98.08, 98.09, 98.09, 98.11, 98.11, 98.1, 98.1, 98.1, 98.1, 98.13, 98.13, 98.11, 98.11, 98.12, 98.12, 98.12, 98.12, 98.11, 98.11, 98.13, 98.13, 98.15, 98.15, 98.11, 98.11, 98.1, 98.1, 98.11, 98.11, 98.1, 98.1, 98.08, 98.08]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 16773 (global); Percentage 3.05 (16773/550021 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.572, Test loss: 1.482, Test accuracy: 52.93
Round   1, Train loss: 1.285, Test loss: 1.109, Test accuracy: 91.88
Round   2, Train loss: 1.002, Test loss: 1.026, Test accuracy: 93.77
Round   3, Train loss: 0.949, Test loss: 1.010, Test accuracy: 94.32
Round   4, Train loss: 0.942, Test loss: 1.001, Test accuracy: 94.53
Round   5, Train loss: 0.931, Test loss: 0.995, Test accuracy: 94.85
Round   6, Train loss: 0.940, Test loss: 0.979, Test accuracy: 95.22
Round   7, Train loss: 0.922, Test loss: 0.977, Test accuracy: 95.40
Round   8, Train loss: 0.934, Test loss: 0.966, Test accuracy: 95.50
Round   9, Train loss: 0.919, Test loss: 0.964, Test accuracy: 95.61
Round  10, Train loss: 0.931, Test loss: 0.952, Test accuracy: 95.92
Round  11, Train loss: 0.926, Test loss: 0.949, Test accuracy: 96.20
Round  12, Train loss: 0.922, Test loss: 0.948, Test accuracy: 96.26
Round  13, Train loss: 0.918, Test loss: 0.948, Test accuracy: 96.21
Round  14, Train loss: 0.920, Test loss: 0.947, Test accuracy: 96.22
Round  15, Train loss: 0.916, Test loss: 0.946, Test accuracy: 96.29
Round  16, Train loss: 0.914, Test loss: 0.946, Test accuracy: 96.30
Round  17, Train loss: 0.912, Test loss: 0.945, Test accuracy: 96.28
Round  18, Train loss: 0.913, Test loss: 0.945, Test accuracy: 96.28
Round  19, Train loss: 0.913, Test loss: 0.945, Test accuracy: 96.29
Round  20, Train loss: 0.914, Test loss: 0.945, Test accuracy: 96.28
Round  21, Train loss: 0.913, Test loss: 0.945, Test accuracy: 96.28
Round  22, Train loss: 0.912, Test loss: 0.945, Test accuracy: 96.27
Round  23, Train loss: 0.913, Test loss: 0.945, Test accuracy: 96.31
Round  24, Train loss: 0.914, Test loss: 0.944, Test accuracy: 96.31
Round  25, Train loss: 0.913, Test loss: 0.944, Test accuracy: 96.37
Round  26, Train loss: 0.913, Test loss: 0.944, Test accuracy: 96.36
Round  27, Train loss: 0.910, Test loss: 0.944, Test accuracy: 96.39
Round  28, Train loss: 0.912, Test loss: 0.944, Test accuracy: 96.39
Round  29, Train loss: 0.909, Test loss: 0.944, Test accuracy: 96.39
Round  30, Train loss: 0.912, Test loss: 0.944, Test accuracy: 96.38
Round  31, Train loss: 0.911, Test loss: 0.944, Test accuracy: 96.35
Round  32, Train loss: 0.914, Test loss: 0.943, Test accuracy: 96.40
Round  33, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.39
Round  34, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.38
Round  35, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.39
Round  36, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.38
Round  37, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.37
Round  38, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.35
Round  39, Train loss: 0.914, Test loss: 0.943, Test accuracy: 96.37
Round  40, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.36
Round  41, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.36
Round  42, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.34
Round  43, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.36
Round  44, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.36
Round  45, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.36
Round  46, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.35
Round  47, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.36
Round  48, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.32
Round  49, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.34
Round  50, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.35
Round  51, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.33
Round  52, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.31
Round  53, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.32
Round  54, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.33
Round  55, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.37
Round  56, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.37
Round  57, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.36
Round  58, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.36
Round  59, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.35
Round  60, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.37
Round  61, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.36
Round  62, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.38
Round  63, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.37
Round  64, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.37
Round  65, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.39
Round  66, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.37
Round  67, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.39
Round  68, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.40
Round  69, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.39
Round  70, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.38
Round  71, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.38
Round  72, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.39
Round  73, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.39
Round  74, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.40
Round  75, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.40
Round  76, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.39
Round  77, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.37
Round  78, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.38
Round  79, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.36
Round  80, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.35
Round  81, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.34
Round  82, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.32
Round  83, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.34
Round  84, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.34
Round  85, Train loss: 0.912, Test loss: 0.943, Test accuracy: 96.34
Round  86, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.35
Round  87, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.34
Round  88, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.33
Round  89, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.33
Round  90, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.33
Round  91, Train loss: 0.908, Test loss: 0.943, Test accuracy: 96.34
Round  92, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.33
Round  93, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.33
Round  94, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.33
Round  95, Train loss: 0.907, Test loss: 0.943, Test accuracy: 96.36
Round  96, Train loss: 0.909, Test loss: 0.943, Test accuracy: 96.34
Round  97, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.33
Round  98, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.32
Round  99, Train loss: 0.911, Test loss: 0.943, Test accuracy: 96.31/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 0.910, Test loss: 0.943, Test accuracy: 96.33
Average accuracy final 10 rounds: 96.332 

970.3475210666656
[0.9299705028533936, 1.859941005706787, 2.6146440505981445, 3.369347095489502, 4.126104831695557, 4.882862567901611, 5.641963005065918, 6.401063442230225, 7.183797121047974, 7.966530799865723, 8.731202363967896, 9.495873928070068, 10.230620384216309, 10.965366840362549, 11.72639799118042, 12.487429141998291, 13.259670972824097, 14.031912803649902, 14.819806098937988, 15.607699394226074, 16.347187757492065, 17.086676120758057, 17.839227199554443, 18.59177827835083, 19.376590251922607, 20.161402225494385, 20.927741527557373, 21.69408082962036, 22.457378149032593, 23.220675468444824, 23.95686149597168, 24.693047523498535, 25.476462602615356, 26.259877681732178, 27.014838457107544, 27.76979923248291, 28.539694786071777, 29.309590339660645, 30.039010047912598, 30.76842975616455, 31.513753652572632, 32.25907754898071, 33.04061222076416, 33.82214689254761, 34.596535444259644, 35.37092399597168, 36.1396119594574, 36.908299922943115, 37.63506603240967, 38.36183214187622, 39.135226011276245, 39.90861988067627, 40.682133197784424, 41.45564651489258, 42.22280192375183, 42.989957332611084, 43.7370879650116, 44.48421859741211, 45.20173406600952, 45.919249534606934, 46.721822023391724, 47.524394512176514, 48.27601933479309, 49.02764415740967, 49.80319690704346, 50.578749656677246, 51.30509972572327, 52.03144979476929, 52.758760929107666, 53.486072063446045, 54.27783536911011, 55.06959867477417, 55.81465435028076, 56.55971002578735, 57.33518171310425, 58.11065340042114, 58.8308207988739, 59.55098819732666, 60.33119082450867, 61.111393451690674, 61.87220597267151, 62.633018493652344, 63.392174243927, 64.15132999420166, 64.87361860275269, 65.59590721130371, 66.34074926376343, 67.08559131622314, 67.85529088973999, 68.62499046325684, 69.37947368621826, 70.13395690917969, 70.89405822753906, 71.65415954589844, 72.39146018028259, 73.12876081466675, 73.91024279594421, 74.69172477722168, 75.45945334434509, 76.2271819114685, 76.9992470741272, 77.77131223678589, 78.5236234664917, 79.27593469619751, 80.02444624900818, 80.77295780181885, 81.54506802558899, 82.31717824935913, 83.06287121772766, 83.80856418609619, 84.5591630935669, 85.3097620010376, 86.03128957748413, 86.75281715393066, 87.53754711151123, 88.3222770690918, 89.10044741630554, 89.87861776351929, 90.64249539375305, 91.40637302398682, 92.14981961250305, 92.89326620101929, 93.62000632286072, 94.34674644470215, 95.14215135574341, 95.93755626678467, 96.6920416355133, 97.44652700424194, 98.21626281738281, 98.98599863052368, 99.74338173866272, 100.50076484680176, 101.25961995124817, 102.01847505569458, 102.81361103057861, 103.60874700546265, 104.41254758834839, 105.21634817123413, 105.97872829437256, 106.74110841751099, 107.50933599472046, 108.27756357192993, 109.05421948432922, 109.83087539672852, 110.60776400566101, 111.3846526145935, 112.16703295707703, 112.94941329956055, 113.7215006351471, 114.49358797073364, 115.263507604599, 116.03342723846436, 116.80619311332703, 117.5789589881897, 118.34237384796143, 119.10578870773315, 119.87094902992249, 120.63610935211182, 121.40794801712036, 122.1797866821289, 122.93850183486938, 123.69721698760986, 124.47277092933655, 125.24832487106323, 126.01094794273376, 126.7735710144043, 127.51992559432983, 128.26628017425537, 129.02191996574402, 129.77755975723267, 130.52931928634644, 131.2810788154602, 132.04151487350464, 132.80195093154907, 133.54915118217468, 134.2963514328003, 135.05460238456726, 135.81285333633423, 136.61683797836304, 137.42082262039185, 138.2015872001648, 138.98235177993774, 139.797376871109, 140.61240196228027, 141.36844563484192, 142.12448930740356, 142.88756203651428, 143.650634765625, 144.41347789764404, 145.1763210296631, 145.93307518959045, 146.68982934951782, 147.44653296470642, 148.20323657989502, 148.95000386238098, 149.69677114486694, 150.46945881843567, 151.2421464920044, 152.00883507728577, 152.77552366256714, 154.23238110542297, 155.6892385482788]
[52.93, 52.93, 91.88, 91.88, 93.77, 93.77, 94.32, 94.32, 94.53, 94.53, 94.85, 94.85, 95.22, 95.22, 95.4, 95.4, 95.5, 95.5, 95.61, 95.61, 95.92, 95.92, 96.2, 96.2, 96.26, 96.26, 96.21, 96.21, 96.22, 96.22, 96.29, 96.29, 96.3, 96.3, 96.28, 96.28, 96.28, 96.28, 96.29, 96.29, 96.28, 96.28, 96.28, 96.28, 96.27, 96.27, 96.31, 96.31, 96.31, 96.31, 96.37, 96.37, 96.36, 96.36, 96.39, 96.39, 96.39, 96.39, 96.39, 96.39, 96.38, 96.38, 96.35, 96.35, 96.4, 96.4, 96.39, 96.39, 96.38, 96.38, 96.39, 96.39, 96.38, 96.38, 96.37, 96.37, 96.35, 96.35, 96.37, 96.37, 96.36, 96.36, 96.36, 96.36, 96.34, 96.34, 96.36, 96.36, 96.36, 96.36, 96.36, 96.36, 96.35, 96.35, 96.36, 96.36, 96.32, 96.32, 96.34, 96.34, 96.35, 96.35, 96.33, 96.33, 96.31, 96.31, 96.32, 96.32, 96.33, 96.33, 96.37, 96.37, 96.37, 96.37, 96.36, 96.36, 96.36, 96.36, 96.35, 96.35, 96.37, 96.37, 96.36, 96.36, 96.38, 96.38, 96.37, 96.37, 96.37, 96.37, 96.39, 96.39, 96.37, 96.37, 96.39, 96.39, 96.4, 96.4, 96.39, 96.39, 96.38, 96.38, 96.38, 96.38, 96.39, 96.39, 96.39, 96.39, 96.4, 96.4, 96.4, 96.4, 96.39, 96.39, 96.37, 96.37, 96.38, 96.38, 96.36, 96.36, 96.35, 96.35, 96.34, 96.34, 96.32, 96.32, 96.34, 96.34, 96.34, 96.34, 96.34, 96.34, 96.35, 96.35, 96.34, 96.34, 96.33, 96.33, 96.33, 96.33, 96.33, 96.33, 96.34, 96.34, 96.33, 96.33, 96.33, 96.33, 96.33, 96.33, 96.36, 96.36, 96.34, 96.34, 96.33, 96.33, 96.32, 96.32, 96.31, 96.31, 96.33, 96.33]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 0.985, Test loss: 1.372, Test accuracy: 92.72
Round   1, Train loss: 0.716, Test loss: 1.085, Test accuracy: 95.18
Round   2, Train loss: 0.704, Test loss: 1.048, Test accuracy: 95.62
Round   3, Train loss: 0.695, Test loss: 1.035, Test accuracy: 95.70
Round   4, Train loss: 0.694, Test loss: 1.026, Test accuracy: 95.90
Round   5, Train loss: 0.697, Test loss: 1.021, Test accuracy: 96.08
Round   6, Train loss: 0.691, Test loss: 1.016, Test accuracy: 96.21
Round   7, Train loss: 0.692, Test loss: 1.014, Test accuracy: 96.26
Round   8, Train loss: 0.691, Test loss: 1.014, Test accuracy: 96.11
Round   9, Train loss: 0.688, Test loss: 1.013, Test accuracy: 95.92
Round  10, Train loss: 0.689, Test loss: 1.012, Test accuracy: 95.90
Round  11, Train loss: 0.688, Test loss: 1.011, Test accuracy: 95.91
Round  12, Train loss: 0.687, Test loss: 1.010, Test accuracy: 95.86
Round  13, Train loss: 0.688, Test loss: 1.010, Test accuracy: 95.85
Round  14, Train loss: 0.686, Test loss: 1.009, Test accuracy: 96.00
Round  15, Train loss: 0.687, Test loss: 1.008, Test accuracy: 95.90
Round  16, Train loss: 0.689, Test loss: 1.008, Test accuracy: 95.85
Round  17, Train loss: 0.686, Test loss: 1.008, Test accuracy: 95.81
Round  18, Train loss: 0.687, Test loss: 1.008, Test accuracy: 95.64
Round  19, Train loss: 0.688, Test loss: 1.009, Test accuracy: 95.62
Round  20, Train loss: 0.685, Test loss: 1.008, Test accuracy: 95.52
Round  21, Train loss: 0.686, Test loss: 1.009, Test accuracy: 95.32
Round  22, Train loss: 0.685, Test loss: 1.009, Test accuracy: 95.24
Round  23, Train loss: 0.687, Test loss: 1.009, Test accuracy: 95.19
Round  24, Train loss: 0.686, Test loss: 1.010, Test accuracy: 95.04
Round  25, Train loss: 0.684, Test loss: 1.010, Test accuracy: 95.00
Round  26, Train loss: 0.685, Test loss: 1.010, Test accuracy: 95.01
Round  27, Train loss: 0.683, Test loss: 1.010, Test accuracy: 94.87
Round  28, Train loss: 0.684, Test loss: 1.011, Test accuracy: 94.75
Round  29, Train loss: 0.685, Test loss: 1.013, Test accuracy: 94.58
Round  30, Train loss: 0.683, Test loss: 1.012, Test accuracy: 94.50
Round  31, Train loss: 0.685, Test loss: 1.014, Test accuracy: 94.38
Round  32, Train loss: 0.683, Test loss: 1.014, Test accuracy: 94.27
Round  33, Train loss: 0.683, Test loss: 1.015, Test accuracy: 94.18
Round  34, Train loss: 0.684, Test loss: 1.015, Test accuracy: 94.14
Round  35, Train loss: 0.685, Test loss: 1.016, Test accuracy: 93.82
Round  36, Train loss: 0.685, Test loss: 1.017, Test accuracy: 93.66
Round  37, Train loss: 0.684, Test loss: 1.018, Test accuracy: 93.63
Round  38, Train loss: 0.685, Test loss: 1.018, Test accuracy: 93.62
Round  39, Train loss: 0.684, Test loss: 1.020, Test accuracy: 93.49
Round  40, Train loss: 0.685, Test loss: 1.020, Test accuracy: 93.35
Round  41, Train loss: 0.683, Test loss: 1.020, Test accuracy: 93.32
Round  42, Train loss: 0.684, Test loss: 1.022, Test accuracy: 93.11
Round  43, Train loss: 0.683, Test loss: 1.021, Test accuracy: 93.17
Round  44, Train loss: 0.684, Test loss: 1.022, Test accuracy: 93.08
Round  45, Train loss: 0.683, Test loss: 1.023, Test accuracy: 92.91
Round  46, Train loss: 0.684, Test loss: 1.023, Test accuracy: 92.83
Round  47, Train loss: 0.684, Test loss: 1.024, Test accuracy: 92.82
Round  48, Train loss: 0.685, Test loss: 1.024, Test accuracy: 92.66
Round  49, Train loss: 0.684, Test loss: 1.025, Test accuracy: 92.53
Round  50, Train loss: 0.684, Test loss: 1.025, Test accuracy: 92.47
Round  51, Train loss: 0.683, Test loss: 1.026, Test accuracy: 92.41
Round  52, Train loss: 0.683, Test loss: 1.025, Test accuracy: 92.49
Round  53, Train loss: 0.683, Test loss: 1.025, Test accuracy: 92.48
Round  54, Train loss: 0.683, Test loss: 1.027, Test accuracy: 92.44
Round  55, Train loss: 0.683, Test loss: 1.027, Test accuracy: 92.36
Round  56, Train loss: 0.683, Test loss: 1.027, Test accuracy: 92.31
Round  57, Train loss: 0.682, Test loss: 1.028, Test accuracy: 92.20
Round  58, Train loss: 0.682, Test loss: 1.028, Test accuracy: 92.30
Round  59, Train loss: 0.683, Test loss: 1.028, Test accuracy: 92.27
Round  60, Train loss: 0.684, Test loss: 1.029, Test accuracy: 92.10
Round  61, Train loss: 0.684, Test loss: 1.030, Test accuracy: 91.95
Round  62, Train loss: 0.683, Test loss: 1.030, Test accuracy: 91.88
Round  63, Train loss: 0.683, Test loss: 1.030, Test accuracy: 91.93
Round  64, Train loss: 0.682, Test loss: 1.031, Test accuracy: 91.79
Round  65, Train loss: 0.683, Test loss: 1.032, Test accuracy: 91.73
Round  66, Train loss: 0.683, Test loss: 1.032, Test accuracy: 91.67
Round  67, Train loss: 0.682, Test loss: 1.032, Test accuracy: 91.66
Round  68, Train loss: 0.684, Test loss: 1.033, Test accuracy: 91.63
Round  69, Train loss: 0.681, Test loss: 1.033, Test accuracy: 91.68
Round  70, Train loss: 0.684, Test loss: 1.032, Test accuracy: 91.67
Round  71, Train loss: 0.683, Test loss: 1.033, Test accuracy: 91.62
Round  72, Train loss: 0.684, Test loss: 1.033, Test accuracy: 91.65
Round  73, Train loss: 0.682, Test loss: 1.034, Test accuracy: 91.54
Round  74, Train loss: 0.684, Test loss: 1.034, Test accuracy: 91.55
Round  75, Train loss: 0.682, Test loss: 1.035, Test accuracy: 91.38
Round  76, Train loss: 0.683, Test loss: 1.036, Test accuracy: 91.29
Round  77, Train loss: 0.684, Test loss: 1.036, Test accuracy: 91.32
Round  78, Train loss: 0.683, Test loss: 1.037, Test accuracy: 91.14
Round  79, Train loss: 0.683, Test loss: 1.037, Test accuracy: 91.12
Round  80, Train loss: 0.683, Test loss: 1.036, Test accuracy: 91.20
Round  81, Train loss: 0.683, Test loss: 1.036, Test accuracy: 91.19
Round  82, Train loss: 0.682, Test loss: 1.036, Test accuracy: 91.13
Round  83, Train loss: 0.682, Test loss: 1.037, Test accuracy: 91.08
Round  84, Train loss: 0.682, Test loss: 1.038, Test accuracy: 90.92
Round  85, Train loss: 0.683, Test loss: 1.039, Test accuracy: 90.87
Round  86, Train loss: 0.681, Test loss: 1.040, Test accuracy: 90.81
Round  87, Train loss: 0.683, Test loss: 1.039, Test accuracy: 90.77
Round  88, Train loss: 0.684, Test loss: 1.040, Test accuracy: 90.63
Round  89, Train loss: 0.683, Test loss: 1.041, Test accuracy: 90.54
Round  90, Train loss: 0.683, Test loss: 1.041, Test accuracy: 90.49
Round  91, Train loss: 0.682, Test loss: 1.041, Test accuracy: 90.54
Round  92, Train loss: 0.683, Test loss: 1.041, Test accuracy: 90.57
Round  93, Train loss: 0.681, Test loss: 1.042, Test accuracy: 90.39
Round  94, Train loss: 0.682, Test loss: 1.042, Test accuracy: 90.36
Round  95, Train loss: 0.682, Test loss: 1.043, Test accuracy: 90.31
Round  96, Train loss: 0.683, Test loss: 1.043, Test accuracy: 90.30
Round  97, Train loss: 0.683, Test loss: 1.043, Test accuracy: 90.39
Round  98, Train loss: 0.682, Test loss: 1.043, Test accuracy: 90.23
Round  99, Train loss: 0.682, Test loss: 1.044, Test accuracy: 90.20
Final Round, Train loss: 0.683, Test loss: 1.044, Test accuracy: 90.22
Average accuracy final 10 rounds: 90.37799999999999
1191.3373198509216
[]
[92.72, 95.18, 95.62, 95.7, 95.9, 96.08, 96.21, 96.26, 96.11, 95.92, 95.9, 95.91, 95.86, 95.85, 96.0, 95.9, 95.85, 95.81, 95.64, 95.62, 95.52, 95.32, 95.24, 95.19, 95.04, 95.0, 95.01, 94.87, 94.75, 94.58, 94.5, 94.38, 94.27, 94.18, 94.14, 93.82, 93.66, 93.63, 93.62, 93.49, 93.35, 93.32, 93.11, 93.17, 93.08, 92.91, 92.83, 92.82, 92.66, 92.53, 92.47, 92.41, 92.49, 92.48, 92.44, 92.36, 92.31, 92.2, 92.3, 92.27, 92.1, 91.95, 91.88, 91.93, 91.79, 91.73, 91.67, 91.66, 91.63, 91.68, 91.67, 91.62, 91.65, 91.54, 91.55, 91.38, 91.29, 91.32, 91.14, 91.12, 91.2, 91.19, 91.13, 91.08, 90.92, 90.87, 90.81, 90.77, 90.63, 90.54, 90.49, 90.54, 90.57, 90.39, 90.36, 90.31, 90.3, 90.39, 90.23, 90.2, 90.22]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.574, Test loss: 1.570, Test accuracy: 37.59
Round   1, Train loss: 1.385, Test loss: 1.452, Test accuracy: 65.54
Round   2, Train loss: 1.288, Test loss: 1.417, Test accuracy: 63.77
Round   3, Train loss: 0.853, Test loss: 1.253, Test accuracy: 83.21
Round   4, Train loss: 0.849, Test loss: 1.233, Test accuracy: 79.77
Round   5, Train loss: 0.768, Test loss: 1.175, Test accuracy: 82.51
Round   6, Train loss: 1.190, Test loss: 1.176, Test accuracy: 80.30
Round   7, Train loss: 1.466, Test loss: 1.206, Test accuracy: 76.47
Round   8, Train loss: 0.997, Test loss: 1.164, Test accuracy: 79.99
Round   9, Train loss: 0.650, Test loss: 1.131, Test accuracy: 83.07
Round  10, Train loss: 0.985, Test loss: 1.134, Test accuracy: 82.96
Round  11, Train loss: 0.784, Test loss: 1.124, Test accuracy: 83.04
Round  12, Train loss: 0.668, Test loss: 1.075, Test accuracy: 85.89
Round  13, Train loss: 0.853, Test loss: 1.071, Test accuracy: 86.17
Round  14, Train loss: 0.666, Test loss: 1.067, Test accuracy: 86.60
Round  15, Train loss: 0.704, Test loss: 1.040, Test accuracy: 88.62
Round  16, Train loss: 0.434, Test loss: 1.009, Test accuracy: 91.87
Round  17, Train loss: 0.748, Test loss: 0.985, Test accuracy: 93.94
Round  18, Train loss: 0.352, Test loss: 0.979, Test accuracy: 94.11
Round  19, Train loss: 0.432, Test loss: 0.981, Test accuracy: 94.00
Round  20, Train loss: 0.541, Test loss: 0.972, Test accuracy: 94.35
Round  21, Train loss: 0.616, Test loss: 0.963, Test accuracy: 95.29
Round  22, Train loss: 0.436, Test loss: 0.960, Test accuracy: 95.34
Round  23, Train loss: 0.436, Test loss: 0.959, Test accuracy: 95.52
Round  24, Train loss: 0.465, Test loss: 0.956, Test accuracy: 95.73
Round  25, Train loss: 0.364, Test loss: 0.955, Test accuracy: 95.86
Round  26, Train loss: 0.176, Test loss: 0.954, Test accuracy: 95.90
Round  27, Train loss: 0.381, Test loss: 0.954, Test accuracy: 95.93
Round  28, Train loss: 0.404, Test loss: 0.951, Test accuracy: 96.09
Round  29, Train loss: 0.280, Test loss: 0.951, Test accuracy: 96.10
Round  30, Train loss: 0.166, Test loss: 0.951, Test accuracy: 96.16
Round  31, Train loss: 0.271, Test loss: 0.950, Test accuracy: 96.15
Round  32, Train loss: 0.178, Test loss: 0.949, Test accuracy: 96.25
Round  33, Train loss: 0.424, Test loss: 0.950, Test accuracy: 96.13
Round  34, Train loss: 0.208, Test loss: 0.946, Test accuracy: 96.21
Round  35, Train loss: 0.217, Test loss: 0.946, Test accuracy: 96.31
Round  36, Train loss: 0.171, Test loss: 0.946, Test accuracy: 96.19
Round  37, Train loss: 0.225, Test loss: 0.946, Test accuracy: 96.28
Round  38, Train loss: 0.087, Test loss: 0.945, Test accuracy: 96.30
Round  39, Train loss: 0.378, Test loss: 0.945, Test accuracy: 96.29
Round  40, Train loss: 0.278, Test loss: 0.946, Test accuracy: 96.25
Round  41, Train loss: 0.357, Test loss: 0.946, Test accuracy: 96.23
Round  42, Train loss: 0.121, Test loss: 0.945, Test accuracy: 96.25
Round  43, Train loss: 0.224, Test loss: 0.943, Test accuracy: 96.36
Round  44, Train loss: 0.112, Test loss: 0.942, Test accuracy: 96.48
Round  45, Train loss: 0.225, Test loss: 0.943, Test accuracy: 96.40
Round  46, Train loss: 0.185, Test loss: 0.944, Test accuracy: 96.19
Round  47, Train loss: 0.028, Test loss: 0.942, Test accuracy: 96.43
Round  48, Train loss: 0.228, Test loss: 0.943, Test accuracy: 96.33
Round  49, Train loss: 0.189, Test loss: 0.943, Test accuracy: 96.36
Round  50, Train loss: 0.332, Test loss: 0.944, Test accuracy: 96.24
Round  51, Train loss: 0.248, Test loss: 0.943, Test accuracy: 96.33
Round  52, Train loss: 0.001, Test loss: 0.943, Test accuracy: 96.32
Round  53, Train loss: 0.148, Test loss: 0.943, Test accuracy: 96.40
Round  54, Train loss: 0.244, Test loss: 0.943, Test accuracy: 96.35
Round  55, Train loss: 0.195, Test loss: 0.944, Test accuracy: 96.28
Round  56, Train loss: 0.255, Test loss: 0.943, Test accuracy: 96.34
Round  57, Train loss: 0.139, Test loss: 0.944, Test accuracy: 96.32
Round  58, Train loss: 0.262, Test loss: 0.943, Test accuracy: 96.45
Round  59, Train loss: 0.040, Test loss: 0.943, Test accuracy: 96.37
Round  60, Train loss: 0.348, Test loss: 0.943, Test accuracy: 96.35
Round  61, Train loss: 0.246, Test loss: 0.943, Test accuracy: 96.42
Round  62, Train loss: 0.118, Test loss: 0.941, Test accuracy: 96.50
Round  63, Train loss: 0.237, Test loss: 0.943, Test accuracy: 96.37
Round  64, Train loss: 0.202, Test loss: 0.942, Test accuracy: 96.43
Round  65, Train loss: 0.210, Test loss: 0.940, Test accuracy: 96.80
Round  66, Train loss: 0.216, Test loss: 0.941, Test accuracy: 96.65
Round  67, Train loss: 0.237, Test loss: 0.941, Test accuracy: 96.54
Round  68, Train loss: 0.204, Test loss: 0.941, Test accuracy: 96.56
Round  69, Train loss: 0.249, Test loss: 0.942, Test accuracy: 96.45
Round  70, Train loss: 0.282, Test loss: 0.943, Test accuracy: 96.39
Round  71, Train loss: 0.287, Test loss: 0.942, Test accuracy: 96.40
Round  72, Train loss: 0.261, Test loss: 0.943, Test accuracy: 96.34
Round  73, Train loss: 0.375, Test loss: 0.943, Test accuracy: 96.38
Round  74, Train loss: 0.514, Test loss: 0.944, Test accuracy: 96.26
Round  75, Train loss: 0.307, Test loss: 0.943, Test accuracy: 96.38
Round  76, Train loss: 0.245, Test loss: 0.941, Test accuracy: 96.53
Round  77, Train loss: 0.325, Test loss: 0.941, Test accuracy: 96.53
Round  78, Train loss: 0.278, Test loss: 0.942, Test accuracy: 96.51
Round  79, Train loss: 0.261, Test loss: 0.942, Test accuracy: 96.42
Round  80, Train loss: 0.358, Test loss: 0.942, Test accuracy: 96.43
Round  81, Train loss: 0.365, Test loss: 0.943, Test accuracy: 96.46
Round  82, Train loss: 0.436, Test loss: 0.943, Test accuracy: 96.47
Round  83, Train loss: 0.209, Test loss: 0.942, Test accuracy: 96.59
Round  84, Train loss: 0.350, Test loss: 0.941, Test accuracy: 96.61
Round  85, Train loss: 0.395, Test loss: 0.941, Test accuracy: 96.56
Round  86, Train loss: 0.189, Test loss: 0.940, Test accuracy: 96.60
Round  87, Train loss: 0.367, Test loss: 0.941, Test accuracy: 96.56
Round  88, Train loss: 0.382, Test loss: 0.941, Test accuracy: 96.59
Round  89, Train loss: 0.468, Test loss: 0.942, Test accuracy: 96.47
Round  90, Train loss: 0.382, Test loss: 0.941, Test accuracy: 96.54
Round  91, Train loss: 0.382, Test loss: 0.940, Test accuracy: 96.67
Round  92, Train loss: 0.390, Test loss: 0.939, Test accuracy: 96.72
Round  93, Train loss: 0.407, Test loss: 0.939, Test accuracy: 96.67
Round  94, Train loss: 0.467, Test loss: 0.941, Test accuracy: 96.48
Round  95, Train loss: 0.441, Test loss: 0.940, Test accuracy: 96.69
Round  96, Train loss: 0.371, Test loss: 0.940, Test accuracy: 96.67
Round  97, Train loss: 0.330, Test loss: 0.941, Test accuracy: 96.65
Round  98, Train loss: 0.498, Test loss: 0.941, Test accuracy: 96.64
Round  99, Train loss: 0.440, Test loss: 0.941, Test accuracy: 96.63
Final Round, Train loss: 0.927, Test loss: 0.937, Test accuracy: 97.18
Average accuracy final 10 rounds: 96.636
Average global accuracy final 10 rounds: 96.636
883.6657104492188
[]
[37.59, 65.54, 63.77, 83.21, 79.77, 82.51, 80.3, 76.47, 79.99, 83.07, 82.96, 83.04, 85.89, 86.17, 86.6, 88.62, 91.87, 93.94, 94.11, 94.0, 94.35, 95.29, 95.34, 95.52, 95.73, 95.86, 95.9, 95.93, 96.09, 96.1, 96.16, 96.15, 96.25, 96.13, 96.21, 96.31, 96.19, 96.28, 96.3, 96.29, 96.25, 96.23, 96.25, 96.36, 96.48, 96.4, 96.19, 96.43, 96.33, 96.36, 96.24, 96.33, 96.32, 96.4, 96.35, 96.28, 96.34, 96.32, 96.45, 96.37, 96.35, 96.42, 96.5, 96.37, 96.43, 96.8, 96.65, 96.54, 96.56, 96.45, 96.39, 96.4, 96.34, 96.38, 96.26, 96.38, 96.53, 96.53, 96.51, 96.42, 96.43, 96.46, 96.47, 96.59, 96.61, 96.56, 96.6, 96.56, 96.59, 96.47, 96.54, 96.67, 96.72, 96.67, 96.48, 96.69, 96.67, 96.65, 96.64, 96.63, 97.18]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.598, Test loss: 1.579, Test accuracy: 59.59
Round   0, Global train loss: 1.598, Global test loss: 1.579, Global test accuracy: 59.44
Round   1, Train loss: 1.442, Test loss: 1.308, Test accuracy: 73.03
Round   1, Global train loss: 1.442, Global test loss: 1.218, Global test accuracy: 77.55
Round   2, Train loss: 1.102, Test loss: 1.142, Test accuracy: 84.99
Round   2, Global train loss: 1.102, Global test loss: 1.011, Global test accuracy: 93.75
Round   3, Train loss: 0.982, Test loss: 1.058, Test accuracy: 89.89
Round   3, Global train loss: 0.982, Global test loss: 0.962, Global test accuracy: 96.50
Round   4, Train loss: 0.953, Test loss: 1.008, Test accuracy: 92.63
Round   4, Global train loss: 0.953, Global test loss: 0.950, Global test accuracy: 96.84
Round   5, Train loss: 0.949, Test loss: 1.000, Test accuracy: 93.07
Round   5, Global train loss: 0.949, Global test loss: 0.943, Global test accuracy: 97.32
Round   6, Train loss: 0.938, Test loss: 0.970, Test accuracy: 95.22
Round   6, Global train loss: 0.938, Global test loss: 0.939, Global test accuracy: 97.41
Round   7, Train loss: 0.937, Test loss: 0.960, Test accuracy: 95.74
Round   7, Global train loss: 0.937, Global test loss: 0.936, Global test accuracy: 97.43
Round   8, Train loss: 0.935, Test loss: 0.944, Test accuracy: 96.81
Round   8, Global train loss: 0.935, Global test loss: 0.935, Global test accuracy: 97.48
Round   9, Train loss: 0.931, Test loss: 0.940, Test accuracy: 96.93
Round   9, Global train loss: 0.931, Global test loss: 0.934, Global test accuracy: 97.38
Round  10, Train loss: 0.928, Test loss: 0.938, Test accuracy: 97.04
Round  10, Global train loss: 0.928, Global test loss: 0.934, Global test accuracy: 97.38
Round  11, Train loss: 0.931, Test loss: 0.938, Test accuracy: 97.01
Round  11, Global train loss: 0.931, Global test loss: 0.933, Global test accuracy: 97.41
Round  12, Train loss: 0.929, Test loss: 0.936, Test accuracy: 97.20
Round  12, Global train loss: 0.929, Global test loss: 0.931, Global test accuracy: 97.44
Round  13, Train loss: 0.926, Test loss: 0.935, Test accuracy: 97.22
Round  13, Global train loss: 0.926, Global test loss: 0.930, Global test accuracy: 97.67
Round  14, Train loss: 0.926, Test loss: 0.935, Test accuracy: 97.24
Round  14, Global train loss: 0.926, Global test loss: 0.931, Global test accuracy: 97.77
Round  15, Train loss: 0.922, Test loss: 0.934, Test accuracy: 97.28
Round  15, Global train loss: 0.922, Global test loss: 0.929, Global test accuracy: 97.83
Round  16, Train loss: 0.930, Test loss: 0.933, Test accuracy: 97.41
Round  16, Global train loss: 0.930, Global test loss: 0.928, Global test accuracy: 97.97
Round  17, Train loss: 0.925, Test loss: 0.932, Test accuracy: 97.44
Round  17, Global train loss: 0.925, Global test loss: 0.928, Global test accuracy: 97.84
Round  18, Train loss: 0.924, Test loss: 0.932, Test accuracy: 97.48
Round  18, Global train loss: 0.924, Global test loss: 0.928, Global test accuracy: 97.76
Round  19, Train loss: 0.924, Test loss: 0.931, Test accuracy: 97.46
Round  19, Global train loss: 0.924, Global test loss: 0.927, Global test accuracy: 97.86
Round  20, Train loss: 0.921, Test loss: 0.931, Test accuracy: 97.53
Round  20, Global train loss: 0.921, Global test loss: 0.927, Global test accuracy: 97.91
Round  21, Train loss: 0.921, Test loss: 0.930, Test accuracy: 97.61
Round  21, Global train loss: 0.921, Global test loss: 0.927, Global test accuracy: 97.94
Round  22, Train loss: 0.920, Test loss: 0.930, Test accuracy: 97.66
Round  22, Global train loss: 0.920, Global test loss: 0.927, Global test accuracy: 97.91
Round  23, Train loss: 0.921, Test loss: 0.929, Test accuracy: 97.73
Round  23, Global train loss: 0.921, Global test loss: 0.926, Global test accuracy: 98.06
Round  24, Train loss: 0.920, Test loss: 0.929, Test accuracy: 97.72
Round  24, Global train loss: 0.920, Global test loss: 0.926, Global test accuracy: 98.04
Round  25, Train loss: 0.919, Test loss: 0.928, Test accuracy: 97.78
Round  25, Global train loss: 0.919, Global test loss: 0.926, Global test accuracy: 98.03
Round  26, Train loss: 0.921, Test loss: 0.928, Test accuracy: 97.78
Round  26, Global train loss: 0.921, Global test loss: 0.925, Global test accuracy: 98.19
Round  27, Train loss: 0.918, Test loss: 0.928, Test accuracy: 97.80
Round  27, Global train loss: 0.918, Global test loss: 0.925, Global test accuracy: 98.24
Round  28, Train loss: 0.919, Test loss: 0.928, Test accuracy: 97.84
Round  28, Global train loss: 0.919, Global test loss: 0.925, Global test accuracy: 98.17
Round  29, Train loss: 0.919, Test loss: 0.927, Test accuracy: 97.87
Round  29, Global train loss: 0.919, Global test loss: 0.925, Global test accuracy: 98.24
Round  30, Train loss: 0.917, Test loss: 0.927, Test accuracy: 97.88
Round  30, Global train loss: 0.917, Global test loss: 0.925, Global test accuracy: 98.09
Round  31, Train loss: 0.920, Test loss: 0.928, Test accuracy: 97.88
Round  31, Global train loss: 0.920, Global test loss: 0.925, Global test accuracy: 98.23
Round  32, Train loss: 0.920, Test loss: 0.927, Test accuracy: 97.93
Round  32, Global train loss: 0.920, Global test loss: 0.925, Global test accuracy: 98.22
Round  33, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.94
Round  33, Global train loss: 0.916, Global test loss: 0.924, Global test accuracy: 98.21
Round  34, Train loss: 0.916, Test loss: 0.927, Test accuracy: 97.96
Round  34, Global train loss: 0.916, Global test loss: 0.924, Global test accuracy: 98.22
Round  35, Train loss: 0.915, Test loss: 0.927, Test accuracy: 98.00
Round  35, Global train loss: 0.915, Global test loss: 0.924, Global test accuracy: 98.31
Round  36, Train loss: 0.918, Test loss: 0.926, Test accuracy: 97.99
Round  36, Global train loss: 0.918, Global test loss: 0.924, Global test accuracy: 98.23
Round  37, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.01
Round  37, Global train loss: 0.915, Global test loss: 0.924, Global test accuracy: 98.38
Round  38, Train loss: 0.916, Test loss: 0.926, Test accuracy: 98.03
Round  38, Global train loss: 0.916, Global test loss: 0.924, Global test accuracy: 98.20
Round  39, Train loss: 0.914, Test loss: 0.926, Test accuracy: 98.07
Round  39, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.34
Round  40, Train loss: 0.918, Test loss: 0.926, Test accuracy: 98.04
Round  40, Global train loss: 0.918, Global test loss: 0.924, Global test accuracy: 98.08
Round  41, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.04
Round  41, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.29
Round  42, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.05
Round  42, Global train loss: 0.914, Global test loss: 0.924, Global test accuracy: 98.19
Round  43, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.01
Round  43, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.31
Round  44, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.03
Round  44, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.36
Round  45, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.05
Round  45, Global train loss: 0.915, Global test loss: 0.922, Global test accuracy: 98.34
Round  46, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.07
Round  46, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.29
Round  47, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.00
Round  47, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.35
Round  48, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.10
Round  48, Global train loss: 0.915, Global test loss: 0.923, Global test accuracy: 98.35
Round  49, Train loss: 0.913, Test loss: 0.925, Test accuracy: 98.09
Round  49, Global train loss: 0.913, Global test loss: 0.923, Global test accuracy: 98.29
Round  50, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.09
Round  50, Global train loss: 0.914, Global test loss: 0.924, Global test accuracy: 98.15
Round  51, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.05
Round  51, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.22
Round  52, Train loss: 0.913, Test loss: 0.925, Test accuracy: 98.06
Round  52, Global train loss: 0.913, Global test loss: 0.923, Global test accuracy: 98.32
Round  53, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.05
Round  53, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.31
Round  54, Train loss: 0.914, Test loss: 0.925, Test accuracy: 98.00
Round  54, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.33
Round  55, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.07
Round  55, Global train loss: 0.911, Global test loss: 0.923, Global test accuracy: 98.25
Round  56, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.05
Round  56, Global train loss: 0.912, Global test loss: 0.923, Global test accuracy: 98.25
Round  57, Train loss: 0.916, Test loss: 0.924, Test accuracy: 98.05
Round  57, Global train loss: 0.916, Global test loss: 0.923, Global test accuracy: 98.27
Round  58, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.10
Round  58, Global train loss: 0.911, Global test loss: 0.923, Global test accuracy: 98.29
Round  59, Train loss: 0.914, Test loss: 0.924, Test accuracy: 98.11
Round  59, Global train loss: 0.914, Global test loss: 0.923, Global test accuracy: 98.30
Round  60, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.14
Round  60, Global train loss: 0.912, Global test loss: 0.923, Global test accuracy: 98.35
Round  61, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.15
Round  61, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.39
Round  62, Train loss: 0.911, Test loss: 0.924, Test accuracy: 98.16
Round  62, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.34
Round  63, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.16
Round  63, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.41
Round  64, Train loss: 0.913, Test loss: 0.924, Test accuracy: 98.18
Round  64, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.38
Round  65, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.24
Round  65, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.30
Round  66, Train loss: 0.912, Test loss: 0.924, Test accuracy: 98.22
Round  66, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.42
Round  67, Train loss: 0.914, Test loss: 0.923, Test accuracy: 98.24
Round  67, Global train loss: 0.914, Global test loss: 0.922, Global test accuracy: 98.39
Round  68, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.24
Round  68, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.40
Round  69, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.24
Round  69, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.38
Round  70, Train loss: 0.911, Test loss: 0.923, Test accuracy: 98.25
Round  70, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.39
Round  71, Train loss: 0.914, Test loss: 0.923, Test accuracy: 98.24
Round  71, Global train loss: 0.914, Global test loss: 0.922, Global test accuracy: 98.36
Round  72, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.26
Round  72, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.42
Round  73, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.26
Round  73, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.39
Round  74, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.27
Round  74, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.48
Round  75, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.26
Round  75, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.42
Round  76, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.25
Round  76, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.42
Round  77, Train loss: 0.914, Test loss: 0.923, Test accuracy: 98.25
Round  77, Global train loss: 0.914, Global test loss: 0.922, Global test accuracy: 98.45
Round  78, Train loss: 0.914, Test loss: 0.923, Test accuracy: 98.27
Round  78, Global train loss: 0.914, Global test loss: 0.922, Global test accuracy: 98.30
Round  79, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.28
Round  79, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.36
Round  80, Train loss: 0.911, Test loss: 0.923, Test accuracy: 98.31
Round  80, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.45
Round  81, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.31
Round  81, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.42
Round  82, Train loss: 0.911, Test loss: 0.923, Test accuracy: 98.31
Round  82, Global train loss: 0.911, Global test loss: 0.921, Global test accuracy: 98.50
Round  83, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.31
Round  83, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.43
Round  84, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.32
Round  84, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.40
Round  85, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.31
Round  85, Global train loss: 0.913, Global test loss: 0.921, Global test accuracy: 98.50
Round  86, Train loss: 0.910, Test loss: 0.922, Test accuracy: 98.34
Round  86, Global train loss: 0.910, Global test loss: 0.921, Global test accuracy: 98.44
Round  87, Train loss: 0.910, Test loss: 0.922, Test accuracy: 98.32
Round  87, Global train loss: 0.910, Global test loss: 0.922, Global test accuracy: 98.40
Round  88, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.32
Round  88, Global train loss: 0.911, Global test loss: 0.921, Global test accuracy: 98.39
Round  89, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.30
Round  89, Global train loss: 0.912, Global test loss: 0.921, Global test accuracy: 98.40
Round  90, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.31
Round  90, Global train loss: 0.914, Global test loss: 0.921, Global test accuracy: 98.47
Round  91, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.33
Round  91, Global train loss: 0.912, Global test loss: 0.921, Global test accuracy: 98.55
Round  92, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.33
Round  92, Global train loss: 0.911, Global test loss: 0.921, Global test accuracy: 98.51
Round  93, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.34
Round  93, Global train loss: 0.912, Global test loss: 0.921, Global test accuracy: 98.43
Round  94, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.37
Round  94, Global train loss: 0.911, Global test loss: 0.921, Global test accuracy: 98.50
Round  95, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.36
Round  95, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.30/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.35
Round  96, Global train loss: 0.912, Global test loss: 0.922, Global test accuracy: 98.30
Round  97, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.38
Round  97, Global train loss: 0.914, Global test loss: 0.922, Global test accuracy: 98.28
Round  98, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.38
Round  98, Global train loss: 0.914, Global test loss: 0.921, Global test accuracy: 98.27
Round  99, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.36
Round  99, Global train loss: 0.913, Global test loss: 0.922, Global test accuracy: 98.29
Final Round, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.31
Final Round, Global train loss: 0.911, Global test loss: 0.922, Global test accuracy: 98.29
Average accuracy final 10 rounds: 98.35099999999998 

Average global accuracy final 10 rounds: 98.39000000000001 

1297.436675786972
[1.0365257263183594, 2.0730514526367188, 3.0284063816070557, 3.9837613105773926, 4.822943210601807, 5.662125110626221, 6.517020225524902, 7.371915340423584, 8.263169050216675, 9.154422760009766, 10.004636764526367, 10.854850769042969, 11.691958665847778, 12.529066562652588, 13.360764503479004, 14.19246244430542, 15.208602905273438, 16.224743366241455, 17.074186325073242, 17.92362928390503, 18.773953676223755, 19.62427806854248, 20.47203016281128, 21.319782257080078, 22.16296362876892, 23.006145000457764, 23.839259386062622, 24.67237377166748, 25.512073278427124, 26.351772785186768, 27.191078424453735, 28.030384063720703, 28.97152614593506, 29.912668228149414, 30.76753830909729, 31.622408390045166, 32.47926330566406, 33.33611822128296, 34.18401002883911, 35.031901836395264, 35.98994755744934, 36.94799327850342, 37.795275926589966, 38.642558574676514, 39.48319220542908, 40.32382583618164, 41.15886735916138, 41.99390888214111, 42.83531332015991, 43.67671775817871, 44.521589279174805, 45.3664608001709, 46.231547355651855, 47.09663391113281, 47.94793462753296, 48.799235343933105, 49.645678997039795, 50.492122650146484, 51.34082555770874, 52.189528465270996, 53.16126489639282, 54.13300132751465, 54.969191789627075, 55.8053822517395, 56.82040286064148, 57.83542346954346, 58.835039138793945, 59.834654808044434, 60.89466118812561, 61.95466756820679, 62.96136450767517, 63.968061447143555, 65.01590538024902, 66.06374931335449, 67.0834596157074, 68.1031699180603, 68.9588873386383, 69.81460475921631, 70.66096925735474, 71.50733375549316, 72.32395696640015, 73.14058017730713, 73.9691252708435, 74.79767036437988, 75.63649487495422, 76.47531938552856, 77.31550979614258, 78.15570020675659, 78.9909987449646, 79.82629728317261, 80.6597728729248, 81.493248462677, 82.31193423271179, 83.13062000274658, 83.95815825462341, 84.78569650650024, 85.60854387283325, 86.43139123916626, 87.4332549571991, 88.43511867523193, 89.30079436302185, 90.16647005081177, 90.99561667442322, 91.82476329803467, 92.64684891700745, 93.46893453598022, 94.29253673553467, 95.11613893508911, 95.9469997882843, 96.77786064147949, 97.60918498039246, 98.44050931930542, 99.2527756690979, 100.06504201889038, 100.88127279281616, 101.69750356674194, 102.52423191070557, 103.35096025466919, 104.30974435806274, 105.2685284614563, 106.08304381370544, 106.89755916595459, 107.68958592414856, 108.48161268234253, 109.27099466323853, 110.06037664413452, 110.87591648101807, 111.69145631790161, 112.53170013427734, 113.37194395065308, 114.21509146690369, 115.0582389831543, 115.85727834701538, 116.65631771087646, 117.55278491973877, 118.44925212860107, 119.31492185592651, 120.18059158325195, 121.03876328468323, 121.8969349861145, 122.74328398704529, 123.58963298797607, 124.43145084381104, 125.273268699646, 126.12713432312012, 126.98099994659424, 127.84364032745361, 128.706280708313, 129.54719138145447, 130.38810205459595, 131.2757453918457, 132.16338872909546, 133.15578365325928, 134.1481785774231, 134.97861576080322, 135.80905294418335, 136.64779829978943, 137.4865436553955, 138.31298208236694, 139.13942050933838, 139.9733486175537, 140.80727672576904, 141.61524319648743, 142.4232096672058, 143.2544400691986, 144.0856704711914, 144.92277312278748, 145.75987577438354, 146.59934496879578, 147.438814163208, 148.28394412994385, 149.1290740966797, 149.96472358703613, 150.80037307739258, 151.63110375404358, 152.46183443069458, 153.304842710495, 154.1478509902954, 154.99074053764343, 155.83363008499146, 156.67979741096497, 157.52596473693848, 158.3565549850464, 159.1871452331543, 160.01225066184998, 160.83735609054565, 161.67956280708313, 162.5217695236206, 163.3565857410431, 164.19140195846558, 165.022634267807, 165.85386657714844, 166.6781930923462, 167.50251960754395, 168.33462929725647, 169.166738986969, 170.00673365592957, 170.84672832489014, 171.70346212387085, 172.56019592285156, 174.6067144870758, 176.65323305130005]
[59.59, 59.59, 73.03, 73.03, 84.99, 84.99, 89.89, 89.89, 92.63, 92.63, 93.07, 93.07, 95.22, 95.22, 95.74, 95.74, 96.81, 96.81, 96.93, 96.93, 97.04, 97.04, 97.01, 97.01, 97.2, 97.2, 97.22, 97.22, 97.24, 97.24, 97.28, 97.28, 97.41, 97.41, 97.44, 97.44, 97.48, 97.48, 97.46, 97.46, 97.53, 97.53, 97.61, 97.61, 97.66, 97.66, 97.73, 97.73, 97.72, 97.72, 97.78, 97.78, 97.78, 97.78, 97.8, 97.8, 97.84, 97.84, 97.87, 97.87, 97.88, 97.88, 97.88, 97.88, 97.93, 97.93, 97.94, 97.94, 97.96, 97.96, 98.0, 98.0, 97.99, 97.99, 98.01, 98.01, 98.03, 98.03, 98.07, 98.07, 98.04, 98.04, 98.04, 98.04, 98.05, 98.05, 98.01, 98.01, 98.03, 98.03, 98.05, 98.05, 98.07, 98.07, 98.0, 98.0, 98.1, 98.1, 98.09, 98.09, 98.09, 98.09, 98.05, 98.05, 98.06, 98.06, 98.05, 98.05, 98.0, 98.0, 98.07, 98.07, 98.05, 98.05, 98.05, 98.05, 98.1, 98.1, 98.11, 98.11, 98.14, 98.14, 98.15, 98.15, 98.16, 98.16, 98.16, 98.16, 98.18, 98.18, 98.24, 98.24, 98.22, 98.22, 98.24, 98.24, 98.24, 98.24, 98.24, 98.24, 98.25, 98.25, 98.24, 98.24, 98.26, 98.26, 98.26, 98.26, 98.27, 98.27, 98.26, 98.26, 98.25, 98.25, 98.25, 98.25, 98.27, 98.27, 98.28, 98.28, 98.31, 98.31, 98.31, 98.31, 98.31, 98.31, 98.31, 98.31, 98.32, 98.32, 98.31, 98.31, 98.34, 98.34, 98.32, 98.32, 98.32, 98.32, 98.3, 98.3, 98.31, 98.31, 98.33, 98.33, 98.33, 98.33, 98.34, 98.34, 98.37, 98.37, 98.36, 98.36, 98.35, 98.35, 98.38, 98.38, 98.38, 98.38, 98.36, 98.36, 98.31, 98.31]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 1.599, Test loss: 1.497, Test accuracy: 57.47
Round   1, Train loss: 1.417, Test loss: 1.030, Test accuracy: 94.19
Round   2, Train loss: 1.045, Test loss: 0.959, Test accuracy: 96.72
Round   3, Train loss: 0.992, Test loss: 0.945, Test accuracy: 97.13
Round   4, Train loss: 0.961, Test loss: 0.940, Test accuracy: 97.34
Round   5, Train loss: 0.944, Test loss: 0.936, Test accuracy: 97.47
Round   6, Train loss: 0.950, Test loss: 0.934, Test accuracy: 97.64
Round   7, Train loss: 0.957, Test loss: 0.932, Test accuracy: 97.71
Round   8, Train loss: 0.955, Test loss: 0.931, Test accuracy: 97.92
Round   9, Train loss: 0.930, Test loss: 0.930, Test accuracy: 97.77
Round  10, Train loss: 0.932, Test loss: 0.930, Test accuracy: 97.61
Round  11, Train loss: 0.936, Test loss: 0.929, Test accuracy: 97.78
Round  12, Train loss: 0.926, Test loss: 0.929, Test accuracy: 97.71
Round  13, Train loss: 0.931, Test loss: 0.929, Test accuracy: 97.69
Round  14, Train loss: 0.925, Test loss: 0.929, Test accuracy: 97.62
Round  15, Train loss: 0.925, Test loss: 0.927, Test accuracy: 97.83
Round  16, Train loss: 0.922, Test loss: 0.927, Test accuracy: 97.88
Round  17, Train loss: 0.920, Test loss: 0.927, Test accuracy: 97.91
Round  18, Train loss: 0.921, Test loss: 0.927, Test accuracy: 97.86
Round  19, Train loss: 0.922, Test loss: 0.926, Test accuracy: 97.89
Round  20, Train loss: 0.920, Test loss: 0.926, Test accuracy: 98.08
Round  21, Train loss: 0.920, Test loss: 0.925, Test accuracy: 98.19
Round  22, Train loss: 0.919, Test loss: 0.924, Test accuracy: 98.29
Round  23, Train loss: 0.918, Test loss: 0.925, Test accuracy: 98.13
Round  24, Train loss: 0.918, Test loss: 0.925, Test accuracy: 98.12
Round  25, Train loss: 0.919, Test loss: 0.924, Test accuracy: 98.23
Round  26, Train loss: 0.917, Test loss: 0.924, Test accuracy: 98.15
Round  27, Train loss: 0.916, Test loss: 0.924, Test accuracy: 98.27
Round  28, Train loss: 0.915, Test loss: 0.924, Test accuracy: 98.13
Round  29, Train loss: 0.916, Test loss: 0.923, Test accuracy: 98.20
Round  30, Train loss: 0.919, Test loss: 0.923, Test accuracy: 98.25
Round  31, Train loss: 0.917, Test loss: 0.923, Test accuracy: 98.21
Round  32, Train loss: 0.915, Test loss: 0.923, Test accuracy: 98.23
Round  33, Train loss: 0.917, Test loss: 0.924, Test accuracy: 98.22
Round  34, Train loss: 0.916, Test loss: 0.923, Test accuracy: 98.24
Round  35, Train loss: 0.916, Test loss: 0.923, Test accuracy: 98.32
Round  36, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.27
Round  37, Train loss: 0.914, Test loss: 0.923, Test accuracy: 98.39
Round  38, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.31
Round  39, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.31
Round  40, Train loss: 0.912, Test loss: 0.923, Test accuracy: 98.28
Round  41, Train loss: 0.915, Test loss: 0.922, Test accuracy: 98.37
Round  42, Train loss: 0.913, Test loss: 0.923, Test accuracy: 98.24
Round  43, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.32
Round  44, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.28
Round  45, Train loss: 0.915, Test loss: 0.922, Test accuracy: 98.27
Round  46, Train loss: 0.910, Test loss: 0.923, Test accuracy: 98.26
Round  47, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.36
Round  48, Train loss: 0.910, Test loss: 0.922, Test accuracy: 98.34
Round  49, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.35
Round  50, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.30
Round  51, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.20
Round  52, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.30
Round  53, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.42
Round  54, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.33
Round  55, Train loss: 0.913, Test loss: 0.921, Test accuracy: 98.39
Round  56, Train loss: 0.911, Test loss: 0.922, Test accuracy: 98.28
Round  57, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.32
Round  58, Train loss: 0.910, Test loss: 0.921, Test accuracy: 98.35
Round  59, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.27
Round  60, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.31
Round  61, Train loss: 0.913, Test loss: 0.922, Test accuracy: 98.29
Round  62, Train loss: 0.914, Test loss: 0.921, Test accuracy: 98.44
Round  63, Train loss: 0.912, Test loss: 0.922, Test accuracy: 98.34
Round  64, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.37
Round  65, Train loss: 0.914, Test loss: 0.921, Test accuracy: 98.33
Round  66, Train loss: 0.913, Test loss: 0.921, Test accuracy: 98.31
Round  67, Train loss: 0.910, Test loss: 0.921, Test accuracy: 98.35
Round  68, Train loss: 0.913, Test loss: 0.921, Test accuracy: 98.47
Round  69, Train loss: 0.912, Test loss: 0.921, Test accuracy: 98.29
Round  70, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.37
Round  71, Train loss: 0.912, Test loss: 0.921, Test accuracy: 98.34
Round  72, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.38
Round  73, Train loss: 0.913, Test loss: 0.921, Test accuracy: 98.36
Round  74, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.36
Round  75, Train loss: 0.912, Test loss: 0.921, Test accuracy: 98.46
Round  76, Train loss: 0.914, Test loss: 0.920, Test accuracy: 98.49
Round  77, Train loss: 0.912, Test loss: 0.920, Test accuracy: 98.43
Round  78, Train loss: 0.909, Test loss: 0.920, Test accuracy: 98.46
Round  79, Train loss: 0.909, Test loss: 0.920, Test accuracy: 98.42
Round  80, Train loss: 0.910, Test loss: 0.920, Test accuracy: 98.48
Round  81, Train loss: 0.912, Test loss: 0.920, Test accuracy: 98.39
Round  82, Train loss: 0.910, Test loss: 0.920, Test accuracy: 98.47
Round  83, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.44
Round  84, Train loss: 0.912, Test loss: 0.920, Test accuracy: 98.51
Round  85, Train loss: 0.910, Test loss: 0.920, Test accuracy: 98.35
Round  86, Train loss: 0.910, Test loss: 0.920, Test accuracy: 98.41
Round  87, Train loss: 0.909, Test loss: 0.920, Test accuracy: 98.48
Round  88, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.42
Round  89, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.37
Round  90, Train loss: 0.910, Test loss: 0.920, Test accuracy: 98.36
Round  91, Train loss: 0.912, Test loss: 0.920, Test accuracy: 98.46
Round  92, Train loss: 0.910, Test loss: 0.920, Test accuracy: 98.40
Round  93, Train loss: 0.913, Test loss: 0.920, Test accuracy: 98.51
Round  94, Train loss: 0.911, Test loss: 0.921, Test accuracy: 98.47
Round  95, Train loss: 0.909, Test loss: 0.920, Test accuracy: 98.46
Round  96, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.41
Round  97, Train loss: 0.909, Test loss: 0.920, Test accuracy: 98.40
Round  98, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.41
Round  99, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.43
Final Round, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.41
Average accuracy final 10 rounds: 98.431
1754.1338047981262
[2.39831280708313, 4.943719148635864, 7.484109401702881, 9.95415210723877, 12.490755319595337, 15.013341903686523, 17.5022189617157, 20.024333953857422, 22.44334101676941, 24.983805894851685, 27.488341331481934, 30.005528450012207, 32.549946308135986, 35.05881428718567, 37.46329212188721, 39.95589733123779, 42.426663398742676, 44.97186064720154, 47.46201467514038, 49.98391795158386, 52.52010679244995, 55.03892254829407, 57.55239510536194, 60.0361692905426, 62.576157331466675, 65.06144714355469, 67.54773211479187, 70.08258414268494, 72.60921931266785, 75.1243884563446, 77.59685969352722, 80.17834973335266, 82.77879595756531, 85.2970540523529, 87.83258748054504, 90.36880993843079, 92.80681204795837, 95.2880449295044, 97.83697247505188, 100.37511277198792, 102.96163511276245, 105.6325671672821, 108.1514081954956, 110.69394445419312, 113.2206540107727, 115.83235740661621, 118.31750655174255, 120.86593508720398, 123.35966491699219, 125.92068529129028, 128.56892561912537, 131.045077085495, 133.65747332572937, 136.27912998199463, 138.8092484474182, 141.30057454109192, 143.77784299850464, 146.27258205413818, 148.70759510993958, 151.2392749786377, 153.81184101104736, 156.31603264808655, 158.8198733329773, 161.32762837409973, 163.78992533683777, 166.41893362998962, 168.98321437835693, 171.47312688827515, 174.08028388023376, 176.62303829193115, 179.17936658859253, 181.70890593528748, 184.30968523025513, 186.8461880683899, 189.32715010643005, 191.8750946521759, 194.34520077705383, 196.90246558189392, 199.41877269744873, 202.00725626945496, 204.49058556556702, 206.96496272087097, 209.52394032478333, 212.04457139968872, 214.51050281524658, 217.02011227607727, 219.58780360221863, 222.1723005771637, 224.72499775886536, 227.27336049079895, 229.8496515750885, 232.3981671333313, 234.91891980171204, 237.45945930480957, 240.0154745578766, 242.72510170936584, 245.2523112297058, 247.73631024360657, 250.2852909564972, 252.87041664123535, 255.48698568344116]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[57.47, 94.19, 96.72, 97.13, 97.34, 97.47, 97.64, 97.71, 97.92, 97.77, 97.61, 97.78, 97.71, 97.69, 97.62, 97.83, 97.88, 97.91, 97.86, 97.89, 98.08, 98.19, 98.29, 98.13, 98.12, 98.23, 98.15, 98.27, 98.13, 98.2, 98.25, 98.21, 98.23, 98.22, 98.24, 98.32, 98.27, 98.39, 98.31, 98.31, 98.28, 98.37, 98.24, 98.32, 98.28, 98.27, 98.26, 98.36, 98.34, 98.35, 98.3, 98.2, 98.3, 98.42, 98.33, 98.39, 98.28, 98.32, 98.35, 98.27, 98.31, 98.29, 98.44, 98.34, 98.37, 98.33, 98.31, 98.35, 98.47, 98.29, 98.37, 98.34, 98.38, 98.36, 98.36, 98.46, 98.49, 98.43, 98.46, 98.42, 98.48, 98.39, 98.47, 98.44, 98.51, 98.35, 98.41, 98.48, 98.42, 98.37, 98.36, 98.46, 98.4, 98.51, 98.47, 98.46, 98.41, 98.4, 98.41, 98.43, 98.41]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.609, Test loss: 1.609, Test accuracy: 26.67
Round   0, Global train loss: 1.609, Global test loss: 1.609, Global test accuracy: 26.65
Round   1, Train loss: 1.609, Test loss: 1.609, Test accuracy: 27.02
Round   1, Global train loss: 1.609, Global test loss: 1.609, Global test accuracy: 27.08
Round   2, Train loss: 1.609, Test loss: 1.609, Test accuracy: 27.33
Round   2, Global train loss: 1.609, Global test loss: 1.609, Global test accuracy: 27.50
Round   3, Train loss: 1.609, Test loss: 1.609, Test accuracy: 27.52
Round   3, Global train loss: 1.609, Global test loss: 1.609, Global test accuracy: 27.74
Round   4, Train loss: 1.608, Test loss: 1.609, Test accuracy: 27.90
Round   4, Global train loss: 1.608, Global test loss: 1.609, Global test accuracy: 28.17
Round   5, Train loss: 1.608, Test loss: 1.609, Test accuracy: 28.25
Round   5, Global train loss: 1.608, Global test loss: 1.609, Global test accuracy: 28.78
Round   6, Train loss: 1.608, Test loss: 1.609, Test accuracy: 28.57
Round   6, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 29.18
Round   7, Train loss: 1.608, Test loss: 1.608, Test accuracy: 29.00
Round   7, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 29.45
Round   8, Train loss: 1.608, Test loss: 1.608, Test accuracy: 29.20
Round   8, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 29.64
Round   9, Train loss: 1.608, Test loss: 1.608, Test accuracy: 29.32
Round   9, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 29.88
Round  10, Train loss: 1.608, Test loss: 1.608, Test accuracy: 29.63
Round  10, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 30.19
Round  11, Train loss: 1.608, Test loss: 1.608, Test accuracy: 29.97
Round  11, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 30.37
Round  12, Train loss: 1.608, Test loss: 1.608, Test accuracy: 30.20
Round  12, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 30.68
Round  13, Train loss: 1.608, Test loss: 1.608, Test accuracy: 30.56
Round  13, Global train loss: 1.608, Global test loss: 1.608, Global test accuracy: 31.16
Round  14, Train loss: 1.607, Test loss: 1.608, Test accuracy: 30.85
Round  14, Global train loss: 1.607, Global test loss: 1.608, Global test accuracy: 31.66
Round  15, Train loss: 1.607, Test loss: 1.608, Test accuracy: 31.29
Round  15, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 32.01
Round  16, Train loss: 1.607, Test loss: 1.608, Test accuracy: 31.56
Round  16, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 32.33
Round  17, Train loss: 1.607, Test loss: 1.608, Test accuracy: 31.70
Round  17, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 32.45
Round  18, Train loss: 1.607, Test loss: 1.607, Test accuracy: 32.10
Round  18, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 32.64
Round  19, Train loss: 1.607, Test loss: 1.607, Test accuracy: 32.40
Round  19, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 33.05
Round  20, Train loss: 1.607, Test loss: 1.607, Test accuracy: 32.62
Round  20, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 33.31
Round  21, Train loss: 1.607, Test loss: 1.607, Test accuracy: 32.92
Round  21, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 33.55
Round  22, Train loss: 1.607, Test loss: 1.607, Test accuracy: 33.27
Round  22, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 33.82
Round  23, Train loss: 1.607, Test loss: 1.607, Test accuracy: 33.47
Round  23, Global train loss: 1.607, Global test loss: 1.607, Global test accuracy: 33.90
Round  24, Train loss: 1.606, Test loss: 1.607, Test accuracy: 33.73
Round  24, Global train loss: 1.606, Global test loss: 1.607, Global test accuracy: 34.02
Round  25, Train loss: 1.606, Test loss: 1.607, Test accuracy: 33.85
Round  25, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 34.23
Round  26, Train loss: 1.606, Test loss: 1.607, Test accuracy: 34.03
Round  26, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 34.36
Round  27, Train loss: 1.606, Test loss: 1.606, Test accuracy: 34.15
Round  27, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 34.63
Round  28, Train loss: 1.606, Test loss: 1.606, Test accuracy: 34.33
Round  28, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 34.70
Round  29, Train loss: 1.606, Test loss: 1.606, Test accuracy: 34.50
Round  29, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 34.81
Round  30, Train loss: 1.606, Test loss: 1.606, Test accuracy: 34.65
Round  30, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 34.91
Round  31, Train loss: 1.606, Test loss: 1.606, Test accuracy: 34.78
Round  31, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 35.06
Round  32, Train loss: 1.606, Test loss: 1.606, Test accuracy: 34.91
Round  32, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 35.21
Round  33, Train loss: 1.606, Test loss: 1.606, Test accuracy: 35.01
Round  33, Global train loss: 1.606, Global test loss: 1.606, Global test accuracy: 35.28
Round  34, Train loss: 1.605, Test loss: 1.606, Test accuracy: 35.13
Round  34, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 35.42
Round  35, Train loss: 1.605, Test loss: 1.606, Test accuracy: 35.36
Round  35, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 35.57
Round  36, Train loss: 1.605, Test loss: 1.605, Test accuracy: 35.41
Round  36, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 35.67
Round  37, Train loss: 1.605, Test loss: 1.605, Test accuracy: 35.46
Round  37, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 35.89
Round  38, Train loss: 1.605, Test loss: 1.605, Test accuracy: 35.57
Round  38, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 35.93
Round  39, Train loss: 1.605, Test loss: 1.605, Test accuracy: 35.75
Round  39, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 36.07
Round  40, Train loss: 1.605, Test loss: 1.605, Test accuracy: 35.98
Round  40, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 36.34
Round  41, Train loss: 1.605, Test loss: 1.605, Test accuracy: 36.09
Round  41, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 36.54
Round  42, Train loss: 1.605, Test loss: 1.605, Test accuracy: 36.15
Round  42, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 36.65
Round  43, Train loss: 1.605, Test loss: 1.605, Test accuracy: 36.32
Round  43, Global train loss: 1.605, Global test loss: 1.604, Global test accuracy: 36.74
Round  44, Train loss: 1.604, Test loss: 1.605, Test accuracy: 36.61
Round  44, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 36.88
Round  45, Train loss: 1.604, Test loss: 1.605, Test accuracy: 36.70
Round  45, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 36.97
Round  46, Train loss: 1.604, Test loss: 1.604, Test accuracy: 36.81
Round  46, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 37.13
Round  47, Train loss: 1.604, Test loss: 1.604, Test accuracy: 36.96
Round  47, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 37.18
Round  48, Train loss: 1.604, Test loss: 1.604, Test accuracy: 37.11
Round  48, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 37.28
Round  49, Train loss: 1.604, Test loss: 1.604, Test accuracy: 37.16
Round  49, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 37.50
Round  50, Train loss: 1.604, Test loss: 1.604, Test accuracy: 37.32
Round  50, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 37.69
Round  51, Train loss: 1.604, Test loss: 1.604, Test accuracy: 37.60
Round  51, Global train loss: 1.604, Global test loss: 1.604, Global test accuracy: 37.83
Round  52, Train loss: 1.603, Test loss: 1.604, Test accuracy: 37.66
Round  52, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 37.83
Round  53, Train loss: 1.603, Test loss: 1.604, Test accuracy: 37.73
Round  53, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 37.84
Round  54, Train loss: 1.603, Test loss: 1.603, Test accuracy: 37.78
Round  54, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 37.96
Round  55, Train loss: 1.603, Test loss: 1.603, Test accuracy: 37.90
Round  55, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 38.27
Round  56, Train loss: 1.603, Test loss: 1.603, Test accuracy: 38.00
Round  56, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 38.25
Round  57, Train loss: 1.603, Test loss: 1.603, Test accuracy: 38.11
Round  57, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 38.42
Round  58, Train loss: 1.603, Test loss: 1.603, Test accuracy: 38.18
Round  58, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 38.44
Round  59, Train loss: 1.603, Test loss: 1.603, Test accuracy: 38.25
Round  59, Global train loss: 1.603, Global test loss: 1.603, Global test accuracy: 38.62
Round  60, Train loss: 1.602, Test loss: 1.603, Test accuracy: 38.51
Round  60, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 38.79
Round  61, Train loss: 1.602, Test loss: 1.603, Test accuracy: 38.61
Round  61, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 38.91
Round  62, Train loss: 1.602, Test loss: 1.602, Test accuracy: 38.77
Round  62, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 39.02
Round  63, Train loss: 1.602, Test loss: 1.602, Test accuracy: 38.97
Round  63, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 39.26
Round  64, Train loss: 1.602, Test loss: 1.602, Test accuracy: 39.10
Round  64, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 39.29
Round  65, Train loss: 1.602, Test loss: 1.602, Test accuracy: 39.17
Round  65, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 39.39
Round  66, Train loss: 1.602, Test loss: 1.602, Test accuracy: 39.24
Round  66, Global train loss: 1.602, Global test loss: 1.602, Global test accuracy: 39.52
Round  67, Train loss: 1.602, Test loss: 1.602, Test accuracy: 39.32
Round  67, Global train loss: 1.602, Global test loss: 1.601, Global test accuracy: 39.65
Round  68, Train loss: 1.601, Test loss: 1.602, Test accuracy: 39.46
Round  68, Global train loss: 1.601, Global test loss: 1.601, Global test accuracy: 39.71
Round  69, Train loss: 1.602, Test loss: 1.601, Test accuracy: 39.56
Round  69, Global train loss: 1.602, Global test loss: 1.601, Global test accuracy: 39.93
Round  70, Train loss: 1.601, Test loss: 1.601, Test accuracy: 39.81
Round  70, Global train loss: 1.601, Global test loss: 1.601, Global test accuracy: 40.33
Round  71, Train loss: 1.601, Test loss: 1.601, Test accuracy: 40.08
Round  71, Global train loss: 1.601, Global test loss: 1.601, Global test accuracy: 40.57
Round  72, Train loss: 1.601, Test loss: 1.601, Test accuracy: 40.31
Round  72, Global train loss: 1.601, Global test loss: 1.601, Global test accuracy: 40.68
Round  73, Train loss: 1.601, Test loss: 1.601, Test accuracy: 40.48
Round  73, Global train loss: 1.601, Global test loss: 1.601, Global test accuracy: 40.87
Round  74, Train loss: 1.601, Test loss: 1.601, Test accuracy: 40.60
Round  74, Global train loss: 1.601, Global test loss: 1.600, Global test accuracy: 41.00
Round  75, Train loss: 1.601, Test loss: 1.601, Test accuracy: 40.88
Round  75, Global train loss: 1.601, Global test loss: 1.600, Global test accuracy: 41.22
Round  76, Train loss: 1.600, Test loss: 1.600, Test accuracy: 41.10
Round  76, Global train loss: 1.600, Global test loss: 1.600, Global test accuracy: 41.51
Round  77, Train loss: 1.600, Test loss: 1.600, Test accuracy: 41.25
Round  77, Global train loss: 1.600, Global test loss: 1.600, Global test accuracy: 41.67
Round  78, Train loss: 1.600, Test loss: 1.600, Test accuracy: 41.45
Round  78, Global train loss: 1.600, Global test loss: 1.600, Global test accuracy: 42.02
Round  79, Train loss: 1.600, Test loss: 1.600, Test accuracy: 41.59
Round  79, Global train loss: 1.600, Global test loss: 1.600, Global test accuracy: 42.14
Round  80, Train loss: 1.600, Test loss: 1.600, Test accuracy: 41.81
Round  80, Global train loss: 1.600, Global test loss: 1.600, Global test accuracy: 42.52
Round  81, Train loss: 1.600, Test loss: 1.600, Test accuracy: 42.08
Round  81, Global train loss: 1.600, Global test loss: 1.599, Global test accuracy: 42.66
Round  82, Train loss: 1.599, Test loss: 1.600, Test accuracy: 42.27
Round  82, Global train loss: 1.599, Global test loss: 1.599, Global test accuracy: 42.98
Round  83, Train loss: 1.599, Test loss: 1.600, Test accuracy: 42.55
Round  83, Global train loss: 1.599, Global test loss: 1.599, Global test accuracy: 43.44
Round  84, Train loss: 1.599, Test loss: 1.599, Test accuracy: 42.97
Round  84, Global train loss: 1.599, Global test loss: 1.599, Global test accuracy: 43.82
Round  85, Train loss: 1.599, Test loss: 1.599, Test accuracy: 43.35
Round  85, Global train loss: 1.599, Global test loss: 1.599, Global test accuracy: 44.30
Round  86, Train loss: 1.599, Test loss: 1.599, Test accuracy: 43.68
Round  86, Global train loss: 1.599, Global test loss: 1.599, Global test accuracy: 44.56
Round  87, Train loss: 1.599, Test loss: 1.599, Test accuracy: 44.26
Round  87, Global train loss: 1.599, Global test loss: 1.598, Global test accuracy: 44.83
Round  88, Train loss: 1.598, Test loss: 1.599, Test accuracy: 44.52
Round  88, Global train loss: 1.598, Global test loss: 1.598, Global test accuracy: 45.17
Round  89, Train loss: 1.598, Test loss: 1.598, Test accuracy: 44.63
Round  89, Global train loss: 1.598, Global test loss: 1.598, Global test accuracy: 45.28
Round  90, Train loss: 1.598, Test loss: 1.598, Test accuracy: 44.93
Round  90, Global train loss: 1.598, Global test loss: 1.598, Global test accuracy: 45.74
Round  91, Train loss: 1.598, Test loss: 1.598, Test accuracy: 45.14
Round  91, Global train loss: 1.598, Global test loss: 1.598, Global test accuracy: 45.95
Round  92, Train loss: 1.598, Test loss: 1.598, Test accuracy: 45.50
Round  92, Global train loss: 1.598, Global test loss: 1.598, Global test accuracy: 46.05
Round  93, Train loss: 1.598, Test loss: 1.598, Test accuracy: 45.85
Round  93, Global train loss: 1.598, Global test loss: 1.597, Global test accuracy: 46.26
Round  94, Train loss: 1.598, Test loss: 1.598, Test accuracy: 46.02
Round  94, Global train loss: 1.598, Global test loss: 1.597, Global test accuracy: 46.52
Round  95, Train loss: 1.597, Test loss: 1.597, Test accuracy: 46.13
Round  95, Global train loss: 1.597, Global test loss: 1.597, Global test accuracy: 46.69
Round  96, Train loss: 1.597, Test loss: 1.597, Test accuracy: 46.41
Round  96, Global train loss: 1.597, Global test loss: 1.597, Global test accuracy: 46.74
Round  97, Train loss: 1.597, Test loss: 1.597, Test accuracy: 46.59
Round  97, Global train loss: 1.597, Global test loss: 1.597, Global test accuracy: 47.15
Round  98, Train loss: 1.597, Test loss: 1.597, Test accuracy: 46.76
Round  98, Global train loss: 1.597, Global test loss: 1.596, Global test accuracy: 47.46
Round  99, Train loss: 1.596, Test loss: 1.597, Test accuracy: 46.89
Round  99, Global train loss: 1.596, Global test loss: 1.596, Global test accuracy: 47.66
Round 100, Train loss: 1.596, Test loss: 1.597, Test accuracy: 47.36
Round 100, Global train loss: 1.596, Global test loss: 1.596, Global test accuracy: 47.92
Round 101, Train loss: 1.596, Test loss: 1.596, Test accuracy: 47.61
Round 101, Global train loss: 1.596, Global test loss: 1.596, Global test accuracy: 48.38
Round 102, Train loss: 1.596, Test loss: 1.596, Test accuracy: 47.80
Round 102, Global train loss: 1.596, Global test loss: 1.596, Global test accuracy: 48.48
Round 103, Train loss: 1.596, Test loss: 1.596, Test accuracy: 48.04
Round 103, Global train loss: 1.596, Global test loss: 1.595, Global test accuracy: 48.70
Round 104, Train loss: 1.596, Test loss: 1.596, Test accuracy: 48.21
Round 104, Global train loss: 1.596, Global test loss: 1.595, Global test accuracy: 48.80
Round 105, Train loss: 1.595, Test loss: 1.596, Test accuracy: 48.23
Round 105, Global train loss: 1.595, Global test loss: 1.595, Global test accuracy: 48.94
Round 106, Train loss: 1.595, Test loss: 1.596, Test accuracy: 48.37
Round 106, Global train loss: 1.595, Global test loss: 1.595, Global test accuracy: 49.08
Round 107, Train loss: 1.595, Test loss: 1.595, Test accuracy: 48.52
Round 107, Global train loss: 1.595, Global test loss: 1.595, Global test accuracy: 49.30
Round 108, Train loss: 1.595, Test loss: 1.595, Test accuracy: 48.91
Round 108, Global train loss: 1.595, Global test loss: 1.594, Global test accuracy: 49.67
Round 109, Train loss: 1.595, Test loss: 1.595, Test accuracy: 49.03
Round 109, Global train loss: 1.595, Global test loss: 1.594, Global test accuracy: 49.83
Round 110, Train loss: 1.594, Test loss: 1.595, Test accuracy: 49.32
Round 110, Global train loss: 1.594, Global test loss: 1.594, Global test accuracy: 50.00
Round 111, Train loss: 1.594, Test loss: 1.594, Test accuracy: 49.44
Round 111, Global train loss: 1.594, Global test loss: 1.594, Global test accuracy: 50.24
Round 112, Train loss: 1.594, Test loss: 1.594, Test accuracy: 49.69
Round 112, Global train loss: 1.594, Global test loss: 1.594, Global test accuracy: 50.63
Round 113, Train loss: 1.594, Test loss: 1.594, Test accuracy: 50.24
Round 113, Global train loss: 1.594, Global test loss: 1.593, Global test accuracy: 50.86
Round 114, Train loss: 1.593, Test loss: 1.594, Test accuracy: 50.38
Round 114, Global train loss: 1.593, Global test loss: 1.593, Global test accuracy: 51.02
Round 115, Train loss: 1.593, Test loss: 1.593, Test accuracy: 50.57
Round 115, Global train loss: 1.593, Global test loss: 1.593, Global test accuracy: 51.13
Round 116, Train loss: 1.593, Test loss: 1.593, Test accuracy: 50.72
Round 116, Global train loss: 1.593, Global test loss: 1.593, Global test accuracy: 51.31
Round 117, Train loss: 1.593, Test loss: 1.593, Test accuracy: 50.99
Round 117, Global train loss: 1.593, Global test loss: 1.592, Global test accuracy: 51.53
Round 118, Train loss: 1.593, Test loss: 1.593, Test accuracy: 51.03
Round 118, Global train loss: 1.593, Global test loss: 1.592, Global test accuracy: 51.70
Round 119, Train loss: 1.592, Test loss: 1.593, Test accuracy: 51.43
Round 119, Global train loss: 1.592, Global test loss: 1.592, Global test accuracy: 51.88
Round 120, Train loss: 1.592, Test loss: 1.592, Test accuracy: 51.54
Round 120, Global train loss: 1.592, Global test loss: 1.592, Global test accuracy: 52.02
Round 121, Train loss: 1.592, Test loss: 1.592, Test accuracy: 51.76
Round 121, Global train loss: 1.592, Global test loss: 1.592, Global test accuracy: 52.16
Round 122, Train loss: 1.592, Test loss: 1.592, Test accuracy: 52.00
Round 122, Global train loss: 1.592, Global test loss: 1.591, Global test accuracy: 52.26
Round 123, Train loss: 1.591, Test loss: 1.592, Test accuracy: 52.20
Round 123, Global train loss: 1.591, Global test loss: 1.591, Global test accuracy: 52.59
Round 124, Train loss: 1.591, Test loss: 1.591, Test accuracy: 52.47
Round 124, Global train loss: 1.591, Global test loss: 1.591, Global test accuracy: 52.71
Round 125, Train loss: 1.591, Test loss: 1.591, Test accuracy: 52.57
Round 125, Global train loss: 1.591, Global test loss: 1.591, Global test accuracy: 52.89
Round 126, Train loss: 1.591, Test loss: 1.591, Test accuracy: 52.61
Round 126, Global train loss: 1.591, Global test loss: 1.590, Global test accuracy: 52.93
Round 127, Train loss: 1.591, Test loss: 1.591, Test accuracy: 52.61
Round 127, Global train loss: 1.591, Global test loss: 1.590, Global test accuracy: 53.13
Round 128, Train loss: 1.590, Test loss: 1.591, Test accuracy: 52.69
Round 128, Global train loss: 1.590, Global test loss: 1.590, Global test accuracy: 53.16
Round 129, Train loss: 1.590, Test loss: 1.590, Test accuracy: 52.82
Round 129, Global train loss: 1.590, Global test loss: 1.589, Global test accuracy: 53.18
Round 130, Train loss: 1.590, Test loss: 1.590, Test accuracy: 52.99
Round 130, Global train loss: 1.590, Global test loss: 1.589, Global test accuracy: 53.30
Round 131, Train loss: 1.589, Test loss: 1.590, Test accuracy: 53.11
Round 131, Global train loss: 1.589, Global test loss: 1.589, Global test accuracy: 53.43
Round 132, Train loss: 1.589, Test loss: 1.589, Test accuracy: 53.25
Round 132, Global train loss: 1.589, Global test loss: 1.589, Global test accuracy: 53.66
Round 133, Train loss: 1.589, Test loss: 1.589, Test accuracy: 53.50
Round 133, Global train loss: 1.589, Global test loss: 1.588, Global test accuracy: 53.81
Round 134, Train loss: 1.588, Test loss: 1.589, Test accuracy: 53.65
Round 134, Global train loss: 1.588, Global test loss: 1.588, Global test accuracy: 54.04
Round 135, Train loss: 1.589, Test loss: 1.588, Test accuracy: 53.78
Round 135, Global train loss: 1.589, Global test loss: 1.588, Global test accuracy: 54.09
Round 136, Train loss: 1.588, Test loss: 1.588, Test accuracy: 53.84
Round 136, Global train loss: 1.588, Global test loss: 1.588, Global test accuracy: 54.13
Round 137, Train loss: 1.588, Test loss: 1.588, Test accuracy: 54.07
Round 137, Global train loss: 1.588, Global test loss: 1.587, Global test accuracy: 54.39
Round 138, Train loss: 1.587, Test loss: 1.588, Test accuracy: 54.19
Round 138, Global train loss: 1.587, Global test loss: 1.587, Global test accuracy: 54.42
Round 139, Train loss: 1.588, Test loss: 1.587, Test accuracy: 54.30
Round 139, Global train loss: 1.588, Global test loss: 1.587, Global test accuracy: 54.45
Round 140, Train loss: 1.587, Test loss: 1.587, Test accuracy: 54.50
Round 140, Global train loss: 1.587, Global test loss: 1.586, Global test accuracy: 54.62
Round 141, Train loss: 1.587, Test loss: 1.587, Test accuracy: 54.51
Round 141, Global train loss: 1.587, Global test loss: 1.586, Global test accuracy: 54.76
Round 142, Train loss: 1.587, Test loss: 1.586, Test accuracy: 54.62
Round 142, Global train loss: 1.587, Global test loss: 1.586, Global test accuracy: 54.88
Round 143, Train loss: 1.586, Test loss: 1.586, Test accuracy: 54.81
Round 143, Global train loss: 1.586, Global test loss: 1.585, Global test accuracy: 54.99
Round 144, Train loss: 1.586, Test loss: 1.586, Test accuracy: 54.86
Round 144, Global train loss: 1.586, Global test loss: 1.585, Global test accuracy: 55.04
Round 145, Train loss: 1.585, Test loss: 1.585, Test accuracy: 54.96
Round 145, Global train loss: 1.585, Global test loss: 1.585, Global test accuracy: 55.15
Round 146, Train loss: 1.585, Test loss: 1.585, Test accuracy: 55.04
Round 146, Global train loss: 1.585, Global test loss: 1.584, Global test accuracy: 55.27
Round 147, Train loss: 1.585, Test loss: 1.585, Test accuracy: 55.15
Round 147, Global train loss: 1.585, Global test loss: 1.584, Global test accuracy: 55.37
Round 148, Train loss: 1.585, Test loss: 1.585, Test accuracy: 55.23
Round 148, Global train loss: 1.585, Global test loss: 1.584, Global test accuracy: 55.45
Round 149, Train loss: 1.584, Test loss: 1.584, Test accuracy: 55.32
Round 149, Global train loss: 1.584, Global test loss: 1.583, Global test accuracy: 55.58
Round 150, Train loss: 1.584, Test loss: 1.584, Test accuracy: 55.49
Round 150, Global train loss: 1.584, Global test loss: 1.583, Global test accuracy: 55.65
Round 151, Train loss: 1.584, Test loss: 1.584, Test accuracy: 55.51
Round 151, Global train loss: 1.584, Global test loss: 1.583, Global test accuracy: 55.68
Round 152, Train loss: 1.583, Test loss: 1.583, Test accuracy: 55.60
Round 152, Global train loss: 1.583, Global test loss: 1.582, Global test accuracy: 55.78
Round 153, Train loss: 1.583, Test loss: 1.583, Test accuracy: 55.70
Round 153, Global train loss: 1.583, Global test loss: 1.582, Global test accuracy: 55.87
Round 154, Train loss: 1.582, Test loss: 1.582, Test accuracy: 55.73
Round 154, Global train loss: 1.582, Global test loss: 1.582, Global test accuracy: 55.97
Round 155, Train loss: 1.582, Test loss: 1.582, Test accuracy: 55.86
Round 155, Global train loss: 1.582, Global test loss: 1.581, Global test accuracy: 56.08
Round 156, Train loss: 1.582, Test loss: 1.582, Test accuracy: 55.92
Round 156, Global train loss: 1.582, Global test loss: 1.581, Global test accuracy: 56.26
Round 157, Train loss: 1.582, Test loss: 1.581, Test accuracy: 56.06
Round 157, Global train loss: 1.582, Global test loss: 1.580, Global test accuracy: 56.37
Round 158, Train loss: 1.581, Test loss: 1.581, Test accuracy: 56.15
Round 158, Global train loss: 1.581, Global test loss: 1.580, Global test accuracy: 56.48
Round 159, Train loss: 1.581, Test loss: 1.581, Test accuracy: 56.28
Round 159, Global train loss: 1.581, Global test loss: 1.580, Global test accuracy: 56.56
Round 160, Train loss: 1.580, Test loss: 1.580, Test accuracy: 56.36
Round 160, Global train loss: 1.580, Global test loss: 1.579, Global test accuracy: 56.67
Round 161, Train loss: 1.580, Test loss: 1.580, Test accuracy: 56.45
Round 161, Global train loss: 1.580, Global test loss: 1.579, Global test accuracy: 56.73
Round 162, Train loss: 1.579, Test loss: 1.579, Test accuracy: 56.54
Round 162, Global train loss: 1.579, Global test loss: 1.578, Global test accuracy: 56.73
Round 163, Train loss: 1.578, Test loss: 1.579, Test accuracy: 56.60
Round 163, Global train loss: 1.578, Global test loss: 1.578, Global test accuracy: 56.86
Round 164, Train loss: 1.578, Test loss: 1.579, Test accuracy: 56.63
Round 164, Global train loss: 1.578, Global test loss: 1.578, Global test accuracy: 56.84
Round 165, Train loss: 1.578, Test loss: 1.578, Test accuracy: 56.79
Round 165, Global train loss: 1.578, Global test loss: 1.577, Global test accuracy: 57.02
Round 166, Train loss: 1.578, Test loss: 1.577, Test accuracy: 56.83
Round 166, Global train loss: 1.578, Global test loss: 1.577, Global test accuracy: 56.97
Round 167, Train loss: 1.577, Test loss: 1.577, Test accuracy: 56.86
Round 167, Global train loss: 1.577, Global test loss: 1.576, Global test accuracy: 57.05
Round 168, Train loss: 1.577, Test loss: 1.577, Test accuracy: 56.90
Round 168, Global train loss: 1.577, Global test loss: 1.576, Global test accuracy: 57.03
Round 169, Train loss: 1.576, Test loss: 1.576, Test accuracy: 56.94
Round 169, Global train loss: 1.576, Global test loss: 1.575, Global test accuracy: 57.10
Round 170, Train loss: 1.576, Test loss: 1.576, Test accuracy: 56.97
Round 170, Global train loss: 1.576, Global test loss: 1.575, Global test accuracy: 57.11
Round 171, Train loss: 1.576, Test loss: 1.576, Test accuracy: 57.10
Round 171, Global train loss: 1.576, Global test loss: 1.574, Global test accuracy: 57.23
Round 172, Train loss: 1.575, Test loss: 1.575, Test accuracy: 57.11
Round 172, Global train loss: 1.575, Global test loss: 1.574, Global test accuracy: 57.20
Round 173, Train loss: 1.574, Test loss: 1.574, Test accuracy: 57.18
Round 173, Global train loss: 1.574, Global test loss: 1.573, Global test accuracy: 57.24
Round 174, Train loss: 1.574, Test loss: 1.574, Test accuracy: 57.21
Round 174, Global train loss: 1.574, Global test loss: 1.573, Global test accuracy: 57.28
Round 175, Train loss: 1.573, Test loss: 1.574, Test accuracy: 57.24
Round 175, Global train loss: 1.573, Global test loss: 1.572, Global test accuracy: 57.32
Round 176, Train loss: 1.573, Test loss: 1.573, Test accuracy: 57.35
Round 176, Global train loss: 1.573, Global test loss: 1.572, Global test accuracy: 57.42
Round 177, Train loss: 1.572, Test loss: 1.572, Test accuracy: 57.43
Round 177, Global train loss: 1.572, Global test loss: 1.571, Global test accuracy: 57.57
Round 178, Train loss: 1.572, Test loss: 1.572, Test accuracy: 57.54
Round 178, Global train loss: 1.572, Global test loss: 1.571, Global test accuracy: 57.64
Round 179, Train loss: 1.571, Test loss: 1.571, Test accuracy: 57.55
Round 179, Global train loss: 1.571, Global test loss: 1.570, Global test accuracy: 57.66
Round 180, Train loss: 1.571, Test loss: 1.571, Test accuracy: 57.63
Round 180, Global train loss: 1.571, Global test loss: 1.570, Global test accuracy: 57.72
Round 181, Train loss: 1.570, Test loss: 1.570, Test accuracy: 57.64
Round 181, Global train loss: 1.570, Global test loss: 1.569, Global test accuracy: 57.77
Round 182, Train loss: 1.570, Test loss: 1.570, Test accuracy: 57.75
Round 182, Global train loss: 1.570, Global test loss: 1.568, Global test accuracy: 57.79
Round 183, Train loss: 1.569, Test loss: 1.569, Test accuracy: 57.76
Round 183, Global train loss: 1.569, Global test loss: 1.568, Global test accuracy: 57.82
Round 184, Train loss: 1.568, Test loss: 1.569, Test accuracy: 57.78
Round 184, Global train loss: 1.568, Global test loss: 1.567, Global test accuracy: 57.87
Round 185, Train loss: 1.568, Test loss: 1.568, Test accuracy: 57.85
Round 185, Global train loss: 1.568, Global test loss: 1.566, Global test accuracy: 58.06
Round 186, Train loss: 1.567, Test loss: 1.567, Test accuracy: 57.83
Round 186, Global train loss: 1.567, Global test loss: 1.566, Global test accuracy: 57.99
Round 187, Train loss: 1.567, Test loss: 1.567, Test accuracy: 57.95
Round 187, Global train loss: 1.567, Global test loss: 1.565, Global test accuracy: 58.10
Round 188, Train loss: 1.566, Test loss: 1.566, Test accuracy: 58.04
Round 188, Global train loss: 1.566, Global test loss: 1.565, Global test accuracy: 58.17
Round 189, Train loss: 1.566, Test loss: 1.565, Test accuracy: 58.18
Round 189, Global train loss: 1.566, Global test loss: 1.564, Global test accuracy: 58.39
Round 190, Train loss: 1.565, Test loss: 1.565, Test accuracy: 58.24
Round 190, Global train loss: 1.565, Global test loss: 1.563, Global test accuracy: 58.47
Round 191, Train loss: 1.564, Test loss: 1.564, Test accuracy: 58.32
Round 191, Global train loss: 1.564, Global test loss: 1.563, Global test accuracy: 58.52
Round 192, Train loss: 1.564, Test loss: 1.563, Test accuracy: 58.37
Round 192, Global train loss: 1.564, Global test loss: 1.562, Global test accuracy: 58.58
Round 193, Train loss: 1.562, Test loss: 1.563, Test accuracy: 58.48
Round 193, Global train loss: 1.562, Global test loss: 1.561, Global test accuracy: 58.61
Round 194, Train loss: 1.562, Test loss: 1.562, Test accuracy: 58.57
Round 194, Global train loss: 1.562, Global test loss: 1.560, Global test accuracy: 58.68
Round 195, Train loss: 1.561, Test loss: 1.561, Test accuracy: 58.59
Round 195, Global train loss: 1.561, Global test loss: 1.560, Global test accuracy: 58.67
Round 196, Train loss: 1.561, Test loss: 1.561, Test accuracy: 58.71
Round 196, Global train loss: 1.561, Global test loss: 1.559, Global test accuracy: 58.87
Round 197, Train loss: 1.561, Test loss: 1.560, Test accuracy: 58.70
Round 197, Global train loss: 1.561, Global test loss: 1.558, Global test accuracy: 58.68
Round 198, Train loss: 1.560, Test loss: 1.559, Test accuracy: 58.76
Round 198, Global train loss: 1.560, Global test loss: 1.557, Global test accuracy: 58.70
Round 199, Train loss: 1.558, Test loss: 1.559, Test accuracy: 58.82
Round 199, Global train loss: 1.558, Global test loss: 1.557, Global test accuracy: 59.15
Round 200, Train loss: 1.558, Test loss: 1.558, Test accuracy: 58.91
Round 200, Global train loss: 1.558, Global test loss: 1.556, Global test accuracy: 59.34
Round 201, Train loss: 1.558, Test loss: 1.557, Test accuracy: 59.11
Round 201, Global train loss: 1.558, Global test loss: 1.555, Global test accuracy: 59.62
Round 202, Train loss: 1.556, Test loss: 1.556, Test accuracy: 59.27
Round 202, Global train loss: 1.556, Global test loss: 1.554, Global test accuracy: 59.64
Round 203, Train loss: 1.554, Test loss: 1.555, Test accuracy: 59.34
Round 203, Global train loss: 1.554, Global test loss: 1.553, Global test accuracy: 59.67
Round 204, Train loss: 1.554, Test loss: 1.554, Test accuracy: 59.42
Round 204, Global train loss: 1.554, Global test loss: 1.552, Global test accuracy: 59.81
Round 205, Train loss: 1.551, Test loss: 1.554, Test accuracy: 59.45
Round 205, Global train loss: 1.551, Global test loss: 1.551, Global test accuracy: 59.80
Round 206, Train loss: 1.553, Test loss: 1.552, Test accuracy: 59.67
Round 206, Global train loss: 1.553, Global test loss: 1.550, Global test accuracy: 59.72
Round 207, Train loss: 1.551, Test loss: 1.551, Test accuracy: 59.78
Round 207, Global train loss: 1.551, Global test loss: 1.549, Global test accuracy: 59.98
Round 208, Train loss: 1.551, Test loss: 1.550, Test accuracy: 59.87
Round 208, Global train loss: 1.551, Global test loss: 1.548, Global test accuracy: 60.06
Round 209, Train loss: 1.549, Test loss: 1.549, Test accuracy: 60.00
Round 209, Global train loss: 1.549, Global test loss: 1.547, Global test accuracy: 60.10
Round 210, Train loss: 1.549, Test loss: 1.549, Test accuracy: 60.03
Round 210, Global train loss: 1.549, Global test loss: 1.546, Global test accuracy: 60.17
Round 211, Train loss: 1.548, Test loss: 1.548, Test accuracy: 60.17
Round 211, Global train loss: 1.548, Global test loss: 1.545, Global test accuracy: 60.24
Round 212, Train loss: 1.546, Test loss: 1.546, Test accuracy: 60.21
Round 212, Global train loss: 1.546, Global test loss: 1.544, Global test accuracy: 60.13
Round 213, Train loss: 1.545, Test loss: 1.545, Test accuracy: 60.21
Round 213, Global train loss: 1.545, Global test loss: 1.543, Global test accuracy: 60.34
Round 214, Train loss: 1.544, Test loss: 1.545, Test accuracy: 60.26
Round 214, Global train loss: 1.544, Global test loss: 1.542, Global test accuracy: 60.35
Round 215, Train loss: 1.542, Test loss: 1.544, Test accuracy: 60.30
Round 215, Global train loss: 1.542, Global test loss: 1.541, Global test accuracy: 60.45
Round 216, Train loss: 1.542, Test loss: 1.542, Test accuracy: 60.35
Round 216, Global train loss: 1.542, Global test loss: 1.540, Global test accuracy: 60.56
Round 217, Train loss: 1.541, Test loss: 1.541, Test accuracy: 60.43
Round 217, Global train loss: 1.541, Global test loss: 1.539, Global test accuracy: 60.94
Round 218, Train loss: 1.539, Test loss: 1.540, Test accuracy: 60.70
Round 218, Global train loss: 1.539, Global test loss: 1.537, Global test accuracy: 61.00
Round 219, Train loss: 1.538, Test loss: 1.539, Test accuracy: 60.83
Round 219, Global train loss: 1.538, Global test loss: 1.536, Global test accuracy: 61.09
Round 220, Train loss: 1.538, Test loss: 1.538, Test accuracy: 60.82
Round 220, Global train loss: 1.538, Global test loss: 1.535, Global test accuracy: 61.16
Round 221, Train loss: 1.537, Test loss: 1.537, Test accuracy: 60.81
Round 221, Global train loss: 1.537, Global test loss: 1.534, Global test accuracy: 61.09
Round 222, Train loss: 1.534, Test loss: 1.536, Test accuracy: 60.87
Round 222, Global train loss: 1.534, Global test loss: 1.532, Global test accuracy: 61.22
Round 223, Train loss: 1.533, Test loss: 1.534, Test accuracy: 61.01
Round 223, Global train loss: 1.533, Global test loss: 1.531, Global test accuracy: 61.13
Round 224, Train loss: 1.532, Test loss: 1.533, Test accuracy: 61.02
Round 224, Global train loss: 1.532, Global test loss: 1.529, Global test accuracy: 61.27
Round 225, Train loss: 1.529, Test loss: 1.533, Test accuracy: 61.04
Round 225, Global train loss: 1.529, Global test loss: 1.528, Global test accuracy: 61.26
Round 226, Train loss: 1.528, Test loss: 1.532, Test accuracy: 61.12
Round 226, Global train loss: 1.528, Global test loss: 1.526, Global test accuracy: 61.33
Round 227, Train loss: 1.529, Test loss: 1.529, Test accuracy: 61.15
Round 227, Global train loss: 1.529, Global test loss: 1.525, Global test accuracy: 61.59
Round 228, Train loss: 1.525, Test loss: 1.527, Test accuracy: 61.36
Round 228, Global train loss: 1.525, Global test loss: 1.523, Global test accuracy: 61.55
Round 229, Train loss: 1.524, Test loss: 1.525, Test accuracy: 61.34
Round 229, Global train loss: 1.524, Global test loss: 1.522, Global test accuracy: 61.47
Round 230, Train loss: 1.524, Test loss: 1.524, Test accuracy: 61.39
Round 230, Global train loss: 1.524, Global test loss: 1.520, Global test accuracy: 61.63
Round 231, Train loss: 1.523, Test loss: 1.522, Test accuracy: 61.44
Round 231, Global train loss: 1.523, Global test loss: 1.518, Global test accuracy: 61.46
Round 232, Train loss: 1.519, Test loss: 1.520, Test accuracy: 61.44
Round 232, Global train loss: 1.519, Global test loss: 1.516, Global test accuracy: 61.52
Round 233, Train loss: 1.520, Test loss: 1.518, Test accuracy: 61.51
Round 233, Global train loss: 1.520, Global test loss: 1.515, Global test accuracy: 61.56
Round 234, Train loss: 1.519, Test loss: 1.517, Test accuracy: 61.54
Round 234, Global train loss: 1.519, Global test loss: 1.513, Global test accuracy: 61.49
Round 235, Train loss: 1.513, Test loss: 1.516, Test accuracy: 61.53
Round 235, Global train loss: 1.513, Global test loss: 1.511, Global test accuracy: 61.50
Round 236, Train loss: 1.512, Test loss: 1.515, Test accuracy: 61.64
Round 236, Global train loss: 1.512, Global test loss: 1.509, Global test accuracy: 61.65
Round 237, Train loss: 1.512, Test loss: 1.513, Test accuracy: 61.56
Round 237, Global train loss: 1.512, Global test loss: 1.507, Global test accuracy: 61.76
Round 238, Train loss: 1.510, Test loss: 1.511, Test accuracy: 61.57
Round 238, Global train loss: 1.510, Global test loss: 1.505, Global test accuracy: 61.82
Round 239, Train loss: 1.507, Test loss: 1.509, Test accuracy: 61.67
Round 239, Global train loss: 1.507, Global test loss: 1.503, Global test accuracy: 61.94
Round 240, Train loss: 1.504, Test loss: 1.507, Test accuracy: 61.71
Round 240, Global train loss: 1.504, Global test loss: 1.501, Global test accuracy: 62.05
Round 241, Train loss: 1.502, Test loss: 1.505, Test accuracy: 61.73
Round 241, Global train loss: 1.502, Global test loss: 1.499, Global test accuracy: 61.86
Round 242, Train loss: 1.502, Test loss: 1.504, Test accuracy: 61.76
Round 242, Global train loss: 1.502, Global test loss: 1.497, Global test accuracy: 61.80
Round 243, Train loss: 1.499, Test loss: 1.502, Test accuracy: 61.77
Round 243, Global train loss: 1.499, Global test loss: 1.495, Global test accuracy: 62.08
Round 244, Train loss: 1.497, Test loss: 1.500, Test accuracy: 61.83
Round 244, Global train loss: 1.497, Global test loss: 1.492, Global test accuracy: 62.31
Round 245, Train loss: 1.492, Test loss: 1.496, Test accuracy: 61.94
Round 245, Global train loss: 1.492, Global test loss: 1.490, Global test accuracy: 62.16
Round 246, Train loss: 1.493, Test loss: 1.493, Test accuracy: 62.02
Round 246, Global train loss: 1.493, Global test loss: 1.488, Global test accuracy: 62.26
Round 247, Train loss: 1.487, Test loss: 1.491, Test accuracy: 62.14
Round 247, Global train loss: 1.487, Global test loss: 1.485, Global test accuracy: 62.15
Round 248, Train loss: 1.488, Test loss: 1.489, Test accuracy: 62.31
Round 248, Global train loss: 1.488, Global test loss: 1.483, Global test accuracy: 62.42
Round 249, Train loss: 1.486, Test loss: 1.485, Test accuracy: 62.42
Round 249, Global train loss: 1.486, Global test loss: 1.480, Global test accuracy: 62.49
Round 250, Train loss: 1.481, Test loss: 1.483, Test accuracy: 62.49
Round 250, Global train loss: 1.481, Global test loss: 1.477, Global test accuracy: 62.50
Round 251, Train loss: 1.479, Test loss: 1.480, Test accuracy: 62.47
Round 251, Global train loss: 1.479, Global test loss: 1.475, Global test accuracy: 62.46
Round 252, Train loss: 1.477, Test loss: 1.478, Test accuracy: 62.44
Round 252, Global train loss: 1.477, Global test loss: 1.472, Global test accuracy: 62.42
Round 253, Train loss: 1.475, Test loss: 1.474, Test accuracy: 62.57
Round 253, Global train loss: 1.475, Global test loss: 1.470, Global test accuracy: 62.41
Round 254, Train loss: 1.472, Test loss: 1.472, Test accuracy: 62.53
Round 254, Global train loss: 1.472, Global test loss: 1.467, Global test accuracy: 62.52
Round 255, Train loss: 1.469, Test loss: 1.469, Test accuracy: 62.58
Round 255, Global train loss: 1.469, Global test loss: 1.464, Global test accuracy: 62.58
Round 256, Train loss: 1.467, Test loss: 1.468, Test accuracy: 62.66
Round 256, Global train loss: 1.467, Global test loss: 1.461, Global test accuracy: 62.75
Round 257, Train loss: 1.465, Test loss: 1.465, Test accuracy: 62.57
Round 257, Global train loss: 1.465, Global test loss: 1.458, Global test accuracy: 62.79
Round 258, Train loss: 1.464, Test loss: 1.461, Test accuracy: 62.62
Round 258, Global train loss: 1.464, Global test loss: 1.456, Global test accuracy: 62.87
Round 259, Train loss: 1.459, Test loss: 1.458, Test accuracy: 62.67
Round 259, Global train loss: 1.459, Global test loss: 1.453, Global test accuracy: 63.02
Round 260, Train loss: 1.457, Test loss: 1.456, Test accuracy: 62.72
Round 260, Global train loss: 1.457, Global test loss: 1.450, Global test accuracy: 63.06
Round 261, Train loss: 1.458, Test loss: 1.454, Test accuracy: 62.96
Round 261, Global train loss: 1.458, Global test loss: 1.447, Global test accuracy: 63.45
Round 262, Train loss: 1.450, Test loss: 1.451, Test accuracy: 63.05
Round 262, Global train loss: 1.450, Global test loss: 1.444, Global test accuracy: 63.43
Round 263, Train loss: 1.447, Test loss: 1.447, Test accuracy: 63.38
Round 263, Global train loss: 1.447, Global test loss: 1.441, Global test accuracy: 63.56
Round 264, Train loss: 1.444, Test loss: 1.444, Test accuracy: 63.47
Round 264, Global train loss: 1.444, Global test loss: 1.438, Global test accuracy: 63.66
Round 265, Train loss: 1.443, Test loss: 1.442, Test accuracy: 63.51
Round 265, Global train loss: 1.443, Global test loss: 1.435, Global test accuracy: 63.70
Round 266, Train loss: 1.438, Test loss: 1.439, Test accuracy: 63.64
Round 266, Global train loss: 1.438, Global test loss: 1.432, Global test accuracy: 63.72
Round 267, Train loss: 1.436, Test loss: 1.436, Test accuracy: 63.66
Round 267, Global train loss: 1.436, Global test loss: 1.428, Global test accuracy: 63.96
Round 268, Train loss: 1.432, Test loss: 1.433, Test accuracy: 63.67
Round 268, Global train loss: 1.432, Global test loss: 1.425, Global test accuracy: 63.87
Round 269, Train loss: 1.428, Test loss: 1.429, Test accuracy: 63.78
Round 269, Global train loss: 1.428, Global test loss: 1.422, Global test accuracy: 63.98
Round 270, Train loss: 1.423, Test loss: 1.425, Test accuracy: 63.92
Round 270, Global train loss: 1.423, Global test loss: 1.419, Global test accuracy: 64.19
Round 271, Train loss: 1.422, Test loss: 1.423, Test accuracy: 63.93
Round 271, Global train loss: 1.422, Global test loss: 1.416, Global test accuracy: 64.19
Round 272, Train loss: 1.419, Test loss: 1.420, Test accuracy: 64.07
Round 272, Global train loss: 1.419, Global test loss: 1.413, Global test accuracy: 64.51
Round 273, Train loss: 1.414, Test loss: 1.416, Test accuracy: 64.19
Round 273, Global train loss: 1.414, Global test loss: 1.409, Global test accuracy: 64.34
Round 274, Train loss: 1.411, Test loss: 1.414, Test accuracy: 64.25
Round 274, Global train loss: 1.411, Global test loss: 1.406, Global test accuracy: 64.76
Round 275, Train loss: 1.411, Test loss: 1.412, Test accuracy: 64.40
Round 275, Global train loss: 1.411, Global test loss: 1.403, Global test accuracy: 64.99
Round 276, Train loss: 1.403, Test loss: 1.409, Test accuracy: 64.61
Round 276, Global train loss: 1.403, Global test loss: 1.399, Global test accuracy: 65.07
Round 277, Train loss: 1.400, Test loss: 1.407, Test accuracy: 64.76
Round 277, Global train loss: 1.400, Global test loss: 1.396, Global test accuracy: 65.27
Round 278, Train loss: 1.402, Test loss: 1.404, Test accuracy: 64.94
Round 278, Global train loss: 1.402, Global test loss: 1.393, Global test accuracy: 65.67
Round 279, Train loss: 1.397, Test loss: 1.399, Test accuracy: 65.20
Round 279, Global train loss: 1.397, Global test loss: 1.390, Global test accuracy: 65.57
Round 280, Train loss: 1.396, Test loss: 1.395, Test accuracy: 65.48
Round 280, Global train loss: 1.396, Global test loss: 1.387, Global test accuracy: 65.76
Round 281, Train loss: 1.391, Test loss: 1.392, Test accuracy: 65.68
Round 281, Global train loss: 1.391, Global test loss: 1.383, Global test accuracy: 65.78
Round 282, Train loss: 1.386, Test loss: 1.389, Test accuracy: 65.67
Round 282, Global train loss: 1.386, Global test loss: 1.380, Global test accuracy: 66.04
Round 283, Train loss: 1.385, Test loss: 1.386, Test accuracy: 65.89
Round 283, Global train loss: 1.385, Global test loss: 1.377, Global test accuracy: 66.40
Round 284, Train loss: 1.381, Test loss: 1.384, Test accuracy: 66.10
Round 284, Global train loss: 1.381, Global test loss: 1.374, Global test accuracy: 66.83
Round 285, Train loss: 1.378, Test loss: 1.380, Test accuracy: 66.39
Round 285, Global train loss: 1.378, Global test loss: 1.370, Global test accuracy: 66.98
Round 286, Train loss: 1.370, Test loss: 1.376, Test accuracy: 66.71
Round 286, Global train loss: 1.370, Global test loss: 1.367, Global test accuracy: 67.32
Round 287, Train loss: 1.372, Test loss: 1.373, Test accuracy: 67.05
Round 287, Global train loss: 1.372, Global test loss: 1.364, Global test accuracy: 67.44
Round 288, Train loss: 1.372, Test loss: 1.370, Test accuracy: 67.20
Round 288, Global train loss: 1.372, Global test loss: 1.361, Global test accuracy: 67.81
Round 289, Train loss: 1.367, Test loss: 1.367, Test accuracy: 67.50
Round 289, Global train loss: 1.367, Global test loss: 1.358, Global test accuracy: 67.93
Round 290, Train loss: 1.362, Test loss: 1.364, Test accuracy: 67.77
Round 290, Global train loss: 1.362, Global test loss: 1.355, Global test accuracy: 68.28
Round 291, Train loss: 1.362, Test loss: 1.361, Test accuracy: 67.93
Round 291, Global train loss: 1.362, Global test loss: 1.352, Global test accuracy: 68.68
Round 292, Train loss: 1.352, Test loss: 1.355, Test accuracy: 68.49
Round 292, Global train loss: 1.352, Global test loss: 1.349, Global test accuracy: 69.10
Round 293, Train loss: 1.356, Test loss: 1.353, Test accuracy: 68.58
Round 293, Global train loss: 1.356, Global test loss: 1.346, Global test accuracy: 69.21
Round 294, Train loss: 1.357, Test loss: 1.352, Test accuracy: 68.76
Round 294, Global train loss: 1.357, Global test loss: 1.343, Global test accuracy: 69.44
Round 295, Train loss: 1.347, Test loss: 1.347, Test accuracy: 69.14
Round 295, Global train loss: 1.347, Global test loss: 1.340, Global test accuracy: 69.76
Round 296, Train loss: 1.340, Test loss: 1.344, Test accuracy: 69.39
Round 296, Global train loss: 1.340, Global test loss: 1.337, Global test accuracy: 70.03
Round 297, Train loss: 1.344, Test loss: 1.341, Test accuracy: 69.62
Round 297, Global train loss: 1.344, Global test loss: 1.334, Global test accuracy: 70.27
Round 298, Train loss: 1.338, Test loss: 1.339, Test accuracy: 69.89
Round 298, Global train loss: 1.338, Global test loss: 1.332, Global test accuracy: 70.46
Round 299, Train loss: 1.334, Test loss: 1.337, Test accuracy: 70.10
Round 299, Global train loss: 1.334, Global test loss: 1.329, Global test accuracy: 70.74
Round 300, Train loss: 1.335, Test loss: 1.335, Test accuracy: 70.30
Round 300, Global train loss: 1.335, Global test loss: 1.326, Global test accuracy: 70.99
Round 301, Train loss: 1.328, Test loss: 1.330, Test accuracy: 70.73
Round 301, Global train loss: 1.328, Global test loss: 1.323, Global test accuracy: 71.48
Round 302, Train loss: 1.333, Test loss: 1.328, Test accuracy: 71.08
Round 302, Global train loss: 1.333, Global test loss: 1.321, Global test accuracy: 71.79
Round 303, Train loss: 1.328, Test loss: 1.326, Test accuracy: 71.19
Round 303, Global train loss: 1.328, Global test loss: 1.318, Global test accuracy: 72.00
Round 304, Train loss: 1.325, Test loss: 1.324, Test accuracy: 71.45
Round 304, Global train loss: 1.325, Global test loss: 1.316, Global test accuracy: 72.49
Round 305, Train loss: 1.318, Test loss: 1.321, Test accuracy: 71.70
Round 305, Global train loss: 1.318, Global test loss: 1.313, Global test accuracy: 72.62
Round 306, Train loss: 1.320, Test loss: 1.319, Test accuracy: 71.88
Round 306, Global train loss: 1.320, Global test loss: 1.311, Global test accuracy: 72.78
Round 307, Train loss: 1.320, Test loss: 1.314, Test accuracy: 72.34
Round 307, Global train loss: 1.320, Global test loss: 1.308, Global test accuracy: 72.91
Round 308, Train loss: 1.315, Test loss: 1.311, Test accuracy: 72.59
Round 308, Global train loss: 1.315, Global test loss: 1.306, Global test accuracy: 73.24
Round 309, Train loss: 1.309, Test loss: 1.308, Test accuracy: 72.95
Round 309, Global train loss: 1.309, Global test loss: 1.303, Global test accuracy: 73.49
Round 310, Train loss: 1.309, Test loss: 1.306, Test accuracy: 73.29
Round 310, Global train loss: 1.309, Global test loss: 1.301, Global test accuracy: 73.84
Round 311, Train loss: 1.309, Test loss: 1.304, Test accuracy: 73.40
Round 311, Global train loss: 1.309, Global test loss: 1.299, Global test accuracy: 74.03
Round 312, Train loss: 1.305, Test loss: 1.302, Test accuracy: 73.58
Round 312, Global train loss: 1.305, Global test loss: 1.297, Global test accuracy: 74.14
Round 313, Train loss: 1.300, Test loss: 1.300, Test accuracy: 73.73
Round 313, Global train loss: 1.300, Global test loss: 1.294, Global test accuracy: 74.28
Round 314, Train loss: 1.300, Test loss: 1.298, Test accuracy: 73.88
Round 314, Global train loss: 1.300, Global test loss: 1.292, Global test accuracy: 74.40
Round 315, Train loss: 1.297, Test loss: 1.294, Test accuracy: 74.11
Round 315, Global train loss: 1.297, Global test loss: 1.290, Global test accuracy: 74.47
Round 316, Train loss: 1.293, Test loss: 1.293, Test accuracy: 74.21
Round 316, Global train loss: 1.293, Global test loss: 1.288, Global test accuracy: 74.55
Round 317, Train loss: 1.297, Test loss: 1.290, Test accuracy: 74.43
Round 317, Global train loss: 1.297, Global test loss: 1.285, Global test accuracy: 74.74
Round 318, Train loss: 1.292, Test loss: 1.288, Test accuracy: 74.54
Round 318, Global train loss: 1.292, Global test loss: 1.283, Global test accuracy: 75.03
Round 319, Train loss: 1.291, Test loss: 1.285, Test accuracy: 74.78
Round 319, Global train loss: 1.291, Global test loss: 1.281, Global test accuracy: 75.23
Round 320, Train loss: 1.287, Test loss: 1.284, Test accuracy: 74.94
Round 320, Global train loss: 1.287, Global test loss: 1.279, Global test accuracy: 75.60
Round 321, Train loss: 1.286, Test loss: 1.282, Test accuracy: 75.15
Round 321, Global train loss: 1.286, Global test loss: 1.277, Global test accuracy: 75.70
Round 322, Train loss: 1.285, Test loss: 1.279, Test accuracy: 75.37
Round 322, Global train loss: 1.285, Global test loss: 1.275, Global test accuracy: 75.90
Round 323, Train loss: 1.284, Test loss: 1.277, Test accuracy: 75.60
Round 323, Global train loss: 1.284, Global test loss: 1.273, Global test accuracy: 76.04
Round 324, Train loss: 1.278, Test loss: 1.276, Test accuracy: 75.75
Round 324, Global train loss: 1.278, Global test loss: 1.271, Global test accuracy: 76.24
Round 325, Train loss: 1.280, Test loss: 1.275, Test accuracy: 75.80
Round 325, Global train loss: 1.280, Global test loss: 1.269, Global test accuracy: 76.29
Round 326, Train loss: 1.279, Test loss: 1.272, Test accuracy: 75.89
Round 326, Global train loss: 1.279, Global test loss: 1.266, Global test accuracy: 76.35
Round 327, Train loss: 1.265, Test loss: 1.270, Test accuracy: 76.03
Round 327, Global train loss: 1.265, Global test loss: 1.264, Global test accuracy: 76.40
Round 328, Train loss: 1.268, Test loss: 1.268, Test accuracy: 76.19
Round 328, Global train loss: 1.268, Global test loss: 1.262, Global test accuracy: 76.47
Round 329, Train loss: 1.269, Test loss: 1.265, Test accuracy: 76.31
Round 329, Global train loss: 1.269, Global test loss: 1.260, Global test accuracy: 76.54
Round 330, Train loss: 1.265, Test loss: 1.263, Test accuracy: 76.37
Round 330, Global train loss: 1.265, Global test loss: 1.258, Global test accuracy: 76.71
Round 331, Train loss: 1.262, Test loss: 1.261, Test accuracy: 76.48
Round 331, Global train loss: 1.262, Global test loss: 1.256, Global test accuracy: 76.90
Round 332, Train loss: 1.262, Test loss: 1.258, Test accuracy: 76.74
Round 332, Global train loss: 1.262, Global test loss: 1.254, Global test accuracy: 76.97
Round 333, Train loss: 1.259, Test loss: 1.256, Test accuracy: 76.86
Round 333, Global train loss: 1.259, Global test loss: 1.252, Global test accuracy: 77.01
Round 334, Train loss: 1.257, Test loss: 1.254, Test accuracy: 76.92
Round 334, Global train loss: 1.257, Global test loss: 1.250, Global test accuracy: 77.10
Round 335, Train loss: 1.255, Test loss: 1.252, Test accuracy: 76.97
Round 335, Global train loss: 1.255, Global test loss: 1.248, Global test accuracy: 77.16
Round 336, Train loss: 1.250, Test loss: 1.250, Test accuracy: 77.09
Round 336, Global train loss: 1.250, Global test loss: 1.246, Global test accuracy: 77.24
Round 337, Train loss: 1.251, Test loss: 1.248, Test accuracy: 77.13
Round 337, Global train loss: 1.251, Global test loss: 1.244, Global test accuracy: 77.29
Round 338, Train loss: 1.249, Test loss: 1.246, Test accuracy: 77.20
Round 338, Global train loss: 1.249, Global test loss: 1.241, Global test accuracy: 77.36
Round 339, Train loss: 1.247, Test loss: 1.244, Test accuracy: 77.34
Round 339, Global train loss: 1.247, Global test loss: 1.239, Global test accuracy: 77.36
Round 340, Train loss: 1.242, Test loss: 1.241, Test accuracy: 77.35
Round 340, Global train loss: 1.242, Global test loss: 1.237, Global test accuracy: 77.39
Round 341, Train loss: 1.239, Test loss: 1.239, Test accuracy: 77.41
Round 341, Global train loss: 1.239, Global test loss: 1.235, Global test accuracy: 77.54
Round 342, Train loss: 1.235, Test loss: 1.238, Test accuracy: 77.47
Round 342, Global train loss: 1.235, Global test loss: 1.233, Global test accuracy: 77.63
Round 343, Train loss: 1.232, Test loss: 1.236, Test accuracy: 77.53
Round 343, Global train loss: 1.232, Global test loss: 1.231, Global test accuracy: 77.71
Round 344, Train loss: 1.236, Test loss: 1.234, Test accuracy: 77.62
Round 344, Global train loss: 1.236, Global test loss: 1.229, Global test accuracy: 77.80
Round 345, Train loss: 1.234, Test loss: 1.232, Test accuracy: 77.68
Round 345, Global train loss: 1.234, Global test loss: 1.226, Global test accuracy: 77.91
Round 346, Train loss: 1.226, Test loss: 1.230, Test accuracy: 77.75
Round 346, Global train loss: 1.226, Global test loss: 1.224, Global test accuracy: 77.95
Round 347, Train loss: 1.231, Test loss: 1.227, Test accuracy: 77.90
Round 347, Global train loss: 1.231, Global test loss: 1.222, Global test accuracy: 77.98
Round 348, Train loss: 1.229, Test loss: 1.224, Test accuracy: 78.01
Round 348, Global train loss: 1.229, Global test loss: 1.220, Global test accuracy: 78.17
Round 349, Train loss: 1.221, Test loss: 1.222, Test accuracy: 78.05
Round 349, Global train loss: 1.221, Global test loss: 1.217, Global test accuracy: 78.17
Round 350, Train loss: 1.218, Test loss: 1.219, Test accuracy: 78.16
Round 350, Global train loss: 1.218, Global test loss: 1.215, Global test accuracy: 78.34
Round 351, Train loss: 1.219, Test loss: 1.217, Test accuracy: 78.31
Round 351, Global train loss: 1.219, Global test loss: 1.213, Global test accuracy: 78.41
Round 352, Train loss: 1.213, Test loss: 1.215, Test accuracy: 78.37
Round 352, Global train loss: 1.213, Global test loss: 1.210, Global test accuracy: 78.46
Round 353, Train loss: 1.215, Test loss: 1.213, Test accuracy: 78.43
Round 353, Global train loss: 1.215, Global test loss: 1.208, Global test accuracy: 78.53
Round 354, Train loss: 1.209, Test loss: 1.211, Test accuracy: 78.51
Round 354, Global train loss: 1.209, Global test loss: 1.206, Global test accuracy: 78.59
Round 355, Train loss: 1.216, Test loss: 1.208, Test accuracy: 78.58
Round 355, Global train loss: 1.216, Global test loss: 1.203, Global test accuracy: 78.65
Round 356, Train loss: 1.209, Test loss: 1.206, Test accuracy: 78.65
Round 356, Global train loss: 1.209, Global test loss: 1.201, Global test accuracy: 78.82
Round 357, Train loss: 1.200, Test loss: 1.204, Test accuracy: 78.78
Round 357, Global train loss: 1.200, Global test loss: 1.199, Global test accuracy: 78.87
Round 358, Train loss: 1.197, Test loss: 1.200, Test accuracy: 78.86
Round 358, Global train loss: 1.197, Global test loss: 1.197, Global test accuracy: 78.96
Round 359, Train loss: 1.203, Test loss: 1.198, Test accuracy: 78.91
Round 359, Global train loss: 1.203, Global test loss: 1.194, Global test accuracy: 79.09
Round 360, Train loss: 1.196, Test loss: 1.197, Test accuracy: 78.98
Round 360, Global train loss: 1.196, Global test loss: 1.192, Global test accuracy: 79.10
Round 361, Train loss: 1.189, Test loss: 1.195, Test accuracy: 79.07
Round 361, Global train loss: 1.189, Global test loss: 1.190, Global test accuracy: 79.23
Round 362, Train loss: 1.192, Test loss: 1.193, Test accuracy: 79.16
Round 362, Global train loss: 1.192, Global test loss: 1.188, Global test accuracy: 79.37
Round 363, Train loss: 1.185, Test loss: 1.191, Test accuracy: 79.23
Round 363, Global train loss: 1.185, Global test loss: 1.185, Global test accuracy: 79.58
Round 364, Train loss: 1.184, Test loss: 1.190, Test accuracy: 79.32
Round 364, Global train loss: 1.184, Global test loss: 1.183, Global test accuracy: 79.67
Round 365, Train loss: 1.187, Test loss: 1.187, Test accuracy: 79.42
Round 365, Global train loss: 1.187, Global test loss: 1.181, Global test accuracy: 79.85
Round 366, Train loss: 1.185, Test loss: 1.184, Test accuracy: 79.68
Round 366, Global train loss: 1.185, Global test loss: 1.179, Global test accuracy: 80.14
Round 367, Train loss: 1.186, Test loss: 1.182, Test accuracy: 79.90
Round 367, Global train loss: 1.186, Global test loss: 1.177, Global test accuracy: 80.38
Round 368, Train loss: 1.182, Test loss: 1.179, Test accuracy: 80.15
Round 368, Global train loss: 1.182, Global test loss: 1.174, Global test accuracy: 80.70
Round 369, Train loss: 1.182, Test loss: 1.178, Test accuracy: 80.29
Round 369, Global train loss: 1.182, Global test loss: 1.172, Global test accuracy: 80.80
Round 370, Train loss: 1.179, Test loss: 1.175, Test accuracy: 80.54
Round 370, Global train loss: 1.179, Global test loss: 1.170, Global test accuracy: 80.93
Round 371, Train loss: 1.173, Test loss: 1.172, Test accuracy: 80.71
Round 371, Global train loss: 1.173, Global test loss: 1.168, Global test accuracy: 81.01
Round 372, Train loss: 1.170, Test loss: 1.170, Test accuracy: 80.93
Round 372, Global train loss: 1.170, Global test loss: 1.166, Global test accuracy: 81.25
Round 373, Train loss: 1.164, Test loss: 1.167, Test accuracy: 81.15
Round 373, Global train loss: 1.164, Global test loss: 1.164, Global test accuracy: 81.46
Round 374, Train loss: 1.170, Test loss: 1.166, Test accuracy: 81.33
Round 374, Global train loss: 1.170, Global test loss: 1.162, Global test accuracy: 81.58
Round 375, Train loss: 1.168, Test loss: 1.165, Test accuracy: 81.42
Round 375, Global train loss: 1.168, Global test loss: 1.160, Global test accuracy: 81.79
Round 376, Train loss: 1.161, Test loss: 1.162, Test accuracy: 81.64
Round 376, Global train loss: 1.161, Global test loss: 1.158, Global test accuracy: 81.93
Round 377, Train loss: 1.157, Test loss: 1.159, Test accuracy: 81.84
Round 377, Global train loss: 1.157, Global test loss: 1.156, Global test accuracy: 81.95
Round 378, Train loss: 1.158, Test loss: 1.158, Test accuracy: 81.90
Round 378, Global train loss: 1.158, Global test loss: 1.154, Global test accuracy: 82.19
Round 379, Train loss: 1.157, Test loss: 1.157, Test accuracy: 82.03
Round 379, Global train loss: 1.157, Global test loss: 1.152, Global test accuracy: 82.40
Round 380, Train loss: 1.153, Test loss: 1.155, Test accuracy: 82.15
Round 380, Global train loss: 1.153, Global test loss: 1.150, Global test accuracy: 82.67
Round 381, Train loss: 1.154, Test loss: 1.151, Test accuracy: 82.52
Round 381, Global train loss: 1.154, Global test loss: 1.148, Global test accuracy: 82.89
Round 382, Train loss: 1.153, Test loss: 1.149, Test accuracy: 82.75
Round 382, Global train loss: 1.153, Global test loss: 1.146, Global test accuracy: 83.01
Round 383, Train loss: 1.150, Test loss: 1.148, Test accuracy: 82.93
Round 383, Global train loss: 1.150, Global test loss: 1.144, Global test accuracy: 83.36
Round 384, Train loss: 1.149, Test loss: 1.147, Test accuracy: 83.08
Round 384, Global train loss: 1.149, Global test loss: 1.142, Global test accuracy: 83.58
Round 385, Train loss: 1.140, Test loss: 1.144, Test accuracy: 83.30
Round 385, Global train loss: 1.140, Global test loss: 1.140, Global test accuracy: 83.92
Round 386, Train loss: 1.144, Test loss: 1.142, Test accuracy: 83.59
Round 386, Global train loss: 1.144, Global test loss: 1.138, Global test accuracy: 84.13
Round 387, Train loss: 1.139, Test loss: 1.141, Test accuracy: 83.81
Round 387, Global train loss: 1.139, Global test loss: 1.136, Global test accuracy: 84.44
Round 388, Train loss: 1.141, Test loss: 1.139, Test accuracy: 84.14
Round 388, Global train loss: 1.141, Global test loss: 1.134, Global test accuracy: 84.61
Round 389, Train loss: 1.137, Test loss: 1.136, Test accuracy: 84.41
Round 389, Global train loss: 1.137, Global test loss: 1.132, Global test accuracy: 84.89
Round 390, Train loss: 1.138, Test loss: 1.135, Test accuracy: 84.61
Round 390, Global train loss: 1.138, Global test loss: 1.130, Global test accuracy: 85.15
Round 391, Train loss: 1.133, Test loss: 1.133, Test accuracy: 84.83
Round 391, Global train loss: 1.133, Global test loss: 1.128, Global test accuracy: 85.59
Round 392, Train loss: 1.129, Test loss: 1.131, Test accuracy: 85.12
Round 392, Global train loss: 1.129, Global test loss: 1.126, Global test accuracy: 86.08
Round 393, Train loss: 1.130, Test loss: 1.130, Test accuracy: 85.37
Round 393, Global train loss: 1.130, Global test loss: 1.124, Global test accuracy: 86.14
Round 394, Train loss: 1.125, Test loss: 1.127, Test accuracy: 85.79
Round 394, Global train loss: 1.125, Global test loss: 1.122, Global test accuracy: 86.51
Round 395, Train loss: 1.131, Test loss: 1.125, Test accuracy: 86.03
Round 395, Global train loss: 1.131, Global test loss: 1.120, Global test accuracy: 86.67
Round 396, Train loss: 1.119, Test loss: 1.124, Test accuracy: 86.21
Round 396, Global train loss: 1.119, Global test loss: 1.118, Global test accuracy: 86.90
Round 397, Train loss: 1.125, Test loss: 1.122, Test accuracy: 86.50
Round 397, Global train loss: 1.125, Global test loss: 1.116, Global test accuracy: 87.25
Round 398, Train loss: 1.121, Test loss: 1.120, Test accuracy: 86.66
Round 398, Global train loss: 1.121, Global test loss: 1.114, Global test accuracy: 87.48
Round 399, Train loss: 1.114, Test loss: 1.117, Test accuracy: 87.07
Round 399, Global train loss: 1.114, Global test loss: 1.112, Global test accuracy: 87.66
Final Round, Train loss: 1.115, Test loss: 1.109, Test accuracy: 88.16
Final Round, Global train loss: 1.115, Global test loss: 1.112, Global test accuracy: 87.66
Average accuracy final 10 rounds: 85.819 

Average global accuracy final 10 rounds: 86.543 

4519.858937263489
[1.0682435035705566, 2.1652374267578125, 3.2363436222076416, 4.358023405075073, 5.413555860519409, 6.502904176712036, 7.563349723815918, 8.627783298492432, 9.704647779464722, 10.76316499710083, 11.847317695617676, 12.93607783317566, 13.99860954284668, 15.095110416412354, 16.39307165145874, 17.43563485145569, 18.508012771606445, 19.661754608154297, 20.829346418380737, 21.897491455078125, 23.027174949645996, 24.102742671966553, 25.193551540374756, 26.317521572113037, 27.381909608840942, 28.477150917053223, 29.538317441940308, 30.64274835586548, 31.723674774169922, 32.77788162231445, 33.85149049758911, 34.959179639816284, 36.04970145225525, 37.11427021026611, 38.22010374069214, 39.25277090072632, 40.360377073287964, 41.517269134521484, 42.582359313964844, 43.649449586868286, 44.71779823303223, 45.83952355384827, 46.891021728515625, 47.95036029815674, 49.05356287956238, 50.14777660369873, 51.24473524093628, 52.30133938789368, 53.446598052978516, 54.47770571708679, 55.66058015823364, 56.751776456832886, 57.76931834220886, 58.84427285194397, 59.90659856796265, 60.971856117248535, 62.0567729473114, 63.115745306015015, 64.17486119270325, 65.25370025634766, 66.32200860977173, 67.38629245758057, 68.43672251701355, 69.54578423500061, 70.63517665863037, 71.68042063713074, 72.73702383041382, 73.78321027755737, 74.94089770317078, 76.01000237464905, 77.0658929347992, 78.15018701553345, 79.21224570274353, 80.32003998756409, 81.40294361114502, 82.50120258331299, 83.55121326446533, 84.59043884277344, 85.70957350730896, 86.77795028686523, 87.89723038673401, 88.983731508255, 90.07032895088196, 91.12132692337036, 92.24956226348877, 93.35919070243835, 94.39808082580566, 95.29901242256165, 96.27255392074585, 97.38069605827332, 98.42809414863586, 99.48760914802551, 100.53370690345764, 101.5920991897583, 102.63796973228455, 103.68230628967285, 104.76848554611206, 105.86792516708374, 106.94013833999634, 108.0297520160675, 109.07828831672668, 110.14392876625061, 111.2274580001831, 112.28776931762695, 113.38146305084229, 114.4610505104065, 115.54644584655762, 116.62156271934509, 117.71912050247192, 118.77545857429504, 119.83363962173462, 120.8667585849762, 121.95043921470642, 123.03175020217896, 124.1240029335022, 125.21067547798157, 126.29099798202515, 127.39317536354065, 128.47591304779053, 129.54031705856323, 130.6067337989807, 131.6525936126709, 132.72662234306335, 133.78788709640503, 134.81889963150024, 135.8576898574829, 136.91023468971252, 137.9351418018341, 138.97242617607117, 139.99779963493347, 141.03432416915894, 142.11155557632446, 143.12696361541748, 144.14545392990112, 145.1895809173584, 146.23149943351746, 147.25655579566956, 148.32007122039795, 149.36062169075012, 150.40772485733032, 151.46517491340637, 152.50056076049805, 153.54662561416626, 154.6041374206543, 155.654394865036, 156.70824313163757, 157.73289704322815, 158.7929835319519, 159.85632014274597, 160.9026198387146, 161.92662930488586, 162.9700222015381, 164.00337648391724, 165.0564787387848, 166.09529399871826, 167.12371349334717, 168.17664313316345, 169.22216892242432, 170.26431679725647, 171.32742738723755, 172.38574266433716, 173.40933918952942, 174.46653056144714, 175.54146027565002, 176.59133386611938, 177.63866806030273, 178.68174242973328, 179.72230744361877, 180.77547359466553, 181.81372666358948, 182.8381962776184, 183.89300107955933, 184.95073461532593, 185.98013353347778, 187.06771063804626, 188.11702585220337, 189.19821906089783, 190.3564305305481, 191.4145839214325, 192.50314140319824, 193.5423619747162, 194.6136932373047, 195.69345569610596, 196.75937843322754, 197.79109239578247, 198.82490062713623, 199.90705847740173, 200.97950625419617, 202.04279446601868, 203.11225056648254, 204.19725513458252, 205.3004274368286, 206.3535921573639, 207.3766951560974, 208.49660277366638, 209.60484838485718, 210.70509910583496, 211.83282613754272, 212.95845103263855, 214.09483170509338, 215.26411747932434, 216.43797659873962, 217.5837209224701, 218.7100749015808, 219.89777493476868, 221.01974153518677, 222.1961977481842, 223.31824350357056, 224.45595932006836, 225.5265393257141, 226.58750462532043, 227.70468544960022, 228.76880407333374, 229.84660744667053, 230.91756772994995, 231.98177313804626, 233.03760838508606, 234.09449934959412, 235.1765673160553, 236.22679734230042, 237.3096113204956, 238.35409474372864, 239.4062225818634, 240.47197651863098, 241.54573273658752, 242.62545704841614, 243.70939826965332, 244.76525902748108, 245.86748456954956, 246.91547417640686, 247.9526960849762, 248.982088804245, 250.0568597316742, 251.11469864845276, 252.16607236862183, 253.24213647842407, 254.31444692611694, 255.36484479904175, 256.4284436702728, 257.4855387210846, 258.5336742401123, 259.57923316955566, 260.66897988319397, 261.77644300460815, 262.82881689071655, 263.87973618507385, 264.9230818748474, 265.98496198654175, 267.043434381485, 268.1095356941223, 269.1614511013031, 270.227881193161, 271.2835943698883, 272.35139179229736, 273.42424416542053, 274.4473412036896, 275.52519726753235, 276.59361839294434, 277.67470622062683, 278.73672246932983, 279.61435770988464, 280.47939109802246, 281.32993841171265, 282.31114053726196, 283.244247674942, 284.16239070892334, 285.0806760787964, 286.0266065597534, 286.9531373977661, 287.88638496398926, 288.82720255851746, 289.77390146255493, 290.7145845890045, 291.6485068798065, 292.6051387786865, 293.5310184955597, 294.4744372367859, 295.39554166793823, 296.32466673851013, 297.24642181396484, 298.1695923805237, 299.10523986816406, 300.0451991558075, 300.9093701839447, 301.7328293323517, 302.57315707206726, 303.39328932762146, 304.2128653526306, 305.03698801994324, 305.91374015808105, 306.76979303359985, 307.87095046043396, 308.91331219673157, 309.96372151374817, 311.0296859741211, 312.10166096687317, 313.17287397384644, 314.25201773643494, 315.3508794307709, 316.46160984039307, 317.51236629486084, 318.5845367908478, 319.69036293029785, 320.79684376716614, 321.883891582489, 322.9558889865875, 324.0239748954773, 325.08947706222534, 326.1551516056061, 327.21676206588745, 328.32807517051697, 329.42226099967957, 330.50746154785156, 331.5830707550049, 332.6827771663666, 333.7965154647827, 334.8885841369629, 335.9975571632385, 337.1311492919922, 338.1979293823242, 339.30667781829834, 340.3969397544861, 341.50222158432007, 342.57701301574707, 343.63449811935425, 344.7210774421692, 345.81517577171326, 346.9256184101105, 348.0509469509125, 349.21375846862793, 350.30468583106995, 351.3823719024658, 352.4510111808777, 353.49670791625977, 354.59859013557434, 355.6684625148773, 356.7630054950714, 357.8536467552185, 358.90285420417786, 360.13288164138794, 361.22348165512085, 362.29861092567444, 363.38664531707764, 364.4827904701233, 365.5553262233734, 366.6330051422119, 367.72930550575256, 368.82498002052307, 369.9046688079834, 370.97124195098877, 372.0202112197876, 373.08322834968567, 374.1813404560089, 375.2409632205963, 376.31040954589844, 377.37267899513245, 378.5032470226288, 379.60920453071594, 380.70813632011414, 381.75376534461975, 382.8494243621826, 383.95718002319336, 385.07483434677124, 386.19720125198364, 387.3163421154022, 388.3589699268341, 389.4605140686035, 390.470894575119, 391.56729197502136, 392.674845457077, 393.8049123287201, 394.8682897090912, 395.95438408851624, 397.06829810142517, 398.1819188594818, 399.2369225025177, 400.33066296577454, 401.4020400047302, 402.4476640224457, 403.5262439250946, 404.68383264541626, 405.7622091770172, 406.7995591163635, 407.9069812297821, 409.00522470474243, 410.00328636169434, 411.0670886039734, 412.1392936706543, 413.2393879890442, 414.3219072818756, 415.45531702041626, 416.5183277130127, 417.59971928596497, 418.70228910446167, 419.7592544555664, 420.84411787986755, 421.92185854911804, 423.005038022995, 424.08438539505005, 425.17988085746765, 427.2925646305084]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[26.67, 27.02, 27.33, 27.52, 27.9, 28.25, 28.57, 29.0, 29.2, 29.32, 29.63, 29.97, 30.2, 30.56, 30.85, 31.29, 31.56, 31.7, 32.1, 32.4, 32.62, 32.92, 33.27, 33.47, 33.73, 33.85, 34.03, 34.15, 34.33, 34.5, 34.65, 34.78, 34.91, 35.01, 35.13, 35.36, 35.41, 35.46, 35.57, 35.75, 35.98, 36.09, 36.15, 36.32, 36.61, 36.7, 36.81, 36.96, 37.11, 37.16, 37.32, 37.6, 37.66, 37.73, 37.78, 37.9, 38.0, 38.11, 38.18, 38.25, 38.51, 38.61, 38.77, 38.97, 39.1, 39.17, 39.24, 39.32, 39.46, 39.56, 39.81, 40.08, 40.31, 40.48, 40.6, 40.88, 41.1, 41.25, 41.45, 41.59, 41.81, 42.08, 42.27, 42.55, 42.97, 43.35, 43.68, 44.26, 44.52, 44.63, 44.93, 45.14, 45.5, 45.85, 46.02, 46.13, 46.41, 46.59, 46.76, 46.89, 47.36, 47.61, 47.8, 48.04, 48.21, 48.23, 48.37, 48.52, 48.91, 49.03, 49.32, 49.44, 49.69, 50.24, 50.38, 50.57, 50.72, 50.99, 51.03, 51.43, 51.54, 51.76, 52.0, 52.2, 52.47, 52.57, 52.61, 52.61, 52.69, 52.82, 52.99, 53.11, 53.25, 53.5, 53.65, 53.78, 53.84, 54.07, 54.19, 54.3, 54.5, 54.51, 54.62, 54.81, 54.86, 54.96, 55.04, 55.15, 55.23, 55.32, 55.49, 55.51, 55.6, 55.7, 55.73, 55.86, 55.92, 56.06, 56.15, 56.28, 56.36, 56.45, 56.54, 56.6, 56.63, 56.79, 56.83, 56.86, 56.9, 56.94, 56.97, 57.1, 57.11, 57.18, 57.21, 57.24, 57.35, 57.43, 57.54, 57.55, 57.63, 57.64, 57.75, 57.76, 57.78, 57.85, 57.83, 57.95, 58.04, 58.18, 58.24, 58.32, 58.37, 58.48, 58.57, 58.59, 58.71, 58.7, 58.76, 58.82, 58.91, 59.11, 59.27, 59.34, 59.42, 59.45, 59.67, 59.78, 59.87, 60.0, 60.03, 60.17, 60.21, 60.21, 60.26, 60.3, 60.35, 60.43, 60.7, 60.83, 60.82, 60.81, 60.87, 61.01, 61.02, 61.04, 61.12, 61.15, 61.36, 61.34, 61.39, 61.44, 61.44, 61.51, 61.54, 61.53, 61.64, 61.56, 61.57, 61.67, 61.71, 61.73, 61.76, 61.77, 61.83, 61.94, 62.02, 62.14, 62.31, 62.42, 62.49, 62.47, 62.44, 62.57, 62.53, 62.58, 62.66, 62.57, 62.62, 62.67, 62.72, 62.96, 63.05, 63.38, 63.47, 63.51, 63.64, 63.66, 63.67, 63.78, 63.92, 63.93, 64.07, 64.19, 64.25, 64.4, 64.61, 64.76, 64.94, 65.2, 65.48, 65.68, 65.67, 65.89, 66.1, 66.39, 66.71, 67.05, 67.2, 67.5, 67.77, 67.93, 68.49, 68.58, 68.76, 69.14, 69.39, 69.62, 69.89, 70.1, 70.3, 70.73, 71.08, 71.19, 71.45, 71.7, 71.88, 72.34, 72.59, 72.95, 73.29, 73.4, 73.58, 73.73, 73.88, 74.11, 74.21, 74.43, 74.54, 74.78, 74.94, 75.15, 75.37, 75.6, 75.75, 75.8, 75.89, 76.03, 76.19, 76.31, 76.37, 76.48, 76.74, 76.86, 76.92, 76.97, 77.09, 77.13, 77.2, 77.34, 77.35, 77.41, 77.47, 77.53, 77.62, 77.68, 77.75, 77.9, 78.01, 78.05, 78.16, 78.31, 78.37, 78.43, 78.51, 78.58, 78.65, 78.78, 78.86, 78.91, 78.98, 79.07, 79.16, 79.23, 79.32, 79.42, 79.68, 79.9, 80.15, 80.29, 80.54, 80.71, 80.93, 81.15, 81.33, 81.42, 81.64, 81.84, 81.9, 82.03, 82.15, 82.52, 82.75, 82.93, 83.08, 83.3, 83.59, 83.81, 84.14, 84.41, 84.61, 84.83, 85.12, 85.37, 85.79, 86.03, 86.21, 86.5, 86.66, 87.07, 88.16]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.623, Test loss: 1.584, Test accuracy: 63.75
Round   1, Train loss: 1.564, Test loss: 1.491, Test accuracy: 84.55
Round   2, Train loss: 1.392, Test loss: 1.221, Test accuracy: 91.10
Round   3, Train loss: 1.116, Test loss: 1.061, Test accuracy: 95.10
Round   4, Train loss: 1.030, Test loss: 1.014, Test accuracy: 96.32
Round   5, Train loss: 1.014, Test loss: 0.986, Test accuracy: 96.75
Round   6, Train loss: 0.985, Test loss: 0.976, Test accuracy: 97.04
Round   7, Train loss: 0.977, Test loss: 0.966, Test accuracy: 97.12
Round   8, Train loss: 0.973, Test loss: 0.961, Test accuracy: 97.10
Round   9, Train loss: 0.972, Test loss: 0.953, Test accuracy: 97.18
Round  10, Train loss: 0.961, Test loss: 0.950, Test accuracy: 97.28
Round  11, Train loss: 0.953, Test loss: 0.949, Test accuracy: 97.38
Round  12, Train loss: 0.955, Test loss: 0.947, Test accuracy: 97.48
Round  13, Train loss: 0.953, Test loss: 0.945, Test accuracy: 97.43
Round  14, Train loss: 0.949, Test loss: 0.943, Test accuracy: 97.52
Round  15, Train loss: 0.943, Test loss: 0.943, Test accuracy: 97.56
Round  16, Train loss: 0.947, Test loss: 0.942, Test accuracy: 97.63
Round  17, Train loss: 0.949, Test loss: 0.939, Test accuracy: 97.76
Round  18, Train loss: 0.937, Test loss: 0.938, Test accuracy: 97.77
Round  19, Train loss: 0.942, Test loss: 0.938, Test accuracy: 97.80
Round  20, Train loss: 0.942, Test loss: 0.936, Test accuracy: 97.84
Round  21, Train loss: 0.938, Test loss: 0.935, Test accuracy: 97.91
Round  22, Train loss: 0.938, Test loss: 0.935, Test accuracy: 97.87
Round  23, Train loss: 0.940, Test loss: 0.934, Test accuracy: 97.91
Round  24, Train loss: 0.935, Test loss: 0.934, Test accuracy: 97.91
Round  25, Train loss: 0.935, Test loss: 0.933, Test accuracy: 97.97
Round  26, Train loss: 0.934, Test loss: 0.933, Test accuracy: 98.08
Round  27, Train loss: 0.928, Test loss: 0.932, Test accuracy: 98.09
Round  28, Train loss: 0.937, Test loss: 0.932, Test accuracy: 98.15
Round  29, Train loss: 0.934, Test loss: 0.931, Test accuracy: 98.20
Round  30, Train loss: 0.930, Test loss: 0.930, Test accuracy: 98.28
Round  31, Train loss: 0.930, Test loss: 0.930, Test accuracy: 98.28
Round  32, Train loss: 0.927, Test loss: 0.930, Test accuracy: 98.25
Round  33, Train loss: 0.925, Test loss: 0.929, Test accuracy: 98.31
Round  34, Train loss: 0.929, Test loss: 0.929, Test accuracy: 98.34
Round  35, Train loss: 0.931, Test loss: 0.929, Test accuracy: 98.38
Round  36, Train loss: 0.928, Test loss: 0.929, Test accuracy: 98.29
Round  37, Train loss: 0.924, Test loss: 0.928, Test accuracy: 98.32
Round  38, Train loss: 0.925, Test loss: 0.928, Test accuracy: 98.34
Round  39, Train loss: 0.926, Test loss: 0.928, Test accuracy: 98.33
Round  40, Train loss: 0.928, Test loss: 0.927, Test accuracy: 98.35
Round  41, Train loss: 0.929, Test loss: 0.927, Test accuracy: 98.42
Round  42, Train loss: 0.922, Test loss: 0.927, Test accuracy: 98.42
Round  43, Train loss: 0.921, Test loss: 0.926, Test accuracy: 98.43
Round  44, Train loss: 0.924, Test loss: 0.926, Test accuracy: 98.44
Round  45, Train loss: 0.923, Test loss: 0.926, Test accuracy: 98.46
Round  46, Train loss: 0.924, Test loss: 0.926, Test accuracy: 98.43
Round  47, Train loss: 0.924, Test loss: 0.926, Test accuracy: 98.48
Round  48, Train loss: 0.925, Test loss: 0.925, Test accuracy: 98.51
Round  49, Train loss: 0.923, Test loss: 0.925, Test accuracy: 98.47
Round  50, Train loss: 0.921, Test loss: 0.925, Test accuracy: 98.47
Round  51, Train loss: 0.922, Test loss: 0.925, Test accuracy: 98.57
Round  52, Train loss: 0.919, Test loss: 0.925, Test accuracy: 98.56
Round  53, Train loss: 0.926, Test loss: 0.925, Test accuracy: 98.60
Round  54, Train loss: 0.918, Test loss: 0.925, Test accuracy: 98.52
Round  55, Train loss: 0.919, Test loss: 0.924, Test accuracy: 98.55
Round  56, Train loss: 0.919, Test loss: 0.924, Test accuracy: 98.58
Round  57, Train loss: 0.920, Test loss: 0.924, Test accuracy: 98.55
Round  58, Train loss: 0.920, Test loss: 0.924, Test accuracy: 98.60
Round  59, Train loss: 0.918, Test loss: 0.924, Test accuracy: 98.58
Round  60, Train loss: 0.920, Test loss: 0.923, Test accuracy: 98.56
Round  61, Train loss: 0.916, Test loss: 0.924, Test accuracy: 98.60
Round  62, Train loss: 0.919, Test loss: 0.923, Test accuracy: 98.55
Round  63, Train loss: 0.916, Test loss: 0.923, Test accuracy: 98.59
Round  64, Train loss: 0.918, Test loss: 0.923, Test accuracy: 98.60
Round  65, Train loss: 0.917, Test loss: 0.923, Test accuracy: 98.66
Round  66, Train loss: 0.916, Test loss: 0.923, Test accuracy: 98.68
Round  67, Train loss: 0.917, Test loss: 0.923, Test accuracy: 98.63
Round  68, Train loss: 0.919, Test loss: 0.923, Test accuracy: 98.65
Round  69, Train loss: 0.918, Test loss: 0.922, Test accuracy: 98.70
Round  70, Train loss: 0.914, Test loss: 0.922, Test accuracy: 98.72
Round  71, Train loss: 0.918, Test loss: 0.922, Test accuracy: 98.71
Round  72, Train loss: 0.918, Test loss: 0.922, Test accuracy: 98.71
Round  73, Train loss: 0.918, Test loss: 0.921, Test accuracy: 98.78
Round  74, Train loss: 0.918, Test loss: 0.921, Test accuracy: 98.77
Round  75, Train loss: 0.915, Test loss: 0.921, Test accuracy: 98.81
Round  76, Train loss: 0.917, Test loss: 0.921, Test accuracy: 98.82
Round  77, Train loss: 0.914, Test loss: 0.921, Test accuracy: 98.83
Round  78, Train loss: 0.915, Test loss: 0.921, Test accuracy: 98.83
Round  79, Train loss: 0.917, Test loss: 0.921, Test accuracy: 98.85
Round  80, Train loss: 0.915, Test loss: 0.921, Test accuracy: 98.85
Round  81, Train loss: 0.915, Test loss: 0.921, Test accuracy: 98.89
Round  82, Train loss: 0.914, Test loss: 0.921, Test accuracy: 98.86
Round  83, Train loss: 0.914, Test loss: 0.921, Test accuracy: 98.91
Round  84, Train loss: 0.915, Test loss: 0.920, Test accuracy: 98.93
Round  85, Train loss: 0.913, Test loss: 0.920, Test accuracy: 98.93
Round  86, Train loss: 0.915, Test loss: 0.920, Test accuracy: 98.96
Round  87, Train loss: 0.913, Test loss: 0.920, Test accuracy: 98.93
Round  88, Train loss: 0.914, Test loss: 0.920, Test accuracy: 98.96
Round  89, Train loss: 0.912, Test loss: 0.920, Test accuracy: 98.97
Round  90, Train loss: 0.917, Test loss: 0.920, Test accuracy: 98.98
Round  91, Train loss: 0.914, Test loss: 0.920, Test accuracy: 98.94
Round  92, Train loss: 0.913, Test loss: 0.920, Test accuracy: 99.01
Round  93, Train loss: 0.915, Test loss: 0.920, Test accuracy: 98.98
Round  94, Train loss: 0.913, Test loss: 0.920, Test accuracy: 98.98
Round  95, Train loss: 0.914, Test loss: 0.920, Test accuracy: 99.00
Round  96, Train loss: 0.912, Test loss: 0.920, Test accuracy: 99.00
Round  97, Train loss: 0.912, Test loss: 0.919, Test accuracy: 99.01
Round  98, Train loss: 0.911, Test loss: 0.920, Test accuracy: 99.03
Round  99, Train loss: 0.912, Test loss: 0.919, Test accuracy: 99.05
Round 100, Train loss: 0.913, Test loss: 0.919, Test accuracy: 99.02
Round 101, Train loss: 0.915, Test loss: 0.919, Test accuracy: 99.01
Round 102, Train loss: 0.911, Test loss: 0.919, Test accuracy: 99.02
Round 103, Train loss: 0.912, Test loss: 0.919, Test accuracy: 99.02
Round 104, Train loss: 0.912, Test loss: 0.919, Test accuracy: 98.99
Round 105, Train loss: 0.913, Test loss: 0.919, Test accuracy: 98.99
Round 106, Train loss: 0.911, Test loss: 0.920, Test accuracy: 98.99
Round 107, Train loss: 0.913, Test loss: 0.919, Test accuracy: 99.00
Round 108, Train loss: 0.913, Test loss: 0.919, Test accuracy: 99.06
Round 109, Train loss: 0.910, Test loss: 0.919, Test accuracy: 99.04
Round 110, Train loss: 0.913, Test loss: 0.919, Test accuracy: 99.02
Round 111, Train loss: 0.910, Test loss: 0.919, Test accuracy: 99.06
Round 112, Train loss: 0.912, Test loss: 0.919, Test accuracy: 99.03
Round 113, Train loss: 0.912, Test loss: 0.919, Test accuracy: 99.06
Round 114, Train loss: 0.911, Test loss: 0.919, Test accuracy: 99.04
Round 115, Train loss: 0.910, Test loss: 0.919, Test accuracy: 99.06
Round 116, Train loss: 0.911, Test loss: 0.919, Test accuracy: 99.05
Round 117, Train loss: 0.911, Test loss: 0.919, Test accuracy: 99.06
Round 118, Train loss: 0.910, Test loss: 0.919, Test accuracy: 99.05
Round 119, Train loss: 0.910, Test loss: 0.919, Test accuracy: 99.05
Round 120, Train loss: 0.910, Test loss: 0.919, Test accuracy: 99.08
Round 121, Train loss: 0.911, Test loss: 0.919, Test accuracy: 99.07
Round 122, Train loss: 0.912, Test loss: 0.919, Test accuracy: 99.06
Round 123, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.08
Round 124, Train loss: 0.912, Test loss: 0.918, Test accuracy: 99.08
Round 125, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.07
Round 126, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.08
Round 127, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.03
Round 128, Train loss: 0.912, Test loss: 0.918, Test accuracy: 99.04
Round 129, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.08
Round 130, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.03
Round 131, Train loss: 0.909, Test loss: 0.918, Test accuracy: 99.04
Round 132, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.04
Round 133, Train loss: 0.912, Test loss: 0.918, Test accuracy: 99.03
Round 134, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.03
Round 135, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.05
Round 136, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.04
Round 137, Train loss: 0.909, Test loss: 0.918, Test accuracy: 99.04
Round 138, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.10
Round 139, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.05
Round 140, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.05
Round 141, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.07
Round 142, Train loss: 0.909, Test loss: 0.918, Test accuracy: 99.08
Round 143, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.06
Round 144, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.07
Round 145, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.07
Round 146, Train loss: 0.911, Test loss: 0.918, Test accuracy: 99.08
Round 147, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.09
Round 148, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.08
Round 149, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.09
Round 150, Train loss: 0.910, Test loss: 0.917, Test accuracy: 99.10
Round 151, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.09
Round 152, Train loss: 0.910, Test loss: 0.917, Test accuracy: 99.08
Round 153, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.09
Round 154, Train loss: 0.910, Test loss: 0.917, Test accuracy: 99.09
Round 155, Train loss: 0.910, Test loss: 0.918, Test accuracy: 99.06
Round 156, Train loss: 0.909, Test loss: 0.918, Test accuracy: 99.08
Round 157, Train loss: 0.910, Test loss: 0.917, Test accuracy: 99.08
Round 158, Train loss: 0.910, Test loss: 0.917, Test accuracy: 99.07
Round 159, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.06
Round 160, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.08
Round 161, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.10
Round 162, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.10
Round 163, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.09
Round 164, Train loss: 0.910, Test loss: 0.917, Test accuracy: 99.09
Round 165, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.08
Round 166, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.08
Round 167, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.09
Round 168, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.06
Round 169, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.08
Round 170, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.07
Round 171, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.10
Round 172, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.09
Round 173, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.09
Round 174, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.09
Round 175, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.08
Round 176, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.12
Round 177, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.08
Round 178, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.12
Round 179, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.10
Round 180, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.11
Round 181, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.11
Round 182, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.07
Round 183, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.08
Round 184, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.10
Round 185, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.10
Round 186, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.10
Round 187, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.09
Round 188, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.10
Round 189, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.10
Round 190, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.11
Round 191, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.11
Round 192, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.13
Round 193, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.12
Round 194, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.12
Round 195, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.12
Round 196, Train loss: 0.908, Test loss: 0.917, Test accuracy: 99.15
Round 197, Train loss: 0.908, Test loss: 0.916, Test accuracy: 99.11
Round 198, Train loss: 0.909, Test loss: 0.917, Test accuracy: 99.11
Round 199, Train loss: 0.909, Test loss: 0.916, Test accuracy: 99.11
Final Round, Train loss: 0.907, Test loss: 0.916, Test accuracy: 99.15
Average accuracy final 10 rounds: 99.119
1828.0375699996948
[1.364952564239502, 2.591118812561035, 3.7962911128997803, 4.936559200286865, 6.158093690872192, 7.343703269958496, 8.507200717926025, 9.67660641670227, 10.869185447692871, 12.055988073348999, 13.269087791442871, 14.448273181915283, 15.683318376541138, 16.8551824092865, 18.058760404586792, 19.23687243461609, 20.4374680519104, 21.700425386428833, 22.865676879882812, 24.055169105529785, 25.248542070388794, 26.403345823287964, 27.581430435180664, 28.769667387008667, 29.939149618148804, 31.09001851081848, 32.28643226623535, 33.492267370224, 34.668866872787476, 35.832125663757324, 37.01004457473755, 38.22258424758911, 39.41664695739746, 40.52725601196289, 41.695486545562744, 42.86205506324768, 44.05251455307007, 45.299407720565796, 46.449007511138916, 47.60221219062805, 48.74947905540466, 49.94110059738159, 51.08081579208374, 52.2694935798645, 53.484211921691895, 54.65589928627014, 55.87063527107239, 57.03662610054016, 58.23008108139038, 59.43817973136902, 60.65761137008667, 61.81877112388611, 62.96527361869812, 64.13064885139465, 65.28594970703125, 66.42281723022461, 67.59660530090332, 68.74076294898987, 69.91287875175476, 71.06937408447266, 72.24290370941162, 73.37068128585815, 74.52344512939453, 75.66179370880127, 76.75820851325989, 77.89296650886536, 79.01277589797974, 80.16527652740479, 81.30280041694641, 82.4463746547699, 83.5942313671112, 84.60435891151428, 85.71944308280945, 86.87877488136292, 88.06071352958679, 89.23221731185913, 90.31731581687927, 91.47758674621582, 92.64093542098999, 93.73705911636353, 94.80607008934021, 95.9611542224884, 97.18097591400146, 98.35110068321228, 99.45508670806885, 100.72116613388062, 101.84903883934021, 103.02027702331543, 104.20005202293396, 105.33840036392212, 106.50783228874207, 107.68183708190918, 108.87117791175842, 110.00921201705933, 111.14624524116516, 112.2504870891571, 113.39479398727417, 114.55787754058838, 115.69889521598816, 116.84922337532043, 118.04581618309021, 119.20491123199463, 120.37986969947815, 121.52974486351013, 122.67966270446777, 123.80465960502625, 124.95552492141724, 126.16474318504333, 127.368008852005, 128.70428347587585, 129.9094786643982, 131.17500495910645, 132.33939290046692, 133.51679062843323, 134.83698153495789, 136.0765256881714, 137.2943024635315, 138.54928278923035, 139.66925430297852, 140.91798090934753, 142.0417091846466, 143.23502898216248, 144.3988218307495, 145.68490600585938, 146.98205161094666, 148.28672695159912, 149.48016595840454, 150.64508271217346, 151.802015542984, 152.88022589683533, 154.09014225006104, 155.27068305015564, 156.3733720779419, 157.5850977897644, 158.80556344985962, 160.08297204971313, 161.23945116996765, 162.3661925792694, 163.54459714889526, 164.69391584396362, 165.8088400363922, 167.00816082954407, 168.15655183792114, 169.33855772018433, 170.5687553882599, 171.8627097606659, 173.14526391029358, 174.34714031219482, 175.56713390350342, 176.81499767303467, 178.08639788627625, 179.43954420089722, 180.57891988754272, 181.73517632484436, 182.87302803993225, 184.0279245376587, 185.1410517692566, 186.306871175766, 187.48268628120422, 188.67269229888916, 189.85449695587158, 190.98009848594666, 192.1247580051422, 193.27390456199646, 194.42596316337585, 195.57364010810852, 196.70826840400696, 197.86132383346558, 198.9516522884369, 200.1395378112793, 201.26962113380432, 202.41853618621826, 203.53559732437134, 204.71243238449097, 205.8321976661682, 206.97003030776978, 208.1326243877411, 209.27435564994812, 210.3518295288086, 211.52348566055298, 212.6511745452881, 213.83530712127686, 214.95942449569702, 216.11156153678894, 217.21715760231018, 218.36157369613647, 219.49243903160095, 220.68016862869263, 221.8053753376007, 222.92259526252747, 224.05133485794067, 225.23185324668884, 226.38207054138184, 227.50135397911072, 228.66979694366455, 229.8405475616455, 231.02904963493347, 232.18982028961182, 233.33815598487854, 234.71261286735535, 236.53468775749207]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[63.75, 84.55, 91.1, 95.1, 96.32, 96.75, 97.04, 97.12, 97.1, 97.18, 97.28, 97.38, 97.48, 97.43, 97.52, 97.56, 97.63, 97.76, 97.77, 97.8, 97.84, 97.91, 97.87, 97.91, 97.91, 97.97, 98.08, 98.09, 98.15, 98.2, 98.28, 98.28, 98.25, 98.31, 98.34, 98.38, 98.29, 98.32, 98.34, 98.33, 98.35, 98.42, 98.42, 98.43, 98.44, 98.46, 98.43, 98.48, 98.51, 98.47, 98.47, 98.57, 98.56, 98.6, 98.52, 98.55, 98.58, 98.55, 98.6, 98.58, 98.56, 98.6, 98.55, 98.59, 98.6, 98.66, 98.68, 98.63, 98.65, 98.7, 98.72, 98.71, 98.71, 98.78, 98.77, 98.81, 98.82, 98.83, 98.83, 98.85, 98.85, 98.89, 98.86, 98.91, 98.93, 98.93, 98.96, 98.93, 98.96, 98.97, 98.98, 98.94, 99.01, 98.98, 98.98, 99.0, 99.0, 99.01, 99.03, 99.05, 99.02, 99.01, 99.02, 99.02, 98.99, 98.99, 98.99, 99.0, 99.06, 99.04, 99.02, 99.06, 99.03, 99.06, 99.04, 99.06, 99.05, 99.06, 99.05, 99.05, 99.08, 99.07, 99.06, 99.08, 99.08, 99.07, 99.08, 99.03, 99.04, 99.08, 99.03, 99.04, 99.04, 99.03, 99.03, 99.05, 99.04, 99.04, 99.1, 99.05, 99.05, 99.07, 99.08, 99.06, 99.07, 99.07, 99.08, 99.09, 99.08, 99.09, 99.1, 99.09, 99.08, 99.09, 99.09, 99.06, 99.08, 99.08, 99.07, 99.06, 99.08, 99.1, 99.1, 99.09, 99.09, 99.08, 99.08, 99.09, 99.06, 99.08, 99.07, 99.1, 99.09, 99.09, 99.09, 99.08, 99.12, 99.08, 99.12, 99.1, 99.11, 99.11, 99.07, 99.08, 99.1, 99.1, 99.1, 99.09, 99.1, 99.1, 99.11, 99.11, 99.13, 99.12, 99.12, 99.12, 99.15, 99.11, 99.11, 99.11, 99.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550016
550021
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.620, Test loss: 1.576, Test accuracy: 30.59
Round   1, Train loss: 1.551, Test loss: 1.427, Test accuracy: 65.29
Round   2, Train loss: 1.350, Test loss: 1.179, Test accuracy: 93.83
Round   3, Train loss: 1.131, Test loss: 1.059, Test accuracy: 95.67
Round   4, Train loss: 1.056, Test loss: 1.028, Test accuracy: 96.16
Round   5, Train loss: 1.046, Test loss: 1.009, Test accuracy: 96.72
Round   6, Train loss: 1.040, Test loss: 0.996, Test accuracy: 97.08
Round   7, Train loss: 1.011, Test loss: 0.995, Test accuracy: 97.12
Round   8, Train loss: 1.015, Test loss: 0.986, Test accuracy: 97.48
Round   9, Train loss: 0.997, Test loss: 0.982, Test accuracy: 97.41
Round  10, Train loss: 0.998, Test loss: 0.978, Test accuracy: 97.52
Round  11, Train loss: 0.999, Test loss: 0.971, Test accuracy: 97.65
Round  12, Train loss: 0.995, Test loss: 0.968, Test accuracy: 97.72
Round  13, Train loss: 0.988, Test loss: 0.967, Test accuracy: 97.88
Round  14, Train loss: 0.992, Test loss: 0.963, Test accuracy: 97.83
Round  15, Train loss: 0.981, Test loss: 0.964, Test accuracy: 97.92
Round  16, Train loss: 0.983, Test loss: 0.961, Test accuracy: 97.98
Round  17, Train loss: 0.976, Test loss: 0.959, Test accuracy: 97.93
Round  18, Train loss: 0.986, Test loss: 0.954, Test accuracy: 98.06
Round  19, Train loss: 0.979, Test loss: 0.952, Test accuracy: 98.03
Round  20, Train loss: 0.980, Test loss: 0.951, Test accuracy: 98.07
Round  21, Train loss: 0.972, Test loss: 0.950, Test accuracy: 98.15
Round  22, Train loss: 0.967, Test loss: 0.951, Test accuracy: 98.17
Round  23, Train loss: 0.972, Test loss: 0.948, Test accuracy: 98.22
Round  24, Train loss: 0.970, Test loss: 0.946, Test accuracy: 98.22
Round  25, Train loss: 0.968, Test loss: 0.945, Test accuracy: 98.23
Round  26, Train loss: 0.961, Test loss: 0.947, Test accuracy: 98.31
Round  27, Train loss: 0.965, Test loss: 0.944, Test accuracy: 98.35
Round  28, Train loss: 0.963, Test loss: 0.943, Test accuracy: 98.39
Round  29, Train loss: 0.958, Test loss: 0.943, Test accuracy: 98.40
Round  30, Train loss: 0.962, Test loss: 0.941, Test accuracy: 98.38
Round  31, Train loss: 0.956, Test loss: 0.942, Test accuracy: 98.37
Round  32, Train loss: 0.959, Test loss: 0.942, Test accuracy: 98.43
Round  33, Train loss: 0.959, Test loss: 0.940, Test accuracy: 98.46
Round  34, Train loss: 0.951, Test loss: 0.941, Test accuracy: 98.42
Round  35, Train loss: 0.953, Test loss: 0.940, Test accuracy: 98.45
Round  36, Train loss: 0.955, Test loss: 0.938, Test accuracy: 98.46
Round  37, Train loss: 0.951, Test loss: 0.939, Test accuracy: 98.49
Round  38, Train loss: 0.954, Test loss: 0.938, Test accuracy: 98.55
Round  39, Train loss: 0.956, Test loss: 0.937, Test accuracy: 98.61
Round  40, Train loss: 0.950, Test loss: 0.938, Test accuracy: 98.65
Round  41, Train loss: 0.951, Test loss: 0.937, Test accuracy: 98.64
Round  42, Train loss: 0.953, Test loss: 0.936, Test accuracy: 98.73
Round  43, Train loss: 0.950, Test loss: 0.937, Test accuracy: 98.71
Round  44, Train loss: 0.950, Test loss: 0.936, Test accuracy: 98.67
Round  45, Train loss: 0.950, Test loss: 0.936, Test accuracy: 98.71
Round  46, Train loss: 0.945, Test loss: 0.935, Test accuracy: 98.71
Round  47, Train loss: 0.948, Test loss: 0.935, Test accuracy: 98.71
Round  48, Train loss: 0.944, Test loss: 0.935, Test accuracy: 98.75
Round  49, Train loss: 0.945, Test loss: 0.936, Test accuracy: 98.80
Round  50, Train loss: 0.944, Test loss: 0.935, Test accuracy: 98.74
Round  51, Train loss: 0.943, Test loss: 0.934, Test accuracy: 98.69
Round  52, Train loss: 0.941, Test loss: 0.935, Test accuracy: 98.72
Round  53, Train loss: 0.944, Test loss: 0.934, Test accuracy: 98.79
Round  54, Train loss: 0.942, Test loss: 0.934, Test accuracy: 98.75
Round  55, Train loss: 0.943, Test loss: 0.933, Test accuracy: 98.78
Round  56, Train loss: 0.942, Test loss: 0.933, Test accuracy: 98.82
Round  57, Train loss: 0.945, Test loss: 0.932, Test accuracy: 98.85
Round  58, Train loss: 0.943, Test loss: 0.933, Test accuracy: 98.88
Round  59, Train loss: 0.944, Test loss: 0.932, Test accuracy: 98.85
Round  60, Train loss: 0.940, Test loss: 0.933, Test accuracy: 98.83
Round  61, Train loss: 0.942, Test loss: 0.932, Test accuracy: 98.89
Round  62, Train loss: 0.941, Test loss: 0.931, Test accuracy: 98.88
Round  63, Train loss: 0.938, Test loss: 0.932, Test accuracy: 98.90
Round  64, Train loss: 0.940, Test loss: 0.930, Test accuracy: 98.90
Round  65, Train loss: 0.940, Test loss: 0.931, Test accuracy: 98.91
Round  66, Train loss: 0.939, Test loss: 0.931, Test accuracy: 98.88
Round  67, Train loss: 0.940, Test loss: 0.931, Test accuracy: 98.90
Round  68, Train loss: 0.941, Test loss: 0.930, Test accuracy: 98.94
Round  69, Train loss: 0.939, Test loss: 0.929, Test accuracy: 98.94
Round  70, Train loss: 0.937, Test loss: 0.930, Test accuracy: 98.92
Round  71, Train loss: 0.938, Test loss: 0.930, Test accuracy: 98.89
Round  72, Train loss: 0.937, Test loss: 0.929, Test accuracy: 98.92
Round  73, Train loss: 0.936, Test loss: 0.930, Test accuracy: 98.94
Round  74, Train loss: 0.938, Test loss: 0.929, Test accuracy: 98.93
Round  75, Train loss: 0.934, Test loss: 0.929, Test accuracy: 98.95
Round  76, Train loss: 0.935, Test loss: 0.930, Test accuracy: 98.97
Round  77, Train loss: 0.937, Test loss: 0.929, Test accuracy: 99.00
Round  78, Train loss: 0.938, Test loss: 0.928, Test accuracy: 99.07
Round  79, Train loss: 0.936, Test loss: 0.929, Test accuracy: 99.01
Round  80, Train loss: 0.936, Test loss: 0.929, Test accuracy: 99.04
Round  81, Train loss: 0.934, Test loss: 0.929, Test accuracy: 98.98
Round  82, Train loss: 0.937, Test loss: 0.928, Test accuracy: 98.98
Round  83, Train loss: 0.935, Test loss: 0.928, Test accuracy: 99.01
Round  84, Train loss: 0.933, Test loss: 0.928, Test accuracy: 99.00
Round  85, Train loss: 0.935, Test loss: 0.928, Test accuracy: 98.98
Round  86, Train loss: 0.933, Test loss: 0.929, Test accuracy: 99.00
Round  87, Train loss: 0.933, Test loss: 0.928, Test accuracy: 99.02
Round  88, Train loss: 0.933, Test loss: 0.928, Test accuracy: 98.99
Round  89, Train loss: 0.932, Test loss: 0.928, Test accuracy: 98.99
Round  90, Train loss: 0.935, Test loss: 0.927, Test accuracy: 99.01
Round  91, Train loss: 0.932, Test loss: 0.928, Test accuracy: 99.01
Round  92, Train loss: 0.934, Test loss: 0.928, Test accuracy: 99.00
Round  93, Train loss: 0.933, Test loss: 0.928, Test accuracy: 99.03
Round  94, Train loss: 0.932, Test loss: 0.927, Test accuracy: 99.03
Round  95, Train loss: 0.933, Test loss: 0.927, Test accuracy: 99.05
Round  96, Train loss: 0.932, Test loss: 0.927, Test accuracy: 99.04
Round  97, Train loss: 0.933, Test loss: 0.927, Test accuracy: 99.06
Round  98, Train loss: 0.932, Test loss: 0.927, Test accuracy: 99.06
Round  99, Train loss: 0.932, Test loss: 0.927, Test accuracy: 99.04
Round 100, Train loss: 0.931, Test loss: 0.926, Test accuracy: 99.04
Round 101, Train loss: 0.930, Test loss: 0.927, Test accuracy: 99.03
Round 102, Train loss: 0.932, Test loss: 0.927, Test accuracy: 99.05
Round 103, Train loss: 0.931, Test loss: 0.927, Test accuracy: 99.03
Round 104, Train loss: 0.930, Test loss: 0.927, Test accuracy: 99.06
Round 105, Train loss: 0.932, Test loss: 0.926, Test accuracy: 99.06
Round 106, Train loss: 0.930, Test loss: 0.927, Test accuracy: 99.06
Round 107, Train loss: 0.932, Test loss: 0.926, Test accuracy: 99.07
Round 108, Train loss: 0.932, Test loss: 0.925, Test accuracy: 99.10
Round 109, Train loss: 0.931, Test loss: 0.925, Test accuracy: 99.09
Round 110, Train loss: 0.931, Test loss: 0.926, Test accuracy: 99.06
Round 111, Train loss: 0.931, Test loss: 0.925, Test accuracy: 99.05
Round 112, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.08
Round 113, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.12
Round 114, Train loss: 0.930, Test loss: 0.925, Test accuracy: 99.10
Round 115, Train loss: 0.930, Test loss: 0.925, Test accuracy: 99.13
Round 116, Train loss: 0.930, Test loss: 0.925, Test accuracy: 99.07
Round 117, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.08
Round 118, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.08
Round 119, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.08
Round 120, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.10
Round 121, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.09
Round 122, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.13
Round 123, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.14
Round 124, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.12
Round 125, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.10
Round 126, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.13
Round 127, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.11
Round 128, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.16
Round 129, Train loss: 0.927, Test loss: 0.925, Test accuracy: 99.17
Round 130, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.12
Round 131, Train loss: 0.929, Test loss: 0.924, Test accuracy: 99.12
Round 132, Train loss: 0.927, Test loss: 0.925, Test accuracy: 99.13
Round 133, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.10
Round 134, Train loss: 0.929, Test loss: 0.924, Test accuracy: 99.12
Round 135, Train loss: 0.928, Test loss: 0.925, Test accuracy: 99.13
Round 136, Train loss: 0.929, Test loss: 0.925, Test accuracy: 99.13
Round 137, Train loss: 0.927, Test loss: 0.925, Test accuracy: 99.10
Round 138, Train loss: 0.929, Test loss: 0.924, Test accuracy: 99.09
Round 139, Train loss: 0.928, Test loss: 0.924, Test accuracy: 99.12
Round 140, Train loss: 0.927, Test loss: 0.925, Test accuracy: 99.10
Round 141, Train loss: 0.927, Test loss: 0.924, Test accuracy: 99.10
Round 142, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.13
Round 143, Train loss: 0.927, Test loss: 0.923, Test accuracy: 99.14
Round 144, Train loss: 0.927, Test loss: 0.924, Test accuracy: 99.15
Round 145, Train loss: 0.927, Test loss: 0.924, Test accuracy: 99.19
Round 146, Train loss: 0.927, Test loss: 0.924, Test accuracy: 99.13
Round 147, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.17
Round 148, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.14
Round 149, Train loss: 0.927, Test loss: 0.924, Test accuracy: 99.15
Round 150, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.14
Round 151, Train loss: 0.927, Test loss: 0.924, Test accuracy: 99.17
Round 152, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.21
Round 153, Train loss: 0.927, Test loss: 0.923, Test accuracy: 99.17
Round 154, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.17
Round 155, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.16
Round 156, Train loss: 0.926, Test loss: 0.924, Test accuracy: 99.14
Round 157, Train loss: 0.925, Test loss: 0.924, Test accuracy: 99.17
Round 158, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.19
Round 159, Train loss: 0.927, Test loss: 0.923, Test accuracy: 99.21
Round 160, Train loss: 0.927, Test loss: 0.923, Test accuracy: 99.17
Round 161, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.18
Round 162, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.21
Round 163, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.20
Round 164, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.19
Round 165, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.21
Round 166, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.21
Round 167, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.18
Round 168, Train loss: 0.927, Test loss: 0.923, Test accuracy: 99.13
Round 169, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.15
Round 170, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.17
Round 171, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.13
Round 172, Train loss: 0.925, Test loss: 0.922, Test accuracy: 99.20
Round 173, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.18
Round 174, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.08
Round 175, Train loss: 0.924, Test loss: 0.923, Test accuracy: 99.14
Round 176, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.15
Round 177, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.14
Round 178, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.09
Round 179, Train loss: 0.925, Test loss: 0.922, Test accuracy: 99.15
Round 180, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.13
Round 181, Train loss: 0.925, Test loss: 0.922, Test accuracy: 99.15
Round 182, Train loss: 0.926, Test loss: 0.922, Test accuracy: 99.20
Round 183, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.14
Round 184, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.11
Round 185, Train loss: 0.924, Test loss: 0.923, Test accuracy: 99.14
Round 186, Train loss: 0.925, Test loss: 0.922, Test accuracy: 99.16
Round 187, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.15
Round 188, Train loss: 0.925, Test loss: 0.923, Test accuracy: 99.14
Round 189, Train loss: 0.924, Test loss: 0.923, Test accuracy: 99.14
Round 190, Train loss: 0.926, Test loss: 0.923, Test accuracy: 99.14
Round 191, Train loss: 0.924, Test loss: 0.923, Test accuracy: 99.14
Round 192, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.14
Round 193, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.16
Round 194, Train loss: 0.924, Test loss: 0.923, Test accuracy: 99.17
Round 195, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.17
Round 196, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.14
Round 197, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.14
Round 198, Train loss: 0.924, Test loss: 0.923, Test accuracy: 99.12
Round 199, Train loss: 0.924, Test loss: 0.922, Test accuracy: 99.12
Final Round, Train loss: 0.911, Test loss: 0.922, Test accuracy: 99.14
Average accuracy final 10 rounds: 99.14400000000002
2173.872742652893
[1.2627792358398438, 2.5255584716796875, 3.6943602561950684, 4.863162040710449, 6.019865036010742, 7.176568031311035, 8.351057529449463, 9.52554702758789, 10.694104194641113, 11.862661361694336, 13.083072900772095, 14.303484439849854, 15.460115671157837, 16.61674690246582, 17.792404413223267, 18.968061923980713, 20.045896530151367, 21.12373113632202, 22.240851402282715, 23.357971668243408, 24.476152896881104, 25.5943341255188, 26.727218866348267, 27.860103607177734, 28.804400205612183, 29.74869680404663, 30.691760778427124, 31.634824752807617, 32.572263956069946, 33.509703159332275, 34.47309446334839, 35.4364857673645, 36.38067102432251, 37.32485628128052, 38.27556848526001, 39.2262806892395, 40.180134773254395, 41.13398885726929, 42.12234663963318, 43.11070442199707, 44.121861696243286, 45.1330189704895, 46.116973876953125, 47.10092878341675, 48.12159252166748, 49.14225625991821, 50.09253430366516, 51.04281234741211, 51.984413862228394, 52.92601537704468, 53.88957738876343, 54.85313940048218, 55.782407999038696, 56.711676597595215, 57.6619188785553, 58.61216115951538, 59.63170051574707, 60.65123987197876, 61.600427865982056, 62.54961585998535, 63.48803663253784, 64.42645740509033, 65.43118166923523, 66.43590593338013, 67.39665269851685, 68.35739946365356, 69.3056058883667, 70.25381231307983, 71.23047208786011, 72.20713186264038, 73.15108966827393, 74.09504747390747, 75.0610601902008, 76.02707290649414, 76.96195888519287, 77.8968448638916, 78.8774185180664, 79.85799217224121, 80.80964136123657, 81.76129055023193, 82.71063566207886, 83.65998077392578, 84.66005778312683, 85.66013479232788, 86.63044762611389, 87.6007604598999, 88.60621237754822, 89.61166429519653, 90.55869841575623, 91.50573253631592, 92.44095349311829, 93.37617444992065, 94.32458806037903, 95.2730016708374, 96.21649670600891, 97.15999174118042, 98.14023327827454, 99.12047481536865, 100.06963920593262, 101.01880359649658, 101.95339608192444, 102.8879885673523, 103.83189797401428, 104.77580738067627, 105.65486288070679, 106.5339183807373, 107.43704342842102, 108.34016847610474, 109.2378203868866, 110.13547229766846, 111.04036664962769, 111.94526100158691, 112.89595293998718, 113.84664487838745, 114.8068118095398, 115.76697874069214, 116.72263169288635, 117.67828464508057, 118.61918020248413, 119.5600757598877, 120.5146906375885, 121.4693055152893, 122.42029333114624, 123.37128114700317, 124.34444189071655, 125.31760263442993, 126.26841330528259, 127.21922397613525, 128.12906002998352, 129.0388960838318, 129.99071431159973, 130.94253253936768, 131.90110683441162, 132.85968112945557, 133.8112506866455, 134.76282024383545, 135.71212792396545, 136.66143560409546, 137.60025930404663, 138.5390830039978, 139.47351574897766, 140.40794849395752, 141.35950350761414, 142.31105852127075, 143.26731967926025, 144.22358083724976, 145.1659653186798, 146.10834980010986, 147.05031371116638, 147.9922776222229, 148.91629433631897, 149.84031105041504, 150.7830183506012, 151.72572565078735, 152.6748502254486, 153.62397480010986, 154.64132475852966, 155.65867471694946, 156.88766622543335, 158.11665773391724, 159.13726139068604, 160.15786504745483, 161.1887640953064, 162.21966314315796, 163.26590251922607, 164.3121418952942, 165.34061312675476, 166.36908435821533, 167.42823195457458, 168.48737955093384, 169.4860463142395, 170.48471307754517, 171.48942923545837, 172.49414539337158, 173.51127815246582, 174.52841091156006, 175.5181655883789, 176.50792026519775, 177.49138522148132, 178.4748501777649, 179.48268723487854, 180.4905242919922, 181.48885297775269, 182.48718166351318, 183.51257491111755, 184.53796815872192, 185.4832239151001, 186.42847967147827, 187.37297821044922, 188.31747674942017, 189.23836302757263, 190.1592493057251, 191.109876871109, 192.06050443649292, 193.00828504562378, 193.95606565475464, 194.96163153648376, 195.9671974182129, 196.9935576915741, 198.0199179649353, 199.01847767829895, 200.0170373916626, 200.94113206863403, 201.86522674560547, 202.81017184257507, 203.75511693954468, 204.70699548721313, 205.6588740348816, 206.61192178726196, 207.56496953964233, 208.4929552078247, 209.42094087600708, 210.34913277626038, 211.27732467651367, 212.19734477996826, 213.11736488342285, 214.05573797225952, 214.9941110610962, 215.93679976463318, 216.87948846817017, 217.78963327407837, 218.69977807998657, 219.63872909545898, 220.5776801109314, 221.49877905845642, 222.41987800598145, 223.37747859954834, 224.33507919311523, 225.2842926979065, 226.23350620269775, 227.24235320091248, 228.2512001991272, 229.25003957748413, 230.24887895584106, 231.2336404323578, 232.2184019088745, 233.19672441482544, 234.17504692077637, 235.13211131095886, 236.08917570114136, 237.05086636543274, 238.01255702972412, 238.96867418289185, 239.92479133605957, 240.8578863143921, 241.7909812927246, 242.76417684555054, 243.73737239837646, 244.7451364994049, 245.75290060043335, 246.7221975326538, 247.69149446487427, 248.67112803459167, 249.65076160430908, 250.58569192886353, 251.52062225341797, 252.40042638778687, 253.28023052215576, 254.15212059020996, 255.02401065826416, 255.9117090702057, 256.7994074821472, 257.6906430721283, 258.5818786621094, 259.4705181121826, 260.35915756225586, 261.24655055999756, 262.13394355773926, 263.00479888916016, 263.87565422058105, 264.77042746543884, 265.66520071029663, 266.56393814086914, 267.46267557144165, 268.3644754886627, 269.2662754058838, 270.1405324935913, 271.0147895812988, 271.90048265457153, 272.78617572784424, 273.6721727848053, 274.55816984176636, 275.45920753479004, 276.3602452278137, 277.25381994247437, 278.147394657135, 279.04316997528076, 279.9389452934265, 280.82470631599426, 281.710467338562, 282.5870478153229, 283.46362829208374, 284.36024808883667, 285.2568678855896, 286.1533033847809, 287.04973888397217, 287.9468183517456, 288.84389781951904, 289.72905707359314, 290.61421632766724, 291.49364280700684, 292.37306928634644, 293.26884841918945, 294.16462755203247, 295.0742280483246, 295.9838285446167, 296.9500575065613, 297.91628646850586, 298.86826181411743, 299.820237159729, 300.7955234050751, 301.77080965042114, 302.83314847946167, 303.8954873085022, 304.97506499290466, 306.05464267730713, 307.13856410980225, 308.22248554229736, 309.2275552749634, 310.2326250076294, 311.21148657798767, 312.19034814834595, 313.1909112930298, 314.1914744377136, 315.1539783477783, 316.116482257843, 317.3653657436371, 318.61424922943115, 319.8577959537506, 321.10134267807007, 322.3746004104614, 323.6478581428528, 324.8279242515564, 326.00799036026, 327.00874066352844, 328.0094909667969, 329.02157759666443, 330.033664226532, 331.0389578342438, 332.04425144195557, 333.063289642334, 334.0823278427124, 335.07029604911804, 336.0582642555237, 337.09656262397766, 338.13486099243164, 339.13447093963623, 340.1340808868408, 341.2177982330322, 342.30151557922363, 343.48271131515503, 344.6639070510864, 345.7388231754303, 346.81373929977417, 347.8037462234497, 348.79375314712524, 349.81694889068604, 350.8401446342468, 351.84789419174194, 352.85564374923706, 353.84236669540405, 354.82908964157104, 355.8093855381012, 356.78968143463135, 357.8099203109741, 358.8301591873169, 359.851215839386, 360.8722724914551, 361.8573853969574, 362.8424983024597, 363.84762811660767, 364.8527579307556, 365.82841897010803, 366.80408000946045, 367.7959740161896, 368.7878680229187, 369.7998220920563, 370.81177616119385, 371.83532667160034, 372.85887718200684, 373.8122799396515, 374.76568269729614, 375.82485795021057, 376.884033203125, 377.9362850189209, 378.9885368347168, 379.9978470802307, 381.00715732574463, 382.0387909412384, 383.0704245567322, 384.11647033691406, 385.16251611709595, 386.19425892829895, 387.22600173950195, 388.215633392334, 389.205265045166, 390.20196437835693, 391.19866371154785, 392.1841413974762, 393.16961908340454, 394.6400284767151, 396.11043787002563]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[30.59, 30.59, 65.29, 65.29, 93.83, 93.83, 95.67, 95.67, 96.16, 96.16, 96.72, 96.72, 97.08, 97.08, 97.12, 97.12, 97.48, 97.48, 97.41, 97.41, 97.52, 97.52, 97.65, 97.65, 97.72, 97.72, 97.88, 97.88, 97.83, 97.83, 97.92, 97.92, 97.98, 97.98, 97.93, 97.93, 98.06, 98.06, 98.03, 98.03, 98.07, 98.07, 98.15, 98.15, 98.17, 98.17, 98.22, 98.22, 98.22, 98.22, 98.23, 98.23, 98.31, 98.31, 98.35, 98.35, 98.39, 98.39, 98.4, 98.4, 98.38, 98.38, 98.37, 98.37, 98.43, 98.43, 98.46, 98.46, 98.42, 98.42, 98.45, 98.45, 98.46, 98.46, 98.49, 98.49, 98.55, 98.55, 98.61, 98.61, 98.65, 98.65, 98.64, 98.64, 98.73, 98.73, 98.71, 98.71, 98.67, 98.67, 98.71, 98.71, 98.71, 98.71, 98.71, 98.71, 98.75, 98.75, 98.8, 98.8, 98.74, 98.74, 98.69, 98.69, 98.72, 98.72, 98.79, 98.79, 98.75, 98.75, 98.78, 98.78, 98.82, 98.82, 98.85, 98.85, 98.88, 98.88, 98.85, 98.85, 98.83, 98.83, 98.89, 98.89, 98.88, 98.88, 98.9, 98.9, 98.9, 98.9, 98.91, 98.91, 98.88, 98.88, 98.9, 98.9, 98.94, 98.94, 98.94, 98.94, 98.92, 98.92, 98.89, 98.89, 98.92, 98.92, 98.94, 98.94, 98.93, 98.93, 98.95, 98.95, 98.97, 98.97, 99.0, 99.0, 99.07, 99.07, 99.01, 99.01, 99.04, 99.04, 98.98, 98.98, 98.98, 98.98, 99.01, 99.01, 99.0, 99.0, 98.98, 98.98, 99.0, 99.0, 99.02, 99.02, 98.99, 98.99, 98.99, 98.99, 99.01, 99.01, 99.01, 99.01, 99.0, 99.0, 99.03, 99.03, 99.03, 99.03, 99.05, 99.05, 99.04, 99.04, 99.06, 99.06, 99.06, 99.06, 99.04, 99.04, 99.04, 99.04, 99.03, 99.03, 99.05, 99.05, 99.03, 99.03, 99.06, 99.06, 99.06, 99.06, 99.06, 99.06, 99.07, 99.07, 99.1, 99.1, 99.09, 99.09, 99.06, 99.06, 99.05, 99.05, 99.08, 99.08, 99.12, 99.12, 99.1, 99.1, 99.13, 99.13, 99.07, 99.07, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.1, 99.1, 99.09, 99.09, 99.13, 99.13, 99.14, 99.14, 99.12, 99.12, 99.1, 99.1, 99.13, 99.13, 99.11, 99.11, 99.16, 99.16, 99.17, 99.17, 99.12, 99.12, 99.12, 99.12, 99.13, 99.13, 99.1, 99.1, 99.12, 99.12, 99.13, 99.13, 99.13, 99.13, 99.1, 99.1, 99.09, 99.09, 99.12, 99.12, 99.1, 99.1, 99.1, 99.1, 99.13, 99.13, 99.14, 99.14, 99.15, 99.15, 99.19, 99.19, 99.13, 99.13, 99.17, 99.17, 99.14, 99.14, 99.15, 99.15, 99.14, 99.14, 99.17, 99.17, 99.21, 99.21, 99.17, 99.17, 99.17, 99.17, 99.16, 99.16, 99.14, 99.14, 99.17, 99.17, 99.19, 99.19, 99.21, 99.21, 99.17, 99.17, 99.18, 99.18, 99.21, 99.21, 99.2, 99.2, 99.19, 99.19, 99.21, 99.21, 99.21, 99.21, 99.18, 99.18, 99.13, 99.13, 99.15, 99.15, 99.17, 99.17, 99.13, 99.13, 99.2, 99.2, 99.18, 99.18, 99.08, 99.08, 99.14, 99.14, 99.15, 99.15, 99.14, 99.14, 99.09, 99.09, 99.15, 99.15, 99.13, 99.13, 99.15, 99.15, 99.2, 99.2, 99.14, 99.14, 99.11, 99.11, 99.14, 99.14, 99.16, 99.16, 99.15, 99.15, 99.14, 99.14, 99.14, 99.14, 99.14, 99.14, 99.14, 99.14, 99.14, 99.14, 99.16, 99.16, 99.17, 99.17, 99.17, 99.17, 99.14, 99.14, 99.14, 99.14, 99.12, 99.12, 99.12, 99.12, 99.14, 99.14]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.288, Test accuracy: 23.57
Round   0, Global train loss: 2.288, Global test loss: 2.297, Global test accuracy: 19.76
Round   1, Train loss: 2.201, Test loss: 2.208, Test accuracy: 24.92
Round   1, Global train loss: 2.201, Global test loss: 2.258, Global test accuracy: 11.42
Round   2, Train loss: 2.025, Test loss: 2.057, Test accuracy: 45.70
Round   2, Global train loss: 2.025, Global test loss: 2.138, Global test accuracy: 35.80
Round   3, Train loss: 1.814, Test loss: 1.918, Test accuracy: 60.25
Round   3, Global train loss: 1.814, Global test loss: 1.992, Global test accuracy: 50.80
Round   4, Train loss: 1.787, Test loss: 1.850, Test accuracy: 66.40
Round   4, Global train loss: 1.787, Global test loss: 1.999, Global test accuracy: 54.03
Round   5, Train loss: 1.714, Test loss: 1.798, Test accuracy: 71.85
Round   5, Global train loss: 1.714, Global test loss: 2.081, Global test accuracy: 49.25
Round   6, Train loss: 1.653, Test loss: 1.767, Test accuracy: 73.75
Round   6, Global train loss: 1.653, Global test loss: 1.998, Global test accuracy: 45.26
Round   7, Train loss: 1.715, Test loss: 1.712, Test accuracy: 80.18
Round   7, Global train loss: 1.715, Global test loss: 1.996, Global test accuracy: 48.00
Round   8, Train loss: 1.670, Test loss: 1.691, Test accuracy: 81.01
Round   8, Global train loss: 1.670, Global test loss: 1.983, Global test accuracy: 48.50
Round   9, Train loss: 1.633, Test loss: 1.657, Test accuracy: 84.11
Round   9, Global train loss: 1.633, Global test loss: 1.955, Global test accuracy: 55.91
Round  10, Train loss: 1.563, Test loss: 1.653, Test accuracy: 84.19
Round  10, Global train loss: 1.563, Global test loss: 2.028, Global test accuracy: 45.16
Round  11, Train loss: 1.556, Test loss: 1.627, Test accuracy: 86.74
Round  11, Global train loss: 1.556, Global test loss: 2.084, Global test accuracy: 36.62
Round  12, Train loss: 1.562, Test loss: 1.623, Test accuracy: 87.09
Round  12, Global train loss: 1.562, Global test loss: 1.935, Global test accuracy: 57.61
Round  13, Train loss: 1.533, Test loss: 1.614, Test accuracy: 87.61
Round  13, Global train loss: 1.533, Global test loss: 1.916, Global test accuracy: 61.08
Round  14, Train loss: 1.538, Test loss: 1.604, Test accuracy: 88.54
Round  14, Global train loss: 1.538, Global test loss: 1.959, Global test accuracy: 52.93
Round  15, Train loss: 1.563, Test loss: 1.583, Test accuracy: 89.83
Round  15, Global train loss: 1.563, Global test loss: 1.908, Global test accuracy: 61.62
Round  16, Train loss: 1.523, Test loss: 1.576, Test accuracy: 90.24
Round  16, Global train loss: 1.523, Global test loss: 1.885, Global test accuracy: 60.31
Round  17, Train loss: 1.481, Test loss: 1.575, Test accuracy: 90.33
Round  17, Global train loss: 1.481, Global test loss: 1.992, Global test accuracy: 47.57
Round  18, Train loss: 1.524, Test loss: 1.572, Test accuracy: 90.34
Round  18, Global train loss: 1.524, Global test loss: 2.016, Global test accuracy: 42.36
Round  19, Train loss: 1.493, Test loss: 1.568, Test accuracy: 90.42
Round  19, Global train loss: 1.493, Global test loss: 2.033, Global test accuracy: 43.00
Round  20, Train loss: 1.512, Test loss: 1.567, Test accuracy: 90.46
Round  20, Global train loss: 1.512, Global test loss: 1.889, Global test accuracy: 58.72
Round  21, Train loss: 1.513, Test loss: 1.566, Test accuracy: 90.49
Round  21, Global train loss: 1.513, Global test loss: 1.956, Global test accuracy: 52.13
Round  22, Train loss: 1.530, Test loss: 1.554, Test accuracy: 91.78
Round  22, Global train loss: 1.530, Global test loss: 1.940, Global test accuracy: 55.93
Round  23, Train loss: 1.482, Test loss: 1.552, Test accuracy: 91.91
Round  23, Global train loss: 1.482, Global test loss: 1.943, Global test accuracy: 55.03
Round  24, Train loss: 1.496, Test loss: 1.546, Test accuracy: 92.67
Round  24, Global train loss: 1.496, Global test loss: 1.889, Global test accuracy: 63.92
Round  25, Train loss: 1.488, Test loss: 1.540, Test accuracy: 93.08
Round  25, Global train loss: 1.488, Global test loss: 1.920, Global test accuracy: 55.54
Round  26, Train loss: 1.486, Test loss: 1.538, Test accuracy: 93.15
Round  26, Global train loss: 1.486, Global test loss: 1.894, Global test accuracy: 61.94
Round  27, Train loss: 1.474, Test loss: 1.538, Test accuracy: 93.20
Round  27, Global train loss: 1.474, Global test loss: 1.922, Global test accuracy: 54.34
Round  28, Train loss: 1.471, Test loss: 1.538, Test accuracy: 93.11
Round  28, Global train loss: 1.471, Global test loss: 2.046, Global test accuracy: 40.92
Round  29, Train loss: 1.475, Test loss: 1.538, Test accuracy: 93.06
Round  29, Global train loss: 1.475, Global test loss: 2.058, Global test accuracy: 39.91
Round  30, Train loss: 1.473, Test loss: 1.538, Test accuracy: 93.05
Round  30, Global train loss: 1.473, Global test loss: 1.939, Global test accuracy: 53.00
Round  31, Train loss: 1.472, Test loss: 1.537, Test accuracy: 93.04
Round  31, Global train loss: 1.472, Global test loss: 1.968, Global test accuracy: 49.08
Round  32, Train loss: 1.478, Test loss: 1.537, Test accuracy: 93.08
Round  32, Global train loss: 1.478, Global test loss: 2.036, Global test accuracy: 44.03
Round  33, Train loss: 1.476, Test loss: 1.537, Test accuracy: 93.06
Round  33, Global train loss: 1.476, Global test loss: 2.020, Global test accuracy: 44.31
Round  34, Train loss: 1.471, Test loss: 1.537, Test accuracy: 93.05
Round  34, Global train loss: 1.471, Global test loss: 1.978, Global test accuracy: 48.63
Round  35, Train loss: 1.469, Test loss: 1.536, Test accuracy: 93.09
Round  35, Global train loss: 1.469, Global test loss: 1.927, Global test accuracy: 53.51
Round  36, Train loss: 1.469, Test loss: 1.536, Test accuracy: 93.12
Round  36, Global train loss: 1.469, Global test loss: 1.979, Global test accuracy: 48.26
Round  37, Train loss: 1.474, Test loss: 1.536, Test accuracy: 93.09
Round  37, Global train loss: 1.474, Global test loss: 1.963, Global test accuracy: 50.48
Round  38, Train loss: 1.473, Test loss: 1.536, Test accuracy: 93.15
Round  38, Global train loss: 1.473, Global test loss: 2.021, Global test accuracy: 43.73
Round  39, Train loss: 1.474, Test loss: 1.536, Test accuracy: 93.17
Round  39, Global train loss: 1.474, Global test loss: 1.973, Global test accuracy: 51.84
Round  40, Train loss: 1.475, Test loss: 1.535, Test accuracy: 93.25
Round  40, Global train loss: 1.475, Global test loss: 2.130, Global test accuracy: 31.92
Round  41, Train loss: 1.471, Test loss: 1.535, Test accuracy: 93.28
Round  41, Global train loss: 1.471, Global test loss: 1.877, Global test accuracy: 65.13
Round  42, Train loss: 1.472, Test loss: 1.535, Test accuracy: 93.29
Round  42, Global train loss: 1.472, Global test loss: 2.022, Global test accuracy: 41.94
Round  43, Train loss: 1.476, Test loss: 1.534, Test accuracy: 93.30
Round  43, Global train loss: 1.476, Global test loss: 2.093, Global test accuracy: 34.45
Round  44, Train loss: 1.469, Test loss: 1.534, Test accuracy: 93.31
Round  44, Global train loss: 1.469, Global test loss: 1.977, Global test accuracy: 49.35
Round  45, Train loss: 1.466, Test loss: 1.534, Test accuracy: 93.32
Round  45, Global train loss: 1.466, Global test loss: 1.882, Global test accuracy: 58.38
Round  46, Train loss: 1.468, Test loss: 1.534, Test accuracy: 93.30
Round  46, Global train loss: 1.468, Global test loss: 1.939, Global test accuracy: 53.33
Round  47, Train loss: 1.474, Test loss: 1.534, Test accuracy: 93.37
Round  47, Global train loss: 1.474, Global test loss: 1.945, Global test accuracy: 52.30
Round  48, Train loss: 1.472, Test loss: 1.534, Test accuracy: 93.36
Round  48, Global train loss: 1.472, Global test loss: 1.926, Global test accuracy: 59.73
Round  49, Train loss: 1.473, Test loss: 1.534, Test accuracy: 93.31
Round  49, Global train loss: 1.473, Global test loss: 1.906, Global test accuracy: 57.43
Round  50, Train loss: 1.471, Test loss: 1.534, Test accuracy: 93.31
Round  50, Global train loss: 1.471, Global test loss: 1.929, Global test accuracy: 57.80
Round  51, Train loss: 1.471, Test loss: 1.534, Test accuracy: 93.28
Round  51, Global train loss: 1.471, Global test loss: 1.974, Global test accuracy: 47.73
Round  52, Train loss: 1.471, Test loss: 1.534, Test accuracy: 93.30
Round  52, Global train loss: 1.471, Global test loss: 1.946, Global test accuracy: 54.53
Round  53, Train loss: 1.474, Test loss: 1.534, Test accuracy: 93.26
Round  53, Global train loss: 1.474, Global test loss: 2.057, Global test accuracy: 38.23
Round  54, Train loss: 1.471, Test loss: 1.534, Test accuracy: 93.22
Round  54, Global train loss: 1.471, Global test loss: 2.055, Global test accuracy: 39.30
Round  55, Train loss: 1.468, Test loss: 1.534, Test accuracy: 93.22
Round  55, Global train loss: 1.468, Global test loss: 1.923, Global test accuracy: 55.66
Round  56, Train loss: 1.469, Test loss: 1.534, Test accuracy: 93.24
Round  56, Global train loss: 1.469, Global test loss: 1.997, Global test accuracy: 44.68
Round  57, Train loss: 1.472, Test loss: 1.534, Test accuracy: 93.24
Round  57, Global train loss: 1.472, Global test loss: 1.996, Global test accuracy: 46.62
Round  58, Train loss: 1.470, Test loss: 1.534, Test accuracy: 93.19
Round  58, Global train loss: 1.470, Global test loss: 2.027, Global test accuracy: 41.13
Round  59, Train loss: 1.475, Test loss: 1.533, Test accuracy: 93.23
Round  59, Global train loss: 1.475, Global test loss: 1.881, Global test accuracy: 63.26
Round  60, Train loss: 1.469, Test loss: 1.533, Test accuracy: 93.26
Round  60, Global train loss: 1.469, Global test loss: 1.927, Global test accuracy: 56.66
Round  61, Train loss: 1.469, Test loss: 1.533, Test accuracy: 93.28
Round  61, Global train loss: 1.469, Global test loss: 2.003, Global test accuracy: 48.67
Round  62, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.28
Round  62, Global train loss: 1.470, Global test loss: 1.965, Global test accuracy: 51.78
Round  63, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.27
Round  63, Global train loss: 1.472, Global test loss: 2.031, Global test accuracy: 41.20
Round  64, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.27
Round  64, Global train loss: 1.472, Global test loss: 2.075, Global test accuracy: 34.51
Round  65, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.26
Round  65, Global train loss: 1.470, Global test loss: 1.988, Global test accuracy: 48.08
Round  66, Train loss: 1.471, Test loss: 1.533, Test accuracy: 93.26
Round  66, Global train loss: 1.471, Global test loss: 1.911, Global test accuracy: 59.37
Round  67, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.28
Round  67, Global train loss: 1.472, Global test loss: 1.996, Global test accuracy: 46.42
Round  68, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.34
Round  68, Global train loss: 1.470, Global test loss: 1.902, Global test accuracy: 57.38
Round  69, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.34
Round  69, Global train loss: 1.470, Global test loss: 1.974, Global test accuracy: 48.07
Round  70, Train loss: 1.468, Test loss: 1.533, Test accuracy: 93.33
Round  70, Global train loss: 1.468, Global test loss: 1.975, Global test accuracy: 51.72
Round  71, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.32
Round  71, Global train loss: 1.470, Global test loss: 2.010, Global test accuracy: 44.17
Round  72, Train loss: 1.467, Test loss: 1.533, Test accuracy: 93.31
Round  72, Global train loss: 1.467, Global test loss: 1.973, Global test accuracy: 48.30
Round  73, Train loss: 1.468, Test loss: 1.533, Test accuracy: 93.33
Round  73, Global train loss: 1.468, Global test loss: 1.900, Global test accuracy: 58.04
Round  74, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.34
Round  74, Global train loss: 1.472, Global test loss: 2.128, Global test accuracy: 31.01
Round  75, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.30
Round  75, Global train loss: 1.472, Global test loss: 2.040, Global test accuracy: 40.83
Round  76, Train loss: 1.469, Test loss: 1.533, Test accuracy: 93.31
Round  76, Global train loss: 1.469, Global test loss: 2.050, Global test accuracy: 40.31
Round  77, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.30
Round  77, Global train loss: 1.470, Global test loss: 2.018, Global test accuracy: 45.38
Round  78, Train loss: 1.471, Test loss: 1.533, Test accuracy: 93.30
Round  78, Global train loss: 1.471, Global test loss: 1.968, Global test accuracy: 50.94
Round  79, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.31
Round  79, Global train loss: 1.470, Global test loss: 2.052, Global test accuracy: 38.75
Round  80, Train loss: 1.471, Test loss: 1.533, Test accuracy: 93.32
Round  80, Global train loss: 1.471, Global test loss: 2.019, Global test accuracy: 42.47
Round  81, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.31
Round  81, Global train loss: 1.469, Global test loss: 2.010, Global test accuracy: 44.88
Round  82, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.35
Round  82, Global train loss: 1.468, Global test loss: 1.953, Global test accuracy: 49.69
Round  83, Train loss: 1.470, Test loss: 1.532, Test accuracy: 93.33
Round  83, Global train loss: 1.470, Global test loss: 2.035, Global test accuracy: 39.23
Round  84, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.32
Round  84, Global train loss: 1.469, Global test loss: 1.892, Global test accuracy: 60.00
Round  85, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.32
Round  85, Global train loss: 1.469, Global test loss: 2.006, Global test accuracy: 44.27
Round  86, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.33
Round  86, Global train loss: 1.469, Global test loss: 1.966, Global test accuracy: 49.75
Round  87, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.34
Round  87, Global train loss: 1.472, Global test loss: 1.899, Global test accuracy: 57.06
Round  88, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.34
Round  88, Global train loss: 1.468, Global test loss: 1.951, Global test accuracy: 52.00
Round  89, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.33
Round  89, Global train loss: 1.469, Global test loss: 2.056, Global test accuracy: 41.15
Round  90, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.33
Round  90, Global train loss: 1.472, Global test loss: 2.085, Global test accuracy: 35.29
Round  91, Train loss: 1.471, Test loss: 1.532, Test accuracy: 93.34
Round  91, Global train loss: 1.471, Global test loss: 2.045, Global test accuracy: 39.44
Round  92, Train loss: 1.467, Test loss: 1.532, Test accuracy: 93.34
Round  92, Global train loss: 1.467, Global test loss: 1.899, Global test accuracy: 60.14
Round  93, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.35
Round  93, Global train loss: 1.472, Global test loss: 2.056, Global test accuracy: 39.65
Round  94, Train loss: 1.470, Test loss: 1.532, Test accuracy: 93.34
Round  94, Global train loss: 1.470, Global test loss: 2.048, Global test accuracy: 40.31
Round  95, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.35
Round  95, Global train loss: 1.468, Global test loss: 1.894, Global test accuracy: 60.17/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.475, Test loss: 1.532, Test accuracy: 93.35
Round  96, Global train loss: 1.475, Global test loss: 2.007, Global test accuracy: 44.46
Round  97, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.34
Round  97, Global train loss: 1.472, Global test loss: 1.976, Global test accuracy: 48.01
Round  98, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.32
Round  98, Global train loss: 1.468, Global test loss: 1.951, Global test accuracy: 51.82
Round  99, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.34
Round  99, Global train loss: 1.469, Global test loss: 1.962, Global test accuracy: 50.55
Final Round, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.37
Final Round, Global train loss: 1.469, Global test loss: 1.962, Global test accuracy: 50.55
Average accuracy final 10 rounds: 93.34 

Average global accuracy final 10 rounds: 46.984 

1167.7910437583923
[0.9390504360198975, 1.878100872039795, 2.717724561691284, 3.5573482513427734, 4.390911340713501, 5.2244744300842285, 6.065160036087036, 6.905845642089844, 7.748708724975586, 8.591571807861328, 9.437478303909302, 10.283384799957275, 11.122023344039917, 11.960661888122559, 12.802227020263672, 13.643792152404785, 14.482553005218506, 15.321313858032227, 16.1706600189209, 17.02000617980957, 17.857561111450195, 18.69511604309082, 19.5262930393219, 20.35747003555298, 21.195622444152832, 22.033774852752686, 22.87020778656006, 23.70664072036743, 24.54244112968445, 25.378241539001465, 26.212511777877808, 27.04678201675415, 27.888356924057007, 28.729931831359863, 29.553388118743896, 30.37684440612793, 31.21517324447632, 32.05350208282471, 32.84252095222473, 33.631539821624756, 34.38620853424072, 35.14087724685669, 35.883251905441284, 36.62562656402588, 37.38068771362305, 38.135748863220215, 38.88943672180176, 39.6431245803833, 40.38574767112732, 41.12837076187134, 41.88191533088684, 42.635459899902344, 43.389235734939575, 44.14301156997681, 44.8901424407959, 45.63727331161499, 46.39026165008545, 47.14324998855591, 47.889604330062866, 48.635958671569824, 49.38328790664673, 50.13061714172363, 50.87212586402893, 51.61363458633423, 52.35223460197449, 53.090834617614746, 53.79291009902954, 54.494985580444336, 55.189268827438354, 55.88355207443237, 56.58280682563782, 57.28206157684326, 57.97254467010498, 58.6630277633667, 59.36396813392639, 60.064908504486084, 60.76896619796753, 61.473023891448975, 62.17465949058533, 62.87629508972168, 63.575852394104004, 64.27540969848633, 64.98043584823608, 65.68546199798584, 66.37622833251953, 67.06699466705322, 67.76460599899292, 68.46221733093262, 69.14749050140381, 69.832763671875, 70.5200309753418, 71.2072982788086, 71.90651392936707, 72.60572957992554, 73.30661153793335, 74.00749349594116, 74.71492576599121, 75.42235803604126, 76.12478184700012, 76.82720565795898, 77.5153877735138, 78.2035698890686, 78.8978705406189, 79.59217119216919, 80.28706860542297, 80.98196601867676, 81.67756032943726, 82.37315464019775, 83.07269597053528, 83.7722373008728, 84.4593415260315, 85.14644575119019, 85.83667850494385, 86.52691125869751, 87.2376914024353, 87.9484715461731, 88.66303563117981, 89.37759971618652, 90.05770015716553, 90.73780059814453, 91.41235208511353, 92.08690357208252, 92.80350828170776, 93.52011299133301, 94.2425971031189, 94.96508121490479, 95.66561508178711, 96.36614894866943, 97.06051754951477, 97.75488615036011, 98.44415020942688, 99.13341426849365, 99.8314573764801, 100.52950048446655, 101.21011114120483, 101.89072179794312, 102.59026098251343, 103.28980016708374, 103.99375748634338, 104.69771480560303, 105.38824081420898, 106.07876682281494, 106.76501059532166, 107.45125436782837, 108.14432644844055, 108.83739852905273, 109.54455780982971, 110.25171709060669, 110.9607298374176, 111.66974258422852, 112.32844066619873, 112.98713874816895, 113.65835404396057, 114.3295693397522, 115.06499314308167, 115.80041694641113, 116.536288022995, 117.27215909957886, 117.99347686767578, 118.7147946357727, 119.40563011169434, 120.09646558761597, 120.77431654930115, 121.45216751098633, 122.15607714653015, 122.85998678207397, 123.57873773574829, 124.29748868942261, 124.99945449829102, 125.70142030715942, 126.38918614387512, 127.07695198059082, 127.76579666137695, 128.4546413421631, 129.1443305015564, 129.8340196609497, 130.53551626205444, 131.23701286315918, 131.930983543396, 132.6249542236328, 133.30778098106384, 133.99060773849487, 134.6863968372345, 135.38218593597412, 136.08879280090332, 136.79539966583252, 137.49397706985474, 138.19255447387695, 138.87913751602173, 139.5657205581665, 140.25607109069824, 140.94642162322998, 141.62833833694458, 142.31025505065918, 142.99932718276978, 143.68839931488037, 144.4026792049408, 145.11695909500122, 145.80993938446045, 146.50291967391968, 147.90902543067932, 149.31513118743896]
[23.57, 23.57, 24.92, 24.92, 45.7, 45.7, 60.25, 60.25, 66.4, 66.4, 71.85, 71.85, 73.75, 73.75, 80.18, 80.18, 81.01, 81.01, 84.11, 84.11, 84.19, 84.19, 86.74, 86.74, 87.09, 87.09, 87.61, 87.61, 88.54, 88.54, 89.83, 89.83, 90.24, 90.24, 90.33, 90.33, 90.34, 90.34, 90.42, 90.42, 90.46, 90.46, 90.49, 90.49, 91.78, 91.78, 91.91, 91.91, 92.67, 92.67, 93.08, 93.08, 93.15, 93.15, 93.2, 93.2, 93.11, 93.11, 93.06, 93.06, 93.05, 93.05, 93.04, 93.04, 93.08, 93.08, 93.06, 93.06, 93.05, 93.05, 93.09, 93.09, 93.12, 93.12, 93.09, 93.09, 93.15, 93.15, 93.17, 93.17, 93.25, 93.25, 93.28, 93.28, 93.29, 93.29, 93.3, 93.3, 93.31, 93.31, 93.32, 93.32, 93.3, 93.3, 93.37, 93.37, 93.36, 93.36, 93.31, 93.31, 93.31, 93.31, 93.28, 93.28, 93.3, 93.3, 93.26, 93.26, 93.22, 93.22, 93.22, 93.22, 93.24, 93.24, 93.24, 93.24, 93.19, 93.19, 93.23, 93.23, 93.26, 93.26, 93.28, 93.28, 93.28, 93.28, 93.27, 93.27, 93.27, 93.27, 93.26, 93.26, 93.26, 93.26, 93.28, 93.28, 93.34, 93.34, 93.34, 93.34, 93.33, 93.33, 93.32, 93.32, 93.31, 93.31, 93.33, 93.33, 93.34, 93.34, 93.3, 93.3, 93.31, 93.31, 93.3, 93.3, 93.3, 93.3, 93.31, 93.31, 93.32, 93.32, 93.31, 93.31, 93.35, 93.35, 93.33, 93.33, 93.32, 93.32, 93.32, 93.32, 93.33, 93.33, 93.34, 93.34, 93.34, 93.34, 93.33, 93.33, 93.33, 93.33, 93.34, 93.34, 93.34, 93.34, 93.35, 93.35, 93.34, 93.34, 93.35, 93.35, 93.35, 93.35, 93.34, 93.34, 93.32, 93.32, 93.34, 93.34, 93.37, 93.37]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.290, Test accuracy: 17.88
Round   0, Global train loss: 2.290, Global test loss: 2.298, Global test accuracy: 12.00
Round   1, Train loss: 2.255, Test loss: 2.245, Test accuracy: 24.30
Round   1, Global train loss: 2.255, Global test loss: 2.268, Global test accuracy: 12.21
Round   2, Train loss: 2.078, Test loss: 2.120, Test accuracy: 44.26
Round   2, Global train loss: 2.078, Global test loss: 2.120, Global test accuracy: 49.88
Round   3, Train loss: 1.860, Test loss: 2.002, Test accuracy: 48.84
Round   3, Global train loss: 1.860, Global test loss: 2.036, Global test accuracy: 45.57
Round   4, Train loss: 1.845, Test loss: 1.913, Test accuracy: 58.03
Round   4, Global train loss: 1.845, Global test loss: 1.914, Global test accuracy: 60.86
Round   5, Train loss: 1.707, Test loss: 1.828, Test accuracy: 65.45
Round   5, Global train loss: 1.707, Global test loss: 1.829, Global test accuracy: 66.70
Round   6, Train loss: 1.708, Test loss: 1.795, Test accuracy: 67.77
Round   6, Global train loss: 1.708, Global test loss: 1.829, Global test accuracy: 65.44
Round   7, Train loss: 1.685, Test loss: 1.780, Test accuracy: 68.84
Round   7, Global train loss: 1.685, Global test loss: 1.792, Global test accuracy: 68.18
Round   8, Train loss: 1.644, Test loss: 1.760, Test accuracy: 70.96
Round   8, Global train loss: 1.644, Global test loss: 1.770, Global test accuracy: 71.90
Round   9, Train loss: 1.636, Test loss: 1.724, Test accuracy: 73.90
Round   9, Global train loss: 1.636, Global test loss: 1.758, Global test accuracy: 71.27
Round  10, Train loss: 1.612, Test loss: 1.721, Test accuracy: 74.08
Round  10, Global train loss: 1.612, Global test loss: 1.749, Global test accuracy: 72.93
Round  11, Train loss: 1.671, Test loss: 1.676, Test accuracy: 79.02
Round  11, Global train loss: 1.671, Global test loss: 1.736, Global test accuracy: 74.27
Round  12, Train loss: 1.659, Test loss: 1.674, Test accuracy: 79.14
Round  12, Global train loss: 1.659, Global test loss: 1.732, Global test accuracy: 74.16
Round  13, Train loss: 1.661, Test loss: 1.673, Test accuracy: 79.21
Round  13, Global train loss: 1.661, Global test loss: 1.744, Global test accuracy: 71.90
Round  14, Train loss: 1.729, Test loss: 1.672, Test accuracy: 79.31
Round  14, Global train loss: 1.729, Global test loss: 1.730, Global test accuracy: 74.03
Round  15, Train loss: 1.658, Test loss: 1.671, Test accuracy: 79.32
Round  15, Global train loss: 1.658, Global test loss: 1.747, Global test accuracy: 72.89
Round  16, Train loss: 1.690, Test loss: 1.661, Test accuracy: 80.32
Round  16, Global train loss: 1.690, Global test loss: 1.746, Global test accuracy: 71.59
Round  17, Train loss: 1.604, Test loss: 1.629, Test accuracy: 83.77
Round  17, Global train loss: 1.604, Global test loss: 1.724, Global test accuracy: 75.03
Round  18, Train loss: 1.567, Test loss: 1.627, Test accuracy: 83.90
Round  18, Global train loss: 1.567, Global test loss: 1.695, Global test accuracy: 78.81
Round  19, Train loss: 1.512, Test loss: 1.603, Test accuracy: 86.45
Round  19, Global train loss: 1.512, Global test loss: 1.724, Global test accuracy: 75.51
Round  20, Train loss: 1.567, Test loss: 1.601, Test accuracy: 86.41
Round  20, Global train loss: 1.567, Global test loss: 1.664, Global test accuracy: 81.70
Round  21, Train loss: 1.629, Test loss: 1.590, Test accuracy: 87.61
Round  21, Global train loss: 1.629, Global test loss: 1.681, Global test accuracy: 79.02
Round  22, Train loss: 1.626, Test loss: 1.590, Test accuracy: 87.57
Round  22, Global train loss: 1.626, Global test loss: 1.651, Global test accuracy: 82.38
Round  23, Train loss: 1.533, Test loss: 1.589, Test accuracy: 87.71
Round  23, Global train loss: 1.533, Global test loss: 1.648, Global test accuracy: 82.60
Round  24, Train loss: 1.559, Test loss: 1.589, Test accuracy: 87.79
Round  24, Global train loss: 1.559, Global test loss: 1.657, Global test accuracy: 81.79
Round  25, Train loss: 1.589, Test loss: 1.588, Test accuracy: 87.82
Round  25, Global train loss: 1.589, Global test loss: 1.637, Global test accuracy: 83.89
Round  26, Train loss: 1.555, Test loss: 1.587, Test accuracy: 87.95
Round  26, Global train loss: 1.555, Global test loss: 1.659, Global test accuracy: 81.49
Round  27, Train loss: 1.498, Test loss: 1.586, Test accuracy: 87.92
Round  27, Global train loss: 1.498, Global test loss: 1.635, Global test accuracy: 83.97
Round  28, Train loss: 1.522, Test loss: 1.586, Test accuracy: 87.94
Round  28, Global train loss: 1.522, Global test loss: 1.651, Global test accuracy: 82.25
Round  29, Train loss: 1.555, Test loss: 1.585, Test accuracy: 88.01
Round  29, Global train loss: 1.555, Global test loss: 1.643, Global test accuracy: 82.56
Round  30, Train loss: 1.581, Test loss: 1.585, Test accuracy: 88.00
Round  30, Global train loss: 1.581, Global test loss: 1.626, Global test accuracy: 84.70
Round  31, Train loss: 1.524, Test loss: 1.585, Test accuracy: 87.84
Round  31, Global train loss: 1.524, Global test loss: 1.631, Global test accuracy: 84.16
Round  32, Train loss: 1.586, Test loss: 1.585, Test accuracy: 87.88
Round  32, Global train loss: 1.586, Global test loss: 1.652, Global test accuracy: 81.45
Round  33, Train loss: 1.582, Test loss: 1.585, Test accuracy: 87.96
Round  33, Global train loss: 1.582, Global test loss: 1.626, Global test accuracy: 84.67
Round  34, Train loss: 1.552, Test loss: 1.584, Test accuracy: 88.01
Round  34, Global train loss: 1.552, Global test loss: 1.656, Global test accuracy: 81.00
Round  35, Train loss: 1.513, Test loss: 1.584, Test accuracy: 87.97
Round  35, Global train loss: 1.513, Global test loss: 1.631, Global test accuracy: 84.29
Round  36, Train loss: 1.613, Test loss: 1.584, Test accuracy: 87.94
Round  36, Global train loss: 1.613, Global test loss: 1.624, Global test accuracy: 84.63
Round  37, Train loss: 1.610, Test loss: 1.584, Test accuracy: 87.92
Round  37, Global train loss: 1.610, Global test loss: 1.628, Global test accuracy: 84.29
Round  38, Train loss: 1.579, Test loss: 1.584, Test accuracy: 87.99
Round  38, Global train loss: 1.579, Global test loss: 1.637, Global test accuracy: 83.18
Round  39, Train loss: 1.543, Test loss: 1.584, Test accuracy: 87.93
Round  39, Global train loss: 1.543, Global test loss: 1.650, Global test accuracy: 81.77
Round  40, Train loss: 1.509, Test loss: 1.583, Test accuracy: 88.08
Round  40, Global train loss: 1.509, Global test loss: 1.624, Global test accuracy: 84.74
Round  41, Train loss: 1.485, Test loss: 1.583, Test accuracy: 88.12
Round  41, Global train loss: 1.485, Global test loss: 1.623, Global test accuracy: 84.81
Round  42, Train loss: 1.583, Test loss: 1.581, Test accuracy: 88.33
Round  42, Global train loss: 1.583, Global test loss: 1.623, Global test accuracy: 84.97
Round  43, Train loss: 1.580, Test loss: 1.581, Test accuracy: 88.34
Round  43, Global train loss: 1.580, Global test loss: 1.634, Global test accuracy: 83.65
Round  44, Train loss: 1.581, Test loss: 1.581, Test accuracy: 88.33
Round  44, Global train loss: 1.581, Global test loss: 1.621, Global test accuracy: 85.08
Round  45, Train loss: 1.580, Test loss: 1.581, Test accuracy: 88.28
Round  45, Global train loss: 1.580, Global test loss: 1.633, Global test accuracy: 83.50
Round  46, Train loss: 1.545, Test loss: 1.581, Test accuracy: 88.27
Round  46, Global train loss: 1.545, Global test loss: 1.615, Global test accuracy: 85.52
Round  47, Train loss: 1.610, Test loss: 1.582, Test accuracy: 88.16
Round  47, Global train loss: 1.610, Global test loss: 1.623, Global test accuracy: 84.69
Round  48, Train loss: 1.545, Test loss: 1.581, Test accuracy: 88.23
Round  48, Global train loss: 1.545, Global test loss: 1.619, Global test accuracy: 85.18
Round  49, Train loss: 1.577, Test loss: 1.581, Test accuracy: 88.24
Round  49, Global train loss: 1.577, Global test loss: 1.617, Global test accuracy: 85.14
Round  50, Train loss: 1.610, Test loss: 1.581, Test accuracy: 88.22
Round  50, Global train loss: 1.610, Global test loss: 1.611, Global test accuracy: 85.76
Round  51, Train loss: 1.574, Test loss: 1.581, Test accuracy: 88.25
Round  51, Global train loss: 1.574, Global test loss: 1.617, Global test accuracy: 84.90
Round  52, Train loss: 1.547, Test loss: 1.579, Test accuracy: 88.40
Round  52, Global train loss: 1.547, Global test loss: 1.611, Global test accuracy: 85.73
Round  53, Train loss: 1.574, Test loss: 1.579, Test accuracy: 88.49
Round  53, Global train loss: 1.574, Global test loss: 1.617, Global test accuracy: 85.04
Round  54, Train loss: 1.610, Test loss: 1.579, Test accuracy: 88.52
Round  54, Global train loss: 1.610, Global test loss: 1.611, Global test accuracy: 85.78
Round  55, Train loss: 1.512, Test loss: 1.579, Test accuracy: 88.49
Round  55, Global train loss: 1.512, Global test loss: 1.613, Global test accuracy: 85.50
Round  56, Train loss: 1.539, Test loss: 1.579, Test accuracy: 88.41
Round  56, Global train loss: 1.539, Global test loss: 1.627, Global test accuracy: 84.01
Round  57, Train loss: 1.543, Test loss: 1.580, Test accuracy: 88.35
Round  57, Global train loss: 1.543, Global test loss: 1.607, Global test accuracy: 85.85
Round  58, Train loss: 1.576, Test loss: 1.579, Test accuracy: 88.58
Round  58, Global train loss: 1.576, Global test loss: 1.607, Global test accuracy: 86.12
Round  59, Train loss: 1.575, Test loss: 1.578, Test accuracy: 88.59
Round  59, Global train loss: 1.575, Global test loss: 1.624, Global test accuracy: 84.32
Round  60, Train loss: 1.543, Test loss: 1.578, Test accuracy: 88.61
Round  60, Global train loss: 1.543, Global test loss: 1.610, Global test accuracy: 85.86
Round  61, Train loss: 1.605, Test loss: 1.578, Test accuracy: 88.51
Round  61, Global train loss: 1.605, Global test loss: 1.615, Global test accuracy: 85.30
Round  62, Train loss: 1.506, Test loss: 1.578, Test accuracy: 88.43
Round  62, Global train loss: 1.506, Global test loss: 1.622, Global test accuracy: 84.61
Round  63, Train loss: 1.575, Test loss: 1.578, Test accuracy: 88.47
Round  63, Global train loss: 1.575, Global test loss: 1.609, Global test accuracy: 85.60
Round  64, Train loss: 1.542, Test loss: 1.578, Test accuracy: 88.51
Round  64, Global train loss: 1.542, Global test loss: 1.608, Global test accuracy: 85.99
Round  65, Train loss: 1.538, Test loss: 1.577, Test accuracy: 88.63
Round  65, Global train loss: 1.538, Global test loss: 1.604, Global test accuracy: 86.27
Round  66, Train loss: 1.539, Test loss: 1.577, Test accuracy: 88.64
Round  66, Global train loss: 1.539, Global test loss: 1.624, Global test accuracy: 84.06
Round  67, Train loss: 1.573, Test loss: 1.576, Test accuracy: 88.66
Round  67, Global train loss: 1.573, Global test loss: 1.603, Global test accuracy: 86.12
Round  68, Train loss: 1.542, Test loss: 1.576, Test accuracy: 88.75
Round  68, Global train loss: 1.542, Global test loss: 1.604, Global test accuracy: 86.40
Round  69, Train loss: 1.539, Test loss: 1.576, Test accuracy: 88.68
Round  69, Global train loss: 1.539, Global test loss: 1.609, Global test accuracy: 85.87
Round  70, Train loss: 1.540, Test loss: 1.576, Test accuracy: 88.70
Round  70, Global train loss: 1.540, Global test loss: 1.610, Global test accuracy: 85.59
Round  71, Train loss: 1.572, Test loss: 1.576, Test accuracy: 88.73
Round  71, Global train loss: 1.572, Global test loss: 1.618, Global test accuracy: 84.92
Round  72, Train loss: 1.510, Test loss: 1.576, Test accuracy: 88.73
Round  72, Global train loss: 1.510, Global test loss: 1.605, Global test accuracy: 86.14
Round  73, Train loss: 1.537, Test loss: 1.576, Test accuracy: 88.73
Round  73, Global train loss: 1.537, Global test loss: 1.617, Global test accuracy: 84.89
Round  74, Train loss: 1.573, Test loss: 1.576, Test accuracy: 88.65
Round  74, Global train loss: 1.573, Global test loss: 1.609, Global test accuracy: 85.92
Round  75, Train loss: 1.604, Test loss: 1.576, Test accuracy: 88.76
Round  75, Global train loss: 1.604, Global test loss: 1.608, Global test accuracy: 85.84
Round  76, Train loss: 1.571, Test loss: 1.576, Test accuracy: 88.70
Round  76, Global train loss: 1.571, Global test loss: 1.603, Global test accuracy: 86.13
Round  77, Train loss: 1.600, Test loss: 1.576, Test accuracy: 88.76
Round  77, Global train loss: 1.600, Global test loss: 1.614, Global test accuracy: 85.31
Round  78, Train loss: 1.473, Test loss: 1.575, Test accuracy: 88.76
Round  78, Global train loss: 1.473, Global test loss: 1.615, Global test accuracy: 85.22
Round  79, Train loss: 1.474, Test loss: 1.575, Test accuracy: 88.80
Round  79, Global train loss: 1.474, Global test loss: 1.607, Global test accuracy: 85.90
Round  80, Train loss: 1.540, Test loss: 1.575, Test accuracy: 88.83
Round  80, Global train loss: 1.540, Global test loss: 1.614, Global test accuracy: 85.13
Round  81, Train loss: 1.535, Test loss: 1.575, Test accuracy: 88.84
Round  81, Global train loss: 1.535, Global test loss: 1.602, Global test accuracy: 86.38
Round  82, Train loss: 1.572, Test loss: 1.575, Test accuracy: 88.85
Round  82, Global train loss: 1.572, Global test loss: 1.604, Global test accuracy: 86.28
Round  83, Train loss: 1.506, Test loss: 1.575, Test accuracy: 88.87
Round  83, Global train loss: 1.506, Global test loss: 1.599, Global test accuracy: 86.87
Round  84, Train loss: 1.569, Test loss: 1.575, Test accuracy: 88.87
Round  84, Global train loss: 1.569, Global test loss: 1.608, Global test accuracy: 85.86
Round  85, Train loss: 1.537, Test loss: 1.575, Test accuracy: 88.85
Round  85, Global train loss: 1.537, Global test loss: 1.600, Global test accuracy: 86.79
Round  86, Train loss: 1.505, Test loss: 1.575, Test accuracy: 88.84
Round  86, Global train loss: 1.505, Global test loss: 1.603, Global test accuracy: 86.11
Round  87, Train loss: 1.601, Test loss: 1.575, Test accuracy: 88.80
Round  87, Global train loss: 1.601, Global test loss: 1.609, Global test accuracy: 85.56
Round  88, Train loss: 1.536, Test loss: 1.575, Test accuracy: 88.87
Round  88, Global train loss: 1.536, Global test loss: 1.600, Global test accuracy: 86.62
Round  89, Train loss: 1.599, Test loss: 1.575, Test accuracy: 88.83
Round  89, Global train loss: 1.599, Global test loss: 1.598, Global test accuracy: 86.89
Round  90, Train loss: 1.568, Test loss: 1.575, Test accuracy: 88.81
Round  90, Global train loss: 1.568, Global test loss: 1.599, Global test accuracy: 86.62
Round  91, Train loss: 1.538, Test loss: 1.575, Test accuracy: 88.82
Round  91, Global train loss: 1.538, Global test loss: 1.599, Global test accuracy: 86.83
Round  92, Train loss: 1.535, Test loss: 1.575, Test accuracy: 88.77
Round  92, Global train loss: 1.535, Global test loss: 1.603, Global test accuracy: 86.07
Round  93, Train loss: 1.567, Test loss: 1.575, Test accuracy: 88.81
Round  93, Global train loss: 1.567, Global test loss: 1.619, Global test accuracy: 84.62
Round  94, Train loss: 1.569, Test loss: 1.575, Test accuracy: 88.84
Round  94, Global train loss: 1.569, Global test loss: 1.620, Global test accuracy: 84.72
Round  95, Train loss: 1.535, Test loss: 1.575, Test accuracy: 88.80
Round  95, Global train loss: 1.535, Global test loss: 1.608, Global test accuracy: 85.79/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.538, Test loss: 1.575, Test accuracy: 88.82
Round  96, Global train loss: 1.538, Global test loss: 1.599, Global test accuracy: 86.76
Round  97, Train loss: 1.602, Test loss: 1.575, Test accuracy: 88.82
Round  97, Global train loss: 1.602, Global test loss: 1.604, Global test accuracy: 85.89
Round  98, Train loss: 1.567, Test loss: 1.575, Test accuracy: 88.84
Round  98, Global train loss: 1.567, Global test loss: 1.608, Global test accuracy: 85.77
Round  99, Train loss: 1.536, Test loss: 1.575, Test accuracy: 88.80
Round  99, Global train loss: 1.536, Global test loss: 1.599, Global test accuracy: 86.68
Final Round, Train loss: 1.548, Test loss: 1.574, Test accuracy: 88.95
Final Round, Global train loss: 1.548, Global test loss: 1.599, Global test accuracy: 86.68
Average accuracy final 10 rounds: 88.81299999999999 

Average global accuracy final 10 rounds: 85.97500000000001 

1206.4813089370728
[0.9115908145904541, 1.8231816291809082, 2.6299502849578857, 3.4367189407348633, 4.241595029830933, 5.046471118927002, 5.851980924606323, 6.6574907302856445, 7.469363212585449, 8.281235694885254, 9.090784788131714, 9.900333881378174, 10.71123194694519, 11.522130012512207, 12.330514192581177, 13.138898372650146, 13.937268018722534, 14.735637664794922, 15.535994052886963, 16.336350440979004, 17.130844593048096, 17.925338745117188, 18.740500688552856, 19.555662631988525, 20.368935585021973, 21.18220853805542, 22.0168035030365, 22.851398468017578, 23.662481546401978, 24.473564624786377, 25.275566577911377, 26.077568531036377, 26.875043392181396, 27.672518253326416, 28.479025840759277, 29.28553342819214, 30.081709146499634, 30.87788486480713, 31.67845368385315, 32.47902250289917, 33.277557611465454, 34.07609272003174, 34.871541023254395, 35.66698932647705, 36.459394454956055, 37.25179958343506, 38.048579454422, 38.845359325408936, 39.641960859298706, 40.43856239318848, 41.229673862457275, 42.020785331726074, 42.82215166091919, 43.623517990112305, 44.41841530799866, 45.21331262588501, 46.013405084609985, 46.81349754333496, 47.62538194656372, 48.43726634979248, 49.23765158653259, 50.038036823272705, 50.83843517303467, 51.63883352279663, 52.43351769447327, 53.2282018661499, 54.020567893981934, 54.812933921813965, 55.61348557472229, 56.414037227630615, 57.22256684303284, 58.03109645843506, 58.83703541755676, 59.64297437667847, 60.441279888153076, 61.239585399627686, 62.03530192375183, 62.83101844787598, 63.619821071624756, 64.40862369537354, 65.206130027771, 66.00363636016846, 66.80396175384521, 67.60428714752197, 68.40759348869324, 69.2108998298645, 70.01434397697449, 70.81778812408447, 71.61746072769165, 72.41713333129883, 73.2177939414978, 74.01845455169678, 74.81809973716736, 75.61774492263794, 76.40867900848389, 77.19961309432983, 77.99711465835571, 78.79461622238159, 79.61016464233398, 80.42571306228638, 81.24152898788452, 82.05734491348267, 82.87687420845032, 83.69640350341797, 84.49540519714355, 85.29440689086914, 86.08876204490662, 86.88311719894409, 87.67757797241211, 88.47203874588013, 89.2686185836792, 90.06519842147827, 90.86010503768921, 91.65501165390015, 92.45999693870544, 93.26498222351074, 94.08104252815247, 94.89710283279419, 95.71489310264587, 96.53268337249756, 97.34764623641968, 98.1626091003418, 98.95530986785889, 99.74801063537598, 100.54399085044861, 101.33997106552124, 102.14172577857971, 102.94348049163818, 103.74084329605103, 104.53820610046387, 105.33825635910034, 106.13830661773682, 106.93746566772461, 107.7366247177124, 108.5374813079834, 109.3383378982544, 110.13181257247925, 110.9252872467041, 111.72586035728455, 112.52643346786499, 113.31075191497803, 114.09507036209106, 114.89392805099487, 115.69278573989868, 116.4954481124878, 117.2981104850769, 118.10368275642395, 118.909255027771, 119.69909310340881, 120.48893117904663, 121.28031587600708, 122.07170057296753, 122.88667511940002, 123.70164966583252, 124.50604200363159, 125.31043434143066, 126.11723971366882, 126.92404508590698, 127.70432806015015, 128.4846110343933, 129.17013001441956, 129.8556489944458, 130.6697175502777, 131.48378610610962, 132.27466344833374, 133.06554079055786, 133.85694575309753, 134.6483507156372, 135.4298324584961, 136.21131420135498, 137.06736135482788, 137.92340850830078, 138.7920835018158, 139.6607584953308, 140.52436542510986, 141.38797235488892, 142.23655652999878, 143.08514070510864, 143.9350929260254, 144.78504514694214, 145.6321883201599, 146.47933149337769, 147.34688186645508, 148.21443223953247, 149.07886123657227, 149.94329023361206, 150.8092381954193, 151.67518615722656, 152.53513431549072, 153.39508247375488, 154.2481873035431, 155.1012921333313, 155.96010899543762, 156.81892585754395, 157.67163729667664, 158.52434873580933, 159.36689567565918, 160.20944261550903, 161.0658733844757, 161.92230415344238, 163.36061668395996, 164.79892921447754]
[17.88, 17.88, 24.3, 24.3, 44.26, 44.26, 48.84, 48.84, 58.03, 58.03, 65.45, 65.45, 67.77, 67.77, 68.84, 68.84, 70.96, 70.96, 73.9, 73.9, 74.08, 74.08, 79.02, 79.02, 79.14, 79.14, 79.21, 79.21, 79.31, 79.31, 79.32, 79.32, 80.32, 80.32, 83.77, 83.77, 83.9, 83.9, 86.45, 86.45, 86.41, 86.41, 87.61, 87.61, 87.57, 87.57, 87.71, 87.71, 87.79, 87.79, 87.82, 87.82, 87.95, 87.95, 87.92, 87.92, 87.94, 87.94, 88.01, 88.01, 88.0, 88.0, 87.84, 87.84, 87.88, 87.88, 87.96, 87.96, 88.01, 88.01, 87.97, 87.97, 87.94, 87.94, 87.92, 87.92, 87.99, 87.99, 87.93, 87.93, 88.08, 88.08, 88.12, 88.12, 88.33, 88.33, 88.34, 88.34, 88.33, 88.33, 88.28, 88.28, 88.27, 88.27, 88.16, 88.16, 88.23, 88.23, 88.24, 88.24, 88.22, 88.22, 88.25, 88.25, 88.4, 88.4, 88.49, 88.49, 88.52, 88.52, 88.49, 88.49, 88.41, 88.41, 88.35, 88.35, 88.58, 88.58, 88.59, 88.59, 88.61, 88.61, 88.51, 88.51, 88.43, 88.43, 88.47, 88.47, 88.51, 88.51, 88.63, 88.63, 88.64, 88.64, 88.66, 88.66, 88.75, 88.75, 88.68, 88.68, 88.7, 88.7, 88.73, 88.73, 88.73, 88.73, 88.73, 88.73, 88.65, 88.65, 88.76, 88.76, 88.7, 88.7, 88.76, 88.76, 88.76, 88.76, 88.8, 88.8, 88.83, 88.83, 88.84, 88.84, 88.85, 88.85, 88.87, 88.87, 88.87, 88.87, 88.85, 88.85, 88.84, 88.84, 88.8, 88.8, 88.87, 88.87, 88.83, 88.83, 88.81, 88.81, 88.82, 88.82, 88.77, 88.77, 88.81, 88.81, 88.84, 88.84, 88.8, 88.8, 88.82, 88.82, 88.82, 88.82, 88.84, 88.84, 88.8, 88.8, 88.95, 88.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.62
Round   1, Train loss: 2.290, Test loss: 2.293, Test accuracy: 14.76
Round   2, Train loss: 2.279, Test loss: 2.280, Test accuracy: 26.08
Round   3, Train loss: 2.217, Test loss: 2.220, Test accuracy: 26.10
Round   4, Train loss: 2.098, Test loss: 2.153, Test accuracy: 31.08
Round   5, Train loss: 2.049, Test loss: 2.089, Test accuracy: 44.34
Round   6, Train loss: 1.891, Test loss: 1.962, Test accuracy: 56.43
Round   7, Train loss: 1.763, Test loss: 1.853, Test accuracy: 66.21
Round   8, Train loss: 1.732, Test loss: 1.783, Test accuracy: 72.69
Round   9, Train loss: 1.634, Test loss: 1.710, Test accuracy: 79.37
Round  10, Train loss: 1.575, Test loss: 1.666, Test accuracy: 82.78
Round  11, Train loss: 1.558, Test loss: 1.653, Test accuracy: 83.41
Round  12, Train loss: 1.610, Test loss: 1.624, Test accuracy: 86.12
Round  13, Train loss: 1.564, Test loss: 1.618, Test accuracy: 86.21
Round  14, Train loss: 1.586, Test loss: 1.600, Test accuracy: 87.75
Round  15, Train loss: 1.578, Test loss: 1.585, Test accuracy: 88.99
Round  16, Train loss: 1.569, Test loss: 1.581, Test accuracy: 89.35
Round  17, Train loss: 1.562, Test loss: 1.579, Test accuracy: 89.39
Round  18, Train loss: 1.530, Test loss: 1.571, Test accuracy: 90.23
Round  19, Train loss: 1.579, Test loss: 1.562, Test accuracy: 91.02
Round  20, Train loss: 1.514, Test loss: 1.561, Test accuracy: 91.13
Round  21, Train loss: 1.530, Test loss: 1.550, Test accuracy: 92.40
Round  22, Train loss: 1.523, Test loss: 1.546, Test accuracy: 92.63
Round  23, Train loss: 1.522, Test loss: 1.544, Test accuracy: 92.75
Round  24, Train loss: 1.513, Test loss: 1.543, Test accuracy: 92.83
Round  25, Train loss: 1.516, Test loss: 1.543, Test accuracy: 92.80
Round  26, Train loss: 1.533, Test loss: 1.535, Test accuracy: 93.49
Round  27, Train loss: 1.511, Test loss: 1.534, Test accuracy: 93.67
Round  28, Train loss: 1.516, Test loss: 1.533, Test accuracy: 93.62
Round  29, Train loss: 1.500, Test loss: 1.533, Test accuracy: 93.62
Round  30, Train loss: 1.510, Test loss: 1.531, Test accuracy: 93.88
Round  31, Train loss: 1.512, Test loss: 1.530, Test accuracy: 94.01
Round  32, Train loss: 1.510, Test loss: 1.528, Test accuracy: 94.10
Round  33, Train loss: 1.509, Test loss: 1.529, Test accuracy: 94.00
Round  34, Train loss: 1.500, Test loss: 1.528, Test accuracy: 93.97
Round  35, Train loss: 1.507, Test loss: 1.528, Test accuracy: 93.95
Round  36, Train loss: 1.499, Test loss: 1.528, Test accuracy: 93.95
Round  37, Train loss: 1.507, Test loss: 1.526, Test accuracy: 94.16
Round  38, Train loss: 1.509, Test loss: 1.526, Test accuracy: 94.19
Round  39, Train loss: 1.503, Test loss: 1.525, Test accuracy: 94.28
Round  40, Train loss: 1.504, Test loss: 1.525, Test accuracy: 94.25
Round  41, Train loss: 1.501, Test loss: 1.525, Test accuracy: 94.21
Round  42, Train loss: 1.498, Test loss: 1.524, Test accuracy: 94.19
Round  43, Train loss: 1.502, Test loss: 1.524, Test accuracy: 94.26
Round  44, Train loss: 1.494, Test loss: 1.524, Test accuracy: 94.29
Round  45, Train loss: 1.497, Test loss: 1.524, Test accuracy: 94.33
Round  46, Train loss: 1.490, Test loss: 1.524, Test accuracy: 94.28
Round  47, Train loss: 1.498, Test loss: 1.522, Test accuracy: 94.35
Round  48, Train loss: 1.494, Test loss: 1.523, Test accuracy: 94.33
Round  49, Train loss: 1.492, Test loss: 1.522, Test accuracy: 94.47
Round  50, Train loss: 1.493, Test loss: 1.522, Test accuracy: 94.40
Round  51, Train loss: 1.497, Test loss: 1.521, Test accuracy: 94.48
Round  52, Train loss: 1.500, Test loss: 1.521, Test accuracy: 94.52
Round  53, Train loss: 1.485, Test loss: 1.521, Test accuracy: 94.47
Round  54, Train loss: 1.493, Test loss: 1.521, Test accuracy: 94.53
Round  55, Train loss: 1.490, Test loss: 1.520, Test accuracy: 94.51
Round  56, Train loss: 1.484, Test loss: 1.520, Test accuracy: 94.53
Round  57, Train loss: 1.489, Test loss: 1.520, Test accuracy: 94.52
Round  58, Train loss: 1.490, Test loss: 1.519, Test accuracy: 94.57
Round  59, Train loss: 1.485, Test loss: 1.519, Test accuracy: 94.65
Round  60, Train loss: 1.490, Test loss: 1.519, Test accuracy: 94.67
Round  61, Train loss: 1.497, Test loss: 1.519, Test accuracy: 94.66
Round  62, Train loss: 1.482, Test loss: 1.519, Test accuracy: 94.69
Round  63, Train loss: 1.486, Test loss: 1.518, Test accuracy: 94.66
Round  64, Train loss: 1.489, Test loss: 1.519, Test accuracy: 94.64
Round  65, Train loss: 1.485, Test loss: 1.519, Test accuracy: 94.64
Round  66, Train loss: 1.492, Test loss: 1.518, Test accuracy: 94.77
Round  67, Train loss: 1.488, Test loss: 1.518, Test accuracy: 94.78
Round  68, Train loss: 1.484, Test loss: 1.518, Test accuracy: 94.70
Round  69, Train loss: 1.489, Test loss: 1.518, Test accuracy: 94.71
Round  70, Train loss: 1.482, Test loss: 1.517, Test accuracy: 94.75
Round  71, Train loss: 1.492, Test loss: 1.517, Test accuracy: 94.68
Round  72, Train loss: 1.482, Test loss: 1.517, Test accuracy: 94.74
Round  73, Train loss: 1.479, Test loss: 1.518, Test accuracy: 94.78
Round  74, Train loss: 1.492, Test loss: 1.517, Test accuracy: 94.83
Round  75, Train loss: 1.488, Test loss: 1.517, Test accuracy: 94.69
Round  76, Train loss: 1.485, Test loss: 1.516, Test accuracy: 94.69
Round  77, Train loss: 1.485, Test loss: 1.516, Test accuracy: 94.87
Round  78, Train loss: 1.480, Test loss: 1.516, Test accuracy: 94.86
Round  79, Train loss: 1.481, Test loss: 1.517, Test accuracy: 94.79
Round  80, Train loss: 1.485, Test loss: 1.516, Test accuracy: 94.78
Round  81, Train loss: 1.480, Test loss: 1.516, Test accuracy: 94.80
Round  82, Train loss: 1.481, Test loss: 1.516, Test accuracy: 94.76
Round  83, Train loss: 1.484, Test loss: 1.517, Test accuracy: 94.72
Round  84, Train loss: 1.487, Test loss: 1.516, Test accuracy: 94.87
Round  85, Train loss: 1.481, Test loss: 1.516, Test accuracy: 94.80
Round  86, Train loss: 1.483, Test loss: 1.516, Test accuracy: 94.75
Round  87, Train loss: 1.474, Test loss: 1.516, Test accuracy: 94.75
Round  88, Train loss: 1.481, Test loss: 1.516, Test accuracy: 94.74
Round  89, Train loss: 1.484, Test loss: 1.516, Test accuracy: 94.85
Round  90, Train loss: 1.483, Test loss: 1.516, Test accuracy: 94.79
Round  91, Train loss: 1.482, Test loss: 1.516, Test accuracy: 94.77
Round  92, Train loss: 1.485, Test loss: 1.515, Test accuracy: 94.85
Round  93, Train loss: 1.481, Test loss: 1.515, Test accuracy: 94.79
Round  94, Train loss: 1.482, Test loss: 1.515, Test accuracy: 94.85
Round  95, Train loss: 1.482, Test loss: 1.514, Test accuracy: 94.86
Round  96, Train loss: 1.481, Test loss: 1.515, Test accuracy: 94.79
Round  97, Train loss: 1.478, Test loss: 1.515, Test accuracy: 94.75
Round  98, Train loss: 1.480, Test loss: 1.515, Test accuracy: 94.86
Round  99, Train loss: 1.484, Test loss: 1.515, Test accuracy: 94.87
Round 100, Train loss: 1.484, Test loss: 1.514, Test accuracy: 94.98
Round 101, Train loss: 1.485, Test loss: 1.514, Test accuracy: 94.95
Round 102, Train loss: 1.480, Test loss: 1.514, Test accuracy: 94.88
Round 103, Train loss: 1.480, Test loss: 1.514, Test accuracy: 94.87
Round 104, Train loss: 1.481, Test loss: 1.514, Test accuracy: 94.88
Round 105, Train loss: 1.478, Test loss: 1.515, Test accuracy: 94.83
Round 106, Train loss: 1.478, Test loss: 1.514, Test accuracy: 94.92
Round 107, Train loss: 1.483, Test loss: 1.514, Test accuracy: 94.89
Round 108, Train loss: 1.479, Test loss: 1.514, Test accuracy: 94.82
Round 109, Train loss: 1.480, Test loss: 1.515, Test accuracy: 94.88
Round 110, Train loss: 1.473, Test loss: 1.514, Test accuracy: 94.92
Round 111, Train loss: 1.478, Test loss: 1.514, Test accuracy: 94.96
Round 112, Train loss: 1.476, Test loss: 1.514, Test accuracy: 94.93
Round 113, Train loss: 1.483, Test loss: 1.514, Test accuracy: 94.99
Round 114, Train loss: 1.483, Test loss: 1.514, Test accuracy: 94.92
Round 115, Train loss: 1.481, Test loss: 1.514, Test accuracy: 94.97
Round 116, Train loss: 1.479, Test loss: 1.514, Test accuracy: 94.96
Round 117, Train loss: 1.484, Test loss: 1.514, Test accuracy: 94.99
Round 118, Train loss: 1.481, Test loss: 1.513, Test accuracy: 94.96
Round 119, Train loss: 1.480, Test loss: 1.513, Test accuracy: 95.01
Round 120, Train loss: 1.475, Test loss: 1.513, Test accuracy: 95.01
Round 121, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.97
Round 122, Train loss: 1.476, Test loss: 1.513, Test accuracy: 94.98
Round 123, Train loss: 1.482, Test loss: 1.514, Test accuracy: 95.01
Round 124, Train loss: 1.479, Test loss: 1.513, Test accuracy: 95.02
Round 125, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.01
Round 126, Train loss: 1.480, Test loss: 1.513, Test accuracy: 94.99
Round 127, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.01
Round 128, Train loss: 1.481, Test loss: 1.513, Test accuracy: 95.03
Round 129, Train loss: 1.479, Test loss: 1.513, Test accuracy: 95.00
Round 130, Train loss: 1.481, Test loss: 1.513, Test accuracy: 94.98
Round 131, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.99
Round 132, Train loss: 1.480, Test loss: 1.513, Test accuracy: 95.03
Round 133, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.04
Round 134, Train loss: 1.480, Test loss: 1.513, Test accuracy: 95.00
Round 135, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.95
Round 136, Train loss: 1.477, Test loss: 1.513, Test accuracy: 94.96
Round 137, Train loss: 1.477, Test loss: 1.513, Test accuracy: 94.95
Round 138, Train loss: 1.476, Test loss: 1.513, Test accuracy: 94.93
Round 139, Train loss: 1.473, Test loss: 1.513, Test accuracy: 94.96
Round 140, Train loss: 1.476, Test loss: 1.513, Test accuracy: 94.98
Round 141, Train loss: 1.481, Test loss: 1.513, Test accuracy: 94.97
Round 142, Train loss: 1.474, Test loss: 1.513, Test accuracy: 95.03
Round 143, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.97
Round 144, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.02
Round 145, Train loss: 1.478, Test loss: 1.513, Test accuracy: 95.00
Round 146, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.93
Round 147, Train loss: 1.475, Test loss: 1.513, Test accuracy: 95.03
Round 148, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.99
Round 149, Train loss: 1.473, Test loss: 1.513, Test accuracy: 95.00
Round 150, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.01
Round 151, Train loss: 1.482, Test loss: 1.513, Test accuracy: 95.02
Round 152, Train loss: 1.480, Test loss: 1.513, Test accuracy: 94.96
Round 153, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.00
Round 154, Train loss: 1.480, Test loss: 1.513, Test accuracy: 95.01
Round 155, Train loss: 1.480, Test loss: 1.513, Test accuracy: 95.02
Round 156, Train loss: 1.477, Test loss: 1.513, Test accuracy: 94.99
Round 157, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.96
Round 158, Train loss: 1.479, Test loss: 1.513, Test accuracy: 94.93
Round 159, Train loss: 1.479, Test loss: 1.513, Test accuracy: 94.95
Round 160, Train loss: 1.474, Test loss: 1.513, Test accuracy: 94.92
Round 161, Train loss: 1.480, Test loss: 1.513, Test accuracy: 94.98
Round 162, Train loss: 1.479, Test loss: 1.513, Test accuracy: 94.98
Round 163, Train loss: 1.471, Test loss: 1.513, Test accuracy: 95.00
Round 164, Train loss: 1.476, Test loss: 1.513, Test accuracy: 94.98
Round 165, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.00
Round 166, Train loss: 1.482, Test loss: 1.513, Test accuracy: 94.97
Round 167, Train loss: 1.479, Test loss: 1.513, Test accuracy: 95.03
Round 168, Train loss: 1.478, Test loss: 1.513, Test accuracy: 95.05
Round 169, Train loss: 1.479, Test loss: 1.513, Test accuracy: 94.99
Round 170, Train loss: 1.479, Test loss: 1.513, Test accuracy: 94.99
Round 171, Train loss: 1.482, Test loss: 1.513, Test accuracy: 94.95
Round 172, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.03
Round 173, Train loss: 1.474, Test loss: 1.512, Test accuracy: 95.07
Round 174, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.02
Round 175, Train loss: 1.480, Test loss: 1.512, Test accuracy: 95.06
Round 176, Train loss: 1.476, Test loss: 1.512, Test accuracy: 95.04
Round 177, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.02
Round 178, Train loss: 1.473, Test loss: 1.513, Test accuracy: 94.97
Round 179, Train loss: 1.473, Test loss: 1.513, Test accuracy: 95.06
Round 180, Train loss: 1.475, Test loss: 1.512, Test accuracy: 95.05
Round 181, Train loss: 1.480, Test loss: 1.512, Test accuracy: 95.03
Round 182, Train loss: 1.480, Test loss: 1.512, Test accuracy: 95.03
Round 183, Train loss: 1.476, Test loss: 1.512, Test accuracy: 95.03
Round 184, Train loss: 1.475, Test loss: 1.512, Test accuracy: 94.96
Round 185, Train loss: 1.481, Test loss: 1.512, Test accuracy: 95.08
Round 186, Train loss: 1.478, Test loss: 1.512, Test accuracy: 95.02
Round 187, Train loss: 1.478, Test loss: 1.512, Test accuracy: 95.05
Round 188, Train loss: 1.475, Test loss: 1.512, Test accuracy: 95.02
Round 189, Train loss: 1.472, Test loss: 1.512, Test accuracy: 94.96
Round 190, Train loss: 1.474, Test loss: 1.513, Test accuracy: 95.02
Round 191, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.01
Round 192, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.03
Round 193, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.03
Round 194, Train loss: 1.474, Test loss: 1.512, Test accuracy: 94.99
Round 195, Train loss: 1.479, Test loss: 1.512, Test accuracy: 95.00
Round 196, Train loss: 1.480, Test loss: 1.513, Test accuracy: 94.95
Round 197, Train loss: 1.476, Test loss: 1.513, Test accuracy: 94.96
Round 198, Train loss: 1.476, Test loss: 1.512, Test accuracy: 95.05
Round 199, Train loss: 1.473, Test loss: 1.512, Test accuracy: 95.04
Final Round, Train loss: 1.476, Test loss: 1.512, Test accuracy: 95.05
Average accuracy final 10 rounds: 95.008 

1781.9746189117432
[0.8291492462158203, 1.6582984924316406, 2.4096524715423584, 3.161006450653076, 3.930487871170044, 4.699969291687012, 5.438845157623291, 6.17772102355957, 6.901832103729248, 7.625943183898926, 8.366069793701172, 9.106196403503418, 9.833931684494019, 10.56166696548462, 11.285676002502441, 12.009685039520264, 12.751121282577515, 13.492557525634766, 14.227818965911865, 14.963080406188965, 15.676004886627197, 16.38892936706543, 17.133716583251953, 17.878503799438477, 18.60524034500122, 19.331976890563965, 20.03998351097107, 20.747990131378174, 21.493366956710815, 22.238743782043457, 22.972407341003418, 23.70607089996338, 24.42011547088623, 25.134160041809082, 25.865983247756958, 26.597806453704834, 27.3231303691864, 28.04845428466797, 28.766340494155884, 29.4842267036438, 30.215229034423828, 30.946231365203857, 31.661628007888794, 32.37702465057373, 33.10126805305481, 33.82551145553589, 34.55264687538147, 35.27978229522705, 35.996469020843506, 36.71315574645996, 37.435816526412964, 38.15847730636597, 38.88685846328735, 39.61523962020874, 40.333733797073364, 41.05222797393799, 41.777575969696045, 42.5029239654541, 43.22961068153381, 43.956297397613525, 44.662280797958374, 45.36826419830322, 46.10726881027222, 46.84627342224121, 47.580182790756226, 48.31409215927124, 49.027780055999756, 49.74146795272827, 50.46930980682373, 51.19715166091919, 51.923351526260376, 52.64955139160156, 53.36168813705444, 54.073824882507324, 54.80644726753235, 55.53906965255737, 56.26344847679138, 56.98782730102539, 57.70958423614502, 58.43134117126465, 59.156004667282104, 59.88066816329956, 60.59994673728943, 61.3192253112793, 62.03795504570007, 62.75668478012085, 63.479398250579834, 64.20211172103882, 64.91770792007446, 65.63330411911011, 66.35813236236572, 67.08296060562134, 67.81918549537659, 68.55541038513184, 69.26503109931946, 69.97465181350708, 70.70890617370605, 71.44316053390503, 72.18638157844543, 72.92960262298584, 73.65737628936768, 74.38514995574951, 75.1060950756073, 75.82704019546509, 76.56797242164612, 77.30890464782715, 78.03064942359924, 78.75239419937134, 79.47143769264221, 80.19048118591309, 80.92194557189941, 81.65340995788574, 82.37539315223694, 83.09737634658813, 83.80867791175842, 84.51997947692871, 85.2488808631897, 85.97778224945068, 86.62854170799255, 87.27930116653442, 87.92983078956604, 88.58036041259766, 89.23698163032532, 89.89360284805298, 90.53759622573853, 91.18158960342407, 91.84784269332886, 92.51409578323364, 93.16058111190796, 93.80706644058228, 94.4519579410553, 95.09684944152832, 95.7525360584259, 96.40822267532349, 97.04251837730408, 97.67681407928467, 98.33483815193176, 98.99286222457886, 99.65163731575012, 100.31041240692139, 100.9455201625824, 101.58062791824341, 102.24948835372925, 102.91834878921509, 103.56370615959167, 104.20906352996826, 104.88378930091858, 105.5585150718689, 106.24486804008484, 106.93122100830078, 107.56665062904358, 108.20208024978638, 108.86982870101929, 109.5375771522522, 110.19741344451904, 110.85724973678589, 111.5061981678009, 112.15514659881592, 112.82059621810913, 113.48604583740234, 114.12962484359741, 114.77320384979248, 115.43063354492188, 116.08806324005127, 116.74694013595581, 117.40581703186035, 118.045569896698, 118.68532276153564, 119.34007477760315, 119.99482679367065, 120.64856362342834, 121.30230045318604, 121.9463222026825, 122.59034395217896, 123.2548577785492, 123.91937160491943, 124.55461502075195, 125.18985843658447, 125.8535647392273, 126.51727104187012, 127.16302704811096, 127.8087830543518, 128.45821571350098, 129.10764837265015, 129.75858354568481, 130.40951871871948, 131.05841875076294, 131.7073187828064, 132.35548996925354, 133.00366115570068, 133.6425633430481, 134.2814655303955, 134.9319887161255, 135.58251190185547, 136.23990845680237, 136.89730501174927, 137.56000351905823, 138.2227020263672, 138.87017035484314, 139.5176386833191, 140.1779980659485, 140.83835744857788, 141.48981094360352, 142.14126443862915, 142.78158521652222, 143.42190599441528, 144.08989095687866, 144.75787591934204, 145.39921045303345, 146.04054498672485, 146.68960762023926, 147.33867025375366, 147.998361825943, 148.65805339813232, 149.30467247962952, 149.9512915611267, 150.6307988166809, 151.3103060722351, 151.9593048095703, 152.60830354690552, 153.2658998966217, 153.9234962463379, 154.58523559570312, 155.24697494506836, 155.8967125415802, 156.54645013809204, 157.19855952262878, 157.85066890716553, 158.5113182067871, 159.1719675064087, 159.84978795051575, 160.5276083946228, 161.25863456726074, 161.98966073989868, 162.71994853019714, 163.4502363204956, 164.19858193397522, 164.94692754745483, 165.69439148902893, 166.44185543060303, 167.1569037437439, 167.87195205688477, 168.61016726493835, 169.34838247299194, 170.07089757919312, 170.7934126853943, 171.5138385295868, 172.2342643737793, 172.93886637687683, 173.64346837997437, 174.360910654068, 175.07835292816162, 175.8083257675171, 176.53829860687256, 177.24613571166992, 177.95397281646729, 178.69636034965515, 179.43874788284302, 180.17180180549622, 180.9048557281494, 181.6195068359375, 182.3341579437256, 183.06664490699768, 183.79913187026978, 184.52220129966736, 185.24527072906494, 185.9751353263855, 186.70499992370605, 187.44288110733032, 188.1807622909546, 188.9005241394043, 189.620285987854, 190.2670202255249, 190.9137544631958, 191.6438546180725, 192.37395477294922, 193.10193514823914, 193.82991552352905, 194.55903482437134, 195.28815412521362, 196.00769662857056, 196.7272391319275, 197.46024107933044, 198.1932430267334, 198.92468309402466, 199.65612316131592, 200.38050985336304, 201.10489654541016, 201.85316562652588, 202.6014347076416, 203.33444356918335, 204.0674524307251, 204.79514145851135, 205.5228304862976, 206.26347589492798, 207.00412130355835, 207.73512935638428, 208.4661374092102, 209.18903017044067, 209.91192293167114, 210.6422426700592, 211.37256240844727, 212.1085720062256, 212.8445816040039, 213.5836136341095, 214.3226456642151, 215.07418990135193, 215.82573413848877, 216.5607032775879, 217.295672416687, 218.03309059143066, 218.77050876617432, 219.52608823776245, 220.2816677093506, 221.00336456298828, 221.72506141662598, 222.4505422115326, 223.1760230064392, 223.9143054485321, 224.652587890625, 225.38181400299072, 226.11104011535645, 226.8457646369934, 227.58048915863037, 228.31218671798706, 229.04388427734375, 229.78570866584778, 230.5275330543518, 231.2578320503235, 231.98813104629517, 232.7099370956421, 233.431743144989, 234.1646683216095, 234.89759349822998, 235.6288514137268, 236.36010932922363, 237.0968644618988, 237.83361959457397, 238.56475496292114, 239.2958903312683, 240.02509784698486, 240.75430536270142, 241.46997714042664, 242.18564891815186, 242.92271494865417, 243.6597809791565, 244.40237140655518, 245.14496183395386, 245.86516976356506, 246.58537769317627, 247.33075547218323, 248.07613325119019, 248.80304765701294, 249.5299620628357, 250.26882600784302, 251.00768995285034, 251.75281286239624, 252.49793577194214, 253.20866084098816, 253.91938591003418, 254.66736221313477, 255.41533851623535, 256.14406657218933, 256.8727946281433, 257.6161289215088, 258.35946321487427, 259.0979354381561, 259.836407661438, 260.55991435050964, 261.2834210395813, 262.04032373428345, 262.7972264289856, 263.51331520080566, 264.22940397262573, 264.98589301109314, 265.74238204956055, 266.50224781036377, 267.262113571167, 267.97131276130676, 268.68051195144653, 269.444872379303, 270.2092328071594, 270.9300911426544, 271.6509494781494, 272.40090823173523, 273.15086698532104, 273.8919360637665, 274.6330051422119, 275.3390588760376, 276.0451126098633, 276.80388259887695, 277.5626525878906, 278.2851634025574, 279.0076742172241, 279.76690649986267, 280.5261387825012, 281.28041648864746, 282.0346941947937, 282.7473633289337, 283.46003246307373, 284.81966519355774, 286.17929792404175]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[13.62, 13.62, 14.76, 14.76, 26.08, 26.08, 26.1, 26.1, 31.08, 31.08, 44.34, 44.34, 56.43, 56.43, 66.21, 66.21, 72.69, 72.69, 79.37, 79.37, 82.78, 82.78, 83.41, 83.41, 86.12, 86.12, 86.21, 86.21, 87.75, 87.75, 88.99, 88.99, 89.35, 89.35, 89.39, 89.39, 90.23, 90.23, 91.02, 91.02, 91.13, 91.13, 92.4, 92.4, 92.63, 92.63, 92.75, 92.75, 92.83, 92.83, 92.8, 92.8, 93.49, 93.49, 93.67, 93.67, 93.62, 93.62, 93.62, 93.62, 93.88, 93.88, 94.01, 94.01, 94.1, 94.1, 94.0, 94.0, 93.97, 93.97, 93.95, 93.95, 93.95, 93.95, 94.16, 94.16, 94.19, 94.19, 94.28, 94.28, 94.25, 94.25, 94.21, 94.21, 94.19, 94.19, 94.26, 94.26, 94.29, 94.29, 94.33, 94.33, 94.28, 94.28, 94.35, 94.35, 94.33, 94.33, 94.47, 94.47, 94.4, 94.4, 94.48, 94.48, 94.52, 94.52, 94.47, 94.47, 94.53, 94.53, 94.51, 94.51, 94.53, 94.53, 94.52, 94.52, 94.57, 94.57, 94.65, 94.65, 94.67, 94.67, 94.66, 94.66, 94.69, 94.69, 94.66, 94.66, 94.64, 94.64, 94.64, 94.64, 94.77, 94.77, 94.78, 94.78, 94.7, 94.7, 94.71, 94.71, 94.75, 94.75, 94.68, 94.68, 94.74, 94.74, 94.78, 94.78, 94.83, 94.83, 94.69, 94.69, 94.69, 94.69, 94.87, 94.87, 94.86, 94.86, 94.79, 94.79, 94.78, 94.78, 94.8, 94.8, 94.76, 94.76, 94.72, 94.72, 94.87, 94.87, 94.8, 94.8, 94.75, 94.75, 94.75, 94.75, 94.74, 94.74, 94.85, 94.85, 94.79, 94.79, 94.77, 94.77, 94.85, 94.85, 94.79, 94.79, 94.85, 94.85, 94.86, 94.86, 94.79, 94.79, 94.75, 94.75, 94.86, 94.86, 94.87, 94.87, 94.98, 94.98, 94.95, 94.95, 94.88, 94.88, 94.87, 94.87, 94.88, 94.88, 94.83, 94.83, 94.92, 94.92, 94.89, 94.89, 94.82, 94.82, 94.88, 94.88, 94.92, 94.92, 94.96, 94.96, 94.93, 94.93, 94.99, 94.99, 94.92, 94.92, 94.97, 94.97, 94.96, 94.96, 94.99, 94.99, 94.96, 94.96, 95.01, 95.01, 95.01, 95.01, 94.97, 94.97, 94.98, 94.98, 95.01, 95.01, 95.02, 95.02, 95.01, 95.01, 94.99, 94.99, 95.01, 95.01, 95.03, 95.03, 95.0, 95.0, 94.98, 94.98, 94.99, 94.99, 95.03, 95.03, 95.04, 95.04, 95.0, 95.0, 94.95, 94.95, 94.96, 94.96, 94.95, 94.95, 94.93, 94.93, 94.96, 94.96, 94.98, 94.98, 94.97, 94.97, 95.03, 95.03, 94.97, 94.97, 95.02, 95.02, 95.0, 95.0, 94.93, 94.93, 95.03, 95.03, 94.99, 94.99, 95.0, 95.0, 95.01, 95.01, 95.02, 95.02, 94.96, 94.96, 95.0, 95.0, 95.01, 95.01, 95.02, 95.02, 94.99, 94.99, 94.96, 94.96, 94.93, 94.93, 94.95, 94.95, 94.92, 94.92, 94.98, 94.98, 94.98, 94.98, 95.0, 95.0, 94.98, 94.98, 95.0, 95.0, 94.97, 94.97, 95.03, 95.03, 95.05, 95.05, 94.99, 94.99, 94.99, 94.99, 94.95, 94.95, 95.03, 95.03, 95.07, 95.07, 95.02, 95.02, 95.06, 95.06, 95.04, 95.04, 95.02, 95.02, 94.97, 94.97, 95.06, 95.06, 95.05, 95.05, 95.03, 95.03, 95.03, 95.03, 95.03, 95.03, 94.96, 94.96, 95.08, 95.08, 95.02, 95.02, 95.05, 95.05, 95.02, 95.02, 94.96, 94.96, 95.02, 95.02, 95.01, 95.01, 95.03, 95.03, 95.03, 95.03, 94.99, 94.99, 95.0, 95.0, 94.95, 94.95, 94.96, 94.96, 95.05, 95.05, 95.04, 95.04, 95.05, 95.05]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.291, Test loss: 2.296, Test accuracy: 24.22
Round   1, Train loss: 2.251, Test loss: 2.258, Test accuracy: 28.38
Round   2, Train loss: 2.023, Test loss: 2.049, Test accuracy: 57.65
Round   3, Train loss: 1.741, Test loss: 1.914, Test accuracy: 61.03
Round   4, Train loss: 1.730, Test loss: 1.798, Test accuracy: 71.05
Round   5, Train loss: 1.661, Test loss: 1.710, Test accuracy: 78.18
Round   6, Train loss: 1.629, Test loss: 1.697, Test accuracy: 78.71
Round   7, Train loss: 1.613, Test loss: 1.656, Test accuracy: 82.92
Round   8, Train loss: 1.605, Test loss: 1.654, Test accuracy: 82.73
Round   9, Train loss: 1.589, Test loss: 1.619, Test accuracy: 86.04
Round  10, Train loss: 1.530, Test loss: 1.597, Test accuracy: 87.80
Round  11, Train loss: 1.548, Test loss: 1.577, Test accuracy: 89.75
Round  12, Train loss: 1.514, Test loss: 1.572, Test accuracy: 90.06
Round  13, Train loss: 1.531, Test loss: 1.571, Test accuracy: 90.16
Round  14, Train loss: 1.573, Test loss: 1.569, Test accuracy: 90.26
Round  15, Train loss: 1.545, Test loss: 1.564, Test accuracy: 90.54
Round  16, Train loss: 1.506, Test loss: 1.564, Test accuracy: 90.51
Round  17, Train loss: 1.533, Test loss: 1.563, Test accuracy: 90.60
Round  18, Train loss: 1.595, Test loss: 1.560, Test accuracy: 90.77
Round  19, Train loss: 1.562, Test loss: 1.559, Test accuracy: 90.83
Round  20, Train loss: 1.524, Test loss: 1.560, Test accuracy: 90.79
Round  21, Train loss: 1.529, Test loss: 1.558, Test accuracy: 90.79
Round  22, Train loss: 1.526, Test loss: 1.557, Test accuracy: 90.97
Round  23, Train loss: 1.487, Test loss: 1.556, Test accuracy: 91.08
Round  24, Train loss: 1.554, Test loss: 1.557, Test accuracy: 90.88
Round  25, Train loss: 1.555, Test loss: 1.556, Test accuracy: 91.00
Round  26, Train loss: 1.520, Test loss: 1.555, Test accuracy: 91.02
Round  27, Train loss: 1.498, Test loss: 1.555, Test accuracy: 91.03
Round  28, Train loss: 1.523, Test loss: 1.554, Test accuracy: 91.14
Round  29, Train loss: 1.518, Test loss: 1.554, Test accuracy: 91.13
Round  30, Train loss: 1.552, Test loss: 1.554, Test accuracy: 91.07
Round  31, Train loss: 1.583, Test loss: 1.554, Test accuracy: 91.20
Round  32, Train loss: 1.487, Test loss: 1.554, Test accuracy: 91.13
Round  33, Train loss: 1.519, Test loss: 1.554, Test accuracy: 91.15
Round  34, Train loss: 1.547, Test loss: 1.554, Test accuracy: 91.16
Round  35, Train loss: 1.510, Test loss: 1.553, Test accuracy: 91.25
Round  36, Train loss: 1.514, Test loss: 1.552, Test accuracy: 91.31
Round  37, Train loss: 1.545, Test loss: 1.552, Test accuracy: 91.30
Round  38, Train loss: 1.546, Test loss: 1.552, Test accuracy: 91.28
Round  39, Train loss: 1.513, Test loss: 1.551, Test accuracy: 91.30
Round  40, Train loss: 1.514, Test loss: 1.551, Test accuracy: 91.30
Round  41, Train loss: 1.511, Test loss: 1.550, Test accuracy: 91.30
Round  42, Train loss: 1.483, Test loss: 1.550, Test accuracy: 91.34
Round  43, Train loss: 1.514, Test loss: 1.550, Test accuracy: 91.46
Round  44, Train loss: 1.484, Test loss: 1.550, Test accuracy: 91.35
Round  45, Train loss: 1.505, Test loss: 1.549, Test accuracy: 91.54
Round  46, Train loss: 1.543, Test loss: 1.549, Test accuracy: 91.50
Round  47, Train loss: 1.479, Test loss: 1.548, Test accuracy: 91.54
Round  48, Train loss: 1.507, Test loss: 1.548, Test accuracy: 91.52
Round  49, Train loss: 1.546, Test loss: 1.548, Test accuracy: 91.54
Round  50, Train loss: 1.506, Test loss: 1.548, Test accuracy: 91.53
Round  51, Train loss: 1.475, Test loss: 1.548, Test accuracy: 91.50
Round  52, Train loss: 1.540, Test loss: 1.548, Test accuracy: 91.55
Round  53, Train loss: 1.481, Test loss: 1.548, Test accuracy: 91.59
Round  54, Train loss: 1.515, Test loss: 1.548, Test accuracy: 91.58
Round  55, Train loss: 1.509, Test loss: 1.547, Test accuracy: 91.58
Round  56, Train loss: 1.474, Test loss: 1.547, Test accuracy: 91.58
Round  57, Train loss: 1.546, Test loss: 1.547, Test accuracy: 91.60
Round  58, Train loss: 1.544, Test loss: 1.547, Test accuracy: 91.67
Round  59, Train loss: 1.574, Test loss: 1.547, Test accuracy: 91.63
Round  60, Train loss: 1.504, Test loss: 1.547, Test accuracy: 91.65
Round  61, Train loss: 1.513, Test loss: 1.547, Test accuracy: 91.60
Round  62, Train loss: 1.507, Test loss: 1.547, Test accuracy: 91.68
Round  63, Train loss: 1.510, Test loss: 1.546, Test accuracy: 91.70
Round  64, Train loss: 1.474, Test loss: 1.546, Test accuracy: 91.78
Round  65, Train loss: 1.541, Test loss: 1.546, Test accuracy: 91.76
Round  66, Train loss: 1.481, Test loss: 1.546, Test accuracy: 91.74
Round  67, Train loss: 1.475, Test loss: 1.546, Test accuracy: 91.79
Round  68, Train loss: 1.501, Test loss: 1.545, Test accuracy: 91.79
Round  69, Train loss: 1.538, Test loss: 1.545, Test accuracy: 91.86
Round  70, Train loss: 1.508, Test loss: 1.546, Test accuracy: 91.80
Round  71, Train loss: 1.507, Test loss: 1.546, Test accuracy: 91.84
Round  72, Train loss: 1.476, Test loss: 1.545, Test accuracy: 91.82
Round  73, Train loss: 1.508, Test loss: 1.545, Test accuracy: 91.84
Round  74, Train loss: 1.475, Test loss: 1.545, Test accuracy: 91.83
Round  75, Train loss: 1.507, Test loss: 1.545, Test accuracy: 91.79
Round  76, Train loss: 1.507, Test loss: 1.545, Test accuracy: 91.87
Round  77, Train loss: 1.571, Test loss: 1.545, Test accuracy: 91.90
Round  78, Train loss: 1.543, Test loss: 1.545, Test accuracy: 91.90
Round  79, Train loss: 1.536, Test loss: 1.545, Test accuracy: 91.89
Round  80, Train loss: 1.504, Test loss: 1.545, Test accuracy: 91.85
Round  81, Train loss: 1.509, Test loss: 1.545, Test accuracy: 91.92
Round  82, Train loss: 1.471, Test loss: 1.545, Test accuracy: 91.87
Round  83, Train loss: 1.506, Test loss: 1.545, Test accuracy: 91.85
Round  84, Train loss: 1.541, Test loss: 1.545, Test accuracy: 91.92
Round  85, Train loss: 1.475, Test loss: 1.544, Test accuracy: 91.89
Round  86, Train loss: 1.506, Test loss: 1.545, Test accuracy: 91.90
Round  87, Train loss: 1.536, Test loss: 1.544, Test accuracy: 91.92
Round  88, Train loss: 1.538, Test loss: 1.544, Test accuracy: 91.92
Round  89, Train loss: 1.506, Test loss: 1.544, Test accuracy: 91.98
Round  90, Train loss: 1.508, Test loss: 1.544, Test accuracy: 91.92
Round  91, Train loss: 1.535, Test loss: 1.544, Test accuracy: 91.94
Round  92, Train loss: 1.506, Test loss: 1.544, Test accuracy: 91.89
Round  93, Train loss: 1.509, Test loss: 1.544, Test accuracy: 91.93
Round  94, Train loss: 1.537, Test loss: 1.544, Test accuracy: 91.92
Round  95, Train loss: 1.504, Test loss: 1.544, Test accuracy: 91.98
Round  96, Train loss: 1.504, Test loss: 1.544, Test accuracy: 91.96
Round  97, Train loss: 1.506, Test loss: 1.544, Test accuracy: 91.89
Round  98, Train loss: 1.504, Test loss: 1.545, Test accuracy: 91.82
Round  99, Train loss: 1.505, Test loss: 1.544, Test accuracy: 91.89
Round 100, Train loss: 1.476, Test loss: 1.544, Test accuracy: 91.85
Round 101, Train loss: 1.570, Test loss: 1.544, Test accuracy: 91.98
Round 102, Train loss: 1.506, Test loss: 1.544, Test accuracy: 91.92
Round 103, Train loss: 1.538, Test loss: 1.543, Test accuracy: 92.03
Round 104, Train loss: 1.605, Test loss: 1.544, Test accuracy: 91.97
Round 105, Train loss: 1.505, Test loss: 1.543, Test accuracy: 92.04
Round 106, Train loss: 1.468, Test loss: 1.544, Test accuracy: 91.99
Round 107, Train loss: 1.504, Test loss: 1.543, Test accuracy: 92.06
Round 108, Train loss: 1.536, Test loss: 1.543, Test accuracy: 92.07
Round 109, Train loss: 1.470, Test loss: 1.543, Test accuracy: 92.11
Round 110, Train loss: 1.503, Test loss: 1.543, Test accuracy: 92.02
Round 111, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.03
Round 112, Train loss: 1.537, Test loss: 1.543, Test accuracy: 92.14
Round 113, Train loss: 1.539, Test loss: 1.543, Test accuracy: 92.06
Round 114, Train loss: 1.538, Test loss: 1.543, Test accuracy: 92.00
Round 115, Train loss: 1.503, Test loss: 1.543, Test accuracy: 92.09
Round 116, Train loss: 1.535, Test loss: 1.543, Test accuracy: 92.08
Round 117, Train loss: 1.506, Test loss: 1.543, Test accuracy: 92.04
Round 118, Train loss: 1.502, Test loss: 1.543, Test accuracy: 92.06
Round 119, Train loss: 1.503, Test loss: 1.543, Test accuracy: 92.02
Round 120, Train loss: 1.473, Test loss: 1.543, Test accuracy: 92.05
Round 121, Train loss: 1.502, Test loss: 1.543, Test accuracy: 92.04
Round 122, Train loss: 1.503, Test loss: 1.543, Test accuracy: 92.05
Round 123, Train loss: 1.472, Test loss: 1.543, Test accuracy: 92.05
Round 124, Train loss: 1.538, Test loss: 1.543, Test accuracy: 92.07
Round 125, Train loss: 1.538, Test loss: 1.543, Test accuracy: 92.05
Round 126, Train loss: 1.504, Test loss: 1.543, Test accuracy: 92.01
Round 127, Train loss: 1.471, Test loss: 1.543, Test accuracy: 92.07
Round 128, Train loss: 1.569, Test loss: 1.543, Test accuracy: 92.02
Round 129, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.01
Round 130, Train loss: 1.469, Test loss: 1.543, Test accuracy: 91.99
Round 131, Train loss: 1.503, Test loss: 1.543, Test accuracy: 91.96
Round 132, Train loss: 1.537, Test loss: 1.542, Test accuracy: 92.04
Round 133, Train loss: 1.471, Test loss: 1.542, Test accuracy: 92.09
Round 134, Train loss: 1.471, Test loss: 1.542, Test accuracy: 92.08
Round 135, Train loss: 1.505, Test loss: 1.543, Test accuracy: 92.05
Round 136, Train loss: 1.473, Test loss: 1.543, Test accuracy: 92.02
Round 137, Train loss: 1.502, Test loss: 1.542, Test accuracy: 92.07
Round 138, Train loss: 1.502, Test loss: 1.542, Test accuracy: 92.10
Round 139, Train loss: 1.503, Test loss: 1.542, Test accuracy: 91.99
Round 140, Train loss: 1.472, Test loss: 1.543, Test accuracy: 92.02
Round 141, Train loss: 1.537, Test loss: 1.542, Test accuracy: 92.03
Round 142, Train loss: 1.536, Test loss: 1.542, Test accuracy: 92.02
Round 143, Train loss: 1.507, Test loss: 1.543, Test accuracy: 92.02
Round 144, Train loss: 1.537, Test loss: 1.543, Test accuracy: 91.97
Round 145, Train loss: 1.537, Test loss: 1.543, Test accuracy: 91.99
Round 146, Train loss: 1.506, Test loss: 1.543, Test accuracy: 92.00
Round 147, Train loss: 1.471, Test loss: 1.543, Test accuracy: 91.95
Round 148, Train loss: 1.536, Test loss: 1.543, Test accuracy: 91.97
Round 149, Train loss: 1.504, Test loss: 1.542, Test accuracy: 92.03
Round 150, Train loss: 1.470, Test loss: 1.542, Test accuracy: 92.01
Round 151, Train loss: 1.503, Test loss: 1.542, Test accuracy: 91.99
Round 152, Train loss: 1.536, Test loss: 1.542, Test accuracy: 92.05
Round 153, Train loss: 1.535, Test loss: 1.542, Test accuracy: 92.06
Round 154, Train loss: 1.504, Test loss: 1.542, Test accuracy: 92.03
Round 155, Train loss: 1.469, Test loss: 1.542, Test accuracy: 92.06
Round 156, Train loss: 1.537, Test loss: 1.542, Test accuracy: 92.10
Round 157, Train loss: 1.536, Test loss: 1.542, Test accuracy: 92.13
Round 158, Train loss: 1.469, Test loss: 1.542, Test accuracy: 92.14
Round 159, Train loss: 1.535, Test loss: 1.542, Test accuracy: 92.11
Round 160, Train loss: 1.535, Test loss: 1.542, Test accuracy: 92.09
Round 161, Train loss: 1.504, Test loss: 1.542, Test accuracy: 92.12
Round 162, Train loss: 1.469, Test loss: 1.542, Test accuracy: 92.16
Round 163, Train loss: 1.504, Test loss: 1.542, Test accuracy: 92.13
Round 164, Train loss: 1.469, Test loss: 1.542, Test accuracy: 92.12
Round 165, Train loss: 1.500, Test loss: 1.542, Test accuracy: 92.09
Round 166, Train loss: 1.503, Test loss: 1.542, Test accuracy: 92.09
Round 167, Train loss: 1.505, Test loss: 1.542, Test accuracy: 92.13
Round 168, Train loss: 1.568, Test loss: 1.542, Test accuracy: 92.13
Round 169, Train loss: 1.471, Test loss: 1.542, Test accuracy: 92.09
Round 170, Train loss: 1.503, Test loss: 1.542, Test accuracy: 92.12
Round 171, Train loss: 1.503, Test loss: 1.542, Test accuracy: 92.14
Round 172, Train loss: 1.537, Test loss: 1.542, Test accuracy: 92.17
Round 173, Train loss: 1.471, Test loss: 1.542, Test accuracy: 92.16
Round 174, Train loss: 1.502, Test loss: 1.541, Test accuracy: 92.18
Round 175, Train loss: 1.537, Test loss: 1.541, Test accuracy: 92.17
Round 176, Train loss: 1.504, Test loss: 1.542, Test accuracy: 92.14
Round 177, Train loss: 1.536, Test loss: 1.541, Test accuracy: 92.17
Round 178, Train loss: 1.500, Test loss: 1.542, Test accuracy: 92.14
Round 179, Train loss: 1.502, Test loss: 1.541, Test accuracy: 92.17
Round 180, Train loss: 1.501, Test loss: 1.541, Test accuracy: 92.13
Round 181, Train loss: 1.470, Test loss: 1.541, Test accuracy: 92.18
Round 182, Train loss: 1.504, Test loss: 1.541, Test accuracy: 92.20
Round 183, Train loss: 1.538, Test loss: 1.541, Test accuracy: 92.20
Round 184, Train loss: 1.467, Test loss: 1.541, Test accuracy: 92.20
Round 185, Train loss: 1.535, Test loss: 1.542, Test accuracy: 92.13
Round 186, Train loss: 1.535, Test loss: 1.541, Test accuracy: 92.12
Round 187, Train loss: 1.503, Test loss: 1.541, Test accuracy: 92.15
Round 188, Train loss: 1.502, Test loss: 1.541, Test accuracy: 92.16
Round 189, Train loss: 1.469, Test loss: 1.541, Test accuracy: 92.16
Round 190, Train loss: 1.536, Test loss: 1.541, Test accuracy: 92.13
Round 191, Train loss: 1.569, Test loss: 1.542, Test accuracy: 92.11
Round 192, Train loss: 1.503, Test loss: 1.542, Test accuracy: 92.13
Round 193, Train loss: 1.569, Test loss: 1.541, Test accuracy: 92.11
Round 194, Train loss: 1.504, Test loss: 1.541, Test accuracy: 92.10
Round 195, Train loss: 1.472, Test loss: 1.541, Test accuracy: 92.11
Round 196, Train loss: 1.501, Test loss: 1.541, Test accuracy: 92.14
Round 197, Train loss: 1.471, Test loss: 1.541, Test accuracy: 92.12
Round 198, Train loss: 1.501, Test loss: 1.541, Test accuracy: 92.15
Round 199, Train loss: 1.535, Test loss: 1.541, Test accuracy: 92.17
Final Round, Train loss: 1.509, Test loss: 1.542, Test accuracy: 92.13
Average accuracy final 10 rounds: 92.12700000000001 

1792.0910637378693
[0.9107418060302734, 1.8214836120605469, 2.655583620071411, 3.4896836280822754, 4.1712400913238525, 4.85279655456543, 5.555365085601807, 6.257933616638184, 6.948909044265747, 7.6398844718933105, 8.320888042449951, 9.001891613006592, 9.708497047424316, 10.415102481842041, 11.094155311584473, 11.773208141326904, 12.482344388961792, 13.19148063659668, 13.894695281982422, 14.597909927368164, 15.266852617263794, 15.935795307159424, 16.645094871520996, 17.35439443588257, 18.033706665039062, 18.713018894195557, 19.418148279190063, 20.12327766418457, 20.831201791763306, 21.53912591934204, 22.20510721206665, 22.87108850479126, 23.571038007736206, 24.270987510681152, 24.970733642578125, 25.670479774475098, 26.351498126983643, 27.032516479492188, 27.735283374786377, 28.438050270080566, 29.119345664978027, 29.80064105987549, 30.495793342590332, 31.190945625305176, 31.87942409515381, 32.56790256500244, 33.24251580238342, 33.917129039764404, 34.61480355262756, 35.31247806549072, 35.988959550857544, 36.665441036224365, 37.36456489562988, 38.0636887550354, 38.749420166015625, 39.43515157699585, 40.11311221122742, 40.791072845458984, 41.50356912612915, 42.216065406799316, 42.874420166015625, 43.532774925231934, 44.24105453491211, 44.949334144592285, 45.64733576774597, 46.34533739089966, 47.00684475898743, 47.668352127075195, 48.368388652801514, 49.06842517852783, 49.76117181777954, 50.45391845703125, 51.144526958465576, 51.8351354598999, 52.53312921524048, 53.231122970581055, 53.902997970581055, 54.574872970581055, 55.27388381958008, 55.9728946685791, 56.67269492149353, 57.37249517440796, 58.043301582336426, 58.71410799026489, 59.42293190956116, 60.13175582885742, 60.80685067176819, 61.481945514678955, 62.18154335021973, 62.8811411857605, 63.58805274963379, 64.29496431350708, 64.96539258956909, 65.6358208656311, 66.34762954711914, 67.05943822860718, 67.7271659374237, 68.39489364624023, 69.10039782524109, 69.80590200424194, 70.52618432044983, 71.24646663665771, 71.90696310997009, 72.56745958328247, 73.28497767448425, 74.00249576568604, 74.71984076499939, 75.43718576431274, 76.15937614440918, 76.88156652450562, 77.59987902641296, 78.31819152832031, 78.97239017486572, 79.62658882141113, 80.3475878238678, 81.06858682632446, 81.76468348503113, 82.4607801437378, 83.11895179748535, 83.77712345123291, 84.49065089225769, 85.20417833328247, 85.86395692825317, 86.52373552322388, 87.22722125053406, 87.93070697784424, 88.63163447380066, 89.33256196975708, 90.00962567329407, 90.68668937683105, 91.38809013366699, 92.08949089050293, 92.74985647201538, 93.41022205352783, 94.1195113658905, 94.82880067825317, 95.51665687561035, 96.20451307296753, 96.88852787017822, 97.57254266738892, 98.2856330871582, 98.99872350692749, 99.68770432472229, 100.37668514251709, 101.08404779434204, 101.79141044616699, 102.5125036239624, 103.23359680175781, 103.90250062942505, 104.57140445709229, 105.30449032783508, 106.03757619857788, 106.74994111061096, 107.46230602264404, 108.14088821411133, 108.81947040557861, 109.54404258728027, 110.26861476898193, 110.95218276977539, 111.63575077056885, 112.3425669670105, 113.04938316345215, 113.78666067123413, 114.52393817901611, 115.19472980499268, 115.86552143096924, 116.57799029350281, 117.29045915603638, 117.99424481391907, 118.69803047180176, 119.37738728523254, 120.05674409866333, 120.75355315208435, 121.45036220550537, 122.1366491317749, 122.82293605804443, 123.53616261482239, 124.24938917160034, 124.9763994216919, 125.70340967178345, 126.39697885513306, 127.09054803848267, 127.78949117660522, 128.48843431472778, 129.20834040641785, 129.9282464981079, 130.659161567688, 131.39007663726807, 132.11326122283936, 132.83644580841064, 133.56469559669495, 134.29294538497925, 134.9897701740265, 135.68659496307373, 136.41253185272217, 137.1384687423706, 137.84491229057312, 138.55135583877563, 139.30268502235413, 140.05401420593262, 140.75671935081482, 141.45942449569702, 142.1929750442505, 142.92652559280396, 143.6804928779602, 144.43446016311646, 145.17479920387268, 145.9151382446289, 146.6513249874115, 147.3875117301941, 148.12783646583557, 148.86816120147705, 149.57464027404785, 150.28111934661865, 150.99739408493042, 151.7136688232422, 152.45300197601318, 153.19233512878418, 153.90343570709229, 154.6145362854004, 155.34074068069458, 156.06694507598877, 156.8752999305725, 157.68365478515625, 158.40611219406128, 159.1285696029663, 159.83291721343994, 160.53726482391357, 161.2150218486786, 161.8927788734436, 162.65084433555603, 163.40890979766846, 164.12258672714233, 164.8362636566162, 165.56608867645264, 166.29591369628906, 167.02631211280823, 167.7567105293274, 168.414612531662, 169.07251453399658, 169.8146595954895, 170.55680465698242, 171.27439618110657, 171.9919877052307, 172.69520568847656, 173.3984236717224, 174.12056064605713, 174.84269762039185, 175.63917708396912, 176.4356565475464, 177.16675686836243, 177.89785718917847, 178.5982346534729, 179.29861211776733, 180.0245237350464, 180.75043535232544, 181.48521637916565, 182.21999740600586, 182.929349899292, 183.63870239257812, 184.35693788528442, 185.07517337799072, 185.75873374938965, 186.44229412078857, 187.1666398048401, 187.8909854888916, 188.63353180885315, 189.3760781288147, 190.1103322505951, 190.8445863723755, 191.54956245422363, 192.25453853607178, 192.97070360183716, 193.68686866760254, 194.40252113342285, 195.11817359924316, 195.80115914344788, 196.4841446876526, 197.20855593681335, 197.93296718597412, 198.63928270339966, 199.3455982208252, 200.0714156627655, 200.7972331047058, 201.52949500083923, 202.26175689697266, 202.97430157661438, 203.6868462562561, 204.407532453537, 205.12821865081787, 205.79760670661926, 206.46699476242065, 207.19658613204956, 207.92617750167847, 208.65005540847778, 209.3739333152771, 210.10688042640686, 210.83982753753662, 211.57761359214783, 212.31539964675903, 213.02944946289062, 213.74349927902222, 214.47730612754822, 215.21111297607422, 215.93068027496338, 216.65024757385254, 217.38086199760437, 218.1114764213562, 218.85625410079956, 219.60103178024292, 220.35607767105103, 221.11112356185913, 221.8257782459259, 222.54043292999268, 223.21542596817017, 223.89041900634766, 224.6241660118103, 225.35791301727295, 226.07379722595215, 226.78968143463135, 227.53243708610535, 228.27519273757935, 229.01727485656738, 229.75935697555542, 230.51010489463806, 231.2608528137207, 231.99675583839417, 232.73265886306763, 233.39022612571716, 234.0477933883667, 234.78748393058777, 235.52717447280884, 236.26242876052856, 236.9976830482483, 237.74897694587708, 238.50027084350586, 239.25366640090942, 240.007061958313, 240.72434163093567, 241.44162130355835, 242.18024516105652, 242.9188690185547, 243.61617469787598, 244.31348037719727, 245.0311300754547, 245.74877977371216, 246.48201060295105, 247.21524143218994, 247.93369388580322, 248.6521463394165, 249.3712100982666, 250.0902738571167, 250.8034791946411, 251.51668453216553, 252.21740794181824, 252.91813135147095, 253.67156648635864, 254.42500162124634, 255.14315056800842, 255.8612995147705, 256.5686523914337, 257.2760052680969, 258.0014679431915, 258.72693061828613, 259.43588280677795, 260.1448349952698, 260.81602597236633, 261.4872169494629, 262.219083070755, 262.9509491920471, 263.6547417640686, 264.3585343360901, 265.09426617622375, 265.8299980163574, 266.5670027732849, 267.3040075302124, 268.0077214241028, 268.71143531799316, 269.482017993927, 270.25260066986084, 270.91673970222473, 271.5808787345886, 272.33845233917236, 273.0960259437561, 273.82569122314453, 274.55535650253296, 275.2614953517914, 275.9676342010498, 276.7037785053253, 277.43992280960083, 278.11755752563477, 278.7951922416687, 279.5225908756256, 280.2499895095825, 280.96670293807983, 281.68341636657715, 282.3931541442871, 283.10289192199707, 283.84399151802063, 284.5850911140442, 285.92221760749817, 287.25934410095215]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[24.22, 24.22, 28.38, 28.38, 57.65, 57.65, 61.03, 61.03, 71.05, 71.05, 78.18, 78.18, 78.71, 78.71, 82.92, 82.92, 82.73, 82.73, 86.04, 86.04, 87.8, 87.8, 89.75, 89.75, 90.06, 90.06, 90.16, 90.16, 90.26, 90.26, 90.54, 90.54, 90.51, 90.51, 90.6, 90.6, 90.77, 90.77, 90.83, 90.83, 90.79, 90.79, 90.79, 90.79, 90.97, 90.97, 91.08, 91.08, 90.88, 90.88, 91.0, 91.0, 91.02, 91.02, 91.03, 91.03, 91.14, 91.14, 91.13, 91.13, 91.07, 91.07, 91.2, 91.2, 91.13, 91.13, 91.15, 91.15, 91.16, 91.16, 91.25, 91.25, 91.31, 91.31, 91.3, 91.3, 91.28, 91.28, 91.3, 91.3, 91.3, 91.3, 91.3, 91.3, 91.34, 91.34, 91.46, 91.46, 91.35, 91.35, 91.54, 91.54, 91.5, 91.5, 91.54, 91.54, 91.52, 91.52, 91.54, 91.54, 91.53, 91.53, 91.5, 91.5, 91.55, 91.55, 91.59, 91.59, 91.58, 91.58, 91.58, 91.58, 91.58, 91.58, 91.6, 91.6, 91.67, 91.67, 91.63, 91.63, 91.65, 91.65, 91.6, 91.6, 91.68, 91.68, 91.7, 91.7, 91.78, 91.78, 91.76, 91.76, 91.74, 91.74, 91.79, 91.79, 91.79, 91.79, 91.86, 91.86, 91.8, 91.8, 91.84, 91.84, 91.82, 91.82, 91.84, 91.84, 91.83, 91.83, 91.79, 91.79, 91.87, 91.87, 91.9, 91.9, 91.9, 91.9, 91.89, 91.89, 91.85, 91.85, 91.92, 91.92, 91.87, 91.87, 91.85, 91.85, 91.92, 91.92, 91.89, 91.89, 91.9, 91.9, 91.92, 91.92, 91.92, 91.92, 91.98, 91.98, 91.92, 91.92, 91.94, 91.94, 91.89, 91.89, 91.93, 91.93, 91.92, 91.92, 91.98, 91.98, 91.96, 91.96, 91.89, 91.89, 91.82, 91.82, 91.89, 91.89, 91.85, 91.85, 91.98, 91.98, 91.92, 91.92, 92.03, 92.03, 91.97, 91.97, 92.04, 92.04, 91.99, 91.99, 92.06, 92.06, 92.07, 92.07, 92.11, 92.11, 92.02, 92.02, 92.03, 92.03, 92.14, 92.14, 92.06, 92.06, 92.0, 92.0, 92.09, 92.09, 92.08, 92.08, 92.04, 92.04, 92.06, 92.06, 92.02, 92.02, 92.05, 92.05, 92.04, 92.04, 92.05, 92.05, 92.05, 92.05, 92.07, 92.07, 92.05, 92.05, 92.01, 92.01, 92.07, 92.07, 92.02, 92.02, 92.01, 92.01, 91.99, 91.99, 91.96, 91.96, 92.04, 92.04, 92.09, 92.09, 92.08, 92.08, 92.05, 92.05, 92.02, 92.02, 92.07, 92.07, 92.1, 92.1, 91.99, 91.99, 92.02, 92.02, 92.03, 92.03, 92.02, 92.02, 92.02, 92.02, 91.97, 91.97, 91.99, 91.99, 92.0, 92.0, 91.95, 91.95, 91.97, 91.97, 92.03, 92.03, 92.01, 92.01, 91.99, 91.99, 92.05, 92.05, 92.06, 92.06, 92.03, 92.03, 92.06, 92.06, 92.1, 92.1, 92.13, 92.13, 92.14, 92.14, 92.11, 92.11, 92.09, 92.09, 92.12, 92.12, 92.16, 92.16, 92.13, 92.13, 92.12, 92.12, 92.09, 92.09, 92.09, 92.09, 92.13, 92.13, 92.13, 92.13, 92.09, 92.09, 92.12, 92.12, 92.14, 92.14, 92.17, 92.17, 92.16, 92.16, 92.18, 92.18, 92.17, 92.17, 92.14, 92.14, 92.17, 92.17, 92.14, 92.14, 92.17, 92.17, 92.13, 92.13, 92.18, 92.18, 92.2, 92.2, 92.2, 92.2, 92.2, 92.2, 92.13, 92.13, 92.12, 92.12, 92.15, 92.15, 92.16, 92.16, 92.16, 92.16, 92.13, 92.13, 92.11, 92.11, 92.13, 92.13, 92.11, 92.11, 92.1, 92.1, 92.11, 92.11, 92.14, 92.14, 92.12, 92.12, 92.15, 92.15, 92.17, 92.17, 92.13, 92.13]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.293, Test accuracy: 14.10
Round   1, Train loss: 2.233, Test loss: 2.250, Test accuracy: 26.81
Round   2, Train loss: 2.053, Test loss: 2.111, Test accuracy: 47.75
Round   3, Train loss: 1.883, Test loss: 1.963, Test accuracy: 58.86
Round   4, Train loss: 1.665, Test loss: 1.905, Test accuracy: 60.88
Round   5, Train loss: 1.741, Test loss: 1.816, Test accuracy: 70.48
Round   6, Train loss: 1.696, Test loss: 1.735, Test accuracy: 75.87
Round   7, Train loss: 1.667, Test loss: 1.732, Test accuracy: 74.79
Round   8, Train loss: 1.630, Test loss: 1.688, Test accuracy: 79.51
Round   9, Train loss: 1.576, Test loss: 1.671, Test accuracy: 81.10
Round  10, Train loss: 1.572, Test loss: 1.654, Test accuracy: 82.70
Round  11, Train loss: 1.589, Test loss: 1.638, Test accuracy: 84.44
Round  12, Train loss: 1.551, Test loss: 1.639, Test accuracy: 83.95
Round  13, Train loss: 1.517, Test loss: 1.631, Test accuracy: 84.65
Round  14, Train loss: 1.577, Test loss: 1.630, Test accuracy: 84.25
Round  15, Train loss: 1.544, Test loss: 1.621, Test accuracy: 85.35
Round  16, Train loss: 1.530, Test loss: 1.607, Test accuracy: 86.97
Round  17, Train loss: 1.587, Test loss: 1.601, Test accuracy: 87.21
Round  18, Train loss: 1.567, Test loss: 1.599, Test accuracy: 87.20
Round  19, Train loss: 1.520, Test loss: 1.579, Test accuracy: 90.07
Round  20, Train loss: 1.481, Test loss: 1.574, Test accuracy: 90.51
Round  21, Train loss: 1.504, Test loss: 1.563, Test accuracy: 91.66
Round  22, Train loss: 1.490, Test loss: 1.553, Test accuracy: 92.47
Round  23, Train loss: 1.477, Test loss: 1.552, Test accuracy: 92.39
Round  24, Train loss: 1.475, Test loss: 1.552, Test accuracy: 92.22
Round  25, Train loss: 1.480, Test loss: 1.545, Test accuracy: 92.70
Round  26, Train loss: 1.479, Test loss: 1.543, Test accuracy: 92.85
Round  27, Train loss: 1.478, Test loss: 1.541, Test accuracy: 92.94
Round  28, Train loss: 1.473, Test loss: 1.543, Test accuracy: 92.70
Round  29, Train loss: 1.476, Test loss: 1.541, Test accuracy: 93.01
Round  30, Train loss: 1.477, Test loss: 1.539, Test accuracy: 93.16
Round  31, Train loss: 1.478, Test loss: 1.538, Test accuracy: 93.22
Round  32, Train loss: 1.470, Test loss: 1.537, Test accuracy: 93.16
Round  33, Train loss: 1.477, Test loss: 1.536, Test accuracy: 93.21
Round  34, Train loss: 1.474, Test loss: 1.536, Test accuracy: 93.25
Round  35, Train loss: 1.477, Test loss: 1.536, Test accuracy: 93.18
Round  36, Train loss: 1.467, Test loss: 1.536, Test accuracy: 93.12
Round  37, Train loss: 1.472, Test loss: 1.535, Test accuracy: 93.19
Round  38, Train loss: 1.474, Test loss: 1.535, Test accuracy: 93.26
Round  39, Train loss: 1.474, Test loss: 1.535, Test accuracy: 93.34
Round  40, Train loss: 1.473, Test loss: 1.535, Test accuracy: 93.24
Round  41, Train loss: 1.472, Test loss: 1.534, Test accuracy: 93.27
Round  42, Train loss: 1.472, Test loss: 1.534, Test accuracy: 93.29
Round  43, Train loss: 1.472, Test loss: 1.534, Test accuracy: 93.25
Round  44, Train loss: 1.474, Test loss: 1.534, Test accuracy: 93.37
Round  45, Train loss: 1.472, Test loss: 1.534, Test accuracy: 93.31
Round  46, Train loss: 1.475, Test loss: 1.534, Test accuracy: 93.29
Round  47, Train loss: 1.469, Test loss: 1.533, Test accuracy: 93.39
Round  48, Train loss: 1.470, Test loss: 1.533, Test accuracy: 93.37
Round  49, Train loss: 1.469, Test loss: 1.533, Test accuracy: 93.35
Round  50, Train loss: 1.469, Test loss: 1.533, Test accuracy: 93.38
Round  51, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.35
Round  52, Train loss: 1.472, Test loss: 1.533, Test accuracy: 93.41
Round  53, Train loss: 1.470, Test loss: 1.532, Test accuracy: 93.34
Round  54, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.41
Round  55, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.42
Round  56, Train loss: 1.471, Test loss: 1.532, Test accuracy: 93.43
Round  57, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.45
Round  58, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.45
Round  59, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.43
Round  60, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.44
Round  61, Train loss: 1.471, Test loss: 1.532, Test accuracy: 93.43
Round  62, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.41
Round  63, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.44
Round  64, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.48
Round  65, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.43
Round  66, Train loss: 1.470, Test loss: 1.531, Test accuracy: 93.48
Round  67, Train loss: 1.470, Test loss: 1.531, Test accuracy: 93.43
Round  68, Train loss: 1.470, Test loss: 1.531, Test accuracy: 93.43
Round  69, Train loss: 1.472, Test loss: 1.531, Test accuracy: 93.40
Round  70, Train loss: 1.475, Test loss: 1.531, Test accuracy: 93.40
Round  71, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.37
Round  72, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.41
Round  73, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.41
Round  74, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.40
Round  75, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.37
Round  76, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.40
Round  77, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.35
Round  78, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.38
Round  79, Train loss: 1.466, Test loss: 1.531, Test accuracy: 93.35
Round  80, Train loss: 1.467, Test loss: 1.531, Test accuracy: 93.37
Round  81, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.36
Round  82, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.36
Round  83, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.36
Round  84, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.38
Round  85, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.37
Round  86, Train loss: 1.472, Test loss: 1.531, Test accuracy: 93.37
Round  87, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.38
Round  88, Train loss: 1.473, Test loss: 1.531, Test accuracy: 93.38
Round  89, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.37
Round  90, Train loss: 1.472, Test loss: 1.531, Test accuracy: 93.39
Round  91, Train loss: 1.467, Test loss: 1.531, Test accuracy: 93.38
Round  92, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.40
Round  93, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.36
Round  94, Train loss: 1.474, Test loss: 1.531, Test accuracy: 93.36
Round  95, Train loss: 1.470, Test loss: 1.531, Test accuracy: 93.37
Round  96, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.37
Round  97, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.38
Round  98, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.39
Round  99, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.39/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.469, Test loss: 1.531, Test accuracy: 93.35
Average accuracy final 10 rounds: 93.37899999999999 

927.7251737117767
[0.938152551651001, 1.876305103302002, 2.6608595848083496, 3.4454140663146973, 4.170430898666382, 4.895447731018066, 5.631933689117432, 6.368419647216797, 7.106555461883545, 7.844691276550293, 8.564090490341187, 9.28348970413208, 10.02288818359375, 10.76228666305542, 11.44620394706726, 12.130121231079102, 12.851902484893799, 13.573683738708496, 14.311394929885864, 15.049106121063232, 15.731527090072632, 16.41394805908203, 17.171898365020752, 17.929848670959473, 18.63386368751526, 19.337878704071045, 20.07116675376892, 20.804454803466797, 21.551913499832153, 22.29937219619751, 22.98947811126709, 23.67958402633667, 24.44649577140808, 25.213407516479492, 25.937147617340088, 26.660887718200684, 27.365208625793457, 28.06952953338623, 28.84739851951599, 29.625267505645752, 30.355407238006592, 31.08554697036743, 31.797874212265015, 32.5102014541626, 33.225311517715454, 33.94042158126831, 34.64966106414795, 35.35890054702759, 36.104880809783936, 36.85086107254028, 37.58517336845398, 38.319485664367676, 39.0339629650116, 39.74844026565552, 40.4986617565155, 41.24888324737549, 41.960155725479126, 42.671428203582764, 43.38136291503906, 44.09129762649536, 44.83164834976196, 45.571999073028564, 46.29228472709656, 47.01257038116455, 47.7412314414978, 48.469892501831055, 49.20700240135193, 49.9441123008728, 50.65687918663025, 51.369646072387695, 52.09281277656555, 52.81597948074341, 53.525617837905884, 54.23525619506836, 54.94305968284607, 55.65086317062378, 56.40876626968384, 57.1666693687439, 57.89291167259216, 58.61915397644043, 59.35633993148804, 60.093525886535645, 60.80419564247131, 61.51486539840698, 62.21728730201721, 62.91970920562744, 63.66108560562134, 64.40246200561523, 65.11226654052734, 65.82207107543945, 66.55339932441711, 67.28472757339478, 68.02472424507141, 68.76472091674805, 69.48515963554382, 70.2055983543396, 70.94599199295044, 71.68638563156128, 72.4014241695404, 73.11646270751953, 73.83356499671936, 74.55066728591919, 75.2893340587616, 76.028000831604, 76.75233054161072, 77.47666025161743, 78.1760470867157, 78.87543392181396, 79.60758304595947, 80.33973217010498, 81.08261942863464, 81.8255066871643, 82.54286241531372, 83.26021814346313, 84.0001220703125, 84.74002599716187, 85.47299885749817, 86.20597171783447, 86.9396698474884, 87.67336797714233, 88.38769507408142, 89.10202217102051, 89.84315896034241, 90.5842957496643, 91.28228282928467, 91.98026990890503, 92.72584557533264, 93.47142124176025, 94.21207976341248, 94.9527382850647, 95.67920017242432, 96.40566205978394, 97.13525342941284, 97.86484479904175, 98.55395102500916, 99.24305725097656, 99.96028709411621, 100.67751693725586, 101.41559886932373, 102.1536808013916, 102.86223101615906, 103.57078123092651, 104.30846381187439, 105.04614639282227, 105.74537968635559, 106.44461297988892, 107.18124198913574, 107.91787099838257, 108.639639377594, 109.36140775680542, 110.09345030784607, 110.82549285888672, 111.570809841156, 112.3161268234253, 113.02451038360596, 113.73289394378662, 114.4546217918396, 115.17634963989258, 115.90569162368774, 116.63503360748291, 117.36752605438232, 118.10001850128174, 118.82938528060913, 119.55875205993652, 120.28065967559814, 121.00256729125977, 121.72894883155823, 122.45533037185669, 123.17288780212402, 123.89044523239136, 124.62319850921631, 125.35595178604126, 126.07048535346985, 126.78501892089844, 127.51061058044434, 128.23620223999023, 128.95754742622375, 129.67889261245728, 130.39139103889465, 131.10388946533203, 131.8318054676056, 132.55972146987915, 133.24625515937805, 133.93278884887695, 134.66004419326782, 135.3872995376587, 136.11524200439453, 136.84318447113037, 137.56329536437988, 138.2834062576294, 139.0303602218628, 139.7773141860962, 140.4570164680481, 141.13671875, 141.85739731788635, 142.5780758857727, 143.29617524147034, 144.01427459716797, 144.7458610534668, 145.47744750976562, 146.8639588356018, 148.250470161438]
[14.1, 14.1, 26.81, 26.81, 47.75, 47.75, 58.86, 58.86, 60.88, 60.88, 70.48, 70.48, 75.87, 75.87, 74.79, 74.79, 79.51, 79.51, 81.1, 81.1, 82.7, 82.7, 84.44, 84.44, 83.95, 83.95, 84.65, 84.65, 84.25, 84.25, 85.35, 85.35, 86.97, 86.97, 87.21, 87.21, 87.2, 87.2, 90.07, 90.07, 90.51, 90.51, 91.66, 91.66, 92.47, 92.47, 92.39, 92.39, 92.22, 92.22, 92.7, 92.7, 92.85, 92.85, 92.94, 92.94, 92.7, 92.7, 93.01, 93.01, 93.16, 93.16, 93.22, 93.22, 93.16, 93.16, 93.21, 93.21, 93.25, 93.25, 93.18, 93.18, 93.12, 93.12, 93.19, 93.19, 93.26, 93.26, 93.34, 93.34, 93.24, 93.24, 93.27, 93.27, 93.29, 93.29, 93.25, 93.25, 93.37, 93.37, 93.31, 93.31, 93.29, 93.29, 93.39, 93.39, 93.37, 93.37, 93.35, 93.35, 93.38, 93.38, 93.35, 93.35, 93.41, 93.41, 93.34, 93.34, 93.41, 93.41, 93.42, 93.42, 93.43, 93.43, 93.45, 93.45, 93.45, 93.45, 93.43, 93.43, 93.44, 93.44, 93.43, 93.43, 93.41, 93.41, 93.44, 93.44, 93.48, 93.48, 93.43, 93.43, 93.48, 93.48, 93.43, 93.43, 93.43, 93.43, 93.4, 93.4, 93.4, 93.4, 93.37, 93.37, 93.41, 93.41, 93.41, 93.41, 93.4, 93.4, 93.37, 93.37, 93.4, 93.4, 93.35, 93.35, 93.38, 93.38, 93.35, 93.35, 93.37, 93.37, 93.36, 93.36, 93.36, 93.36, 93.36, 93.36, 93.38, 93.38, 93.37, 93.37, 93.37, 93.37, 93.38, 93.38, 93.38, 93.38, 93.37, 93.37, 93.39, 93.39, 93.38, 93.38, 93.4, 93.4, 93.36, 93.36, 93.36, 93.36, 93.37, 93.37, 93.37, 93.37, 93.38, 93.38, 93.39, 93.39, 93.39, 93.39, 93.35, 93.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.575, Test loss: 2.254, Test accuracy: 55.81
Round   1, Train loss: 1.350, Test loss: 2.119, Test accuracy: 54.92
Round   2, Train loss: 1.222, Test loss: 1.924, Test accuracy: 70.27
Round   3, Train loss: 1.296, Test loss: 1.858, Test accuracy: 74.09
Round   4, Train loss: 1.278, Test loss: 1.808, Test accuracy: 76.99
Round   5, Train loss: 1.176, Test loss: 1.773, Test accuracy: 80.37
Round   6, Train loss: 1.160, Test loss: 1.747, Test accuracy: 82.39
Round   7, Train loss: 1.218, Test loss: 1.718, Test accuracy: 85.53
Round   8, Train loss: 1.194, Test loss: 1.708, Test accuracy: 85.53
Round   9, Train loss: 1.193, Test loss: 1.701, Test accuracy: 85.54
Round  10, Train loss: 1.191, Test loss: 1.690, Test accuracy: 86.62
Round  11, Train loss: 1.183, Test loss: 1.687, Test accuracy: 86.19
Round  12, Train loss: 1.145, Test loss: 1.679, Test accuracy: 86.75
Round  13, Train loss: 1.213, Test loss: 1.678, Test accuracy: 86.44
Round  14, Train loss: 1.185, Test loss: 1.677, Test accuracy: 86.37
Round  15, Train loss: 1.155, Test loss: 1.671, Test accuracy: 86.51
Round  16, Train loss: 1.135, Test loss: 1.670, Test accuracy: 86.24
Round  17, Train loss: 1.205, Test loss: 1.671, Test accuracy: 86.18
Round  18, Train loss: 1.156, Test loss: 1.668, Test accuracy: 86.32
Round  19, Train loss: 1.158, Test loss: 1.667, Test accuracy: 86.26
Round  20, Train loss: 1.153, Test loss: 1.671, Test accuracy: 85.60
Round  21, Train loss: 1.156, Test loss: 1.670, Test accuracy: 85.58
Round  22, Train loss: 1.205, Test loss: 1.668, Test accuracy: 85.64
Round  23, Train loss: 1.179, Test loss: 1.667, Test accuracy: 85.66
Round  24, Train loss: 1.205, Test loss: 1.669, Test accuracy: 85.47
Round  25, Train loss: 1.129, Test loss: 1.667, Test accuracy: 85.58
Round  26, Train loss: 1.204, Test loss: 1.667, Test accuracy: 85.86
Round  27, Train loss: 1.181, Test loss: 1.668, Test accuracy: 85.65
Round  28, Train loss: 1.130, Test loss: 1.667, Test accuracy: 85.66
Round  29, Train loss: 1.153, Test loss: 1.666, Test accuracy: 85.41
Round  30, Train loss: 1.175, Test loss: 1.665, Test accuracy: 85.27
Round  31, Train loss: 1.181, Test loss: 1.666, Test accuracy: 85.11
Round  32, Train loss: 1.177, Test loss: 1.666, Test accuracy: 85.08
Round  33, Train loss: 1.130, Test loss: 1.668, Test accuracy: 84.86
Round  34, Train loss: 1.151, Test loss: 1.666, Test accuracy: 85.03
Round  35, Train loss: 1.176, Test loss: 1.670, Test accuracy: 84.48
Round  36, Train loss: 1.129, Test loss: 1.668, Test accuracy: 84.54
Round  37, Train loss: 1.151, Test loss: 1.667, Test accuracy: 84.52
Round  38, Train loss: 1.129, Test loss: 1.667, Test accuracy: 84.43
Round  39, Train loss: 1.153, Test loss: 1.667, Test accuracy: 84.34
Round  40, Train loss: 1.153, Test loss: 1.669, Test accuracy: 84.08
Round  41, Train loss: 1.128, Test loss: 1.670, Test accuracy: 84.11
Round  42, Train loss: 1.202, Test loss: 1.669, Test accuracy: 84.10
Round  43, Train loss: 1.176, Test loss: 1.671, Test accuracy: 83.89
Round  44, Train loss: 1.131, Test loss: 1.672, Test accuracy: 83.74
Round  45, Train loss: 1.103, Test loss: 1.671, Test accuracy: 83.76
Round  46, Train loss: 1.129, Test loss: 1.672, Test accuracy: 83.36
Round  47, Train loss: 1.132, Test loss: 1.673, Test accuracy: 83.31
Round  48, Train loss: 1.130, Test loss: 1.673, Test accuracy: 83.21
Round  49, Train loss: 1.128, Test loss: 1.673, Test accuracy: 83.30
Round  50, Train loss: 1.153, Test loss: 1.676, Test accuracy: 82.92
Round  51, Train loss: 1.150, Test loss: 1.675, Test accuracy: 82.81
Round  52, Train loss: 1.128, Test loss: 1.678, Test accuracy: 82.69
Round  53, Train loss: 1.179, Test loss: 1.678, Test accuracy: 82.65
Round  54, Train loss: 1.175, Test loss: 1.677, Test accuracy: 82.69
Round  55, Train loss: 1.151, Test loss: 1.676, Test accuracy: 82.71
Round  56, Train loss: 1.130, Test loss: 1.677, Test accuracy: 82.67
Round  57, Train loss: 1.175, Test loss: 1.679, Test accuracy: 82.45
Round  58, Train loss: 1.129, Test loss: 1.682, Test accuracy: 82.09
Round  59, Train loss: 1.152, Test loss: 1.681, Test accuracy: 81.96
Round  60, Train loss: 1.126, Test loss: 1.682, Test accuracy: 81.89
Round  61, Train loss: 1.151, Test loss: 1.682, Test accuracy: 81.86
Round  62, Train loss: 1.128, Test loss: 1.683, Test accuracy: 81.91
Round  63, Train loss: 1.174, Test loss: 1.683, Test accuracy: 81.61
Round  64, Train loss: 1.176, Test loss: 1.687, Test accuracy: 81.42
Round  65, Train loss: 1.175, Test loss: 1.686, Test accuracy: 81.32
Round  66, Train loss: 1.151, Test loss: 1.689, Test accuracy: 81.00
Round  67, Train loss: 1.126, Test loss: 1.688, Test accuracy: 81.01
Round  68, Train loss: 1.151, Test loss: 1.688, Test accuracy: 81.05
Round  69, Train loss: 1.150, Test loss: 1.687, Test accuracy: 81.08
Round  70, Train loss: 1.150, Test loss: 1.688, Test accuracy: 81.00
Round  71, Train loss: 1.127, Test loss: 1.689, Test accuracy: 81.00
Round  72, Train loss: 1.153, Test loss: 1.690, Test accuracy: 80.78
Round  73, Train loss: 1.126, Test loss: 1.689, Test accuracy: 80.89
Round  74, Train loss: 1.149, Test loss: 1.690, Test accuracy: 80.76
Round  75, Train loss: 1.174, Test loss: 1.690, Test accuracy: 80.67
Round  76, Train loss: 1.127, Test loss: 1.692, Test accuracy: 80.52
Round  77, Train loss: 1.174, Test loss: 1.693, Test accuracy: 80.47
Round  78, Train loss: 1.177, Test loss: 1.694, Test accuracy: 80.15
Round  79, Train loss: 1.127, Test loss: 1.693, Test accuracy: 80.33
Round  80, Train loss: 1.151, Test loss: 1.694, Test accuracy: 80.19
Round  81, Train loss: 1.176, Test loss: 1.695, Test accuracy: 80.11
Round  82, Train loss: 1.198, Test loss: 1.695, Test accuracy: 80.03
Round  83, Train loss: 1.151, Test loss: 1.694, Test accuracy: 80.20
Round  84, Train loss: 1.173, Test loss: 1.694, Test accuracy: 80.27
Round  85, Train loss: 1.152, Test loss: 1.697, Test accuracy: 80.03
Round  86, Train loss: 1.172, Test loss: 1.697, Test accuracy: 80.10
Round  87, Train loss: 1.151, Test loss: 1.698, Test accuracy: 79.96
Round  88, Train loss: 1.174, Test loss: 1.699, Test accuracy: 79.83
Round  89, Train loss: 1.151, Test loss: 1.698, Test accuracy: 79.79
Round  90, Train loss: 1.125, Test loss: 1.700, Test accuracy: 79.63
Round  91, Train loss: 1.150, Test loss: 1.700, Test accuracy: 79.43
Round  92, Train loss: 1.148, Test loss: 1.702, Test accuracy: 79.41
Round  93, Train loss: 1.148, Test loss: 1.701, Test accuracy: 79.32
Round  94, Train loss: 1.151, Test loss: 1.700, Test accuracy: 79.45
Round  95, Train loss: 1.198, Test loss: 1.702, Test accuracy: 79.19
Round  96, Train loss: 1.125, Test loss: 1.704, Test accuracy: 79.09
Round  97, Train loss: 1.150, Test loss: 1.703, Test accuracy: 79.08
Round  98, Train loss: 1.125, Test loss: 1.705, Test accuracy: 78.88
Round  99, Train loss: 1.126, Test loss: 1.705, Test accuracy: 78.49
Final Round, Train loss: 1.152, Test loss: 1.708, Test accuracy: 78.27
Average accuracy final 10 rounds: 79.197
1131.6452820301056
[]
[55.81, 54.92, 70.27, 74.09, 76.99, 80.37, 82.39, 85.53, 85.53, 85.54, 86.62, 86.19, 86.75, 86.44, 86.37, 86.51, 86.24, 86.18, 86.32, 86.26, 85.6, 85.58, 85.64, 85.66, 85.47, 85.58, 85.86, 85.65, 85.66, 85.41, 85.27, 85.11, 85.08, 84.86, 85.03, 84.48, 84.54, 84.52, 84.43, 84.34, 84.08, 84.11, 84.1, 83.89, 83.74, 83.76, 83.36, 83.31, 83.21, 83.3, 82.92, 82.81, 82.69, 82.65, 82.69, 82.71, 82.67, 82.45, 82.09, 81.96, 81.89, 81.86, 81.91, 81.61, 81.42, 81.32, 81.0, 81.01, 81.05, 81.08, 81.0, 81.0, 80.78, 80.89, 80.76, 80.67, 80.52, 80.47, 80.15, 80.33, 80.19, 80.11, 80.03, 80.2, 80.27, 80.03, 80.1, 79.96, 79.83, 79.79, 79.63, 79.43, 79.41, 79.32, 79.45, 79.19, 79.09, 79.08, 78.88, 78.49, 78.27]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.287, Test loss: 2.289, Test accuracy: 16.40
Round   1, Train loss: 2.267, Test loss: 2.275, Test accuracy: 18.00
Round   2, Train loss: 2.257, Test loss: 2.267, Test accuracy: 19.24
Round   3, Train loss: 2.232, Test loss: 2.235, Test accuracy: 22.54
Round   4, Train loss: 2.178, Test loss: 2.198, Test accuracy: 24.60
Round   5, Train loss: 1.893, Test loss: 2.106, Test accuracy: 39.67
Round   6, Train loss: 1.590, Test loss: 2.021, Test accuracy: 51.54
Round   7, Train loss: 1.825, Test loss: 2.040, Test accuracy: 49.84
Round   8, Train loss: 1.253, Test loss: 2.046, Test accuracy: 48.41
Round   9, Train loss: 1.743, Test loss: 2.023, Test accuracy: 46.61
Round  10, Train loss: 0.808, Test loss: 1.969, Test accuracy: 50.80
Round  11, Train loss: 1.057, Test loss: 2.031, Test accuracy: 44.64
Round  12, Train loss: 1.552, Test loss: 2.013, Test accuracy: 46.44
Round  13, Train loss: 1.294, Test loss: 1.982, Test accuracy: 50.52
Round  14, Train loss: 1.260, Test loss: 1.935, Test accuracy: 57.06
Round  15, Train loss: 0.886, Test loss: 1.901, Test accuracy: 60.36
Round  16, Train loss: 1.067, Test loss: 1.922, Test accuracy: 57.23
Round  17, Train loss: 0.340, Test loss: 1.866, Test accuracy: 61.13
Round  18, Train loss: 0.657, Test loss: 1.854, Test accuracy: 61.26
Round  19, Train loss: 0.215, Test loss: 1.889, Test accuracy: 56.50
Round  20, Train loss: 0.410, Test loss: 1.825, Test accuracy: 63.90
Round  21, Train loss: 1.301, Test loss: 1.839, Test accuracy: 63.16
Round  22, Train loss: 0.516, Test loss: 1.792, Test accuracy: 68.22
Round  23, Train loss: 0.238, Test loss: 1.821, Test accuracy: 64.55
Round  24, Train loss: -0.873, Test loss: 1.775, Test accuracy: 69.37
Round  25, Train loss: 0.508, Test loss: 1.784, Test accuracy: 68.54
Round  26, Train loss: 0.183, Test loss: 1.752, Test accuracy: 72.16
Round  27, Train loss: 0.337, Test loss: 1.749, Test accuracy: 73.07
Round  28, Train loss: -0.086, Test loss: 1.685, Test accuracy: 78.58
Round  29, Train loss: 1.156, Test loss: 1.713, Test accuracy: 77.00
Round  30, Train loss: -0.761, Test loss: 1.640, Test accuracy: 83.84
Round  31, Train loss: 0.537, Test loss: 1.664, Test accuracy: 81.41
Round  32, Train loss: 0.365, Test loss: 1.681, Test accuracy: 79.82
Round  33, Train loss: 0.009, Test loss: 1.685, Test accuracy: 78.67
Round  34, Train loss: -0.846, Test loss: 1.680, Test accuracy: 78.85
Round  35, Train loss: -1.189, Test loss: 1.630, Test accuracy: 83.71
Round  36, Train loss: -1.218, Test loss: 1.658, Test accuracy: 80.61
Round  37, Train loss: 0.231, Test loss: 1.682, Test accuracy: 78.36
Round  38, Train loss: -0.670, Test loss: 1.642, Test accuracy: 82.46
Round  39, Train loss: 0.012, Test loss: 1.640, Test accuracy: 82.48
Round  40, Train loss: -0.761, Test loss: 1.644, Test accuracy: 81.95
Round  41, Train loss: -1.265, Test loss: 1.646, Test accuracy: 81.66
Round  42, Train loss: 0.487, Test loss: 1.665, Test accuracy: 79.86
Round  43, Train loss: -0.605, Test loss: 1.647, Test accuracy: 81.63
Round  44, Train loss: -1.398, Test loss: 1.592, Test accuracy: 86.94
Round  45, Train loss: -0.152, Test loss: 1.610, Test accuracy: 85.08
Round  46, Train loss: -0.062, Test loss: 1.635, Test accuracy: 82.52
Round  47, Train loss: 0.035, Test loss: 1.642, Test accuracy: 82.03
Round  48, Train loss: -0.361, Test loss: 1.638, Test accuracy: 82.63
Round  49, Train loss: -0.983, Test loss: 1.626, Test accuracy: 83.64
Round  50, Train loss: -0.397, Test loss: 1.616, Test accuracy: 84.68
Round  51, Train loss: -0.400, Test loss: 1.623, Test accuracy: 83.87
Round  52, Train loss: -0.623, Test loss: 1.633, Test accuracy: 82.91
Round  53, Train loss: -0.761, Test loss: 1.632, Test accuracy: 82.95
Round  54, Train loss: -1.027, Test loss: 1.630, Test accuracy: 83.20
Round  55, Train loss: -0.657, Test loss: 1.612, Test accuracy: 84.88
Round  56, Train loss: -0.766, Test loss: 1.594, Test accuracy: 86.90
Round  57, Train loss: -0.368, Test loss: 1.597, Test accuracy: 86.70
Round  58, Train loss: -0.963, Test loss: 1.568, Test accuracy: 89.56
Round  59, Train loss: -0.400, Test loss: 1.584, Test accuracy: 87.88
Round  60, Train loss: -0.940, Test loss: 1.576, Test accuracy: 88.68
Round  61, Train loss: -0.641, Test loss: 1.600, Test accuracy: 86.30
Round  62, Train loss: -0.328, Test loss: 1.593, Test accuracy: 86.96
Round  63, Train loss: -0.543, Test loss: 1.590, Test accuracy: 87.26
Round  64, Train loss: -0.640, Test loss: 1.575, Test accuracy: 88.73
Round  65, Train loss: -0.554, Test loss: 1.594, Test accuracy: 86.87
Round  66, Train loss: -0.703, Test loss: 1.587, Test accuracy: 87.57
Round  67, Train loss: -0.490, Test loss: 1.575, Test accuracy: 88.81
Round  68, Train loss: -0.359, Test loss: 1.599, Test accuracy: 86.35
Round  69, Train loss: -0.866, Test loss: 1.600, Test accuracy: 86.18
Round  70, Train loss: -0.607, Test loss: 1.591, Test accuracy: 87.04
Round  71, Train loss: -0.535, Test loss: 1.581, Test accuracy: 88.07
Round  72, Train loss: -0.574, Test loss: 1.581, Test accuracy: 88.08
Round  73, Train loss: -0.804, Test loss: 1.580, Test accuracy: 88.09
Round  74, Train loss: -0.392, Test loss: 1.594, Test accuracy: 86.77
Round  75, Train loss: -0.538, Test loss: 1.611, Test accuracy: 85.03
Round  76, Train loss: -0.533, Test loss: 1.589, Test accuracy: 87.17
Round  77, Train loss: -0.770, Test loss: 1.589, Test accuracy: 87.26
Round  78, Train loss: -0.497, Test loss: 1.586, Test accuracy: 87.63
Round  79, Train loss: -0.561, Test loss: 1.586, Test accuracy: 87.62
Round  80, Train loss: -0.865, Test loss: 1.572, Test accuracy: 89.00
Round  81, Train loss: -0.588, Test loss: 1.569, Test accuracy: 89.30
Round  82, Train loss: -0.630, Test loss: 1.572, Test accuracy: 88.97
Round  83, Train loss: -0.188, Test loss: 1.591, Test accuracy: 87.17
Round  84, Train loss: -0.481, Test loss: 1.583, Test accuracy: 88.07
Round  85, Train loss: -0.476, Test loss: 1.578, Test accuracy: 88.66
Round  86, Train loss: -0.826, Test loss: 1.557, Test accuracy: 90.65
Round  87, Train loss: -0.396, Test loss: 1.571, Test accuracy: 88.95
Round  88, Train loss: -0.521, Test loss: 1.564, Test accuracy: 89.72
Round  89, Train loss: -0.354, Test loss: 1.572, Test accuracy: 89.04
Round  90, Train loss: -0.628, Test loss: 1.569, Test accuracy: 89.42
Round  91, Train loss: -0.266, Test loss: 1.576, Test accuracy: 88.53
Round  92, Train loss: -0.178, Test loss: 1.584, Test accuracy: 87.76
Round  93, Train loss: -0.343, Test loss: 1.564, Test accuracy: 89.87
Round  94, Train loss: -0.762, Test loss: 1.558, Test accuracy: 90.41
Round  95, Train loss: -0.492, Test loss: 1.554, Test accuracy: 90.86
Round  96, Train loss: -0.931, Test loss: 1.555, Test accuracy: 90.80
Round  97, Train loss: -0.084, Test loss: 1.571, Test accuracy: 89.20
Round  98, Train loss: -0.097, Test loss: 1.580, Test accuracy: 88.34
Round  99, Train loss: -0.220, Test loss: 1.580, Test accuracy: 88.35
Final Round, Train loss: 1.563, Test loss: 1.559, Test accuracy: 91.32
Average accuracy final 10 rounds: 89.354
Average global accuracy final 10 rounds: 89.354
846.9021475315094
[]
[16.4, 18.0, 19.24, 22.54, 24.6, 39.67, 51.54, 49.84, 48.41, 46.61, 50.8, 44.64, 46.44, 50.52, 57.06, 60.36, 57.23, 61.13, 61.26, 56.5, 63.9, 63.16, 68.22, 64.55, 69.37, 68.54, 72.16, 73.07, 78.58, 77.0, 83.84, 81.41, 79.82, 78.67, 78.85, 83.71, 80.61, 78.36, 82.46, 82.48, 81.95, 81.66, 79.86, 81.63, 86.94, 85.08, 82.52, 82.03, 82.63, 83.64, 84.68, 83.87, 82.91, 82.95, 83.2, 84.88, 86.9, 86.7, 89.56, 87.88, 88.68, 86.3, 86.96, 87.26, 88.73, 86.87, 87.57, 88.81, 86.35, 86.18, 87.04, 88.07, 88.08, 88.09, 86.77, 85.03, 87.17, 87.26, 87.63, 87.62, 89.0, 89.3, 88.97, 87.17, 88.07, 88.66, 90.65, 88.95, 89.72, 89.04, 89.42, 88.53, 87.76, 89.87, 90.41, 90.86, 90.8, 89.2, 88.34, 88.35, 91.32]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.293, Test accuracy: 17.68
Round   0, Global train loss: 2.290, Global test loss: 2.297, Global test accuracy: 14.00
Round   1, Train loss: 2.261, Test loss: 2.252, Test accuracy: 23.58
Round   1, Global train loss: 2.261, Global test loss: 2.269, Global test accuracy: 21.67
Round   2, Train loss: 2.133, Test loss: 2.169, Test accuracy: 30.74
Round   2, Global train loss: 2.133, Global test loss: 2.183, Global test accuracy: 31.52
Round   3, Train loss: 1.954, Test loss: 2.044, Test accuracy: 47.35
Round   3, Global train loss: 1.954, Global test loss: 2.050, Global test accuracy: 45.51
Round   4, Train loss: 1.815, Test loss: 1.956, Test accuracy: 55.20
Round   4, Global train loss: 1.815, Global test loss: 1.941, Global test accuracy: 58.37
Round   5, Train loss: 1.764, Test loss: 1.893, Test accuracy: 60.30
Round   5, Global train loss: 1.764, Global test loss: 1.842, Global test accuracy: 67.26
Round   6, Train loss: 1.777, Test loss: 1.860, Test accuracy: 62.84
Round   6, Global train loss: 1.777, Global test loss: 1.855, Global test accuracy: 63.22
Round   7, Train loss: 1.689, Test loss: 1.767, Test accuracy: 71.61
Round   7, Global train loss: 1.689, Global test loss: 1.781, Global test accuracy: 71.52
Round   8, Train loss: 1.680, Test loss: 1.733, Test accuracy: 74.12
Round   8, Global train loss: 1.680, Global test loss: 1.763, Global test accuracy: 72.37
Round   9, Train loss: 1.704, Test loss: 1.733, Test accuracy: 73.94
Round   9, Global train loss: 1.704, Global test loss: 1.789, Global test accuracy: 69.61
Round  10, Train loss: 1.731, Test loss: 1.722, Test accuracy: 74.43
Round  10, Global train loss: 1.731, Global test loss: 1.753, Global test accuracy: 72.70
Round  11, Train loss: 1.697, Test loss: 1.721, Test accuracy: 74.49
Round  11, Global train loss: 1.697, Global test loss: 1.753, Global test accuracy: 72.35
Round  12, Train loss: 1.749, Test loss: 1.720, Test accuracy: 74.53
Round  12, Global train loss: 1.749, Global test loss: 1.754, Global test accuracy: 72.03
Round  13, Train loss: 1.649, Test loss: 1.699, Test accuracy: 77.16
Round  13, Global train loss: 1.649, Global test loss: 1.739, Global test accuracy: 74.28
Round  14, Train loss: 1.694, Test loss: 1.696, Test accuracy: 77.32
Round  14, Global train loss: 1.694, Global test loss: 1.749, Global test accuracy: 72.42
Round  15, Train loss: 1.593, Test loss: 1.682, Test accuracy: 78.74
Round  15, Global train loss: 1.593, Global test loss: 1.718, Global test accuracy: 76.19
Round  16, Train loss: 1.636, Test loss: 1.671, Test accuracy: 79.88
Round  16, Global train loss: 1.636, Global test loss: 1.714, Global test accuracy: 76.37
Round  17, Train loss: 1.701, Test loss: 1.672, Test accuracy: 79.79
Round  17, Global train loss: 1.701, Global test loss: 1.715, Global test accuracy: 76.51
Round  18, Train loss: 1.667, Test loss: 1.666, Test accuracy: 80.18
Round  18, Global train loss: 1.667, Global test loss: 1.714, Global test accuracy: 76.29
Round  19, Train loss: 1.601, Test loss: 1.659, Test accuracy: 80.68
Round  19, Global train loss: 1.601, Global test loss: 1.707, Global test accuracy: 77.14
Round  20, Train loss: 1.662, Test loss: 1.659, Test accuracy: 80.70
Round  20, Global train loss: 1.662, Global test loss: 1.695, Global test accuracy: 77.84
Round  21, Train loss: 1.662, Test loss: 1.657, Test accuracy: 80.79
Round  21, Global train loss: 1.662, Global test loss: 1.716, Global test accuracy: 76.02
Round  22, Train loss: 1.631, Test loss: 1.657, Test accuracy: 80.83
Round  22, Global train loss: 1.631, Global test loss: 1.694, Global test accuracy: 78.01
Round  23, Train loss: 1.686, Test loss: 1.657, Test accuracy: 80.82
Round  23, Global train loss: 1.686, Global test loss: 1.692, Global test accuracy: 77.99
Round  24, Train loss: 1.567, Test loss: 1.655, Test accuracy: 81.04
Round  24, Global train loss: 1.567, Global test loss: 1.685, Global test accuracy: 78.59
Round  25, Train loss: 1.657, Test loss: 1.654, Test accuracy: 80.99
Round  25, Global train loss: 1.657, Global test loss: 1.693, Global test accuracy: 77.87
Round  26, Train loss: 1.656, Test loss: 1.653, Test accuracy: 81.13
Round  26, Global train loss: 1.656, Global test loss: 1.686, Global test accuracy: 78.75
Round  27, Train loss: 1.623, Test loss: 1.654, Test accuracy: 81.09
Round  27, Global train loss: 1.623, Global test loss: 1.699, Global test accuracy: 76.93
Round  28, Train loss: 1.707, Test loss: 1.653, Test accuracy: 81.06
Round  28, Global train loss: 1.707, Global test loss: 1.699, Global test accuracy: 76.66
Round  29, Train loss: 1.681, Test loss: 1.653, Test accuracy: 80.98
Round  29, Global train loss: 1.681, Global test loss: 1.686, Global test accuracy: 78.26
Round  30, Train loss: 1.647, Test loss: 1.655, Test accuracy: 80.77
Round  30, Global train loss: 1.647, Global test loss: 1.691, Global test accuracy: 77.81
Round  31, Train loss: 1.627, Test loss: 1.654, Test accuracy: 80.82
Round  31, Global train loss: 1.627, Global test loss: 1.686, Global test accuracy: 78.29
Round  32, Train loss: 1.706, Test loss: 1.653, Test accuracy: 81.00
Round  32, Global train loss: 1.706, Global test loss: 1.689, Global test accuracy: 77.99
Round  33, Train loss: 1.686, Test loss: 1.653, Test accuracy: 81.01
Round  33, Global train loss: 1.686, Global test loss: 1.690, Global test accuracy: 77.70
Round  34, Train loss: 1.680, Test loss: 1.652, Test accuracy: 81.07
Round  34, Global train loss: 1.680, Global test loss: 1.687, Global test accuracy: 78.14
Round  35, Train loss: 1.617, Test loss: 1.652, Test accuracy: 81.12
Round  35, Global train loss: 1.617, Global test loss: 1.680, Global test accuracy: 78.83
Round  36, Train loss: 1.644, Test loss: 1.651, Test accuracy: 81.11
Round  36, Global train loss: 1.644, Global test loss: 1.690, Global test accuracy: 77.78
Round  37, Train loss: 1.675, Test loss: 1.651, Test accuracy: 81.10
Round  37, Global train loss: 1.675, Global test loss: 1.711, Global test accuracy: 75.51
Round  38, Train loss: 1.674, Test loss: 1.651, Test accuracy: 81.14
Round  38, Global train loss: 1.674, Global test loss: 1.685, Global test accuracy: 78.42
Round  39, Train loss: 1.613, Test loss: 1.650, Test accuracy: 81.07
Round  39, Global train loss: 1.613, Global test loss: 1.698, Global test accuracy: 77.19
Round  40, Train loss: 1.611, Test loss: 1.650, Test accuracy: 81.20
Round  40, Global train loss: 1.611, Global test loss: 1.688, Global test accuracy: 78.12
Round  41, Train loss: 1.587, Test loss: 1.650, Test accuracy: 81.11
Round  41, Global train loss: 1.587, Global test loss: 1.673, Global test accuracy: 79.63
Round  42, Train loss: 1.583, Test loss: 1.650, Test accuracy: 81.16
Round  42, Global train loss: 1.583, Global test loss: 1.674, Global test accuracy: 79.22
Round  43, Train loss: 1.548, Test loss: 1.651, Test accuracy: 81.01
Round  43, Global train loss: 1.548, Global test loss: 1.675, Global test accuracy: 78.93
Round  44, Train loss: 1.642, Test loss: 1.652, Test accuracy: 80.99
Round  44, Global train loss: 1.642, Global test loss: 1.695, Global test accuracy: 76.93
Round  45, Train loss: 1.641, Test loss: 1.651, Test accuracy: 81.10
Round  45, Global train loss: 1.641, Global test loss: 1.682, Global test accuracy: 78.42
Round  46, Train loss: 1.619, Test loss: 1.649, Test accuracy: 81.25
Round  46, Global train loss: 1.619, Global test loss: 1.673, Global test accuracy: 79.40
Round  47, Train loss: 1.651, Test loss: 1.649, Test accuracy: 81.30
Round  47, Global train loss: 1.651, Global test loss: 1.680, Global test accuracy: 78.61
Round  48, Train loss: 1.611, Test loss: 1.648, Test accuracy: 81.38
Round  48, Global train loss: 1.611, Global test loss: 1.669, Global test accuracy: 79.75
Round  49, Train loss: 1.643, Test loss: 1.648, Test accuracy: 81.42
Round  49, Global train loss: 1.643, Global test loss: 1.681, Global test accuracy: 78.64
Round  50, Train loss: 1.610, Test loss: 1.647, Test accuracy: 81.48
Round  50, Global train loss: 1.610, Global test loss: 1.674, Global test accuracy: 79.38
Round  51, Train loss: 1.642, Test loss: 1.647, Test accuracy: 81.41
Round  51, Global train loss: 1.642, Global test loss: 1.671, Global test accuracy: 79.61
Round  52, Train loss: 1.640, Test loss: 1.647, Test accuracy: 81.41
Round  52, Global train loss: 1.640, Global test loss: 1.673, Global test accuracy: 79.35
Round  53, Train loss: 1.644, Test loss: 1.647, Test accuracy: 81.48
Round  53, Global train loss: 1.644, Global test loss: 1.670, Global test accuracy: 79.40
Round  54, Train loss: 1.578, Test loss: 1.647, Test accuracy: 81.54
Round  54, Global train loss: 1.578, Global test loss: 1.671, Global test accuracy: 79.17
Round  55, Train loss: 1.608, Test loss: 1.647, Test accuracy: 81.49
Round  55, Global train loss: 1.608, Global test loss: 1.671, Global test accuracy: 79.45
Round  56, Train loss: 1.604, Test loss: 1.647, Test accuracy: 81.51
Round  56, Global train loss: 1.604, Global test loss: 1.671, Global test accuracy: 79.49
Round  57, Train loss: 1.609, Test loss: 1.647, Test accuracy: 81.55
Round  57, Global train loss: 1.609, Global test loss: 1.669, Global test accuracy: 79.57
Round  58, Train loss: 1.578, Test loss: 1.647, Test accuracy: 81.52
Round  58, Global train loss: 1.578, Global test loss: 1.680, Global test accuracy: 78.56
Round  59, Train loss: 1.671, Test loss: 1.647, Test accuracy: 81.51
Round  59, Global train loss: 1.671, Global test loss: 1.668, Global test accuracy: 79.73
Round  60, Train loss: 1.607, Test loss: 1.647, Test accuracy: 81.45
Round  60, Global train loss: 1.607, Global test loss: 1.667, Global test accuracy: 79.78
Round  61, Train loss: 1.574, Test loss: 1.646, Test accuracy: 81.57
Round  61, Global train loss: 1.574, Global test loss: 1.666, Global test accuracy: 79.94
Round  62, Train loss: 1.635, Test loss: 1.646, Test accuracy: 81.55
Round  62, Global train loss: 1.635, Global test loss: 1.669, Global test accuracy: 79.50
Round  63, Train loss: 1.606, Test loss: 1.646, Test accuracy: 81.56
Round  63, Global train loss: 1.606, Global test loss: 1.669, Global test accuracy: 79.47
Round  64, Train loss: 1.543, Test loss: 1.646, Test accuracy: 81.56
Round  64, Global train loss: 1.543, Global test loss: 1.666, Global test accuracy: 80.00
Round  65, Train loss: 1.606, Test loss: 1.645, Test accuracy: 81.63
Round  65, Global train loss: 1.606, Global test loss: 1.665, Global test accuracy: 79.97
Round  66, Train loss: 1.639, Test loss: 1.646, Test accuracy: 81.63
Round  66, Global train loss: 1.639, Global test loss: 1.669, Global test accuracy: 79.50
Round  67, Train loss: 1.571, Test loss: 1.645, Test accuracy: 81.65
Round  67, Global train loss: 1.571, Global test loss: 1.667, Global test accuracy: 79.88
Round  68, Train loss: 1.574, Test loss: 1.645, Test accuracy: 81.74
Round  68, Global train loss: 1.574, Global test loss: 1.663, Global test accuracy: 80.18
Round  69, Train loss: 1.669, Test loss: 1.644, Test accuracy: 81.71
Round  69, Global train loss: 1.669, Global test loss: 1.666, Global test accuracy: 79.91
Round  70, Train loss: 1.601, Test loss: 1.644, Test accuracy: 81.72
Round  70, Global train loss: 1.601, Global test loss: 1.666, Global test accuracy: 79.69
Round  71, Train loss: 1.669, Test loss: 1.644, Test accuracy: 81.69
Round  71, Global train loss: 1.669, Global test loss: 1.664, Global test accuracy: 79.97
Round  72, Train loss: 1.543, Test loss: 1.644, Test accuracy: 81.70
Round  72, Global train loss: 1.543, Global test loss: 1.664, Global test accuracy: 80.12
Round  73, Train loss: 1.604, Test loss: 1.644, Test accuracy: 81.67
Round  73, Global train loss: 1.604, Global test loss: 1.664, Global test accuracy: 79.96
Round  74, Train loss: 1.509, Test loss: 1.644, Test accuracy: 81.72
Round  74, Global train loss: 1.509, Global test loss: 1.667, Global test accuracy: 79.72
Round  75, Train loss: 1.604, Test loss: 1.644, Test accuracy: 81.70
Round  75, Global train loss: 1.604, Global test loss: 1.664, Global test accuracy: 79.88
Round  76, Train loss: 1.575, Test loss: 1.644, Test accuracy: 81.67
Round  76, Global train loss: 1.575, Global test loss: 1.669, Global test accuracy: 79.64
Round  77, Train loss: 1.509, Test loss: 1.644, Test accuracy: 81.75
Round  77, Global train loss: 1.509, Global test loss: 1.676, Global test accuracy: 78.82
Round  78, Train loss: 1.669, Test loss: 1.644, Test accuracy: 81.77
Round  78, Global train loss: 1.669, Global test loss: 1.662, Global test accuracy: 80.25
Round  79, Train loss: 1.733, Test loss: 1.644, Test accuracy: 81.76
Round  79, Global train loss: 1.733, Global test loss: 1.664, Global test accuracy: 79.94
Round  80, Train loss: 1.633, Test loss: 1.643, Test accuracy: 81.87
Round  80, Global train loss: 1.633, Global test loss: 1.662, Global test accuracy: 80.17
Round  81, Train loss: 1.605, Test loss: 1.643, Test accuracy: 81.88
Round  81, Global train loss: 1.605, Global test loss: 1.664, Global test accuracy: 79.81
Round  82, Train loss: 1.665, Test loss: 1.642, Test accuracy: 81.91
Round  82, Global train loss: 1.665, Global test loss: 1.664, Global test accuracy: 79.93
Round  83, Train loss: 1.538, Test loss: 1.642, Test accuracy: 81.93
Round  83, Global train loss: 1.538, Global test loss: 1.661, Global test accuracy: 80.31
Round  84, Train loss: 1.637, Test loss: 1.643, Test accuracy: 81.88
Round  84, Global train loss: 1.637, Global test loss: 1.661, Global test accuracy: 80.30
Round  85, Train loss: 1.603, Test loss: 1.643, Test accuracy: 81.85
Round  85, Global train loss: 1.603, Global test loss: 1.661, Global test accuracy: 80.27
Round  86, Train loss: 1.603, Test loss: 1.642, Test accuracy: 81.91
Round  86, Global train loss: 1.603, Global test loss: 1.663, Global test accuracy: 80.18
Round  87, Train loss: 1.605, Test loss: 1.642, Test accuracy: 81.89
Round  87, Global train loss: 1.605, Global test loss: 1.663, Global test accuracy: 80.05
Round  88, Train loss: 1.632, Test loss: 1.642, Test accuracy: 81.89
Round  88, Global train loss: 1.632, Global test loss: 1.663, Global test accuracy: 80.10
Round  89, Train loss: 1.572, Test loss: 1.642, Test accuracy: 81.91
Round  89, Global train loss: 1.572, Global test loss: 1.661, Global test accuracy: 80.26
Round  90, Train loss: 1.600, Test loss: 1.642, Test accuracy: 81.92
Round  90, Global train loss: 1.600, Global test loss: 1.659, Global test accuracy: 80.46
Round  91, Train loss: 1.664, Test loss: 1.642, Test accuracy: 81.92
Round  91, Global train loss: 1.664, Global test loss: 1.667, Global test accuracy: 79.65
Round  92, Train loss: 1.663, Test loss: 1.642, Test accuracy: 81.92
Round  92, Global train loss: 1.663, Global test loss: 1.666, Global test accuracy: 79.88
Round  93, Train loss: 1.541, Test loss: 1.642, Test accuracy: 81.90
Round  93, Global train loss: 1.541, Global test loss: 1.660, Global test accuracy: 80.24
Round  94, Train loss: 1.632, Test loss: 1.642, Test accuracy: 81.86
Round  94, Global train loss: 1.632, Global test loss: 1.661, Global test accuracy: 80.31
Round  95, Train loss: 1.696, Test loss: 1.642, Test accuracy: 81.90
Round  95, Global train loss: 1.696, Global test loss: 1.669, Global test accuracy: 79.61/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.633, Test loss: 1.642, Test accuracy: 82.00
Round  96, Global train loss: 1.633, Global test loss: 1.662, Global test accuracy: 79.98
Round  97, Train loss: 1.536, Test loss: 1.642, Test accuracy: 81.97
Round  97, Global train loss: 1.536, Global test loss: 1.660, Global test accuracy: 80.42
Round  98, Train loss: 1.631, Test loss: 1.642, Test accuracy: 81.98
Round  98, Global train loss: 1.631, Global test loss: 1.660, Global test accuracy: 80.32
Round  99, Train loss: 1.600, Test loss: 1.641, Test accuracy: 81.96
Round  99, Global train loss: 1.600, Global test loss: 1.664, Global test accuracy: 80.11
Final Round, Train loss: 1.616, Test loss: 1.641, Test accuracy: 81.97
Final Round, Global train loss: 1.616, Global test loss: 1.664, Global test accuracy: 80.11
Average accuracy final 10 rounds: 81.93300000000002 

Average global accuracy final 10 rounds: 80.09799999999998 

1219.0346703529358
[0.9113485813140869, 1.8226971626281738, 2.684997320175171, 3.547297477722168, 4.486718654632568, 5.426139831542969, 6.342237710952759, 7.258335590362549, 8.070814847946167, 8.883294105529785, 9.690470218658447, 10.49764633178711, 11.294590950012207, 12.091535568237305, 12.89601469039917, 13.700493812561035, 14.501983642578125, 15.303473472595215, 16.120794534683228, 16.93811559677124, 17.76286482810974, 18.587614059448242, 19.409077882766724, 20.230541706085205, 21.051560163497925, 21.872578620910645, 22.681496381759644, 23.490414142608643, 24.28369116783142, 25.0769681930542, 25.88737916946411, 26.697790145874023, 27.512001991271973, 28.326213836669922, 29.136032342910767, 29.94585084915161, 30.774648427963257, 31.603446006774902, 32.41711115837097, 33.23077630996704, 34.041516065597534, 34.85225582122803, 35.67477512359619, 36.497294425964355, 37.30555057525635, 38.11380672454834, 38.923216342926025, 39.73262596130371, 40.542736530303955, 41.3528470993042, 42.159581661224365, 42.96631622314453, 43.77343034744263, 44.58054447174072, 45.40271186828613, 46.22487926483154, 47.03585886955261, 47.84683847427368, 48.660192012786865, 49.47354555130005, 50.282796144485474, 51.0920467376709, 51.912447690963745, 52.73284864425659, 53.53738808631897, 54.34192752838135, 55.14251661300659, 55.943105697631836, 56.75369167327881, 57.56427764892578, 58.364115715026855, 59.16395378112793, 59.971317291259766, 60.7786808013916, 61.59587621688843, 62.413071632385254, 63.22941517829895, 64.04575872421265, 64.86092114448547, 65.6760835647583, 66.48212957382202, 67.28817558288574, 68.10418391227722, 68.9201922416687, 69.73692154884338, 70.55365085601807, 71.38164973258972, 72.20964860916138, 73.03048801422119, 73.851327419281, 74.67505311965942, 75.49877882003784, 76.31734204292297, 77.1359052658081, 77.95026707649231, 78.76462888717651, 79.60931158065796, 80.4539942741394, 81.2775993347168, 82.10120439529419, 82.92042469978333, 83.73964500427246, 84.56931114196777, 85.39897727966309, 86.21391868591309, 87.02886009216309, 87.84352040290833, 88.65818071365356, 89.46309661865234, 90.26801252365112, 91.06475639343262, 91.86150026321411, 92.6748595237732, 93.48821878433228, 94.28948068618774, 95.09074258804321, 95.91100215911865, 96.73126173019409, 97.53722643852234, 98.34319114685059, 99.17449116706848, 100.00579118728638, 100.82189726829529, 101.6380033493042, 102.45798850059509, 103.27797365188599, 104.09634566307068, 104.91471767425537, 105.73475861549377, 106.55479955673218, 107.38458967208862, 108.21437978744507, 109.02788877487183, 109.84139776229858, 110.65471506118774, 111.4680323600769, 112.28255271911621, 113.09707307815552, 113.90298891067505, 114.70890474319458, 115.52656316757202, 116.34422159194946, 117.14958262443542, 117.95494365692139, 118.77721905708313, 119.59949445724487, 120.412846326828, 121.22619819641113, 122.04538369178772, 122.8645691871643, 123.6611053943634, 124.4576416015625, 125.27897191047668, 126.10030221939087, 126.91057538986206, 127.72084856033325, 128.53933906555176, 129.35782957077026, 130.1745457649231, 130.99126195907593, 131.79609775543213, 132.60093355178833, 133.40861344337463, 134.21629333496094, 135.02153754234314, 135.82678174972534, 136.63101148605347, 137.4352412223816, 138.2388334274292, 139.0424256324768, 139.86195635795593, 140.68148708343506, 141.48647046089172, 142.2914538383484, 143.10983085632324, 143.9282078742981, 144.7337610721588, 145.53931427001953, 146.34211659431458, 147.14491891860962, 147.96299266815186, 148.7810664176941, 149.59725737571716, 150.41344833374023, 151.21924757957458, 152.02504682540894, 152.8484456539154, 153.67184448242188, 154.47908210754395, 155.28631973266602, 156.10076904296875, 156.91521835327148, 157.72801733016968, 158.54081630706787, 159.35912346839905, 160.17743062973022, 160.98718881607056, 161.7969470024109, 162.62383890151978, 163.45073080062866, 165.154052734375, 166.85737466812134]
[17.68, 17.68, 23.58, 23.58, 30.74, 30.74, 47.35, 47.35, 55.2, 55.2, 60.3, 60.3, 62.84, 62.84, 71.61, 71.61, 74.12, 74.12, 73.94, 73.94, 74.43, 74.43, 74.49, 74.49, 74.53, 74.53, 77.16, 77.16, 77.32, 77.32, 78.74, 78.74, 79.88, 79.88, 79.79, 79.79, 80.18, 80.18, 80.68, 80.68, 80.7, 80.7, 80.79, 80.79, 80.83, 80.83, 80.82, 80.82, 81.04, 81.04, 80.99, 80.99, 81.13, 81.13, 81.09, 81.09, 81.06, 81.06, 80.98, 80.98, 80.77, 80.77, 80.82, 80.82, 81.0, 81.0, 81.01, 81.01, 81.07, 81.07, 81.12, 81.12, 81.11, 81.11, 81.1, 81.1, 81.14, 81.14, 81.07, 81.07, 81.2, 81.2, 81.11, 81.11, 81.16, 81.16, 81.01, 81.01, 80.99, 80.99, 81.1, 81.1, 81.25, 81.25, 81.3, 81.3, 81.38, 81.38, 81.42, 81.42, 81.48, 81.48, 81.41, 81.41, 81.41, 81.41, 81.48, 81.48, 81.54, 81.54, 81.49, 81.49, 81.51, 81.51, 81.55, 81.55, 81.52, 81.52, 81.51, 81.51, 81.45, 81.45, 81.57, 81.57, 81.55, 81.55, 81.56, 81.56, 81.56, 81.56, 81.63, 81.63, 81.63, 81.63, 81.65, 81.65, 81.74, 81.74, 81.71, 81.71, 81.72, 81.72, 81.69, 81.69, 81.7, 81.7, 81.67, 81.67, 81.72, 81.72, 81.7, 81.7, 81.67, 81.67, 81.75, 81.75, 81.77, 81.77, 81.76, 81.76, 81.87, 81.87, 81.88, 81.88, 81.91, 81.91, 81.93, 81.93, 81.88, 81.88, 81.85, 81.85, 81.91, 81.91, 81.89, 81.89, 81.89, 81.89, 81.91, 81.91, 81.92, 81.92, 81.92, 81.92, 81.92, 81.92, 81.9, 81.9, 81.86, 81.86, 81.9, 81.9, 82.0, 82.0, 81.97, 81.97, 81.98, 81.98, 81.96, 81.96, 81.97, 81.97]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.296, Test loss: 2.298, Test accuracy: 25.81
Round   1, Train loss: 2.276, Test loss: 2.259, Test accuracy: 26.95
Round   2, Train loss: 2.112, Test loss: 2.082, Test accuracy: 41.45
Round   3, Train loss: 1.871, Test loss: 2.012, Test accuracy: 45.90
Round   4, Train loss: 1.789, Test loss: 1.854, Test accuracy: 69.75
Round   5, Train loss: 1.661, Test loss: 1.792, Test accuracy: 69.49
Round   6, Train loss: 1.635, Test loss: 1.736, Test accuracy: 75.03
Round   7, Train loss: 1.580, Test loss: 1.702, Test accuracy: 77.91
Round   8, Train loss: 1.555, Test loss: 1.716, Test accuracy: 76.69
Round   9, Train loss: 1.526, Test loss: 1.698, Test accuracy: 77.28
Round  10, Train loss: 1.587, Test loss: 1.646, Test accuracy: 84.99
Round  11, Train loss: 1.524, Test loss: 1.707, Test accuracy: 76.09
Round  12, Train loss: 1.532, Test loss: 1.658, Test accuracy: 81.49
Round  13, Train loss: 1.537, Test loss: 1.643, Test accuracy: 83.04
Round  14, Train loss: 1.509, Test loss: 1.670, Test accuracy: 79.19
Round  15, Train loss: 1.508, Test loss: 1.631, Test accuracy: 85.58
Round  16, Train loss: 1.506, Test loss: 1.640, Test accuracy: 83.41
Round  17, Train loss: 1.513, Test loss: 1.622, Test accuracy: 85.97
Round  18, Train loss: 1.497, Test loss: 1.619, Test accuracy: 85.08
Round  19, Train loss: 1.510, Test loss: 1.634, Test accuracy: 83.15
Round  20, Train loss: 1.506, Test loss: 1.600, Test accuracy: 87.61
Round  21, Train loss: 1.501, Test loss: 1.641, Test accuracy: 81.85
Round  22, Train loss: 1.507, Test loss: 1.695, Test accuracy: 76.29
Round  23, Train loss: 1.508, Test loss: 1.609, Test accuracy: 86.74
Round  24, Train loss: 1.497, Test loss: 1.591, Test accuracy: 88.41
Round  25, Train loss: 1.489, Test loss: 1.604, Test accuracy: 86.98
Round  26, Train loss: 1.491, Test loss: 1.588, Test accuracy: 88.64
Round  27, Train loss: 1.494, Test loss: 1.583, Test accuracy: 89.03
Round  28, Train loss: 1.498, Test loss: 1.616, Test accuracy: 85.16
Round  29, Train loss: 1.497, Test loss: 1.589, Test accuracy: 88.53
Round  30, Train loss: 1.489, Test loss: 1.592, Test accuracy: 87.86
Round  31, Train loss: 1.495, Test loss: 1.587, Test accuracy: 88.55
Round  32, Train loss: 1.483, Test loss: 1.613, Test accuracy: 85.39
Round  33, Train loss: 1.493, Test loss: 1.571, Test accuracy: 90.10
Round  34, Train loss: 1.489, Test loss: 1.609, Test accuracy: 85.63
Round  35, Train loss: 1.482, Test loss: 1.579, Test accuracy: 88.98
Round  36, Train loss: 1.484, Test loss: 1.581, Test accuracy: 88.87
Round  37, Train loss: 1.487, Test loss: 1.596, Test accuracy: 87.30
Round  38, Train loss: 1.493, Test loss: 1.577, Test accuracy: 89.43
Round  39, Train loss: 1.488, Test loss: 1.590, Test accuracy: 87.72
Round  40, Train loss: 1.489, Test loss: 1.604, Test accuracy: 86.47
Round  41, Train loss: 1.488, Test loss: 1.575, Test accuracy: 89.57
Round  42, Train loss: 1.485, Test loss: 1.561, Test accuracy: 91.22
Round  43, Train loss: 1.486, Test loss: 1.569, Test accuracy: 90.17
Round  44, Train loss: 1.490, Test loss: 1.570, Test accuracy: 90.02
Round  45, Train loss: 1.485, Test loss: 1.570, Test accuracy: 90.04
Round  46, Train loss: 1.485, Test loss: 1.578, Test accuracy: 89.19
Round  47, Train loss: 1.481, Test loss: 1.584, Test accuracy: 88.35
Round  48, Train loss: 1.487, Test loss: 1.578, Test accuracy: 88.89
Round  49, Train loss: 1.490, Test loss: 1.563, Test accuracy: 90.54
Round  50, Train loss: 1.485, Test loss: 1.563, Test accuracy: 90.66
Round  51, Train loss: 1.482, Test loss: 1.560, Test accuracy: 90.78
Round  52, Train loss: 1.484, Test loss: 1.559, Test accuracy: 91.09
Round  53, Train loss: 1.479, Test loss: 1.554, Test accuracy: 91.48
Round  54, Train loss: 1.478, Test loss: 1.555, Test accuracy: 91.38
Round  55, Train loss: 1.482, Test loss: 1.559, Test accuracy: 90.92
Round  56, Train loss: 1.478, Test loss: 1.581, Test accuracy: 88.85
Round  57, Train loss: 1.482, Test loss: 1.582, Test accuracy: 88.48
Round  58, Train loss: 1.481, Test loss: 1.561, Test accuracy: 90.89
Round  59, Train loss: 1.482, Test loss: 1.578, Test accuracy: 88.70
Round  60, Train loss: 1.479, Test loss: 1.557, Test accuracy: 90.99
Round  61, Train loss: 1.481, Test loss: 1.554, Test accuracy: 91.37
Round  62, Train loss: 1.476, Test loss: 1.556, Test accuracy: 91.17
Round  63, Train loss: 1.482, Test loss: 1.558, Test accuracy: 91.03
Round  64, Train loss: 1.476, Test loss: 1.572, Test accuracy: 89.73
Round  65, Train loss: 1.472, Test loss: 1.559, Test accuracy: 90.92
Round  66, Train loss: 1.483, Test loss: 1.556, Test accuracy: 91.20
Round  67, Train loss: 1.475, Test loss: 1.560, Test accuracy: 90.49
Round  68, Train loss: 1.474, Test loss: 1.557, Test accuracy: 91.10
Round  69, Train loss: 1.476, Test loss: 1.560, Test accuracy: 90.80
Round  70, Train loss: 1.482, Test loss: 1.547, Test accuracy: 92.07
Round  71, Train loss: 1.479, Test loss: 1.551, Test accuracy: 91.73
Round  72, Train loss: 1.478, Test loss: 1.555, Test accuracy: 91.35
Round  73, Train loss: 1.477, Test loss: 1.552, Test accuracy: 91.50
Round  74, Train loss: 1.475, Test loss: 1.552, Test accuracy: 91.55
Round  75, Train loss: 1.471, Test loss: 1.561, Test accuracy: 90.54
Round  76, Train loss: 1.472, Test loss: 1.556, Test accuracy: 91.27
Round  77, Train loss: 1.477, Test loss: 1.562, Test accuracy: 90.47
Round  78, Train loss: 1.478, Test loss: 1.560, Test accuracy: 90.66
Round  79, Train loss: 1.477, Test loss: 1.549, Test accuracy: 91.96
Round  80, Train loss: 1.475, Test loss: 1.545, Test accuracy: 92.25
Round  81, Train loss: 1.477, Test loss: 1.558, Test accuracy: 90.74
Round  82, Train loss: 1.479, Test loss: 1.558, Test accuracy: 91.03
Round  83, Train loss: 1.475, Test loss: 1.550, Test accuracy: 91.62
Round  84, Train loss: 1.478, Test loss: 1.551, Test accuracy: 91.69
Round  85, Train loss: 1.476, Test loss: 1.544, Test accuracy: 92.33
Round  86, Train loss: 1.478, Test loss: 1.543, Test accuracy: 92.28
Round  87, Train loss: 1.475, Test loss: 1.558, Test accuracy: 90.88
Round  88, Train loss: 1.473, Test loss: 1.551, Test accuracy: 91.49
Round  89, Train loss: 1.470, Test loss: 1.545, Test accuracy: 92.24
Round  90, Train loss: 1.479, Test loss: 1.568, Test accuracy: 89.68
Round  91, Train loss: 1.475, Test loss: 1.557, Test accuracy: 91.10
Round  92, Train loss: 1.471, Test loss: 1.550, Test accuracy: 91.62
Round  93, Train loss: 1.473, Test loss: 1.541, Test accuracy: 92.37
Round  94, Train loss: 1.473, Test loss: 1.545, Test accuracy: 92.11
Round  95, Train loss: 1.472, Test loss: 1.551, Test accuracy: 91.54
Round  96, Train loss: 1.474, Test loss: 1.566, Test accuracy: 89.84
Round  97, Train loss: 1.471, Test loss: 1.542, Test accuracy: 92.46
Round  98, Train loss: 1.475, Test loss: 1.543, Test accuracy: 92.49
Round  99, Train loss: 1.473, Test loss: 1.540, Test accuracy: 92.67
Final Round, Train loss: 1.475, Test loss: 1.537, Test accuracy: 92.87
Average accuracy final 10 rounds: 91.588
1518.1774978637695
[2.103239059448242, 4.137574672698975, 6.1660315990448, 8.163173913955688, 10.194969654083252, 12.229994773864746, 14.282355308532715, 16.337146282196045, 18.386883020401, 20.404451608657837, 22.4313645362854, 24.44066858291626, 26.49326491355896, 28.507628202438354, 30.52545142173767, 32.55121660232544, 34.69643497467041, 36.73796820640564, 38.76545214653015, 40.802417039871216, 42.830631256103516, 44.85281729698181, 46.91449975967407, 48.97086954116821, 51.003597259521484, 53.141249895095825, 55.29090118408203, 57.33324670791626, 59.377904653549194, 61.57378363609314, 63.61936378479004, 65.66417407989502, 67.73287796974182, 69.84932470321655, 71.94959259033203, 74.0445339679718, 76.08913612365723, 78.12544178962708, 80.16457557678223, 82.25328660011292, 84.3455023765564, 86.43694233894348, 88.51643943786621, 90.63133692741394, 92.74263334274292, 94.81855964660645, 96.89661312103271, 98.97749018669128, 101.05598187446594, 103.12138032913208, 105.19489741325378, 107.28340196609497, 109.37092304229736, 111.45584225654602, 113.5328278541565, 115.61122441291809, 117.69228482246399, 119.77195811271667, 121.85692524909973, 123.95399928092957, 126.04164361953735, 128.1462218761444, 130.22641372680664, 132.29099535942078, 134.3760666847229, 136.4473912715912, 138.53683257102966, 140.63587141036987, 142.72537779808044, 144.82680082321167, 146.9299395084381, 149.01262426376343, 151.09002709388733, 153.17533826828003, 155.2196605205536, 157.27492880821228, 159.35966062545776, 161.4671013355255, 163.54252552986145, 165.64504837989807, 167.73657178878784, 169.82111740112305, 171.91085767745972, 173.99026608467102, 176.06904435157776, 178.18064427375793, 180.26849508285522, 182.36427855491638, 184.44835591316223, 186.53110909461975, 188.6128568649292, 190.71714091300964, 192.82957458496094, 194.90531134605408, 196.96534276008606, 199.07184863090515, 201.16295170783997, 203.23985171318054, 205.29604077339172, 207.36753606796265, 209.45101141929626]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[25.81, 26.95, 41.45, 45.9, 69.75, 69.49, 75.03, 77.91, 76.69, 77.28, 84.99, 76.09, 81.49, 83.04, 79.19, 85.58, 83.41, 85.97, 85.08, 83.15, 87.61, 81.85, 76.29, 86.74, 88.41, 86.98, 88.64, 89.03, 85.16, 88.53, 87.86, 88.55, 85.39, 90.1, 85.63, 88.98, 88.87, 87.3, 89.43, 87.72, 86.47, 89.57, 91.22, 90.17, 90.02, 90.04, 89.19, 88.35, 88.89, 90.54, 90.66, 90.78, 91.09, 91.48, 91.38, 90.92, 88.85, 88.48, 90.89, 88.7, 90.99, 91.37, 91.17, 91.03, 89.73, 90.92, 91.2, 90.49, 91.1, 90.8, 92.07, 91.73, 91.35, 91.5, 91.55, 90.54, 91.27, 90.47, 90.66, 91.96, 92.25, 90.74, 91.03, 91.62, 91.69, 92.33, 92.28, 90.88, 91.49, 92.24, 89.68, 91.1, 91.62, 92.37, 92.11, 91.54, 89.84, 92.46, 92.49, 92.67, 92.87]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.06
Round   0, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.05
Round   1, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.06
Round   1, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.05
Round   2, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.05
Round   2, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.04
Round   3, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.05
Round   3, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.04
Round   4, Train loss: 2.304, Test loss: 2.302, Test accuracy: 13.05
Round   4, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 13.04
Round   5, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.05
Round   5, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.04
Round   6, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.05
Round   6, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.04
Round   7, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.05
Round   7, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.04
Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.05
Round   8, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.04
Round   9, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.05
Round   9, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.04
Round  10, Train loss: 2.304, Test loss: 2.302, Test accuracy: 13.05
Round  10, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 13.04
Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.05
Round  11, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.04
Round  12, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.05
Round  12, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.03
Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.04
Round  13, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.03
Round  14, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.04
Round  14, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.03
Round  15, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.04
Round  15, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.03
Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.03
Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.03
Round  17, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.03
Round  17, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.03
Round  18, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.03
Round  18, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.03
Round  19, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.03
Round  19, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.03
Round  20, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.03
Round  20, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.03
Round  21, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.03
Round  21, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.01
Round  22, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.03
Round  22, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.01
Round  23, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.03
Round  23, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.01
Round  24, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.02
Round  24, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.01
Round  25, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.01
Round  25, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.01
Round  26, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.01
Round  26, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.01
Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.01
Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.01
Round  28, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.01
Round  28, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.01
Round  29, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.01
Round  29, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.01
Round  30, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.01
Round  30, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.01
Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.01
Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.01
Round  32, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.01
Round  32, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.01
Round  33, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.01
Round  33, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.01
Round  34, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  34, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.01
Round  35, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  35, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.01
Round  36, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  36, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  37, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  37, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  38, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  38, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  39, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  39, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  40, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  40, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  41, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  41, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  42, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  42, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  43, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  43, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  44, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  44, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  45, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round  45, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  46, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  46, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  47, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  47, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  48, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.01
Round  48, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.01
Round  49, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  49, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  50, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  50, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  51, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  51, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  52, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  52, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  53, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  53, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  54, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round  54, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  55, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  55, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  56, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  56, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  57, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  57, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  58, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  58, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  59, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  59, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  60, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.01
Round  60, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.01
Round  61, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  61, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  62, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  62, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  63, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round  63, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  64, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round  64, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  65, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  65, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  66, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round  66, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  67, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  67, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  68, Train loss: 2.298, Test loss: 2.301, Test accuracy: 13.01
Round  68, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 13.01
Round  69, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  69, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  70, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.00
Round  70, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  71, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.00
Round  71, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  72, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.00
Round  72, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  73, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.00
Round  73, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.01
Round  74, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.00
Round  74, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  75, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.01
Round  75, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.01
Round  76, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.01
Round  76, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.01
Round  77, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round  77, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.00
Round  78, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.01
Round  78, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.00
Round  79, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.01
Round  79, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.00
Round  80, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.00
Round  80, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.00
Round  81, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.00
Round  81, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.00
Round  82, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.00
Round  82, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.00
Round  83, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.00
Round  83, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.00
Round  84, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.00
Round  84, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.00
Round  85, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.00
Round  85, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.00
Round  86, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round  86, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.00
Round  87, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round  87, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.00
Round  88, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round  88, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round  89, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round  89, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round  90, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round  90, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round  91, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round  91, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round  92, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round  92, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round  93, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round  93, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round  94, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round  94, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round  95, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round  95, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round  96, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round  96, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round  97, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round  97, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round  98, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round  98, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round  99, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round  99, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 100, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 100, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 101, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 101, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 102, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round 102, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round 103, Train loss: 2.298, Test loss: 2.300, Test accuracy: 13.00
Round 103, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 13.00
Round 104, Train loss: 2.302, Test loss: 2.300, Test accuracy: 13.00
Round 104, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 13.00
Round 105, Train loss: 2.302, Test loss: 2.300, Test accuracy: 13.00
Round 105, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 13.00
Round 106, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 106, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 107, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 107, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 108, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 108, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 109, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 109, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 110, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 110, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 111, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 111, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 112, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 112, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 113, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 113, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 114, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round 114, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round 115, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 115, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 116, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round 116, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round 117, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 117, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 118, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 118, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 119, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 119, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 120, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 120, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 121, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 121, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 122, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round 122, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round 123, Train loss: 2.298, Test loss: 2.300, Test accuracy: 13.00
Round 123, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 13.00
Round 124, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 124, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 125, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 125, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 126, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round 126, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round 127, Train loss: 2.297, Test loss: 2.300, Test accuracy: 13.00
Round 127, Global train loss: 2.297, Global test loss: 2.300, Global test accuracy: 13.00
Round 128, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 128, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 129, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.00
Round 129, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.00
Round 130, Train loss: 2.298, Test loss: 2.300, Test accuracy: 13.00
Round 130, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 13.00
Round 131, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 131, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 132, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.00
Round 132, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 13.00
Round 133, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 133, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 134, Train loss: 2.300, Test loss: 2.300, Test accuracy: 13.00
Round 134, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.00
Round 135, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.00
Round 135, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 13.00
Round 136, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.00
Round 136, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 13.00
Round 137, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.00
Round 137, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 138, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.00
Round 138, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.00
Round 139, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.00
Round 139, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.00
Round 140, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.00
Round 140, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 141, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.00
Round 141, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 142, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.00
Round 142, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.00
Round 143, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.00
Round 143, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 144, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.00
Round 144, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 145, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.00
Round 145, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 146, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.01
Round 146, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.00
Round 147, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.01
Round 147, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.00
Round 148, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.01
Round 148, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.01
Round 149, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.01
Round 149, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.01
Round 150, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.01
Round 150, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.01
Round 151, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.01
Round 151, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 152, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.01
Round 152, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.01
Round 153, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 153, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 154, Train loss: 2.297, Test loss: 2.299, Test accuracy: 13.02
Round 154, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 13.02
Round 155, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 155, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 156, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 156, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 157, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 157, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 158, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.02
Round 158, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.02
Round 159, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 159, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 160, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.02
Round 160, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.02
Round 161, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 161, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 162, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 162, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 163, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 163, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 164, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.02
Round 164, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.02
Round 165, Train loss: 2.302, Test loss: 2.299, Test accuracy: 13.02
Round 165, Global train loss: 2.302, Global test loss: 2.299, Global test accuracy: 13.02
Round 166, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.02
Round 166, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.02
Round 167, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 167, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 168, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 168, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 169, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 169, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 170, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.02
Round 170, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 13.02
Round 171, Train loss: 2.297, Test loss: 2.299, Test accuracy: 13.02
Round 171, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 13.02
Round 172, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 172, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 173, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 173, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 174, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 174, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 175, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 175, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 176, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.02
Round 176, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 177, Train loss: 2.298, Test loss: 2.299, Test accuracy: 13.02
Round 177, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 13.02
Round 178, Train loss: 2.296, Test loss: 2.299, Test accuracy: 13.02
Round 178, Global train loss: 2.296, Global test loss: 2.299, Global test accuracy: 13.02
Round 179, Train loss: 2.299, Test loss: 2.298, Test accuracy: 13.02
Round 179, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.02
Round 180, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 180, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.02
Round 181, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.03
Round 181, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.02
Round 182, Train loss: 2.299, Test loss: 2.298, Test accuracy: 13.03
Round 182, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 13.02
Round 183, Train loss: 2.299, Test loss: 2.298, Test accuracy: 13.03
Round 183, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 13.02
Round 184, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.03
Round 184, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.02
Round 185, Train loss: 2.299, Test loss: 2.298, Test accuracy: 13.03
Round 185, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 13.02
Round 186, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 186, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.02
Round 187, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.03
Round 187, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.02
Round 188, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 188, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.02
Round 189, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 189, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 190, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 190, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 191, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 191, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 192, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.03
Round 192, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.03
Round 193, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 193, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 194, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 194, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 195, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.03
Round 195, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.03
Round 196, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 196, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 197, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 197, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 198, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.03
Round 198, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.03
Round 199, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.03
Round 199, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.03
Round 200, Train loss: 2.300, Test loss: 2.298, Test accuracy: 13.03
Round 200, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 13.03
Round 201, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.03
Round 201, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.03
Round 202, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 202, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 203, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.03
Round 203, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.03
Round 204, Train loss: 2.299, Test loss: 2.298, Test accuracy: 13.03
Round 204, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 13.03
Round 205, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.03
Round 205, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.03
Round 206, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.03
Round 206, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.03
Round 207, Train loss: 2.295, Test loss: 2.298, Test accuracy: 13.03
Round 207, Global train loss: 2.295, Global test loss: 2.298, Global test accuracy: 13.03
Round 208, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 208, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 209, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.04
Round 209, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.03
Round 210, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.03
Round 210, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.03
Round 211, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.04
Round 211, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.03
Round 212, Train loss: 2.297, Test loss: 2.298, Test accuracy: 13.04
Round 212, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 13.04
Round 213, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.04
Round 213, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.04
Round 214, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.04
Round 214, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.04
Round 215, Train loss: 2.298, Test loss: 2.298, Test accuracy: 13.04
Round 215, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 13.04
Round 216, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.04
Round 216, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.04
Round 217, Train loss: 2.294, Test loss: 2.297, Test accuracy: 13.04
Round 217, Global train loss: 2.294, Global test loss: 2.297, Global test accuracy: 13.04
Round 218, Train loss: 2.295, Test loss: 2.297, Test accuracy: 13.04
Round 218, Global train loss: 2.295, Global test loss: 2.297, Global test accuracy: 13.04
Round 219, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.04
Round 219, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.04
Round 220, Train loss: 2.298, Test loss: 2.297, Test accuracy: 13.04
Round 220, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 13.04
Round 221, Train loss: 2.300, Test loss: 2.297, Test accuracy: 13.04
Round 221, Global train loss: 2.300, Global test loss: 2.297, Global test accuracy: 13.04
Round 222, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.04
Round 222, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.04
Round 223, Train loss: 2.298, Test loss: 2.297, Test accuracy: 13.04
Round 223, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 13.04
Round 224, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.04
Round 224, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.04
Round 225, Train loss: 2.295, Test loss: 2.297, Test accuracy: 13.04
Round 225, Global train loss: 2.295, Global test loss: 2.297, Global test accuracy: 13.04
Round 226, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.04
Round 226, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.04
Round 227, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.04
Round 227, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.04
Round 228, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.04
Round 228, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.04
Round 229, Train loss: 2.298, Test loss: 2.297, Test accuracy: 13.04
Round 229, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 13.04
Round 230, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.04
Round 230, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.04
Round 231, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.04
Round 231, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.04
Round 232, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.05
Round 232, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 233, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.05
Round 233, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.05
Round 234, Train loss: 2.298, Test loss: 2.297, Test accuracy: 13.05
Round 234, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 13.05
Round 235, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.06
Round 235, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.05
Round 236, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.06
Round 236, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.05
Round 237, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.06
Round 237, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 238, Train loss: 2.294, Test loss: 2.297, Test accuracy: 13.05
Round 238, Global train loss: 2.294, Global test loss: 2.297, Global test accuracy: 13.05
Round 239, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.05
Round 239, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 240, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.05
Round 240, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.05
Round 241, Train loss: 2.294, Test loss: 2.297, Test accuracy: 13.05
Round 241, Global train loss: 2.294, Global test loss: 2.297, Global test accuracy: 13.05
Round 242, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.05
Round 242, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 243, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.06
Round 243, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 244, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.06
Round 244, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 245, Train loss: 2.298, Test loss: 2.297, Test accuracy: 13.06
Round 245, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 13.05
Round 246, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.06
Round 246, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 13.05
Round 247, Train loss: 2.297, Test loss: 2.297, Test accuracy: 13.07
Round 247, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.05
Round 248, Train loss: 2.294, Test loss: 2.297, Test accuracy: 13.07
Round 248, Global train loss: 2.294, Global test loss: 2.297, Global test accuracy: 13.05
Round 249, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.07
Round 249, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 13.05
Round 250, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.07
Round 250, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.07
Round 251, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.07
Round 251, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 13.07
Round 252, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.07
Round 252, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.07
Round 253, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.07
Round 253, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.08
Round 254, Train loss: 2.298, Test loss: 2.296, Test accuracy: 13.08
Round 254, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 13.08
Round 255, Train loss: 2.294, Test loss: 2.296, Test accuracy: 13.08
Round 255, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 13.08
Round 256, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.08
Round 256, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 13.08
Round 257, Train loss: 2.299, Test loss: 2.296, Test accuracy: 13.09
Round 257, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 13.09
Round 258, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.09
Round 258, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 13.08
Round 259, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.10
Round 259, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.09
Round 260, Train loss: 2.295, Test loss: 2.296, Test accuracy: 13.11
Round 260, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 13.09
Round 261, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.11
Round 261, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.09
Round 262, Train loss: 2.295, Test loss: 2.296, Test accuracy: 13.11
Round 262, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 13.09
Round 263, Train loss: 2.295, Test loss: 2.296, Test accuracy: 13.12
Round 263, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 13.15
Round 264, Train loss: 2.299, Test loss: 2.296, Test accuracy: 13.12
Round 264, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 13.09
Round 265, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.12
Round 265, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.09
Round 266, Train loss: 2.294, Test loss: 2.296, Test accuracy: 13.12
Round 266, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 13.09
Round 267, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.11
Round 267, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.11
Round 268, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.13
Round 268, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 13.15
Round 269, Train loss: 2.298, Test loss: 2.296, Test accuracy: 13.13
Round 269, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 13.16
Round 270, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.13
Round 270, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.16
Round 271, Train loss: 2.294, Test loss: 2.296, Test accuracy: 13.16
Round 271, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 13.17
Round 272, Train loss: 2.298, Test loss: 2.296, Test accuracy: 13.16
Round 272, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 13.17
Round 273, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.16
Round 273, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 13.16
Round 274, Train loss: 2.294, Test loss: 2.296, Test accuracy: 13.16
Round 274, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 13.16
Round 275, Train loss: 2.293, Test loss: 2.296, Test accuracy: 13.17
Round 275, Global train loss: 2.293, Global test loss: 2.296, Global test accuracy: 13.16
Round 276, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.18
Round 276, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.17
Round 277, Train loss: 2.295, Test loss: 2.296, Test accuracy: 13.18
Round 277, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 13.17
Round 278, Train loss: 2.295, Test loss: 2.296, Test accuracy: 13.18
Round 278, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 13.17
Round 279, Train loss: 2.296, Test loss: 2.296, Test accuracy: 13.18
Round 279, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.17
Round 280, Train loss: 2.296, Test loss: 2.295, Test accuracy: 13.18
Round 280, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.17
Round 281, Train loss: 2.293, Test loss: 2.295, Test accuracy: 13.18
Round 281, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 13.18
Round 282, Train loss: 2.297, Test loss: 2.295, Test accuracy: 13.18
Round 282, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 13.18
Round 283, Train loss: 2.296, Test loss: 2.295, Test accuracy: 13.18
Round 283, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 13.18
Round 284, Train loss: 2.293, Test loss: 2.295, Test accuracy: 13.20
Round 284, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 13.19
Round 285, Train loss: 2.297, Test loss: 2.295, Test accuracy: 13.20
Round 285, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 13.19
Round 286, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.20
Round 286, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.19
Round 287, Train loss: 2.297, Test loss: 2.295, Test accuracy: 13.20
Round 287, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 13.19
Round 288, Train loss: 2.296, Test loss: 2.295, Test accuracy: 13.20
Round 288, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 13.20
Round 289, Train loss: 2.294, Test loss: 2.295, Test accuracy: 13.21
Round 289, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 13.21
Round 290, Train loss: 2.298, Test loss: 2.295, Test accuracy: 13.21
Round 290, Global train loss: 2.298, Global test loss: 2.295, Global test accuracy: 13.23
Round 291, Train loss: 2.293, Test loss: 2.295, Test accuracy: 13.21
Round 291, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 13.23
Round 292, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.21
Round 292, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.23
Round 293, Train loss: 2.298, Test loss: 2.295, Test accuracy: 13.21
Round 293, Global train loss: 2.298, Global test loss: 2.295, Global test accuracy: 13.24
Round 294, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.21
Round 294, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.24
Round 295, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.23
Round 295, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.24
Round 296, Train loss: 2.293, Test loss: 2.295, Test accuracy: 13.24
Round 296, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 13.24
Round 297, Train loss: 2.296, Test loss: 2.295, Test accuracy: 13.24
Round 297, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 13.24
Round 298, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.24
Round 298, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.24
Round 299, Train loss: 2.294, Test loss: 2.295, Test accuracy: 13.24
Round 299, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 13.24
Round 300, Train loss: 2.297, Test loss: 2.295, Test accuracy: 13.26
Round 300, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 13.26
Round 301, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.28
Round 301, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.26
Round 302, Train loss: 2.293, Test loss: 2.295, Test accuracy: 13.30
Round 302, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 13.26
Round 303, Train loss: 2.294, Test loss: 2.295, Test accuracy: 13.30
Round 303, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 13.26
Round 304, Train loss: 2.298, Test loss: 2.295, Test accuracy: 13.30
Round 304, Global train loss: 2.298, Global test loss: 2.295, Global test accuracy: 13.26
Round 305, Train loss: 2.299, Test loss: 2.295, Test accuracy: 13.30
Round 305, Global train loss: 2.299, Global test loss: 2.295, Global test accuracy: 13.30
Round 306, Train loss: 2.297, Test loss: 2.295, Test accuracy: 13.30
Round 306, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 13.28
Round 307, Train loss: 2.295, Test loss: 2.295, Test accuracy: 13.33
Round 307, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 13.31
Round 308, Train loss: 2.296, Test loss: 2.294, Test accuracy: 13.33
Round 308, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 13.36
Round 309, Train loss: 2.296, Test loss: 2.294, Test accuracy: 13.35
Round 309, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 13.36
Round 310, Train loss: 2.294, Test loss: 2.294, Test accuracy: 13.38
Round 310, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 13.37
Round 311, Train loss: 2.297, Test loss: 2.294, Test accuracy: 13.38
Round 311, Global train loss: 2.297, Global test loss: 2.294, Global test accuracy: 13.44
Round 312, Train loss: 2.294, Test loss: 2.294, Test accuracy: 13.42
Round 312, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 13.45
Round 313, Train loss: 2.295, Test loss: 2.294, Test accuracy: 13.45
Round 313, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 13.46
Round 314, Train loss: 2.295, Test loss: 2.294, Test accuracy: 13.46
Round 314, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 13.47
Round 315, Train loss: 2.296, Test loss: 2.294, Test accuracy: 13.48
Round 315, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 13.48
Round 316, Train loss: 2.295, Test loss: 2.294, Test accuracy: 13.48
Round 316, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 13.54
Round 317, Train loss: 2.293, Test loss: 2.294, Test accuracy: 13.54
Round 317, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 13.55
Round 318, Train loss: 2.294, Test loss: 2.294, Test accuracy: 13.57
Round 318, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 13.60
Round 319, Train loss: 2.292, Test loss: 2.294, Test accuracy: 13.59
Round 319, Global train loss: 2.292, Global test loss: 2.294, Global test accuracy: 13.62
Round 320, Train loss: 2.295, Test loss: 2.294, Test accuracy: 13.60
Round 320, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 13.60
Round 321, Train loss: 2.293, Test loss: 2.294, Test accuracy: 13.61
Round 321, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 13.60
Round 322, Train loss: 2.295, Test loss: 2.294, Test accuracy: 13.59
Round 322, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 13.60
Round 323, Train loss: 2.293, Test loss: 2.294, Test accuracy: 13.63
Round 323, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 13.60
Round 324, Train loss: 2.293, Test loss: 2.294, Test accuracy: 13.63
Round 324, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 13.64
Round 325, Train loss: 2.293, Test loss: 2.294, Test accuracy: 13.64
Round 325, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 13.69
Round 326, Train loss: 2.292, Test loss: 2.294, Test accuracy: 13.66
Round 326, Global train loss: 2.292, Global test loss: 2.294, Global test accuracy: 13.75
Round 327, Train loss: 2.295, Test loss: 2.294, Test accuracy: 13.67
Round 327, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 13.71
Round 328, Train loss: 2.297, Test loss: 2.294, Test accuracy: 13.68
Round 328, Global train loss: 2.297, Global test loss: 2.294, Global test accuracy: 13.81
Round 329, Train loss: 2.294, Test loss: 2.294, Test accuracy: 13.69
Round 329, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 13.83
Round 330, Train loss: 2.292, Test loss: 2.294, Test accuracy: 13.71
Round 330, Global train loss: 2.292, Global test loss: 2.294, Global test accuracy: 13.83
Round 331, Train loss: 2.290, Test loss: 2.294, Test accuracy: 13.79
Round 331, Global train loss: 2.290, Global test loss: 2.294, Global test accuracy: 13.83
Round 332, Train loss: 2.291, Test loss: 2.293, Test accuracy: 13.81
Round 332, Global train loss: 2.291, Global test loss: 2.294, Global test accuracy: 13.86
Round 333, Train loss: 2.293, Test loss: 2.293, Test accuracy: 13.84
Round 333, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 13.86
Round 334, Train loss: 2.293, Test loss: 2.293, Test accuracy: 13.92
Round 334, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 13.89
Round 335, Train loss: 2.290, Test loss: 2.293, Test accuracy: 13.95
Round 335, Global train loss: 2.290, Global test loss: 2.293, Global test accuracy: 13.93
Round 336, Train loss: 2.291, Test loss: 2.293, Test accuracy: 13.96
Round 336, Global train loss: 2.291, Global test loss: 2.293, Global test accuracy: 13.89
Round 337, Train loss: 2.293, Test loss: 2.293, Test accuracy: 13.96
Round 337, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 13.89
Round 338, Train loss: 2.292, Test loss: 2.293, Test accuracy: 13.97
Round 338, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 13.89
Round 339, Train loss: 2.297, Test loss: 2.293, Test accuracy: 13.97
Round 339, Global train loss: 2.297, Global test loss: 2.293, Global test accuracy: 13.87
Round 340, Train loss: 2.292, Test loss: 2.293, Test accuracy: 13.95
Round 340, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 13.89
Round 341, Train loss: 2.292, Test loss: 2.293, Test accuracy: 13.96
Round 341, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 13.87
Round 342, Train loss: 2.293, Test loss: 2.293, Test accuracy: 13.96
Round 342, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 13.93
Round 343, Train loss: 2.297, Test loss: 2.293, Test accuracy: 13.96
Round 343, Global train loss: 2.297, Global test loss: 2.293, Global test accuracy: 13.98
Round 344, Train loss: 2.295, Test loss: 2.293, Test accuracy: 13.97
Round 344, Global train loss: 2.295, Global test loss: 2.293, Global test accuracy: 13.98
Round 345, Train loss: 2.291, Test loss: 2.293, Test accuracy: 13.99
Round 345, Global train loss: 2.291, Global test loss: 2.293, Global test accuracy: 13.98
Round 346, Train loss: 2.294, Test loss: 2.293, Test accuracy: 13.99
Round 346, Global train loss: 2.294, Global test loss: 2.293, Global test accuracy: 13.93
Round 347, Train loss: 2.292, Test loss: 2.293, Test accuracy: 13.99
Round 347, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 13.98
Round 348, Train loss: 2.293, Test loss: 2.293, Test accuracy: 14.00
Round 348, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 13.98
Round 349, Train loss: 2.289, Test loss: 2.293, Test accuracy: 13.99
Round 349, Global train loss: 2.289, Global test loss: 2.293, Global test accuracy: 13.94
Round 350, Train loss: 2.292, Test loss: 2.293, Test accuracy: 14.00
Round 350, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 13.93
Round 351, Train loss: 2.297, Test loss: 2.293, Test accuracy: 14.00
Round 351, Global train loss: 2.297, Global test loss: 2.293, Global test accuracy: 13.94
Round 352, Train loss: 2.293, Test loss: 2.293, Test accuracy: 14.00
Round 352, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 13.94
Round 353, Train loss: 2.291, Test loss: 2.292, Test accuracy: 13.99
Round 353, Global train loss: 2.291, Global test loss: 2.293, Global test accuracy: 13.98
Round 354, Train loss: 2.296, Test loss: 2.292, Test accuracy: 14.00
Round 354, Global train loss: 2.296, Global test loss: 2.292, Global test accuracy: 14.00
Round 355, Train loss: 2.291, Test loss: 2.292, Test accuracy: 14.01
Round 355, Global train loss: 2.291, Global test loss: 2.292, Global test accuracy: 14.00
Round 356, Train loss: 2.293, Test loss: 2.292, Test accuracy: 14.03
Round 356, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 14.00
Round 357, Train loss: 2.292, Test loss: 2.292, Test accuracy: 14.03
Round 357, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 14.00
Round 358, Train loss: 2.289, Test loss: 2.292, Test accuracy: 14.04
Round 358, Global train loss: 2.289, Global test loss: 2.292, Global test accuracy: 13.98
Round 359, Train loss: 2.290, Test loss: 2.292, Test accuracy: 14.03
Round 359, Global train loss: 2.290, Global test loss: 2.292, Global test accuracy: 14.00
Round 360, Train loss: 2.287, Test loss: 2.292, Test accuracy: 14.05
Round 360, Global train loss: 2.287, Global test loss: 2.292, Global test accuracy: 14.02
Round 361, Train loss: 2.290, Test loss: 2.292, Test accuracy: 14.06
Round 361, Global train loss: 2.290, Global test loss: 2.292, Global test accuracy: 14.02
Round 362, Train loss: 2.289, Test loss: 2.292, Test accuracy: 14.08
Round 362, Global train loss: 2.289, Global test loss: 2.292, Global test accuracy: 14.07
Round 363, Train loss: 2.292, Test loss: 2.292, Test accuracy: 14.11
Round 363, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 14.07
Round 364, Train loss: 2.290, Test loss: 2.292, Test accuracy: 14.14
Round 364, Global train loss: 2.290, Global test loss: 2.292, Global test accuracy: 14.13
Round 365, Train loss: 2.287, Test loss: 2.292, Test accuracy: 14.14
Round 365, Global train loss: 2.287, Global test loss: 2.292, Global test accuracy: 14.10
Round 366, Train loss: 2.291, Test loss: 2.292, Test accuracy: 14.18
Round 366, Global train loss: 2.291, Global test loss: 2.292, Global test accuracy: 14.13
Round 367, Train loss: 2.297, Test loss: 2.292, Test accuracy: 14.18
Round 367, Global train loss: 2.297, Global test loss: 2.292, Global test accuracy: 14.18
Round 368, Train loss: 2.293, Test loss: 2.292, Test accuracy: 14.18
Round 368, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 14.13
Round 369, Train loss: 2.290, Test loss: 2.292, Test accuracy: 14.18
Round 369, Global train loss: 2.290, Global test loss: 2.292, Global test accuracy: 14.11
Round 370, Train loss: 2.290, Test loss: 2.291, Test accuracy: 14.18
Round 370, Global train loss: 2.290, Global test loss: 2.292, Global test accuracy: 14.11
Round 371, Train loss: 2.294, Test loss: 2.291, Test accuracy: 14.18
Round 371, Global train loss: 2.294, Global test loss: 2.292, Global test accuracy: 14.11
Round 372, Train loss: 2.292, Test loss: 2.291, Test accuracy: 14.19
Round 372, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 14.17
Round 373, Train loss: 2.293, Test loss: 2.291, Test accuracy: 14.19
Round 373, Global train loss: 2.293, Global test loss: 2.291, Global test accuracy: 14.17
Round 374, Train loss: 2.292, Test loss: 2.291, Test accuracy: 14.19
Round 374, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 14.13
Round 375, Train loss: 2.296, Test loss: 2.291, Test accuracy: 14.19
Round 375, Global train loss: 2.296, Global test loss: 2.291, Global test accuracy: 14.13
Round 376, Train loss: 2.291, Test loss: 2.291, Test accuracy: 14.20
Round 376, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 14.18
Round 377, Train loss: 2.291, Test loss: 2.291, Test accuracy: 14.21
Round 377, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 14.22
Round 378, Train loss: 2.289, Test loss: 2.291, Test accuracy: 14.23
Round 378, Global train loss: 2.289, Global test loss: 2.291, Global test accuracy: 14.23
Round 379, Train loss: 2.291, Test loss: 2.291, Test accuracy: 14.23
Round 379, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 14.22
Round 380, Train loss: 2.292, Test loss: 2.291, Test accuracy: 14.26
Round 380, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 14.24
Round 381, Train loss: 2.289, Test loss: 2.291, Test accuracy: 14.27
Round 381, Global train loss: 2.289, Global test loss: 2.291, Global test accuracy: 14.23
Round 382, Train loss: 2.292, Test loss: 2.291, Test accuracy: 14.27
Round 382, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 14.23
Round 383, Train loss: 2.289, Test loss: 2.291, Test accuracy: 14.27
Round 383, Global train loss: 2.289, Global test loss: 2.291, Global test accuracy: 14.20
Round 384, Train loss: 2.288, Test loss: 2.291, Test accuracy: 14.27
Round 384, Global train loss: 2.288, Global test loss: 2.291, Global test accuracy: 14.20
Round 385, Train loss: 2.292, Test loss: 2.291, Test accuracy: 14.27
Round 385, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 14.21
Round 386, Train loss: 2.289, Test loss: 2.291, Test accuracy: 14.25
Round 386, Global train loss: 2.289, Global test loss: 2.291, Global test accuracy: 14.20
Round 387, Train loss: 2.296, Test loss: 2.291, Test accuracy: 14.25
Round 387, Global train loss: 2.296, Global test loss: 2.291, Global test accuracy: 14.22
Round 388, Train loss: 2.290, Test loss: 2.290, Test accuracy: 14.29
Round 388, Global train loss: 2.290, Global test loss: 2.291, Global test accuracy: 14.22
Round 389, Train loss: 2.287, Test loss: 2.290, Test accuracy: 14.31
Round 389, Global train loss: 2.287, Global test loss: 2.290, Global test accuracy: 14.24
Round 390, Train loss: 2.292, Test loss: 2.290, Test accuracy: 14.32
Round 390, Global train loss: 2.292, Global test loss: 2.290, Global test accuracy: 14.29
Round 391, Train loss: 2.293, Test loss: 2.290, Test accuracy: 14.34
Round 391, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 14.32
Round 392, Train loss: 2.290, Test loss: 2.290, Test accuracy: 14.34
Round 392, Global train loss: 2.290, Global test loss: 2.290, Global test accuracy: 14.30
Round 393, Train loss: 2.296, Test loss: 2.290, Test accuracy: 14.34
Round 393, Global train loss: 2.296, Global test loss: 2.290, Global test accuracy: 14.31
Round 394, Train loss: 2.293, Test loss: 2.290, Test accuracy: 14.37
Round 394, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 14.35
Round 395, Train loss: 2.293, Test loss: 2.290, Test accuracy: 14.38
Round 395, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 14.37
Round 396, Train loss: 2.290, Test loss: 2.290, Test accuracy: 14.38
Round 396, Global train loss: 2.290, Global test loss: 2.290, Global test accuracy: 14.31
Round 397, Train loss: 2.293, Test loss: 2.290, Test accuracy: 14.40
Round 397, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 14.35
Round 398, Train loss: 2.287, Test loss: 2.290, Test accuracy: 14.43
Round 398, Global train loss: 2.287, Global test loss: 2.290, Global test accuracy: 14.43
Round 399, Train loss: 2.291, Test loss: 2.290, Test accuracy: 14.44
Round 399, Global train loss: 2.291, Global test loss: 2.290, Global test accuracy: 14.44
Final Round, Train loss: 2.290, Test loss: 2.289, Test accuracy: 14.65
Final Round, Global train loss: 2.290, Global test loss: 2.290, Global test accuracy: 14.44
Average accuracy final 10 rounds: 14.373999999999999 

Average global accuracy final 10 rounds: 14.346999999999998 

3943.8700766563416
[0.9961838722229004, 1.8388724327087402, 2.6305766105651855, 3.449728012084961, 4.251312494277954, 5.0856850147247314, 5.918846607208252, 6.737942457199097, 7.561119794845581, 8.37440299987793, 9.192402124404907, 10.000128746032715, 10.827656269073486, 11.670184850692749, 12.496992349624634, 13.320187330245972, 14.135972261428833, 14.949947834014893, 15.760930061340332, 16.592357397079468, 17.41446614265442, 18.248777866363525, 19.067784070968628, 19.87834358215332, 20.706979990005493, 21.52852487564087, 22.371619701385498, 23.197569608688354, 24.02304983139038, 24.835250854492188, 25.651341915130615, 26.451192140579224, 27.250258207321167, 28.071504831314087, 28.91989040374756, 29.77347207069397, 30.5872745513916, 31.395916223526, 32.20816111564636, 33.02889943122864, 33.86375403404236, 34.68578910827637, 35.51147699356079, 36.33192229270935, 37.1584575176239, 37.982075691223145, 38.80879998207092, 39.63665175437927, 40.472195625305176, 41.29256749153137, 42.1153450012207, 42.93093967437744, 43.77968120574951, 44.61141753196716, 45.42951774597168, 46.25850772857666, 47.075340270996094, 47.89109754562378, 48.70806312561035, 49.548364877700806, 50.37641739845276, 51.19060206413269, 52.01962661743164, 52.846333265304565, 53.67043685913086, 54.50024771690369, 55.32307028770447, 56.17480540275574, 56.99825716018677, 57.83106541633606, 58.659789085388184, 59.47625136375427, 60.296226501464844, 61.12406396865845, 61.95337462425232, 62.77299404144287, 63.60565137863159, 64.40439486503601, 65.22049307823181, 66.04467725753784, 66.87347340583801, 67.70456981658936, 68.54382586479187, 69.36673545837402, 70.18287825584412, 70.99794316291809, 71.80501437187195, 72.63968014717102, 73.4587459564209, 74.29226756095886, 75.11725783348083, 75.94155859947205, 76.8018569946289, 77.63288807868958, 78.46986150741577, 79.29787015914917, 80.11668229103088, 80.94493341445923, 81.76868319511414, 82.58963871002197, 83.42769241333008, 84.25572872161865, 85.08352494239807, 85.91317820549011, 86.72986507415771, 87.54840159416199, 88.36341381072998, 89.1895649433136, 90.03701829910278, 90.8683762550354, 91.69380164146423, 92.51278614997864, 93.32977032661438, 94.14356780052185, 94.97086024284363, 95.7931776046753, 96.62555980682373, 97.44261431694031, 98.26108813285828, 99.06517887115479, 99.87613081932068, 100.69438815116882, 101.5107159614563, 102.32583975791931, 103.15217471122742, 103.9532425403595, 104.76843690872192, 105.58092927932739, 106.39591479301453, 107.22595500946045, 108.04875898361206, 108.85783100128174, 109.67226386070251, 110.46677041053772, 111.29381108283997, 112.1154716014862, 112.94419550895691, 113.76496839523315, 114.60175514221191, 115.40603446960449, 116.21404385566711, 117.02496433258057, 117.85195469856262, 118.67629861831665, 119.48027658462524, 120.27999067306519, 121.09936499595642, 121.91155982017517, 122.72845411300659, 123.54043364524841, 124.35208559036255, 125.15877532958984, 125.97444200515747, 126.79726099967957, 127.6098358631134, 128.4196536540985, 129.24503183364868, 130.05032873153687, 130.84727883338928, 131.6646695137024, 132.4747292995453, 133.30262684822083, 134.1216139793396, 134.94061946868896, 135.76364588737488, 136.57752346992493, 137.37774896621704, 138.16779828071594, 138.94920897483826, 139.7367012500763, 140.52054238319397, 141.2956247329712, 142.10993337631226, 142.89177584648132, 143.68096542358398, 144.4867570400238, 145.28347277641296, 146.09302735328674, 146.90408968925476, 147.71231627464294, 148.51344919204712, 149.27627992630005, 150.04046392440796, 150.81485676765442, 151.5831491947174, 152.3813600540161, 153.1614649295807, 153.93437504768372, 154.7038450241089, 155.47110652923584, 156.27718138694763, 157.0694441795349, 157.86307215690613, 158.66171789169312, 159.44450902938843, 160.25575995445251, 161.0525243282318, 161.85113549232483, 162.6511628627777, 163.41877150535583, 164.23320984840393, 165.037095785141, 165.83104538917542, 166.64135122299194, 167.44986653327942, 168.22865509986877, 169.02975344657898, 169.82242369651794, 170.6305525302887, 171.4388942718506, 172.21728253364563, 172.99517035484314, 173.7804811000824, 174.57059264183044, 175.3668715953827, 176.1626489162445, 176.97771191596985, 177.77235651016235, 178.5917809009552, 179.39894080162048, 180.203027009964, 180.99128198623657, 181.81433010101318, 182.59361934661865, 183.40758633613586, 184.2176661491394, 185.04859113693237, 185.8513059616089, 186.64366960525513, 187.44844770431519, 188.2600827217102, 189.08089923858643, 189.90865850448608, 190.7220003604889, 191.53803324699402, 192.34487509727478, 193.15756344795227, 193.99648594856262, 194.80628943443298, 195.64570808410645, 196.46866822242737, 197.25795936584473, 198.06212162971497, 198.8777928352356, 199.6930935382843, 200.5241026878357, 201.34261393547058, 202.17352509498596, 203.0062780380249, 203.79981231689453, 204.6132378578186, 205.44030165672302, 206.2672255039215, 207.10584425926208, 207.91892290115356, 208.728862285614, 209.56399536132812, 210.39261651039124, 211.23089599609375, 212.06172370910645, 212.87230324745178, 213.69482588768005, 214.51019072532654, 215.33436250686646, 216.17360973358154, 217.00277638435364, 217.84480786323547, 218.6730751991272, 219.4725387096405, 220.2806625366211, 221.09458374977112, 221.9157407283783, 222.74435019493103, 223.55840611457825, 224.3865807056427, 225.19836807250977, 226.0113286972046, 226.84472751617432, 227.66350269317627, 228.47373223304749, 229.3153431415558, 230.1344518661499, 230.94595170021057, 231.76803493499756, 232.6002197265625, 233.4495165348053, 234.28630113601685, 235.1136679649353, 235.937664270401, 236.71990156173706, 237.54313230514526, 238.3861780166626, 239.22323274612427, 240.05654907226562, 240.88715481758118, 241.70121026039124, 242.55532884597778, 243.3812370300293, 244.22380137443542, 245.06083941459656, 245.90731811523438, 246.75310802459717, 247.59480500221252, 248.4579312801361, 249.3071162700653, 250.12730050086975, 250.97451519966125, 251.8087282180786, 252.62694144248962, 253.46395087242126, 254.3070023059845, 255.14179062843323, 255.98538279533386, 256.8337173461914, 257.6685106754303, 258.5165295600891, 259.3820970058441, 260.23346495628357, 261.09026622772217, 261.91009402275085, 262.74074625968933, 263.5815808773041, 264.41639518737793, 265.24880838394165, 266.0913083553314, 266.9472990036011, 267.79442286491394, 268.6411383152008, 269.48474979400635, 270.3363881111145, 271.1771430969238, 272.0239746570587, 272.8624827861786, 273.70644998550415, 274.53192138671875, 275.36155915260315, 276.2031760215759, 277.0503821372986, 277.86936140060425, 278.7243142127991, 279.5732321739197, 280.4361107349396, 281.2804605960846, 282.1187798976898, 282.9695715904236, 283.8271255493164, 284.66058588027954, 285.49887108802795, 286.3528211116791, 287.1903862953186, 288.03039050102234, 288.88083505630493, 289.7286071777344, 290.5595302581787, 291.41772270202637, 292.2594578266144, 293.1041111946106, 293.95637249946594, 294.80627846717834, 295.65592885017395, 296.4995882511139, 297.3340001106262, 298.17570519447327, 299.01728105545044, 299.8330554962158, 300.6808202266693, 301.5311532020569, 302.36695861816406, 303.195392370224, 304.0406301021576, 304.8636815547943, 305.71175503730774, 306.56527948379517, 307.40958523750305, 308.2465159893036, 309.0841557979584, 309.90815711021423, 310.7511296272278, 311.5893204212189, 312.4154899120331, 313.27016830444336, 314.10746145248413, 314.9412214756012, 315.7789053916931, 316.6207067966461, 317.4679534435272, 318.31193566322327, 319.15081691741943, 319.99517822265625, 320.8374762535095, 321.69634079933167, 322.54534459114075, 323.3757448196411, 324.18778014183044, 325.0227265357971, 325.86008524894714, 326.6987724304199, 327.5320086479187, 328.36686754226685, 329.20497608184814, 330.87246084213257]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[13.06, 13.06, 13.05, 13.05, 13.05, 13.05, 13.05, 13.05, 13.05, 13.05, 13.05, 13.05, 13.05, 13.04, 13.04, 13.04, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.02, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.0, 13.0, 13.0, 13.0, 13.0, 13.01, 13.01, 13.01, 13.01, 13.01, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.01, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.02, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.03, 13.04, 13.03, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.04, 13.05, 13.05, 13.05, 13.06, 13.06, 13.06, 13.05, 13.05, 13.05, 13.05, 13.05, 13.06, 13.06, 13.06, 13.06, 13.07, 13.07, 13.07, 13.07, 13.07, 13.07, 13.07, 13.08, 13.08, 13.08, 13.09, 13.09, 13.1, 13.11, 13.11, 13.11, 13.12, 13.12, 13.12, 13.12, 13.11, 13.13, 13.13, 13.13, 13.16, 13.16, 13.16, 13.16, 13.17, 13.18, 13.18, 13.18, 13.18, 13.18, 13.18, 13.18, 13.18, 13.2, 13.2, 13.2, 13.2, 13.2, 13.21, 13.21, 13.21, 13.21, 13.21, 13.21, 13.23, 13.24, 13.24, 13.24, 13.24, 13.26, 13.28, 13.3, 13.3, 13.3, 13.3, 13.3, 13.33, 13.33, 13.35, 13.38, 13.38, 13.42, 13.45, 13.46, 13.48, 13.48, 13.54, 13.57, 13.59, 13.6, 13.61, 13.59, 13.63, 13.63, 13.64, 13.66, 13.67, 13.68, 13.69, 13.71, 13.79, 13.81, 13.84, 13.92, 13.95, 13.96, 13.96, 13.97, 13.97, 13.95, 13.96, 13.96, 13.96, 13.97, 13.99, 13.99, 13.99, 14.0, 13.99, 14.0, 14.0, 14.0, 13.99, 14.0, 14.01, 14.03, 14.03, 14.04, 14.03, 14.05, 14.06, 14.08, 14.11, 14.14, 14.14, 14.18, 14.18, 14.18, 14.18, 14.18, 14.18, 14.19, 14.19, 14.19, 14.19, 14.2, 14.21, 14.23, 14.23, 14.26, 14.27, 14.27, 14.27, 14.27, 14.27, 14.25, 14.25, 14.29, 14.31, 14.32, 14.34, 14.34, 14.34, 14.37, 14.38, 14.38, 14.4, 14.43, 14.44, 14.65]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.314, Test loss: 2.299, Test accuracy: 11.17
Round   1, Train loss: 2.287, Test loss: 2.291, Test accuracy: 16.99
Round   2, Train loss: 2.271, Test loss: 2.272, Test accuracy: 32.70
Round   3, Train loss: 2.206, Test loss: 2.209, Test accuracy: 48.47
Round   4, Train loss: 2.072, Test loss: 2.059, Test accuracy: 54.19
Round   5, Train loss: 1.908, Test loss: 1.943, Test accuracy: 66.12
Round   6, Train loss: 1.823, Test loss: 1.830, Test accuracy: 75.11
Round   7, Train loss: 1.711, Test loss: 1.757, Test accuracy: 78.13
Round   8, Train loss: 1.678, Test loss: 1.708, Test accuracy: 81.75
Round   9, Train loss: 1.672, Test loss: 1.666, Test accuracy: 86.62
Round  10, Train loss: 1.635, Test loss: 1.643, Test accuracy: 88.05
Round  11, Train loss: 1.605, Test loss: 1.628, Test accuracy: 89.00
Round  12, Train loss: 1.587, Test loss: 1.614, Test accuracy: 89.57
Round  13, Train loss: 1.582, Test loss: 1.599, Test accuracy: 91.54
Round  14, Train loss: 1.620, Test loss: 1.587, Test accuracy: 92.95
Round  15, Train loss: 1.551, Test loss: 1.577, Test accuracy: 94.03
Round  16, Train loss: 1.559, Test loss: 1.571, Test accuracy: 94.12
Round  17, Train loss: 1.559, Test loss: 1.568, Test accuracy: 94.43
Round  18, Train loss: 1.539, Test loss: 1.563, Test accuracy: 94.12
Round  19, Train loss: 1.546, Test loss: 1.559, Test accuracy: 94.48
Round  20, Train loss: 1.537, Test loss: 1.558, Test accuracy: 94.22
Round  21, Train loss: 1.537, Test loss: 1.555, Test accuracy: 94.27
Round  22, Train loss: 1.532, Test loss: 1.552, Test accuracy: 94.53
Round  23, Train loss: 1.552, Test loss: 1.542, Test accuracy: 95.07
Round  24, Train loss: 1.526, Test loss: 1.541, Test accuracy: 95.28
Round  25, Train loss: 1.532, Test loss: 1.539, Test accuracy: 95.39
Round  26, Train loss: 1.522, Test loss: 1.537, Test accuracy: 95.43
Round  27, Train loss: 1.534, Test loss: 1.534, Test accuracy: 95.58
Round  28, Train loss: 1.529, Test loss: 1.532, Test accuracy: 95.60
Round  29, Train loss: 1.519, Test loss: 1.533, Test accuracy: 95.48
Round  30, Train loss: 1.522, Test loss: 1.531, Test accuracy: 95.74
Round  31, Train loss: 1.520, Test loss: 1.530, Test accuracy: 95.76
Round  32, Train loss: 1.505, Test loss: 1.530, Test accuracy: 95.78
Round  33, Train loss: 1.505, Test loss: 1.529, Test accuracy: 95.93
Round  34, Train loss: 1.505, Test loss: 1.529, Test accuracy: 95.94
Round  35, Train loss: 1.509, Test loss: 1.528, Test accuracy: 95.97
Round  36, Train loss: 1.520, Test loss: 1.524, Test accuracy: 96.13
Round  37, Train loss: 1.519, Test loss: 1.522, Test accuracy: 96.18
Round  38, Train loss: 1.513, Test loss: 1.520, Test accuracy: 96.14
Round  39, Train loss: 1.503, Test loss: 1.520, Test accuracy: 96.27
Round  40, Train loss: 1.507, Test loss: 1.519, Test accuracy: 96.25
Round  41, Train loss: 1.506, Test loss: 1.518, Test accuracy: 96.26
Round  42, Train loss: 1.506, Test loss: 1.517, Test accuracy: 96.34
Round  43, Train loss: 1.498, Test loss: 1.517, Test accuracy: 96.32
Round  44, Train loss: 1.504, Test loss: 1.516, Test accuracy: 96.39
Round  45, Train loss: 1.498, Test loss: 1.515, Test accuracy: 96.43
Round  46, Train loss: 1.501, Test loss: 1.515, Test accuracy: 96.40
Round  47, Train loss: 1.499, Test loss: 1.515, Test accuracy: 96.47
Round  48, Train loss: 1.495, Test loss: 1.515, Test accuracy: 96.44
Round  49, Train loss: 1.500, Test loss: 1.514, Test accuracy: 96.43
Round  50, Train loss: 1.502, Test loss: 1.511, Test accuracy: 96.60
Round  51, Train loss: 1.499, Test loss: 1.512, Test accuracy: 96.66
Round  52, Train loss: 1.487, Test loss: 1.511, Test accuracy: 96.74
Round  53, Train loss: 1.487, Test loss: 1.511, Test accuracy: 96.78
Round  54, Train loss: 1.498, Test loss: 1.510, Test accuracy: 96.72
Round  55, Train loss: 1.492, Test loss: 1.510, Test accuracy: 96.89
Round  56, Train loss: 1.486, Test loss: 1.510, Test accuracy: 96.84
Round  57, Train loss: 1.493, Test loss: 1.509, Test accuracy: 96.80
Round  58, Train loss: 1.496, Test loss: 1.508, Test accuracy: 96.82
Round  59, Train loss: 1.488, Test loss: 1.507, Test accuracy: 96.88
Round  60, Train loss: 1.490, Test loss: 1.507, Test accuracy: 96.92
Round  61, Train loss: 1.489, Test loss: 1.507, Test accuracy: 96.91
Round  62, Train loss: 1.491, Test loss: 1.507, Test accuracy: 96.83
Round  63, Train loss: 1.489, Test loss: 1.507, Test accuracy: 97.02
Round  64, Train loss: 1.488, Test loss: 1.506, Test accuracy: 96.94
Round  65, Train loss: 1.490, Test loss: 1.506, Test accuracy: 96.95
Round  66, Train loss: 1.492, Test loss: 1.505, Test accuracy: 96.93
Round  67, Train loss: 1.487, Test loss: 1.506, Test accuracy: 96.88
Round  68, Train loss: 1.482, Test loss: 1.505, Test accuracy: 97.03
Round  69, Train loss: 1.485, Test loss: 1.504, Test accuracy: 97.10
Round  70, Train loss: 1.488, Test loss: 1.504, Test accuracy: 97.04
Round  71, Train loss: 1.487, Test loss: 1.504, Test accuracy: 97.14
Round  72, Train loss: 1.485, Test loss: 1.504, Test accuracy: 97.05
Round  73, Train loss: 1.481, Test loss: 1.503, Test accuracy: 97.06
Round  74, Train loss: 1.482, Test loss: 1.503, Test accuracy: 97.10
Round  75, Train loss: 1.478, Test loss: 1.503, Test accuracy: 97.17
Round  76, Train loss: 1.479, Test loss: 1.503, Test accuracy: 97.30
Round  77, Train loss: 1.488, Test loss: 1.503, Test accuracy: 97.23
Round  78, Train loss: 1.480, Test loss: 1.502, Test accuracy: 97.31
Round  79, Train loss: 1.479, Test loss: 1.502, Test accuracy: 97.22
Round  80, Train loss: 1.484, Test loss: 1.502, Test accuracy: 97.28
Round  81, Train loss: 1.481, Test loss: 1.502, Test accuracy: 97.24
Round  82, Train loss: 1.481, Test loss: 1.502, Test accuracy: 97.28
Round  83, Train loss: 1.480, Test loss: 1.502, Test accuracy: 97.28
Round  84, Train loss: 1.479, Test loss: 1.501, Test accuracy: 97.27
Round  85, Train loss: 1.480, Test loss: 1.501, Test accuracy: 97.23
Round  86, Train loss: 1.479, Test loss: 1.501, Test accuracy: 97.30
Round  87, Train loss: 1.475, Test loss: 1.501, Test accuracy: 97.29
Round  88, Train loss: 1.478, Test loss: 1.501, Test accuracy: 97.30
Round  89, Train loss: 1.479, Test loss: 1.501, Test accuracy: 97.28
Round  90, Train loss: 1.479, Test loss: 1.502, Test accuracy: 97.19
Round  91, Train loss: 1.477, Test loss: 1.501, Test accuracy: 97.27
Round  92, Train loss: 1.483, Test loss: 1.500, Test accuracy: 97.20
Round  93, Train loss: 1.481, Test loss: 1.500, Test accuracy: 97.29
Round  94, Train loss: 1.480, Test loss: 1.500, Test accuracy: 97.27
Round  95, Train loss: 1.481, Test loss: 1.499, Test accuracy: 97.24
Round  96, Train loss: 1.479, Test loss: 1.499, Test accuracy: 97.31
Round  97, Train loss: 1.478, Test loss: 1.499, Test accuracy: 97.32
Round  98, Train loss: 1.477, Test loss: 1.499, Test accuracy: 97.34
Round  99, Train loss: 1.481, Test loss: 1.499, Test accuracy: 97.34
Round 100, Train loss: 1.478, Test loss: 1.499, Test accuracy: 97.28
Round 101, Train loss: 1.478, Test loss: 1.499, Test accuracy: 97.33
Round 102, Train loss: 1.479, Test loss: 1.499, Test accuracy: 97.29
Round 103, Train loss: 1.476, Test loss: 1.499, Test accuracy: 97.26
Round 104, Train loss: 1.474, Test loss: 1.499, Test accuracy: 97.25
Round 105, Train loss: 1.480, Test loss: 1.499, Test accuracy: 97.36
Round 106, Train loss: 1.478, Test loss: 1.498, Test accuracy: 97.36
Round 107, Train loss: 1.472, Test loss: 1.498, Test accuracy: 97.38
Round 108, Train loss: 1.475, Test loss: 1.498, Test accuracy: 97.34
Round 109, Train loss: 1.477, Test loss: 1.498, Test accuracy: 97.39
Round 110, Train loss: 1.475, Test loss: 1.498, Test accuracy: 97.36
Round 111, Train loss: 1.475, Test loss: 1.498, Test accuracy: 97.32
Round 112, Train loss: 1.477, Test loss: 1.498, Test accuracy: 97.26
Round 113, Train loss: 1.475, Test loss: 1.498, Test accuracy: 97.25
Round 114, Train loss: 1.476, Test loss: 1.498, Test accuracy: 97.24
Round 115, Train loss: 1.472, Test loss: 1.498, Test accuracy: 97.25
Round 116, Train loss: 1.474, Test loss: 1.498, Test accuracy: 97.26
Round 117, Train loss: 1.474, Test loss: 1.498, Test accuracy: 97.35
Round 118, Train loss: 1.474, Test loss: 1.497, Test accuracy: 97.33
Round 119, Train loss: 1.475, Test loss: 1.497, Test accuracy: 97.38
Round 120, Train loss: 1.475, Test loss: 1.497, Test accuracy: 97.35
Round 121, Train loss: 1.474, Test loss: 1.497, Test accuracy: 97.32
Round 122, Train loss: 1.474, Test loss: 1.497, Test accuracy: 97.35
Round 123, Train loss: 1.472, Test loss: 1.496, Test accuracy: 97.34
Round 124, Train loss: 1.475, Test loss: 1.497, Test accuracy: 97.35
Round 125, Train loss: 1.474, Test loss: 1.497, Test accuracy: 97.28
Round 126, Train loss: 1.474, Test loss: 1.496, Test accuracy: 97.29
Round 127, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.34
Round 128, Train loss: 1.472, Test loss: 1.496, Test accuracy: 97.35
Round 129, Train loss: 1.473, Test loss: 1.496, Test accuracy: 97.41
Round 130, Train loss: 1.472, Test loss: 1.496, Test accuracy: 97.44
Round 131, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.31
Round 132, Train loss: 1.473, Test loss: 1.496, Test accuracy: 97.43
Round 133, Train loss: 1.473, Test loss: 1.496, Test accuracy: 97.34
Round 134, Train loss: 1.473, Test loss: 1.496, Test accuracy: 97.31
Round 135, Train loss: 1.470, Test loss: 1.496, Test accuracy: 97.42
Round 136, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.36
Round 137, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.39
Round 138, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.37
Round 139, Train loss: 1.469, Test loss: 1.496, Test accuracy: 97.39
Round 140, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.37
Round 141, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.32
Round 142, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.35
Round 143, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.38
Round 144, Train loss: 1.471, Test loss: 1.495, Test accuracy: 97.42
Round 145, Train loss: 1.472, Test loss: 1.495, Test accuracy: 97.37
Round 146, Train loss: 1.471, Test loss: 1.496, Test accuracy: 97.38
Round 147, Train loss: 1.469, Test loss: 1.495, Test accuracy: 97.37
Round 148, Train loss: 1.471, Test loss: 1.495, Test accuracy: 97.40
Round 149, Train loss: 1.470, Test loss: 1.495, Test accuracy: 97.49
Round 150, Train loss: 1.471, Test loss: 1.495, Test accuracy: 97.42
Round 151, Train loss: 1.470, Test loss: 1.495, Test accuracy: 97.42
Round 152, Train loss: 1.470, Test loss: 1.495, Test accuracy: 97.43
Round 153, Train loss: 1.469, Test loss: 1.495, Test accuracy: 97.41
Round 154, Train loss: 1.471, Test loss: 1.495, Test accuracy: 97.40
Round 155, Train loss: 1.470, Test loss: 1.495, Test accuracy: 97.45
Round 156, Train loss: 1.471, Test loss: 1.495, Test accuracy: 97.47
Round 157, Train loss: 1.470, Test loss: 1.495, Test accuracy: 97.46
Round 158, Train loss: 1.470, Test loss: 1.494, Test accuracy: 97.47
Round 159, Train loss: 1.469, Test loss: 1.495, Test accuracy: 97.38
Round 160, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.46
Round 161, Train loss: 1.471, Test loss: 1.495, Test accuracy: 97.47
Round 162, Train loss: 1.470, Test loss: 1.494, Test accuracy: 97.48
Round 163, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.50
Round 164, Train loss: 1.470, Test loss: 1.494, Test accuracy: 97.47
Round 165, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.49
Round 166, Train loss: 1.470, Test loss: 1.494, Test accuracy: 97.51
Round 167, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.48
Round 168, Train loss: 1.470, Test loss: 1.494, Test accuracy: 97.42
Round 169, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.49
Round 170, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.40
Round 171, Train loss: 1.471, Test loss: 1.494, Test accuracy: 97.47
Round 172, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.42
Round 173, Train loss: 1.470, Test loss: 1.494, Test accuracy: 97.41
Round 174, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.54
Round 175, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.51
Round 176, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.51
Round 177, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.47
Round 178, Train loss: 1.467, Test loss: 1.494, Test accuracy: 97.48
Round 179, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.42
Round 180, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.55
Round 181, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.49
Round 182, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.53
Round 183, Train loss: 1.467, Test loss: 1.493, Test accuracy: 97.54
Round 184, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.51
Round 185, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.56
Round 186, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.48
Round 187, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.46
Round 188, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.47
Round 189, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.46
Round 190, Train loss: 1.468, Test loss: 1.494, Test accuracy: 97.46
Round 191, Train loss: 1.469, Test loss: 1.494, Test accuracy: 97.54
Round 192, Train loss: 1.467, Test loss: 1.493, Test accuracy: 97.50
Round 193, Train loss: 1.468, Test loss: 1.493, Test accuracy: 97.57
Round 194, Train loss: 1.467, Test loss: 1.493, Test accuracy: 97.55
Round 195, Train loss: 1.468, Test loss: 1.493, Test accuracy: 97.59
Round 196, Train loss: 1.469, Test loss: 1.493, Test accuracy: 97.52
Round 197, Train loss: 1.468, Test loss: 1.493, Test accuracy: 97.55
Round 198, Train loss: 1.467, Test loss: 1.493, Test accuracy: 97.62
Round 199, Train loss: 1.468, Test loss: 1.493, Test accuracy: 97.58
Final Round, Train loss: 1.465, Test loss: 1.493, Test accuracy: 97.59
Average accuracy final 10 rounds: 97.54799999999999
1665.4079253673553
[1.1574013233184814, 2.1553590297698975, 3.147753953933716, 4.137793302536011, 5.129818439483643, 6.129974126815796, 7.134306192398071, 8.123624801635742, 9.120352268218994, 10.101126909255981, 11.103848218917847, 12.10497522354126, 13.09958529472351, 14.09805703163147, 15.08339524269104, 16.067462921142578, 17.083654165267944, 18.071950674057007, 19.064196586608887, 20.03540849685669, 21.037187337875366, 22.023082494735718, 23.00681471824646, 24.00742483139038, 25.017409801483154, 26.02343440055847, 27.0230131149292, 28.01535439491272, 28.995412349700928, 29.980915546417236, 30.97674822807312, 31.97902750968933, 32.969943046569824, 33.96437406539917, 34.965145111083984, 35.9590847492218, 36.96415948867798, 37.954288482666016, 38.94826602935791, 39.9374577999115, 40.94100785255432, 41.940751791000366, 42.94085073471069, 43.93366527557373, 44.91920590400696, 45.918577671051025, 46.91687297821045, 47.92041325569153, 48.922675371170044, 49.91907095909119, 50.93218159675598, 51.924678802490234, 52.91068148612976, 53.902496337890625, 54.87190270423889, 55.862364292144775, 56.83522963523865, 57.82640504837036, 58.78932547569275, 59.754070520401, 60.7336163520813, 61.695709466934204, 62.65510439872742, 63.619455337524414, 64.6156210899353, 65.60739612579346, 66.56120443344116, 67.52459716796875, 68.51270866394043, 69.48404240608215, 70.45136499404907, 71.43265318870544, 72.39251685142517, 73.36772608757019, 74.32619571685791, 75.30355286598206, 76.27086210250854, 77.3198766708374, 78.36525535583496, 79.42493891716003, 80.45383739471436, 81.43727612495422, 82.41155982017517, 83.38296270370483, 84.36499190330505, 85.35670018196106, 86.32221555709839, 87.30488896369934, 88.28676104545593, 89.27599358558655, 90.27151536941528, 91.23668122291565, 92.21220850944519, 93.18634486198425, 94.17302465438843, 95.1692144870758, 96.14687418937683, 97.12340807914734, 98.10407137870789, 99.06803822517395, 100.03651118278503, 101.01385307312012, 102.00366497039795, 103.02767086029053, 104.003741979599, 104.99475717544556, 105.98133730888367, 106.97323966026306, 107.94960594177246, 108.91372108459473, 109.8931155204773, 110.87384700775146, 111.85047316551208, 112.81320428848267, 113.76303577423096, 114.74159908294678, 115.7110846042633, 116.68616509437561, 117.69855618476868, 118.64068698883057, 119.55916333198547, 120.49843430519104, 121.44909596443176, 122.37080001831055, 123.31011128425598, 124.24630355834961, 125.17757487297058, 126.12054538726807, 127.05820345878601, 127.99948620796204, 128.96993279457092, 129.92947006225586, 130.889732837677, 131.86167216300964, 132.8211784362793, 133.77089190483093, 134.75599789619446, 135.73736929893494, 136.702641248703, 137.67902851104736, 138.62588930130005, 139.57892632484436, 140.5589497089386, 141.55264258384705, 142.50089049339294, 143.4516167640686, 144.39506483078003, 145.29601073265076, 146.2098000049591, 147.12824726104736, 148.02938437461853, 148.96143794059753, 149.88251733779907, 150.79831862449646, 151.7384066581726, 152.6772699356079, 153.5894434452057, 154.51973819732666, 155.45933151245117, 156.3836133480072, 157.34634804725647, 158.2913269996643, 159.2083237171173, 160.15741395950317, 161.1129059791565, 162.05258703231812, 163.00000643730164, 163.9425790309906, 164.8781762123108, 165.8449273109436, 166.80010223388672, 167.75025510787964, 168.69266080856323, 169.63555645942688, 170.6258568763733, 171.6536853313446, 172.59234404563904, 173.51585865020752, 174.50868964195251, 175.43088006973267, 176.37692880630493, 177.3275694847107, 178.26859736442566, 179.19963264465332, 180.1316475868225, 181.09882521629333, 182.02928638458252, 183.01240730285645, 183.93590831756592, 184.87769985198975, 185.80662560462952, 186.74617052078247, 187.673433303833, 188.59306597709656, 189.52112412452698, 190.45451879501343, 191.40176105499268, 192.33856201171875, 193.26460695266724, 194.1911745071411, 195.68311071395874]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[11.17, 16.99, 32.7, 48.47, 54.19, 66.12, 75.11, 78.13, 81.75, 86.62, 88.05, 89.0, 89.57, 91.54, 92.95, 94.03, 94.12, 94.43, 94.12, 94.48, 94.22, 94.27, 94.53, 95.07, 95.28, 95.39, 95.43, 95.58, 95.6, 95.48, 95.74, 95.76, 95.78, 95.93, 95.94, 95.97, 96.13, 96.18, 96.14, 96.27, 96.25, 96.26, 96.34, 96.32, 96.39, 96.43, 96.4, 96.47, 96.44, 96.43, 96.6, 96.66, 96.74, 96.78, 96.72, 96.89, 96.84, 96.8, 96.82, 96.88, 96.92, 96.91, 96.83, 97.02, 96.94, 96.95, 96.93, 96.88, 97.03, 97.1, 97.04, 97.14, 97.05, 97.06, 97.1, 97.17, 97.3, 97.23, 97.31, 97.22, 97.28, 97.24, 97.28, 97.28, 97.27, 97.23, 97.3, 97.29, 97.3, 97.28, 97.19, 97.27, 97.2, 97.29, 97.27, 97.24, 97.31, 97.32, 97.34, 97.34, 97.28, 97.33, 97.29, 97.26, 97.25, 97.36, 97.36, 97.38, 97.34, 97.39, 97.36, 97.32, 97.26, 97.25, 97.24, 97.25, 97.26, 97.35, 97.33, 97.38, 97.35, 97.32, 97.35, 97.34, 97.35, 97.28, 97.29, 97.34, 97.35, 97.41, 97.44, 97.31, 97.43, 97.34, 97.31, 97.42, 97.36, 97.39, 97.37, 97.39, 97.37, 97.32, 97.35, 97.38, 97.42, 97.37, 97.38, 97.37, 97.4, 97.49, 97.42, 97.42, 97.43, 97.41, 97.4, 97.45, 97.47, 97.46, 97.47, 97.38, 97.46, 97.47, 97.48, 97.5, 97.47, 97.49, 97.51, 97.48, 97.42, 97.49, 97.4, 97.47, 97.42, 97.41, 97.54, 97.51, 97.51, 97.47, 97.48, 97.42, 97.55, 97.49, 97.53, 97.54, 97.51, 97.56, 97.48, 97.46, 97.47, 97.46, 97.46, 97.54, 97.5, 97.57, 97.55, 97.59, 97.52, 97.55, 97.62, 97.58, 97.59]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.297, Test accuracy: 21.11
Round   1, Train loss: 2.294, Test loss: 2.285, Test accuracy: 31.01
Round   2, Train loss: 2.254, Test loss: 2.238, Test accuracy: 31.46
Round   3, Train loss: 2.135, Test loss: 2.117, Test accuracy: 46.55
Round   4, Train loss: 2.003, Test loss: 2.014, Test accuracy: 60.07
Round   5, Train loss: 1.926, Test loss: 1.931, Test accuracy: 65.89
Round   6, Train loss: 1.812, Test loss: 1.898, Test accuracy: 66.55
Round   7, Train loss: 1.806, Test loss: 1.875, Test accuracy: 66.73
Round   8, Train loss: 1.826, Test loss: 1.843, Test accuracy: 69.55
Round   9, Train loss: 1.810, Test loss: 1.816, Test accuracy: 71.34
Round  10, Train loss: 1.752, Test loss: 1.779, Test accuracy: 75.10
Round  11, Train loss: 1.745, Test loss: 1.733, Test accuracy: 79.92
Round  12, Train loss: 1.699, Test loss: 1.715, Test accuracy: 81.17
Round  13, Train loss: 1.707, Test loss: 1.687, Test accuracy: 84.22
Round  14, Train loss: 1.702, Test loss: 1.679, Test accuracy: 84.21
Round  15, Train loss: 1.677, Test loss: 1.656, Test accuracy: 86.53
Round  16, Train loss: 1.645, Test loss: 1.633, Test accuracy: 89.80
Round  17, Train loss: 1.589, Test loss: 1.629, Test accuracy: 90.30
Round  18, Train loss: 1.597, Test loss: 1.616, Test accuracy: 91.58
Round  19, Train loss: 1.619, Test loss: 1.601, Test accuracy: 93.08
Round  20, Train loss: 1.572, Test loss: 1.602, Test accuracy: 93.08
Round  21, Train loss: 1.582, Test loss: 1.593, Test accuracy: 93.26
Round  22, Train loss: 1.578, Test loss: 1.587, Test accuracy: 93.38
Round  23, Train loss: 1.554, Test loss: 1.588, Test accuracy: 93.47
Round  24, Train loss: 1.596, Test loss: 1.586, Test accuracy: 93.73
Round  25, Train loss: 1.577, Test loss: 1.579, Test accuracy: 93.70
Round  26, Train loss: 1.592, Test loss: 1.570, Test accuracy: 94.13
Round  27, Train loss: 1.555, Test loss: 1.572, Test accuracy: 94.07
Round  28, Train loss: 1.591, Test loss: 1.560, Test accuracy: 94.82
Round  29, Train loss: 1.558, Test loss: 1.558, Test accuracy: 95.33
Round  30, Train loss: 1.557, Test loss: 1.557, Test accuracy: 95.37
Round  31, Train loss: 1.560, Test loss: 1.555, Test accuracy: 95.36
Round  32, Train loss: 1.573, Test loss: 1.553, Test accuracy: 95.58
Round  33, Train loss: 1.541, Test loss: 1.552, Test accuracy: 95.48
Round  34, Train loss: 1.562, Test loss: 1.546, Test accuracy: 96.06
Round  35, Train loss: 1.546, Test loss: 1.545, Test accuracy: 96.17
Round  36, Train loss: 1.552, Test loss: 1.541, Test accuracy: 96.43
Round  37, Train loss: 1.534, Test loss: 1.541, Test accuracy: 96.51
Round  38, Train loss: 1.540, Test loss: 1.540, Test accuracy: 96.64
Round  39, Train loss: 1.537, Test loss: 1.538, Test accuracy: 96.60
Round  40, Train loss: 1.538, Test loss: 1.537, Test accuracy: 96.60
Round  41, Train loss: 1.537, Test loss: 1.535, Test accuracy: 96.72
Round  42, Train loss: 1.526, Test loss: 1.536, Test accuracy: 96.78
Round  43, Train loss: 1.546, Test loss: 1.532, Test accuracy: 96.86
Round  44, Train loss: 1.539, Test loss: 1.530, Test accuracy: 97.05
Round  45, Train loss: 1.527, Test loss: 1.531, Test accuracy: 97.00
Round  46, Train loss: 1.535, Test loss: 1.528, Test accuracy: 96.99
Round  47, Train loss: 1.529, Test loss: 1.527, Test accuracy: 97.03
Round  48, Train loss: 1.519, Test loss: 1.528, Test accuracy: 97.15
Round  49, Train loss: 1.525, Test loss: 1.528, Test accuracy: 97.13
Round  50, Train loss: 1.521, Test loss: 1.527, Test accuracy: 97.21
Round  51, Train loss: 1.522, Test loss: 1.527, Test accuracy: 97.23
Round  52, Train loss: 1.516, Test loss: 1.528, Test accuracy: 97.24
Round  53, Train loss: 1.525, Test loss: 1.526, Test accuracy: 97.21
Round  54, Train loss: 1.522, Test loss: 1.523, Test accuracy: 97.24
Round  55, Train loss: 1.516, Test loss: 1.523, Test accuracy: 97.27
Round  56, Train loss: 1.513, Test loss: 1.523, Test accuracy: 97.37
Round  57, Train loss: 1.518, Test loss: 1.522, Test accuracy: 97.43
Round  58, Train loss: 1.509, Test loss: 1.521, Test accuracy: 97.49
Round  59, Train loss: 1.509, Test loss: 1.522, Test accuracy: 97.47
Round  60, Train loss: 1.513, Test loss: 1.521, Test accuracy: 97.45
Round  61, Train loss: 1.509, Test loss: 1.521, Test accuracy: 97.46
Round  62, Train loss: 1.513, Test loss: 1.521, Test accuracy: 97.43
Round  63, Train loss: 1.516, Test loss: 1.518, Test accuracy: 97.43
Round  64, Train loss: 1.510, Test loss: 1.517, Test accuracy: 97.54
Round  65, Train loss: 1.508, Test loss: 1.519, Test accuracy: 97.51
Round  66, Train loss: 1.512, Test loss: 1.517, Test accuracy: 97.60
Round  67, Train loss: 1.507, Test loss: 1.518, Test accuracy: 97.72
Round  68, Train loss: 1.510, Test loss: 1.516, Test accuracy: 97.67
Round  69, Train loss: 1.512, Test loss: 1.515, Test accuracy: 97.64
Round  70, Train loss: 1.515, Test loss: 1.515, Test accuracy: 97.65
Round  71, Train loss: 1.505, Test loss: 1.514, Test accuracy: 97.67
Round  72, Train loss: 1.506, Test loss: 1.516, Test accuracy: 97.54
Round  73, Train loss: 1.509, Test loss: 1.513, Test accuracy: 97.65
Round  74, Train loss: 1.506, Test loss: 1.513, Test accuracy: 97.55
Round  75, Train loss: 1.501, Test loss: 1.513, Test accuracy: 97.58
Round  76, Train loss: 1.505, Test loss: 1.513, Test accuracy: 97.65
Round  77, Train loss: 1.503, Test loss: 1.512, Test accuracy: 97.66
Round  78, Train loss: 1.503, Test loss: 1.513, Test accuracy: 97.64
Round  79, Train loss: 1.502, Test loss: 1.514, Test accuracy: 97.64
Round  80, Train loss: 1.502, Test loss: 1.511, Test accuracy: 97.70
Round  81, Train loss: 1.500, Test loss: 1.513, Test accuracy: 97.74
Round  82, Train loss: 1.500, Test loss: 1.511, Test accuracy: 97.87
Round  83, Train loss: 1.505, Test loss: 1.512, Test accuracy: 97.73
Round  84, Train loss: 1.503, Test loss: 1.510, Test accuracy: 97.71
Round  85, Train loss: 1.500, Test loss: 1.512, Test accuracy: 97.78
Round  86, Train loss: 1.499, Test loss: 1.511, Test accuracy: 97.73
Round  87, Train loss: 1.501, Test loss: 1.512, Test accuracy: 97.73
Round  88, Train loss: 1.500, Test loss: 1.509, Test accuracy: 97.79
Round  89, Train loss: 1.499, Test loss: 1.509, Test accuracy: 97.79
Round  90, Train loss: 1.495, Test loss: 1.510, Test accuracy: 97.82
Round  91, Train loss: 1.499, Test loss: 1.510, Test accuracy: 97.82
Round  92, Train loss: 1.498, Test loss: 1.508, Test accuracy: 97.95
Round  93, Train loss: 1.497, Test loss: 1.508, Test accuracy: 97.83
Round  94, Train loss: 1.497, Test loss: 1.509, Test accuracy: 97.77
Round  95, Train loss: 1.497, Test loss: 1.509, Test accuracy: 97.84
Round  96, Train loss: 1.496, Test loss: 1.509, Test accuracy: 97.89
Round  97, Train loss: 1.498, Test loss: 1.509, Test accuracy: 97.89
Round  98, Train loss: 1.492, Test loss: 1.508, Test accuracy: 97.86
Round  99, Train loss: 1.494, Test loss: 1.508, Test accuracy: 97.88
Round 100, Train loss: 1.497, Test loss: 1.508, Test accuracy: 97.86
Round 101, Train loss: 1.497, Test loss: 1.507, Test accuracy: 97.86
Round 102, Train loss: 1.497, Test loss: 1.506, Test accuracy: 97.92
Round 103, Train loss: 1.496, Test loss: 1.507, Test accuracy: 97.97
Round 104, Train loss: 1.494, Test loss: 1.507, Test accuracy: 97.87
Round 105, Train loss: 1.494, Test loss: 1.507, Test accuracy: 97.82
Round 106, Train loss: 1.493, Test loss: 1.507, Test accuracy: 97.90
Round 107, Train loss: 1.492, Test loss: 1.507, Test accuracy: 97.86
Round 108, Train loss: 1.495, Test loss: 1.506, Test accuracy: 98.01
Round 109, Train loss: 1.493, Test loss: 1.507, Test accuracy: 97.93
Round 110, Train loss: 1.494, Test loss: 1.506, Test accuracy: 97.96
Round 111, Train loss: 1.494, Test loss: 1.505, Test accuracy: 97.96
Round 112, Train loss: 1.493, Test loss: 1.506, Test accuracy: 98.03
Round 113, Train loss: 1.493, Test loss: 1.506, Test accuracy: 98.01
Round 114, Train loss: 1.492, Test loss: 1.506, Test accuracy: 98.06
Round 115, Train loss: 1.493, Test loss: 1.505, Test accuracy: 97.96
Round 116, Train loss: 1.492, Test loss: 1.506, Test accuracy: 97.93
Round 117, Train loss: 1.491, Test loss: 1.505, Test accuracy: 98.04
Round 118, Train loss: 1.491, Test loss: 1.506, Test accuracy: 97.93
Round 119, Train loss: 1.492, Test loss: 1.506, Test accuracy: 97.99
Round 120, Train loss: 1.490, Test loss: 1.506, Test accuracy: 97.97
Round 121, Train loss: 1.491, Test loss: 1.505, Test accuracy: 97.98
Round 122, Train loss: 1.492, Test loss: 1.505, Test accuracy: 97.98
Round 123, Train loss: 1.489, Test loss: 1.504, Test accuracy: 98.01
Round 124, Train loss: 1.490, Test loss: 1.504, Test accuracy: 97.99
Round 125, Train loss: 1.489, Test loss: 1.505, Test accuracy: 97.98
Round 126, Train loss: 1.490, Test loss: 1.504, Test accuracy: 98.00
Round 127, Train loss: 1.490, Test loss: 1.505, Test accuracy: 97.99
Round 128, Train loss: 1.490, Test loss: 1.503, Test accuracy: 98.06
Round 129, Train loss: 1.489, Test loss: 1.503, Test accuracy: 97.97
Round 130, Train loss: 1.488, Test loss: 1.503, Test accuracy: 98.00
Round 131, Train loss: 1.491, Test loss: 1.504, Test accuracy: 98.02
Round 132, Train loss: 1.487, Test loss: 1.503, Test accuracy: 98.08
Round 133, Train loss: 1.490, Test loss: 1.503, Test accuracy: 98.06
Round 134, Train loss: 1.489, Test loss: 1.504, Test accuracy: 98.00
Round 135, Train loss: 1.488, Test loss: 1.503, Test accuracy: 98.04
Round 136, Train loss: 1.489, Test loss: 1.503, Test accuracy: 97.99
Round 137, Train loss: 1.490, Test loss: 1.504, Test accuracy: 97.96
Round 138, Train loss: 1.489, Test loss: 1.503, Test accuracy: 97.98
Round 139, Train loss: 1.487, Test loss: 1.503, Test accuracy: 97.95
Round 140, Train loss: 1.487, Test loss: 1.503, Test accuracy: 97.99
Round 141, Train loss: 1.489, Test loss: 1.504, Test accuracy: 97.97
Round 142, Train loss: 1.488, Test loss: 1.504, Test accuracy: 97.93
Round 143, Train loss: 1.486, Test loss: 1.503, Test accuracy: 98.10
Round 144, Train loss: 1.487, Test loss: 1.504, Test accuracy: 97.92
Round 145, Train loss: 1.486, Test loss: 1.503, Test accuracy: 98.04
Round 146, Train loss: 1.487, Test loss: 1.502, Test accuracy: 98.08
Round 147, Train loss: 1.486, Test loss: 1.504, Test accuracy: 97.96
Round 148, Train loss: 1.487, Test loss: 1.503, Test accuracy: 98.02
Round 149, Train loss: 1.488, Test loss: 1.503, Test accuracy: 97.92
Round 150, Train loss: 1.487, Test loss: 1.503, Test accuracy: 98.00
Round 151, Train loss: 1.487, Test loss: 1.503, Test accuracy: 98.05
Round 152, Train loss: 1.488, Test loss: 1.503, Test accuracy: 98.01
Round 153, Train loss: 1.486, Test loss: 1.503, Test accuracy: 98.03
Round 154, Train loss: 1.487, Test loss: 1.502, Test accuracy: 98.00
Round 155, Train loss: 1.485, Test loss: 1.502, Test accuracy: 98.08
Round 156, Train loss: 1.486, Test loss: 1.501, Test accuracy: 98.10
Round 157, Train loss: 1.485, Test loss: 1.502, Test accuracy: 98.09
Round 158, Train loss: 1.486, Test loss: 1.502, Test accuracy: 98.04
Round 159, Train loss: 1.485, Test loss: 1.501, Test accuracy: 98.07
Round 160, Train loss: 1.485, Test loss: 1.502, Test accuracy: 98.01
Round 161, Train loss: 1.485, Test loss: 1.502, Test accuracy: 98.00
Round 162, Train loss: 1.484, Test loss: 1.502, Test accuracy: 98.04
Round 163, Train loss: 1.484, Test loss: 1.503, Test accuracy: 97.90
Round 164, Train loss: 1.486, Test loss: 1.502, Test accuracy: 98.03
Round 165, Train loss: 1.485, Test loss: 1.502, Test accuracy: 98.01
Round 166, Train loss: 1.486, Test loss: 1.501, Test accuracy: 97.98
Round 167, Train loss: 1.485, Test loss: 1.501, Test accuracy: 98.07
Round 168, Train loss: 1.485, Test loss: 1.501, Test accuracy: 98.01
Round 169, Train loss: 1.485, Test loss: 1.502, Test accuracy: 97.97
Round 170, Train loss: 1.486, Test loss: 1.501, Test accuracy: 98.09
Round 171, Train loss: 1.484, Test loss: 1.501, Test accuracy: 98.00
Round 172, Train loss: 1.485, Test loss: 1.501, Test accuracy: 98.00
Round 173, Train loss: 1.484, Test loss: 1.501, Test accuracy: 97.97
Round 174, Train loss: 1.485, Test loss: 1.502, Test accuracy: 98.00
Round 175, Train loss: 1.484, Test loss: 1.501, Test accuracy: 98.02
Round 176, Train loss: 1.483, Test loss: 1.501, Test accuracy: 98.08
Round 177, Train loss: 1.485, Test loss: 1.501, Test accuracy: 98.01
Round 178, Train loss: 1.484, Test loss: 1.502, Test accuracy: 97.94
Round 179, Train loss: 1.483, Test loss: 1.501, Test accuracy: 98.08
Round 180, Train loss: 1.484, Test loss: 1.502, Test accuracy: 97.95
Round 181, Train loss: 1.483, Test loss: 1.501, Test accuracy: 98.00
Round 182, Train loss: 1.484, Test loss: 1.501, Test accuracy: 97.94
Round 183, Train loss: 1.483, Test loss: 1.501, Test accuracy: 97.99
Round 184, Train loss: 1.483, Test loss: 1.500, Test accuracy: 98.04
Round 185, Train loss: 1.485, Test loss: 1.501, Test accuracy: 97.96
Round 186, Train loss: 1.483, Test loss: 1.501, Test accuracy: 97.99
Round 187, Train loss: 1.483, Test loss: 1.501, Test accuracy: 97.97
Round 188, Train loss: 1.484, Test loss: 1.501, Test accuracy: 98.00
Round 189, Train loss: 1.483, Test loss: 1.501, Test accuracy: 97.99
Round 190, Train loss: 1.484, Test loss: 1.502, Test accuracy: 97.92
Round 191, Train loss: 1.485, Test loss: 1.501, Test accuracy: 97.97
Round 192, Train loss: 1.483, Test loss: 1.501, Test accuracy: 98.02
Round 193, Train loss: 1.483, Test loss: 1.501, Test accuracy: 98.02
Round 194, Train loss: 1.485, Test loss: 1.500, Test accuracy: 98.08
Round 195, Train loss: 1.483, Test loss: 1.501, Test accuracy: 98.02
Round 196, Train loss: 1.482, Test loss: 1.500, Test accuracy: 98.00
Round 197, Train loss: 1.482, Test loss: 1.500, Test accuracy: 98.05
Round 198, Train loss: 1.482, Test loss: 1.501, Test accuracy: 98.02
Round 199, Train loss: 1.484, Test loss: 1.501, Test accuracy: 97.99
Final Round, Train loss: 1.469, Test loss: 1.499, Test accuracy: 98.01
Average accuracy final 10 rounds: 98.00899999999999
2012.805302619934
[1.118229627609253, 2.236459255218506, 3.1914238929748535, 4.146388530731201, 5.093202114105225, 6.040015697479248, 6.961709022521973, 7.883402347564697, 8.798229694366455, 9.713057041168213, 10.582306861877441, 11.45155668258667, 12.360685110092163, 13.269813537597656, 14.181528568267822, 15.093243598937988, 15.976069688796997, 16.858895778656006, 17.739357948303223, 18.61982011795044, 19.487799406051636, 20.355778694152832, 21.22450613975525, 22.093233585357666, 22.993747234344482, 23.8942608833313, 24.846943616867065, 25.799626350402832, 26.68956470489502, 27.579503059387207, 28.47047519683838, 29.36144733428955, 30.265496969223022, 31.169546604156494, 32.07028126716614, 32.97101593017578, 33.85951495170593, 34.748013973236084, 35.646000385284424, 36.543986797332764, 37.40896821022034, 38.27394962310791, 39.14515924453735, 40.0163688659668, 40.93047761917114, 41.84458637237549, 42.75755548477173, 43.67052459716797, 44.55530261993408, 45.440080642700195, 46.32366228103638, 47.20724391937256, 48.1243212223053, 49.04139852523804, 49.907878160476685, 50.77435779571533, 51.67587995529175, 52.577402114868164, 53.48072600364685, 54.38404989242554, 55.29487156867981, 56.20569324493408, 57.086804151535034, 57.967915058135986, 58.873204469680786, 59.778493881225586, 60.64892816543579, 61.519362449645996, 62.40862274169922, 63.29788303375244, 64.23254585266113, 65.16720867156982, 66.09757208824158, 67.02793550491333, 67.93744087219238, 68.84694623947144, 69.71440243721008, 70.58185863494873, 71.4619722366333, 72.34208583831787, 73.21780395507812, 74.09352207183838, 74.96500086784363, 75.83647966384888, 76.75422716140747, 77.67197465896606, 78.57755517959595, 79.48313570022583, 80.34863996505737, 81.21414422988892, 82.09110450744629, 82.96806478500366, 83.91918802261353, 84.87031126022339, 85.78565859794617, 86.70100593566895, 87.626944065094, 88.55288219451904, 89.4879105091095, 90.42293882369995, 91.34854006767273, 92.27414131164551, 93.14980101585388, 94.02546072006226, 94.92110228538513, 95.81674385070801, 96.72294211387634, 97.62914037704468, 98.5238869190216, 99.41863346099854, 100.34565567970276, 101.27267789840698, 102.19383358955383, 103.11498928070068, 103.98941683769226, 104.86384439468384, 105.7659478187561, 106.66805124282837, 107.60042095184326, 108.53279066085815, 109.45447897911072, 110.37616729736328, 111.25379776954651, 112.13142824172974, 113.03192448616028, 113.93242073059082, 114.83493709564209, 115.73745346069336, 116.59466934204102, 117.45188522338867, 118.38632106781006, 119.32075691223145, 120.25485491752625, 121.18895292282104, 122.07409143447876, 122.95922994613647, 123.84232950210571, 124.72542905807495, 125.64587640762329, 126.56632375717163, 127.43101739883423, 128.29571104049683, 129.19443011283875, 130.09314918518066, 131.08591175079346, 132.07867431640625, 132.99501204490662, 133.91134977340698, 134.78858423233032, 135.66581869125366, 136.55538511276245, 137.44495153427124, 138.31963467597961, 139.194317817688, 140.14357590675354, 141.0928339958191, 142.00623178482056, 142.91962957382202, 143.82240200042725, 144.72517442703247, 145.61285090446472, 146.50052738189697, 147.37712621688843, 148.25372505187988, 149.14181661605835, 150.02990818023682, 150.89491152763367, 151.75991487503052, 152.64013528823853, 153.52035570144653, 154.41348886489868, 155.30662202835083, 156.17455315589905, 157.04248428344727, 157.9141502380371, 158.78581619262695, 159.6564748287201, 160.52713346481323, 161.3904218673706, 162.25371026992798, 163.1462857723236, 164.03886127471924, 164.9156403541565, 165.79241943359375, 166.660653591156, 167.52888774871826, 168.4179961681366, 169.30710458755493, 170.1572015285492, 171.00729846954346, 171.88404893875122, 172.76079940795898, 173.65486812591553, 174.54893684387207, 175.43793201446533, 176.3269271850586, 177.21507048606873, 178.10321378707886, 178.98244285583496, 179.86167192459106, 180.7329740524292, 181.60427618026733, 182.49026679992676, 183.37625741958618, 184.2460081577301, 185.11575889587402, 186.00857710838318, 186.90139532089233, 187.78985857963562, 188.6783218383789, 189.55041456222534, 190.42250728607178, 191.2952208518982, 192.1679344177246, 193.03298258781433, 193.89803075790405, 194.79537224769592, 195.6927137374878, 196.58436679840088, 197.47601985931396, 198.35281491279602, 199.22960996627808, 200.1220145225525, 201.0144190788269, 201.87200474739075, 202.7295904159546, 203.62053155899048, 204.51147270202637, 205.39034605026245, 206.26921939849854, 207.14192533493042, 208.0146312713623, 208.89811635017395, 209.7816014289856, 210.65876507759094, 211.5359287261963, 212.38794922828674, 213.2399697303772, 214.12345552444458, 215.00694131851196, 215.87840938568115, 216.74987745285034, 217.64148044586182, 218.5330834388733, 219.42345523834229, 220.31382703781128, 221.18153023719788, 222.04923343658447, 222.91331028938293, 223.7773871421814, 224.6417374610901, 225.50608777999878, 226.39682507514954, 227.2875623703003, 228.17864894866943, 229.06973552703857, 229.9598195552826, 230.8499035835266, 231.7182776927948, 232.586651802063, 233.4594898223877, 234.3323278427124, 235.19668912887573, 236.06105041503906, 236.95204758644104, 237.84304475784302, 238.72017192840576, 239.5972990989685, 240.47063040733337, 241.34396171569824, 242.23165941238403, 243.11935710906982, 243.9605405330658, 244.80172395706177, 245.69612169265747, 246.59051942825317, 247.48082613945007, 248.37113285064697, 249.23680186271667, 250.10247087478638, 250.99423360824585, 251.88599634170532, 252.7674596309662, 253.64892292022705, 254.5148425102234, 255.38076210021973, 256.26574087142944, 257.15071964263916, 258.03963017463684, 258.9285407066345, 259.824964761734, 260.7213888168335, 261.6123368740082, 262.50328493118286, 263.37413573265076, 264.24498653411865, 265.13133549690247, 266.0176844596863, 266.888787984848, 267.75989151000977, 268.6279966831207, 269.4961018562317, 270.3906388282776, 271.2851758003235, 272.1647856235504, 273.04439544677734, 273.93578267097473, 274.8271698951721, 275.70756936073303, 276.58796882629395, 277.4552438259125, 278.322518825531, 279.2241551876068, 280.1257915496826, 281.01197695732117, 281.8981623649597, 282.78547072410583, 283.67277908325195, 284.55923223495483, 285.4456853866577, 286.3352391719818, 287.2247929573059, 288.1058487892151, 288.98690462112427, 289.849871635437, 290.71283864974976, 291.5963408946991, 292.47984313964844, 293.3637068271637, 294.24757051467896, 295.132936000824, 296.018301486969, 296.9195821285248, 297.82086277008057, 298.70208382606506, 299.58330488204956, 300.4596827030182, 301.3360605239868, 302.2258837223053, 303.1157069206238, 304.01459312438965, 304.9134793281555, 305.7957091331482, 306.67793893814087, 307.5773904323578, 308.4768419265747, 309.347932100296, 310.21902227401733, 311.08962416648865, 311.96022605895996, 312.8449320793152, 313.7296380996704, 314.62105321884155, 315.5124683380127, 316.3982081413269, 317.2839479446411, 318.1766080856323, 319.06926822662354, 319.9379880428314, 320.8067078590393, 321.6916697025299, 322.5766315460205, 323.45477199554443, 324.33291244506836, 325.22246742248535, 326.11202239990234, 326.99299478530884, 327.87396717071533, 328.76680278778076, 329.6596384048462, 330.5457787513733, 331.4319190979004, 332.3071839809418, 333.18244886398315, 334.050039768219, 334.91763067245483, 335.80901622772217, 336.7004017829895, 337.5894820690155, 338.4785623550415, 339.3696572780609, 340.2607522010803, 341.14570808410645, 342.03066396713257, 342.9072976112366, 343.7839312553406, 344.66611528396606, 345.54829931259155, 346.451589345932, 347.35487937927246, 348.24096751213074, 349.127055644989, 350.0124843120575, 350.897912979126, 351.79692554473877, 352.69593811035156, 353.5748176574707, 354.45369720458984, 355.32651233673096, 356.19932746887207, 357.6061923503876, 359.0130572319031]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[21.11, 21.11, 31.01, 31.01, 31.46, 31.46, 46.55, 46.55, 60.07, 60.07, 65.89, 65.89, 66.55, 66.55, 66.73, 66.73, 69.55, 69.55, 71.34, 71.34, 75.1, 75.1, 79.92, 79.92, 81.17, 81.17, 84.22, 84.22, 84.21, 84.21, 86.53, 86.53, 89.8, 89.8, 90.3, 90.3, 91.58, 91.58, 93.08, 93.08, 93.08, 93.08, 93.26, 93.26, 93.38, 93.38, 93.47, 93.47, 93.73, 93.73, 93.7, 93.7, 94.13, 94.13, 94.07, 94.07, 94.82, 94.82, 95.33, 95.33, 95.37, 95.37, 95.36, 95.36, 95.58, 95.58, 95.48, 95.48, 96.06, 96.06, 96.17, 96.17, 96.43, 96.43, 96.51, 96.51, 96.64, 96.64, 96.6, 96.6, 96.6, 96.6, 96.72, 96.72, 96.78, 96.78, 96.86, 96.86, 97.05, 97.05, 97.0, 97.0, 96.99, 96.99, 97.03, 97.03, 97.15, 97.15, 97.13, 97.13, 97.21, 97.21, 97.23, 97.23, 97.24, 97.24, 97.21, 97.21, 97.24, 97.24, 97.27, 97.27, 97.37, 97.37, 97.43, 97.43, 97.49, 97.49, 97.47, 97.47, 97.45, 97.45, 97.46, 97.46, 97.43, 97.43, 97.43, 97.43, 97.54, 97.54, 97.51, 97.51, 97.6, 97.6, 97.72, 97.72, 97.67, 97.67, 97.64, 97.64, 97.65, 97.65, 97.67, 97.67, 97.54, 97.54, 97.65, 97.65, 97.55, 97.55, 97.58, 97.58, 97.65, 97.65, 97.66, 97.66, 97.64, 97.64, 97.64, 97.64, 97.7, 97.7, 97.74, 97.74, 97.87, 97.87, 97.73, 97.73, 97.71, 97.71, 97.78, 97.78, 97.73, 97.73, 97.73, 97.73, 97.79, 97.79, 97.79, 97.79, 97.82, 97.82, 97.82, 97.82, 97.95, 97.95, 97.83, 97.83, 97.77, 97.77, 97.84, 97.84, 97.89, 97.89, 97.89, 97.89, 97.86, 97.86, 97.88, 97.88, 97.86, 97.86, 97.86, 97.86, 97.92, 97.92, 97.97, 97.97, 97.87, 97.87, 97.82, 97.82, 97.9, 97.9, 97.86, 97.86, 98.01, 98.01, 97.93, 97.93, 97.96, 97.96, 97.96, 97.96, 98.03, 98.03, 98.01, 98.01, 98.06, 98.06, 97.96, 97.96, 97.93, 97.93, 98.04, 98.04, 97.93, 97.93, 97.99, 97.99, 97.97, 97.97, 97.98, 97.98, 97.98, 97.98, 98.01, 98.01, 97.99, 97.99, 97.98, 97.98, 98.0, 98.0, 97.99, 97.99, 98.06, 98.06, 97.97, 97.97, 98.0, 98.0, 98.02, 98.02, 98.08, 98.08, 98.06, 98.06, 98.0, 98.0, 98.04, 98.04, 97.99, 97.99, 97.96, 97.96, 97.98, 97.98, 97.95, 97.95, 97.99, 97.99, 97.97, 97.97, 97.93, 97.93, 98.1, 98.1, 97.92, 97.92, 98.04, 98.04, 98.08, 98.08, 97.96, 97.96, 98.02, 98.02, 97.92, 97.92, 98.0, 98.0, 98.05, 98.05, 98.01, 98.01, 98.03, 98.03, 98.0, 98.0, 98.08, 98.08, 98.1, 98.1, 98.09, 98.09, 98.04, 98.04, 98.07, 98.07, 98.01, 98.01, 98.0, 98.0, 98.04, 98.04, 97.9, 97.9, 98.03, 98.03, 98.01, 98.01, 97.98, 97.98, 98.07, 98.07, 98.01, 98.01, 97.97, 97.97, 98.09, 98.09, 98.0, 98.0, 98.0, 98.0, 97.97, 97.97, 98.0, 98.0, 98.02, 98.02, 98.08, 98.08, 98.01, 98.01, 97.94, 97.94, 98.08, 98.08, 97.95, 97.95, 98.0, 98.0, 97.94, 97.94, 97.99, 97.99, 98.04, 98.04, 97.96, 97.96, 97.99, 97.99, 97.97, 97.97, 98.0, 98.0, 97.99, 97.99, 97.92, 97.92, 97.97, 97.97, 98.02, 98.02, 98.02, 98.02, 98.08, 98.08, 98.02, 98.02, 98.0, 98.0, 98.05, 98.05, 98.02, 98.02, 97.99, 97.99, 98.01, 98.01]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.282, Test loss: 2.285, Test accuracy: 15.24
Round   0, Global train loss: 2.282, Global test loss: 2.302, Global test accuracy: 9.00
Round   1, Train loss: 2.190, Test loss: 2.213, Test accuracy: 24.21
Round   1, Global train loss: 2.190, Global test loss: 2.298, Global test accuracy: 14.15
Round   2, Train loss: 2.031, Test loss: 2.093, Test accuracy: 39.47
Round   2, Global train loss: 2.031, Global test loss: 2.286, Global test accuracy: 15.30
Round   3, Train loss: 1.917, Test loss: 1.982, Test accuracy: 49.94
Round   3, Global train loss: 1.917, Global test loss: 2.294, Global test accuracy: 13.12
Round   4, Train loss: 1.724, Test loss: 1.933, Test accuracy: 56.21
Round   4, Global train loss: 1.724, Global test loss: 2.309, Global test accuracy: 11.36
Round   5, Train loss: 1.802, Test loss: 1.860, Test accuracy: 62.70
Round   5, Global train loss: 1.802, Global test loss: 2.277, Global test accuracy: 16.33
Round   6, Train loss: 1.665, Test loss: 1.824, Test accuracy: 65.57
Round   6, Global train loss: 1.665, Global test loss: 2.293, Global test accuracy: 11.83
Round   7, Train loss: 1.702, Test loss: 1.760, Test accuracy: 72.26
Round   7, Global train loss: 1.702, Global test loss: 2.263, Global test accuracy: 17.95
Round   8, Train loss: 1.607, Test loss: 1.765, Test accuracy: 70.44
Round   8, Global train loss: 1.607, Global test loss: 2.299, Global test accuracy: 11.20
Round   9, Train loss: 1.710, Test loss: 1.709, Test accuracy: 77.72
Round   9, Global train loss: 1.710, Global test loss: 2.253, Global test accuracy: 18.84
Round  10, Train loss: 1.612, Test loss: 1.701, Test accuracy: 78.46
Round  10, Global train loss: 1.612, Global test loss: 2.285, Global test accuracy: 13.77
Round  11, Train loss: 1.637, Test loss: 1.691, Test accuracy: 79.35
Round  11, Global train loss: 1.637, Global test loss: 2.276, Global test accuracy: 17.56
Round  12, Train loss: 1.715, Test loss: 1.657, Test accuracy: 82.38
Round  12, Global train loss: 1.715, Global test loss: 2.277, Global test accuracy: 16.22
Round  13, Train loss: 1.552, Test loss: 1.654, Test accuracy: 82.44
Round  13, Global train loss: 1.552, Global test loss: 2.271, Global test accuracy: 17.30
Round  14, Train loss: 1.566, Test loss: 1.646, Test accuracy: 83.29
Round  14, Global train loss: 1.566, Global test loss: 2.263, Global test accuracy: 17.22
Round  15, Train loss: 1.585, Test loss: 1.644, Test accuracy: 83.34
Round  15, Global train loss: 1.585, Global test loss: 2.270, Global test accuracy: 19.45
Round  16, Train loss: 1.574, Test loss: 1.637, Test accuracy: 83.43
Round  16, Global train loss: 1.574, Global test loss: 2.266, Global test accuracy: 18.92
Round  17, Train loss: 1.631, Test loss: 1.629, Test accuracy: 84.34
Round  17, Global train loss: 1.631, Global test loss: 2.268, Global test accuracy: 17.53
Round  18, Train loss: 1.642, Test loss: 1.619, Test accuracy: 85.29
Round  18, Global train loss: 1.642, Global test loss: 2.229, Global test accuracy: 21.74
Round  19, Train loss: 1.541, Test loss: 1.618, Test accuracy: 85.30
Round  19, Global train loss: 1.541, Global test loss: 2.289, Global test accuracy: 13.89
Round  20, Train loss: 1.581, Test loss: 1.615, Test accuracy: 85.38
Round  20, Global train loss: 1.581, Global test loss: 2.308, Global test accuracy: 12.30
Round  21, Train loss: 1.578, Test loss: 1.614, Test accuracy: 85.39
Round  21, Global train loss: 1.578, Global test loss: 2.266, Global test accuracy: 17.04
Round  22, Train loss: 1.538, Test loss: 1.614, Test accuracy: 85.42
Round  22, Global train loss: 1.538, Global test loss: 2.270, Global test accuracy: 17.25
Round  23, Train loss: 1.548, Test loss: 1.613, Test accuracy: 85.51
Round  23, Global train loss: 1.548, Global test loss: 2.273, Global test accuracy: 16.71
Round  24, Train loss: 1.513, Test loss: 1.612, Test accuracy: 85.54
Round  24, Global train loss: 1.513, Global test loss: 2.271, Global test accuracy: 15.42
Round  25, Train loss: 1.557, Test loss: 1.607, Test accuracy: 86.08
Round  25, Global train loss: 1.557, Global test loss: 2.272, Global test accuracy: 15.74
Round  26, Train loss: 1.579, Test loss: 1.600, Test accuracy: 86.82
Round  26, Global train loss: 1.579, Global test loss: 2.271, Global test accuracy: 16.58
Round  27, Train loss: 1.512, Test loss: 1.600, Test accuracy: 86.86
Round  27, Global train loss: 1.512, Global test loss: 2.291, Global test accuracy: 12.51
Round  28, Train loss: 1.602, Test loss: 1.599, Test accuracy: 86.96
Round  28, Global train loss: 1.602, Global test loss: 2.281, Global test accuracy: 16.18
Round  29, Train loss: 1.601, Test loss: 1.599, Test accuracy: 86.91
Round  29, Global train loss: 1.601, Global test loss: 2.266, Global test accuracy: 16.29
Round  30, Train loss: 1.509, Test loss: 1.599, Test accuracy: 86.93
Round  30, Global train loss: 1.509, Global test loss: 2.317, Global test accuracy: 10.04
Round  31, Train loss: 1.571, Test loss: 1.597, Test accuracy: 87.04
Round  31, Global train loss: 1.571, Global test loss: 2.261, Global test accuracy: 18.19
Round  32, Train loss: 1.502, Test loss: 1.596, Test accuracy: 87.01
Round  32, Global train loss: 1.502, Global test loss: 2.302, Global test accuracy: 11.85
Round  33, Train loss: 1.535, Test loss: 1.596, Test accuracy: 87.00
Round  33, Global train loss: 1.535, Global test loss: 2.297, Global test accuracy: 13.61
Round  34, Train loss: 1.533, Test loss: 1.591, Test accuracy: 87.74
Round  34, Global train loss: 1.533, Global test loss: 2.288, Global test accuracy: 13.87
Round  35, Train loss: 1.505, Test loss: 1.586, Test accuracy: 88.35
Round  35, Global train loss: 1.505, Global test loss: 2.288, Global test accuracy: 13.08
Round  36, Train loss: 1.503, Test loss: 1.586, Test accuracy: 88.36
Round  36, Global train loss: 1.503, Global test loss: 2.312, Global test accuracy: 11.42
Round  37, Train loss: 1.503, Test loss: 1.586, Test accuracy: 88.38
Round  37, Global train loss: 1.503, Global test loss: 2.264, Global test accuracy: 17.33
Round  38, Train loss: 1.544, Test loss: 1.582, Test accuracy: 88.64
Round  38, Global train loss: 1.544, Global test loss: 2.268, Global test accuracy: 16.93
Round  39, Train loss: 1.538, Test loss: 1.582, Test accuracy: 88.66
Round  39, Global train loss: 1.538, Global test loss: 2.253, Global test accuracy: 18.80
Round  40, Train loss: 1.511, Test loss: 1.579, Test accuracy: 88.85
Round  40, Global train loss: 1.511, Global test loss: 2.278, Global test accuracy: 15.48
Round  41, Train loss: 1.505, Test loss: 1.579, Test accuracy: 88.82
Round  41, Global train loss: 1.505, Global test loss: 2.278, Global test accuracy: 14.69
Round  42, Train loss: 1.507, Test loss: 1.579, Test accuracy: 88.82
Round  42, Global train loss: 1.507, Global test loss: 2.259, Global test accuracy: 18.49
Round  43, Train loss: 1.504, Test loss: 1.578, Test accuracy: 88.82
Round  43, Global train loss: 1.504, Global test loss: 2.292, Global test accuracy: 14.39
Round  44, Train loss: 1.469, Test loss: 1.578, Test accuracy: 88.84
Round  44, Global train loss: 1.469, Global test loss: 2.314, Global test accuracy: 11.43
Round  45, Train loss: 1.534, Test loss: 1.578, Test accuracy: 88.85
Round  45, Global train loss: 1.534, Global test loss: 2.306, Global test accuracy: 12.18
Round  46, Train loss: 1.478, Test loss: 1.571, Test accuracy: 89.68
Round  46, Global train loss: 1.478, Global test loss: 2.284, Global test accuracy: 14.78
Round  47, Train loss: 1.537, Test loss: 1.570, Test accuracy: 89.69
Round  47, Global train loss: 1.537, Global test loss: 2.259, Global test accuracy: 18.01
Round  48, Train loss: 1.472, Test loss: 1.570, Test accuracy: 89.65
Round  48, Global train loss: 1.472, Global test loss: 2.295, Global test accuracy: 14.50
Round  49, Train loss: 1.536, Test loss: 1.570, Test accuracy: 89.67
Round  49, Global train loss: 1.536, Global test loss: 2.248, Global test accuracy: 20.51
Round  50, Train loss: 1.503, Test loss: 1.570, Test accuracy: 89.70
Round  50, Global train loss: 1.503, Global test loss: 2.258, Global test accuracy: 18.69
Round  51, Train loss: 1.503, Test loss: 1.570, Test accuracy: 89.65
Round  51, Global train loss: 1.503, Global test loss: 2.250, Global test accuracy: 19.74
Round  52, Train loss: 1.473, Test loss: 1.570, Test accuracy: 89.64
Round  52, Global train loss: 1.473, Global test loss: 2.289, Global test accuracy: 14.29
Round  53, Train loss: 1.501, Test loss: 1.569, Test accuracy: 89.63
Round  53, Global train loss: 1.501, Global test loss: 2.251, Global test accuracy: 19.40
Round  54, Train loss: 1.501, Test loss: 1.570, Test accuracy: 89.60
Round  54, Global train loss: 1.501, Global test loss: 2.272, Global test accuracy: 16.62
Round  55, Train loss: 1.501, Test loss: 1.570, Test accuracy: 89.62
Round  55, Global train loss: 1.501, Global test loss: 2.274, Global test accuracy: 15.56
Round  56, Train loss: 1.501, Test loss: 1.569, Test accuracy: 89.67
Round  56, Global train loss: 1.501, Global test loss: 2.282, Global test accuracy: 15.67
Round  57, Train loss: 1.534, Test loss: 1.569, Test accuracy: 89.65
Round  57, Global train loss: 1.534, Global test loss: 2.268, Global test accuracy: 16.92
Round  58, Train loss: 1.500, Test loss: 1.569, Test accuracy: 89.63
Round  58, Global train loss: 1.500, Global test loss: 2.238, Global test accuracy: 20.04
Round  59, Train loss: 1.502, Test loss: 1.569, Test accuracy: 89.66
Round  59, Global train loss: 1.502, Global test loss: 2.242, Global test accuracy: 21.01
Round  60, Train loss: 1.505, Test loss: 1.569, Test accuracy: 89.67
Round  60, Global train loss: 1.505, Global test loss: 2.260, Global test accuracy: 18.61
Round  61, Train loss: 1.501, Test loss: 1.569, Test accuracy: 89.66
Round  61, Global train loss: 1.501, Global test loss: 2.269, Global test accuracy: 16.19
Round  62, Train loss: 1.500, Test loss: 1.569, Test accuracy: 89.66
Round  62, Global train loss: 1.500, Global test loss: 2.265, Global test accuracy: 17.27
Round  63, Train loss: 1.499, Test loss: 1.569, Test accuracy: 89.68
Round  63, Global train loss: 1.499, Global test loss: 2.244, Global test accuracy: 20.48
Round  64, Train loss: 1.565, Test loss: 1.569, Test accuracy: 89.69
Round  64, Global train loss: 1.565, Global test loss: 2.249, Global test accuracy: 19.48
Round  65, Train loss: 1.532, Test loss: 1.569, Test accuracy: 89.69
Round  65, Global train loss: 1.532, Global test loss: 2.293, Global test accuracy: 12.91
Round  66, Train loss: 1.500, Test loss: 1.569, Test accuracy: 89.70
Round  66, Global train loss: 1.500, Global test loss: 2.288, Global test accuracy: 13.95
Round  67, Train loss: 1.470, Test loss: 1.569, Test accuracy: 89.69
Round  67, Global train loss: 1.470, Global test loss: 2.276, Global test accuracy: 16.92
Round  68, Train loss: 1.504, Test loss: 1.569, Test accuracy: 89.70
Round  68, Global train loss: 1.504, Global test loss: 2.250, Global test accuracy: 20.25
Round  69, Train loss: 1.533, Test loss: 1.569, Test accuracy: 89.72
Round  69, Global train loss: 1.533, Global test loss: 2.236, Global test accuracy: 20.64
Round  70, Train loss: 1.534, Test loss: 1.569, Test accuracy: 89.74
Round  70, Global train loss: 1.534, Global test loss: 2.256, Global test accuracy: 19.82
Round  71, Train loss: 1.530, Test loss: 1.568, Test accuracy: 89.74
Round  71, Global train loss: 1.530, Global test loss: 2.266, Global test accuracy: 16.97
Round  72, Train loss: 1.502, Test loss: 1.568, Test accuracy: 89.72
Round  72, Global train loss: 1.502, Global test loss: 2.283, Global test accuracy: 15.07
Round  73, Train loss: 1.501, Test loss: 1.569, Test accuracy: 89.71
Round  73, Global train loss: 1.501, Global test loss: 2.323, Global test accuracy: 9.01
Round  74, Train loss: 1.470, Test loss: 1.569, Test accuracy: 89.71
Round  74, Global train loss: 1.470, Global test loss: 2.273, Global test accuracy: 17.07
Round  75, Train loss: 1.503, Test loss: 1.569, Test accuracy: 89.71
Round  75, Global train loss: 1.503, Global test loss: 2.265, Global test accuracy: 17.84
Round  76, Train loss: 1.536, Test loss: 1.568, Test accuracy: 89.71
Round  76, Global train loss: 1.536, Global test loss: 2.275, Global test accuracy: 15.06
Round  77, Train loss: 1.500, Test loss: 1.569, Test accuracy: 89.72
Round  77, Global train loss: 1.500, Global test loss: 2.259, Global test accuracy: 18.83
Round  78, Train loss: 1.531, Test loss: 1.569, Test accuracy: 89.64
Round  78, Global train loss: 1.531, Global test loss: 2.257, Global test accuracy: 19.44
Round  79, Train loss: 1.499, Test loss: 1.569, Test accuracy: 89.64
Round  79, Global train loss: 1.499, Global test loss: 2.285, Global test accuracy: 15.48
Round  80, Train loss: 1.467, Test loss: 1.569, Test accuracy: 89.69
Round  80, Global train loss: 1.467, Global test loss: 2.246, Global test accuracy: 20.10
Round  81, Train loss: 1.465, Test loss: 1.569, Test accuracy: 89.62
Round  81, Global train loss: 1.465, Global test loss: 2.278, Global test accuracy: 14.59
Round  82, Train loss: 1.499, Test loss: 1.569, Test accuracy: 89.64
Round  82, Global train loss: 1.499, Global test loss: 2.286, Global test accuracy: 13.89
Round  83, Train loss: 1.469, Test loss: 1.569, Test accuracy: 89.66
Round  83, Global train loss: 1.469, Global test loss: 2.298, Global test accuracy: 12.69
Round  84, Train loss: 1.534, Test loss: 1.569, Test accuracy: 89.64
Round  84, Global train loss: 1.534, Global test loss: 2.303, Global test accuracy: 13.40
Round  85, Train loss: 1.467, Test loss: 1.569, Test accuracy: 89.64
Round  85, Global train loss: 1.467, Global test loss: 2.281, Global test accuracy: 15.31
Round  86, Train loss: 1.495, Test loss: 1.564, Test accuracy: 90.24
Round  86, Global train loss: 1.495, Global test loss: 2.270, Global test accuracy: 17.39
Round  87, Train loss: 1.467, Test loss: 1.564, Test accuracy: 90.24
Round  87, Global train loss: 1.467, Global test loss: 2.292, Global test accuracy: 14.09
Round  88, Train loss: 1.536, Test loss: 1.562, Test accuracy: 90.39
Round  88, Global train loss: 1.536, Global test loss: 2.232, Global test accuracy: 21.68
Round  89, Train loss: 1.469, Test loss: 1.562, Test accuracy: 90.40
Round  89, Global train loss: 1.469, Global test loss: 2.281, Global test accuracy: 14.69
Round  90, Train loss: 1.499, Test loss: 1.562, Test accuracy: 90.39
Round  90, Global train loss: 1.499, Global test loss: 2.301, Global test accuracy: 14.03
Round  91, Train loss: 1.533, Test loss: 1.562, Test accuracy: 90.38
Round  91, Global train loss: 1.533, Global test loss: 2.249, Global test accuracy: 19.12
Round  92, Train loss: 1.531, Test loss: 1.562, Test accuracy: 90.37
Round  92, Global train loss: 1.531, Global test loss: 2.244, Global test accuracy: 20.45
Round  93, Train loss: 1.470, Test loss: 1.562, Test accuracy: 90.37
Round  93, Global train loss: 1.470, Global test loss: 2.261, Global test accuracy: 17.86
Round  94, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.37
Round  94, Global train loss: 1.466, Global test loss: 2.260, Global test accuracy: 18.50
Round  95, Train loss: 1.470, Test loss: 1.562, Test accuracy: 90.27
Round  95, Global train loss: 1.470, Global test loss: 2.284, Global test accuracy: 15.99/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.476, Test loss: 1.555, Test accuracy: 91.00
Round  96, Global train loss: 1.476, Global test loss: 2.312, Global test accuracy: 12.42
Round  97, Train loss: 1.500, Test loss: 1.555, Test accuracy: 91.04
Round  97, Global train loss: 1.500, Global test loss: 2.247, Global test accuracy: 19.42
Round  98, Train loss: 1.500, Test loss: 1.555, Test accuracy: 91.06
Round  98, Global train loss: 1.500, Global test loss: 2.275, Global test accuracy: 16.61
Round  99, Train loss: 1.501, Test loss: 1.555, Test accuracy: 91.11
Round  99, Global train loss: 1.501, Global test loss: 2.279, Global test accuracy: 14.39
Final Round, Train loss: 1.488, Test loss: 1.553, Test accuracy: 91.14
Final Round, Global train loss: 1.488, Global test loss: 2.279, Global test accuracy: 14.39
Average accuracy final 10 rounds: 90.636 

Average global accuracy final 10 rounds: 16.878999999999998 

1313.8675587177277
[0.9964301586151123, 1.9928603172302246, 2.895479917526245, 3.7980995178222656, 4.680158376693726, 5.5622172355651855, 6.4432666301727295, 7.324316024780273, 8.226772546768188, 9.129229068756104, 10.017138957977295, 10.905048847198486, 11.807700872421265, 12.710352897644043, 13.607190370559692, 14.504027843475342, 15.398592948913574, 16.293158054351807, 17.191046953201294, 18.08893585205078, 18.9905526638031, 19.89216947555542, 20.79206109046936, 21.6919527053833, 22.60492753982544, 23.517902374267578, 24.433712244033813, 25.34952211380005, 26.263847827911377, 27.178173542022705, 28.08426284790039, 28.990352153778076, 29.883899927139282, 30.77744770050049, 31.68422555923462, 32.59100341796875, 33.48746919631958, 34.38393497467041, 35.28298020362854, 36.18202543258667, 37.070236682891846, 37.95844793319702, 38.85568904876709, 39.75293016433716, 40.65335035324097, 41.553770542144775, 42.4512984752655, 43.34882640838623, 44.25293803215027, 45.15704965591431, 46.06742715835571, 46.97780466079712, 47.88308548927307, 48.78836631774902, 49.697206258773804, 50.606046199798584, 51.51074719429016, 52.41544818878174, 53.32052659988403, 54.22560501098633, 55.124287128448486, 56.022969245910645, 56.91398072242737, 57.80499219894409, 58.69469094276428, 59.58438968658447, 60.47613787651062, 61.36788606643677, 62.27296757698059, 63.178049087524414, 64.07033967971802, 64.96263027191162, 65.86895632743835, 66.77528238296509, 67.68243503570557, 68.58958768844604, 69.49393391609192, 70.3982801437378, 71.30864024162292, 72.21900033950806, 73.12888431549072, 74.03876829147339, 74.94863390922546, 75.85849952697754, 76.77239656448364, 77.68629360198975, 78.59406566619873, 79.50183773040771, 80.4148223400116, 81.32780694961548, 82.2345232963562, 83.14123964309692, 84.04564046859741, 84.9500412940979, 85.83643007278442, 86.72281885147095, 87.6172935962677, 88.51176834106445, 89.41449666023254, 90.31722497940063, 91.23125743865967, 92.1452898979187, 93.04970121383667, 93.95411252975464, 94.85690116882324, 95.75968980789185, 96.66366457939148, 97.56763935089111, 98.47789072990417, 99.38814210891724, 100.29511713981628, 101.20209217071533, 102.1079478263855, 103.01380348205566, 103.9341242313385, 104.85444498062134, 105.76597452163696, 106.67750406265259, 107.58572220802307, 108.49394035339355, 109.4056487083435, 110.31735706329346, 111.20765399932861, 112.09795093536377, 112.98900127410889, 113.880051612854, 114.7892997264862, 115.69854784011841, 116.60198712348938, 117.50542640686035, 118.41107439994812, 119.31672239303589, 120.22119045257568, 121.12565851211548, 122.03062152862549, 122.9355845451355, 123.84246826171875, 124.749351978302, 125.66528987884521, 126.58122777938843, 127.48886132240295, 128.39649486541748, 129.3001937866211, 130.2038927078247, 131.1108820438385, 132.0178713798523, 132.9285659790039, 133.83926057815552, 134.73975706100464, 135.64025354385376, 136.53544402122498, 137.4306344985962, 138.32305216789246, 139.21546983718872, 140.09241271018982, 140.96935558319092, 141.85683584213257, 142.74431610107422, 143.6287796497345, 144.51324319839478, 145.38974404335022, 146.26624488830566, 147.15851759910583, 148.050790309906, 148.95005202293396, 149.8493137359619, 150.74587082862854, 151.64242792129517, 152.54843544960022, 153.45444297790527, 154.35273098945618, 155.25101900100708, 156.1591362953186, 157.06725358963013, 157.96990513801575, 158.87255668640137, 159.75022101402283, 160.6278853416443, 161.50725865364075, 162.3866319656372, 163.2696976661682, 164.15276336669922, 165.04433822631836, 165.9359130859375, 166.78973507881165, 167.6435570716858, 168.4731957912445, 169.30283451080322, 170.12153840065002, 170.94024229049683, 171.76424860954285, 172.58825492858887, 173.41251277923584, 174.2367706298828, 175.06593561172485, 175.8951005935669, 176.71997451782227, 177.54484844207764, 178.3605992794037, 179.17635011672974, 180.81316900253296, 182.44998788833618]
[15.24, 15.24, 24.21, 24.21, 39.47, 39.47, 49.94, 49.94, 56.21, 56.21, 62.7, 62.7, 65.57, 65.57, 72.26, 72.26, 70.44, 70.44, 77.72, 77.72, 78.46, 78.46, 79.35, 79.35, 82.38, 82.38, 82.44, 82.44, 83.29, 83.29, 83.34, 83.34, 83.43, 83.43, 84.34, 84.34, 85.29, 85.29, 85.3, 85.3, 85.38, 85.38, 85.39, 85.39, 85.42, 85.42, 85.51, 85.51, 85.54, 85.54, 86.08, 86.08, 86.82, 86.82, 86.86, 86.86, 86.96, 86.96, 86.91, 86.91, 86.93, 86.93, 87.04, 87.04, 87.01, 87.01, 87.0, 87.0, 87.74, 87.74, 88.35, 88.35, 88.36, 88.36, 88.38, 88.38, 88.64, 88.64, 88.66, 88.66, 88.85, 88.85, 88.82, 88.82, 88.82, 88.82, 88.82, 88.82, 88.84, 88.84, 88.85, 88.85, 89.68, 89.68, 89.69, 89.69, 89.65, 89.65, 89.67, 89.67, 89.7, 89.7, 89.65, 89.65, 89.64, 89.64, 89.63, 89.63, 89.6, 89.6, 89.62, 89.62, 89.67, 89.67, 89.65, 89.65, 89.63, 89.63, 89.66, 89.66, 89.67, 89.67, 89.66, 89.66, 89.66, 89.66, 89.68, 89.68, 89.69, 89.69, 89.69, 89.69, 89.7, 89.7, 89.69, 89.69, 89.7, 89.7, 89.72, 89.72, 89.74, 89.74, 89.74, 89.74, 89.72, 89.72, 89.71, 89.71, 89.71, 89.71, 89.71, 89.71, 89.71, 89.71, 89.72, 89.72, 89.64, 89.64, 89.64, 89.64, 89.69, 89.69, 89.62, 89.62, 89.64, 89.64, 89.66, 89.66, 89.64, 89.64, 89.64, 89.64, 90.24, 90.24, 90.24, 90.24, 90.39, 90.39, 90.4, 90.4, 90.39, 90.39, 90.38, 90.38, 90.37, 90.37, 90.37, 90.37, 90.37, 90.37, 90.27, 90.27, 91.0, 91.0, 91.04, 91.04, 91.06, 91.06, 91.11, 91.11, 91.14, 91.14]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.290, Test accuracy: 18.35
Round   0, Global train loss: 2.288, Global test loss: 2.299, Global test accuracy: 16.76
Round   1, Train loss: 2.249, Test loss: 2.257, Test accuracy: 18.96
Round   1, Global train loss: 2.249, Global test loss: 2.290, Global test accuracy: 16.35
Round   2, Train loss: 2.156, Test loss: 2.187, Test accuracy: 28.48
Round   2, Global train loss: 2.156, Global test loss: 2.283, Global test accuracy: 16.11
Round   3, Train loss: 2.048, Test loss: 2.083, Test accuracy: 40.82
Round   3, Global train loss: 2.048, Global test loss: 2.262, Global test accuracy: 17.07
Round   4, Train loss: 2.018, Test loss: 2.003, Test accuracy: 48.83
Round   4, Global train loss: 2.018, Global test loss: 2.251, Global test accuracy: 18.70
Round   5, Train loss: 1.915, Test loss: 1.965, Test accuracy: 53.05
Round   5, Global train loss: 1.915, Global test loss: 2.258, Global test accuracy: 18.18
Round   6, Train loss: 2.016, Test loss: 1.936, Test accuracy: 54.47
Round   6, Global train loss: 2.016, Global test loss: 2.241, Global test accuracy: 19.46
Round   7, Train loss: 1.887, Test loss: 1.923, Test accuracy: 55.89
Round   7, Global train loss: 1.887, Global test loss: 2.247, Global test accuracy: 20.51
Round   8, Train loss: 1.883, Test loss: 1.889, Test accuracy: 58.32
Round   8, Global train loss: 1.883, Global test loss: 2.252, Global test accuracy: 20.25
Round   9, Train loss: 1.922, Test loss: 1.874, Test accuracy: 59.65
Round   9, Global train loss: 1.922, Global test loss: 2.237, Global test accuracy: 21.77
Round  10, Train loss: 1.936, Test loss: 1.860, Test accuracy: 61.05
Round  10, Global train loss: 1.936, Global test loss: 2.236, Global test accuracy: 21.24
Round  11, Train loss: 1.849, Test loss: 1.847, Test accuracy: 62.17
Round  11, Global train loss: 1.849, Global test loss: 2.230, Global test accuracy: 21.50
Round  12, Train loss: 1.894, Test loss: 1.845, Test accuracy: 62.18
Round  12, Global train loss: 1.894, Global test loss: 2.239, Global test accuracy: 20.92
Round  13, Train loss: 1.776, Test loss: 1.839, Test accuracy: 63.10
Round  13, Global train loss: 1.776, Global test loss: 2.232, Global test accuracy: 21.03
Round  14, Train loss: 1.826, Test loss: 1.828, Test accuracy: 64.09
Round  14, Global train loss: 1.826, Global test loss: 2.243, Global test accuracy: 20.51
Round  15, Train loss: 1.839, Test loss: 1.812, Test accuracy: 65.61
Round  15, Global train loss: 1.839, Global test loss: 2.263, Global test accuracy: 17.43
Round  16, Train loss: 1.775, Test loss: 1.807, Test accuracy: 65.94
Round  16, Global train loss: 1.775, Global test loss: 2.257, Global test accuracy: 18.71
Round  17, Train loss: 1.755, Test loss: 1.789, Test accuracy: 67.84
Round  17, Global train loss: 1.755, Global test loss: 2.243, Global test accuracy: 19.23
Round  18, Train loss: 1.759, Test loss: 1.785, Test accuracy: 68.04
Round  18, Global train loss: 1.759, Global test loss: 2.256, Global test accuracy: 18.64
Round  19, Train loss: 1.846, Test loss: 1.785, Test accuracy: 68.12
Round  19, Global train loss: 1.846, Global test loss: 2.258, Global test accuracy: 18.71
Round  20, Train loss: 1.883, Test loss: 1.818, Test accuracy: 64.53
Round  20, Global train loss: 1.883, Global test loss: 2.251, Global test accuracy: 19.09
Round  21, Train loss: 1.924, Test loss: 1.830, Test accuracy: 63.20
Round  21, Global train loss: 1.924, Global test loss: 2.249, Global test accuracy: 19.67
Round  22, Train loss: 1.765, Test loss: 1.827, Test accuracy: 63.44
Round  22, Global train loss: 1.765, Global test loss: 2.240, Global test accuracy: 20.59
Round  23, Train loss: 1.813, Test loss: 1.817, Test accuracy: 64.43
Round  23, Global train loss: 1.813, Global test loss: 2.241, Global test accuracy: 20.11
Round  24, Train loss: 1.723, Test loss: 1.820, Test accuracy: 63.99
Round  24, Global train loss: 1.723, Global test loss: 2.258, Global test accuracy: 18.09
Round  25, Train loss: 1.853, Test loss: 1.823, Test accuracy: 63.80
Round  25, Global train loss: 1.853, Global test loss: 2.264, Global test accuracy: 17.67
Round  26, Train loss: 1.797, Test loss: 1.800, Test accuracy: 66.09
Round  26, Global train loss: 1.797, Global test loss: 2.242, Global test accuracy: 20.34
Round  27, Train loss: 1.788, Test loss: 1.809, Test accuracy: 65.20
Round  27, Global train loss: 1.788, Global test loss: 2.240, Global test accuracy: 20.64
Round  28, Train loss: 1.797, Test loss: 1.807, Test accuracy: 65.41
Round  28, Global train loss: 1.797, Global test loss: 2.247, Global test accuracy: 19.33
Round  29, Train loss: 1.855, Test loss: 1.791, Test accuracy: 67.08
Round  29, Global train loss: 1.855, Global test loss: 2.243, Global test accuracy: 20.57
Round  30, Train loss: 1.855, Test loss: 1.784, Test accuracy: 67.90
Round  30, Global train loss: 1.855, Global test loss: 2.258, Global test accuracy: 18.32
Round  31, Train loss: 1.806, Test loss: 1.774, Test accuracy: 68.97
Round  31, Global train loss: 1.806, Global test loss: 2.268, Global test accuracy: 17.24
Round  32, Train loss: 1.820, Test loss: 1.771, Test accuracy: 69.22
Round  32, Global train loss: 1.820, Global test loss: 2.260, Global test accuracy: 17.99
Round  33, Train loss: 1.815, Test loss: 1.763, Test accuracy: 70.08
Round  33, Global train loss: 1.815, Global test loss: 2.242, Global test accuracy: 20.39
Round  34, Train loss: 1.872, Test loss: 1.770, Test accuracy: 69.26
Round  34, Global train loss: 1.872, Global test loss: 2.244, Global test accuracy: 20.27
Round  35, Train loss: 1.746, Test loss: 1.769, Test accuracy: 69.36
Round  35, Global train loss: 1.746, Global test loss: 2.261, Global test accuracy: 17.87
Round  36, Train loss: 1.802, Test loss: 1.785, Test accuracy: 67.67
Round  36, Global train loss: 1.802, Global test loss: 2.243, Global test accuracy: 19.72
Round  37, Train loss: 1.711, Test loss: 1.786, Test accuracy: 67.52
Round  37, Global train loss: 1.711, Global test loss: 2.221, Global test accuracy: 22.41
Round  38, Train loss: 1.770, Test loss: 1.784, Test accuracy: 67.70
Round  38, Global train loss: 1.770, Global test loss: 2.236, Global test accuracy: 20.70
Round  39, Train loss: 1.779, Test loss: 1.793, Test accuracy: 66.71
Round  39, Global train loss: 1.779, Global test loss: 2.235, Global test accuracy: 20.71
Round  40, Train loss: 1.751, Test loss: 1.786, Test accuracy: 67.45
Round  40, Global train loss: 1.751, Global test loss: 2.244, Global test accuracy: 20.05
Round  41, Train loss: 1.790, Test loss: 1.785, Test accuracy: 67.44
Round  41, Global train loss: 1.790, Global test loss: 2.241, Global test accuracy: 20.51
Round  42, Train loss: 1.749, Test loss: 1.788, Test accuracy: 67.27
Round  42, Global train loss: 1.749, Global test loss: 2.236, Global test accuracy: 20.94
Round  43, Train loss: 1.725, Test loss: 1.768, Test accuracy: 69.33
Round  43, Global train loss: 1.725, Global test loss: 2.228, Global test accuracy: 21.54
Round  44, Train loss: 1.768, Test loss: 1.774, Test accuracy: 68.65
Round  44, Global train loss: 1.768, Global test loss: 2.238, Global test accuracy: 20.57
Round  45, Train loss: 1.842, Test loss: 1.772, Test accuracy: 68.78
Round  45, Global train loss: 1.842, Global test loss: 2.247, Global test accuracy: 19.93
Round  46, Train loss: 1.799, Test loss: 1.773, Test accuracy: 68.70
Round  46, Global train loss: 1.799, Global test loss: 2.259, Global test accuracy: 17.66
Round  47, Train loss: 1.815, Test loss: 1.761, Test accuracy: 70.02
Round  47, Global train loss: 1.815, Global test loss: 2.238, Global test accuracy: 20.18
Round  48, Train loss: 1.768, Test loss: 1.769, Test accuracy: 69.23
Round  48, Global train loss: 1.768, Global test loss: 2.241, Global test accuracy: 19.56
Round  49, Train loss: 1.828, Test loss: 1.766, Test accuracy: 69.53
Round  49, Global train loss: 1.828, Global test loss: 2.237, Global test accuracy: 20.83
Round  50, Train loss: 1.721, Test loss: 1.756, Test accuracy: 70.47
Round  50, Global train loss: 1.721, Global test loss: 2.245, Global test accuracy: 19.54
Round  51, Train loss: 1.844, Test loss: 1.743, Test accuracy: 71.99
Round  51, Global train loss: 1.844, Global test loss: 2.243, Global test accuracy: 19.79
Round  52, Train loss: 1.690, Test loss: 1.750, Test accuracy: 71.25
Round  52, Global train loss: 1.690, Global test loss: 2.224, Global test accuracy: 22.30
Round  53, Train loss: 1.709, Test loss: 1.756, Test accuracy: 70.47
Round  53, Global train loss: 1.709, Global test loss: 2.239, Global test accuracy: 19.90
Round  54, Train loss: 1.773, Test loss: 1.761, Test accuracy: 69.99
Round  54, Global train loss: 1.773, Global test loss: 2.225, Global test accuracy: 21.99
Round  55, Train loss: 1.758, Test loss: 1.761, Test accuracy: 69.96
Round  55, Global train loss: 1.758, Global test loss: 2.245, Global test accuracy: 19.77
Round  56, Train loss: 1.706, Test loss: 1.760, Test accuracy: 70.01
Round  56, Global train loss: 1.706, Global test loss: 2.231, Global test accuracy: 21.60
Round  57, Train loss: 1.754, Test loss: 1.760, Test accuracy: 69.99
Round  57, Global train loss: 1.754, Global test loss: 2.221, Global test accuracy: 21.91
Round  58, Train loss: 1.780, Test loss: 1.769, Test accuracy: 69.06
Round  58, Global train loss: 1.780, Global test loss: 2.241, Global test accuracy: 19.99
Round  59, Train loss: 1.728, Test loss: 1.769, Test accuracy: 69.09
Round  59, Global train loss: 1.728, Global test loss: 2.222, Global test accuracy: 22.78
Round  60, Train loss: 1.688, Test loss: 1.750, Test accuracy: 71.11
Round  60, Global train loss: 1.688, Global test loss: 2.231, Global test accuracy: 21.36
Round  61, Train loss: 1.766, Test loss: 1.735, Test accuracy: 72.72
Round  61, Global train loss: 1.766, Global test loss: 2.232, Global test accuracy: 20.75
Round  62, Train loss: 1.699, Test loss: 1.727, Test accuracy: 73.58
Round  62, Global train loss: 1.699, Global test loss: 2.227, Global test accuracy: 21.83
Round  63, Train loss: 1.742, Test loss: 1.726, Test accuracy: 73.61
Round  63, Global train loss: 1.742, Global test loss: 2.234, Global test accuracy: 20.95
Round  64, Train loss: 1.687, Test loss: 1.726, Test accuracy: 73.55
Round  64, Global train loss: 1.687, Global test loss: 2.243, Global test accuracy: 19.97
Round  65, Train loss: 1.691, Test loss: 1.726, Test accuracy: 73.54
Round  65, Global train loss: 1.691, Global test loss: 2.231, Global test accuracy: 21.65
Round  66, Train loss: 1.711, Test loss: 1.718, Test accuracy: 74.43
Round  66, Global train loss: 1.711, Global test loss: 2.232, Global test accuracy: 21.40
Round  67, Train loss: 1.698, Test loss: 1.717, Test accuracy: 74.44
Round  67, Global train loss: 1.698, Global test loss: 2.222, Global test accuracy: 22.50
Round  68, Train loss: 1.720, Test loss: 1.717, Test accuracy: 74.48
Round  68, Global train loss: 1.720, Global test loss: 2.231, Global test accuracy: 21.35
Round  69, Train loss: 1.695, Test loss: 1.717, Test accuracy: 74.41
Round  69, Global train loss: 1.695, Global test loss: 2.246, Global test accuracy: 19.48
Round  70, Train loss: 1.711, Test loss: 1.717, Test accuracy: 74.44
Round  70, Global train loss: 1.711, Global test loss: 2.222, Global test accuracy: 22.34
Round  71, Train loss: 1.658, Test loss: 1.716, Test accuracy: 74.53
Round  71, Global train loss: 1.658, Global test loss: 2.212, Global test accuracy: 23.20
Round  72, Train loss: 1.673, Test loss: 1.716, Test accuracy: 74.54
Round  72, Global train loss: 1.673, Global test loss: 2.221, Global test accuracy: 22.56
Round  73, Train loss: 1.746, Test loss: 1.724, Test accuracy: 73.73
Round  73, Global train loss: 1.746, Global test loss: 2.240, Global test accuracy: 20.13
Round  74, Train loss: 1.821, Test loss: 1.725, Test accuracy: 73.68
Round  74, Global train loss: 1.821, Global test loss: 2.240, Global test accuracy: 19.60
Round  75, Train loss: 1.740, Test loss: 1.725, Test accuracy: 73.61
Round  75, Global train loss: 1.740, Global test loss: 2.238, Global test accuracy: 20.29
Round  76, Train loss: 1.750, Test loss: 1.725, Test accuracy: 73.57
Round  76, Global train loss: 1.750, Global test loss: 2.227, Global test accuracy: 21.92
Round  77, Train loss: 1.804, Test loss: 1.724, Test accuracy: 73.67
Round  77, Global train loss: 1.804, Global test loss: 2.252, Global test accuracy: 17.84
Round  78, Train loss: 1.635, Test loss: 1.724, Test accuracy: 73.68
Round  78, Global train loss: 1.635, Global test loss: 2.243, Global test accuracy: 20.34
Round  79, Train loss: 1.794, Test loss: 1.718, Test accuracy: 74.19
Round  79, Global train loss: 1.794, Global test loss: 2.240, Global test accuracy: 20.18
Round  80, Train loss: 1.713, Test loss: 1.715, Test accuracy: 74.56
Round  80, Global train loss: 1.713, Global test loss: 2.260, Global test accuracy: 17.24
Round  81, Train loss: 1.789, Test loss: 1.714, Test accuracy: 74.57
Round  81, Global train loss: 1.789, Global test loss: 2.242, Global test accuracy: 20.16
Round  82, Train loss: 1.691, Test loss: 1.714, Test accuracy: 74.62
Round  82, Global train loss: 1.691, Global test loss: 2.223, Global test accuracy: 22.17
Round  83, Train loss: 1.761, Test loss: 1.706, Test accuracy: 75.52
Round  83, Global train loss: 1.761, Global test loss: 2.222, Global test accuracy: 21.99
Round  84, Train loss: 1.709, Test loss: 1.723, Test accuracy: 73.67
Round  84, Global train loss: 1.709, Global test loss: 2.223, Global test accuracy: 22.63
Round  85, Train loss: 1.669, Test loss: 1.724, Test accuracy: 73.64
Round  85, Global train loss: 1.669, Global test loss: 2.230, Global test accuracy: 21.31
Round  86, Train loss: 1.767, Test loss: 1.725, Test accuracy: 73.59
Round  86, Global train loss: 1.767, Global test loss: 2.230, Global test accuracy: 21.19
Round  87, Train loss: 1.754, Test loss: 1.719, Test accuracy: 74.21
Round  87, Global train loss: 1.754, Global test loss: 2.238, Global test accuracy: 20.57
Round  88, Train loss: 1.643, Test loss: 1.718, Test accuracy: 74.29
Round  88, Global train loss: 1.643, Global test loss: 2.223, Global test accuracy: 22.19
Round  89, Train loss: 1.781, Test loss: 1.699, Test accuracy: 76.27
Round  89, Global train loss: 1.781, Global test loss: 2.228, Global test accuracy: 21.40
Round  90, Train loss: 1.687, Test loss: 1.690, Test accuracy: 77.10
Round  90, Global train loss: 1.687, Global test loss: 2.234, Global test accuracy: 20.88
Round  91, Train loss: 1.692, Test loss: 1.692, Test accuracy: 76.99
Round  91, Global train loss: 1.692, Global test loss: 2.237, Global test accuracy: 20.27
Round  92, Train loss: 1.681, Test loss: 1.692, Test accuracy: 77.03
Round  92, Global train loss: 1.681, Global test loss: 2.225, Global test accuracy: 22.14
Round  93, Train loss: 1.711, Test loss: 1.693, Test accuracy: 76.93
Round  93, Global train loss: 1.711, Global test loss: 2.223, Global test accuracy: 21.66
Round  94, Train loss: 1.681, Test loss: 1.688, Test accuracy: 77.39
Round  94, Global train loss: 1.681, Global test loss: 2.231, Global test accuracy: 21.12
Round  95, Train loss: 1.684, Test loss: 1.679, Test accuracy: 78.37
Round  95, Global train loss: 1.684, Global test loss: 2.232, Global test accuracy: 21.55/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.691, Test loss: 1.679, Test accuracy: 78.38
Round  96, Global train loss: 1.691, Global test loss: 2.241, Global test accuracy: 20.36
Round  97, Train loss: 1.691, Test loss: 1.678, Test accuracy: 78.42
Round  97, Global train loss: 1.691, Global test loss: 2.233, Global test accuracy: 21.12
Round  98, Train loss: 1.664, Test loss: 1.678, Test accuracy: 78.46
Round  98, Global train loss: 1.664, Global test loss: 2.236, Global test accuracy: 20.58
Round  99, Train loss: 1.661, Test loss: 1.678, Test accuracy: 78.39
Round  99, Global train loss: 1.661, Global test loss: 2.233, Global test accuracy: 21.35
Final Round, Train loss: 1.638, Test loss: 1.650, Test accuracy: 81.21
Final Round, Global train loss: 1.638, Global test loss: 2.233, Global test accuracy: 21.35
Average accuracy final 10 rounds: 77.746 

Average global accuracy final 10 rounds: 21.103 

1169.6899952888489
[0.959975004196167, 1.919950008392334, 2.772576093673706, 3.625202178955078, 4.345001459121704, 5.06480073928833, 5.810143947601318, 6.555487155914307, 7.314659357070923, 8.073831558227539, 8.804534912109375, 9.535238265991211, 10.263285398483276, 10.991332530975342, 11.733231544494629, 12.475130558013916, 13.203708410263062, 13.932286262512207, 14.648707866668701, 15.365129470825195, 16.085949659347534, 16.806769847869873, 17.557076692581177, 18.30738353729248, 19.055140018463135, 19.80289649963379, 20.514315605163574, 21.22573471069336, 21.907902717590332, 22.590070724487305, 23.309366941452026, 24.028663158416748, 24.74519181251526, 25.46172046661377, 26.16185164451599, 26.861982822418213, 27.566558599472046, 28.27113437652588, 29.013481378555298, 29.755828380584717, 30.478967428207397, 31.202106475830078, 31.919159412384033, 32.63621234893799, 33.34791803359985, 34.05962371826172, 34.77137279510498, 35.48312187194824, 36.190924406051636, 36.89872694015503, 37.60200548171997, 38.30528402328491, 39.019919872283936, 39.73455572128296, 40.46281981468201, 41.191083908081055, 41.91882610321045, 42.646568298339844, 43.38004398345947, 44.1135196685791, 44.85044193267822, 45.587364196777344, 46.30530285835266, 47.02324151992798, 47.73615097999573, 48.44906044006348, 49.18677353858948, 49.92448663711548, 50.66942739486694, 51.41436815261841, 52.14823269844055, 52.882097244262695, 53.58326029777527, 54.28442335128784, 55.00998139381409, 55.73553943634033, 56.48088216781616, 57.22622489929199, 57.97157835960388, 58.71693181991577, 59.41749858856201, 60.11806535720825, 60.81876039505005, 61.519455432891846, 62.23956513404846, 62.95967483520508, 63.65667223930359, 64.3536696434021, 65.01761364936829, 65.68155765533447, 66.39848208427429, 67.11540651321411, 67.85493993759155, 68.594473361969, 69.3189709186554, 70.0434684753418, 70.75025415420532, 71.45703983306885, 72.19031643867493, 72.923593044281, 73.66485238075256, 74.40611171722412, 75.14049029350281, 75.8748688697815, 76.59729099273682, 77.31971311569214, 78.04702949523926, 78.77434587478638, 79.4996726512909, 80.22499942779541, 80.95782399177551, 81.69064855575562, 82.41377377510071, 83.1368989944458, 83.8612470626831, 84.58559513092041, 85.308748960495, 86.03190279006958, 86.73365354537964, 87.4354043006897, 88.16156005859375, 88.8877158164978, 89.60497283935547, 90.32222986221313, 90.99111843109131, 91.66000699996948, 92.37329363822937, 93.08658027648926, 93.81915640830994, 94.55173254013062, 95.2785964012146, 96.00546026229858, 96.72606778144836, 97.44667530059814, 98.16073966026306, 98.87480401992798, 99.60540843009949, 100.336012840271, 101.06572580337524, 101.79543876647949, 102.51167178153992, 103.22790479660034, 103.92990446090698, 104.63190412521362, 105.36394023895264, 106.09597635269165, 106.82552599906921, 107.55507564544678, 108.27870297431946, 109.00233030319214, 109.68767428398132, 110.37301826477051, 111.08540868759155, 111.7977991104126, 112.51324653625488, 113.22869396209717, 113.92102861404419, 114.61336326599121, 115.31952834129333, 116.02569341659546, 116.75715208053589, 117.48861074447632, 118.22995209693909, 118.97129344940186, 119.68762850761414, 120.40396356582642, 121.12717294692993, 121.85038232803345, 122.58616852760315, 123.32195472717285, 124.05020380020142, 124.77845287322998, 125.49525451660156, 126.21205615997314, 126.91953635215759, 127.62701654434204, 128.33956456184387, 129.0521125793457, 129.7654995918274, 130.47888660430908, 131.1786072254181, 131.8783278465271, 132.57649397850037, 133.27466011047363, 133.9746060371399, 134.67455196380615, 135.37612462043762, 136.0776972770691, 136.78765058517456, 137.49760389328003, 138.21586561203003, 138.93412733078003, 139.65219902992249, 140.37027072906494, 141.0918574333191, 141.81344413757324, 142.52937054634094, 143.24529695510864, 143.96930646896362, 144.6933159828186, 146.14074611663818, 147.58817625045776]
[18.35, 18.35, 18.96, 18.96, 28.48, 28.48, 40.82, 40.82, 48.83, 48.83, 53.05, 53.05, 54.47, 54.47, 55.89, 55.89, 58.32, 58.32, 59.65, 59.65, 61.05, 61.05, 62.17, 62.17, 62.18, 62.18, 63.1, 63.1, 64.09, 64.09, 65.61, 65.61, 65.94, 65.94, 67.84, 67.84, 68.04, 68.04, 68.12, 68.12, 64.53, 64.53, 63.2, 63.2, 63.44, 63.44, 64.43, 64.43, 63.99, 63.99, 63.8, 63.8, 66.09, 66.09, 65.2, 65.2, 65.41, 65.41, 67.08, 67.08, 67.9, 67.9, 68.97, 68.97, 69.22, 69.22, 70.08, 70.08, 69.26, 69.26, 69.36, 69.36, 67.67, 67.67, 67.52, 67.52, 67.7, 67.7, 66.71, 66.71, 67.45, 67.45, 67.44, 67.44, 67.27, 67.27, 69.33, 69.33, 68.65, 68.65, 68.78, 68.78, 68.7, 68.7, 70.02, 70.02, 69.23, 69.23, 69.53, 69.53, 70.47, 70.47, 71.99, 71.99, 71.25, 71.25, 70.47, 70.47, 69.99, 69.99, 69.96, 69.96, 70.01, 70.01, 69.99, 69.99, 69.06, 69.06, 69.09, 69.09, 71.11, 71.11, 72.72, 72.72, 73.58, 73.58, 73.61, 73.61, 73.55, 73.55, 73.54, 73.54, 74.43, 74.43, 74.44, 74.44, 74.48, 74.48, 74.41, 74.41, 74.44, 74.44, 74.53, 74.53, 74.54, 74.54, 73.73, 73.73, 73.68, 73.68, 73.61, 73.61, 73.57, 73.57, 73.67, 73.67, 73.68, 73.68, 74.19, 74.19, 74.56, 74.56, 74.57, 74.57, 74.62, 74.62, 75.52, 75.52, 73.67, 73.67, 73.64, 73.64, 73.59, 73.59, 74.21, 74.21, 74.29, 74.29, 76.27, 76.27, 77.1, 77.1, 76.99, 76.99, 77.03, 77.03, 76.93, 76.93, 77.39, 77.39, 78.37, 78.37, 78.38, 78.38, 78.42, 78.42, 78.46, 78.46, 78.39, 78.39, 81.21, 81.21]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.301, Test accuracy: 13.02
Round   1, Train loss: 2.295, Test loss: 2.299, Test accuracy: 13.04
Round   2, Train loss: 2.292, Test loss: 2.297, Test accuracy: 13.99
Round   3, Train loss: 2.283, Test loss: 2.290, Test accuracy: 14.88
Round   4, Train loss: 2.267, Test loss: 2.277, Test accuracy: 18.18
Round   5, Train loss: 2.234, Test loss: 2.256, Test accuracy: 19.45
Round   6, Train loss: 2.204, Test loss: 2.232, Test accuracy: 21.02
Round   7, Train loss: 2.164, Test loss: 2.207, Test accuracy: 25.00
Round   8, Train loss: 2.118, Test loss: 2.178, Test accuracy: 28.07
Round   9, Train loss: 2.061, Test loss: 2.123, Test accuracy: 36.70
Round  10, Train loss: 1.982, Test loss: 2.072, Test accuracy: 41.82
Round  11, Train loss: 1.956, Test loss: 2.036, Test accuracy: 43.93
Round  12, Train loss: 1.886, Test loss: 1.982, Test accuracy: 49.66
Round  13, Train loss: 1.849, Test loss: 1.939, Test accuracy: 54.30
Round  14, Train loss: 1.786, Test loss: 1.910, Test accuracy: 56.63
Round  15, Train loss: 1.879, Test loss: 1.881, Test accuracy: 59.69
Round  16, Train loss: 1.815, Test loss: 1.873, Test accuracy: 59.89
Round  17, Train loss: 1.730, Test loss: 1.849, Test accuracy: 62.70
Round  18, Train loss: 1.799, Test loss: 1.839, Test accuracy: 63.36
Round  19, Train loss: 1.805, Test loss: 1.830, Test accuracy: 64.42
Round  20, Train loss: 1.848, Test loss: 1.826, Test accuracy: 64.66
Round  21, Train loss: 1.709, Test loss: 1.824, Test accuracy: 64.68
Round  22, Train loss: 1.856, Test loss: 1.824, Test accuracy: 64.57
Round  23, Train loss: 1.800, Test loss: 1.811, Test accuracy: 66.08
Round  24, Train loss: 1.762, Test loss: 1.800, Test accuracy: 67.42
Round  25, Train loss: 1.786, Test loss: 1.798, Test accuracy: 67.49
Round  26, Train loss: 1.743, Test loss: 1.791, Test accuracy: 68.00
Round  27, Train loss: 1.797, Test loss: 1.782, Test accuracy: 68.62
Round  28, Train loss: 1.733, Test loss: 1.774, Test accuracy: 69.41
Round  29, Train loss: 1.724, Test loss: 1.763, Test accuracy: 70.69
Round  30, Train loss: 1.824, Test loss: 1.763, Test accuracy: 70.68
Round  31, Train loss: 1.788, Test loss: 1.761, Test accuracy: 70.74
Round  32, Train loss: 1.677, Test loss: 1.761, Test accuracy: 70.59
Round  33, Train loss: 1.718, Test loss: 1.759, Test accuracy: 70.81
Round  34, Train loss: 1.740, Test loss: 1.758, Test accuracy: 70.95
Round  35, Train loss: 1.779, Test loss: 1.753, Test accuracy: 71.32
Round  36, Train loss: 1.680, Test loss: 1.751, Test accuracy: 71.53
Round  37, Train loss: 1.733, Test loss: 1.750, Test accuracy: 71.70
Round  38, Train loss: 1.683, Test loss: 1.750, Test accuracy: 71.42
Round  39, Train loss: 1.842, Test loss: 1.750, Test accuracy: 71.44
Round  40, Train loss: 1.680, Test loss: 1.743, Test accuracy: 72.42
Round  41, Train loss: 1.715, Test loss: 1.744, Test accuracy: 72.32
Round  42, Train loss: 1.625, Test loss: 1.739, Test accuracy: 72.70
Round  43, Train loss: 1.601, Test loss: 1.739, Test accuracy: 72.69
Round  44, Train loss: 1.642, Test loss: 1.737, Test accuracy: 72.81
Round  45, Train loss: 1.818, Test loss: 1.736, Test accuracy: 72.91
Round  46, Train loss: 1.672, Test loss: 1.734, Test accuracy: 73.09
Round  47, Train loss: 1.762, Test loss: 1.733, Test accuracy: 73.14
Round  48, Train loss: 1.726, Test loss: 1.734, Test accuracy: 73.18
Round  49, Train loss: 1.752, Test loss: 1.733, Test accuracy: 73.10
Round  50, Train loss: 1.601, Test loss: 1.732, Test accuracy: 73.25
Round  51, Train loss: 1.693, Test loss: 1.731, Test accuracy: 73.38
Round  52, Train loss: 1.697, Test loss: 1.731, Test accuracy: 73.24
Round  53, Train loss: 1.635, Test loss: 1.730, Test accuracy: 73.36
Round  54, Train loss: 1.598, Test loss: 1.729, Test accuracy: 73.47
Round  55, Train loss: 1.780, Test loss: 1.729, Test accuracy: 73.37
Round  56, Train loss: 1.717, Test loss: 1.729, Test accuracy: 73.38
Round  57, Train loss: 1.713, Test loss: 1.729, Test accuracy: 73.43
Round  58, Train loss: 1.729, Test loss: 1.728, Test accuracy: 73.38
Round  59, Train loss: 1.628, Test loss: 1.729, Test accuracy: 73.36
Round  60, Train loss: 1.595, Test loss: 1.729, Test accuracy: 73.40
Round  61, Train loss: 1.679, Test loss: 1.730, Test accuracy: 73.43
Round  62, Train loss: 1.745, Test loss: 1.729, Test accuracy: 73.39
Round  63, Train loss: 1.627, Test loss: 1.729, Test accuracy: 73.46
Round  64, Train loss: 1.688, Test loss: 1.729, Test accuracy: 73.51
Round  65, Train loss: 1.686, Test loss: 1.726, Test accuracy: 73.72
Round  66, Train loss: 1.714, Test loss: 1.725, Test accuracy: 73.80
Round  67, Train loss: 1.838, Test loss: 1.725, Test accuracy: 73.79
Round  68, Train loss: 1.717, Test loss: 1.725, Test accuracy: 73.77
Round  69, Train loss: 1.748, Test loss: 1.725, Test accuracy: 73.72
Round  70, Train loss: 1.686, Test loss: 1.725, Test accuracy: 73.73
Round  71, Train loss: 1.684, Test loss: 1.725, Test accuracy: 73.72
Round  72, Train loss: 1.775, Test loss: 1.725, Test accuracy: 73.72
Round  73, Train loss: 1.777, Test loss: 1.725, Test accuracy: 73.66
Round  74, Train loss: 1.680, Test loss: 1.725, Test accuracy: 73.76
Round  75, Train loss: 1.681, Test loss: 1.724, Test accuracy: 73.76
Round  76, Train loss: 1.713, Test loss: 1.725, Test accuracy: 73.81
Round  77, Train loss: 1.656, Test loss: 1.725, Test accuracy: 73.67
Round  78, Train loss: 1.653, Test loss: 1.725, Test accuracy: 73.72
Round  79, Train loss: 1.741, Test loss: 1.725, Test accuracy: 73.70
Round  80, Train loss: 1.590, Test loss: 1.724, Test accuracy: 73.72
Round  81, Train loss: 1.678, Test loss: 1.724, Test accuracy: 73.81
Round  82, Train loss: 1.739, Test loss: 1.724, Test accuracy: 73.78
Round  83, Train loss: 1.710, Test loss: 1.724, Test accuracy: 73.85
Round  84, Train loss: 1.775, Test loss: 1.723, Test accuracy: 73.87
Round  85, Train loss: 1.682, Test loss: 1.724, Test accuracy: 73.82
Round  86, Train loss: 1.648, Test loss: 1.724, Test accuracy: 73.84
Round  87, Train loss: 1.647, Test loss: 1.723, Test accuracy: 73.81
Round  88, Train loss: 1.741, Test loss: 1.724, Test accuracy: 73.75
Round  89, Train loss: 1.708, Test loss: 1.724, Test accuracy: 73.81
Round  90, Train loss: 1.735, Test loss: 1.724, Test accuracy: 73.83
Round  91, Train loss: 1.617, Test loss: 1.723, Test accuracy: 73.95
Round  92, Train loss: 1.741, Test loss: 1.723, Test accuracy: 73.90
Round  93, Train loss: 1.680, Test loss: 1.723, Test accuracy: 73.91
Round  94, Train loss: 1.708, Test loss: 1.722, Test accuracy: 73.93
Round  95, Train loss: 1.678, Test loss: 1.722, Test accuracy: 73.85
Round  96, Train loss: 1.738, Test loss: 1.722, Test accuracy: 73.90
Round  97, Train loss: 1.649, Test loss: 1.721, Test accuracy: 74.12
Round  98, Train loss: 1.741, Test loss: 1.721, Test accuracy: 74.04
Round  99, Train loss: 1.642, Test loss: 1.721, Test accuracy: 74.14
Round 100, Train loss: 1.766, Test loss: 1.721, Test accuracy: 74.24
Round 101, Train loss: 1.644, Test loss: 1.721, Test accuracy: 74.12
Round 102, Train loss: 1.579, Test loss: 1.721, Test accuracy: 74.08
Round 103, Train loss: 1.742, Test loss: 1.720, Test accuracy: 74.08
Round 104, Train loss: 1.707, Test loss: 1.721, Test accuracy: 74.11
Round 105, Train loss: 1.737, Test loss: 1.721, Test accuracy: 74.06
Round 106, Train loss: 1.662, Test loss: 1.717, Test accuracy: 74.57
Round 107, Train loss: 1.645, Test loss: 1.712, Test accuracy: 75.10
Round 108, Train loss: 1.680, Test loss: 1.711, Test accuracy: 75.03
Round 109, Train loss: 1.704, Test loss: 1.711, Test accuracy: 75.13
Round 110, Train loss: 1.633, Test loss: 1.709, Test accuracy: 75.38
Round 111, Train loss: 1.681, Test loss: 1.705, Test accuracy: 75.76
Round 112, Train loss: 1.711, Test loss: 1.704, Test accuracy: 75.81
Round 113, Train loss: 1.617, Test loss: 1.704, Test accuracy: 75.82
Round 114, Train loss: 1.705, Test loss: 1.703, Test accuracy: 75.93
Round 115, Train loss: 1.642, Test loss: 1.703, Test accuracy: 75.95
Round 116, Train loss: 1.648, Test loss: 1.702, Test accuracy: 76.02
Round 117, Train loss: 1.678, Test loss: 1.703, Test accuracy: 75.96
Round 118, Train loss: 1.646, Test loss: 1.702, Test accuracy: 75.99
Round 119, Train loss: 1.703, Test loss: 1.703, Test accuracy: 75.88
Round 120, Train loss: 1.644, Test loss: 1.701, Test accuracy: 76.07
Round 121, Train loss: 1.672, Test loss: 1.701, Test accuracy: 76.11
Round 122, Train loss: 1.707, Test loss: 1.701, Test accuracy: 76.09
Round 123, Train loss: 1.676, Test loss: 1.701, Test accuracy: 76.06
Round 124, Train loss: 1.701, Test loss: 1.700, Test accuracy: 76.10
Round 125, Train loss: 1.671, Test loss: 1.700, Test accuracy: 76.14
Round 126, Train loss: 1.704, Test loss: 1.701, Test accuracy: 76.07
Round 127, Train loss: 1.704, Test loss: 1.701, Test accuracy: 76.11
Round 128, Train loss: 1.669, Test loss: 1.701, Test accuracy: 76.12
Round 129, Train loss: 1.669, Test loss: 1.701, Test accuracy: 76.11
Round 130, Train loss: 1.704, Test loss: 1.701, Test accuracy: 76.12
Round 131, Train loss: 1.673, Test loss: 1.701, Test accuracy: 76.12
Round 132, Train loss: 1.611, Test loss: 1.701, Test accuracy: 76.11
Round 133, Train loss: 1.701, Test loss: 1.701, Test accuracy: 76.14
Round 134, Train loss: 1.669, Test loss: 1.700, Test accuracy: 76.14
Round 135, Train loss: 1.734, Test loss: 1.700, Test accuracy: 76.18
Round 136, Train loss: 1.765, Test loss: 1.700, Test accuracy: 76.08
Round 137, Train loss: 1.796, Test loss: 1.701, Test accuracy: 76.04
Round 138, Train loss: 1.605, Test loss: 1.700, Test accuracy: 76.16
Round 139, Train loss: 1.671, Test loss: 1.700, Test accuracy: 76.10
Round 140, Train loss: 1.639, Test loss: 1.700, Test accuracy: 76.15
Round 141, Train loss: 1.734, Test loss: 1.700, Test accuracy: 76.22
Round 142, Train loss: 1.606, Test loss: 1.699, Test accuracy: 76.25
Round 143, Train loss: 1.716, Test loss: 1.690, Test accuracy: 77.15
Round 144, Train loss: 1.703, Test loss: 1.690, Test accuracy: 77.20
Round 145, Train loss: 1.705, Test loss: 1.690, Test accuracy: 77.21
Round 146, Train loss: 1.643, Test loss: 1.690, Test accuracy: 77.17
Round 147, Train loss: 1.637, Test loss: 1.690, Test accuracy: 77.19
Round 148, Train loss: 1.667, Test loss: 1.690, Test accuracy: 77.24
Round 149, Train loss: 1.641, Test loss: 1.690, Test accuracy: 77.28
Round 150, Train loss: 1.674, Test loss: 1.689, Test accuracy: 77.28
Round 151, Train loss: 1.673, Test loss: 1.690, Test accuracy: 77.29
Round 152, Train loss: 1.641, Test loss: 1.689, Test accuracy: 77.29
Round 153, Train loss: 1.705, Test loss: 1.689, Test accuracy: 77.29
Round 154, Train loss: 1.700, Test loss: 1.689, Test accuracy: 77.22
Round 155, Train loss: 1.668, Test loss: 1.690, Test accuracy: 77.13
Round 156, Train loss: 1.634, Test loss: 1.690, Test accuracy: 77.20
Round 157, Train loss: 1.669, Test loss: 1.690, Test accuracy: 77.19
Round 158, Train loss: 1.641, Test loss: 1.690, Test accuracy: 77.24
Round 159, Train loss: 1.576, Test loss: 1.689, Test accuracy: 77.25
Round 160, Train loss: 1.669, Test loss: 1.689, Test accuracy: 77.24
Round 161, Train loss: 1.640, Test loss: 1.690, Test accuracy: 77.27
Round 162, Train loss: 1.575, Test loss: 1.689, Test accuracy: 77.28
Round 163, Train loss: 1.671, Test loss: 1.689, Test accuracy: 77.25
Round 164, Train loss: 1.605, Test loss: 1.689, Test accuracy: 77.31
Round 165, Train loss: 1.704, Test loss: 1.689, Test accuracy: 77.33
Round 166, Train loss: 1.704, Test loss: 1.689, Test accuracy: 77.35
Round 167, Train loss: 1.636, Test loss: 1.689, Test accuracy: 77.33
Round 168, Train loss: 1.671, Test loss: 1.689, Test accuracy: 77.35
Round 169, Train loss: 1.729, Test loss: 1.689, Test accuracy: 77.28
Round 170, Train loss: 1.606, Test loss: 1.689, Test accuracy: 77.25
Round 171, Train loss: 1.687, Test loss: 1.683, Test accuracy: 77.88
Round 172, Train loss: 1.607, Test loss: 1.682, Test accuracy: 77.90
Round 173, Train loss: 1.636, Test loss: 1.682, Test accuracy: 77.98
Round 174, Train loss: 1.635, Test loss: 1.682, Test accuracy: 78.03
Round 175, Train loss: 1.606, Test loss: 1.682, Test accuracy: 78.02
Round 176, Train loss: 1.676, Test loss: 1.681, Test accuracy: 78.05
Round 177, Train loss: 1.639, Test loss: 1.681, Test accuracy: 78.07
Round 178, Train loss: 1.670, Test loss: 1.681, Test accuracy: 78.03
Round 179, Train loss: 1.544, Test loss: 1.681, Test accuracy: 78.01
Round 180, Train loss: 1.666, Test loss: 1.681, Test accuracy: 78.03
Round 181, Train loss: 1.670, Test loss: 1.681, Test accuracy: 77.98
Round 182, Train loss: 1.638, Test loss: 1.681, Test accuracy: 77.96
Round 183, Train loss: 1.602, Test loss: 1.681, Test accuracy: 77.97
Round 184, Train loss: 1.574, Test loss: 1.681, Test accuracy: 77.98
Round 185, Train loss: 1.733, Test loss: 1.681, Test accuracy: 78.04
Round 186, Train loss: 1.638, Test loss: 1.681, Test accuracy: 78.04
Round 187, Train loss: 1.543, Test loss: 1.681, Test accuracy: 78.05
Round 188, Train loss: 1.604, Test loss: 1.681, Test accuracy: 78.08
Round 189, Train loss: 1.639, Test loss: 1.681, Test accuracy: 78.04
Round 190, Train loss: 1.638, Test loss: 1.681, Test accuracy: 78.03
Round 191, Train loss: 1.671, Test loss: 1.681, Test accuracy: 78.04
Round 192, Train loss: 1.671, Test loss: 1.681, Test accuracy: 77.98
Round 193, Train loss: 1.606, Test loss: 1.680, Test accuracy: 78.03
Round 194, Train loss: 1.637, Test loss: 1.680, Test accuracy: 78.05
Round 195, Train loss: 1.668, Test loss: 1.680, Test accuracy: 78.07
Round 196, Train loss: 1.666, Test loss: 1.680, Test accuracy: 78.08
Round 197, Train loss: 1.632, Test loss: 1.680, Test accuracy: 78.11
Round 198, Train loss: 1.605, Test loss: 1.680, Test accuracy: 78.06
Round 199, Train loss: 1.604, Test loss: 1.680, Test accuracy: 78.05
Final Round, Train loss: 1.642, Test loss: 1.671, Test accuracy: 79.01
Average accuracy final 10 rounds: 78.05000000000001 

1835.8398151397705
[0.8496437072753906, 1.6992874145507812, 2.467466115951538, 3.235644817352295, 3.98211407661438, 4.728583335876465, 5.470600128173828, 6.212616920471191, 6.976294994354248, 7.739973068237305, 8.490121126174927, 9.240269184112549, 9.999199628829956, 10.758130073547363, 11.515739917755127, 12.27334976196289, 13.019032001495361, 13.764714241027832, 14.525583744049072, 15.286453247070312, 16.04283094406128, 16.799208641052246, 17.557611227035522, 18.3160138130188, 19.078306198120117, 19.840598583221436, 20.61159086227417, 21.382583141326904, 22.143255710601807, 22.90392827987671, 23.64697551727295, 24.39002275466919, 25.144280433654785, 25.89853811264038, 26.64512276649475, 27.39170742034912, 28.16719126701355, 28.94267511367798, 29.715967416763306, 30.489259719848633, 31.228652715682983, 31.968045711517334, 32.72289752960205, 33.47774934768677, 34.23715281486511, 34.99655628204346, 35.74708700180054, 36.49761772155762, 37.23991346359253, 37.98220920562744, 38.6749153137207, 39.367621421813965, 40.04845571517944, 40.72929000854492, 41.42685151100159, 42.12441301345825, 42.78303503990173, 43.441657066345215, 44.132537841796875, 44.823418617248535, 45.506797552108765, 46.190176486968994, 46.86401081085205, 47.53784513473511, 48.184202432632446, 48.830559730529785, 49.53040075302124, 50.230241775512695, 50.92900800704956, 51.627774238586426, 52.27636694908142, 52.924959659576416, 53.61711812019348, 54.30927658081055, 54.970337867736816, 55.631399154663086, 56.31157040596008, 56.99174165725708, 57.67324495315552, 58.354748249053955, 59.017351388931274, 59.679954528808594, 60.357202768325806, 61.03445100784302, 61.69341206550598, 62.352373123168945, 63.05321717262268, 63.754061222076416, 64.44505167007446, 65.13604211807251, 65.8007459640503, 66.46544981002808, 67.16014456748962, 67.85483932495117, 68.53767251968384, 69.2205057144165, 69.89397501945496, 70.56744432449341, 71.26407146453857, 71.96069860458374, 72.6244056224823, 73.28811264038086, 73.97040724754333, 74.65270185470581, 75.32975888252258, 76.00681591033936, 76.69719243049622, 77.38756895065308, 78.05773901939392, 78.72790908813477, 79.41285753250122, 80.09780597686768, 80.79697942733765, 81.49615287780762, 82.16151189804077, 82.82687091827393, 83.50985026359558, 84.19282960891724, 84.88286352157593, 85.57289743423462, 86.23511362075806, 86.8973298072815, 87.58904671669006, 88.28076362609863, 88.96300458908081, 89.64524555206299, 90.33394312858582, 91.02264070510864, 91.70141291618347, 92.3801851272583, 93.06223201751709, 93.74427890777588, 94.43481874465942, 95.12535858154297, 95.78196620941162, 96.43857383728027, 97.1237542629242, 97.80893468856812, 98.48765873908997, 99.16638278961182, 99.824636220932, 100.4828896522522, 101.18621921539307, 101.88954877853394, 102.57569622993469, 103.26184368133545, 103.9209578037262, 104.58007192611694, 105.26070404052734, 105.94133615493774, 106.61905813217163, 107.29678010940552, 107.97836184501648, 108.65994358062744, 109.34136009216309, 110.02277660369873, 110.70272326469421, 111.3826699256897, 112.05673503875732, 112.73080015182495, 113.41376519203186, 114.09673023223877, 114.79324746131897, 115.48976469039917, 116.1714403629303, 116.85311603546143, 117.51607894897461, 118.1790418624878, 118.8616988658905, 119.54435586929321, 120.20974373817444, 120.87513160705566, 121.62933349609375, 122.38353538513184, 123.13283634185791, 123.88213729858398, 124.62850022315979, 125.3748631477356, 126.10192465782166, 126.82898616790771, 127.57271099090576, 128.3164358139038, 129.07188439369202, 129.82733297348022, 130.59411883354187, 131.36090469360352, 132.1019880771637, 132.84307146072388, 133.60440611839294, 134.365740776062, 135.1142280101776, 135.8627152442932, 136.59081029891968, 137.31890535354614, 138.07704949378967, 138.8351936340332, 139.5841338634491, 140.333074092865, 141.07808470726013, 141.82309532165527, 142.5855586528778, 143.34802198410034, 144.09721851348877, 144.8464150428772, 145.59996247291565, 146.3535099029541, 147.09807968139648, 147.84264945983887, 148.59691524505615, 149.35118103027344, 150.10035347938538, 150.84952592849731, 151.58811569213867, 152.32670545578003, 153.08304524421692, 153.8393850326538, 154.60258722305298, 155.36578941345215, 156.11743187904358, 156.869074344635, 157.60859036445618, 158.34810638427734, 159.09297370910645, 159.83784103393555, 160.59654188156128, 161.355242729187, 162.10908961296082, 162.86293649673462, 163.60817861557007, 164.35342073440552, 165.10833978652954, 165.86325883865356, 166.62331628799438, 167.3833737373352, 168.1360387802124, 168.8887038230896, 169.643949508667, 170.39919519424438, 171.15365505218506, 171.90811491012573, 172.6554834842682, 173.40285205841064, 174.1519856452942, 174.90111923217773, 175.64114952087402, 176.3811798095703, 177.13732886314392, 177.89347791671753, 178.63690567016602, 179.3803334236145, 180.10919833183289, 180.83806324005127, 181.5930953025818, 182.3481273651123, 183.104816198349, 183.8615050315857, 184.59901690483093, 185.33652877807617, 186.08077001571655, 186.82501125335693, 187.57513785362244, 188.32526445388794, 189.0589702129364, 189.79267597198486, 190.5416750907898, 191.29067420959473, 192.03020644187927, 192.76973867416382, 193.52529406547546, 194.2808494567871, 195.02103066444397, 195.76121187210083, 196.48509097099304, 197.20897006988525, 197.9541094303131, 198.69924879074097, 199.44806790351868, 200.1968870162964, 200.94674515724182, 201.69660329818726, 202.4272813796997, 203.15795946121216, 203.90866780281067, 204.65937614440918, 205.42157173156738, 206.1837673187256, 206.93046140670776, 207.67715549468994, 208.39820456504822, 209.1192536354065, 209.88132643699646, 210.64339923858643, 211.37977409362793, 212.11614894866943, 212.86583495140076, 213.61552095413208, 214.3674762248993, 215.1194314956665, 215.85789847373962, 216.59636545181274, 217.34646940231323, 218.09657335281372, 218.8632845878601, 219.6299958229065, 220.36152744293213, 221.09305906295776, 221.85518312454224, 222.6173071861267, 223.37993264198303, 224.14255809783936, 224.8788197040558, 225.61508131027222, 226.3672013282776, 227.11932134628296, 227.85669016838074, 228.59405899047852, 229.34574723243713, 230.09743547439575, 230.8637797832489, 231.63012409210205, 232.37749671936035, 233.12486934661865, 233.85969853401184, 234.59452772140503, 235.3416407108307, 236.08875370025635, 236.83820819854736, 237.58766269683838, 238.34138083457947, 239.09509897232056, 239.8330521583557, 240.57100534439087, 241.32996034622192, 242.08891534805298, 242.85051846504211, 243.61212158203125, 244.3480064868927, 245.08389139175415, 245.83197855949402, 246.5800657272339, 247.3230483531952, 248.0660309791565, 248.80816292762756, 249.55029487609863, 250.3082196712494, 251.06614446640015, 251.82277131080627, 252.5793981552124, 253.30584478378296, 254.03229141235352, 254.8005063533783, 255.56872129440308, 256.33394169807434, 257.0991621017456, 257.84619545936584, 258.5932288169861, 259.33350014686584, 260.0737714767456, 260.8205335140228, 261.56729555130005, 262.31491708755493, 263.0625386238098, 263.81761717796326, 264.5726957321167, 265.31205916404724, 266.0514225959778, 266.80581974983215, 267.5602169036865, 268.3061134815216, 269.0520100593567, 269.8027708530426, 270.5535316467285, 271.3005452156067, 272.04755878448486, 272.8017506599426, 273.5559425354004, 274.3212947845459, 275.0866470336914, 275.85321521759033, 276.61978340148926, 277.3707435131073, 278.12170362472534, 278.8517942428589, 279.58188486099243, 280.33374214172363, 281.08559942245483, 281.83645844459534, 282.58731746673584, 283.35694789886475, 284.12657833099365, 284.8566792011261, 285.58678007125854, 286.34184885025024, 287.09691762924194, 287.8474268913269, 288.59793615341187, 289.3254041671753, 290.0528721809387, 290.80582880973816, 291.5587854385376, 292.94310998916626, 294.3274345397949]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[13.02, 13.02, 13.04, 13.04, 13.99, 13.99, 14.88, 14.88, 18.18, 18.18, 19.45, 19.45, 21.02, 21.02, 25.0, 25.0, 28.07, 28.07, 36.7, 36.7, 41.82, 41.82, 43.93, 43.93, 49.66, 49.66, 54.3, 54.3, 56.63, 56.63, 59.69, 59.69, 59.89, 59.89, 62.7, 62.7, 63.36, 63.36, 64.42, 64.42, 64.66, 64.66, 64.68, 64.68, 64.57, 64.57, 66.08, 66.08, 67.42, 67.42, 67.49, 67.49, 68.0, 68.0, 68.62, 68.62, 69.41, 69.41, 70.69, 70.69, 70.68, 70.68, 70.74, 70.74, 70.59, 70.59, 70.81, 70.81, 70.95, 70.95, 71.32, 71.32, 71.53, 71.53, 71.7, 71.7, 71.42, 71.42, 71.44, 71.44, 72.42, 72.42, 72.32, 72.32, 72.7, 72.7, 72.69, 72.69, 72.81, 72.81, 72.91, 72.91, 73.09, 73.09, 73.14, 73.14, 73.18, 73.18, 73.1, 73.1, 73.25, 73.25, 73.38, 73.38, 73.24, 73.24, 73.36, 73.36, 73.47, 73.47, 73.37, 73.37, 73.38, 73.38, 73.43, 73.43, 73.38, 73.38, 73.36, 73.36, 73.4, 73.4, 73.43, 73.43, 73.39, 73.39, 73.46, 73.46, 73.51, 73.51, 73.72, 73.72, 73.8, 73.8, 73.79, 73.79, 73.77, 73.77, 73.72, 73.72, 73.73, 73.73, 73.72, 73.72, 73.72, 73.72, 73.66, 73.66, 73.76, 73.76, 73.76, 73.76, 73.81, 73.81, 73.67, 73.67, 73.72, 73.72, 73.7, 73.7, 73.72, 73.72, 73.81, 73.81, 73.78, 73.78, 73.85, 73.85, 73.87, 73.87, 73.82, 73.82, 73.84, 73.84, 73.81, 73.81, 73.75, 73.75, 73.81, 73.81, 73.83, 73.83, 73.95, 73.95, 73.9, 73.9, 73.91, 73.91, 73.93, 73.93, 73.85, 73.85, 73.9, 73.9, 74.12, 74.12, 74.04, 74.04, 74.14, 74.14, 74.24, 74.24, 74.12, 74.12, 74.08, 74.08, 74.08, 74.08, 74.11, 74.11, 74.06, 74.06, 74.57, 74.57, 75.1, 75.1, 75.03, 75.03, 75.13, 75.13, 75.38, 75.38, 75.76, 75.76, 75.81, 75.81, 75.82, 75.82, 75.93, 75.93, 75.95, 75.95, 76.02, 76.02, 75.96, 75.96, 75.99, 75.99, 75.88, 75.88, 76.07, 76.07, 76.11, 76.11, 76.09, 76.09, 76.06, 76.06, 76.1, 76.1, 76.14, 76.14, 76.07, 76.07, 76.11, 76.11, 76.12, 76.12, 76.11, 76.11, 76.12, 76.12, 76.12, 76.12, 76.11, 76.11, 76.14, 76.14, 76.14, 76.14, 76.18, 76.18, 76.08, 76.08, 76.04, 76.04, 76.16, 76.16, 76.1, 76.1, 76.15, 76.15, 76.22, 76.22, 76.25, 76.25, 77.15, 77.15, 77.2, 77.2, 77.21, 77.21, 77.17, 77.17, 77.19, 77.19, 77.24, 77.24, 77.28, 77.28, 77.28, 77.28, 77.29, 77.29, 77.29, 77.29, 77.29, 77.29, 77.22, 77.22, 77.13, 77.13, 77.2, 77.2, 77.19, 77.19, 77.24, 77.24, 77.25, 77.25, 77.24, 77.24, 77.27, 77.27, 77.28, 77.28, 77.25, 77.25, 77.31, 77.31, 77.33, 77.33, 77.35, 77.35, 77.33, 77.33, 77.35, 77.35, 77.28, 77.28, 77.25, 77.25, 77.88, 77.88, 77.9, 77.9, 77.98, 77.98, 78.03, 78.03, 78.02, 78.02, 78.05, 78.05, 78.07, 78.07, 78.03, 78.03, 78.01, 78.01, 78.03, 78.03, 77.98, 77.98, 77.96, 77.96, 77.97, 77.97, 77.98, 77.98, 78.04, 78.04, 78.04, 78.04, 78.05, 78.05, 78.08, 78.08, 78.04, 78.04, 78.03, 78.03, 78.04, 78.04, 77.98, 77.98, 78.03, 78.03, 78.05, 78.05, 78.07, 78.07, 78.08, 78.08, 78.11, 78.11, 78.06, 78.06, 78.05, 78.05, 79.01, 79.01]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.294, Test loss: 2.299, Test accuracy: 14.52
Round   1, Train loss: 2.277, Test loss: 2.286, Test accuracy: 15.79
Round   2, Train loss: 2.198, Test loss: 2.261, Test accuracy: 17.59
Round   3, Train loss: 2.103, Test loss: 2.224, Test accuracy: 23.69
Round   4, Train loss: 1.988, Test loss: 2.157, Test accuracy: 30.47
Round   5, Train loss: 1.938, Test loss: 2.090, Test accuracy: 38.51
Round   6, Train loss: 1.832, Test loss: 2.027, Test accuracy: 46.26
Round   7, Train loss: 1.857, Test loss: 1.985, Test accuracy: 49.17
Round   8, Train loss: 1.850, Test loss: 1.953, Test accuracy: 53.07
Round   9, Train loss: 1.758, Test loss: 1.907, Test accuracy: 57.40
Round  10, Train loss: 1.749, Test loss: 1.880, Test accuracy: 59.53
Round  11, Train loss: 1.680, Test loss: 1.876, Test accuracy: 59.58
Round  12, Train loss: 1.790, Test loss: 1.857, Test accuracy: 61.26
Round  13, Train loss: 1.793, Test loss: 1.849, Test accuracy: 62.10
Round  14, Train loss: 1.681, Test loss: 1.825, Test accuracy: 64.16
Round  15, Train loss: 1.642, Test loss: 1.818, Test accuracy: 64.69
Round  16, Train loss: 1.722, Test loss: 1.814, Test accuracy: 65.17
Round  17, Train loss: 1.726, Test loss: 1.803, Test accuracy: 66.24
Round  18, Train loss: 1.786, Test loss: 1.774, Test accuracy: 69.56
Round  19, Train loss: 1.695, Test loss: 1.767, Test accuracy: 70.05
Round  20, Train loss: 1.678, Test loss: 1.755, Test accuracy: 71.22
Round  21, Train loss: 1.655, Test loss: 1.752, Test accuracy: 71.49
Round  22, Train loss: 1.605, Test loss: 1.747, Test accuracy: 72.08
Round  23, Train loss: 1.691, Test loss: 1.741, Test accuracy: 72.67
Round  24, Train loss: 1.738, Test loss: 1.729, Test accuracy: 73.62
Round  25, Train loss: 1.591, Test loss: 1.727, Test accuracy: 73.91
Round  26, Train loss: 1.671, Test loss: 1.722, Test accuracy: 74.21
Round  27, Train loss: 1.624, Test loss: 1.718, Test accuracy: 74.71
Round  28, Train loss: 1.602, Test loss: 1.705, Test accuracy: 75.95
Round  29, Train loss: 1.677, Test loss: 1.702, Test accuracy: 76.34
Round  30, Train loss: 1.666, Test loss: 1.699, Test accuracy: 76.53
Round  31, Train loss: 1.584, Test loss: 1.699, Test accuracy: 76.55
Round  32, Train loss: 1.717, Test loss: 1.696, Test accuracy: 76.65
Round  33, Train loss: 1.646, Test loss: 1.697, Test accuracy: 76.62
Round  34, Train loss: 1.612, Test loss: 1.696, Test accuracy: 76.81
Round  35, Train loss: 1.627, Test loss: 1.692, Test accuracy: 77.07
Round  36, Train loss: 1.617, Test loss: 1.693, Test accuracy: 77.11
Round  37, Train loss: 1.615, Test loss: 1.690, Test accuracy: 77.32
Round  38, Train loss: 1.679, Test loss: 1.689, Test accuracy: 77.42
Round  39, Train loss: 1.649, Test loss: 1.683, Test accuracy: 78.03
Round  40, Train loss: 1.740, Test loss: 1.682, Test accuracy: 78.14
Round  41, Train loss: 1.676, Test loss: 1.682, Test accuracy: 78.20
Round  42, Train loss: 1.583, Test loss: 1.681, Test accuracy: 78.29
Round  43, Train loss: 1.709, Test loss: 1.680, Test accuracy: 78.46
Round  44, Train loss: 1.672, Test loss: 1.679, Test accuracy: 78.36
Round  45, Train loss: 1.672, Test loss: 1.679, Test accuracy: 78.42
Round  46, Train loss: 1.678, Test loss: 1.679, Test accuracy: 78.47
Round  47, Train loss: 1.671, Test loss: 1.678, Test accuracy: 78.37
Round  48, Train loss: 1.608, Test loss: 1.677, Test accuracy: 78.57
Round  49, Train loss: 1.610, Test loss: 1.678, Test accuracy: 78.58
Round  50, Train loss: 1.606, Test loss: 1.678, Test accuracy: 78.54
Round  51, Train loss: 1.578, Test loss: 1.677, Test accuracy: 78.50
Round  52, Train loss: 1.669, Test loss: 1.678, Test accuracy: 78.48
Round  53, Train loss: 1.691, Test loss: 1.671, Test accuracy: 79.19
Round  54, Train loss: 1.576, Test loss: 1.670, Test accuracy: 79.20
Round  55, Train loss: 1.581, Test loss: 1.670, Test accuracy: 79.19
Round  56, Train loss: 1.675, Test loss: 1.670, Test accuracy: 79.30
Round  57, Train loss: 1.607, Test loss: 1.665, Test accuracy: 79.78
Round  58, Train loss: 1.635, Test loss: 1.665, Test accuracy: 79.82
Round  59, Train loss: 1.639, Test loss: 1.664, Test accuracy: 79.98
Round  60, Train loss: 1.672, Test loss: 1.659, Test accuracy: 80.46
Round  61, Train loss: 1.699, Test loss: 1.659, Test accuracy: 80.44
Round  62, Train loss: 1.679, Test loss: 1.657, Test accuracy: 80.68
Round  63, Train loss: 1.634, Test loss: 1.657, Test accuracy: 80.59
Round  64, Train loss: 1.670, Test loss: 1.657, Test accuracy: 80.64
Round  65, Train loss: 1.542, Test loss: 1.655, Test accuracy: 80.75
Round  66, Train loss: 1.602, Test loss: 1.655, Test accuracy: 80.80
Round  67, Train loss: 1.572, Test loss: 1.654, Test accuracy: 80.79
Round  68, Train loss: 1.637, Test loss: 1.654, Test accuracy: 80.88
Round  69, Train loss: 1.578, Test loss: 1.654, Test accuracy: 80.89
Round  70, Train loss: 1.668, Test loss: 1.654, Test accuracy: 80.88
Round  71, Train loss: 1.605, Test loss: 1.654, Test accuracy: 81.00
Round  72, Train loss: 1.699, Test loss: 1.653, Test accuracy: 81.02
Round  73, Train loss: 1.605, Test loss: 1.652, Test accuracy: 81.01
Round  74, Train loss: 1.606, Test loss: 1.653, Test accuracy: 81.00
Round  75, Train loss: 1.606, Test loss: 1.652, Test accuracy: 81.07
Round  76, Train loss: 1.634, Test loss: 1.652, Test accuracy: 81.03
Round  77, Train loss: 1.637, Test loss: 1.652, Test accuracy: 81.05
Round  78, Train loss: 1.571, Test loss: 1.652, Test accuracy: 81.06
Round  79, Train loss: 1.541, Test loss: 1.651, Test accuracy: 81.11
Round  80, Train loss: 1.539, Test loss: 1.651, Test accuracy: 81.11
Round  81, Train loss: 1.669, Test loss: 1.651, Test accuracy: 81.16
Round  82, Train loss: 1.537, Test loss: 1.651, Test accuracy: 81.09
Round  83, Train loss: 1.672, Test loss: 1.651, Test accuracy: 81.16
Round  84, Train loss: 1.604, Test loss: 1.651, Test accuracy: 81.17
Round  85, Train loss: 1.602, Test loss: 1.651, Test accuracy: 81.07
Round  86, Train loss: 1.636, Test loss: 1.651, Test accuracy: 81.18
Round  87, Train loss: 1.636, Test loss: 1.651, Test accuracy: 81.22
Round  88, Train loss: 1.567, Test loss: 1.651, Test accuracy: 81.08
Round  89, Train loss: 1.509, Test loss: 1.650, Test accuracy: 81.16
Round  90, Train loss: 1.538, Test loss: 1.650, Test accuracy: 81.13
Round  91, Train loss: 1.606, Test loss: 1.650, Test accuracy: 81.22
Round  92, Train loss: 1.607, Test loss: 1.650, Test accuracy: 81.24
Round  93, Train loss: 1.636, Test loss: 1.650, Test accuracy: 81.19
Round  94, Train loss: 1.667, Test loss: 1.650, Test accuracy: 81.21
Round  95, Train loss: 1.604, Test loss: 1.650, Test accuracy: 81.25
Round  96, Train loss: 1.633, Test loss: 1.650, Test accuracy: 81.23
Round  97, Train loss: 1.700, Test loss: 1.650, Test accuracy: 81.15
Round  98, Train loss: 1.633, Test loss: 1.650, Test accuracy: 81.26
Round  99, Train loss: 1.536, Test loss: 1.650, Test accuracy: 81.24
Round 100, Train loss: 1.604, Test loss: 1.650, Test accuracy: 81.22
Round 101, Train loss: 1.635, Test loss: 1.650, Test accuracy: 81.25
Round 102, Train loss: 1.600, Test loss: 1.650, Test accuracy: 81.30
Round 103, Train loss: 1.605, Test loss: 1.649, Test accuracy: 81.26
Round 104, Train loss: 1.602, Test loss: 1.649, Test accuracy: 81.22
Round 105, Train loss: 1.602, Test loss: 1.650, Test accuracy: 81.22
Round 106, Train loss: 1.697, Test loss: 1.650, Test accuracy: 81.18
Round 107, Train loss: 1.664, Test loss: 1.649, Test accuracy: 81.28
Round 108, Train loss: 1.632, Test loss: 1.648, Test accuracy: 81.32
Round 109, Train loss: 1.640, Test loss: 1.642, Test accuracy: 82.06
Round 110, Train loss: 1.638, Test loss: 1.642, Test accuracy: 82.05
Round 111, Train loss: 1.601, Test loss: 1.641, Test accuracy: 82.08
Round 112, Train loss: 1.701, Test loss: 1.641, Test accuracy: 82.13
Round 113, Train loss: 1.602, Test loss: 1.640, Test accuracy: 82.14
Round 114, Train loss: 1.598, Test loss: 1.640, Test accuracy: 82.18
Round 115, Train loss: 1.598, Test loss: 1.640, Test accuracy: 82.22
Round 116, Train loss: 1.599, Test loss: 1.640, Test accuracy: 82.25
Round 117, Train loss: 1.636, Test loss: 1.640, Test accuracy: 82.26
Round 118, Train loss: 1.667, Test loss: 1.640, Test accuracy: 82.21
Round 119, Train loss: 1.600, Test loss: 1.640, Test accuracy: 82.29
Round 120, Train loss: 1.631, Test loss: 1.640, Test accuracy: 82.22
Round 121, Train loss: 1.532, Test loss: 1.640, Test accuracy: 82.29
Round 122, Train loss: 1.582, Test loss: 1.632, Test accuracy: 83.11
Round 123, Train loss: 1.601, Test loss: 1.632, Test accuracy: 83.10
Round 124, Train loss: 1.663, Test loss: 1.632, Test accuracy: 83.04
Round 125, Train loss: 1.605, Test loss: 1.632, Test accuracy: 83.07
Round 126, Train loss: 1.508, Test loss: 1.631, Test accuracy: 83.13
Round 127, Train loss: 1.635, Test loss: 1.631, Test accuracy: 83.13
Round 128, Train loss: 1.665, Test loss: 1.631, Test accuracy: 83.18
Round 129, Train loss: 1.538, Test loss: 1.631, Test accuracy: 83.18
Round 130, Train loss: 1.633, Test loss: 1.631, Test accuracy: 83.17
Round 131, Train loss: 1.573, Test loss: 1.630, Test accuracy: 83.16
Round 132, Train loss: 1.537, Test loss: 1.630, Test accuracy: 83.25
Round 133, Train loss: 1.636, Test loss: 1.630, Test accuracy: 83.20
Round 134, Train loss: 1.669, Test loss: 1.630, Test accuracy: 83.11
Round 135, Train loss: 1.604, Test loss: 1.630, Test accuracy: 83.15
Round 136, Train loss: 1.699, Test loss: 1.630, Test accuracy: 83.20
Round 137, Train loss: 1.598, Test loss: 1.630, Test accuracy: 83.23
Round 138, Train loss: 1.667, Test loss: 1.630, Test accuracy: 83.27
Round 139, Train loss: 1.602, Test loss: 1.630, Test accuracy: 83.29
Round 140, Train loss: 1.602, Test loss: 1.629, Test accuracy: 83.30
Round 141, Train loss: 1.632, Test loss: 1.629, Test accuracy: 83.34
Round 142, Train loss: 1.570, Test loss: 1.629, Test accuracy: 83.29
Round 143, Train loss: 1.664, Test loss: 1.629, Test accuracy: 83.31
Round 144, Train loss: 1.568, Test loss: 1.630, Test accuracy: 83.30
Round 145, Train loss: 1.634, Test loss: 1.629, Test accuracy: 83.29
Round 146, Train loss: 1.537, Test loss: 1.629, Test accuracy: 83.29
Round 147, Train loss: 1.567, Test loss: 1.629, Test accuracy: 83.28
Round 148, Train loss: 1.569, Test loss: 1.629, Test accuracy: 83.31
Round 149, Train loss: 1.599, Test loss: 1.629, Test accuracy: 83.27
Round 150, Train loss: 1.566, Test loss: 1.629, Test accuracy: 83.29
Round 151, Train loss: 1.635, Test loss: 1.629, Test accuracy: 83.30
Round 152, Train loss: 1.535, Test loss: 1.629, Test accuracy: 83.29
Round 153, Train loss: 1.664, Test loss: 1.629, Test accuracy: 83.24
Round 154, Train loss: 1.602, Test loss: 1.629, Test accuracy: 83.30
Round 155, Train loss: 1.570, Test loss: 1.629, Test accuracy: 83.27
Round 156, Train loss: 1.602, Test loss: 1.629, Test accuracy: 83.30
Round 157, Train loss: 1.665, Test loss: 1.629, Test accuracy: 83.28
Round 158, Train loss: 1.700, Test loss: 1.628, Test accuracy: 83.33
Round 159, Train loss: 1.568, Test loss: 1.628, Test accuracy: 83.33
Round 160, Train loss: 1.601, Test loss: 1.629, Test accuracy: 83.32
Round 161, Train loss: 1.666, Test loss: 1.628, Test accuracy: 83.40
Round 162, Train loss: 1.566, Test loss: 1.628, Test accuracy: 83.36
Round 163, Train loss: 1.663, Test loss: 1.628, Test accuracy: 83.34
Round 164, Train loss: 1.730, Test loss: 1.629, Test accuracy: 83.32
Round 165, Train loss: 1.569, Test loss: 1.628, Test accuracy: 83.37
Round 166, Train loss: 1.569, Test loss: 1.628, Test accuracy: 83.30
Round 167, Train loss: 1.661, Test loss: 1.629, Test accuracy: 83.26
Round 168, Train loss: 1.665, Test loss: 1.628, Test accuracy: 83.35
Round 169, Train loss: 1.535, Test loss: 1.628, Test accuracy: 83.32
Round 170, Train loss: 1.598, Test loss: 1.629, Test accuracy: 83.34
Round 171, Train loss: 1.663, Test loss: 1.629, Test accuracy: 83.30
Round 172, Train loss: 1.535, Test loss: 1.628, Test accuracy: 83.25
Round 173, Train loss: 1.663, Test loss: 1.628, Test accuracy: 83.34
Round 174, Train loss: 1.533, Test loss: 1.628, Test accuracy: 83.33
Round 175, Train loss: 1.504, Test loss: 1.628, Test accuracy: 83.37
Round 176, Train loss: 1.564, Test loss: 1.628, Test accuracy: 83.45
Round 177, Train loss: 1.567, Test loss: 1.628, Test accuracy: 83.33
Round 178, Train loss: 1.567, Test loss: 1.628, Test accuracy: 83.40
Round 179, Train loss: 1.631, Test loss: 1.628, Test accuracy: 83.28
Round 180, Train loss: 1.600, Test loss: 1.628, Test accuracy: 83.30
Round 181, Train loss: 1.570, Test loss: 1.628, Test accuracy: 83.30
Round 182, Train loss: 1.632, Test loss: 1.628, Test accuracy: 83.40
Round 183, Train loss: 1.570, Test loss: 1.628, Test accuracy: 83.35
Round 184, Train loss: 1.631, Test loss: 1.627, Test accuracy: 83.32
Round 185, Train loss: 1.600, Test loss: 1.627, Test accuracy: 83.32
Round 186, Train loss: 1.696, Test loss: 1.627, Test accuracy: 83.33
Round 187, Train loss: 1.601, Test loss: 1.627, Test accuracy: 83.34
Round 188, Train loss: 1.564, Test loss: 1.627, Test accuracy: 83.40
Round 189, Train loss: 1.692, Test loss: 1.622, Test accuracy: 83.94
Round 190, Train loss: 1.538, Test loss: 1.622, Test accuracy: 84.11
Round 191, Train loss: 1.596, Test loss: 1.622, Test accuracy: 83.92
Round 192, Train loss: 1.533, Test loss: 1.622, Test accuracy: 83.93
Round 193, Train loss: 1.565, Test loss: 1.622, Test accuracy: 83.91
Round 194, Train loss: 1.602, Test loss: 1.619, Test accuracy: 84.22
Round 195, Train loss: 1.598, Test loss: 1.619, Test accuracy: 84.19
Round 196, Train loss: 1.566, Test loss: 1.619, Test accuracy: 84.31
Round 197, Train loss: 1.599, Test loss: 1.619, Test accuracy: 84.22
Round 198, Train loss: 1.630, Test loss: 1.618, Test accuracy: 84.25
Round 199, Train loss: 1.564, Test loss: 1.618, Test accuracy: 84.28
Final Round, Train loss: 1.586, Test loss: 1.618, Test accuracy: 84.20
Average accuracy final 10 rounds: 84.13399999999999 

1827.7732203006744
[0.9342038631439209, 1.8684077262878418, 2.6955955028533936, 3.5227832794189453, 4.242799997329712, 4.9628167152404785, 5.669074535369873, 6.375332355499268, 7.08176326751709, 7.788194179534912, 8.513558626174927, 9.238923072814941, 9.959860563278198, 10.680798053741455, 11.378399133682251, 12.076000213623047, 12.790878534317017, 13.505756855010986, 14.224717617034912, 14.943678379058838, 15.649824380874634, 16.35597038269043, 17.061426639556885, 17.76688289642334, 18.49195647239685, 19.21703004837036, 19.934621334075928, 20.652212619781494, 21.375765562057495, 22.099318504333496, 22.798372745513916, 23.497426986694336, 24.21063232421875, 24.923837661743164, 25.638957500457764, 26.354077339172363, 27.074302434921265, 27.794527530670166, 28.47450089454651, 29.15447425842285, 29.876199960708618, 30.597925662994385, 31.317572355270386, 32.03721904754639, 32.738497734069824, 33.43977642059326, 34.1489999294281, 34.85822343826294, 35.572181701660156, 36.28613996505737, 37.007505893707275, 37.72887182235718, 38.439090967178345, 39.14931011199951, 39.85860896110535, 40.56790781021118, 41.27611470222473, 41.98432159423828, 42.70476937294006, 43.425217151641846, 44.14208507537842, 44.85895299911499, 45.57341742515564, 46.28788185119629, 47.02866005897522, 47.76943826675415, 48.49397873878479, 49.21851921081543, 49.927292823791504, 50.63606643676758, 51.34879469871521, 52.06152296066284, 52.766913652420044, 53.472304344177246, 54.19893527030945, 54.92556619644165, 55.6486918926239, 56.37181758880615, 57.06692123413086, 57.762024879455566, 58.48295521736145, 59.203885555267334, 59.92951059341431, 60.65513563156128, 61.359240770339966, 62.06334590911865, 62.78904438018799, 63.514742851257324, 64.23967742919922, 64.96461200714111, 65.67305517196655, 66.38149833679199, 67.10139226913452, 67.82128620147705, 68.52337598800659, 69.22546577453613, 69.93399453163147, 70.6425232887268, 71.36799383163452, 72.09346437454224, 72.81623363494873, 73.53900289535522, 74.21953296661377, 74.90006303787231, 75.6184561252594, 76.33684921264648, 77.04581332206726, 77.75477743148804, 78.46520233154297, 79.1756272315979, 79.88717341423035, 80.5987195968628, 81.30528163909912, 82.01184368133545, 82.72521138191223, 83.43857908248901, 84.1521406173706, 84.8657021522522, 85.56910276412964, 86.27250337600708, 86.98574566841125, 87.69898796081543, 88.4154622554779, 89.13193655014038, 89.84389448165894, 90.55585241317749, 91.2675564289093, 91.97926044464111, 92.7008593082428, 93.42245817184448, 94.14795708656311, 94.87345600128174, 95.57556629180908, 96.27767658233643, 96.99517869949341, 97.71268081665039, 98.43373703956604, 99.15479326248169, 99.87716293334961, 100.59953260421753, 101.3093512058258, 102.01916980743408, 102.72642993927002, 103.43369007110596, 104.15048265457153, 104.86727523803711, 105.58965492248535, 106.3120346069336, 106.98784708976746, 107.66365957260132, 108.38276934623718, 109.10187911987305, 109.83009696006775, 110.55831480026245, 111.26711893081665, 111.97592306137085, 112.6789608001709, 113.38199853897095, 114.0924768447876, 114.80295515060425, 115.52669835090637, 116.2504415512085, 116.9701840877533, 117.6899266242981, 118.38741064071655, 119.08489465713501, 119.80678653717041, 120.52867841720581, 121.25550603866577, 121.98233366012573, 122.70133972167969, 123.42034578323364, 124.12398290634155, 124.82762002944946, 125.55101013183594, 126.27440023422241, 126.99310159683228, 127.71180295944214, 128.42516231536865, 129.13852167129517, 129.8358347415924, 130.53314781188965, 131.23962426185608, 131.9461007118225, 132.6701145172119, 133.39412832260132, 134.10467910766602, 134.8152298927307, 135.49043035507202, 136.16563081741333, 136.88567757606506, 137.6057243347168, 138.31743335723877, 139.02914237976074, 139.72024178504944, 140.41134119033813, 141.12083530426025, 141.83032941818237, 142.54527115821838, 143.2602128982544, 143.96725487709045, 144.6742968559265, 145.38663029670715, 146.0989637374878, 146.80310583114624, 147.5072479248047, 148.22580480575562, 148.94436168670654, 149.65649461746216, 150.36862754821777, 151.07378578186035, 151.77894401550293, 152.49722337722778, 153.21550273895264, 153.93270301818848, 154.64990329742432, 155.36461281776428, 156.07932233810425, 156.77872371673584, 157.47812509536743, 158.1952509880066, 158.91237688064575, 159.63358736038208, 160.3547978401184, 161.06306529045105, 161.7713327407837, 162.4745376110077, 163.1777424812317, 163.88868474960327, 164.59962701797485, 165.32217860221863, 166.0447301864624, 166.7637460231781, 167.4827618598938, 168.17603754997253, 168.86931324005127, 169.58515310287476, 170.30099296569824, 171.0309853553772, 171.76097774505615, 172.4641752243042, 173.16737270355225, 173.86684441566467, 174.5663161277771, 175.29665064811707, 176.02698516845703, 176.72178053855896, 177.4165759086609, 178.12292051315308, 178.82926511764526, 179.5222523212433, 180.2152395248413, 180.91495418548584, 181.61466884613037, 182.33491015434265, 183.05515146255493, 183.76461577415466, 184.4740800857544, 185.18678903579712, 185.89949798583984, 186.62033700942993, 187.34117603302002, 188.05531096458435, 188.76944589614868, 189.46211218833923, 190.15477848052979, 190.86795115470886, 191.58112382888794, 192.28460574150085, 192.98808765411377, 193.7050142288208, 194.42194080352783, 195.12432503700256, 195.8267092704773, 196.53372836112976, 197.24074745178223, 197.97079181671143, 198.70083618164062, 199.41343331336975, 200.12603044509888, 200.80201935768127, 201.47800827026367, 202.18964529037476, 202.90128231048584, 203.62114667892456, 204.34101104736328, 205.03835701942444, 205.7357029914856, 206.42981123924255, 207.1239194869995, 207.83597373962402, 208.54802799224854, 209.25875759124756, 209.96948719024658, 210.68242144584656, 211.39535570144653, 212.10060954093933, 212.80586338043213, 213.51937103271484, 214.23287868499756, 214.9629466533661, 215.69301462173462, 216.42916989326477, 217.16532516479492, 217.84039068222046, 218.515456199646, 219.20845317840576, 219.90145015716553, 220.6369869709015, 221.37252378463745, 222.09650874137878, 222.82049369812012, 223.54577469825745, 224.27105569839478, 224.9932825565338, 225.71550941467285, 226.42748379707336, 227.13945817947388, 227.86645102500916, 228.59344387054443, 229.2958424091339, 229.9982409477234, 230.74132323265076, 231.48440551757812, 232.20989394187927, 232.93538236618042, 233.65343475341797, 234.37148714065552, 235.10245156288147, 235.83341598510742, 236.57973885536194, 237.32606172561646, 238.05832529067993, 238.7905888557434, 239.52163076400757, 240.25267267227173, 240.95772171020508, 241.66277074813843, 242.4112389087677, 243.15970706939697, 243.9004101753235, 244.64111328125, 245.380357503891, 246.11960172653198, 246.83204746246338, 247.54449319839478, 248.28707647323608, 249.0296597480774, 249.76626825332642, 250.50287675857544, 251.23946499824524, 251.97605323791504, 252.7079300880432, 253.4398069381714, 254.1829640865326, 254.9261212348938, 255.63839197158813, 256.35066270828247, 257.0787169933319, 257.80677127838135, 258.5305235385895, 259.2542757987976, 259.98653864860535, 260.7188014984131, 261.46549224853516, 262.2121829986572, 262.9404788017273, 263.66877460479736, 264.3681764602661, 265.06757831573486, 265.80722284317017, 266.54686737060547, 267.2872540950775, 268.02764081954956, 268.7754487991333, 269.52325677871704, 270.2345190048218, 270.9457812309265, 271.66765117645264, 272.38952112197876, 273.12844038009644, 273.8673596382141, 274.6010408401489, 275.33472204208374, 276.0698003768921, 276.80487871170044, 277.5124852657318, 278.2200918197632, 278.9717230796814, 279.7233543395996, 280.4754972457886, 281.22764015197754, 281.9371666908264, 282.6466932296753, 283.371563911438, 284.0964345932007, 284.80354952812195, 285.5106644630432, 286.2665765285492, 287.0224885940552, 288.369900226593, 289.71731185913086]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[14.52, 14.52, 15.79, 15.79, 17.59, 17.59, 23.69, 23.69, 30.47, 30.47, 38.51, 38.51, 46.26, 46.26, 49.17, 49.17, 53.07, 53.07, 57.4, 57.4, 59.53, 59.53, 59.58, 59.58, 61.26, 61.26, 62.1, 62.1, 64.16, 64.16, 64.69, 64.69, 65.17, 65.17, 66.24, 66.24, 69.56, 69.56, 70.05, 70.05, 71.22, 71.22, 71.49, 71.49, 72.08, 72.08, 72.67, 72.67, 73.62, 73.62, 73.91, 73.91, 74.21, 74.21, 74.71, 74.71, 75.95, 75.95, 76.34, 76.34, 76.53, 76.53, 76.55, 76.55, 76.65, 76.65, 76.62, 76.62, 76.81, 76.81, 77.07, 77.07, 77.11, 77.11, 77.32, 77.32, 77.42, 77.42, 78.03, 78.03, 78.14, 78.14, 78.2, 78.2, 78.29, 78.29, 78.46, 78.46, 78.36, 78.36, 78.42, 78.42, 78.47, 78.47, 78.37, 78.37, 78.57, 78.57, 78.58, 78.58, 78.54, 78.54, 78.5, 78.5, 78.48, 78.48, 79.19, 79.19, 79.2, 79.2, 79.19, 79.19, 79.3, 79.3, 79.78, 79.78, 79.82, 79.82, 79.98, 79.98, 80.46, 80.46, 80.44, 80.44, 80.68, 80.68, 80.59, 80.59, 80.64, 80.64, 80.75, 80.75, 80.8, 80.8, 80.79, 80.79, 80.88, 80.88, 80.89, 80.89, 80.88, 80.88, 81.0, 81.0, 81.02, 81.02, 81.01, 81.01, 81.0, 81.0, 81.07, 81.07, 81.03, 81.03, 81.05, 81.05, 81.06, 81.06, 81.11, 81.11, 81.11, 81.11, 81.16, 81.16, 81.09, 81.09, 81.16, 81.16, 81.17, 81.17, 81.07, 81.07, 81.18, 81.18, 81.22, 81.22, 81.08, 81.08, 81.16, 81.16, 81.13, 81.13, 81.22, 81.22, 81.24, 81.24, 81.19, 81.19, 81.21, 81.21, 81.25, 81.25, 81.23, 81.23, 81.15, 81.15, 81.26, 81.26, 81.24, 81.24, 81.22, 81.22, 81.25, 81.25, 81.3, 81.3, 81.26, 81.26, 81.22, 81.22, 81.22, 81.22, 81.18, 81.18, 81.28, 81.28, 81.32, 81.32, 82.06, 82.06, 82.05, 82.05, 82.08, 82.08, 82.13, 82.13, 82.14, 82.14, 82.18, 82.18, 82.22, 82.22, 82.25, 82.25, 82.26, 82.26, 82.21, 82.21, 82.29, 82.29, 82.22, 82.22, 82.29, 82.29, 83.11, 83.11, 83.1, 83.1, 83.04, 83.04, 83.07, 83.07, 83.13, 83.13, 83.13, 83.13, 83.18, 83.18, 83.18, 83.18, 83.17, 83.17, 83.16, 83.16, 83.25, 83.25, 83.2, 83.2, 83.11, 83.11, 83.15, 83.15, 83.2, 83.2, 83.23, 83.23, 83.27, 83.27, 83.29, 83.29, 83.3, 83.3, 83.34, 83.34, 83.29, 83.29, 83.31, 83.31, 83.3, 83.3, 83.29, 83.29, 83.29, 83.29, 83.28, 83.28, 83.31, 83.31, 83.27, 83.27, 83.29, 83.29, 83.3, 83.3, 83.29, 83.29, 83.24, 83.24, 83.3, 83.3, 83.27, 83.27, 83.3, 83.3, 83.28, 83.28, 83.33, 83.33, 83.33, 83.33, 83.32, 83.32, 83.4, 83.4, 83.36, 83.36, 83.34, 83.34, 83.32, 83.32, 83.37, 83.37, 83.3, 83.3, 83.26, 83.26, 83.35, 83.35, 83.32, 83.32, 83.34, 83.34, 83.3, 83.3, 83.25, 83.25, 83.34, 83.34, 83.33, 83.33, 83.37, 83.37, 83.45, 83.45, 83.33, 83.33, 83.4, 83.4, 83.28, 83.28, 83.3, 83.3, 83.3, 83.3, 83.4, 83.4, 83.35, 83.35, 83.32, 83.32, 83.32, 83.32, 83.33, 83.33, 83.34, 83.34, 83.4, 83.4, 83.94, 83.94, 84.11, 84.11, 83.92, 83.92, 83.93, 83.93, 83.91, 83.91, 84.22, 84.22, 84.19, 84.19, 84.31, 84.31, 84.22, 84.22, 84.25, 84.25, 84.28, 84.28, 84.2, 84.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.286, Test loss: 2.295, Test accuracy: 11.58
Round   1, Train loss: 2.227, Test loss: 2.266, Test accuracy: 14.98
Round   2, Train loss: 2.113, Test loss: 2.197, Test accuracy: 30.35
Round   3, Train loss: 1.845, Test loss: 2.114, Test accuracy: 39.58
Round   4, Train loss: 1.899, Test loss: 2.002, Test accuracy: 49.72
Round   5, Train loss: 1.728, Test loss: 1.881, Test accuracy: 62.55
Round   6, Train loss: 1.614, Test loss: 1.821, Test accuracy: 68.67
Round   7, Train loss: 1.631, Test loss: 1.771, Test accuracy: 70.96
Round   8, Train loss: 1.659, Test loss: 1.742, Test accuracy: 74.74
Round   9, Train loss: 1.563, Test loss: 1.740, Test accuracy: 73.96
Round  10, Train loss: 1.703, Test loss: 1.721, Test accuracy: 76.15
Round  11, Train loss: 1.543, Test loss: 1.700, Test accuracy: 77.95
Round  12, Train loss: 1.597, Test loss: 1.683, Test accuracy: 79.15
Round  13, Train loss: 1.619, Test loss: 1.672, Test accuracy: 79.88
Round  14, Train loss: 1.627, Test loss: 1.663, Test accuracy: 80.87
Round  15, Train loss: 1.575, Test loss: 1.658, Test accuracy: 81.13
Round  16, Train loss: 1.480, Test loss: 1.654, Test accuracy: 81.27
Round  17, Train loss: 1.541, Test loss: 1.652, Test accuracy: 81.43
Round  18, Train loss: 1.543, Test loss: 1.622, Test accuracy: 84.97
Round  19, Train loss: 1.484, Test loss: 1.620, Test accuracy: 84.85
Round  20, Train loss: 1.479, Test loss: 1.612, Test accuracy: 85.74
Round  21, Train loss: 1.536, Test loss: 1.611, Test accuracy: 85.80
Round  22, Train loss: 1.537, Test loss: 1.609, Test accuracy: 85.88
Round  23, Train loss: 1.554, Test loss: 1.602, Test accuracy: 86.64
Round  24, Train loss: 1.539, Test loss: 1.600, Test accuracy: 86.89
Round  25, Train loss: 1.496, Test loss: 1.598, Test accuracy: 87.11
Round  26, Train loss: 1.540, Test loss: 1.596, Test accuracy: 87.14
Round  27, Train loss: 1.566, Test loss: 1.596, Test accuracy: 87.18
Round  28, Train loss: 1.570, Test loss: 1.594, Test accuracy: 87.23
Round  29, Train loss: 1.537, Test loss: 1.590, Test accuracy: 87.70
Round  30, Train loss: 1.536, Test loss: 1.590, Test accuracy: 87.78
Round  31, Train loss: 1.537, Test loss: 1.588, Test accuracy: 87.86
Round  32, Train loss: 1.570, Test loss: 1.588, Test accuracy: 87.87
Round  33, Train loss: 1.535, Test loss: 1.587, Test accuracy: 88.04
Round  34, Train loss: 1.504, Test loss: 1.587, Test accuracy: 88.00
Round  35, Train loss: 1.536, Test loss: 1.587, Test accuracy: 88.01
Round  36, Train loss: 1.541, Test loss: 1.583, Test accuracy: 88.34
Round  37, Train loss: 1.473, Test loss: 1.579, Test accuracy: 88.84
Round  38, Train loss: 1.566, Test loss: 1.579, Test accuracy: 88.78
Round  39, Train loss: 1.469, Test loss: 1.579, Test accuracy: 88.76
Round  40, Train loss: 1.500, Test loss: 1.580, Test accuracy: 88.72
Round  41, Train loss: 1.531, Test loss: 1.580, Test accuracy: 88.70
Round  42, Train loss: 1.566, Test loss: 1.579, Test accuracy: 88.57
Round  43, Train loss: 1.534, Test loss: 1.577, Test accuracy: 88.81
Round  44, Train loss: 1.469, Test loss: 1.577, Test accuracy: 88.82
Round  45, Train loss: 1.587, Test loss: 1.572, Test accuracy: 89.40
Round  46, Train loss: 1.533, Test loss: 1.572, Test accuracy: 89.38
Round  47, Train loss: 1.503, Test loss: 1.568, Test accuracy: 89.80
Round  48, Train loss: 1.502, Test loss: 1.568, Test accuracy: 89.83
Round  49, Train loss: 1.470, Test loss: 1.560, Test accuracy: 90.55
Round  50, Train loss: 1.467, Test loss: 1.560, Test accuracy: 90.61
Round  51, Train loss: 1.471, Test loss: 1.559, Test accuracy: 90.59
Round  52, Train loss: 1.500, Test loss: 1.559, Test accuracy: 90.63
Round  53, Train loss: 1.533, Test loss: 1.559, Test accuracy: 90.69
Round  54, Train loss: 1.499, Test loss: 1.558, Test accuracy: 90.73
Round  55, Train loss: 1.470, Test loss: 1.558, Test accuracy: 90.74
Round  56, Train loss: 1.498, Test loss: 1.556, Test accuracy: 90.94
Round  57, Train loss: 1.465, Test loss: 1.556, Test accuracy: 90.95
Round  58, Train loss: 1.469, Test loss: 1.556, Test accuracy: 90.91
Round  59, Train loss: 1.532, Test loss: 1.556, Test accuracy: 90.91
Round  60, Train loss: 1.466, Test loss: 1.556, Test accuracy: 90.96
Round  61, Train loss: 1.466, Test loss: 1.556, Test accuracy: 90.97
Round  62, Train loss: 1.466, Test loss: 1.556, Test accuracy: 90.99
Round  63, Train loss: 1.530, Test loss: 1.556, Test accuracy: 90.96
Round  64, Train loss: 1.532, Test loss: 1.556, Test accuracy: 91.02
Round  65, Train loss: 1.467, Test loss: 1.556, Test accuracy: 91.00
Round  66, Train loss: 1.503, Test loss: 1.552, Test accuracy: 91.46
Round  67, Train loss: 1.469, Test loss: 1.552, Test accuracy: 91.44
Round  68, Train loss: 1.499, Test loss: 1.551, Test accuracy: 91.60
Round  69, Train loss: 1.467, Test loss: 1.550, Test accuracy: 91.59
Round  70, Train loss: 1.505, Test loss: 1.546, Test accuracy: 92.06
Round  71, Train loss: 1.470, Test loss: 1.546, Test accuracy: 92.08
Round  72, Train loss: 1.466, Test loss: 1.546, Test accuracy: 92.02
Round  73, Train loss: 1.470, Test loss: 1.546, Test accuracy: 92.07
Round  74, Train loss: 1.498, Test loss: 1.546, Test accuracy: 92.05
Round  75, Train loss: 1.468, Test loss: 1.546, Test accuracy: 92.04
Round  76, Train loss: 1.472, Test loss: 1.545, Test accuracy: 92.07
Round  77, Train loss: 1.499, Test loss: 1.545, Test accuracy: 92.10
Round  78, Train loss: 1.465, Test loss: 1.545, Test accuracy: 92.11
Round  79, Train loss: 1.499, Test loss: 1.545, Test accuracy: 92.15
Round  80, Train loss: 1.466, Test loss: 1.544, Test accuracy: 92.13
Round  81, Train loss: 1.470, Test loss: 1.543, Test accuracy: 92.23
Round  82, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.26
Round  83, Train loss: 1.465, Test loss: 1.543, Test accuracy: 92.27
Round  84, Train loss: 1.497, Test loss: 1.543, Test accuracy: 92.29
Round  85, Train loss: 1.466, Test loss: 1.543, Test accuracy: 92.31
Round  86, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.33
Round  87, Train loss: 1.497, Test loss: 1.543, Test accuracy: 92.34
Round  88, Train loss: 1.464, Test loss: 1.543, Test accuracy: 92.29
Round  89, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.35
Round  90, Train loss: 1.470, Test loss: 1.543, Test accuracy: 92.36
Round  91, Train loss: 1.497, Test loss: 1.543, Test accuracy: 92.34
Round  92, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.34
Round  93, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.31
Round  94, Train loss: 1.498, Test loss: 1.543, Test accuracy: 92.32
Round  95, Train loss: 1.500, Test loss: 1.542, Test accuracy: 92.38
Round  96, Train loss: 1.501, Test loss: 1.542, Test accuracy: 92.39
Round  97, Train loss: 1.464, Test loss: 1.542, Test accuracy: 92.39
Round  98, Train loss: 1.469, Test loss: 1.542, Test accuracy: 92.41
Round  99, Train loss: 1.483, Test loss: 1.538, Test accuracy: 92.85/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.467, Test loss: 1.533, Test accuracy: 93.42
Average accuracy final 10 rounds: 92.409 

946.5599961280823
[0.8990590572357178, 1.7981181144714355, 2.634382486343384, 3.470646858215332, 4.29284930229187, 5.115051746368408, 5.940251350402832, 6.765450954437256, 7.566469669342041, 8.367488384246826, 9.203743696212769, 10.039999008178711, 10.857059001922607, 11.674118995666504, 12.521153688430786, 13.368188381195068, 14.193723440170288, 15.019258499145508, 15.840052127838135, 16.66084575653076, 17.493534088134766, 18.32622241973877, 19.047937870025635, 19.7696533203125, 20.500033378601074, 21.23041343688965, 21.927001953125, 22.62359046936035, 23.370994567871094, 24.118398666381836, 24.846916437149048, 25.57543420791626, 26.285063982009888, 26.994693756103516, 27.721794605255127, 28.44889545440674, 29.139397859573364, 29.82990026473999, 30.56124234199524, 31.29258441925049, 32.00792932510376, 32.72327423095703, 33.4657564163208, 34.20823860168457, 35.01918053627014, 35.83012247085571, 36.628572940826416, 37.42702341079712, 38.244104623794556, 39.06118583679199, 39.858720541000366, 40.65625524520874, 41.47657036781311, 42.29688549041748, 43.10318398475647, 43.90948247909546, 44.746230363845825, 45.58297824859619, 46.38558340072632, 47.188188552856445, 48.01252365112305, 48.83685874938965, 49.64994955062866, 50.463040351867676, 51.294116497039795, 52.125192642211914, 52.957236528396606, 53.7892804145813, 54.61700916290283, 55.444737911224365, 56.266093492507935, 57.087449073791504, 57.9074227809906, 58.7273964881897, 59.539546728134155, 60.35169696807861, 61.14613175392151, 61.940566539764404, 62.7570538520813, 63.57354116439819, 64.3585114479065, 65.1434817314148, 65.970290184021, 66.7970986366272, 67.59933471679688, 68.40157079696655, 69.22134399414062, 70.0411171913147, 70.86849117279053, 71.69586515426636, 72.52427625656128, 73.3526873588562, 74.17801475524902, 75.00334215164185, 75.81933331489563, 76.63532447814941, 77.45590806007385, 78.27649164199829, 79.08296513557434, 79.88943862915039, 80.71069025993347, 81.53194189071655, 82.33871245384216, 83.14548301696777, 83.97791147232056, 84.81033992767334, 85.6266815662384, 86.44302320480347, 87.26775240898132, 88.09248161315918, 88.91790747642517, 89.74333333969116, 90.57253122329712, 91.40172910690308, 92.1057231426239, 92.80971717834473, 93.52824902534485, 94.24678087234497, 94.95376634597778, 95.6607518196106, 96.38978266716003, 97.11881351470947, 97.83644127845764, 98.55406904220581, 99.27294421195984, 99.99181938171387, 100.70464158058167, 101.41746377944946, 102.13226795196533, 102.8470721244812, 103.532879114151, 104.2186861038208, 104.92431139945984, 105.62993669509888, 106.33843111991882, 107.04692554473877, 107.76628375053406, 108.48564195632935, 109.21183133125305, 109.93802070617676, 110.66216015815735, 111.38629961013794, 112.08330583572388, 112.78031206130981, 113.48334813117981, 114.1863842010498, 114.89544486999512, 115.60450553894043, 116.32982158660889, 117.05513763427734, 117.76657724380493, 118.47801685333252, 119.18999075889587, 119.90196466445923, 120.60682821273804, 121.31169176101685, 122.03146171569824, 122.75123167037964, 123.46024942398071, 124.16926717758179, 124.865891456604, 125.56251573562622, 126.29324102401733, 127.02396631240845, 127.70492720603943, 128.3858880996704, 129.10262966156006, 129.8193712234497, 130.5046136379242, 131.18985605239868, 131.9049689769745, 132.6200819015503, 133.34743547439575, 134.0747890472412, 134.80945563316345, 135.5441222190857, 136.28377747535706, 137.02343273162842, 137.72083806991577, 138.41824340820312, 139.11765098571777, 139.81705856323242, 140.5307013988495, 141.24434423446655, 141.96326684951782, 142.6821894645691, 143.3924674987793, 144.1027455329895, 144.82930874824524, 145.55587196350098, 146.28289103507996, 147.00991010665894, 147.65983772277832, 148.3097653388977, 149.03107118606567, 149.75237703323364, 150.4503390789032, 151.14830112457275, 151.85810351371765, 152.56790590286255, 153.91251635551453, 155.2571268081665]
[11.58, 11.58, 14.98, 14.98, 30.35, 30.35, 39.58, 39.58, 49.72, 49.72, 62.55, 62.55, 68.67, 68.67, 70.96, 70.96, 74.74, 74.74, 73.96, 73.96, 76.15, 76.15, 77.95, 77.95, 79.15, 79.15, 79.88, 79.88, 80.87, 80.87, 81.13, 81.13, 81.27, 81.27, 81.43, 81.43, 84.97, 84.97, 84.85, 84.85, 85.74, 85.74, 85.8, 85.8, 85.88, 85.88, 86.64, 86.64, 86.89, 86.89, 87.11, 87.11, 87.14, 87.14, 87.18, 87.18, 87.23, 87.23, 87.7, 87.7, 87.78, 87.78, 87.86, 87.86, 87.87, 87.87, 88.04, 88.04, 88.0, 88.0, 88.01, 88.01, 88.34, 88.34, 88.84, 88.84, 88.78, 88.78, 88.76, 88.76, 88.72, 88.72, 88.7, 88.7, 88.57, 88.57, 88.81, 88.81, 88.82, 88.82, 89.4, 89.4, 89.38, 89.38, 89.8, 89.8, 89.83, 89.83, 90.55, 90.55, 90.61, 90.61, 90.59, 90.59, 90.63, 90.63, 90.69, 90.69, 90.73, 90.73, 90.74, 90.74, 90.94, 90.94, 90.95, 90.95, 90.91, 90.91, 90.91, 90.91, 90.96, 90.96, 90.97, 90.97, 90.99, 90.99, 90.96, 90.96, 91.02, 91.02, 91.0, 91.0, 91.46, 91.46, 91.44, 91.44, 91.6, 91.6, 91.59, 91.59, 92.06, 92.06, 92.08, 92.08, 92.02, 92.02, 92.07, 92.07, 92.05, 92.05, 92.04, 92.04, 92.07, 92.07, 92.1, 92.1, 92.11, 92.11, 92.15, 92.15, 92.13, 92.13, 92.23, 92.23, 92.26, 92.26, 92.27, 92.27, 92.29, 92.29, 92.31, 92.31, 92.33, 92.33, 92.34, 92.34, 92.29, 92.29, 92.35, 92.35, 92.36, 92.36, 92.34, 92.34, 92.34, 92.34, 92.31, 92.31, 92.32, 92.32, 92.38, 92.38, 92.39, 92.39, 92.39, 92.39, 92.41, 92.41, 92.85, 92.85, 93.42, 93.42]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.599, Test loss: 2.272, Test accuracy: 30.03
Round   1, Train loss: 1.397, Test loss: 2.186, Test accuracy: 42.45
Round   2, Train loss: 1.436, Test loss: 2.109, Test accuracy: 52.14
Round   3, Train loss: 1.309, Test loss: 2.056, Test accuracy: 54.69
Round   4, Train loss: 1.360, Test loss: 1.983, Test accuracy: 61.91
Round   5, Train loss: 1.361, Test loss: 1.936, Test accuracy: 65.31
Round   6, Train loss: 1.279, Test loss: 1.893, Test accuracy: 68.72
Round   7, Train loss: 1.229, Test loss: 1.878, Test accuracy: 69.12
Round   8, Train loss: 1.332, Test loss: 1.870, Test accuracy: 68.56
Round   9, Train loss: 1.288, Test loss: 1.858, Test accuracy: 68.21
Round  10, Train loss: 1.290, Test loss: 1.844, Test accuracy: 69.10
Round  11, Train loss: 1.249, Test loss: 1.834, Test accuracy: 69.20
Round  12, Train loss: 1.378, Test loss: 1.828, Test accuracy: 69.46
Round  13, Train loss: 1.239, Test loss: 1.821, Test accuracy: 69.23
Round  14, Train loss: 1.235, Test loss: 1.813, Test accuracy: 68.72
Round  15, Train loss: 1.273, Test loss: 1.813, Test accuracy: 68.62
Round  16, Train loss: 1.330, Test loss: 1.809, Test accuracy: 69.03
Round  17, Train loss: 1.277, Test loss: 1.805, Test accuracy: 68.74
Round  18, Train loss: 1.259, Test loss: 1.805, Test accuracy: 69.06
Round  19, Train loss: 1.256, Test loss: 1.799, Test accuracy: 69.35
Round  20, Train loss: 1.307, Test loss: 1.800, Test accuracy: 68.88
Round  21, Train loss: 1.350, Test loss: 1.804, Test accuracy: 68.10
Round  22, Train loss: 1.302, Test loss: 1.798, Test accuracy: 68.76
Round  23, Train loss: 1.277, Test loss: 1.796, Test accuracy: 68.68
Round  24, Train loss: 1.304, Test loss: 1.796, Test accuracy: 68.59
Round  25, Train loss: 1.255, Test loss: 1.800, Test accuracy: 68.10
Round  26, Train loss: 1.278, Test loss: 1.798, Test accuracy: 68.30
Round  27, Train loss: 1.277, Test loss: 1.799, Test accuracy: 68.16
Round  28, Train loss: 1.276, Test loss: 1.803, Test accuracy: 67.53
Round  29, Train loss: 1.251, Test loss: 1.806, Test accuracy: 67.27
Round  30, Train loss: 1.276, Test loss: 1.805, Test accuracy: 67.26
Round  31, Train loss: 1.228, Test loss: 1.804, Test accuracy: 67.20
Round  32, Train loss: 1.323, Test loss: 1.804, Test accuracy: 67.22
Round  33, Train loss: 1.304, Test loss: 1.801, Test accuracy: 67.57
Round  34, Train loss: 1.277, Test loss: 1.799, Test accuracy: 67.57
Round  35, Train loss: 1.202, Test loss: 1.802, Test accuracy: 67.10
Round  36, Train loss: 1.277, Test loss: 1.802, Test accuracy: 67.02
Round  37, Train loss: 1.278, Test loss: 1.805, Test accuracy: 66.61
Round  38, Train loss: 1.328, Test loss: 1.808, Test accuracy: 66.38
Round  39, Train loss: 1.253, Test loss: 1.804, Test accuracy: 66.74
Round  40, Train loss: 1.230, Test loss: 1.803, Test accuracy: 66.82
Round  41, Train loss: 1.277, Test loss: 1.805, Test accuracy: 66.53
Round  42, Train loss: 1.249, Test loss: 1.806, Test accuracy: 66.52
Round  43, Train loss: 1.251, Test loss: 1.807, Test accuracy: 66.62
Round  44, Train loss: 1.254, Test loss: 1.806, Test accuracy: 66.64
Round  45, Train loss: 1.251, Test loss: 1.807, Test accuracy: 66.67
Round  46, Train loss: 1.301, Test loss: 1.808, Test accuracy: 66.37
Round  47, Train loss: 1.324, Test loss: 1.807, Test accuracy: 66.39
Round  48, Train loss: 1.230, Test loss: 1.806, Test accuracy: 66.41
Round  49, Train loss: 1.204, Test loss: 1.807, Test accuracy: 66.28
Round  50, Train loss: 1.303, Test loss: 1.807, Test accuracy: 66.27
Round  51, Train loss: 1.251, Test loss: 1.808, Test accuracy: 66.09
Round  52, Train loss: 1.275, Test loss: 1.808, Test accuracy: 66.34
Round  53, Train loss: 1.203, Test loss: 1.809, Test accuracy: 66.12
Round  54, Train loss: 1.204, Test loss: 1.808, Test accuracy: 66.25
Round  55, Train loss: 1.275, Test loss: 1.809, Test accuracy: 66.20
Round  56, Train loss: 1.253, Test loss: 1.810, Test accuracy: 66.04
Round  57, Train loss: 1.227, Test loss: 1.808, Test accuracy: 66.29
Round  58, Train loss: 1.249, Test loss: 1.810, Test accuracy: 66.09
Round  59, Train loss: 1.227, Test loss: 1.813, Test accuracy: 65.74
Round  60, Train loss: 1.297, Test loss: 1.814, Test accuracy: 65.72
Round  61, Train loss: 1.250, Test loss: 1.811, Test accuracy: 66.01
Round  62, Train loss: 1.278, Test loss: 1.819, Test accuracy: 64.84
Round  63, Train loss: 1.227, Test loss: 1.821, Test accuracy: 64.57
Round  64, Train loss: 1.275, Test loss: 1.819, Test accuracy: 64.88
Round  65, Train loss: 1.348, Test loss: 1.823, Test accuracy: 64.57
Round  66, Train loss: 1.275, Test loss: 1.822, Test accuracy: 64.47
Round  67, Train loss: 1.202, Test loss: 1.821, Test accuracy: 64.42
Round  68, Train loss: 1.290, Test loss: 1.817, Test accuracy: 64.74
Round  69, Train loss: 1.226, Test loss: 1.819, Test accuracy: 64.63
Round  70, Train loss: 1.274, Test loss: 1.824, Test accuracy: 64.41
Round  71, Train loss: 1.305, Test loss: 1.832, Test accuracy: 63.56
Round  72, Train loss: 1.277, Test loss: 1.826, Test accuracy: 64.03
Round  73, Train loss: 1.252, Test loss: 1.829, Test accuracy: 63.60
Round  74, Train loss: 1.278, Test loss: 1.829, Test accuracy: 63.43
Round  75, Train loss: 1.274, Test loss: 1.829, Test accuracy: 63.65
Round  76, Train loss: 1.250, Test loss: 1.833, Test accuracy: 63.13
Round  77, Train loss: 1.275, Test loss: 1.833, Test accuracy: 63.04
Round  78, Train loss: 1.275, Test loss: 1.838, Test accuracy: 62.54
Round  79, Train loss: 1.324, Test loss: 1.831, Test accuracy: 63.12
Round  80, Train loss: 1.349, Test loss: 1.829, Test accuracy: 63.28
Round  81, Train loss: 1.227, Test loss: 1.834, Test accuracy: 62.79
Round  82, Train loss: 1.371, Test loss: 1.836, Test accuracy: 62.53
Round  83, Train loss: 1.276, Test loss: 1.836, Test accuracy: 62.42
Round  84, Train loss: 1.276, Test loss: 1.835, Test accuracy: 62.61
Round  85, Train loss: 1.251, Test loss: 1.836, Test accuracy: 62.43
Round  86, Train loss: 1.250, Test loss: 1.834, Test accuracy: 62.62
Round  87, Train loss: 1.248, Test loss: 1.836, Test accuracy: 62.43
Round  88, Train loss: 1.227, Test loss: 1.838, Test accuracy: 62.14
Round  89, Train loss: 1.250, Test loss: 1.838, Test accuracy: 62.15
Round  90, Train loss: 1.228, Test loss: 1.840, Test accuracy: 62.00
Round  91, Train loss: 1.224, Test loss: 1.840, Test accuracy: 61.96
Round  92, Train loss: 1.276, Test loss: 1.846, Test accuracy: 61.24
Round  93, Train loss: 1.254, Test loss: 1.849, Test accuracy: 61.02
Round  94, Train loss: 1.223, Test loss: 1.850, Test accuracy: 60.80
Round  95, Train loss: 1.225, Test loss: 1.850, Test accuracy: 60.78
Round  96, Train loss: 1.298, Test loss: 1.850, Test accuracy: 60.92
Round  97, Train loss: 1.248, Test loss: 1.846, Test accuracy: 61.41
Round  98, Train loss: 1.253, Test loss: 1.850, Test accuracy: 60.80
Round  99, Train loss: 1.274, Test loss: 1.850, Test accuracy: 61.00
Final Round, Train loss: 1.257, Test loss: 1.856, Test accuracy: 60.26
Average accuracy final 10 rounds: 61.193000000000005
1206.9150793552399
[]
[30.03, 42.45, 52.14, 54.69, 61.91, 65.31, 68.72, 69.12, 68.56, 68.21, 69.1, 69.2, 69.46, 69.23, 68.72, 68.62, 69.03, 68.74, 69.06, 69.35, 68.88, 68.1, 68.76, 68.68, 68.59, 68.1, 68.3, 68.16, 67.53, 67.27, 67.26, 67.2, 67.22, 67.57, 67.57, 67.1, 67.02, 66.61, 66.38, 66.74, 66.82, 66.53, 66.52, 66.62, 66.64, 66.67, 66.37, 66.39, 66.41, 66.28, 66.27, 66.09, 66.34, 66.12, 66.25, 66.2, 66.04, 66.29, 66.09, 65.74, 65.72, 66.01, 64.84, 64.57, 64.88, 64.57, 64.47, 64.42, 64.74, 64.63, 64.41, 63.56, 64.03, 63.6, 63.43, 63.65, 63.13, 63.04, 62.54, 63.12, 63.28, 62.79, 62.53, 62.42, 62.61, 62.43, 62.62, 62.43, 62.14, 62.15, 62.0, 61.96, 61.24, 61.02, 60.8, 60.78, 60.92, 61.41, 60.8, 61.0, 60.26]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.292, Test loss: 2.293, Test accuracy: 12.42
Round   1, Train loss: 2.282, Test loss: 2.289, Test accuracy: 15.09
Round   2, Train loss: 2.260, Test loss: 2.270, Test accuracy: 15.80
Round   3, Train loss: 2.239, Test loss: 2.272, Test accuracy: 15.06
Round   4, Train loss: 2.222, Test loss: 2.254, Test accuracy: 16.48
Round   5, Train loss: 2.106, Test loss: 2.216, Test accuracy: 23.87
Round   6, Train loss: 2.132, Test loss: 2.225, Test accuracy: 24.45
Round   7, Train loss: 2.172, Test loss: 2.224, Test accuracy: 21.89
Round   8, Train loss: 1.861, Test loss: 2.165, Test accuracy: 32.32
Round   9, Train loss: 1.874, Test loss: 2.150, Test accuracy: 34.38
Round  10, Train loss: 1.971, Test loss: 2.178, Test accuracy: 28.11
Round  11, Train loss: 1.994, Test loss: 2.211, Test accuracy: 25.54
Round  12, Train loss: 1.404, Test loss: 2.091, Test accuracy: 37.48
Round  13, Train loss: 1.986, Test loss: 2.190, Test accuracy: 28.74
Round  14, Train loss: 1.339, Test loss: 2.084, Test accuracy: 40.21
Round  15, Train loss: 0.991, Test loss: 2.050, Test accuracy: 42.65
Round  16, Train loss: 1.648, Test loss: 1.992, Test accuracy: 50.16
Round  17, Train loss: 1.547, Test loss: 2.107, Test accuracy: 38.76
Round  18, Train loss: 1.014, Test loss: 2.021, Test accuracy: 46.18
Round  19, Train loss: 0.578, Test loss: 1.950, Test accuracy: 52.13
Round  20, Train loss: 0.703, Test loss: 1.970, Test accuracy: 51.03
Round  21, Train loss: 0.704, Test loss: 2.029, Test accuracy: 45.09
Round  22, Train loss: 1.259, Test loss: 2.038, Test accuracy: 45.83
Round  23, Train loss: 0.459, Test loss: 2.035, Test accuracy: 45.27
Round  24, Train loss: 0.768, Test loss: 2.090, Test accuracy: 37.37
Round  25, Train loss: 0.303, Test loss: 2.104, Test accuracy: 36.30
Round  26, Train loss: -0.152, Test loss: 2.069, Test accuracy: 41.83
Round  27, Train loss: -0.008, Test loss: 1.899, Test accuracy: 57.80
Round  28, Train loss: 0.429, Test loss: 1.867, Test accuracy: 60.00
Round  29, Train loss: 0.087, Test loss: 1.916, Test accuracy: 53.58
Round  30, Train loss: 0.037, Test loss: 1.931, Test accuracy: 51.70
Round  31, Train loss: -1.038, Test loss: 1.866, Test accuracy: 60.49
Round  32, Train loss: -0.534, Test loss: 1.927, Test accuracy: 56.46
Round  33, Train loss: -1.214, Test loss: 1.838, Test accuracy: 65.28
Round  34, Train loss: -0.331, Test loss: 1.850, Test accuracy: 62.39
Round  35, Train loss: -0.338, Test loss: 1.847, Test accuracy: 64.91
Round  36, Train loss: -0.983, Test loss: 1.883, Test accuracy: 60.96
Round  37, Train loss: -1.654, Test loss: 1.816, Test accuracy: 67.50
Round  38, Train loss: -1.066, Test loss: 1.820, Test accuracy: 65.67
Round  39, Train loss: -0.766, Test loss: 1.837, Test accuracy: 63.87
Round  40, Train loss: -1.164, Test loss: 1.837, Test accuracy: 63.68
Round  41, Train loss: -1.308, Test loss: 1.853, Test accuracy: 62.35
Round  42, Train loss: -1.376, Test loss: 1.850, Test accuracy: 61.83
Round  43, Train loss: -1.801, Test loss: 1.816, Test accuracy: 66.10
Round  44, Train loss: -1.619, Test loss: 1.840, Test accuracy: 63.76
Round  45, Train loss: -2.206, Test loss: 1.843, Test accuracy: 62.95
Round  46, Train loss: -2.375, Test loss: 1.810, Test accuracy: 67.23
Round  47, Train loss: -3.202, Test loss: 1.831, Test accuracy: 65.20
Round  48, Train loss: -2.780, Test loss: 1.755, Test accuracy: 72.21
Round  49, Train loss: -0.820, Test loss: 1.800, Test accuracy: 68.49
Round  50, Train loss: -2.373, Test loss: 1.742, Test accuracy: 73.34
Round  51, Train loss: -2.592, Test loss: 1.749, Test accuracy: 72.38
Round  52, Train loss: -2.098, Test loss: 1.766, Test accuracy: 71.72
Round  53, Train loss: -3.231, Test loss: 1.722, Test accuracy: 74.89
Round  54, Train loss: -2.511, Test loss: 1.686, Test accuracy: 77.88
Round  55, Train loss: -3.280, Test loss: 1.682, Test accuracy: 77.67
Round  56, Train loss: -4.476, Test loss: 1.679, Test accuracy: 77.96
Round  57, Train loss: -4.026, Test loss: 1.648, Test accuracy: 81.65
Round  58, Train loss: -3.215, Test loss: 1.655, Test accuracy: 81.30
Round  59, Train loss: -2.684, Test loss: 1.670, Test accuracy: 79.72
Round  60, Train loss: -3.074, Test loss: 1.665, Test accuracy: 80.41
Round  61, Train loss: -3.742, Test loss: 1.652, Test accuracy: 81.33
Round  62, Train loss: -4.156, Test loss: 1.651, Test accuracy: 81.08
Round  63, Train loss: -3.596, Test loss: 1.657, Test accuracy: 80.49
Round  64, Train loss: -3.497, Test loss: 1.649, Test accuracy: 81.40
Round  65, Train loss: -4.497, Test loss: 1.644, Test accuracy: 81.89
Round  66, Train loss: -3.757, Test loss: 1.665, Test accuracy: 79.59
Round  67, Train loss: -3.819, Test loss: 1.652, Test accuracy: 80.94
Round  68, Train loss: -4.060, Test loss: 1.654, Test accuracy: 80.71
Round  69, Train loss: -4.165, Test loss: 1.659, Test accuracy: 80.10
Round  70, Train loss: -4.812, Test loss: 1.651, Test accuracy: 80.86
Round  71, Train loss: -5.534, Test loss: 1.658, Test accuracy: 80.10
Round  72, Train loss: -4.936, Test loss: 1.636, Test accuracy: 82.40
Round  73, Train loss: -4.471, Test loss: 1.633, Test accuracy: 82.72
Round  74, Train loss: -5.436, Test loss: 1.631, Test accuracy: 82.91
Round  75, Train loss: -4.846, Test loss: 1.638, Test accuracy: 82.20
Round  76, Train loss: -4.694, Test loss: 1.638, Test accuracy: 82.23
Round  77, Train loss: -5.390, Test loss: 1.626, Test accuracy: 83.45
Round  78, Train loss: -4.882, Test loss: 1.622, Test accuracy: 84.00
Round  79, Train loss: -5.827, Test loss: 1.613, Test accuracy: 84.76
Round  80, Train loss: -4.572, Test loss: 1.631, Test accuracy: 82.97
Round  81, Train loss: -5.033, Test loss: 1.641, Test accuracy: 81.99
Round  82, Train loss: -5.426, Test loss: 1.637, Test accuracy: 82.23
Round  83, Train loss: -5.629, Test loss: 1.620, Test accuracy: 83.95
Round  84, Train loss: -3.982, Test loss: 1.641, Test accuracy: 81.88
Round  85, Train loss: -5.512, Test loss: 1.649, Test accuracy: 81.21
Round  86, Train loss: -5.369, Test loss: 1.631, Test accuracy: 82.88
Round  87, Train loss: -6.077, Test loss: 1.635, Test accuracy: 82.53
Round  88, Train loss: -5.199, Test loss: 1.627, Test accuracy: 83.36
Round  89, Train loss: -4.553, Test loss: 1.635, Test accuracy: 82.59
Round  90, Train loss: -5.381, Test loss: 1.617, Test accuracy: 84.34
Round  91, Train loss: -4.724, Test loss: 1.651, Test accuracy: 80.97
Round  92, Train loss: -4.049, Test loss: 1.625, Test accuracy: 83.63
Round  93, Train loss: -4.331, Test loss: 1.611, Test accuracy: 85.05
Round  94, Train loss: -5.962, Test loss: 1.626, Test accuracy: 83.53
Round  95, Train loss: -5.389, Test loss: 1.624, Test accuracy: 83.73
Round  96, Train loss: -5.081, Test loss: 1.616, Test accuracy: 84.49
Round  97, Train loss: -5.023, Test loss: 1.603, Test accuracy: 85.80
Round  98, Train loss: -4.957, Test loss: 1.581, Test accuracy: 87.99
Round  99, Train loss: -4.717, Test loss: 1.601, Test accuracy: 85.95
Final Round, Train loss: 1.802, Test loss: 1.726, Test accuracy: 74.62
Average accuracy final 10 rounds: 84.548
Average global accuracy final 10 rounds: 84.548
891.7107884883881
[]
[12.42, 15.09, 15.8, 15.06, 16.48, 23.87, 24.45, 21.89, 32.32, 34.38, 28.11, 25.54, 37.48, 28.74, 40.21, 42.65, 50.16, 38.76, 46.18, 52.13, 51.03, 45.09, 45.83, 45.27, 37.37, 36.3, 41.83, 57.8, 60.0, 53.58, 51.7, 60.49, 56.46, 65.28, 62.39, 64.91, 60.96, 67.5, 65.67, 63.87, 63.68, 62.35, 61.83, 66.1, 63.76, 62.95, 67.23, 65.2, 72.21, 68.49, 73.34, 72.38, 71.72, 74.89, 77.88, 77.67, 77.96, 81.65, 81.3, 79.72, 80.41, 81.33, 81.08, 80.49, 81.4, 81.89, 79.59, 80.94, 80.71, 80.1, 80.86, 80.1, 82.4, 82.72, 82.91, 82.2, 82.23, 83.45, 84.0, 84.76, 82.97, 81.99, 82.23, 83.95, 81.88, 81.21, 82.88, 82.53, 83.36, 82.59, 84.34, 80.97, 83.63, 85.05, 83.53, 83.73, 84.49, 85.8, 87.99, 85.95, 74.62]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.292, Test loss: 2.296, Test accuracy: 14.01
Round   0, Global train loss: 2.292, Global test loss: 2.303, Global test accuracy: 9.01
Round   1, Train loss: 2.281, Test loss: 2.281, Test accuracy: 19.21
Round   1, Global train loss: 2.281, Global test loss: 2.301, Global test accuracy: 11.00
Round   2, Train loss: 2.240, Test loss: 2.237, Test accuracy: 23.84
Round   2, Global train loss: 2.240, Global test loss: 2.296, Global test accuracy: 10.42
Round   3, Train loss: 2.140, Test loss: 2.153, Test accuracy: 38.24
Round   3, Global train loss: 2.140, Global test loss: 2.284, Global test accuracy: 17.81
Round   4, Train loss: 1.985, Test loss: 2.081, Test accuracy: 42.97
Round   4, Global train loss: 1.985, Global test loss: 2.274, Global test accuracy: 17.65
Round   5, Train loss: 1.934, Test loss: 2.007, Test accuracy: 50.86
Round   5, Global train loss: 1.934, Global test loss: 2.271, Global test accuracy: 15.98
Round   6, Train loss: 1.890, Test loss: 1.934, Test accuracy: 57.06
Round   6, Global train loss: 1.890, Global test loss: 2.250, Global test accuracy: 19.18
Round   7, Train loss: 1.879, Test loss: 1.882, Test accuracy: 62.82
Round   7, Global train loss: 1.879, Global test loss: 2.258, Global test accuracy: 18.30
Round   8, Train loss: 1.920, Test loss: 1.882, Test accuracy: 62.09
Round   8, Global train loss: 1.920, Global test loss: 2.268, Global test accuracy: 15.90
Round   9, Train loss: 1.907, Test loss: 1.857, Test accuracy: 63.80
Round   9, Global train loss: 1.907, Global test loss: 2.250, Global test accuracy: 18.78
Round  10, Train loss: 1.826, Test loss: 1.863, Test accuracy: 62.88
Round  10, Global train loss: 1.826, Global test loss: 2.252, Global test accuracy: 18.95
Round  11, Train loss: 1.850, Test loss: 1.847, Test accuracy: 64.56
Round  11, Global train loss: 1.850, Global test loss: 2.262, Global test accuracy: 18.01
Round  12, Train loss: 1.826, Test loss: 1.857, Test accuracy: 63.16
Round  12, Global train loss: 1.826, Global test loss: 2.250, Global test accuracy: 19.26
Round  13, Train loss: 1.870, Test loss: 1.849, Test accuracy: 63.04
Round  13, Global train loss: 1.870, Global test loss: 2.248, Global test accuracy: 19.58
Round  14, Train loss: 1.884, Test loss: 1.858, Test accuracy: 62.08
Round  14, Global train loss: 1.884, Global test loss: 2.255, Global test accuracy: 18.62
Round  15, Train loss: 1.896, Test loss: 1.851, Test accuracy: 62.10
Round  15, Global train loss: 1.896, Global test loss: 2.272, Global test accuracy: 16.95
Round  16, Train loss: 1.816, Test loss: 1.849, Test accuracy: 62.13
Round  16, Global train loss: 1.816, Global test loss: 2.263, Global test accuracy: 17.75
Round  17, Train loss: 1.834, Test loss: 1.841, Test accuracy: 62.34
Round  17, Global train loss: 1.834, Global test loss: 2.249, Global test accuracy: 20.11
Round  18, Train loss: 1.873, Test loss: 1.845, Test accuracy: 61.85
Round  18, Global train loss: 1.873, Global test loss: 2.239, Global test accuracy: 20.91
Round  19, Train loss: 1.865, Test loss: 1.844, Test accuracy: 61.87
Round  19, Global train loss: 1.865, Global test loss: 2.263, Global test accuracy: 16.81
Round  20, Train loss: 1.869, Test loss: 1.840, Test accuracy: 62.38
Round  20, Global train loss: 1.869, Global test loss: 2.249, Global test accuracy: 19.63
Round  21, Train loss: 1.823, Test loss: 1.827, Test accuracy: 63.65
Round  21, Global train loss: 1.823, Global test loss: 2.256, Global test accuracy: 18.75
Round  22, Train loss: 1.837, Test loss: 1.810, Test accuracy: 65.43
Round  22, Global train loss: 1.837, Global test loss: 2.233, Global test accuracy: 21.26
Round  23, Train loss: 1.774, Test loss: 1.810, Test accuracy: 65.37
Round  23, Global train loss: 1.774, Global test loss: 2.240, Global test accuracy: 20.78
Round  24, Train loss: 1.840, Test loss: 1.810, Test accuracy: 65.40
Round  24, Global train loss: 1.840, Global test loss: 2.247, Global test accuracy: 19.28
Round  25, Train loss: 1.807, Test loss: 1.804, Test accuracy: 66.10
Round  25, Global train loss: 1.807, Global test loss: 2.263, Global test accuracy: 16.87
Round  26, Train loss: 1.831, Test loss: 1.802, Test accuracy: 66.25
Round  26, Global train loss: 1.831, Global test loss: 2.241, Global test accuracy: 20.37
Round  27, Train loss: 1.834, Test loss: 1.802, Test accuracy: 66.10
Round  27, Global train loss: 1.834, Global test loss: 2.230, Global test accuracy: 21.50
Round  28, Train loss: 1.850, Test loss: 1.796, Test accuracy: 66.74
Round  28, Global train loss: 1.850, Global test loss: 2.262, Global test accuracy: 17.50
Round  29, Train loss: 1.776, Test loss: 1.780, Test accuracy: 68.63
Round  29, Global train loss: 1.776, Global test loss: 2.244, Global test accuracy: 20.02
Round  30, Train loss: 1.727, Test loss: 1.779, Test accuracy: 68.58
Round  30, Global train loss: 1.727, Global test loss: 2.245, Global test accuracy: 19.75
Round  31, Train loss: 1.790, Test loss: 1.778, Test accuracy: 68.59
Round  31, Global train loss: 1.790, Global test loss: 2.246, Global test accuracy: 19.79
Round  32, Train loss: 1.715, Test loss: 1.770, Test accuracy: 69.49
Round  32, Global train loss: 1.715, Global test loss: 2.244, Global test accuracy: 19.96
Round  33, Train loss: 1.719, Test loss: 1.771, Test accuracy: 69.40
Round  33, Global train loss: 1.719, Global test loss: 2.234, Global test accuracy: 21.28
Round  34, Train loss: 1.707, Test loss: 1.775, Test accuracy: 68.96
Round  34, Global train loss: 1.707, Global test loss: 2.231, Global test accuracy: 21.79
Round  35, Train loss: 1.732, Test loss: 1.776, Test accuracy: 68.87
Round  35, Global train loss: 1.732, Global test loss: 2.225, Global test accuracy: 22.36
Round  36, Train loss: 1.805, Test loss: 1.782, Test accuracy: 68.14
Round  36, Global train loss: 1.805, Global test loss: 2.239, Global test accuracy: 20.66
Round  37, Train loss: 1.878, Test loss: 1.773, Test accuracy: 69.05
Round  37, Global train loss: 1.878, Global test loss: 2.267, Global test accuracy: 17.08
Round  38, Train loss: 1.703, Test loss: 1.764, Test accuracy: 69.96
Round  38, Global train loss: 1.703, Global test loss: 2.241, Global test accuracy: 19.88
Round  39, Train loss: 1.809, Test loss: 1.758, Test accuracy: 70.58
Round  39, Global train loss: 1.809, Global test loss: 2.230, Global test accuracy: 21.69
Round  40, Train loss: 1.855, Test loss: 1.763, Test accuracy: 70.22
Round  40, Global train loss: 1.855, Global test loss: 2.239, Global test accuracy: 20.67
Round  41, Train loss: 1.813, Test loss: 1.755, Test accuracy: 70.96
Round  41, Global train loss: 1.813, Global test loss: 2.248, Global test accuracy: 19.29
Round  42, Train loss: 1.759, Test loss: 1.754, Test accuracy: 71.10
Round  42, Global train loss: 1.759, Global test loss: 2.256, Global test accuracy: 18.74
Round  43, Train loss: 1.730, Test loss: 1.754, Test accuracy: 71.08
Round  43, Global train loss: 1.730, Global test loss: 2.238, Global test accuracy: 20.91
Round  44, Train loss: 1.783, Test loss: 1.761, Test accuracy: 70.41
Round  44, Global train loss: 1.783, Global test loss: 2.234, Global test accuracy: 21.38
Round  45, Train loss: 1.812, Test loss: 1.759, Test accuracy: 70.53
Round  45, Global train loss: 1.812, Global test loss: 2.236, Global test accuracy: 20.89
Round  46, Train loss: 1.760, Test loss: 1.759, Test accuracy: 70.42
Round  46, Global train loss: 1.760, Global test loss: 2.242, Global test accuracy: 20.74
Round  47, Train loss: 1.782, Test loss: 1.751, Test accuracy: 71.17
Round  47, Global train loss: 1.782, Global test loss: 2.218, Global test accuracy: 23.40
Round  48, Train loss: 1.823, Test loss: 1.758, Test accuracy: 70.36
Round  48, Global train loss: 1.823, Global test loss: 2.243, Global test accuracy: 20.08
Round  49, Train loss: 1.774, Test loss: 1.757, Test accuracy: 70.56
Round  49, Global train loss: 1.774, Global test loss: 2.230, Global test accuracy: 21.65
Round  50, Train loss: 1.861, Test loss: 1.755, Test accuracy: 70.76
Round  50, Global train loss: 1.861, Global test loss: 2.241, Global test accuracy: 20.48
Round  51, Train loss: 1.711, Test loss: 1.755, Test accuracy: 70.83
Round  51, Global train loss: 1.711, Global test loss: 2.246, Global test accuracy: 19.69
Round  52, Train loss: 1.750, Test loss: 1.739, Test accuracy: 72.50
Round  52, Global train loss: 1.750, Global test loss: 2.219, Global test accuracy: 22.77
Round  53, Train loss: 1.773, Test loss: 1.739, Test accuracy: 72.54
Round  53, Global train loss: 1.773, Global test loss: 2.220, Global test accuracy: 23.23
Round  54, Train loss: 1.765, Test loss: 1.733, Test accuracy: 73.18
Round  54, Global train loss: 1.765, Global test loss: 2.227, Global test accuracy: 22.29
Round  55, Train loss: 1.759, Test loss: 1.732, Test accuracy: 73.15
Round  55, Global train loss: 1.759, Global test loss: 2.230, Global test accuracy: 21.73
Round  56, Train loss: 1.853, Test loss: 1.742, Test accuracy: 72.17
Round  56, Global train loss: 1.853, Global test loss: 2.249, Global test accuracy: 19.73
Round  57, Train loss: 1.748, Test loss: 1.767, Test accuracy: 69.61
Round  57, Global train loss: 1.748, Global test loss: 2.232, Global test accuracy: 21.26
Round  58, Train loss: 1.691, Test loss: 1.758, Test accuracy: 70.60
Round  58, Global train loss: 1.691, Global test loss: 2.228, Global test accuracy: 22.03
Round  59, Train loss: 1.820, Test loss: 1.750, Test accuracy: 71.51
Round  59, Global train loss: 1.820, Global test loss: 2.218, Global test accuracy: 23.29
Round  60, Train loss: 1.736, Test loss: 1.733, Test accuracy: 73.30
Round  60, Global train loss: 1.736, Global test loss: 2.234, Global test accuracy: 21.14
Round  61, Train loss: 1.797, Test loss: 1.732, Test accuracy: 73.21
Round  61, Global train loss: 1.797, Global test loss: 2.228, Global test accuracy: 22.12
Round  62, Train loss: 1.693, Test loss: 1.729, Test accuracy: 73.51
Round  62, Global train loss: 1.693, Global test loss: 2.230, Global test accuracy: 21.55
Round  63, Train loss: 1.763, Test loss: 1.727, Test accuracy: 73.99
Round  63, Global train loss: 1.763, Global test loss: 2.222, Global test accuracy: 22.68
Round  64, Train loss: 1.711, Test loss: 1.723, Test accuracy: 74.32
Round  64, Global train loss: 1.711, Global test loss: 2.260, Global test accuracy: 18.11
Round  65, Train loss: 1.684, Test loss: 1.713, Test accuracy: 75.39
Round  65, Global train loss: 1.684, Global test loss: 2.227, Global test accuracy: 21.92
Round  66, Train loss: 1.680, Test loss: 1.709, Test accuracy: 75.59
Round  66, Global train loss: 1.680, Global test loss: 2.226, Global test accuracy: 22.82
Round  67, Train loss: 1.734, Test loss: 1.712, Test accuracy: 75.43
Round  67, Global train loss: 1.734, Global test loss: 2.222, Global test accuracy: 22.32
Round  68, Train loss: 1.792, Test loss: 1.712, Test accuracy: 75.46
Round  68, Global train loss: 1.792, Global test loss: 2.254, Global test accuracy: 18.65
Round  69, Train loss: 1.712, Test loss: 1.701, Test accuracy: 76.50
Round  69, Global train loss: 1.712, Global test loss: 2.242, Global test accuracy: 19.83
Round  70, Train loss: 1.738, Test loss: 1.699, Test accuracy: 76.78
Round  70, Global train loss: 1.738, Global test loss: 2.252, Global test accuracy: 18.72
Round  71, Train loss: 1.657, Test loss: 1.700, Test accuracy: 76.72
Round  71, Global train loss: 1.657, Global test loss: 2.241, Global test accuracy: 20.49
Round  72, Train loss: 1.671, Test loss: 1.701, Test accuracy: 76.54
Round  72, Global train loss: 1.671, Global test loss: 2.244, Global test accuracy: 19.63
Round  73, Train loss: 1.786, Test loss: 1.711, Test accuracy: 75.51
Round  73, Global train loss: 1.786, Global test loss: 2.229, Global test accuracy: 21.87
Round  74, Train loss: 1.768, Test loss: 1.709, Test accuracy: 75.73
Round  74, Global train loss: 1.768, Global test loss: 2.219, Global test accuracy: 23.13
Round  75, Train loss: 1.715, Test loss: 1.708, Test accuracy: 75.75
Round  75, Global train loss: 1.715, Global test loss: 2.245, Global test accuracy: 19.32
Round  76, Train loss: 1.700, Test loss: 1.693, Test accuracy: 77.43
Round  76, Global train loss: 1.700, Global test loss: 2.229, Global test accuracy: 21.65
Round  77, Train loss: 1.775, Test loss: 1.691, Test accuracy: 77.58
Round  77, Global train loss: 1.775, Global test loss: 2.221, Global test accuracy: 22.90
Round  78, Train loss: 1.717, Test loss: 1.699, Test accuracy: 76.70
Round  78, Global train loss: 1.717, Global test loss: 2.234, Global test accuracy: 20.96
Round  79, Train loss: 1.689, Test loss: 1.690, Test accuracy: 77.58
Round  79, Global train loss: 1.689, Global test loss: 2.215, Global test accuracy: 23.29
Round  80, Train loss: 1.699, Test loss: 1.697, Test accuracy: 76.81
Round  80, Global train loss: 1.699, Global test loss: 2.222, Global test accuracy: 22.18
Round  81, Train loss: 1.754, Test loss: 1.697, Test accuracy: 76.77
Round  81, Global train loss: 1.754, Global test loss: 2.220, Global test accuracy: 22.94
Round  82, Train loss: 1.638, Test loss: 1.699, Test accuracy: 76.55
Round  82, Global train loss: 1.638, Global test loss: 2.244, Global test accuracy: 20.02
Round  83, Train loss: 1.715, Test loss: 1.697, Test accuracy: 76.83
Round  83, Global train loss: 1.715, Global test loss: 2.249, Global test accuracy: 19.68
Round  84, Train loss: 1.702, Test loss: 1.700, Test accuracy: 76.48
Round  84, Global train loss: 1.702, Global test loss: 2.259, Global test accuracy: 18.13
Round  85, Train loss: 1.691, Test loss: 1.700, Test accuracy: 76.53
Round  85, Global train loss: 1.691, Global test loss: 2.223, Global test accuracy: 22.63
Round  86, Train loss: 1.721, Test loss: 1.701, Test accuracy: 76.39
Round  86, Global train loss: 1.721, Global test loss: 2.259, Global test accuracy: 18.24
Round  87, Train loss: 1.729, Test loss: 1.693, Test accuracy: 77.27
Round  87, Global train loss: 1.729, Global test loss: 2.241, Global test accuracy: 20.22
Round  88, Train loss: 1.656, Test loss: 1.691, Test accuracy: 77.53
Round  88, Global train loss: 1.656, Global test loss: 2.242, Global test accuracy: 20.03
Round  89, Train loss: 1.664, Test loss: 1.692, Test accuracy: 77.44
Round  89, Global train loss: 1.664, Global test loss: 2.227, Global test accuracy: 21.60
Round  90, Train loss: 1.684, Test loss: 1.692, Test accuracy: 77.42
Round  90, Global train loss: 1.684, Global test loss: 2.230, Global test accuracy: 21.51
Round  91, Train loss: 1.675, Test loss: 1.701, Test accuracy: 76.62
Round  91, Global train loss: 1.675, Global test loss: 2.238, Global test accuracy: 20.59
Round  92, Train loss: 1.680, Test loss: 1.700, Test accuracy: 76.70
Round  92, Global train loss: 1.680, Global test loss: 2.236, Global test accuracy: 21.06
Round  93, Train loss: 1.684, Test loss: 1.701, Test accuracy: 76.58
Round  93, Global train loss: 1.684, Global test loss: 2.231, Global test accuracy: 21.71
Round  94, Train loss: 1.792, Test loss: 1.709, Test accuracy: 75.60
Round  94, Global train loss: 1.792, Global test loss: 2.232, Global test accuracy: 21.25
Round  95, Train loss: 1.598, Test loss: 1.709, Test accuracy: 75.56
Round  95, Global train loss: 1.598, Global test loss: 2.224, Global test accuracy: 21.99/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.661, Test loss: 1.701, Test accuracy: 76.38
Round  96, Global train loss: 1.661, Global test loss: 2.234, Global test accuracy: 21.07
Round  97, Train loss: 1.688, Test loss: 1.701, Test accuracy: 76.38
Round  97, Global train loss: 1.688, Global test loss: 2.228, Global test accuracy: 21.44
Round  98, Train loss: 1.678, Test loss: 1.701, Test accuracy: 76.30
Round  98, Global train loss: 1.678, Global test loss: 2.219, Global test accuracy: 22.93
Round  99, Train loss: 1.620, Test loss: 1.700, Test accuracy: 76.35
Round  99, Global train loss: 1.620, Global test loss: 2.227, Global test accuracy: 21.91
Final Round, Train loss: 1.668, Test loss: 1.683, Test accuracy: 78.20
Final Round, Global train loss: 1.668, Global test loss: 2.227, Global test accuracy: 21.91
Average accuracy final 10 rounds: 76.389 

Average global accuracy final 10 rounds: 21.546000000000003 

1295.498279094696
[0.9692103862762451, 1.9384207725524902, 2.7548484802246094, 3.5712761878967285, 4.39464545249939, 5.218014717102051, 6.04618239402771, 6.874350070953369, 7.702386856079102, 8.530423641204834, 9.365469217300415, 10.200514793395996, 11.043721675872803, 11.88692855834961, 12.736543655395508, 13.586158752441406, 14.421210050582886, 15.256261348724365, 16.09369730949402, 16.931133270263672, 17.813770294189453, 18.696407318115234, 19.543969869613647, 20.39153242111206, 21.246387004852295, 22.10124158859253, 22.957821369171143, 23.814401149749756, 24.663915157318115, 25.513429164886475, 26.360633611679077, 27.20783805847168, 28.04986023902893, 28.89188241958618, 29.73058533668518, 30.56928825378418, 31.42184019088745, 32.27439212799072, 33.123342514038086, 33.97229290008545, 34.82335567474365, 35.674418449401855, 36.53406047821045, 37.39370250701904, 38.24156212806702, 39.08942174911499, 39.92569446563721, 40.761967182159424, 41.60873460769653, 42.45550203323364, 43.29580903053284, 44.13611602783203, 44.994174003601074, 45.85223197937012, 46.75524282455444, 47.65825366973877, 48.52361011505127, 49.38896656036377, 50.23357129096985, 51.07817602157593, 51.86977791786194, 52.66137981414795, 53.453588247299194, 54.24579668045044, 55.04187798500061, 55.83795928955078, 56.64433026313782, 57.45070123672485, 58.25572681427002, 59.060752391815186, 59.86320209503174, 60.66565179824829, 61.46117663383484, 62.25670146942139, 63.05076813697815, 63.84483480453491, 64.63926243782043, 65.43369007110596, 66.22655391693115, 67.01941776275635, 67.82141137123108, 68.62340497970581, 69.43285393714905, 70.24230289459229, 71.16410112380981, 72.08589935302734, 72.98814010620117, 73.890380859375, 74.73868465423584, 75.58698844909668, 76.42160701751709, 77.2562255859375, 78.10003185272217, 78.94383811950684, 79.79371666908264, 80.64359521865845, 81.49325203895569, 82.34290885925293, 83.19418120384216, 84.0454535484314, 84.89132833480835, 85.7372031211853, 86.5796115398407, 87.4220199584961, 88.27493190765381, 89.12784385681152, 89.98791193962097, 90.84798002243042, 91.69958901405334, 92.55119800567627, 93.40543937683105, 94.25968074798584, 95.09620976448059, 95.93273878097534, 96.77455854415894, 97.61637830734253, 98.4547266960144, 99.29307508468628, 100.1337456703186, 100.97441625595093, 101.82217216491699, 102.66992807388306, 103.51123857498169, 104.35254907608032, 105.1882073879242, 106.02386569976807, 106.86024689674377, 107.69662809371948, 108.53699517250061, 109.37736225128174, 110.2274911403656, 111.07762002944946, 111.92488360404968, 112.7721471786499, 113.60714054107666, 114.44213390350342, 115.28120446205139, 116.12027502059937, 116.9633800983429, 117.80648517608643, 118.65442538261414, 119.50236558914185, 120.35554218292236, 121.20871877670288, 122.04948735237122, 122.89025592803955, 123.74855184555054, 124.60684776306152, 125.44377827644348, 126.28070878982544, 127.11849641799927, 127.9562840461731, 128.79566502571106, 129.63504600524902, 130.47781443595886, 131.3205828666687, 132.16061449050903, 133.00064611434937, 133.8488175868988, 134.69698905944824, 135.54575181007385, 136.39451456069946, 137.23467421531677, 138.07483386993408, 138.9537854194641, 139.83273696899414, 140.68196630477905, 141.53119564056396, 142.3657488822937, 143.20030212402344, 144.04718112945557, 144.8940601348877, 145.73598647117615, 146.5779128074646, 147.42104649543762, 148.26418018341064, 149.1074297428131, 149.95067930221558, 150.7905261516571, 151.63037300109863, 152.47812056541443, 153.32586812973022, 154.1639382839203, 155.00200843811035, 155.836092710495, 156.67017698287964, 157.57728958129883, 158.48440217971802, 159.3486909866333, 160.21297979354858, 161.0497441291809, 161.88650846481323, 162.72400426864624, 163.56150007247925, 164.40958261489868, 165.25766515731812, 166.0941879749298, 166.9307107925415, 167.77701783180237, 168.62332487106323, 170.29586124420166, 171.9683976173401]
[14.01, 14.01, 19.21, 19.21, 23.84, 23.84, 38.24, 38.24, 42.97, 42.97, 50.86, 50.86, 57.06, 57.06, 62.82, 62.82, 62.09, 62.09, 63.8, 63.8, 62.88, 62.88, 64.56, 64.56, 63.16, 63.16, 63.04, 63.04, 62.08, 62.08, 62.1, 62.1, 62.13, 62.13, 62.34, 62.34, 61.85, 61.85, 61.87, 61.87, 62.38, 62.38, 63.65, 63.65, 65.43, 65.43, 65.37, 65.37, 65.4, 65.4, 66.1, 66.1, 66.25, 66.25, 66.1, 66.1, 66.74, 66.74, 68.63, 68.63, 68.58, 68.58, 68.59, 68.59, 69.49, 69.49, 69.4, 69.4, 68.96, 68.96, 68.87, 68.87, 68.14, 68.14, 69.05, 69.05, 69.96, 69.96, 70.58, 70.58, 70.22, 70.22, 70.96, 70.96, 71.1, 71.1, 71.08, 71.08, 70.41, 70.41, 70.53, 70.53, 70.42, 70.42, 71.17, 71.17, 70.36, 70.36, 70.56, 70.56, 70.76, 70.76, 70.83, 70.83, 72.5, 72.5, 72.54, 72.54, 73.18, 73.18, 73.15, 73.15, 72.17, 72.17, 69.61, 69.61, 70.6, 70.6, 71.51, 71.51, 73.3, 73.3, 73.21, 73.21, 73.51, 73.51, 73.99, 73.99, 74.32, 74.32, 75.39, 75.39, 75.59, 75.59, 75.43, 75.43, 75.46, 75.46, 76.5, 76.5, 76.78, 76.78, 76.72, 76.72, 76.54, 76.54, 75.51, 75.51, 75.73, 75.73, 75.75, 75.75, 77.43, 77.43, 77.58, 77.58, 76.7, 76.7, 77.58, 77.58, 76.81, 76.81, 76.77, 76.77, 76.55, 76.55, 76.83, 76.83, 76.48, 76.48, 76.53, 76.53, 76.39, 76.39, 77.27, 77.27, 77.53, 77.53, 77.44, 77.44, 77.42, 77.42, 76.62, 76.62, 76.7, 76.7, 76.58, 76.58, 75.6, 75.6, 75.56, 75.56, 76.38, 76.38, 76.38, 76.38, 76.3, 76.3, 76.35, 76.35, 78.2, 78.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.295, Test loss: 2.301, Test accuracy: 9.00
Round   1, Train loss: 2.287, Test loss: 2.297, Test accuracy: 12.61
Round   2, Train loss: 2.219, Test loss: 2.292, Test accuracy: 14.16
Round   3, Train loss: 2.094, Test loss: 2.289, Test accuracy: 13.87
Round   4, Train loss: 2.013, Test loss: 2.282, Test accuracy: 14.73
Round   5, Train loss: 1.870, Test loss: 2.281, Test accuracy: 14.83
Round   6, Train loss: 1.820, Test loss: 2.277, Test accuracy: 15.73
Round   7, Train loss: 1.883, Test loss: 2.265, Test accuracy: 16.70
Round   8, Train loss: 1.841, Test loss: 2.275, Test accuracy: 15.76
Round   9, Train loss: 1.839, Test loss: 2.274, Test accuracy: 16.54
Round  10, Train loss: 1.958, Test loss: 2.274, Test accuracy: 16.36
Round  11, Train loss: 1.918, Test loss: 2.269, Test accuracy: 16.73
Round  12, Train loss: 1.805, Test loss: 2.266, Test accuracy: 17.73
Round  13, Train loss: 1.897, Test loss: 2.273, Test accuracy: 17.42
Round  14, Train loss: 1.782, Test loss: 2.267, Test accuracy: 16.76
Round  15, Train loss: 1.820, Test loss: 2.261, Test accuracy: 18.36
Round  16, Train loss: 1.896, Test loss: 2.274, Test accuracy: 16.24
Round  17, Train loss: 1.811, Test loss: 2.260, Test accuracy: 18.46
Round  18, Train loss: 1.811, Test loss: 2.259, Test accuracy: 18.26
Round  19, Train loss: 1.735, Test loss: 2.267, Test accuracy: 18.38
Round  20, Train loss: 1.753, Test loss: 2.271, Test accuracy: 16.58
Round  21, Train loss: 1.756, Test loss: 2.287, Test accuracy: 15.84
Round  22, Train loss: 1.740, Test loss: 2.280, Test accuracy: 15.15
Round  23, Train loss: 1.734, Test loss: 2.263, Test accuracy: 17.74
Round  24, Train loss: 1.783, Test loss: 2.271, Test accuracy: 16.99
Round  25, Train loss: 1.789, Test loss: 2.256, Test accuracy: 18.42
Round  26, Train loss: 1.688, Test loss: 2.269, Test accuracy: 16.56
Round  27, Train loss: 1.617, Test loss: 2.282, Test accuracy: 16.09
Round  28, Train loss: 1.722, Test loss: 2.280, Test accuracy: 16.11
Round  29, Train loss: 1.724, Test loss: 2.259, Test accuracy: 17.97
Round  30, Train loss: 1.738, Test loss: 2.253, Test accuracy: 19.03
Round  31, Train loss: 1.706, Test loss: 2.250, Test accuracy: 19.09
Round  32, Train loss: 1.737, Test loss: 2.251, Test accuracy: 19.30
Round  33, Train loss: 1.737, Test loss: 2.258, Test accuracy: 18.33
Round  34, Train loss: 1.701, Test loss: 2.264, Test accuracy: 17.78
Round  35, Train loss: 1.769, Test loss: 2.265, Test accuracy: 17.38
Round  36, Train loss: 1.675, Test loss: 2.250, Test accuracy: 19.53
Round  37, Train loss: 1.692, Test loss: 2.258, Test accuracy: 18.58
Round  38, Train loss: 1.702, Test loss: 2.267, Test accuracy: 17.85
Round  39, Train loss: 1.660, Test loss: 2.262, Test accuracy: 18.21
Round  40, Train loss: 1.667, Test loss: 2.248, Test accuracy: 19.71
Round  41, Train loss: 1.815, Test loss: 2.271, Test accuracy: 17.54
Round  42, Train loss: 1.666, Test loss: 2.260, Test accuracy: 18.24
Round  43, Train loss: 1.667, Test loss: 2.264, Test accuracy: 17.65
Round  44, Train loss: 1.665, Test loss: 2.269, Test accuracy: 17.07
Round  45, Train loss: 1.772, Test loss: 2.250, Test accuracy: 19.25
Round  46, Train loss: 1.731, Test loss: 2.269, Test accuracy: 17.23
Round  47, Train loss: 1.690, Test loss: 2.251, Test accuracy: 19.80
Round  48, Train loss: 1.680, Test loss: 2.259, Test accuracy: 18.43
Round  49, Train loss: 1.756, Test loss: 2.250, Test accuracy: 19.68
Round  50, Train loss: 1.719, Test loss: 2.261, Test accuracy: 17.98
Round  51, Train loss: 1.693, Test loss: 2.261, Test accuracy: 18.30
Round  52, Train loss: 1.784, Test loss: 2.272, Test accuracy: 16.87
Round  53, Train loss: 1.700, Test loss: 2.258, Test accuracy: 18.51
Round  54, Train loss: 1.657, Test loss: 2.269, Test accuracy: 17.14
Round  55, Train loss: 1.717, Test loss: 2.263, Test accuracy: 17.90
Round  56, Train loss: 1.775, Test loss: 2.262, Test accuracy: 18.07
Round  57, Train loss: 1.721, Test loss: 2.263, Test accuracy: 17.94
Round  58, Train loss: 1.663, Test loss: 2.255, Test accuracy: 19.02
Round  59, Train loss: 1.565, Test loss: 2.264, Test accuracy: 18.09
Round  60, Train loss: 1.714, Test loss: 2.257, Test accuracy: 18.68
Round  61, Train loss: 1.815, Test loss: 2.263, Test accuracy: 17.44
Round  62, Train loss: 1.657, Test loss: 2.265, Test accuracy: 17.82
Round  63, Train loss: 1.773, Test loss: 2.260, Test accuracy: 18.35
Round  64, Train loss: 1.585, Test loss: 2.262, Test accuracy: 18.12
Round  65, Train loss: 1.629, Test loss: 2.262, Test accuracy: 18.50
Round  66, Train loss: 1.711, Test loss: 2.267, Test accuracy: 17.37
Round  67, Train loss: 1.625, Test loss: 2.257, Test accuracy: 18.55
Round  68, Train loss: 1.587, Test loss: 2.263, Test accuracy: 17.56
Round  69, Train loss: 1.654, Test loss: 2.270, Test accuracy: 16.79
Round  70, Train loss: 1.589, Test loss: 2.257, Test accuracy: 18.49
Round  71, Train loss: 1.567, Test loss: 2.258, Test accuracy: 18.71
Round  72, Train loss: 1.644, Test loss: 2.265, Test accuracy: 17.38
Round  73, Train loss: 1.661, Test loss: 2.262, Test accuracy: 17.76
Round  74, Train loss: 1.658, Test loss: 2.248, Test accuracy: 19.48
Round  75, Train loss: 1.650, Test loss: 2.267, Test accuracy: 17.24
Round  76, Train loss: 1.626, Test loss: 2.249, Test accuracy: 19.37
Round  77, Train loss: 1.625, Test loss: 2.239, Test accuracy: 20.51
Round  78, Train loss: 1.697, Test loss: 2.256, Test accuracy: 18.06
Round  79, Train loss: 1.585, Test loss: 2.247, Test accuracy: 19.67
Round  80, Train loss: 1.627, Test loss: 2.275, Test accuracy: 16.29
Round  81, Train loss: 1.632, Test loss: 2.272, Test accuracy: 16.28
Round  82, Train loss: 1.660, Test loss: 2.262, Test accuracy: 17.84
Round  83, Train loss: 1.604, Test loss: 2.301, Test accuracy: 12.78
Round  84, Train loss: 1.511, Test loss: 2.264, Test accuracy: 17.22
Round  85, Train loss: 1.613, Test loss: 2.271, Test accuracy: 16.69
Round  86, Train loss: 1.628, Test loss: 2.256, Test accuracy: 18.83
Round  87, Train loss: 1.618, Test loss: 2.246, Test accuracy: 19.89
Round  88, Train loss: 1.609, Test loss: 2.260, Test accuracy: 18.29
Round  89, Train loss: 1.570, Test loss: 2.259, Test accuracy: 18.49
Round  90, Train loss: 1.596, Test loss: 2.257, Test accuracy: 18.93
Round  91, Train loss: 1.596, Test loss: 2.261, Test accuracy: 17.34
Round  92, Train loss: 1.628, Test loss: 2.277, Test accuracy: 15.49
Round  93, Train loss: 1.567, Test loss: 2.264, Test accuracy: 17.93
Round  94, Train loss: 1.555, Test loss: 2.272, Test accuracy: 16.51
Round  95, Train loss: 1.597, Test loss: 2.267, Test accuracy: 16.81
Round  96, Train loss: 1.567, Test loss: 2.278, Test accuracy: 16.52
Round  97, Train loss: 1.500, Test loss: 2.270, Test accuracy: 16.55
Round  98, Train loss: 1.587, Test loss: 2.248, Test accuracy: 19.14
Round  99, Train loss: 1.522, Test loss: 2.251, Test accuracy: 18.84
Final Round, Train loss: 1.570, Test loss: 2.241, Test accuracy: 20.22
Average accuracy final 10 rounds: 17.406
1476.0402343273163
[2.1687183380126953, 4.222796678543091, 6.267620086669922, 8.333211898803711, 10.40006685256958, 12.481388568878174, 14.552018880844116, 16.62726593017578, 18.68035387992859, 20.733513593673706, 22.7912278175354, 24.852062463760376, 26.918042182922363, 28.92280626296997, 30.956891536712646, 32.983943700790405, 34.97312140464783, 36.95458698272705, 38.94285249710083, 40.953503131866455, 42.96232533454895, 44.976558446884155, 46.977617263793945, 48.98330116271973, 50.981115102767944, 53.00358581542969, 55.008832931518555, 56.99686241149902, 58.994983196258545, 60.98749756813049, 63.02754807472229, 65.04008102416992, 67.05424356460571, 69.06603336334229, 71.07329034805298, 73.07588768005371, 75.0685646533966, 77.06611728668213, 79.06318712234497, 81.05706882476807, 83.05691719055176, 85.0528085231781, 87.04328894615173, 89.04480338096619, 91.0310525894165, 93.01112723350525, 94.99060940742493, 96.98976540565491, 98.99837636947632, 100.9981734752655, 102.98979759216309, 104.9996702671051, 107.00664758682251, 109.00348830223083, 111.01496052742004, 113.02751135826111, 115.05118608474731, 117.04147839546204, 119.00952816009521, 121.00001931190491, 123.00816464424133, 125.01204633712769, 127.01745629310608, 129.03449940681458, 131.04951167106628, 133.0701024532318, 135.07744598388672, 137.09062886238098, 139.09993839263916, 141.11928462982178, 143.12545228004456, 145.13170671463013, 147.1428394317627, 149.16659307479858, 151.167809009552, 153.1713650226593, 155.16738080978394, 157.16804003715515, 159.19129467010498, 161.19994235038757, 163.2077054977417, 165.23103666305542, 167.2605049610138, 169.2765622138977, 171.28642964363098, 173.29315423965454, 175.30003094673157, 177.31713700294495, 179.32590436935425, 181.34201574325562, 183.36403918266296, 185.3690745830536, 187.38926649093628, 189.42615604400635, 191.4574065208435, 193.46077060699463, 195.49058294296265, 197.5134892463684, 199.52640557289124, 201.54334044456482, 203.55477714538574]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[9.0, 12.61, 14.16, 13.87, 14.73, 14.83, 15.73, 16.7, 15.76, 16.54, 16.36, 16.73, 17.73, 17.42, 16.76, 18.36, 16.24, 18.46, 18.26, 18.38, 16.58, 15.84, 15.15, 17.74, 16.99, 18.42, 16.56, 16.09, 16.11, 17.97, 19.03, 19.09, 19.3, 18.33, 17.78, 17.38, 19.53, 18.58, 17.85, 18.21, 19.71, 17.54, 18.24, 17.65, 17.07, 19.25, 17.23, 19.8, 18.43, 19.68, 17.98, 18.3, 16.87, 18.51, 17.14, 17.9, 18.07, 17.94, 19.02, 18.09, 18.68, 17.44, 17.82, 18.35, 18.12, 18.5, 17.37, 18.55, 17.56, 16.79, 18.49, 18.71, 17.38, 17.76, 19.48, 17.24, 19.37, 20.51, 18.06, 19.67, 16.29, 16.28, 17.84, 12.78, 17.22, 16.69, 18.83, 19.89, 18.29, 18.49, 18.93, 17.34, 15.49, 17.93, 16.51, 16.81, 16.52, 16.55, 19.14, 18.84, 20.22]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.12
Round   0, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.03
Round   1, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.18
Round   1, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.04
Round   2, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.28
Round   2, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.09
Round   3, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.29
Round   3, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.07
Round   4, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.33
Round   4, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.12
Round   5, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.42
Round   5, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.14
Round   6, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.43
Round   6, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.18
Round   7, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.55
Round   7, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.22
Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.55
Round   8, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.26
Round   9, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.52
Round   9, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.21
Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.53
Round  10, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.31
Round  11, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.53
Round  11, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.30
Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.55
Round  12, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.29
Round  13, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.60
Round  13, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.27
Round  14, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.61
Round  14, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.35
Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.69
Round  15, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.36
Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.69
Round  16, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.36
Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.65
Round  17, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.34
Round  18, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.68
Round  18, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.36
Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.72
Round  19, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.43
Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.70
Round  20, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.43
Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.69
Round  21, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.45
Round  22, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.74
Round  22, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.47
Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.71
Round  23, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.52
Round  24, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.75
Round  24, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.60
Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.81
Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.60
Round  26, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.87
Round  26, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.61
Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.90
Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.56
Round  28, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.96
Round  28, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.56
Round  29, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.01
Round  29, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.62
Round  30, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.04
Round  30, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.76
Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.05
Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.82
Round  32, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.05
Round  32, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.83
Round  33, Train loss: 2.304, Test loss: 2.302, Test accuracy: 11.06
Round  33, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.86
Round  34, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.15
Round  34, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.89
Round  35, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.14
Round  35, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.95
Round  36, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.13
Round  36, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.92
Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.20
Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.94
Round  38, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.24
Round  38, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.03
Round  39, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.30
Round  39, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.12
Round  40, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.41
Round  40, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.17
Round  41, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.45
Round  41, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.22
Round  42, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.55
Round  42, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.24
Round  43, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.65
Round  43, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.28
Round  44, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.61
Round  44, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.32
Round  45, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.66
Round  45, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.40
Round  46, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.64
Round  46, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.36
Round  47, Train loss: 2.304, Test loss: 2.302, Test accuracy: 11.67
Round  47, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 11.43
Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.69
Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.42
Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.71
Round  49, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.40
Round  50, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.75
Round  50, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.43
Round  51, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.86
Round  51, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.43
Round  52, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.78
Round  52, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.54
Round  53, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.84
Round  53, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.60
Round  54, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.89
Round  54, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.62
Round  55, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.91
Round  55, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.69
Round  56, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.96
Round  56, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.70
Round  57, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.96
Round  57, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.70
Round  58, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.04
Round  58, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.71
Round  59, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.07
Round  59, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.75
Round  60, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.06
Round  60, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.76
Round  61, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.11
Round  61, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.78
Round  62, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.21
Round  62, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.85
Round  63, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.19
Round  63, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.87
Round  64, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.26
Round  64, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.89
Round  65, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.30
Round  65, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.96
Round  66, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.13
Round  66, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.95
Round  67, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.22
Round  67, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.92
Round  68, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.24
Round  68, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.93
Round  69, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.24
Round  69, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.90
Round  70, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.24
Round  70, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.08
Round  71, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.23
Round  71, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.09
Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.26
Round  72, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.07
Round  73, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.33
Round  73, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.08
Round  74, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.33
Round  74, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.09
Round  75, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.35
Round  75, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.10
Round  76, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.39
Round  76, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.13
Round  77, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.46
Round  77, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.22
Round  78, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.51
Round  78, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.35
Round  79, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.53
Round  79, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.44
Round  80, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.64
Round  80, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.49
Round  81, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.66
Round  81, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.47
Round  82, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.73
Round  82, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.47
Round  83, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.86
Round  83, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.52
Round  84, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.89
Round  84, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.49
Round  85, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.83
Round  85, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.52
Round  86, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.85
Round  86, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.59
Round  87, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.92
Round  87, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.67
Round  88, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.87
Round  88, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.67
Round  89, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.92
Round  89, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.68
Round  90, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.97
Round  90, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.69
Round  91, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.00
Round  91, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.77
Round  92, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.19
Round  92, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.80
Round  93, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.12
Round  93, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.79
Round  94, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.11
Round  94, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.81
Round  95, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.14
Round  95, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.86
Round  96, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.19
Round  96, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.89
Round  97, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.17
Round  97, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.89
Round  98, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.19
Round  98, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.92
Round  99, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.27
Round  99, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.03
Round 100, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.35
Round 100, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.05
Round 101, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.42
Round 101, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.15
Round 102, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.44
Round 102, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.18
Round 103, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.45
Round 103, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.37
Round 104, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.40
Round 104, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.40
Round 105, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.31
Round 105, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.41
Round 106, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.38
Round 106, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.38
Round 107, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.41
Round 107, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.42
Round 108, Train loss: 2.304, Test loss: 2.302, Test accuracy: 13.52
Round 108, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 13.42
Round 109, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.61
Round 109, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.43
Round 110, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.61
Round 110, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.44
Round 111, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.66
Round 111, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.41
Round 112, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.68
Round 112, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.42
Round 113, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.71
Round 113, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.46
Round 114, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.76
Round 114, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.46
Round 115, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.71
Round 115, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.49
Round 116, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.72
Round 116, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.47
Round 117, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.71
Round 117, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.47
Round 118, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.74
Round 118, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.46
Round 119, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.75
Round 119, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.48
Round 120, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.72
Round 120, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.51
Round 121, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.75
Round 121, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.49
Round 122, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.81
Round 122, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.50
Round 123, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.91
Round 123, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.62
Round 124, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.90
Round 124, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.62
Round 125, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.90
Round 125, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.67
Round 126, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.91
Round 126, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.70
Round 127, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.92
Round 127, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.64
Round 128, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.93
Round 128, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.66
Round 129, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.93
Round 129, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.64
Round 130, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.94
Round 130, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.67
Round 131, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.93
Round 131, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.65
Round 132, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.97
Round 132, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.71
Round 133, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.99
Round 133, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.78
Round 134, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.97
Round 134, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.75
Round 135, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.01
Round 135, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.72
Round 136, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.03
Round 136, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.82
Round 137, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.98
Round 137, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.84
Round 138, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.01
Round 138, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.85
Round 139, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.09
Round 139, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.88
Round 140, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.11
Round 140, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.99
Round 141, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.11
Round 141, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.01
Round 142, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.20
Round 142, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.02
Round 143, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.26
Round 143, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.99
Round 144, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.27
Round 144, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.01
Round 145, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.26
Round 145, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.03
Round 146, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.29
Round 146, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.99
Round 147, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.28
Round 147, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.97
Round 148, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.43
Round 148, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.05
Round 149, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.49
Round 149, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.12
Round 150, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.46
Round 150, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.15
Round 151, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.35
Round 151, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.15
Round 152, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.31
Round 152, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.15
Round 153, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.39
Round 153, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.13
Round 154, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.47
Round 154, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.14
Round 155, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.47
Round 155, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.17
Round 156, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.47
Round 156, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.18
Round 157, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.45
Round 157, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.24
Round 158, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.48
Round 158, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.30
Round 159, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.50
Round 159, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.28
Round 160, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.50
Round 160, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.33
Round 161, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.48
Round 161, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.34
Round 162, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.53
Round 162, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.36
Round 163, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.64
Round 163, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.35
Round 164, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.61
Round 164, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.40
Round 165, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.63
Round 165, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.42
Round 166, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.70
Round 166, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.43
Round 167, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.76
Round 167, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.53
Round 168, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.78
Round 168, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.53
Round 169, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.80
Round 169, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.54
Round 170, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.87
Round 170, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.53
Round 171, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.84
Round 171, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.56
Round 172, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.87
Round 172, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.55
Round 173, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.89
Round 173, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.58
Round 174, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.91
Round 174, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.59
Round 175, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.04
Round 175, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.62
Round 176, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.05
Round 176, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.64
Round 177, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.91
Round 177, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.64
Round 178, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.81
Round 178, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.62
Round 179, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.84
Round 179, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.68
Round 180, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.81
Round 180, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.67
Round 181, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.82
Round 181, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.66
Round 182, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.88
Round 182, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.65
Round 183, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.91
Round 183, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.63
Round 184, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.94
Round 184, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.62
Round 185, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.91
Round 185, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.62
Round 186, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.87
Round 186, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.64
Round 187, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.88
Round 187, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.66
Round 188, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.87
Round 188, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.66
Round 189, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.87
Round 189, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.62
Round 190, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.88
Round 190, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.64
Round 191, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.86
Round 191, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.65
Round 192, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.88
Round 192, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.65
Round 193, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.87
Round 193, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.65
Round 194, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.87
Round 194, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.65
Round 195, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.87
Round 195, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.65
Round 196, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.89
Round 196, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.67
Round 197, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.88
Round 197, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.67
Round 198, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.86
Round 198, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.68
Round 199, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.93
Round 199, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.71
Round 200, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.95
Round 200, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.64
Round 201, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.92
Round 201, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.60
Round 202, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.95
Round 202, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.67
Round 203, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.97
Round 203, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.63
Round 204, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.95
Round 204, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.73
Round 205, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.98
Round 205, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.73
Round 206, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.96
Round 206, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.69
Round 207, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.94
Round 207, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 208, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.92
Round 208, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.61
Round 209, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.96
Round 209, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.60
Round 210, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.95
Round 210, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.70
Round 211, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.91
Round 211, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.67
Round 212, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.93
Round 212, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.61
Round 213, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.94
Round 213, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 214, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.90
Round 214, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.59
Round 215, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.89
Round 215, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.60
Round 216, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.89
Round 216, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 217, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.90
Round 217, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.56
Round 218, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.92
Round 218, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.54
Round 219, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.95
Round 219, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.59
Round 220, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.94
Round 220, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.58
Round 221, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.92
Round 221, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 222, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.93
Round 222, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.62
Round 223, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.86
Round 223, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.61
Round 224, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.82
Round 224, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.61
Round 225, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.81
Round 225, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.59
Round 226, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.76
Round 226, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.60
Round 227, Train loss: 2.298, Test loss: 2.301, Test accuracy: 14.79
Round 227, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 14.58
Round 228, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.81
Round 228, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.56
Round 229, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.79
Round 229, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.55
Round 230, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.83
Round 230, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.56
Round 231, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.83
Round 231, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.58
Round 232, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.82
Round 232, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.59
Round 233, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.73
Round 233, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.59
Round 234, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.73
Round 234, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.59
Round 235, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.71
Round 235, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.54
Round 236, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.75
Round 236, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.58
Round 237, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.72
Round 237, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 238, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.72
Round 238, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.66
Round 239, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.71
Round 239, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.63
Round 240, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.72
Round 240, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.61
Round 241, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.74
Round 241, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.66
Round 242, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.73
Round 242, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.65
Round 243, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.71
Round 243, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.58
Round 244, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.71
Round 244, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.53
Round 245, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.74
Round 245, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.54
Round 246, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.72
Round 246, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.54
Round 247, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.72
Round 247, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.54
Round 248, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.73
Round 248, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.53
Round 249, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.73
Round 249, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.53
Round 250, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.73
Round 250, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.52
Round 251, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.68
Round 251, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.55
Round 252, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.71
Round 252, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.48
Round 253, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.68
Round 253, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.46
Round 254, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.69
Round 254, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.47
Round 255, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.69
Round 255, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.47
Round 256, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.73
Round 256, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.47
Round 257, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.71
Round 257, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.51
Round 258, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.65
Round 258, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.43
Round 259, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.62
Round 259, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.44
Round 260, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.62
Round 260, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.44
Round 261, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.64
Round 261, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.36
Round 262, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.64
Round 262, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.35
Round 263, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.65
Round 263, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.39
Round 264, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.65
Round 264, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.38
Round 265, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.56
Round 265, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.38
Round 266, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.55
Round 266, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.37
Round 267, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.55
Round 267, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.39
Round 268, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.56
Round 268, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.34
Round 269, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.50
Round 269, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.32
Round 270, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.51
Round 270, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.33
Round 271, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.41
Round 271, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.32
Round 272, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.39
Round 272, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.32
Round 273, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.39
Round 273, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.33
Round 274, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.42
Round 274, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.32
Round 275, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.42
Round 275, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.32
Round 276, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.41
Round 276, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.32
Round 277, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.40
Round 277, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.32
Round 278, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.41
Round 278, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.33
Round 279, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.42
Round 279, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.32
Round 280, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.42
Round 280, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.32
Round 281, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.43
Round 281, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.30
Round 282, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.39
Round 282, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.32
Round 283, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.39
Round 283, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.33
Round 284, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.39
Round 284, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.33
Round 285, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.38
Round 285, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.32
Round 286, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.40
Round 286, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.29
Round 287, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.40
Round 287, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.31
Round 288, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.40
Round 288, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.32
Round 289, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.41
Round 289, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.34
Round 290, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.41
Round 290, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.32
Round 291, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.41
Round 291, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.31
Round 292, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.37
Round 292, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.31
Round 293, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.38
Round 293, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.28
Round 294, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.38
Round 294, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.29
Round 295, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.37
Round 295, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.31
Round 296, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.37
Round 296, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.29
Round 297, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.37
Round 297, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.31
Round 298, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.38
Round 298, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.29
Round 299, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.38
Round 299, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.25
Round 300, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.37
Round 300, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.26
Round 301, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.34
Round 301, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.26
Round 302, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.31
Round 302, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.26
Round 303, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.33
Round 303, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.26
Round 304, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.32
Round 304, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.23
Round 305, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.32
Round 305, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.23
Round 306, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.33
Round 306, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.21
Round 307, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.29
Round 307, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.15
Round 308, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.29
Round 308, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.15
Round 309, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.28
Round 309, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.13
Round 310, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.25
Round 310, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 311, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.22
Round 311, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.15
Round 312, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.22
Round 312, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.14
Round 313, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.24
Round 313, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.13
Round 314, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.24
Round 314, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.13
Round 315, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.24
Round 315, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.13
Round 316, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.17
Round 316, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.13
Round 317, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.17
Round 317, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.13
Round 318, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.17
Round 318, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.13
Round 319, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.15
Round 319, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.12
Round 320, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.13
Round 320, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 321, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.14
Round 321, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 322, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.15
Round 322, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 323, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.13
Round 323, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.12
Round 324, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.14
Round 324, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.12
Round 325, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.14
Round 325, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.12
Round 326, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.15
Round 326, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.11
Round 327, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.15
Round 327, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.13
Round 328, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.15
Round 328, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 329, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.16
Round 329, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.12
Round 330, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.16
Round 330, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.12
Round 331, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.16
Round 331, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.12
Round 332, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.16
Round 332, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.12
Round 333, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.16
Round 333, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 334, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.18
Round 334, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.13
Round 335, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.17
Round 335, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 336, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.18
Round 336, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.13
Round 337, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.18
Round 337, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.14
Round 338, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.18
Round 338, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.14
Round 339, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.18
Round 339, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.15
Round 340, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.18
Round 340, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.15
Round 341, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.18
Round 341, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.13
Round 342, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.18
Round 342, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 343, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.18
Round 343, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.11
Round 344, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.17
Round 344, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.12
Round 345, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.17
Round 345, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 346, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.16
Round 346, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 347, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.16
Round 347, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.11
Round 348, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.17
Round 348, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.09
Round 349, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.16
Round 349, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 350, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.16
Round 350, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 351, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.16
Round 351, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.11
Round 352, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.15
Round 352, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.11
Round 353, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.16
Round 353, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.11
Round 354, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.16
Round 354, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.12
Round 355, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.14
Round 355, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 356, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.14
Round 356, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.09
Round 357, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.15
Round 357, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.09
Round 358, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.15
Round 358, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.09
Round 359, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.15
Round 359, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 360, Train loss: 2.303, Test loss: 2.300, Test accuracy: 14.15
Round 360, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.12
Round 361, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.15
Round 361, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 362, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.15
Round 362, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.11
Round 363, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.15
Round 363, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.09
Round 364, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.15
Round 364, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.09
Round 365, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.13
Round 365, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.08
Round 366, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.13
Round 366, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.08
Round 367, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.13
Round 367, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.08
Round 368, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.12
Round 368, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.10
Round 369, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.12
Round 369, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.10
Round 370, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.14
Round 370, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.08
Round 371, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.14
Round 371, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.08
Round 372, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.15
Round 372, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.10
Round 373, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.15
Round 373, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.08
Round 374, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.15
Round 374, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.08
Round 375, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.15
Round 375, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.06
Round 376, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.13
Round 376, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.06
Round 377, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.13
Round 377, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.06
Round 378, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.14
Round 378, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.05
Round 379, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.12
Round 379, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 14.05
Round 380, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.12
Round 380, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 14.05
Round 381, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.12
Round 381, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.05
Round 382, Train loss: 2.298, Test loss: 2.300, Test accuracy: 14.11
Round 382, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 14.05
Round 383, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.06
Round 383, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.05
Round 384, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.06
Round 384, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.05
Round 385, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.07
Round 385, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.06
Round 386, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.08
Round 386, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.06
Round 387, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.08
Round 387, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.06
Round 388, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.08
Round 388, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.03
Round 389, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.08
Round 389, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.03
Round 390, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.07
Round 390, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.03
Round 391, Train loss: 2.298, Test loss: 2.300, Test accuracy: 14.07
Round 391, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 14.03
Round 392, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.06
Round 392, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.04
Round 393, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.06
Round 393, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.04
Round 394, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.06
Round 394, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.04
Round 395, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.05
Round 395, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.04
Round 396, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.05
Round 396, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.02
Round 397, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.04
Round 397, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.02
Round 398, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.04
Round 398, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 14.04
Round 399, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.04
Round 399, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.04
Final Round, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.05
Final Round, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.04
Average accuracy final 10 rounds: 14.054 

Average global accuracy final 10 rounds: 14.033999999999999 

3993.7936205863953
[0.9325907230377197, 1.7622530460357666, 2.590773582458496, 3.407578945159912, 4.222709894180298, 5.033951044082642, 5.844990253448486, 6.672638177871704, 7.503046989440918, 8.327408790588379, 9.15268588066101, 9.977943181991577, 10.789584636688232, 11.599308013916016, 12.420999526977539, 13.224371671676636, 14.050499677658081, 14.867635488510132, 15.67386269569397, 16.490649700164795, 17.309900045394897, 18.11961555480957, 18.946141004562378, 19.774078369140625, 20.57737946510315, 21.394744157791138, 22.21668028831482, 23.030072450637817, 23.847808361053467, 24.66918635368347, 25.481003046035767, 26.30522131919861, 27.12277126312256, 27.930752754211426, 28.75147008895874, 29.575201272964478, 30.389009952545166, 31.21759271621704, 32.03793287277222, 32.84645199775696, 33.67480969429016, 34.495319843292236, 35.30545210838318, 36.1218581199646, 36.93025183677673, 37.74478578567505, 38.569915771484375, 39.386723041534424, 40.19971585273743, 41.02408695220947, 41.84589910507202, 42.65226078033447, 43.47168803215027, 44.28119683265686, 45.10584735870361, 45.937278032302856, 46.77113199234009, 47.577674865722656, 48.40518665313721, 49.22947955131531, 50.04255437850952, 50.852415323257446, 51.655991077423096, 52.45411467552185, 53.25926351547241, 54.066487073898315, 54.87026286125183, 55.6712691783905, 56.48672580718994, 57.29987120628357, 58.10100531578064, 59.00703549385071, 59.85394525527954, 60.66470003128052, 61.46906280517578, 62.26135325431824, 63.07453203201294, 63.88943862915039, 64.69272184371948, 65.51252126693726, 66.32028222084045, 67.13787937164307, 67.96245861053467, 68.7761857509613, 69.58720016479492, 70.41178321838379, 71.22120141983032, 72.04095387458801, 72.86703324317932, 73.67893481254578, 74.50759863853455, 75.33301424980164, 76.14231467247009, 76.9577419757843, 77.77008748054504, 78.58149695396423, 79.39458775520325, 80.2089831829071, 81.01379060745239, 81.83337497711182, 82.65639591217041, 83.47112941741943, 84.2923047542572, 85.08804392814636, 85.904611825943, 86.7273416519165, 87.53847646713257, 88.359126329422, 89.17391967773438, 89.98569583892822, 90.80924415588379, 91.64701986312866, 92.46331548690796, 93.28320097923279, 94.12105107307434, 94.94247913360596, 95.76597809791565, 96.60931515693665, 97.44502019882202, 98.29687309265137, 99.15157341957092, 99.98995590209961, 100.83965563774109, 101.6833074092865, 102.52033495903015, 103.36996817588806, 104.22706913948059, 105.06135869026184, 105.89734935760498, 106.75263237953186, 107.59786009788513, 108.43798518180847, 109.27438497543335, 110.10764479637146, 110.96148180961609, 111.81488180160522, 112.66225790977478, 113.51160621643066, 114.34774661064148, 115.18732357025146, 116.03224110603333, 116.88214993476868, 117.71908903121948, 118.56193804740906, 119.39267134666443, 120.22748613357544, 121.07419562339783, 121.93112874031067, 122.7692551612854, 123.6142852306366, 124.46974229812622, 125.31572341918945, 126.15826678276062, 127.00007629394531, 127.8503954410553, 128.70607376098633, 129.5565948486328, 130.3981454372406, 131.24427843093872, 132.09470772743225, 132.94148993492126, 133.7879762649536, 134.6426329612732, 135.47552037239075, 136.3293273448944, 137.17371821403503, 138.0088894367218, 138.86678171157837, 139.7194173336029, 140.55467820167542, 141.3986632823944, 142.25469660758972, 143.0988757610321, 143.9392614364624, 144.7814748287201, 145.6193549633026, 146.46603226661682, 147.31665921211243, 148.1594831943512, 149.0040831565857, 149.84099626541138, 150.68604707717896, 151.52679419517517, 152.38082456588745, 153.2217960357666, 154.0715615749359, 154.92976784706116, 155.77384686470032, 156.61968660354614, 157.4650752544403, 158.30280208587646, 159.13085007667542, 159.98469185829163, 160.83017683029175, 161.6846010684967, 162.52960109710693, 163.37082743644714, 164.20854377746582, 165.0246901512146, 165.90727019309998, 166.77447772026062, 167.64532327651978, 168.50525784492493, 169.37556791305542, 170.24184942245483, 171.09260749816895, 171.9520869255066, 172.78557467460632, 173.64512276649475, 174.48528003692627, 175.3611295223236, 176.21621680259705, 177.08529925346375, 177.95397019386292, 178.8058431148529, 179.65649366378784, 180.5005283355713, 181.35226702690125, 182.2068808078766, 183.0661325454712, 183.9278748035431, 184.78400659561157, 185.65775656700134, 186.49783873558044, 187.35337901115417, 188.20010614395142, 189.07613968849182, 189.94406127929688, 190.80813336372375, 191.69250226020813, 192.53101539611816, 193.37709951400757, 194.24197125434875, 195.0927402973175, 195.9469907283783, 196.78666162490845, 197.650456905365, 198.51560950279236, 199.3740086555481, 200.25006127357483, 201.11458778381348, 201.9561378955841, 202.82348537445068, 203.68244075775146, 204.5642900466919, 205.41783452033997, 206.27500772476196, 207.14661645889282, 208.00866103172302, 208.8583278656006, 209.71046614646912, 210.59051084518433, 211.4525249004364, 212.3122856616974, 213.19200992584229, 214.0656054019928, 214.94160199165344, 215.79857778549194, 216.66789197921753, 217.53856110572815, 218.40041971206665, 219.25462365150452, 220.103919506073, 220.96345281600952, 221.8132562637329, 222.6653652191162, 223.53088188171387, 224.39269471168518, 225.23310494422913, 226.10291957855225, 226.95327401161194, 227.80748891830444, 228.65654230117798, 229.51331305503845, 230.37008905410767, 231.22874355316162, 232.09018898010254, 232.93249416351318, 233.78951501846313, 234.64131474494934, 235.50048065185547, 236.4238200187683, 237.29602932929993, 238.17245316505432, 239.02501440048218, 239.89448046684265, 240.737943649292, 241.6039342880249, 242.47436261177063, 243.3571801185608, 244.26637077331543, 245.13168239593506, 245.98929905891418, 246.8630793094635, 247.75229954719543, 248.59211444854736, 249.4474470615387, 250.31467485427856, 251.23205828666687, 252.08937215805054, 252.92384386062622, 253.77394723892212, 254.6217987537384, 255.46957087516785, 256.316038608551, 257.1508400440216, 257.9737491607666, 258.8221437931061, 259.6319763660431, 260.4819526672363, 261.3285698890686, 262.1719250679016, 263.01748394966125, 263.8448784351349, 264.6777195930481, 265.5176875591278, 266.3580470085144, 267.1957449913025, 268.02777218818665, 268.8489875793457, 269.67137002944946, 270.4979634284973, 271.3540575504303, 272.20102977752686, 273.0416190624237, 273.8855347633362, 274.72337913513184, 275.5611708164215, 276.3960270881653, 277.2366087436676, 278.0816447734833, 278.92517471313477, 279.76862955093384, 280.61168456077576, 281.4645924568176, 282.2917866706848, 283.1378765106201, 283.9740045070648, 284.8140015602112, 285.6550385951996, 286.4872486591339, 287.30797386169434, 288.1551287174225, 289.0061204433441, 289.8331775665283, 290.68008732795715, 291.50807094573975, 292.3245255947113, 293.13896679878235, 293.9622983932495, 294.78782749176025, 295.62950372695923, 296.48658514022827, 297.3243691921234, 298.136568069458, 298.95222759246826, 299.7796654701233, 300.6082487106323, 301.4399700164795, 302.26120686531067, 303.0811812877655, 303.90649342536926, 304.71780037879944, 305.5423357486725, 306.3522913455963, 307.17159962654114, 307.99864315986633, 308.8258581161499, 309.6411409378052, 310.45605206489563, 311.2746207714081, 312.1088516712189, 312.9343059062958, 313.7431752681732, 314.5669322013855, 315.37646889686584, 316.20405626296997, 317.0275423526764, 317.84918093681335, 318.69039821624756, 319.50934290885925, 320.3285427093506, 321.13758993148804, 321.95126485824585, 322.7627925872803, 323.5783760547638, 324.41463685035706, 325.22965145111084, 326.049063205719, 326.85342955589294, 327.6869308948517, 328.5065667629242, 329.35500288009644, 330.1844837665558, 331.05000376701355, 331.8420376777649, 332.61767196655273, 333.43056535720825, 334.2419695854187, 335.0423011779785, 336.6039843559265]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[10.12, 10.18, 10.28, 10.29, 10.33, 10.42, 10.43, 10.55, 10.55, 10.52, 10.53, 10.53, 10.55, 10.6, 10.61, 10.69, 10.69, 10.65, 10.68, 10.72, 10.7, 10.69, 10.74, 10.71, 10.75, 10.81, 10.87, 10.9, 10.96, 11.01, 11.04, 11.05, 11.05, 11.06, 11.15, 11.14, 11.13, 11.2, 11.24, 11.3, 11.41, 11.45, 11.55, 11.65, 11.61, 11.66, 11.64, 11.67, 11.69, 11.71, 11.75, 11.86, 11.78, 11.84, 11.89, 11.91, 11.96, 11.96, 12.04, 12.07, 12.06, 12.11, 12.21, 12.19, 12.26, 12.3, 12.13, 12.22, 12.24, 12.24, 12.24, 12.23, 12.26, 12.33, 12.33, 12.35, 12.39, 12.46, 12.51, 12.53, 12.64, 12.66, 12.73, 12.86, 12.89, 12.83, 12.85, 12.92, 12.87, 12.92, 12.97, 13.0, 13.19, 13.12, 13.11, 13.14, 13.19, 13.17, 13.19, 13.27, 13.35, 13.42, 13.44, 13.45, 13.4, 13.31, 13.38, 13.41, 13.52, 13.61, 13.61, 13.66, 13.68, 13.71, 13.76, 13.71, 13.72, 13.71, 13.74, 13.75, 13.72, 13.75, 13.81, 13.91, 13.9, 13.9, 13.91, 13.92, 13.93, 13.93, 13.94, 13.93, 13.97, 13.99, 13.97, 14.01, 14.03, 13.98, 14.01, 14.09, 14.11, 14.11, 14.2, 14.26, 14.27, 14.26, 14.29, 14.28, 14.43, 14.49, 14.46, 14.35, 14.31, 14.39, 14.47, 14.47, 14.47, 14.45, 14.48, 14.5, 14.5, 14.48, 14.53, 14.64, 14.61, 14.63, 14.7, 14.76, 14.78, 14.8, 14.87, 14.84, 14.87, 14.89, 14.91, 15.04, 15.05, 14.91, 14.81, 14.84, 14.81, 14.82, 14.88, 14.91, 14.94, 14.91, 14.87, 14.88, 14.87, 14.87, 14.88, 14.86, 14.88, 14.87, 14.87, 14.87, 14.89, 14.88, 14.86, 14.93, 14.95, 14.92, 14.95, 14.97, 14.95, 14.98, 14.96, 14.94, 14.92, 14.96, 14.95, 14.91, 14.93, 14.94, 14.9, 14.89, 14.89, 14.9, 14.92, 14.95, 14.94, 14.92, 14.93, 14.86, 14.82, 14.81, 14.76, 14.79, 14.81, 14.79, 14.83, 14.83, 14.82, 14.73, 14.73, 14.71, 14.75, 14.72, 14.72, 14.71, 14.72, 14.74, 14.73, 14.71, 14.71, 14.74, 14.72, 14.72, 14.73, 14.73, 14.73, 14.68, 14.71, 14.68, 14.69, 14.69, 14.73, 14.71, 14.65, 14.62, 14.62, 14.64, 14.64, 14.65, 14.65, 14.56, 14.55, 14.55, 14.56, 14.5, 14.51, 14.41, 14.39, 14.39, 14.42, 14.42, 14.41, 14.4, 14.41, 14.42, 14.42, 14.43, 14.39, 14.39, 14.39, 14.38, 14.4, 14.4, 14.4, 14.41, 14.41, 14.41, 14.37, 14.38, 14.38, 14.37, 14.37, 14.37, 14.38, 14.38, 14.37, 14.34, 14.31, 14.33, 14.32, 14.32, 14.33, 14.29, 14.29, 14.28, 14.25, 14.22, 14.22, 14.24, 14.24, 14.24, 14.17, 14.17, 14.17, 14.15, 14.13, 14.14, 14.15, 14.13, 14.14, 14.14, 14.15, 14.15, 14.15, 14.16, 14.16, 14.16, 14.16, 14.16, 14.18, 14.17, 14.18, 14.18, 14.18, 14.18, 14.18, 14.18, 14.18, 14.18, 14.17, 14.17, 14.16, 14.16, 14.17, 14.16, 14.16, 14.16, 14.15, 14.16, 14.16, 14.14, 14.14, 14.15, 14.15, 14.15, 14.15, 14.15, 14.15, 14.15, 14.15, 14.13, 14.13, 14.13, 14.12, 14.12, 14.14, 14.14, 14.15, 14.15, 14.15, 14.15, 14.13, 14.13, 14.14, 14.12, 14.12, 14.12, 14.11, 14.06, 14.06, 14.07, 14.08, 14.08, 14.08, 14.08, 14.07, 14.07, 14.06, 14.06, 14.06, 14.05, 14.05, 14.04, 14.04, 14.04, 14.05]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.316, Test loss: 2.302, Test accuracy: 13.25
Round   1, Train loss: 2.295, Test loss: 2.301, Test accuracy: 14.97
Round   2, Train loss: 2.293, Test loss: 2.299, Test accuracy: 12.16
Round   3, Train loss: 2.281, Test loss: 2.294, Test accuracy: 15.86
Round   4, Train loss: 2.272, Test loss: 2.285, Test accuracy: 19.39
Round   5, Train loss: 2.241, Test loss: 2.267, Test accuracy: 19.73
Round   6, Train loss: 2.190, Test loss: 2.246, Test accuracy: 21.18
Round   7, Train loss: 2.171, Test loss: 2.220, Test accuracy: 25.86
Round   8, Train loss: 2.108, Test loss: 2.180, Test accuracy: 31.91
Round   9, Train loss: 2.053, Test loss: 2.134, Test accuracy: 36.83
Round  10, Train loss: 1.984, Test loss: 2.085, Test accuracy: 41.39
Round  11, Train loss: 1.875, Test loss: 2.028, Test accuracy: 48.04
Round  12, Train loss: 1.804, Test loss: 1.973, Test accuracy: 54.38
Round  13, Train loss: 1.925, Test loss: 1.944, Test accuracy: 58.67
Round  14, Train loss: 1.873, Test loss: 1.908, Test accuracy: 62.72
Round  15, Train loss: 1.830, Test loss: 1.864, Test accuracy: 67.66
Round  16, Train loss: 1.769, Test loss: 1.839, Test accuracy: 68.58
Round  17, Train loss: 1.759, Test loss: 1.804, Test accuracy: 72.17
Round  18, Train loss: 1.822, Test loss: 1.788, Test accuracy: 74.26
Round  19, Train loss: 1.754, Test loss: 1.748, Test accuracy: 79.63
Round  20, Train loss: 1.727, Test loss: 1.736, Test accuracy: 80.08
Round  21, Train loss: 1.757, Test loss: 1.723, Test accuracy: 81.36
Round  22, Train loss: 1.698, Test loss: 1.712, Test accuracy: 81.89
Round  23, Train loss: 1.626, Test loss: 1.691, Test accuracy: 83.39
Round  24, Train loss: 1.668, Test loss: 1.681, Test accuracy: 84.23
Round  25, Train loss: 1.683, Test loss: 1.681, Test accuracy: 84.56
Round  26, Train loss: 1.691, Test loss: 1.678, Test accuracy: 85.46
Round  27, Train loss: 1.640, Test loss: 1.671, Test accuracy: 85.63
Round  28, Train loss: 1.578, Test loss: 1.655, Test accuracy: 86.56
Round  29, Train loss: 1.665, Test loss: 1.654, Test accuracy: 86.78
Round  30, Train loss: 1.684, Test loss: 1.655, Test accuracy: 87.06
Round  31, Train loss: 1.600, Test loss: 1.648, Test accuracy: 87.25
Round  32, Train loss: 1.594, Test loss: 1.639, Test accuracy: 87.39
Round  33, Train loss: 1.606, Test loss: 1.638, Test accuracy: 87.69
Round  34, Train loss: 1.541, Test loss: 1.637, Test accuracy: 87.49
Round  35, Train loss: 1.628, Test loss: 1.632, Test accuracy: 87.53
Round  36, Train loss: 1.661, Test loss: 1.639, Test accuracy: 87.42
Round  37, Train loss: 1.618, Test loss: 1.627, Test accuracy: 87.80
Round  38, Train loss: 1.604, Test loss: 1.628, Test accuracy: 88.19
Round  39, Train loss: 1.577, Test loss: 1.624, Test accuracy: 87.79
Round  40, Train loss: 1.596, Test loss: 1.622, Test accuracy: 88.06
Round  41, Train loss: 1.651, Test loss: 1.629, Test accuracy: 87.67
Round  42, Train loss: 1.601, Test loss: 1.621, Test accuracy: 87.96
Round  43, Train loss: 1.559, Test loss: 1.617, Test accuracy: 87.92
Round  44, Train loss: 1.555, Test loss: 1.616, Test accuracy: 88.31
Round  45, Train loss: 1.584, Test loss: 1.614, Test accuracy: 88.38
Round  46, Train loss: 1.540, Test loss: 1.611, Test accuracy: 88.41
Round  47, Train loss: 1.646, Test loss: 1.616, Test accuracy: 88.42
Round  48, Train loss: 1.593, Test loss: 1.618, Test accuracy: 88.17
Round  49, Train loss: 1.592, Test loss: 1.615, Test accuracy: 88.42
Round  50, Train loss: 1.640, Test loss: 1.612, Test accuracy: 88.58
Round  51, Train loss: 1.667, Test loss: 1.609, Test accuracy: 89.48
Round  52, Train loss: 1.593, Test loss: 1.604, Test accuracy: 89.62
Round  53, Train loss: 1.582, Test loss: 1.604, Test accuracy: 89.53
Round  54, Train loss: 1.549, Test loss: 1.602, Test accuracy: 89.62
Round  55, Train loss: 1.551, Test loss: 1.599, Test accuracy: 89.78
Round  56, Train loss: 1.578, Test loss: 1.604, Test accuracy: 89.35
Round  57, Train loss: 1.635, Test loss: 1.602, Test accuracy: 89.65
Round  58, Train loss: 1.551, Test loss: 1.603, Test accuracy: 89.27
Round  59, Train loss: 1.518, Test loss: 1.594, Test accuracy: 89.66
Round  60, Train loss: 1.513, Test loss: 1.593, Test accuracy: 89.71
Round  61, Train loss: 1.604, Test loss: 1.601, Test accuracy: 89.42
Round  62, Train loss: 1.662, Test loss: 1.607, Test accuracy: 89.19
Round  63, Train loss: 1.552, Test loss: 1.593, Test accuracy: 90.05
Round  64, Train loss: 1.573, Test loss: 1.595, Test accuracy: 89.87
Round  65, Train loss: 1.633, Test loss: 1.604, Test accuracy: 89.54
Round  66, Train loss: 1.573, Test loss: 1.597, Test accuracy: 89.78
Round  67, Train loss: 1.628, Test loss: 1.598, Test accuracy: 89.61
Round  68, Train loss: 1.543, Test loss: 1.593, Test accuracy: 89.94
Round  69, Train loss: 1.565, Test loss: 1.592, Test accuracy: 89.92
Round  70, Train loss: 1.541, Test loss: 1.592, Test accuracy: 89.82
Round  71, Train loss: 1.530, Test loss: 1.590, Test accuracy: 89.75
Round  72, Train loss: 1.563, Test loss: 1.595, Test accuracy: 89.81
Round  73, Train loss: 1.600, Test loss: 1.589, Test accuracy: 90.26
Round  74, Train loss: 1.534, Test loss: 1.592, Test accuracy: 90.10
Round  75, Train loss: 1.530, Test loss: 1.585, Test accuracy: 90.32
Round  76, Train loss: 1.558, Test loss: 1.587, Test accuracy: 90.14
Round  77, Train loss: 1.536, Test loss: 1.586, Test accuracy: 90.28
Round  78, Train loss: 1.557, Test loss: 1.589, Test accuracy: 90.07
Round  79, Train loss: 1.530, Test loss: 1.586, Test accuracy: 90.07
Round  80, Train loss: 1.657, Test loss: 1.598, Test accuracy: 89.84
Round  81, Train loss: 1.569, Test loss: 1.590, Test accuracy: 90.17
Round  82, Train loss: 1.563, Test loss: 1.590, Test accuracy: 90.10
Round  83, Train loss: 1.563, Test loss: 1.585, Test accuracy: 90.18
Round  84, Train loss: 1.556, Test loss: 1.584, Test accuracy: 90.25
Round  85, Train loss: 1.528, Test loss: 1.581, Test accuracy: 90.29
Round  86, Train loss: 1.593, Test loss: 1.589, Test accuracy: 90.21
Round  87, Train loss: 1.590, Test loss: 1.585, Test accuracy: 90.18
Round  88, Train loss: 1.595, Test loss: 1.590, Test accuracy: 90.16
Round  89, Train loss: 1.500, Test loss: 1.579, Test accuracy: 90.41
Round  90, Train loss: 1.523, Test loss: 1.580, Test accuracy: 90.30
Round  91, Train loss: 1.557, Test loss: 1.586, Test accuracy: 90.24
Round  92, Train loss: 1.589, Test loss: 1.584, Test accuracy: 90.37
Round  93, Train loss: 1.588, Test loss: 1.593, Test accuracy: 89.99
Round  94, Train loss: 1.587, Test loss: 1.589, Test accuracy: 90.20
Round  95, Train loss: 1.557, Test loss: 1.587, Test accuracy: 90.29
Round  96, Train loss: 1.583, Test loss: 1.597, Test accuracy: 89.68
Round  97, Train loss: 1.558, Test loss: 1.586, Test accuracy: 90.23
Round  98, Train loss: 1.539, Test loss: 1.579, Test accuracy: 91.13
Round  99, Train loss: 1.556, Test loss: 1.584, Test accuracy: 91.01
Round 100, Train loss: 1.490, Test loss: 1.579, Test accuracy: 91.01
Round 101, Train loss: 1.487, Test loss: 1.575, Test accuracy: 91.07
Round 102, Train loss: 1.558, Test loss: 1.577, Test accuracy: 91.15
Round 103, Train loss: 1.583, Test loss: 1.578, Test accuracy: 91.19
Round 104, Train loss: 1.556, Test loss: 1.580, Test accuracy: 91.19
Round 105, Train loss: 1.554, Test loss: 1.579, Test accuracy: 91.25
Round 106, Train loss: 1.518, Test loss: 1.580, Test accuracy: 91.03
Round 107, Train loss: 1.555, Test loss: 1.578, Test accuracy: 91.19
Round 108, Train loss: 1.523, Test loss: 1.578, Test accuracy: 91.10
Round 109, Train loss: 1.584, Test loss: 1.579, Test accuracy: 91.25
Round 110, Train loss: 1.489, Test loss: 1.574, Test accuracy: 91.26
Round 111, Train loss: 1.550, Test loss: 1.577, Test accuracy: 91.13
Round 112, Train loss: 1.584, Test loss: 1.580, Test accuracy: 91.08
Round 113, Train loss: 1.517, Test loss: 1.577, Test accuracy: 91.08
Round 114, Train loss: 1.519, Test loss: 1.577, Test accuracy: 90.95
Round 115, Train loss: 1.594, Test loss: 1.576, Test accuracy: 91.10
Round 116, Train loss: 1.521, Test loss: 1.573, Test accuracy: 91.30
Round 117, Train loss: 1.515, Test loss: 1.570, Test accuracy: 91.46
Round 118, Train loss: 1.486, Test loss: 1.570, Test accuracy: 91.34
Round 119, Train loss: 1.582, Test loss: 1.580, Test accuracy: 91.14
Round 120, Train loss: 1.549, Test loss: 1.573, Test accuracy: 91.38
Round 121, Train loss: 1.514, Test loss: 1.570, Test accuracy: 91.39
Round 122, Train loss: 1.622, Test loss: 1.573, Test accuracy: 91.32
Round 123, Train loss: 1.488, Test loss: 1.569, Test accuracy: 91.35
Round 124, Train loss: 1.485, Test loss: 1.566, Test accuracy: 91.49
Round 125, Train loss: 1.514, Test loss: 1.568, Test accuracy: 91.46
Round 126, Train loss: 1.517, Test loss: 1.570, Test accuracy: 91.39
Round 127, Train loss: 1.519, Test loss: 1.571, Test accuracy: 91.40
Round 128, Train loss: 1.518, Test loss: 1.570, Test accuracy: 91.39
Round 129, Train loss: 1.519, Test loss: 1.575, Test accuracy: 91.22
Round 130, Train loss: 1.549, Test loss: 1.581, Test accuracy: 91.08
Round 131, Train loss: 1.548, Test loss: 1.571, Test accuracy: 91.48
Round 132, Train loss: 1.543, Test loss: 1.571, Test accuracy: 91.34
Round 133, Train loss: 1.542, Test loss: 1.569, Test accuracy: 91.41
Round 134, Train loss: 1.545, Test loss: 1.574, Test accuracy: 91.34
Round 135, Train loss: 1.526, Test loss: 1.570, Test accuracy: 91.36
Round 136, Train loss: 1.485, Test loss: 1.567, Test accuracy: 91.34
Round 137, Train loss: 1.496, Test loss: 1.560, Test accuracy: 92.31
Round 138, Train loss: 1.479, Test loss: 1.561, Test accuracy: 92.28
Round 139, Train loss: 1.650, Test loss: 1.575, Test accuracy: 91.97
Round 140, Train loss: 1.500, Test loss: 1.560, Test accuracy: 92.39
Round 141, Train loss: 1.521, Test loss: 1.557, Test accuracy: 92.47
Round 142, Train loss: 1.487, Test loss: 1.555, Test accuracy: 92.37
Round 143, Train loss: 1.583, Test loss: 1.559, Test accuracy: 92.39
Round 144, Train loss: 1.514, Test loss: 1.561, Test accuracy: 92.24
Round 145, Train loss: 1.523, Test loss: 1.556, Test accuracy: 92.40
Round 146, Train loss: 1.517, Test loss: 1.555, Test accuracy: 92.43
Round 147, Train loss: 1.546, Test loss: 1.558, Test accuracy: 92.41
Round 148, Train loss: 1.517, Test loss: 1.556, Test accuracy: 92.50
Round 149, Train loss: 1.547, Test loss: 1.562, Test accuracy: 92.49
Round 150, Train loss: 1.551, Test loss: 1.556, Test accuracy: 92.51
Round 151, Train loss: 1.517, Test loss: 1.557, Test accuracy: 92.45
Round 152, Train loss: 1.545, Test loss: 1.557, Test accuracy: 92.45
Round 153, Train loss: 1.512, Test loss: 1.557, Test accuracy: 92.39
Round 154, Train loss: 1.542, Test loss: 1.561, Test accuracy: 92.22
Round 155, Train loss: 1.519, Test loss: 1.559, Test accuracy: 92.23
Round 156, Train loss: 1.512, Test loss: 1.563, Test accuracy: 91.91
Round 157, Train loss: 1.582, Test loss: 1.559, Test accuracy: 92.49
Round 158, Train loss: 1.514, Test loss: 1.558, Test accuracy: 92.28
Round 159, Train loss: 1.551, Test loss: 1.558, Test accuracy: 92.46
Round 160, Train loss: 1.545, Test loss: 1.561, Test accuracy: 92.36
Round 161, Train loss: 1.580, Test loss: 1.566, Test accuracy: 92.27
Round 162, Train loss: 1.514, Test loss: 1.560, Test accuracy: 92.37
Round 163, Train loss: 1.547, Test loss: 1.560, Test accuracy: 92.42
Round 164, Train loss: 1.513, Test loss: 1.557, Test accuracy: 92.43
Round 165, Train loss: 1.512, Test loss: 1.559, Test accuracy: 92.31
Round 166, Train loss: 1.479, Test loss: 1.554, Test accuracy: 92.49
Round 167, Train loss: 1.480, Test loss: 1.553, Test accuracy: 92.54
Round 168, Train loss: 1.514, Test loss: 1.555, Test accuracy: 92.54
Round 169, Train loss: 1.511, Test loss: 1.556, Test accuracy: 92.54
Round 170, Train loss: 1.545, Test loss: 1.557, Test accuracy: 92.53
Round 171, Train loss: 1.514, Test loss: 1.554, Test accuracy: 92.52
Round 172, Train loss: 1.480, Test loss: 1.555, Test accuracy: 92.65
Round 173, Train loss: 1.544, Test loss: 1.555, Test accuracy: 92.65
Round 174, Train loss: 1.545, Test loss: 1.556, Test accuracy: 92.63
Round 175, Train loss: 1.544, Test loss: 1.554, Test accuracy: 92.60
Round 176, Train loss: 1.513, Test loss: 1.554, Test accuracy: 92.62
Round 177, Train loss: 1.481, Test loss: 1.553, Test accuracy: 92.42
Round 178, Train loss: 1.479, Test loss: 1.553, Test accuracy: 92.42
Round 179, Train loss: 1.476, Test loss: 1.552, Test accuracy: 92.42
Round 180, Train loss: 1.477, Test loss: 1.551, Test accuracy: 92.56
Round 181, Train loss: 1.543, Test loss: 1.554, Test accuracy: 92.37
Round 182, Train loss: 1.514, Test loss: 1.553, Test accuracy: 92.68
Round 183, Train loss: 1.579, Test loss: 1.558, Test accuracy: 92.46
Round 184, Train loss: 1.545, Test loss: 1.560, Test accuracy: 92.39
Round 185, Train loss: 1.513, Test loss: 1.556, Test accuracy: 92.45
Round 186, Train loss: 1.576, Test loss: 1.559, Test accuracy: 92.52
Round 187, Train loss: 1.576, Test loss: 1.560, Test accuracy: 92.55
Round 188, Train loss: 1.513, Test loss: 1.555, Test accuracy: 92.53
Round 189, Train loss: 1.575, Test loss: 1.559, Test accuracy: 92.52
Round 190, Train loss: 1.509, Test loss: 1.553, Test accuracy: 92.51
Round 191, Train loss: 1.546, Test loss: 1.553, Test accuracy: 92.62
Round 192, Train loss: 1.510, Test loss: 1.555, Test accuracy: 92.44
Round 193, Train loss: 1.509, Test loss: 1.552, Test accuracy: 92.60
Round 194, Train loss: 1.544, Test loss: 1.553, Test accuracy: 92.61
Round 195, Train loss: 1.512, Test loss: 1.553, Test accuracy: 92.56
Round 196, Train loss: 1.511, Test loss: 1.552, Test accuracy: 92.70
Round 197, Train loss: 1.542, Test loss: 1.554, Test accuracy: 92.49
Round 198, Train loss: 1.511, Test loss: 1.553, Test accuracy: 92.52
Round 199, Train loss: 1.478, Test loss: 1.551, Test accuracy: 92.55
Final Round, Train loss: 1.517, Test loss: 1.549, Test accuracy: 92.63
Average accuracy final 10 rounds: 92.55999999999999
1610.7381224632263
[1.0191318988800049, 1.9836750030517578, 2.9505224227905273, 3.919867753982544, 4.895090103149414, 5.91147780418396, 6.893765211105347, 7.8991663455963135, 8.888404846191406, 9.9008309841156, 10.937569618225098, 11.926283597946167, 12.92423939704895, 13.896282434463501, 14.873735666275024, 15.811672687530518, 16.785839080810547, 17.756547212600708, 18.746546030044556, 19.702473878860474, 20.661844730377197, 21.672693490982056, 22.634252786636353, 23.60921573638916, 24.553515672683716, 25.532655715942383, 26.50575876235962, 27.484899520874023, 28.514448881149292, 29.488466024398804, 30.43134307861328, 31.411516427993774, 32.401050329208374, 33.366740465164185, 34.31108784675598, 35.351325035095215, 36.415533781051636, 37.545971155166626, 38.56778144836426, 39.57418179512024, 40.54375147819519, 41.52170372009277, 42.49421191215515, 43.47796154022217, 44.44518780708313, 45.41271185874939, 46.374255657196045, 47.32863926887512, 48.32906460762024, 49.306591749191284, 50.29112124443054, 51.28829550743103, 52.352283239364624, 53.32877063751221, 54.29486083984375, 55.276901721954346, 56.24790811538696, 57.19123315811157, 58.145090103149414, 59.085256576538086, 60.04813575744629, 60.99888801574707, 61.969775915145874, 62.91573095321655, 63.92255711555481, 64.88865733146667, 65.89919328689575, 66.84316730499268, 67.82649731636047, 68.79609203338623, 69.77318668365479, 70.73933386802673, 71.71077561378479, 72.69490718841553, 73.64590644836426, 74.5565459728241, 75.46139144897461, 76.36615872383118, 77.28459930419922, 78.19123148918152, 79.07847428321838, 79.97662949562073, 80.91060018539429, 81.82519888877869, 82.72462272644043, 83.67034649848938, 84.54794359207153, 85.4562578201294, 86.34602165222168, 87.3067569732666, 88.17280793190002, 89.10438776016235, 90.00038838386536, 90.87830758094788, 91.78106355667114, 92.6752359867096, 93.55899286270142, 94.48221015930176, 95.39282369613647, 96.27666902542114, 97.21053504943848, 98.10196232795715, 98.99905633926392, 99.8815667629242, 100.81124258041382, 101.67483401298523, 102.61455202102661, 103.51889228820801, 104.43373131752014, 105.322518825531, 106.24229717254639, 107.10732698440552, 108.04352021217346, 108.9428596496582, 109.83760261535645, 110.74358701705933, 111.64911603927612, 112.57450294494629, 113.54493856430054, 114.46101403236389, 115.35098624229431, 116.25750756263733, 117.14048480987549, 118.0669538974762, 118.98721885681152, 119.9306058883667, 120.80422377586365, 121.74452900886536, 122.63306427001953, 123.53634715080261, 124.41116523742676, 125.35395455360413, 126.27601313591003, 127.22721910476685, 128.15684413909912, 129.03579926490784, 129.94488787651062, 130.86373353004456, 131.75496578216553, 132.6755838394165, 133.58860611915588, 134.47695326805115, 135.38043689727783, 136.29132747650146, 137.22317099571228, 138.10694646835327, 139.06042623519897, 139.96265649795532, 140.89013266563416, 141.78307390213013, 142.69589686393738, 143.58964347839355, 144.52591037750244, 145.42966437339783, 146.3587362766266, 147.30249571800232, 148.21270871162415, 149.12583303451538, 150.03276300430298, 150.95097279548645, 151.88462710380554, 152.82823705673218, 153.716233253479, 154.64374256134033, 155.52566838264465, 156.44083309173584, 157.31548047065735, 158.24713897705078, 159.14272689819336, 160.0858542919159, 161.09650683403015, 162.1001009941101, 162.99355149269104, 163.90636777877808, 164.83197021484375, 165.71911716461182, 166.63654589653015, 167.51868796348572, 168.45745253562927, 169.34052348136902, 170.27548956871033, 171.13509893417358, 172.0567536354065, 172.95267581939697, 173.84847378730774, 174.7308337688446, 175.64366626739502, 176.51161122322083, 177.43480038642883, 178.3503861427307, 179.24764466285706, 180.16539597511292, 181.0506889820099, 181.9335973262787, 182.89830231666565, 183.81345772743225, 184.73475575447083, 185.66395497322083, 186.57116556167603, 187.49806094169617, 188.9538471698761]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[13.25, 14.97, 12.16, 15.86, 19.39, 19.73, 21.18, 25.86, 31.91, 36.83, 41.39, 48.04, 54.38, 58.67, 62.72, 67.66, 68.58, 72.17, 74.26, 79.63, 80.08, 81.36, 81.89, 83.39, 84.23, 84.56, 85.46, 85.63, 86.56, 86.78, 87.06, 87.25, 87.39, 87.69, 87.49, 87.53, 87.42, 87.8, 88.19, 87.79, 88.06, 87.67, 87.96, 87.92, 88.31, 88.38, 88.41, 88.42, 88.17, 88.42, 88.58, 89.48, 89.62, 89.53, 89.62, 89.78, 89.35, 89.65, 89.27, 89.66, 89.71, 89.42, 89.19, 90.05, 89.87, 89.54, 89.78, 89.61, 89.94, 89.92, 89.82, 89.75, 89.81, 90.26, 90.1, 90.32, 90.14, 90.28, 90.07, 90.07, 89.84, 90.17, 90.1, 90.18, 90.25, 90.29, 90.21, 90.18, 90.16, 90.41, 90.3, 90.24, 90.37, 89.99, 90.2, 90.29, 89.68, 90.23, 91.13, 91.01, 91.01, 91.07, 91.15, 91.19, 91.19, 91.25, 91.03, 91.19, 91.1, 91.25, 91.26, 91.13, 91.08, 91.08, 90.95, 91.1, 91.3, 91.46, 91.34, 91.14, 91.38, 91.39, 91.32, 91.35, 91.49, 91.46, 91.39, 91.4, 91.39, 91.22, 91.08, 91.48, 91.34, 91.41, 91.34, 91.36, 91.34, 92.31, 92.28, 91.97, 92.39, 92.47, 92.37, 92.39, 92.24, 92.4, 92.43, 92.41, 92.5, 92.49, 92.51, 92.45, 92.45, 92.39, 92.22, 92.23, 91.91, 92.49, 92.28, 92.46, 92.36, 92.27, 92.37, 92.42, 92.43, 92.31, 92.49, 92.54, 92.54, 92.54, 92.53, 92.52, 92.65, 92.65, 92.63, 92.6, 92.62, 92.42, 92.42, 92.42, 92.56, 92.37, 92.68, 92.46, 92.39, 92.45, 92.52, 92.55, 92.53, 92.52, 92.51, 92.62, 92.44, 92.6, 92.61, 92.56, 92.7, 92.49, 92.52, 92.55, 92.63]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.301, Test accuracy: 10.76
Round   1, Train loss: 2.302, Test loss: 2.294, Test accuracy: 15.15
Round   2, Train loss: 2.264, Test loss: 2.280, Test accuracy: 17.59
Round   3, Train loss: 2.228, Test loss: 2.262, Test accuracy: 18.94
Round   4, Train loss: 2.200, Test loss: 2.245, Test accuracy: 21.98
Round   5, Train loss: 2.150, Test loss: 2.217, Test accuracy: 28.78
Round   6, Train loss: 2.142, Test loss: 2.167, Test accuracy: 30.55
Round   7, Train loss: 2.082, Test loss: 2.123, Test accuracy: 38.45
Round   8, Train loss: 2.059, Test loss: 2.076, Test accuracy: 49.31
Round   9, Train loss: 2.000, Test loss: 2.037, Test accuracy: 53.42
Round  10, Train loss: 1.929, Test loss: 1.996, Test accuracy: 56.78
Round  11, Train loss: 1.916, Test loss: 1.972, Test accuracy: 58.50
Round  12, Train loss: 1.846, Test loss: 1.925, Test accuracy: 62.97
Round  13, Train loss: 1.844, Test loss: 1.913, Test accuracy: 64.61
Round  14, Train loss: 1.823, Test loss: 1.880, Test accuracy: 68.60
Round  15, Train loss: 1.784, Test loss: 1.855, Test accuracy: 70.49
Round  16, Train loss: 1.699, Test loss: 1.842, Test accuracy: 70.12
Round  17, Train loss: 1.804, Test loss: 1.815, Test accuracy: 72.87
Round  18, Train loss: 1.743, Test loss: 1.799, Test accuracy: 74.32
Round  19, Train loss: 1.724, Test loss: 1.791, Test accuracy: 74.48
Round  20, Train loss: 1.819, Test loss: 1.765, Test accuracy: 77.08
Round  21, Train loss: 1.723, Test loss: 1.750, Test accuracy: 79.19
Round  22, Train loss: 1.692, Test loss: 1.735, Test accuracy: 80.53
Round  23, Train loss: 1.651, Test loss: 1.732, Test accuracy: 80.92
Round  24, Train loss: 1.747, Test loss: 1.706, Test accuracy: 82.88
Round  25, Train loss: 1.744, Test loss: 1.701, Test accuracy: 83.42
Round  26, Train loss: 1.695, Test loss: 1.699, Test accuracy: 83.42
Round  27, Train loss: 1.643, Test loss: 1.683, Test accuracy: 83.94
Round  28, Train loss: 1.719, Test loss: 1.681, Test accuracy: 85.03
Round  29, Train loss: 1.682, Test loss: 1.663, Test accuracy: 85.06
Round  30, Train loss: 1.667, Test loss: 1.658, Test accuracy: 86.05
Round  31, Train loss: 1.655, Test loss: 1.655, Test accuracy: 86.19
Round  32, Train loss: 1.658, Test loss: 1.653, Test accuracy: 86.41
Round  33, Train loss: 1.600, Test loss: 1.645, Test accuracy: 86.61
Round  34, Train loss: 1.622, Test loss: 1.641, Test accuracy: 86.60
Round  35, Train loss: 1.635, Test loss: 1.645, Test accuracy: 86.84
Round  36, Train loss: 1.679, Test loss: 1.641, Test accuracy: 87.01
Round  37, Train loss: 1.617, Test loss: 1.632, Test accuracy: 87.57
Round  38, Train loss: 1.614, Test loss: 1.624, Test accuracy: 88.55
Round  39, Train loss: 1.578, Test loss: 1.620, Test accuracy: 88.77
Round  40, Train loss: 1.595, Test loss: 1.623, Test accuracy: 88.74
Round  41, Train loss: 1.606, Test loss: 1.612, Test accuracy: 89.12
Round  42, Train loss: 1.631, Test loss: 1.618, Test accuracy: 89.13
Round  43, Train loss: 1.618, Test loss: 1.621, Test accuracy: 89.20
Round  44, Train loss: 1.596, Test loss: 1.618, Test accuracy: 89.13
Round  45, Train loss: 1.670, Test loss: 1.616, Test accuracy: 89.57
Round  46, Train loss: 1.618, Test loss: 1.618, Test accuracy: 89.53
Round  47, Train loss: 1.622, Test loss: 1.613, Test accuracy: 89.73
Round  48, Train loss: 1.592, Test loss: 1.609, Test accuracy: 89.88
Round  49, Train loss: 1.588, Test loss: 1.606, Test accuracy: 89.71
Round  50, Train loss: 1.582, Test loss: 1.608, Test accuracy: 89.69
Round  51, Train loss: 1.551, Test loss: 1.606, Test accuracy: 89.74
Round  52, Train loss: 1.617, Test loss: 1.605, Test accuracy: 89.85
Round  53, Train loss: 1.585, Test loss: 1.603, Test accuracy: 89.85
Round  54, Train loss: 1.577, Test loss: 1.598, Test accuracy: 89.95
Round  55, Train loss: 1.591, Test loss: 1.597, Test accuracy: 89.73
Round  56, Train loss: 1.580, Test loss: 1.591, Test accuracy: 90.82
Round  57, Train loss: 1.615, Test loss: 1.585, Test accuracy: 91.60
Round  58, Train loss: 1.554, Test loss: 1.584, Test accuracy: 91.71
Round  59, Train loss: 1.592, Test loss: 1.582, Test accuracy: 91.51
Round  60, Train loss: 1.532, Test loss: 1.571, Test accuracy: 92.68
Round  61, Train loss: 1.523, Test loss: 1.572, Test accuracy: 92.79
Round  62, Train loss: 1.526, Test loss: 1.570, Test accuracy: 92.76
Round  63, Train loss: 1.519, Test loss: 1.571, Test accuracy: 92.60
Round  64, Train loss: 1.549, Test loss: 1.570, Test accuracy: 92.68
Round  65, Train loss: 1.568, Test loss: 1.573, Test accuracy: 92.88
Round  66, Train loss: 1.578, Test loss: 1.568, Test accuracy: 92.93
Round  67, Train loss: 1.554, Test loss: 1.562, Test accuracy: 93.79
Round  68, Train loss: 1.515, Test loss: 1.561, Test accuracy: 93.85
Round  69, Train loss: 1.516, Test loss: 1.560, Test accuracy: 93.77
Round  70, Train loss: 1.550, Test loss: 1.558, Test accuracy: 93.83
Round  71, Train loss: 1.536, Test loss: 1.560, Test accuracy: 93.88
Round  72, Train loss: 1.535, Test loss: 1.557, Test accuracy: 93.95
Round  73, Train loss: 1.525, Test loss: 1.551, Test accuracy: 94.73
Round  74, Train loss: 1.520, Test loss: 1.545, Test accuracy: 94.84
Round  75, Train loss: 1.548, Test loss: 1.547, Test accuracy: 94.68
Round  76, Train loss: 1.509, Test loss: 1.546, Test accuracy: 94.83
Round  77, Train loss: 1.515, Test loss: 1.544, Test accuracy: 94.73
Round  78, Train loss: 1.509, Test loss: 1.544, Test accuracy: 94.80
Round  79, Train loss: 1.518, Test loss: 1.541, Test accuracy: 94.79
Round  80, Train loss: 1.565, Test loss: 1.546, Test accuracy: 94.93
Round  81, Train loss: 1.509, Test loss: 1.541, Test accuracy: 94.98
Round  82, Train loss: 1.525, Test loss: 1.542, Test accuracy: 94.81
Round  83, Train loss: 1.535, Test loss: 1.542, Test accuracy: 95.09
Round  84, Train loss: 1.503, Test loss: 1.543, Test accuracy: 94.97
Round  85, Train loss: 1.504, Test loss: 1.542, Test accuracy: 95.09
Round  86, Train loss: 1.504, Test loss: 1.540, Test accuracy: 95.00
Round  87, Train loss: 1.516, Test loss: 1.534, Test accuracy: 96.00
Round  88, Train loss: 1.511, Test loss: 1.531, Test accuracy: 96.13
Round  89, Train loss: 1.504, Test loss: 1.530, Test accuracy: 96.12
Round  90, Train loss: 1.503, Test loss: 1.531, Test accuracy: 96.14
Round  91, Train loss: 1.504, Test loss: 1.530, Test accuracy: 96.21
Round  92, Train loss: 1.502, Test loss: 1.528, Test accuracy: 96.24
Round  93, Train loss: 1.508, Test loss: 1.527, Test accuracy: 96.15
Round  94, Train loss: 1.500, Test loss: 1.528, Test accuracy: 96.27
Round  95, Train loss: 1.501, Test loss: 1.529, Test accuracy: 96.13
Round  96, Train loss: 1.505, Test loss: 1.528, Test accuracy: 96.07
Round  97, Train loss: 1.498, Test loss: 1.526, Test accuracy: 96.26
Round  98, Train loss: 1.498, Test loss: 1.527, Test accuracy: 96.30
Round  99, Train loss: 1.498, Test loss: 1.528, Test accuracy: 96.33
Round 100, Train loss: 1.528, Test loss: 1.529, Test accuracy: 96.33
Round 101, Train loss: 1.499, Test loss: 1.526, Test accuracy: 96.35
Round 102, Train loss: 1.496, Test loss: 1.528, Test accuracy: 96.23
Round 103, Train loss: 1.497, Test loss: 1.528, Test accuracy: 96.31
Round 104, Train loss: 1.530, Test loss: 1.529, Test accuracy: 96.27
Round 105, Train loss: 1.525, Test loss: 1.532, Test accuracy: 96.15
Round 106, Train loss: 1.499, Test loss: 1.528, Test accuracy: 96.31
Round 107, Train loss: 1.497, Test loss: 1.526, Test accuracy: 96.39
Round 108, Train loss: 1.497, Test loss: 1.526, Test accuracy: 96.25
Round 109, Train loss: 1.495, Test loss: 1.527, Test accuracy: 96.45
Round 110, Train loss: 1.497, Test loss: 1.524, Test accuracy: 96.42
Round 111, Train loss: 1.495, Test loss: 1.524, Test accuracy: 96.48
Round 112, Train loss: 1.493, Test loss: 1.524, Test accuracy: 96.54
Round 113, Train loss: 1.493, Test loss: 1.524, Test accuracy: 96.34
Round 114, Train loss: 1.528, Test loss: 1.526, Test accuracy: 96.36
Round 115, Train loss: 1.527, Test loss: 1.528, Test accuracy: 96.44
Round 116, Train loss: 1.526, Test loss: 1.528, Test accuracy: 96.27
Round 117, Train loss: 1.493, Test loss: 1.524, Test accuracy: 96.46
Round 118, Train loss: 1.495, Test loss: 1.523, Test accuracy: 96.35
Round 119, Train loss: 1.526, Test loss: 1.526, Test accuracy: 96.45
Round 120, Train loss: 1.493, Test loss: 1.525, Test accuracy: 96.29
Round 121, Train loss: 1.492, Test loss: 1.523, Test accuracy: 96.38
Round 122, Train loss: 1.524, Test loss: 1.524, Test accuracy: 96.45
Round 123, Train loss: 1.522, Test loss: 1.527, Test accuracy: 96.40
Round 124, Train loss: 1.495, Test loss: 1.523, Test accuracy: 96.53
Round 125, Train loss: 1.491, Test loss: 1.522, Test accuracy: 96.52
Round 126, Train loss: 1.490, Test loss: 1.523, Test accuracy: 96.49
Round 127, Train loss: 1.491, Test loss: 1.523, Test accuracy: 96.45
Round 128, Train loss: 1.493, Test loss: 1.522, Test accuracy: 96.45
Round 129, Train loss: 1.493, Test loss: 1.521, Test accuracy: 96.52
Round 130, Train loss: 1.490, Test loss: 1.522, Test accuracy: 96.43
Round 131, Train loss: 1.489, Test loss: 1.524, Test accuracy: 96.43
Round 132, Train loss: 1.490, Test loss: 1.524, Test accuracy: 96.46
Round 133, Train loss: 1.491, Test loss: 1.521, Test accuracy: 96.47
Round 134, Train loss: 1.489, Test loss: 1.521, Test accuracy: 96.57
Round 135, Train loss: 1.490, Test loss: 1.521, Test accuracy: 96.38
Round 136, Train loss: 1.489, Test loss: 1.522, Test accuracy: 96.45
Round 137, Train loss: 1.488, Test loss: 1.521, Test accuracy: 96.49
Round 138, Train loss: 1.521, Test loss: 1.524, Test accuracy: 96.46
Round 139, Train loss: 1.520, Test loss: 1.525, Test accuracy: 96.49
Round 140, Train loss: 1.491, Test loss: 1.522, Test accuracy: 96.57
Round 141, Train loss: 1.489, Test loss: 1.522, Test accuracy: 96.44
Round 142, Train loss: 1.488, Test loss: 1.522, Test accuracy: 96.51
Round 143, Train loss: 1.490, Test loss: 1.521, Test accuracy: 96.47
Round 144, Train loss: 1.489, Test loss: 1.521, Test accuracy: 96.38
Round 145, Train loss: 1.487, Test loss: 1.521, Test accuracy: 96.37
Round 146, Train loss: 1.487, Test loss: 1.521, Test accuracy: 96.45
Round 147, Train loss: 1.487, Test loss: 1.521, Test accuracy: 96.57
Round 148, Train loss: 1.520, Test loss: 1.525, Test accuracy: 96.46
Round 149, Train loss: 1.489, Test loss: 1.520, Test accuracy: 96.55
Round 150, Train loss: 1.488, Test loss: 1.520, Test accuracy: 96.46
Round 151, Train loss: 1.488, Test loss: 1.519, Test accuracy: 96.48
Round 152, Train loss: 1.489, Test loss: 1.519, Test accuracy: 96.57
Round 153, Train loss: 1.487, Test loss: 1.519, Test accuracy: 96.55
Round 154, Train loss: 1.517, Test loss: 1.520, Test accuracy: 96.53
Round 155, Train loss: 1.518, Test loss: 1.524, Test accuracy: 96.57
Round 156, Train loss: 1.488, Test loss: 1.519, Test accuracy: 96.65
Round 157, Train loss: 1.486, Test loss: 1.519, Test accuracy: 96.50
Round 158, Train loss: 1.485, Test loss: 1.520, Test accuracy: 96.51
Round 159, Train loss: 1.486, Test loss: 1.519, Test accuracy: 96.57
Round 160, Train loss: 1.485, Test loss: 1.520, Test accuracy: 96.57
Round 161, Train loss: 1.485, Test loss: 1.520, Test accuracy: 96.46
Round 162, Train loss: 1.487, Test loss: 1.520, Test accuracy: 96.57
Round 163, Train loss: 1.486, Test loss: 1.520, Test accuracy: 96.59
Round 164, Train loss: 1.485, Test loss: 1.520, Test accuracy: 96.51
Round 165, Train loss: 1.518, Test loss: 1.522, Test accuracy: 96.52
Round 166, Train loss: 1.486, Test loss: 1.518, Test accuracy: 96.59
Round 167, Train loss: 1.487, Test loss: 1.519, Test accuracy: 96.50
Round 168, Train loss: 1.486, Test loss: 1.518, Test accuracy: 96.63
Round 169, Train loss: 1.485, Test loss: 1.518, Test accuracy: 96.55
Round 170, Train loss: 1.485, Test loss: 1.517, Test accuracy: 96.59
Round 171, Train loss: 1.485, Test loss: 1.518, Test accuracy: 96.60
Round 172, Train loss: 1.517, Test loss: 1.521, Test accuracy: 96.51
Round 173, Train loss: 1.485, Test loss: 1.519, Test accuracy: 96.48
Round 174, Train loss: 1.486, Test loss: 1.517, Test accuracy: 96.60
Round 175, Train loss: 1.518, Test loss: 1.519, Test accuracy: 96.56
Round 176, Train loss: 1.484, Test loss: 1.517, Test accuracy: 96.56
Round 177, Train loss: 1.516, Test loss: 1.519, Test accuracy: 96.58
Round 178, Train loss: 1.516, Test loss: 1.520, Test accuracy: 96.61
Round 179, Train loss: 1.517, Test loss: 1.522, Test accuracy: 96.60
Round 180, Train loss: 1.484, Test loss: 1.519, Test accuracy: 96.50
Round 181, Train loss: 1.484, Test loss: 1.517, Test accuracy: 96.62
Round 182, Train loss: 1.483, Test loss: 1.517, Test accuracy: 96.53
Round 183, Train loss: 1.483, Test loss: 1.518, Test accuracy: 96.57
Round 184, Train loss: 1.483, Test loss: 1.517, Test accuracy: 96.66
Round 185, Train loss: 1.485, Test loss: 1.517, Test accuracy: 96.68
Round 186, Train loss: 1.516, Test loss: 1.518, Test accuracy: 96.70
Round 187, Train loss: 1.516, Test loss: 1.520, Test accuracy: 96.62
Round 188, Train loss: 1.485, Test loss: 1.517, Test accuracy: 96.69
Round 189, Train loss: 1.515, Test loss: 1.520, Test accuracy: 96.59
Round 190, Train loss: 1.515, Test loss: 1.521, Test accuracy: 96.52
Round 191, Train loss: 1.485, Test loss: 1.518, Test accuracy: 96.50
Round 192, Train loss: 1.484, Test loss: 1.516, Test accuracy: 96.64
Round 193, Train loss: 1.483, Test loss: 1.516, Test accuracy: 96.71
Round 194, Train loss: 1.513, Test loss: 1.518, Test accuracy: 96.60
Round 195, Train loss: 1.484, Test loss: 1.517, Test accuracy: 96.63
Round 196, Train loss: 1.483, Test loss: 1.517, Test accuracy: 96.55
Round 197, Train loss: 1.484, Test loss: 1.516, Test accuracy: 96.59
Round 198, Train loss: 1.483, Test loss: 1.516, Test accuracy: 96.54
Round 199, Train loss: 1.483, Test loss: 1.516, Test accuracy: 96.65
Final Round, Train loss: 1.480, Test loss: 1.514, Test accuracy: 96.71
Average accuracy final 10 rounds: 96.593
2228.2070512771606
[1.1263301372528076, 2.2526602745056152, 3.1511948108673096, 4.049729347229004, 4.97443151473999, 5.899133682250977, 6.81995701789856, 7.740780353546143, 8.631454229354858, 9.522128105163574, 10.418895483016968, 11.315662860870361, 12.221083164215088, 13.126503467559814, 14.035667896270752, 14.94483232498169, 15.943057298660278, 16.941282272338867, 17.87337064743042, 18.805459022521973, 19.694093227386475, 20.582727432250977, 21.46530771255493, 22.347887992858887, 23.713199615478516, 25.078511238098145, 26.203806400299072, 27.3291015625, 28.48433208465576, 29.639562606811523, 30.590413808822632, 31.54126501083374, 32.486653089523315, 33.43204116821289, 34.3666877746582, 35.301334381103516, 36.23410749435425, 37.16688060760498, 38.08993935585022, 39.01299810409546, 39.947526693344116, 40.88205528259277, 41.83629894256592, 42.79054260253906, 43.73065519332886, 44.67076778411865, 45.60056138038635, 46.53035497665405, 47.464972257614136, 48.39958953857422, 49.33867383003235, 50.27775812149048, 51.16970753669739, 52.0616569519043, 53.01293468475342, 53.96421241760254, 54.89932107925415, 55.83442974090576, 56.79676699638367, 57.75910425186157, 58.84109687805176, 59.92308950424194, 60.87154030799866, 61.81999111175537, 62.748719215393066, 63.67744731903076, 64.6200635433197, 65.56267976760864, 66.4948377609253, 67.42699575424194, 68.36175894737244, 69.29652214050293, 70.26323795318604, 71.22995376586914, 72.19292092323303, 73.15588808059692, 74.07422089576721, 74.9925537109375, 75.9454116821289, 76.89826965332031, 77.8432068824768, 78.7881441116333, 79.702152967453, 80.6161618232727, 81.53296637535095, 82.4497709274292, 83.37230658531189, 84.29484224319458, 85.20002937316895, 86.10521650314331, 87.04868507385254, 87.99215364456177, 88.99547457695007, 89.99879550933838, 90.9255576133728, 91.85231971740723, 92.78986406326294, 93.72740840911865, 94.6515564918518, 95.57570457458496, 96.49041438102722, 97.40512418746948, 98.32956433296204, 99.25400447845459, 100.16888117790222, 101.08375787734985, 101.99887108802795, 102.91398429870605, 103.84096884727478, 104.7679533958435, 105.68935704231262, 106.61076068878174, 107.52375268936157, 108.4367446899414, 109.34699535369873, 110.25724601745605, 111.22852325439453, 112.19980049133301, 113.14148545265198, 114.08317041397095, 115.01280689239502, 115.94244337081909, 116.88062381744385, 117.8188042640686, 118.71610832214355, 119.6134123802185, 120.58455777168274, 121.55570316314697, 122.48511743545532, 123.41453170776367, 124.35517072677612, 125.29580974578857, 126.2236704826355, 127.15153121948242, 128.10925722122192, 129.06698322296143, 130.00619983673096, 130.9454164505005, 131.95692896842957, 132.96844148635864, 133.97630071640015, 134.98415994644165, 135.96888375282288, 136.9536075592041, 137.9163076877594, 138.8790078163147, 139.84799766540527, 140.81698751449585, 141.7856912612915, 142.75439500808716, 143.72303771972656, 144.69168043136597, 145.65836000442505, 146.62503957748413, 147.58847451210022, 148.5519094467163, 149.56882739067078, 150.58574533462524, 151.59288716316223, 152.60002899169922, 153.63152885437012, 154.66302871704102, 155.65943956375122, 156.65585041046143, 157.6741406917572, 158.69243097305298, 159.62254548072815, 160.55265998840332, 161.51837968826294, 162.48409938812256, 163.4384560585022, 164.39281272888184, 165.34613466262817, 166.2994565963745, 167.2624909877777, 168.2255253791809, 169.1777412891388, 170.12995719909668, 171.10940718650818, 172.08885717391968, 173.0214500427246, 173.95404291152954, 174.863587141037, 175.77313137054443, 176.6984302997589, 177.6237292289734, 178.54862022399902, 179.47351121902466, 180.4058380126953, 181.33816480636597, 182.32054734230042, 183.30292987823486, 184.25755333900452, 185.21217679977417, 186.2525770664215, 187.29297733306885, 188.39425492286682, 189.4955325126648, 190.56752276420593, 191.63951301574707, 192.6473355293274, 193.65515804290771, 194.66175484657288, 195.66835165023804, 196.73725175857544, 197.80615186691284, 198.83430433273315, 199.86245679855347, 200.89308047294617, 201.92370414733887, 202.91446328163147, 203.90522241592407, 205.02265000343323, 206.14007759094238, 207.1685357093811, 208.19699382781982, 209.20800113677979, 210.21900844573975, 211.23126339912415, 212.24351835250854, 213.30668377876282, 214.3698492050171, 215.39638805389404, 216.422926902771, 217.44730019569397, 218.47167348861694, 219.49750423431396, 220.523334980011, 221.57378125190735, 222.6242275238037, 223.60538029670715, 224.5865330696106, 225.6241853237152, 226.66183757781982, 227.68545651435852, 228.70907545089722, 229.74387049674988, 230.77866554260254, 231.81412267684937, 232.8495798110962, 233.89638805389404, 234.9431962966919, 236.03942704200745, 237.135657787323, 238.2514054775238, 239.3671531677246, 240.3878014087677, 241.4084496498108, 242.50094890594482, 243.59344816207886, 244.59673500061035, 245.60002183914185, 246.62841176986694, 247.65680170059204, 248.69801568984985, 249.73922967910767, 250.78645062446594, 251.83367156982422, 252.8461890220642, 253.8587064743042, 254.90740370750427, 255.95610094070435, 256.990065574646, 258.02403020858765, 259.1441535949707, 260.26427698135376, 261.3355314731598, 262.4067859649658, 263.4314503669739, 264.45611476898193, 265.46685695648193, 266.47759914398193, 267.4858253002167, 268.4940514564514, 269.5134611129761, 270.53287076950073, 271.54099798202515, 272.54912519454956, 273.56853342056274, 274.5879416465759, 275.7112798690796, 276.83461809158325, 277.87135767936707, 278.9080972671509, 279.9669167995453, 281.0257363319397, 282.0532228946686, 283.08070945739746, 284.11526823043823, 285.149827003479, 286.1949415206909, 287.24005603790283, 288.2531650066376, 289.2662739753723, 290.25230383872986, 291.2383337020874, 292.227383852005, 293.2164340019226, 294.19788908958435, 295.1793441772461, 296.17848014831543, 297.17761611938477, 298.15623664855957, 299.1348571777344, 300.14659094810486, 301.15832471847534, 302.1786642074585, 303.19900369644165, 304.2162137031555, 305.2334237098694, 306.2537214756012, 307.274019241333, 308.2792375087738, 309.2844557762146, 310.2967574596405, 311.3090591430664, 312.28679394721985, 313.2645287513733, 314.26949739456177, 315.27446603775024, 316.2395396232605, 317.20461320877075, 318.25013756752014, 319.29566192626953, 320.2722737789154, 321.2488856315613, 322.2690546512604, 323.2892236709595, 324.2931241989136, 325.2970247268677, 326.31662344932556, 327.33622217178345, 328.3401987552643, 329.3441753387451, 330.3650941848755, 331.38601303100586, 332.3981947898865, 333.4103765487671, 334.41642355918884, 335.4224705696106, 336.44199204444885, 337.4615135192871, 338.45034623146057, 339.43917894363403, 340.45488810539246, 341.4705972671509, 342.450213432312, 343.42982959747314, 344.4343385696411, 345.4388475418091, 346.4181809425354, 347.3975143432617, 348.409215927124, 349.4209175109863, 350.43567848205566, 351.450439453125, 352.4650754928589, 353.4797115325928, 354.4915783405304, 355.503445148468, 356.5130548477173, 357.52266454696655, 358.55447030067444, 359.5862760543823, 360.61677527427673, 361.64727449417114, 362.64960980415344, 363.65194511413574, 364.65115451812744, 365.65036392211914, 366.63758182525635, 367.62479972839355, 368.6318128108978, 369.6388258934021, 370.63849902153015, 371.6381721496582, 372.5948328971863, 373.55149364471436, 374.52536702156067, 375.499240398407, 376.4930820465088, 377.4869236946106, 378.4974660873413, 379.508008480072, 380.49974060058594, 381.49147272109985, 382.4636182785034, 383.435763835907, 384.41425371170044, 385.3927435874939, 386.3936400413513, 387.39453649520874, 388.35411310195923, 389.3136897087097, 390.30036425590515, 391.2870388031006, 392.2140769958496, 393.14111518859863, 394.08294653892517, 395.0247778892517, 396.50584387779236, 397.986909866333]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[10.76, 10.76, 15.15, 15.15, 17.59, 17.59, 18.94, 18.94, 21.98, 21.98, 28.78, 28.78, 30.55, 30.55, 38.45, 38.45, 49.31, 49.31, 53.42, 53.42, 56.78, 56.78, 58.5, 58.5, 62.97, 62.97, 64.61, 64.61, 68.6, 68.6, 70.49, 70.49, 70.12, 70.12, 72.87, 72.87, 74.32, 74.32, 74.48, 74.48, 77.08, 77.08, 79.19, 79.19, 80.53, 80.53, 80.92, 80.92, 82.88, 82.88, 83.42, 83.42, 83.42, 83.42, 83.94, 83.94, 85.03, 85.03, 85.06, 85.06, 86.05, 86.05, 86.19, 86.19, 86.41, 86.41, 86.61, 86.61, 86.6, 86.6, 86.84, 86.84, 87.01, 87.01, 87.57, 87.57, 88.55, 88.55, 88.77, 88.77, 88.74, 88.74, 89.12, 89.12, 89.13, 89.13, 89.2, 89.2, 89.13, 89.13, 89.57, 89.57, 89.53, 89.53, 89.73, 89.73, 89.88, 89.88, 89.71, 89.71, 89.69, 89.69, 89.74, 89.74, 89.85, 89.85, 89.85, 89.85, 89.95, 89.95, 89.73, 89.73, 90.82, 90.82, 91.6, 91.6, 91.71, 91.71, 91.51, 91.51, 92.68, 92.68, 92.79, 92.79, 92.76, 92.76, 92.6, 92.6, 92.68, 92.68, 92.88, 92.88, 92.93, 92.93, 93.79, 93.79, 93.85, 93.85, 93.77, 93.77, 93.83, 93.83, 93.88, 93.88, 93.95, 93.95, 94.73, 94.73, 94.84, 94.84, 94.68, 94.68, 94.83, 94.83, 94.73, 94.73, 94.8, 94.8, 94.79, 94.79, 94.93, 94.93, 94.98, 94.98, 94.81, 94.81, 95.09, 95.09, 94.97, 94.97, 95.09, 95.09, 95.0, 95.0, 96.0, 96.0, 96.13, 96.13, 96.12, 96.12, 96.14, 96.14, 96.21, 96.21, 96.24, 96.24, 96.15, 96.15, 96.27, 96.27, 96.13, 96.13, 96.07, 96.07, 96.26, 96.26, 96.3, 96.3, 96.33, 96.33, 96.33, 96.33, 96.35, 96.35, 96.23, 96.23, 96.31, 96.31, 96.27, 96.27, 96.15, 96.15, 96.31, 96.31, 96.39, 96.39, 96.25, 96.25, 96.45, 96.45, 96.42, 96.42, 96.48, 96.48, 96.54, 96.54, 96.34, 96.34, 96.36, 96.36, 96.44, 96.44, 96.27, 96.27, 96.46, 96.46, 96.35, 96.35, 96.45, 96.45, 96.29, 96.29, 96.38, 96.38, 96.45, 96.45, 96.4, 96.4, 96.53, 96.53, 96.52, 96.52, 96.49, 96.49, 96.45, 96.45, 96.45, 96.45, 96.52, 96.52, 96.43, 96.43, 96.43, 96.43, 96.46, 96.46, 96.47, 96.47, 96.57, 96.57, 96.38, 96.38, 96.45, 96.45, 96.49, 96.49, 96.46, 96.46, 96.49, 96.49, 96.57, 96.57, 96.44, 96.44, 96.51, 96.51, 96.47, 96.47, 96.38, 96.38, 96.37, 96.37, 96.45, 96.45, 96.57, 96.57, 96.46, 96.46, 96.55, 96.55, 96.46, 96.46, 96.48, 96.48, 96.57, 96.57, 96.55, 96.55, 96.53, 96.53, 96.57, 96.57, 96.65, 96.65, 96.5, 96.5, 96.51, 96.51, 96.57, 96.57, 96.57, 96.57, 96.46, 96.46, 96.57, 96.57, 96.59, 96.59, 96.51, 96.51, 96.52, 96.52, 96.59, 96.59, 96.5, 96.5, 96.63, 96.63, 96.55, 96.55, 96.59, 96.59, 96.6, 96.6, 96.51, 96.51, 96.48, 96.48, 96.6, 96.6, 96.56, 96.56, 96.56, 96.56, 96.58, 96.58, 96.61, 96.61, 96.6, 96.6, 96.5, 96.5, 96.62, 96.62, 96.53, 96.53, 96.57, 96.57, 96.66, 96.66, 96.68, 96.68, 96.7, 96.7, 96.62, 96.62, 96.69, 96.69, 96.59, 96.59, 96.52, 96.52, 96.5, 96.5, 96.64, 96.64, 96.71, 96.71, 96.6, 96.6, 96.63, 96.63, 96.55, 96.55, 96.59, 96.59, 96.54, 96.54, 96.65, 96.65, 96.71, 96.71]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.289, Test loss: 2.291, Test accuracy: 18.60
Round   0, Global train loss: 2.289, Global test loss: 2.301, Global test accuracy: 11.83
Round   1, Train loss: 2.235, Test loss: 2.240, Test accuracy: 23.70
Round   1, Global train loss: 2.235, Global test loss: 2.294, Global test accuracy: 12.43
Round   2, Train loss: 2.104, Test loss: 2.146, Test accuracy: 35.68
Round   2, Global train loss: 2.104, Global test loss: 2.283, Global test accuracy: 13.85
Round   3, Train loss: 1.856, Test loss: 2.059, Test accuracy: 45.47
Round   3, Global train loss: 1.856, Global test loss: 2.272, Global test accuracy: 14.96
Round   4, Train loss: 1.856, Test loss: 1.964, Test accuracy: 56.85
Round   4, Global train loss: 1.856, Global test loss: 2.286, Global test accuracy: 13.41
Round   5, Train loss: 1.952, Test loss: 1.893, Test accuracy: 62.00
Round   5, Global train loss: 1.952, Global test loss: 2.279, Global test accuracy: 16.50
Round   6, Train loss: 1.929, Test loss: 1.837, Test accuracy: 68.29
Round   6, Global train loss: 1.929, Global test loss: 2.287, Global test accuracy: 13.68
Round   7, Train loss: 1.666, Test loss: 1.804, Test accuracy: 70.55
Round   7, Global train loss: 1.666, Global test loss: 2.284, Global test accuracy: 12.87
Round   8, Train loss: 1.703, Test loss: 1.734, Test accuracy: 76.37
Round   8, Global train loss: 1.703, Global test loss: 2.279, Global test accuracy: 14.55
Round   9, Train loss: 1.580, Test loss: 1.699, Test accuracy: 79.08
Round   9, Global train loss: 1.580, Global test loss: 2.292, Global test accuracy: 13.08
Round  10, Train loss: 1.569, Test loss: 1.688, Test accuracy: 79.90
Round  10, Global train loss: 1.569, Global test loss: 2.266, Global test accuracy: 18.53
Round  11, Train loss: 1.623, Test loss: 1.646, Test accuracy: 83.41
Round  11, Global train loss: 1.623, Global test loss: 2.279, Global test accuracy: 15.04
Round  12, Train loss: 1.603, Test loss: 1.641, Test accuracy: 83.78
Round  12, Global train loss: 1.603, Global test loss: 2.272, Global test accuracy: 17.06
Round  13, Train loss: 1.623, Test loss: 1.632, Test accuracy: 84.53
Round  13, Global train loss: 1.623, Global test loss: 2.274, Global test accuracy: 16.55
Round  14, Train loss: 1.523, Test loss: 1.629, Test accuracy: 84.60
Round  14, Global train loss: 1.523, Global test loss: 2.293, Global test accuracy: 15.78
Round  15, Train loss: 1.577, Test loss: 1.629, Test accuracy: 84.53
Round  15, Global train loss: 1.577, Global test loss: 2.266, Global test accuracy: 16.84
Round  16, Train loss: 1.712, Test loss: 1.626, Test accuracy: 84.63
Round  16, Global train loss: 1.712, Global test loss: 2.278, Global test accuracy: 15.03
Round  17, Train loss: 1.618, Test loss: 1.619, Test accuracy: 85.21
Round  17, Global train loss: 1.618, Global test loss: 2.278, Global test accuracy: 14.63
Round  18, Train loss: 1.552, Test loss: 1.613, Test accuracy: 85.82
Round  18, Global train loss: 1.552, Global test loss: 2.263, Global test accuracy: 18.38
Round  19, Train loss: 1.639, Test loss: 1.612, Test accuracy: 85.79
Round  19, Global train loss: 1.639, Global test loss: 2.279, Global test accuracy: 15.74
Round  20, Train loss: 1.572, Test loss: 1.608, Test accuracy: 86.35
Round  20, Global train loss: 1.572, Global test loss: 2.285, Global test accuracy: 13.89
Round  21, Train loss: 1.539, Test loss: 1.607, Test accuracy: 86.45
Round  21, Global train loss: 1.539, Global test loss: 2.297, Global test accuracy: 14.03
Round  22, Train loss: 1.605, Test loss: 1.602, Test accuracy: 86.75
Round  22, Global train loss: 1.605, Global test loss: 2.292, Global test accuracy: 14.51
Round  23, Train loss: 1.564, Test loss: 1.592, Test accuracy: 87.70
Round  23, Global train loss: 1.564, Global test loss: 2.298, Global test accuracy: 13.22
Round  24, Train loss: 1.479, Test loss: 1.592, Test accuracy: 87.82
Round  24, Global train loss: 1.479, Global test loss: 2.286, Global test accuracy: 14.61
Round  25, Train loss: 1.514, Test loss: 1.591, Test accuracy: 87.88
Round  25, Global train loss: 1.514, Global test loss: 2.287, Global test accuracy: 13.94
Round  26, Train loss: 1.571, Test loss: 1.590, Test accuracy: 87.89
Round  26, Global train loss: 1.571, Global test loss: 2.275, Global test accuracy: 16.99
Round  27, Train loss: 1.505, Test loss: 1.589, Test accuracy: 87.97
Round  27, Global train loss: 1.505, Global test loss: 2.281, Global test accuracy: 15.20
Round  28, Train loss: 1.508, Test loss: 1.588, Test accuracy: 88.12
Round  28, Global train loss: 1.508, Global test loss: 2.293, Global test accuracy: 14.30
Round  29, Train loss: 1.509, Test loss: 1.587, Test accuracy: 88.08
Round  29, Global train loss: 1.509, Global test loss: 2.284, Global test accuracy: 14.20
Round  30, Train loss: 1.470, Test loss: 1.587, Test accuracy: 88.07
Round  30, Global train loss: 1.470, Global test loss: 2.297, Global test accuracy: 12.88
Round  31, Train loss: 1.508, Test loss: 1.586, Test accuracy: 88.10
Round  31, Global train loss: 1.508, Global test loss: 2.289, Global test accuracy: 15.32
Round  32, Train loss: 1.507, Test loss: 1.586, Test accuracy: 88.09
Round  32, Global train loss: 1.507, Global test loss: 2.292, Global test accuracy: 13.82
Round  33, Train loss: 1.471, Test loss: 1.586, Test accuracy: 88.08
Round  33, Global train loss: 1.471, Global test loss: 2.279, Global test accuracy: 15.78
Round  34, Train loss: 1.487, Test loss: 1.582, Test accuracy: 88.50
Round  34, Global train loss: 1.487, Global test loss: 2.280, Global test accuracy: 15.59
Round  35, Train loss: 1.503, Test loss: 1.582, Test accuracy: 88.47
Round  35, Global train loss: 1.503, Global test loss: 2.305, Global test accuracy: 14.41
Round  36, Train loss: 1.538, Test loss: 1.581, Test accuracy: 88.48
Round  36, Global train loss: 1.538, Global test loss: 2.307, Global test accuracy: 13.56
Round  37, Train loss: 1.506, Test loss: 1.581, Test accuracy: 88.50
Round  37, Global train loss: 1.506, Global test loss: 2.301, Global test accuracy: 13.85
Round  38, Train loss: 1.472, Test loss: 1.581, Test accuracy: 88.47
Round  38, Global train loss: 1.472, Global test loss: 2.282, Global test accuracy: 14.25
Round  39, Train loss: 1.574, Test loss: 1.579, Test accuracy: 88.61
Round  39, Global train loss: 1.574, Global test loss: 2.288, Global test accuracy: 15.05
Round  40, Train loss: 1.503, Test loss: 1.579, Test accuracy: 88.59
Round  40, Global train loss: 1.503, Global test loss: 2.279, Global test accuracy: 15.71
Round  41, Train loss: 1.482, Test loss: 1.572, Test accuracy: 89.35
Round  41, Global train loss: 1.482, Global test loss: 2.285, Global test accuracy: 13.43
Round  42, Train loss: 1.504, Test loss: 1.571, Test accuracy: 89.46
Round  42, Global train loss: 1.504, Global test loss: 2.319, Global test accuracy: 11.69
Round  43, Train loss: 1.469, Test loss: 1.570, Test accuracy: 89.45
Round  43, Global train loss: 1.469, Global test loss: 2.304, Global test accuracy: 13.50
Round  44, Train loss: 1.505, Test loss: 1.570, Test accuracy: 89.43
Round  44, Global train loss: 1.505, Global test loss: 2.285, Global test accuracy: 14.51
Round  45, Train loss: 1.474, Test loss: 1.570, Test accuracy: 89.47
Round  45, Global train loss: 1.474, Global test loss: 2.275, Global test accuracy: 17.27
Round  46, Train loss: 1.506, Test loss: 1.570, Test accuracy: 89.51
Round  46, Global train loss: 1.506, Global test loss: 2.297, Global test accuracy: 12.92
Round  47, Train loss: 1.505, Test loss: 1.569, Test accuracy: 89.55
Round  47, Global train loss: 1.505, Global test loss: 2.257, Global test accuracy: 18.82
Round  48, Train loss: 1.539, Test loss: 1.569, Test accuracy: 89.58
Round  48, Global train loss: 1.539, Global test loss: 2.282, Global test accuracy: 14.83
Round  49, Train loss: 1.534, Test loss: 1.569, Test accuracy: 89.61
Round  49, Global train loss: 1.534, Global test loss: 2.270, Global test accuracy: 17.04
Round  50, Train loss: 1.501, Test loss: 1.569, Test accuracy: 89.54
Round  50, Global train loss: 1.501, Global test loss: 2.258, Global test accuracy: 18.00
Round  51, Train loss: 1.471, Test loss: 1.569, Test accuracy: 89.53
Round  51, Global train loss: 1.471, Global test loss: 2.277, Global test accuracy: 16.46
Round  52, Train loss: 1.535, Test loss: 1.569, Test accuracy: 89.53
Round  52, Global train loss: 1.535, Global test loss: 2.277, Global test accuracy: 15.86
Round  53, Train loss: 1.502, Test loss: 1.569, Test accuracy: 89.50
Round  53, Global train loss: 1.502, Global test loss: 2.262, Global test accuracy: 17.58
Round  54, Train loss: 1.501, Test loss: 1.569, Test accuracy: 89.50
Round  54, Global train loss: 1.501, Global test loss: 2.283, Global test accuracy: 14.02
Round  55, Train loss: 1.564, Test loss: 1.569, Test accuracy: 89.49
Round  55, Global train loss: 1.564, Global test loss: 2.298, Global test accuracy: 11.75
Round  56, Train loss: 1.502, Test loss: 1.569, Test accuracy: 89.50
Round  56, Global train loss: 1.502, Global test loss: 2.295, Global test accuracy: 12.53
Round  57, Train loss: 1.500, Test loss: 1.569, Test accuracy: 89.51
Round  57, Global train loss: 1.500, Global test loss: 2.313, Global test accuracy: 13.20
Round  58, Train loss: 1.472, Test loss: 1.569, Test accuracy: 89.54
Round  58, Global train loss: 1.472, Global test loss: 2.263, Global test accuracy: 16.95
Round  59, Train loss: 1.471, Test loss: 1.569, Test accuracy: 89.54
Round  59, Global train loss: 1.471, Global test loss: 2.284, Global test accuracy: 15.22
Round  60, Train loss: 1.566, Test loss: 1.569, Test accuracy: 89.52
Round  60, Global train loss: 1.566, Global test loss: 2.297, Global test accuracy: 12.60
Round  61, Train loss: 1.500, Test loss: 1.569, Test accuracy: 89.50
Round  61, Global train loss: 1.500, Global test loss: 2.272, Global test accuracy: 16.30
Round  62, Train loss: 1.536, Test loss: 1.569, Test accuracy: 89.52
Round  62, Global train loss: 1.536, Global test loss: 2.295, Global test accuracy: 13.79
Round  63, Train loss: 1.535, Test loss: 1.568, Test accuracy: 89.55
Round  63, Global train loss: 1.535, Global test loss: 2.282, Global test accuracy: 14.75
Round  64, Train loss: 1.565, Test loss: 1.568, Test accuracy: 89.58
Round  64, Global train loss: 1.565, Global test loss: 2.283, Global test accuracy: 15.42
Round  65, Train loss: 1.469, Test loss: 1.568, Test accuracy: 89.56
Round  65, Global train loss: 1.469, Global test loss: 2.265, Global test accuracy: 17.37
Round  66, Train loss: 1.503, Test loss: 1.568, Test accuracy: 89.57
Round  66, Global train loss: 1.503, Global test loss: 2.277, Global test accuracy: 15.44
Round  67, Train loss: 1.501, Test loss: 1.568, Test accuracy: 89.58
Round  67, Global train loss: 1.501, Global test loss: 2.295, Global test accuracy: 12.81
Round  68, Train loss: 1.503, Test loss: 1.568, Test accuracy: 89.56
Round  68, Global train loss: 1.503, Global test loss: 2.274, Global test accuracy: 16.14
Round  69, Train loss: 1.503, Test loss: 1.568, Test accuracy: 89.56
Round  69, Global train loss: 1.503, Global test loss: 2.294, Global test accuracy: 14.52
Round  70, Train loss: 1.565, Test loss: 1.568, Test accuracy: 89.59
Round  70, Global train loss: 1.565, Global test loss: 2.268, Global test accuracy: 18.06
Round  71, Train loss: 1.467, Test loss: 1.568, Test accuracy: 89.60
Round  71, Global train loss: 1.467, Global test loss: 2.291, Global test accuracy: 14.38
Round  72, Train loss: 1.535, Test loss: 1.568, Test accuracy: 89.62
Round  72, Global train loss: 1.535, Global test loss: 2.289, Global test accuracy: 14.99
Round  73, Train loss: 1.472, Test loss: 1.568, Test accuracy: 89.59
Round  73, Global train loss: 1.472, Global test loss: 2.323, Global test accuracy: 12.10
Round  74, Train loss: 1.499, Test loss: 1.568, Test accuracy: 89.59
Round  74, Global train loss: 1.499, Global test loss: 2.267, Global test accuracy: 16.62
Round  75, Train loss: 1.469, Test loss: 1.568, Test accuracy: 89.60
Round  75, Global train loss: 1.469, Global test loss: 2.303, Global test accuracy: 13.51
Round  76, Train loss: 1.469, Test loss: 1.568, Test accuracy: 89.62
Round  76, Global train loss: 1.469, Global test loss: 2.272, Global test accuracy: 18.17
Round  77, Train loss: 1.470, Test loss: 1.568, Test accuracy: 89.63
Round  77, Global train loss: 1.470, Global test loss: 2.288, Global test accuracy: 15.81
Round  78, Train loss: 1.500, Test loss: 1.568, Test accuracy: 89.60
Round  78, Global train loss: 1.500, Global test loss: 2.306, Global test accuracy: 13.44
Round  79, Train loss: 1.564, Test loss: 1.568, Test accuracy: 89.63
Round  79, Global train loss: 1.564, Global test loss: 2.276, Global test accuracy: 15.29
Round  80, Train loss: 1.565, Test loss: 1.568, Test accuracy: 89.64
Round  80, Global train loss: 1.565, Global test loss: 2.270, Global test accuracy: 17.07
Round  81, Train loss: 1.533, Test loss: 1.568, Test accuracy: 89.63
Round  81, Global train loss: 1.533, Global test loss: 2.272, Global test accuracy: 15.54
Round  82, Train loss: 1.503, Test loss: 1.568, Test accuracy: 89.63
Round  82, Global train loss: 1.503, Global test loss: 2.319, Global test accuracy: 12.32
Round  83, Train loss: 1.530, Test loss: 1.568, Test accuracy: 89.63
Round  83, Global train loss: 1.530, Global test loss: 2.279, Global test accuracy: 16.11
Round  84, Train loss: 1.468, Test loss: 1.567, Test accuracy: 89.63
Round  84, Global train loss: 1.468, Global test loss: 2.283, Global test accuracy: 15.06
Round  85, Train loss: 1.532, Test loss: 1.567, Test accuracy: 89.64
Round  85, Global train loss: 1.532, Global test loss: 2.278, Global test accuracy: 16.90
Round  86, Train loss: 1.501, Test loss: 1.567, Test accuracy: 89.61
Round  86, Global train loss: 1.501, Global test loss: 2.307, Global test accuracy: 13.56
Round  87, Train loss: 1.564, Test loss: 1.567, Test accuracy: 89.61
Round  87, Global train loss: 1.564, Global test loss: 2.317, Global test accuracy: 12.44
Round  88, Train loss: 1.502, Test loss: 1.567, Test accuracy: 89.61
Round  88, Global train loss: 1.502, Global test loss: 2.311, Global test accuracy: 14.10
Round  89, Train loss: 1.564, Test loss: 1.567, Test accuracy: 89.63
Round  89, Global train loss: 1.564, Global test loss: 2.291, Global test accuracy: 13.90
Round  90, Train loss: 1.502, Test loss: 1.567, Test accuracy: 89.62
Round  90, Global train loss: 1.502, Global test loss: 2.310, Global test accuracy: 13.10
Round  91, Train loss: 1.563, Test loss: 1.567, Test accuracy: 89.64
Round  91, Global train loss: 1.563, Global test loss: 2.285, Global test accuracy: 13.79
Round  92, Train loss: 1.501, Test loss: 1.567, Test accuracy: 89.64
Round  92, Global train loss: 1.501, Global test loss: 2.262, Global test accuracy: 17.45
Round  93, Train loss: 1.502, Test loss: 1.567, Test accuracy: 89.63
Round  93, Global train loss: 1.502, Global test loss: 2.261, Global test accuracy: 17.95
Round  94, Train loss: 1.502, Test loss: 1.567, Test accuracy: 89.64
Round  94, Global train loss: 1.502, Global test loss: 2.299, Global test accuracy: 13.63
Round  95, Train loss: 1.543, Test loss: 1.560, Test accuracy: 90.45
Round  95, Global train loss: 1.543, Global test loss: 2.262, Global test accuracy: 17.67/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.504, Test loss: 1.560, Test accuracy: 90.43
Round  96, Global train loss: 1.504, Global test loss: 2.305, Global test accuracy: 11.96
Round  97, Train loss: 1.469, Test loss: 1.560, Test accuracy: 90.43
Round  97, Global train loss: 1.469, Global test loss: 2.286, Global test accuracy: 13.72
Round  98, Train loss: 1.503, Test loss: 1.560, Test accuracy: 90.42
Round  98, Global train loss: 1.503, Global test loss: 2.289, Global test accuracy: 14.17
Round  99, Train loss: 1.469, Test loss: 1.560, Test accuracy: 90.42
Round  99, Global train loss: 1.469, Global test loss: 2.265, Global test accuracy: 18.04
Final Round, Train loss: 1.498, Test loss: 1.560, Test accuracy: 90.36
Final Round, Global train loss: 1.498, Global test loss: 2.265, Global test accuracy: 18.04
Average accuracy final 10 rounds: 90.03200000000001 

Average global accuracy final 10 rounds: 15.148 

1254.861793756485
[0.9263608455657959, 1.8527216911315918, 2.6612582206726074, 3.469794750213623, 4.2687060832977295, 5.067617416381836, 5.883612394332886, 6.6996073722839355, 7.464804649353027, 8.23000192642212, 8.996843099594116, 9.763684272766113, 10.607725143432617, 11.451766014099121, 12.249724864959717, 13.047683715820312, 13.821236848831177, 14.594789981842041, 15.366904973983765, 16.13901996612549, 16.876878261566162, 17.614736557006836, 18.366371631622314, 19.118006706237793, 19.866672039031982, 20.615337371826172, 21.54092025756836, 22.466503143310547, 23.408093452453613, 24.34968376159668, 25.156493663787842, 25.963303565979004, 26.749897003173828, 27.536490440368652, 28.341280460357666, 29.14607048034668, 29.958319902420044, 30.770569324493408, 31.565901517868042, 32.361233711242676, 33.11971068382263, 33.87818765640259, 34.760658740997314, 35.64312982559204, 36.41603970527649, 37.18894958496094, 38.06521153450012, 38.94147348403931, 40.083274841308594, 41.22507619857788, 42.00190305709839, 42.7787299156189, 43.57000207901001, 44.36127424240112, 45.18579030036926, 46.0103063583374, 46.78925633430481, 47.56820631027222, 48.357699394226074, 49.14719247817993, 49.971293210983276, 50.79539394378662, 51.535829067230225, 52.27626419067383, 53.02591943740845, 53.775574684143066, 54.512277364730835, 55.2489800453186, 55.984907388687134, 56.720834732055664, 57.43951630592346, 58.15819787979126, 58.90137505531311, 59.64455223083496, 60.39560532569885, 61.146658420562744, 61.873642921447754, 62.600627422332764, 63.32198762893677, 64.04334783554077, 64.7528305053711, 65.46231317520142, 66.22027659416199, 66.97824001312256, 67.72960567474365, 68.48097133636475, 69.22220730781555, 69.96344327926636, 70.67605495452881, 71.38866662979126, 72.15541887283325, 72.92217111587524, 73.68553137779236, 74.44889163970947, 75.17467474937439, 75.9004578590393, 76.6441080570221, 77.38775825500488, 78.11864852905273, 78.84953880310059, 79.6066381931305, 80.3637375831604, 81.12668371200562, 81.88962984085083, 82.6678216457367, 83.44601345062256, 84.21053791046143, 84.9750623703003, 85.7302770614624, 86.48549175262451, 87.24489259719849, 88.00429344177246, 88.76454639434814, 89.52479934692383, 90.29006433486938, 91.05532932281494, 91.8198094367981, 92.58428955078125, 93.31952285766602, 94.05475616455078, 94.7646598815918, 95.47456359863281, 96.22408390045166, 96.97360420227051, 97.73739004135132, 98.50117588043213, 99.25618886947632, 100.01120185852051, 100.74846696853638, 101.48573207855225, 102.23179459571838, 102.97785711288452, 103.75058889389038, 104.52332067489624, 105.30239367485046, 106.08146667480469, 106.85721015930176, 107.63295364379883, 108.37910985946655, 109.12526607513428, 109.8492021560669, 110.57313823699951, 111.33511924743652, 112.09710025787354, 112.86967182159424, 113.64224338531494, 114.40193963050842, 115.1616358757019, 115.90532350540161, 116.64901113510132, 117.37363600730896, 118.0982608795166, 118.87833666801453, 119.65841245651245, 120.4342908859253, 121.21016931533813, 121.9811270236969, 122.75208473205566, 123.51562476158142, 124.27916479110718, 125.02810192108154, 125.77703905105591, 126.55033159255981, 127.32362413406372, 128.10452580451965, 128.8854274749756, 129.66445136070251, 130.44347524642944, 131.2060685157776, 131.96866178512573, 132.7219226360321, 133.47518348693848, 134.2175030708313, 134.95982265472412, 135.72028255462646, 136.4807424545288, 137.23466753959656, 137.9885926246643, 138.71714425086975, 139.4456958770752, 140.18740105628967, 140.92910623550415, 141.67903900146484, 142.42897176742554, 143.20160365104675, 143.97423553466797, 144.74534344673157, 145.51645135879517, 146.29019045829773, 147.0639295578003, 147.82398414611816, 148.58403873443604, 149.33529710769653, 150.08655548095703, 150.83784747123718, 151.58913946151733, 152.34854936599731, 153.1079592704773, 153.88679671287537, 154.66563415527344, 156.24084544181824, 157.81605672836304]
[18.6, 18.6, 23.7, 23.7, 35.68, 35.68, 45.47, 45.47, 56.85, 56.85, 62.0, 62.0, 68.29, 68.29, 70.55, 70.55, 76.37, 76.37, 79.08, 79.08, 79.9, 79.9, 83.41, 83.41, 83.78, 83.78, 84.53, 84.53, 84.6, 84.6, 84.53, 84.53, 84.63, 84.63, 85.21, 85.21, 85.82, 85.82, 85.79, 85.79, 86.35, 86.35, 86.45, 86.45, 86.75, 86.75, 87.7, 87.7, 87.82, 87.82, 87.88, 87.88, 87.89, 87.89, 87.97, 87.97, 88.12, 88.12, 88.08, 88.08, 88.07, 88.07, 88.1, 88.1, 88.09, 88.09, 88.08, 88.08, 88.5, 88.5, 88.47, 88.47, 88.48, 88.48, 88.5, 88.5, 88.47, 88.47, 88.61, 88.61, 88.59, 88.59, 89.35, 89.35, 89.46, 89.46, 89.45, 89.45, 89.43, 89.43, 89.47, 89.47, 89.51, 89.51, 89.55, 89.55, 89.58, 89.58, 89.61, 89.61, 89.54, 89.54, 89.53, 89.53, 89.53, 89.53, 89.5, 89.5, 89.5, 89.5, 89.49, 89.49, 89.5, 89.5, 89.51, 89.51, 89.54, 89.54, 89.54, 89.54, 89.52, 89.52, 89.5, 89.5, 89.52, 89.52, 89.55, 89.55, 89.58, 89.58, 89.56, 89.56, 89.57, 89.57, 89.58, 89.58, 89.56, 89.56, 89.56, 89.56, 89.59, 89.59, 89.6, 89.6, 89.62, 89.62, 89.59, 89.59, 89.59, 89.59, 89.6, 89.6, 89.62, 89.62, 89.63, 89.63, 89.6, 89.6, 89.63, 89.63, 89.64, 89.64, 89.63, 89.63, 89.63, 89.63, 89.63, 89.63, 89.63, 89.63, 89.64, 89.64, 89.61, 89.61, 89.61, 89.61, 89.61, 89.61, 89.63, 89.63, 89.62, 89.62, 89.64, 89.64, 89.64, 89.64, 89.63, 89.63, 89.64, 89.64, 90.45, 90.45, 90.43, 90.43, 90.43, 90.43, 90.42, 90.42, 90.42, 90.42, 90.36, 90.36]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.289, Test loss: 2.293, Test accuracy: 14.57
Round   0, Global train loss: 2.289, Global test loss: 2.302, Global test accuracy: 11.60
Round   1, Train loss: 2.260, Test loss: 2.261, Test accuracy: 20.84
Round   1, Global train loss: 2.260, Global test loss: 2.299, Global test accuracy: 11.00
Round   2, Train loss: 2.147, Test loss: 2.186, Test accuracy: 29.46
Round   2, Global train loss: 2.147, Global test loss: 2.289, Global test accuracy: 14.47
Round   3, Train loss: 2.055, Test loss: 2.087, Test accuracy: 40.29
Round   3, Global train loss: 2.055, Global test loss: 2.310, Global test accuracy: 11.23
Round   4, Train loss: 2.040, Test loss: 1.988, Test accuracy: 51.97
Round   4, Global train loss: 2.040, Global test loss: 2.273, Global test accuracy: 16.09
Round   5, Train loss: 1.912, Test loss: 1.944, Test accuracy: 56.48
Round   5, Global train loss: 1.912, Global test loss: 2.269, Global test accuracy: 17.40
Round   6, Train loss: 1.884, Test loss: 1.920, Test accuracy: 58.27
Round   6, Global train loss: 1.884, Global test loss: 2.271, Global test accuracy: 16.22
Round   7, Train loss: 1.890, Test loss: 1.880, Test accuracy: 62.37
Round   7, Global train loss: 1.890, Global test loss: 2.257, Global test accuracy: 17.27
Round   8, Train loss: 1.859, Test loss: 1.870, Test accuracy: 62.77
Round   8, Global train loss: 1.859, Global test loss: 2.245, Global test accuracy: 19.96
Round   9, Train loss: 1.897, Test loss: 1.882, Test accuracy: 61.23
Round   9, Global train loss: 1.897, Global test loss: 2.254, Global test accuracy: 18.01
Round  10, Train loss: 1.809, Test loss: 1.866, Test accuracy: 61.67
Round  10, Global train loss: 1.809, Global test loss: 2.263, Global test accuracy: 16.79
Round  11, Train loss: 1.913, Test loss: 1.855, Test accuracy: 62.69
Round  11, Global train loss: 1.913, Global test loss: 2.263, Global test accuracy: 17.14
Round  12, Train loss: 1.849, Test loss: 1.839, Test accuracy: 63.65
Round  12, Global train loss: 1.849, Global test loss: 2.268, Global test accuracy: 17.17
Round  13, Train loss: 1.816, Test loss: 1.821, Test accuracy: 64.36
Round  13, Global train loss: 1.816, Global test loss: 2.250, Global test accuracy: 19.18
Round  14, Train loss: 1.842, Test loss: 1.821, Test accuracy: 64.45
Round  14, Global train loss: 1.842, Global test loss: 2.245, Global test accuracy: 19.59
Round  15, Train loss: 1.846, Test loss: 1.822, Test accuracy: 64.34
Round  15, Global train loss: 1.846, Global test loss: 2.259, Global test accuracy: 17.47
Round  16, Train loss: 1.858, Test loss: 1.821, Test accuracy: 64.50
Round  16, Global train loss: 1.858, Global test loss: 2.258, Global test accuracy: 18.02
Round  17, Train loss: 1.815, Test loss: 1.810, Test accuracy: 65.50
Round  17, Global train loss: 1.815, Global test loss: 2.237, Global test accuracy: 20.26
Round  18, Train loss: 1.793, Test loss: 1.808, Test accuracy: 65.58
Round  18, Global train loss: 1.793, Global test loss: 2.238, Global test accuracy: 20.36
Round  19, Train loss: 1.951, Test loss: 1.806, Test accuracy: 65.77
Round  19, Global train loss: 1.951, Global test loss: 2.262, Global test accuracy: 17.46
Round  20, Train loss: 1.851, Test loss: 1.806, Test accuracy: 65.79
Round  20, Global train loss: 1.851, Global test loss: 2.243, Global test accuracy: 19.89
Round  21, Train loss: 1.763, Test loss: 1.806, Test accuracy: 65.63
Round  21, Global train loss: 1.763, Global test loss: 2.249, Global test accuracy: 19.27
Round  22, Train loss: 1.926, Test loss: 1.807, Test accuracy: 65.47
Round  22, Global train loss: 1.926, Global test loss: 2.244, Global test accuracy: 18.79
Round  23, Train loss: 1.843, Test loss: 1.809, Test accuracy: 65.32
Round  23, Global train loss: 1.843, Global test loss: 2.237, Global test accuracy: 20.27
Round  24, Train loss: 1.858, Test loss: 1.809, Test accuracy: 65.30
Round  24, Global train loss: 1.858, Global test loss: 2.239, Global test accuracy: 20.34
Round  25, Train loss: 1.800, Test loss: 1.816, Test accuracy: 64.40
Round  25, Global train loss: 1.800, Global test loss: 2.268, Global test accuracy: 17.48
Round  26, Train loss: 1.846, Test loss: 1.808, Test accuracy: 65.26
Round  26, Global train loss: 1.846, Global test loss: 2.236, Global test accuracy: 20.84
Round  27, Train loss: 1.766, Test loss: 1.809, Test accuracy: 65.27
Round  27, Global train loss: 1.766, Global test loss: 2.253, Global test accuracy: 18.57
Round  28, Train loss: 1.796, Test loss: 1.809, Test accuracy: 65.23
Round  28, Global train loss: 1.796, Global test loss: 2.252, Global test accuracy: 19.44
Round  29, Train loss: 1.880, Test loss: 1.809, Test accuracy: 65.22
Round  29, Global train loss: 1.880, Global test loss: 2.231, Global test accuracy: 21.35
Round  30, Train loss: 1.773, Test loss: 1.811, Test accuracy: 64.96
Round  30, Global train loss: 1.773, Global test loss: 2.232, Global test accuracy: 21.71
Round  31, Train loss: 1.766, Test loss: 1.800, Test accuracy: 66.04
Round  31, Global train loss: 1.766, Global test loss: 2.231, Global test accuracy: 21.39
Round  32, Train loss: 1.810, Test loss: 1.800, Test accuracy: 66.06
Round  32, Global train loss: 1.810, Global test loss: 2.238, Global test accuracy: 21.14
Round  33, Train loss: 1.828, Test loss: 1.799, Test accuracy: 66.10
Round  33, Global train loss: 1.828, Global test loss: 2.237, Global test accuracy: 21.00
Round  34, Train loss: 1.919, Test loss: 1.808, Test accuracy: 65.24
Round  34, Global train loss: 1.919, Global test loss: 2.276, Global test accuracy: 16.71
Round  35, Train loss: 1.839, Test loss: 1.799, Test accuracy: 66.18
Round  35, Global train loss: 1.839, Global test loss: 2.227, Global test accuracy: 21.79
Round  36, Train loss: 1.863, Test loss: 1.809, Test accuracy: 65.17
Round  36, Global train loss: 1.863, Global test loss: 2.262, Global test accuracy: 17.99
Round  37, Train loss: 1.783, Test loss: 1.809, Test accuracy: 65.15
Round  37, Global train loss: 1.783, Global test loss: 2.261, Global test accuracy: 18.20
Round  38, Train loss: 1.793, Test loss: 1.817, Test accuracy: 64.30
Round  38, Global train loss: 1.793, Global test loss: 2.243, Global test accuracy: 20.52
Round  39, Train loss: 1.852, Test loss: 1.816, Test accuracy: 64.40
Round  39, Global train loss: 1.852, Global test loss: 2.240, Global test accuracy: 20.53
Round  40, Train loss: 1.753, Test loss: 1.816, Test accuracy: 64.48
Round  40, Global train loss: 1.753, Global test loss: 2.247, Global test accuracy: 20.06
Round  41, Train loss: 1.752, Test loss: 1.815, Test accuracy: 64.48
Round  41, Global train loss: 1.752, Global test loss: 2.255, Global test accuracy: 18.53
Round  42, Train loss: 1.781, Test loss: 1.815, Test accuracy: 64.49
Round  42, Global train loss: 1.781, Global test loss: 2.273, Global test accuracy: 16.86
Round  43, Train loss: 1.806, Test loss: 1.810, Test accuracy: 65.08
Round  43, Global train loss: 1.806, Global test loss: 2.228, Global test accuracy: 21.77
Round  44, Train loss: 1.825, Test loss: 1.814, Test accuracy: 64.59
Round  44, Global train loss: 1.825, Global test loss: 2.241, Global test accuracy: 20.22
Round  45, Train loss: 1.847, Test loss: 1.800, Test accuracy: 65.97
Round  45, Global train loss: 1.847, Global test loss: 2.217, Global test accuracy: 23.24
Round  46, Train loss: 1.912, Test loss: 1.799, Test accuracy: 66.08
Round  46, Global train loss: 1.912, Global test loss: 2.258, Global test accuracy: 18.88
Round  47, Train loss: 1.917, Test loss: 1.816, Test accuracy: 64.31
Round  47, Global train loss: 1.917, Global test loss: 2.245, Global test accuracy: 19.21
Round  48, Train loss: 1.764, Test loss: 1.803, Test accuracy: 65.67
Round  48, Global train loss: 1.764, Global test loss: 2.235, Global test accuracy: 20.99
Round  49, Train loss: 1.751, Test loss: 1.803, Test accuracy: 65.72
Round  49, Global train loss: 1.751, Global test loss: 2.230, Global test accuracy: 21.90
Round  50, Train loss: 1.845, Test loss: 1.802, Test accuracy: 65.69
Round  50, Global train loss: 1.845, Global test loss: 2.241, Global test accuracy: 20.18
Round  51, Train loss: 1.820, Test loss: 1.802, Test accuracy: 65.66
Round  51, Global train loss: 1.820, Global test loss: 2.265, Global test accuracy: 17.94
Round  52, Train loss: 1.839, Test loss: 1.806, Test accuracy: 65.24
Round  52, Global train loss: 1.839, Global test loss: 2.250, Global test accuracy: 19.46
Round  53, Train loss: 1.782, Test loss: 1.806, Test accuracy: 65.25
Round  53, Global train loss: 1.782, Global test loss: 2.241, Global test accuracy: 20.15
Round  54, Train loss: 1.763, Test loss: 1.807, Test accuracy: 65.09
Round  54, Global train loss: 1.763, Global test loss: 2.243, Global test accuracy: 19.47
Round  55, Train loss: 1.817, Test loss: 1.808, Test accuracy: 65.05
Round  55, Global train loss: 1.817, Global test loss: 2.239, Global test accuracy: 20.54
Round  56, Train loss: 1.796, Test loss: 1.801, Test accuracy: 65.83
Round  56, Global train loss: 1.796, Global test loss: 2.244, Global test accuracy: 19.89
Round  57, Train loss: 1.723, Test loss: 1.800, Test accuracy: 65.94
Round  57, Global train loss: 1.723, Global test loss: 2.257, Global test accuracy: 18.08
Round  58, Train loss: 1.753, Test loss: 1.796, Test accuracy: 66.41
Round  58, Global train loss: 1.753, Global test loss: 2.222, Global test accuracy: 23.18
Round  59, Train loss: 1.835, Test loss: 1.795, Test accuracy: 66.50
Round  59, Global train loss: 1.835, Global test loss: 2.256, Global test accuracy: 18.79
Round  60, Train loss: 1.910, Test loss: 1.794, Test accuracy: 66.60
Round  60, Global train loss: 1.910, Global test loss: 2.234, Global test accuracy: 21.21
Round  61, Train loss: 1.748, Test loss: 1.800, Test accuracy: 65.85
Round  61, Global train loss: 1.748, Global test loss: 2.234, Global test accuracy: 21.28
Round  62, Train loss: 1.703, Test loss: 1.798, Test accuracy: 65.98
Round  62, Global train loss: 1.703, Global test loss: 2.235, Global test accuracy: 20.97
Round  63, Train loss: 1.715, Test loss: 1.783, Test accuracy: 67.65
Round  63, Global train loss: 1.715, Global test loss: 2.211, Global test accuracy: 24.18
Round  64, Train loss: 1.789, Test loss: 1.782, Test accuracy: 67.72
Round  64, Global train loss: 1.789, Global test loss: 2.243, Global test accuracy: 20.19
Round  65, Train loss: 1.785, Test loss: 1.790, Test accuracy: 66.90
Round  65, Global train loss: 1.785, Global test loss: 2.245, Global test accuracy: 20.13
Round  66, Train loss: 1.700, Test loss: 1.790, Test accuracy: 66.90
Round  66, Global train loss: 1.700, Global test loss: 2.243, Global test accuracy: 19.57
Round  67, Train loss: 1.799, Test loss: 1.790, Test accuracy: 66.78
Round  67, Global train loss: 1.799, Global test loss: 2.266, Global test accuracy: 17.13
Round  68, Train loss: 1.817, Test loss: 1.790, Test accuracy: 66.78
Round  68, Global train loss: 1.817, Global test loss: 2.235, Global test accuracy: 20.85
Round  69, Train loss: 1.869, Test loss: 1.782, Test accuracy: 67.62
Round  69, Global train loss: 1.869, Global test loss: 2.271, Global test accuracy: 16.50
Round  70, Train loss: 1.774, Test loss: 1.781, Test accuracy: 67.71
Round  70, Global train loss: 1.774, Global test loss: 2.234, Global test accuracy: 21.00
Round  71, Train loss: 1.742, Test loss: 1.781, Test accuracy: 67.84
Round  71, Global train loss: 1.742, Global test loss: 2.244, Global test accuracy: 20.01
Round  72, Train loss: 1.738, Test loss: 1.780, Test accuracy: 67.97
Round  72, Global train loss: 1.738, Global test loss: 2.227, Global test accuracy: 21.90
Round  73, Train loss: 1.711, Test loss: 1.779, Test accuracy: 68.03
Round  73, Global train loss: 1.711, Global test loss: 2.214, Global test accuracy: 23.62
Round  74, Train loss: 1.775, Test loss: 1.771, Test accuracy: 68.75
Round  74, Global train loss: 1.775, Global test loss: 2.245, Global test accuracy: 20.02
Round  75, Train loss: 1.738, Test loss: 1.773, Test accuracy: 68.61
Round  75, Global train loss: 1.738, Global test loss: 2.221, Global test accuracy: 22.30
Round  76, Train loss: 1.783, Test loss: 1.775, Test accuracy: 68.59
Round  76, Global train loss: 1.783, Global test loss: 2.230, Global test accuracy: 21.89
Round  77, Train loss: 1.647, Test loss: 1.776, Test accuracy: 68.55
Round  77, Global train loss: 1.647, Global test loss: 2.220, Global test accuracy: 23.15
Round  78, Train loss: 1.871, Test loss: 1.773, Test accuracy: 68.68
Round  78, Global train loss: 1.871, Global test loss: 2.222, Global test accuracy: 22.38
Round  79, Train loss: 1.777, Test loss: 1.773, Test accuracy: 68.67
Round  79, Global train loss: 1.777, Global test loss: 2.226, Global test accuracy: 22.18
Round  80, Train loss: 1.771, Test loss: 1.773, Test accuracy: 68.73
Round  80, Global train loss: 1.771, Global test loss: 2.236, Global test accuracy: 20.82
Round  81, Train loss: 1.843, Test loss: 1.773, Test accuracy: 68.72
Round  81, Global train loss: 1.843, Global test loss: 2.250, Global test accuracy: 19.20
Round  82, Train loss: 1.778, Test loss: 1.772, Test accuracy: 68.78
Round  82, Global train loss: 1.778, Global test loss: 2.263, Global test accuracy: 17.53
Round  83, Train loss: 1.763, Test loss: 1.772, Test accuracy: 68.76
Round  83, Global train loss: 1.763, Global test loss: 2.250, Global test accuracy: 19.54
Round  84, Train loss: 1.842, Test loss: 1.772, Test accuracy: 68.75
Round  84, Global train loss: 1.842, Global test loss: 2.232, Global test accuracy: 21.75
Round  85, Train loss: 1.774, Test loss: 1.772, Test accuracy: 68.83
Round  85, Global train loss: 1.774, Global test loss: 2.224, Global test accuracy: 22.55
Round  86, Train loss: 1.763, Test loss: 1.772, Test accuracy: 68.64
Round  86, Global train loss: 1.763, Global test loss: 2.235, Global test accuracy: 21.44
Round  87, Train loss: 1.744, Test loss: 1.773, Test accuracy: 68.69
Round  87, Global train loss: 1.744, Global test loss: 2.226, Global test accuracy: 22.63
Round  88, Train loss: 1.762, Test loss: 1.772, Test accuracy: 68.73
Round  88, Global train loss: 1.762, Global test loss: 2.224, Global test accuracy: 22.25
Round  89, Train loss: 1.745, Test loss: 1.773, Test accuracy: 68.55
Round  89, Global train loss: 1.745, Global test loss: 2.245, Global test accuracy: 19.83
Round  90, Train loss: 1.758, Test loss: 1.773, Test accuracy: 68.49
Round  90, Global train loss: 1.758, Global test loss: 2.249, Global test accuracy: 19.46
Round  91, Train loss: 1.711, Test loss: 1.772, Test accuracy: 68.68
Round  91, Global train loss: 1.711, Global test loss: 2.229, Global test accuracy: 21.93
Round  92, Train loss: 1.881, Test loss: 1.763, Test accuracy: 69.61
Round  92, Global train loss: 1.881, Global test loss: 2.231, Global test accuracy: 21.51
Round  93, Train loss: 1.808, Test loss: 1.772, Test accuracy: 68.67
Round  93, Global train loss: 1.808, Global test loss: 2.260, Global test accuracy: 18.19
Round  94, Train loss: 1.793, Test loss: 1.781, Test accuracy: 67.74
Round  94, Global train loss: 1.793, Global test loss: 2.269, Global test accuracy: 17.21
Round  95, Train loss: 1.769, Test loss: 1.781, Test accuracy: 67.74
Round  95, Global train loss: 1.769, Global test loss: 2.235, Global test accuracy: 20.84/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.817, Test loss: 1.781, Test accuracy: 67.73
Round  96, Global train loss: 1.817, Global test loss: 2.250, Global test accuracy: 18.99
Round  97, Train loss: 1.867, Test loss: 1.770, Test accuracy: 68.76
Round  97, Global train loss: 1.867, Global test loss: 2.240, Global test accuracy: 20.53
Round  98, Train loss: 1.746, Test loss: 1.770, Test accuracy: 68.86
Round  98, Global train loss: 1.746, Global test loss: 2.242, Global test accuracy: 20.07
Round  99, Train loss: 1.737, Test loss: 1.770, Test accuracy: 68.85
Round  99, Global train loss: 1.737, Global test loss: 2.249, Global test accuracy: 18.85
Final Round, Train loss: 1.739, Test loss: 1.763, Test accuracy: 69.62
Final Round, Global train loss: 1.739, Global test loss: 2.249, Global test accuracy: 18.85
Average accuracy final 10 rounds: 68.513 

Average global accuracy final 10 rounds: 19.758000000000003 

1244.9436304569244
[0.928788423538208, 1.857576847076416, 2.624882459640503, 3.39218807220459, 4.184173583984375, 4.97615909576416, 5.742537021636963, 6.508914947509766, 7.269377708435059, 8.029840469360352, 8.76841139793396, 9.506982326507568, 10.29507851600647, 11.083174705505371, 11.874872922897339, 12.666571140289307, 13.50081467628479, 14.335058212280273, 15.104574918746948, 15.874091625213623, 16.627638816833496, 17.38118600845337, 18.142771244049072, 18.904356479644775, 19.690072536468506, 20.475788593292236, 21.260633945465088, 22.04547929763794, 22.82680368423462, 23.6081280708313, 24.383388996124268, 25.158649921417236, 25.910534381866455, 26.662418842315674, 27.453027486801147, 28.24363613128662, 29.0203959941864, 29.79715585708618, 30.75548791885376, 31.713819980621338, 32.566293239593506, 33.418766498565674, 34.17675280570984, 34.934739112854004, 35.70481324195862, 36.47488737106323, 37.25910782814026, 38.043328285217285, 38.827006578445435, 39.610684871673584, 40.390718936920166, 41.17075300216675, 42.041083097457886, 42.91141319274902, 43.76757454872131, 44.6237359046936, 45.53755331039429, 46.45137071609497, 47.35953712463379, 48.26770353317261, 49.20155143737793, 50.13539934158325, 51.03725242614746, 51.93910551071167, 52.84374284744263, 53.748380184173584, 54.654884338378906, 55.56138849258423, 56.30810475349426, 57.0548210144043, 57.840100049972534, 58.62537908554077, 59.38695502281189, 60.14853096008301, 60.90127658843994, 61.654022216796875, 62.40413856506348, 63.15425491333008, 63.93883395195007, 64.72341299057007, 65.50773620605469, 66.2920594215393, 67.06962370872498, 67.84718799591064, 68.62033271789551, 69.39347743988037, 70.13925123214722, 70.88502502441406, 71.62644529342651, 72.36786556243896, 73.1296865940094, 73.89150762557983, 74.64808917045593, 75.40467071533203, 76.14659929275513, 76.88852787017822, 77.61975073814392, 78.35097360610962, 79.11861276626587, 79.88625192642212, 80.66320443153381, 81.44015693664551, 82.21497702598572, 82.98979711532593, 83.76728677749634, 84.54477643966675, 85.31145310401917, 86.07812976837158, 86.83001828193665, 87.58190679550171, 88.34705066680908, 89.11219453811646, 89.88063216209412, 90.64906978607178, 91.4184410572052, 92.18781232833862, 92.92474150657654, 93.66167068481445, 94.39908337593079, 95.13649606704712, 95.90615582466125, 96.67581558227539, 97.44863653182983, 98.22145748138428, 98.99787855148315, 99.77429962158203, 100.543386220932, 101.31247282028198, 102.08040571212769, 102.84833860397339, 103.6005871295929, 104.3528356552124, 105.10608148574829, 105.85932731628418, 106.62611627578735, 107.39290523529053, 108.13119649887085, 108.86948776245117, 109.60627722740173, 110.3430666923523, 111.0909571647644, 111.83884763717651, 112.60103869438171, 113.36322975158691, 114.09997963905334, 114.83672952651978, 115.60246801376343, 116.36820650100708, 117.11525869369507, 117.86231088638306, 118.60565972328186, 119.34900856018066, 120.07756018638611, 120.80611181259155, 121.5656111240387, 122.32511043548584, 123.08621430397034, 123.84731817245483, 124.59870314598083, 125.35008811950684, 126.09138417243958, 126.83268022537231, 127.54610872268677, 128.25953722000122, 129.01708602905273, 129.77463483810425, 130.5512354373932, 131.32783603668213, 132.09213519096375, 132.85643434524536, 133.59937143325806, 134.34230852127075, 135.09322595596313, 135.84414339065552, 136.58318257331848, 137.32222175598145, 138.0786635875702, 138.83510541915894, 139.58603191375732, 140.3369584083557, 141.08102464675903, 141.82509088516235, 142.55792784690857, 143.29076480865479, 144.0348436832428, 144.7789225578308, 145.54898524284363, 146.31904792785645, 147.09075140953064, 147.86245489120483, 148.62077832221985, 149.37910175323486, 150.12883305549622, 150.87856435775757, 151.60787653923035, 152.33718872070312, 153.07083749771118, 153.80448627471924, 154.5627191066742, 155.32095193862915, 156.8212447166443, 158.32153749465942]
[14.57, 14.57, 20.84, 20.84, 29.46, 29.46, 40.29, 40.29, 51.97, 51.97, 56.48, 56.48, 58.27, 58.27, 62.37, 62.37, 62.77, 62.77, 61.23, 61.23, 61.67, 61.67, 62.69, 62.69, 63.65, 63.65, 64.36, 64.36, 64.45, 64.45, 64.34, 64.34, 64.5, 64.5, 65.5, 65.5, 65.58, 65.58, 65.77, 65.77, 65.79, 65.79, 65.63, 65.63, 65.47, 65.47, 65.32, 65.32, 65.3, 65.3, 64.4, 64.4, 65.26, 65.26, 65.27, 65.27, 65.23, 65.23, 65.22, 65.22, 64.96, 64.96, 66.04, 66.04, 66.06, 66.06, 66.1, 66.1, 65.24, 65.24, 66.18, 66.18, 65.17, 65.17, 65.15, 65.15, 64.3, 64.3, 64.4, 64.4, 64.48, 64.48, 64.48, 64.48, 64.49, 64.49, 65.08, 65.08, 64.59, 64.59, 65.97, 65.97, 66.08, 66.08, 64.31, 64.31, 65.67, 65.67, 65.72, 65.72, 65.69, 65.69, 65.66, 65.66, 65.24, 65.24, 65.25, 65.25, 65.09, 65.09, 65.05, 65.05, 65.83, 65.83, 65.94, 65.94, 66.41, 66.41, 66.5, 66.5, 66.6, 66.6, 65.85, 65.85, 65.98, 65.98, 67.65, 67.65, 67.72, 67.72, 66.9, 66.9, 66.9, 66.9, 66.78, 66.78, 66.78, 66.78, 67.62, 67.62, 67.71, 67.71, 67.84, 67.84, 67.97, 67.97, 68.03, 68.03, 68.75, 68.75, 68.61, 68.61, 68.59, 68.59, 68.55, 68.55, 68.68, 68.68, 68.67, 68.67, 68.73, 68.73, 68.72, 68.72, 68.78, 68.78, 68.76, 68.76, 68.75, 68.75, 68.83, 68.83, 68.64, 68.64, 68.69, 68.69, 68.73, 68.73, 68.55, 68.55, 68.49, 68.49, 68.68, 68.68, 69.61, 69.61, 68.67, 68.67, 67.74, 67.74, 67.74, 67.74, 67.73, 67.73, 68.76, 68.76, 68.86, 68.86, 68.85, 68.85, 69.62, 69.62]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.302, Test accuracy: 13.35
Round   1, Train loss: 2.294, Test loss: 2.300, Test accuracy: 15.41
Round   2, Train loss: 2.283, Test loss: 2.295, Test accuracy: 14.42
Round   3, Train loss: 2.271, Test loss: 2.284, Test accuracy: 19.14
Round   4, Train loss: 2.232, Test loss: 2.262, Test accuracy: 19.67
Round   5, Train loss: 2.221, Test loss: 2.235, Test accuracy: 19.58
Round   6, Train loss: 2.160, Test loss: 2.205, Test accuracy: 23.62
Round   7, Train loss: 2.115, Test loss: 2.172, Test accuracy: 28.87
Round   8, Train loss: 2.032, Test loss: 2.132, Test accuracy: 34.55
Round   9, Train loss: 1.952, Test loss: 2.091, Test accuracy: 37.72
Round  10, Train loss: 2.028, Test loss: 2.055, Test accuracy: 41.60
Round  11, Train loss: 2.026, Test loss: 2.042, Test accuracy: 42.55
Round  12, Train loss: 1.895, Test loss: 1.996, Test accuracy: 47.37
Round  13, Train loss: 1.881, Test loss: 1.963, Test accuracy: 50.77
Round  14, Train loss: 1.910, Test loss: 1.932, Test accuracy: 54.14
Round  15, Train loss: 1.791, Test loss: 1.879, Test accuracy: 59.79
Round  16, Train loss: 1.803, Test loss: 1.867, Test accuracy: 60.86
Round  17, Train loss: 1.874, Test loss: 1.853, Test accuracy: 62.11
Round  18, Train loss: 1.878, Test loss: 1.843, Test accuracy: 62.91
Round  19, Train loss: 1.740, Test loss: 1.829, Test accuracy: 64.29
Round  20, Train loss: 1.790, Test loss: 1.813, Test accuracy: 65.94
Round  21, Train loss: 1.778, Test loss: 1.808, Test accuracy: 66.09
Round  22, Train loss: 1.739, Test loss: 1.797, Test accuracy: 67.21
Round  23, Train loss: 1.813, Test loss: 1.793, Test accuracy: 67.65
Round  24, Train loss: 1.775, Test loss: 1.793, Test accuracy: 67.76
Round  25, Train loss: 1.738, Test loss: 1.791, Test accuracy: 67.81
Round  26, Train loss: 1.735, Test loss: 1.785, Test accuracy: 68.26
Round  27, Train loss: 1.683, Test loss: 1.784, Test accuracy: 68.38
Round  28, Train loss: 1.816, Test loss: 1.783, Test accuracy: 68.37
Round  29, Train loss: 1.669, Test loss: 1.782, Test accuracy: 68.39
Round  30, Train loss: 1.750, Test loss: 1.775, Test accuracy: 69.04
Round  31, Train loss: 1.800, Test loss: 1.772, Test accuracy: 69.31
Round  32, Train loss: 1.780, Test loss: 1.765, Test accuracy: 69.99
Round  33, Train loss: 1.766, Test loss: 1.763, Test accuracy: 69.99
Round  34, Train loss: 1.698, Test loss: 1.762, Test accuracy: 70.19
Round  35, Train loss: 1.757, Test loss: 1.762, Test accuracy: 70.11
Round  36, Train loss: 1.703, Test loss: 1.760, Test accuracy: 70.28
Round  37, Train loss: 1.730, Test loss: 1.759, Test accuracy: 70.48
Round  38, Train loss: 1.760, Test loss: 1.759, Test accuracy: 70.42
Round  39, Train loss: 1.819, Test loss: 1.758, Test accuracy: 70.55
Round  40, Train loss: 1.760, Test loss: 1.758, Test accuracy: 70.61
Round  41, Train loss: 1.845, Test loss: 1.757, Test accuracy: 70.63
Round  42, Train loss: 1.788, Test loss: 1.757, Test accuracy: 70.76
Round  43, Train loss: 1.816, Test loss: 1.757, Test accuracy: 70.58
Round  44, Train loss: 1.665, Test loss: 1.756, Test accuracy: 70.81
Round  45, Train loss: 1.816, Test loss: 1.756, Test accuracy: 70.82
Round  46, Train loss: 1.743, Test loss: 1.755, Test accuracy: 70.85
Round  47, Train loss: 1.818, Test loss: 1.756, Test accuracy: 70.69
Round  48, Train loss: 1.733, Test loss: 1.749, Test accuracy: 71.55
Round  49, Train loss: 1.686, Test loss: 1.748, Test accuracy: 71.61
Round  50, Train loss: 1.748, Test loss: 1.745, Test accuracy: 71.74
Round  51, Train loss: 1.747, Test loss: 1.744, Test accuracy: 71.78
Round  52, Train loss: 1.683, Test loss: 1.744, Test accuracy: 71.87
Round  53, Train loss: 1.721, Test loss: 1.743, Test accuracy: 71.90
Round  54, Train loss: 1.624, Test loss: 1.743, Test accuracy: 72.03
Round  55, Train loss: 1.656, Test loss: 1.742, Test accuracy: 72.05
Round  56, Train loss: 1.712, Test loss: 1.741, Test accuracy: 72.12
Round  57, Train loss: 1.682, Test loss: 1.741, Test accuracy: 72.11
Round  58, Train loss: 1.709, Test loss: 1.740, Test accuracy: 72.13
Round  59, Train loss: 1.744, Test loss: 1.740, Test accuracy: 72.13
Round  60, Train loss: 1.710, Test loss: 1.741, Test accuracy: 72.14
Round  61, Train loss: 1.645, Test loss: 1.740, Test accuracy: 72.04
Round  62, Train loss: 1.676, Test loss: 1.740, Test accuracy: 72.04
Round  63, Train loss: 1.740, Test loss: 1.740, Test accuracy: 72.10
Round  64, Train loss: 1.745, Test loss: 1.740, Test accuracy: 72.14
Round  65, Train loss: 1.779, Test loss: 1.740, Test accuracy: 72.08
Round  66, Train loss: 1.771, Test loss: 1.740, Test accuracy: 72.05
Round  67, Train loss: 1.674, Test loss: 1.740, Test accuracy: 72.07
Round  68, Train loss: 1.676, Test loss: 1.740, Test accuracy: 72.16
Round  69, Train loss: 1.712, Test loss: 1.739, Test accuracy: 72.19
Round  70, Train loss: 1.712, Test loss: 1.739, Test accuracy: 72.24
Round  71, Train loss: 1.680, Test loss: 1.739, Test accuracy: 72.23
Round  72, Train loss: 1.686, Test loss: 1.730, Test accuracy: 73.10
Round  73, Train loss: 1.680, Test loss: 1.729, Test accuracy: 73.14
Round  74, Train loss: 1.678, Test loss: 1.729, Test accuracy: 73.08
Round  75, Train loss: 1.736, Test loss: 1.729, Test accuracy: 73.08
Round  76, Train loss: 1.770, Test loss: 1.729, Test accuracy: 73.09
Round  77, Train loss: 1.713, Test loss: 1.728, Test accuracy: 73.15
Round  78, Train loss: 1.710, Test loss: 1.728, Test accuracy: 73.23
Round  79, Train loss: 1.740, Test loss: 1.728, Test accuracy: 73.32
Round  80, Train loss: 1.740, Test loss: 1.727, Test accuracy: 73.25
Round  81, Train loss: 1.645, Test loss: 1.727, Test accuracy: 73.30
Round  82, Train loss: 1.756, Test loss: 1.725, Test accuracy: 73.55
Round  83, Train loss: 1.737, Test loss: 1.726, Test accuracy: 73.58
Round  84, Train loss: 1.709, Test loss: 1.725, Test accuracy: 73.58
Round  85, Train loss: 1.672, Test loss: 1.725, Test accuracy: 73.63
Round  86, Train loss: 1.679, Test loss: 1.718, Test accuracy: 74.34
Round  87, Train loss: 1.607, Test loss: 1.718, Test accuracy: 74.22
Round  88, Train loss: 1.679, Test loss: 1.718, Test accuracy: 74.36
Round  89, Train loss: 1.703, Test loss: 1.717, Test accuracy: 74.37
Round  90, Train loss: 1.643, Test loss: 1.717, Test accuracy: 74.35
Round  91, Train loss: 1.677, Test loss: 1.717, Test accuracy: 74.29
Round  92, Train loss: 1.672, Test loss: 1.717, Test accuracy: 74.24
Round  93, Train loss: 1.709, Test loss: 1.717, Test accuracy: 74.38
Round  94, Train loss: 1.676, Test loss: 1.717, Test accuracy: 74.36
Round  95, Train loss: 1.672, Test loss: 1.716, Test accuracy: 74.47
Round  96, Train loss: 1.705, Test loss: 1.716, Test accuracy: 74.46
Round  97, Train loss: 1.704, Test loss: 1.716, Test accuracy: 74.42
Round  98, Train loss: 1.703, Test loss: 1.716, Test accuracy: 74.37
Round  99, Train loss: 1.672, Test loss: 1.715, Test accuracy: 74.50
Round 100, Train loss: 1.701, Test loss: 1.715, Test accuracy: 74.49
Round 101, Train loss: 1.637, Test loss: 1.715, Test accuracy: 74.56
Round 102, Train loss: 1.737, Test loss: 1.715, Test accuracy: 74.47
Round 103, Train loss: 1.699, Test loss: 1.715, Test accuracy: 74.53
Round 104, Train loss: 1.770, Test loss: 1.715, Test accuracy: 74.59
Round 105, Train loss: 1.643, Test loss: 1.715, Test accuracy: 74.63
Round 106, Train loss: 1.673, Test loss: 1.715, Test accuracy: 74.65
Round 107, Train loss: 1.705, Test loss: 1.715, Test accuracy: 74.67
Round 108, Train loss: 1.701, Test loss: 1.715, Test accuracy: 74.62
Round 109, Train loss: 1.692, Test loss: 1.715, Test accuracy: 74.50
Round 110, Train loss: 1.673, Test loss: 1.715, Test accuracy: 74.56
Round 111, Train loss: 1.640, Test loss: 1.714, Test accuracy: 74.64
Round 112, Train loss: 1.704, Test loss: 1.713, Test accuracy: 74.73
Round 113, Train loss: 1.643, Test loss: 1.713, Test accuracy: 74.72
Round 114, Train loss: 1.671, Test loss: 1.713, Test accuracy: 74.75
Round 115, Train loss: 1.671, Test loss: 1.706, Test accuracy: 75.46
Round 116, Train loss: 1.705, Test loss: 1.706, Test accuracy: 75.54
Round 117, Train loss: 1.671, Test loss: 1.706, Test accuracy: 75.64
Round 118, Train loss: 1.672, Test loss: 1.705, Test accuracy: 75.63
Round 119, Train loss: 1.702, Test loss: 1.705, Test accuracy: 75.60
Round 120, Train loss: 1.669, Test loss: 1.705, Test accuracy: 75.54
Round 121, Train loss: 1.666, Test loss: 1.705, Test accuracy: 75.59
Round 122, Train loss: 1.669, Test loss: 1.705, Test accuracy: 75.58
Round 123, Train loss: 1.638, Test loss: 1.705, Test accuracy: 75.55
Round 124, Train loss: 1.638, Test loss: 1.705, Test accuracy: 75.59
Round 125, Train loss: 1.639, Test loss: 1.704, Test accuracy: 75.59
Round 126, Train loss: 1.706, Test loss: 1.705, Test accuracy: 75.56
Round 127, Train loss: 1.671, Test loss: 1.705, Test accuracy: 75.59
Round 128, Train loss: 1.669, Test loss: 1.705, Test accuracy: 75.58
Round 129, Train loss: 1.669, Test loss: 1.705, Test accuracy: 75.53
Round 130, Train loss: 1.671, Test loss: 1.705, Test accuracy: 75.47
Round 131, Train loss: 1.764, Test loss: 1.704, Test accuracy: 75.63
Round 132, Train loss: 1.733, Test loss: 1.704, Test accuracy: 75.61
Round 133, Train loss: 1.703, Test loss: 1.704, Test accuracy: 75.62
Round 134, Train loss: 1.730, Test loss: 1.704, Test accuracy: 75.69
Round 135, Train loss: 1.668, Test loss: 1.704, Test accuracy: 75.68
Round 136, Train loss: 1.670, Test loss: 1.704, Test accuracy: 75.64
Round 137, Train loss: 1.636, Test loss: 1.704, Test accuracy: 75.58
Round 138, Train loss: 1.634, Test loss: 1.704, Test accuracy: 75.62
Round 139, Train loss: 1.668, Test loss: 1.703, Test accuracy: 75.67
Round 140, Train loss: 1.667, Test loss: 1.703, Test accuracy: 75.68
Round 141, Train loss: 1.665, Test loss: 1.703, Test accuracy: 75.78
Round 142, Train loss: 1.730, Test loss: 1.703, Test accuracy: 75.79
Round 143, Train loss: 1.699, Test loss: 1.703, Test accuracy: 75.78
Round 144, Train loss: 1.734, Test loss: 1.703, Test accuracy: 75.77
Round 145, Train loss: 1.633, Test loss: 1.703, Test accuracy: 75.75
Round 146, Train loss: 1.697, Test loss: 1.703, Test accuracy: 75.71
Round 147, Train loss: 1.733, Test loss: 1.703, Test accuracy: 75.66
Round 148, Train loss: 1.699, Test loss: 1.703, Test accuracy: 75.65
Round 149, Train loss: 1.673, Test loss: 1.703, Test accuracy: 75.57
Round 150, Train loss: 1.701, Test loss: 1.703, Test accuracy: 75.63
Round 151, Train loss: 1.668, Test loss: 1.703, Test accuracy: 75.59
Round 152, Train loss: 1.635, Test loss: 1.703, Test accuracy: 75.69
Round 153, Train loss: 1.697, Test loss: 1.703, Test accuracy: 75.60
Round 154, Train loss: 1.602, Test loss: 1.703, Test accuracy: 75.75
Round 155, Train loss: 1.765, Test loss: 1.702, Test accuracy: 75.79
Round 156, Train loss: 1.666, Test loss: 1.702, Test accuracy: 75.84
Round 157, Train loss: 1.664, Test loss: 1.702, Test accuracy: 75.73
Round 158, Train loss: 1.636, Test loss: 1.702, Test accuracy: 75.77
Round 159, Train loss: 1.665, Test loss: 1.702, Test accuracy: 75.80
Round 160, Train loss: 1.719, Test loss: 1.701, Test accuracy: 75.92
Round 161, Train loss: 1.665, Test loss: 1.700, Test accuracy: 75.93
Round 162, Train loss: 1.697, Test loss: 1.700, Test accuracy: 75.96
Round 163, Train loss: 1.674, Test loss: 1.695, Test accuracy: 76.54
Round 164, Train loss: 1.671, Test loss: 1.695, Test accuracy: 76.49
Round 165, Train loss: 1.704, Test loss: 1.694, Test accuracy: 76.59
Round 166, Train loss: 1.637, Test loss: 1.694, Test accuracy: 76.64
Round 167, Train loss: 1.699, Test loss: 1.694, Test accuracy: 76.73
Round 168, Train loss: 1.604, Test loss: 1.694, Test accuracy: 76.72
Round 169, Train loss: 1.631, Test loss: 1.693, Test accuracy: 76.73
Round 170, Train loss: 1.631, Test loss: 1.693, Test accuracy: 76.75
Round 171, Train loss: 1.670, Test loss: 1.693, Test accuracy: 76.72
Round 172, Train loss: 1.669, Test loss: 1.693, Test accuracy: 76.69
Round 173, Train loss: 1.627, Test loss: 1.692, Test accuracy: 76.81
Round 174, Train loss: 1.638, Test loss: 1.693, Test accuracy: 76.72
Round 175, Train loss: 1.631, Test loss: 1.692, Test accuracy: 76.77
Round 176, Train loss: 1.664, Test loss: 1.692, Test accuracy: 76.76
Round 177, Train loss: 1.671, Test loss: 1.692, Test accuracy: 76.77
Round 178, Train loss: 1.605, Test loss: 1.692, Test accuracy: 76.82
Round 179, Train loss: 1.673, Test loss: 1.685, Test accuracy: 77.67
Round 180, Train loss: 1.572, Test loss: 1.685, Test accuracy: 77.68
Round 181, Train loss: 1.664, Test loss: 1.684, Test accuracy: 77.64
Round 182, Train loss: 1.634, Test loss: 1.684, Test accuracy: 77.62
Round 183, Train loss: 1.637, Test loss: 1.684, Test accuracy: 77.63
Round 184, Train loss: 1.582, Test loss: 1.676, Test accuracy: 78.58
Round 185, Train loss: 1.668, Test loss: 1.676, Test accuracy: 78.58
Round 186, Train loss: 1.636, Test loss: 1.676, Test accuracy: 78.68
Round 187, Train loss: 1.763, Test loss: 1.675, Test accuracy: 78.60
Round 188, Train loss: 1.604, Test loss: 1.674, Test accuracy: 78.72
Round 189, Train loss: 1.700, Test loss: 1.674, Test accuracy: 78.74
Round 190, Train loss: 1.669, Test loss: 1.674, Test accuracy: 78.74
Round 191, Train loss: 1.633, Test loss: 1.674, Test accuracy: 78.77
Round 192, Train loss: 1.676, Test loss: 1.666, Test accuracy: 79.53
Round 193, Train loss: 1.608, Test loss: 1.666, Test accuracy: 79.53
Round 194, Train loss: 1.666, Test loss: 1.665, Test accuracy: 79.53
Round 195, Train loss: 1.669, Test loss: 1.666, Test accuracy: 79.50
Round 196, Train loss: 1.604, Test loss: 1.665, Test accuracy: 79.54
Round 197, Train loss: 1.637, Test loss: 1.666, Test accuracy: 79.47
Round 198, Train loss: 1.601, Test loss: 1.665, Test accuracy: 79.49
Round 199, Train loss: 1.602, Test loss: 1.665, Test accuracy: 79.59
Final Round, Train loss: 1.638, Test loss: 1.665, Test accuracy: 79.64
Average accuracy final 10 rounds: 79.36900000000001 

1950.3899388313293
[0.855290412902832, 1.710580825805664, 2.446812152862549, 3.1830434799194336, 3.9270410537719727, 4.671038627624512, 5.391358852386475, 6.1116790771484375, 6.8331382274627686, 7.5545973777771, 8.306128025054932, 9.057658672332764, 9.786393165588379, 10.515127658843994, 11.229629755020142, 11.944131851196289, 12.656141996383667, 13.368152141571045, 14.102942705154419, 14.837733268737793, 15.571735143661499, 16.305737018585205, 17.0148983001709, 17.724059581756592, 18.460819959640503, 19.197580337524414, 19.936879634857178, 20.67617893218994, 21.37268614768982, 22.069193363189697, 22.767683506011963, 23.46617364883423, 24.21197533607483, 24.95777702331543, 25.663947105407715, 26.3701171875, 27.12751340866089, 27.884909629821777, 28.625636339187622, 29.366363048553467, 30.08725595474243, 30.808148860931396, 31.577586889266968, 32.34702491760254, 33.11298155784607, 33.8789381980896, 34.65365934371948, 35.428380489349365, 36.202128410339355, 36.975876331329346, 37.78329300880432, 38.5907096862793, 39.353107929229736, 40.115506172180176, 41.04625201225281, 41.97699785232544, 42.75298547744751, 43.52897310256958, 44.272377729415894, 45.01578235626221, 45.77845358848572, 46.54112482070923, 47.297287940979004, 48.05345106124878, 48.81475877761841, 49.57606649398804, 50.33506774902344, 51.09406900405884, 51.849247455596924, 52.60442590713501, 53.419477701187134, 54.23452949523926, 55.13006091117859, 56.02559232711792, 56.78237271308899, 57.53915309906006, 58.33203125, 59.12490940093994, 59.874467611312866, 60.62402582168579, 61.370776653289795, 62.1175274848938, 62.82440209388733, 63.53127670288086, 64.297372341156, 65.06346797943115, 65.87427878379822, 66.68508958816528, 67.52625513076782, 68.36742067337036, 69.17918801307678, 69.9909553527832, 70.76262474060059, 71.53429412841797, 72.30308556556702, 73.07187700271606, 73.95806360244751, 74.84425020217896, 75.59695053100586, 76.34965085983276, 77.16692781448364, 77.98420476913452, 78.75250005722046, 79.5207953453064, 80.25342035293579, 80.98604536056519, 81.7436032295227, 82.50116109848022, 83.29903888702393, 84.09691667556763, 84.85718154907227, 85.6174464225769, 86.36792254447937, 87.11839866638184, 87.87660884857178, 88.63481903076172, 89.40325284004211, 90.17168664932251, 90.99125528335571, 91.81082391738892, 92.58787131309509, 93.36491870880127, 94.21116161346436, 95.05740451812744, 95.81491661071777, 96.5724287033081, 97.35933303833008, 98.14623737335205, 99.02937889099121, 99.91252040863037, 100.63977289199829, 101.36702537536621, 102.13014101982117, 102.89325666427612, 103.66341018676758, 104.43356370925903, 105.20183825492859, 105.97011280059814, 106.73362302780151, 107.49713325500488, 108.26281213760376, 109.02849102020264, 109.8413667678833, 110.65424251556396, 111.4133186340332, 112.17239475250244, 112.91052484512329, 113.64865493774414, 114.36180186271667, 115.07494878768921, 115.80965781211853, 116.54436683654785, 117.27556705474854, 118.00676727294922, 118.71338033676147, 119.41999340057373, 120.16562056541443, 120.91124773025513, 121.65087056159973, 122.39049339294434, 123.11254096031189, 123.83458852767944, 124.56696939468384, 125.29935026168823, 126.01205563545227, 126.72476100921631, 127.45875000953674, 128.19273900985718, 128.88929176330566, 129.58584451675415, 130.32828521728516, 131.07072591781616, 131.812908411026, 132.55509090423584, 133.27549982070923, 133.99590873718262, 134.7391757965088, 135.48244285583496, 136.20558881759644, 136.9287347793579, 137.6659460067749, 138.4031572341919, 139.13408732414246, 139.86501741409302, 140.5811905860901, 141.29736375808716, 142.05390810966492, 142.81045246124268, 143.5042746067047, 144.19809675216675, 144.92744898796082, 145.65680122375488, 146.40195608139038, 147.14711093902588, 147.86419939994812, 148.58128786087036, 149.3158314228058, 150.0503749847412, 150.76158380508423, 151.47279262542725, 152.20425367355347, 152.9357147216797, 153.6731367111206, 154.41055870056152, 155.12281203269958, 155.83506536483765, 156.58492016792297, 157.3347749710083, 158.05987811088562, 158.78498125076294, 159.49963879585266, 160.21429634094238, 160.94718217849731, 161.68006801605225, 162.3940510749817, 163.10803413391113, 163.84550023078918, 164.58296632766724, 165.28112196922302, 165.9792776107788, 166.7108917236328, 167.44250583648682, 168.20569372177124, 168.96888160705566, 169.66120409965515, 170.35352659225464, 171.12163281440735, 171.88973903656006, 172.6136031150818, 173.33746719360352, 174.04179406166077, 174.74612092971802, 175.46924924850464, 176.19237756729126, 176.90409564971924, 177.61581373214722, 178.36500239372253, 179.11419105529785, 179.82520127296448, 180.5362114906311, 181.24494171142578, 181.95367193222046, 182.69030117988586, 183.42693042755127, 184.14626049995422, 184.86559057235718, 185.5763304233551, 186.28707027435303, 187.0302505493164, 187.77343082427979, 188.4966905117035, 189.2199501991272, 189.94838619232178, 190.67682218551636, 191.38613319396973, 192.0954442024231, 192.8317997455597, 193.5681552886963, 194.32276558876038, 195.07737588882446, 195.7789807319641, 196.48058557510376, 197.2268352508545, 197.97308492660522, 198.70910739898682, 199.4451298713684, 200.16120648384094, 200.87728309631348, 201.62657260894775, 202.37586212158203, 203.09633612632751, 203.816810131073, 204.55088305473328, 205.28495597839355, 206.0135087966919, 206.74206161499023, 207.44426226615906, 208.14646291732788, 208.8858425617218, 209.62522220611572, 210.41265988349915, 211.20009756088257, 212.00625348091125, 212.81240940093994, 213.60248613357544, 214.39256286621094, 215.14758372306824, 215.90260457992554, 216.6644413471222, 217.42627811431885, 218.23329758644104, 219.04031705856323, 219.78866624832153, 220.53701543807983, 221.39607858657837, 222.2551417350769, 223.0307629108429, 223.8063840866089, 224.56276774406433, 225.31915140151978, 226.07955408096313, 226.8399567604065, 227.54343223571777, 228.24690771102905, 229.02801299095154, 229.80911827087402, 230.54789209365845, 231.28666591644287, 232.03579711914062, 232.78492832183838, 233.5520315170288, 234.31913471221924, 235.0801956653595, 235.84125661849976, 236.58730626106262, 237.3333559036255, 238.1562421321869, 238.9791283607483, 239.70953607559204, 240.4399437904358, 241.2063946723938, 241.9728455543518, 242.7091372013092, 243.4454288482666, 244.23329734802246, 245.02116584777832, 245.77976298332214, 246.53836011886597, 247.2925682067871, 248.04677629470825, 248.8519992828369, 249.65722227096558, 250.41498494148254, 251.1727476119995, 251.90658259391785, 252.64041757583618, 253.40916275978088, 254.1779079437256, 254.90641069412231, 255.63491344451904, 256.4539496898651, 257.2729859352112, 258.06190490722656, 258.85082387924194, 259.5937874317169, 260.3367509841919, 261.1481204032898, 261.9594898223877, 262.72657775878906, 263.49366569519043, 264.2306671142578, 264.9676685333252, 265.79826951026917, 266.62887048721313, 267.3958694934845, 268.16286849975586, 268.94650053977966, 269.73013257980347, 270.5021903514862, 271.27424812316895, 272.02915811538696, 272.784068107605, 273.5518388748169, 274.3196096420288, 275.0862293243408, 275.85284900665283, 276.60198736190796, 277.3511257171631, 278.11159014701843, 278.8720545768738, 279.6077127456665, 280.34337091445923, 281.11222743988037, 281.8810839653015, 282.64899253845215, 283.4169011116028, 284.10393381118774, 284.7909665107727, 285.57626605033875, 286.3615655899048, 287.1814410686493, 288.0013165473938, 288.7469096183777, 289.4925026893616, 290.3430161476135, 291.1935296058655, 291.91722989082336, 292.64093017578125, 293.450635433197, 294.2603406906128, 295.01133847236633, 295.7623362541199, 296.49151587486267, 297.22069549560547, 298.02659845352173, 298.832501411438, 299.62971472740173, 300.4269280433655, 301.2079658508301, 301.9890036582947, 303.40547704696655, 304.8219504356384]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[13.35, 13.35, 15.41, 15.41, 14.42, 14.42, 19.14, 19.14, 19.67, 19.67, 19.58, 19.58, 23.62, 23.62, 28.87, 28.87, 34.55, 34.55, 37.72, 37.72, 41.6, 41.6, 42.55, 42.55, 47.37, 47.37, 50.77, 50.77, 54.14, 54.14, 59.79, 59.79, 60.86, 60.86, 62.11, 62.11, 62.91, 62.91, 64.29, 64.29, 65.94, 65.94, 66.09, 66.09, 67.21, 67.21, 67.65, 67.65, 67.76, 67.76, 67.81, 67.81, 68.26, 68.26, 68.38, 68.38, 68.37, 68.37, 68.39, 68.39, 69.04, 69.04, 69.31, 69.31, 69.99, 69.99, 69.99, 69.99, 70.19, 70.19, 70.11, 70.11, 70.28, 70.28, 70.48, 70.48, 70.42, 70.42, 70.55, 70.55, 70.61, 70.61, 70.63, 70.63, 70.76, 70.76, 70.58, 70.58, 70.81, 70.81, 70.82, 70.82, 70.85, 70.85, 70.69, 70.69, 71.55, 71.55, 71.61, 71.61, 71.74, 71.74, 71.78, 71.78, 71.87, 71.87, 71.9, 71.9, 72.03, 72.03, 72.05, 72.05, 72.12, 72.12, 72.11, 72.11, 72.13, 72.13, 72.13, 72.13, 72.14, 72.14, 72.04, 72.04, 72.04, 72.04, 72.1, 72.1, 72.14, 72.14, 72.08, 72.08, 72.05, 72.05, 72.07, 72.07, 72.16, 72.16, 72.19, 72.19, 72.24, 72.24, 72.23, 72.23, 73.1, 73.1, 73.14, 73.14, 73.08, 73.08, 73.08, 73.08, 73.09, 73.09, 73.15, 73.15, 73.23, 73.23, 73.32, 73.32, 73.25, 73.25, 73.3, 73.3, 73.55, 73.55, 73.58, 73.58, 73.58, 73.58, 73.63, 73.63, 74.34, 74.34, 74.22, 74.22, 74.36, 74.36, 74.37, 74.37, 74.35, 74.35, 74.29, 74.29, 74.24, 74.24, 74.38, 74.38, 74.36, 74.36, 74.47, 74.47, 74.46, 74.46, 74.42, 74.42, 74.37, 74.37, 74.5, 74.5, 74.49, 74.49, 74.56, 74.56, 74.47, 74.47, 74.53, 74.53, 74.59, 74.59, 74.63, 74.63, 74.65, 74.65, 74.67, 74.67, 74.62, 74.62, 74.5, 74.5, 74.56, 74.56, 74.64, 74.64, 74.73, 74.73, 74.72, 74.72, 74.75, 74.75, 75.46, 75.46, 75.54, 75.54, 75.64, 75.64, 75.63, 75.63, 75.6, 75.6, 75.54, 75.54, 75.59, 75.59, 75.58, 75.58, 75.55, 75.55, 75.59, 75.59, 75.59, 75.59, 75.56, 75.56, 75.59, 75.59, 75.58, 75.58, 75.53, 75.53, 75.47, 75.47, 75.63, 75.63, 75.61, 75.61, 75.62, 75.62, 75.69, 75.69, 75.68, 75.68, 75.64, 75.64, 75.58, 75.58, 75.62, 75.62, 75.67, 75.67, 75.68, 75.68, 75.78, 75.78, 75.79, 75.79, 75.78, 75.78, 75.77, 75.77, 75.75, 75.75, 75.71, 75.71, 75.66, 75.66, 75.65, 75.65, 75.57, 75.57, 75.63, 75.63, 75.59, 75.59, 75.69, 75.69, 75.6, 75.6, 75.75, 75.75, 75.79, 75.79, 75.84, 75.84, 75.73, 75.73, 75.77, 75.77, 75.8, 75.8, 75.92, 75.92, 75.93, 75.93, 75.96, 75.96, 76.54, 76.54, 76.49, 76.49, 76.59, 76.59, 76.64, 76.64, 76.73, 76.73, 76.72, 76.72, 76.73, 76.73, 76.75, 76.75, 76.72, 76.72, 76.69, 76.69, 76.81, 76.81, 76.72, 76.72, 76.77, 76.77, 76.76, 76.76, 76.77, 76.77, 76.82, 76.82, 77.67, 77.67, 77.68, 77.68, 77.64, 77.64, 77.62, 77.62, 77.63, 77.63, 78.58, 78.58, 78.58, 78.58, 78.68, 78.68, 78.6, 78.6, 78.72, 78.72, 78.74, 78.74, 78.74, 78.74, 78.77, 78.77, 79.53, 79.53, 79.53, 79.53, 79.53, 79.53, 79.5, 79.5, 79.54, 79.54, 79.47, 79.47, 79.49, 79.49, 79.59, 79.59, 79.64, 79.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.298, Test accuracy: 14.32
Round   1, Train loss: 2.229, Test loss: 2.277, Test accuracy: 15.02
Round   2, Train loss: 2.114, Test loss: 2.242, Test accuracy: 21.32
Round   3, Train loss: 1.990, Test loss: 2.217, Test accuracy: 22.36
Round   4, Train loss: 1.953, Test loss: 2.164, Test accuracy: 32.15
Round   5, Train loss: 1.802, Test loss: 2.092, Test accuracy: 40.37
Round   6, Train loss: 1.735, Test loss: 2.056, Test accuracy: 42.39
Round   7, Train loss: 1.861, Test loss: 1.995, Test accuracy: 49.25
Round   8, Train loss: 1.761, Test loss: 1.956, Test accuracy: 52.63
Round   9, Train loss: 1.803, Test loss: 1.948, Test accuracy: 52.45
Round  10, Train loss: 1.819, Test loss: 1.887, Test accuracy: 58.99
Round  11, Train loss: 1.811, Test loss: 1.863, Test accuracy: 61.74
Round  12, Train loss: 1.665, Test loss: 1.847, Test accuracy: 62.85
Round  13, Train loss: 1.787, Test loss: 1.840, Test accuracy: 63.26
Round  14, Train loss: 1.775, Test loss: 1.832, Test accuracy: 64.01
Round  15, Train loss: 1.749, Test loss: 1.814, Test accuracy: 65.48
Round  16, Train loss: 1.713, Test loss: 1.796, Test accuracy: 67.57
Round  17, Train loss: 1.783, Test loss: 1.781, Test accuracy: 68.93
Round  18, Train loss: 1.760, Test loss: 1.774, Test accuracy: 69.59
Round  19, Train loss: 1.747, Test loss: 1.765, Test accuracy: 70.49
Round  20, Train loss: 1.644, Test loss: 1.748, Test accuracy: 72.03
Round  21, Train loss: 1.751, Test loss: 1.737, Test accuracy: 73.18
Round  22, Train loss: 1.727, Test loss: 1.732, Test accuracy: 73.64
Round  23, Train loss: 1.574, Test loss: 1.725, Test accuracy: 74.14
Round  24, Train loss: 1.697, Test loss: 1.727, Test accuracy: 74.12
Round  25, Train loss: 1.685, Test loss: 1.721, Test accuracy: 74.80
Round  26, Train loss: 1.658, Test loss: 1.717, Test accuracy: 75.09
Round  27, Train loss: 1.594, Test loss: 1.711, Test accuracy: 75.66
Round  28, Train loss: 1.621, Test loss: 1.705, Test accuracy: 76.31
Round  29, Train loss: 1.626, Test loss: 1.700, Test accuracy: 76.66
Round  30, Train loss: 1.652, Test loss: 1.697, Test accuracy: 76.79
Round  31, Train loss: 1.587, Test loss: 1.696, Test accuracy: 76.94
Round  32, Train loss: 1.712, Test loss: 1.691, Test accuracy: 77.45
Round  33, Train loss: 1.674, Test loss: 1.694, Test accuracy: 77.20
Round  34, Train loss: 1.707, Test loss: 1.694, Test accuracy: 77.18
Round  35, Train loss: 1.738, Test loss: 1.696, Test accuracy: 76.88
Round  36, Train loss: 1.746, Test loss: 1.687, Test accuracy: 77.89
Round  37, Train loss: 1.582, Test loss: 1.684, Test accuracy: 78.10
Round  38, Train loss: 1.674, Test loss: 1.683, Test accuracy: 78.12
Round  39, Train loss: 1.646, Test loss: 1.683, Test accuracy: 78.06
Round  40, Train loss: 1.613, Test loss: 1.681, Test accuracy: 78.25
Round  41, Train loss: 1.648, Test loss: 1.681, Test accuracy: 78.34
Round  42, Train loss: 1.670, Test loss: 1.674, Test accuracy: 79.15
Round  43, Train loss: 1.648, Test loss: 1.672, Test accuracy: 79.26
Round  44, Train loss: 1.735, Test loss: 1.673, Test accuracy: 79.02
Round  45, Train loss: 1.645, Test loss: 1.669, Test accuracy: 79.37
Round  46, Train loss: 1.701, Test loss: 1.670, Test accuracy: 79.31
Round  47, Train loss: 1.579, Test loss: 1.668, Test accuracy: 79.45
Round  48, Train loss: 1.704, Test loss: 1.668, Test accuracy: 79.47
Round  49, Train loss: 1.608, Test loss: 1.668, Test accuracy: 79.50
Round  50, Train loss: 1.671, Test loss: 1.669, Test accuracy: 79.42
Round  51, Train loss: 1.577, Test loss: 1.667, Test accuracy: 79.48
Round  52, Train loss: 1.673, Test loss: 1.666, Test accuracy: 79.62
Round  53, Train loss: 1.546, Test loss: 1.664, Test accuracy: 79.82
Round  54, Train loss: 1.635, Test loss: 1.664, Test accuracy: 80.02
Round  55, Train loss: 1.636, Test loss: 1.665, Test accuracy: 79.70
Round  56, Train loss: 1.664, Test loss: 1.666, Test accuracy: 79.62
Round  57, Train loss: 1.666, Test loss: 1.660, Test accuracy: 80.23
Round  58, Train loss: 1.610, Test loss: 1.656, Test accuracy: 80.71
Round  59, Train loss: 1.610, Test loss: 1.656, Test accuracy: 80.66
Round  60, Train loss: 1.603, Test loss: 1.657, Test accuracy: 80.51
Round  61, Train loss: 1.637, Test loss: 1.655, Test accuracy: 80.71
Round  62, Train loss: 1.640, Test loss: 1.656, Test accuracy: 80.65
Round  63, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.63
Round  64, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.71
Round  65, Train loss: 1.726, Test loss: 1.656, Test accuracy: 80.51
Round  66, Train loss: 1.547, Test loss: 1.652, Test accuracy: 80.98
Round  67, Train loss: 1.696, Test loss: 1.653, Test accuracy: 80.78
Round  68, Train loss: 1.572, Test loss: 1.653, Test accuracy: 80.77
Round  69, Train loss: 1.574, Test loss: 1.652, Test accuracy: 80.81
Round  70, Train loss: 1.571, Test loss: 1.652, Test accuracy: 80.87
Round  71, Train loss: 1.665, Test loss: 1.654, Test accuracy: 80.78
Round  72, Train loss: 1.603, Test loss: 1.654, Test accuracy: 80.69
Round  73, Train loss: 1.578, Test loss: 1.651, Test accuracy: 81.06
Round  74, Train loss: 1.509, Test loss: 1.650, Test accuracy: 81.04
Round  75, Train loss: 1.699, Test loss: 1.650, Test accuracy: 81.01
Round  76, Train loss: 1.570, Test loss: 1.650, Test accuracy: 81.07
Round  77, Train loss: 1.571, Test loss: 1.651, Test accuracy: 81.02
Round  78, Train loss: 1.605, Test loss: 1.650, Test accuracy: 81.09
Round  79, Train loss: 1.664, Test loss: 1.652, Test accuracy: 80.96
Round  80, Train loss: 1.572, Test loss: 1.650, Test accuracy: 81.07
Round  81, Train loss: 1.607, Test loss: 1.650, Test accuracy: 81.11
Round  82, Train loss: 1.573, Test loss: 1.649, Test accuracy: 81.18
Round  83, Train loss: 1.538, Test loss: 1.648, Test accuracy: 81.25
Round  84, Train loss: 1.601, Test loss: 1.649, Test accuracy: 81.31
Round  85, Train loss: 1.602, Test loss: 1.649, Test accuracy: 81.16
Round  86, Train loss: 1.702, Test loss: 1.650, Test accuracy: 81.08
Round  87, Train loss: 1.607, Test loss: 1.648, Test accuracy: 81.28
Round  88, Train loss: 1.631, Test loss: 1.649, Test accuracy: 81.09
Round  89, Train loss: 1.570, Test loss: 1.650, Test accuracy: 81.07
Round  90, Train loss: 1.634, Test loss: 1.649, Test accuracy: 81.11
Round  91, Train loss: 1.602, Test loss: 1.649, Test accuracy: 81.15
Round  92, Train loss: 1.570, Test loss: 1.649, Test accuracy: 81.16
Round  93, Train loss: 1.569, Test loss: 1.650, Test accuracy: 81.08
Round  94, Train loss: 1.569, Test loss: 1.649, Test accuracy: 81.18
Round  95, Train loss: 1.567, Test loss: 1.648, Test accuracy: 81.18
Round  96, Train loss: 1.568, Test loss: 1.649, Test accuracy: 81.11
Round  97, Train loss: 1.656, Test loss: 1.641, Test accuracy: 82.00
Round  98, Train loss: 1.699, Test loss: 1.641, Test accuracy: 82.09
Round  99, Train loss: 1.534, Test loss: 1.641, Test accuracy: 82.05
Round 100, Train loss: 1.601, Test loss: 1.641, Test accuracy: 82.06
Round 101, Train loss: 1.565, Test loss: 1.641, Test accuracy: 82.13
Round 102, Train loss: 1.633, Test loss: 1.640, Test accuracy: 82.10
Round 103, Train loss: 1.603, Test loss: 1.641, Test accuracy: 82.06
Round 104, Train loss: 1.626, Test loss: 1.641, Test accuracy: 82.08
Round 105, Train loss: 1.698, Test loss: 1.641, Test accuracy: 82.08
Round 106, Train loss: 1.696, Test loss: 1.641, Test accuracy: 82.13
Round 107, Train loss: 1.602, Test loss: 1.640, Test accuracy: 82.16
Round 108, Train loss: 1.694, Test loss: 1.639, Test accuracy: 82.19
Round 109, Train loss: 1.601, Test loss: 1.638, Test accuracy: 82.27
Round 110, Train loss: 1.631, Test loss: 1.638, Test accuracy: 82.25
Round 111, Train loss: 1.665, Test loss: 1.638, Test accuracy: 82.24
Round 112, Train loss: 1.698, Test loss: 1.638, Test accuracy: 82.26
Round 113, Train loss: 1.537, Test loss: 1.637, Test accuracy: 82.30
Round 114, Train loss: 1.600, Test loss: 1.637, Test accuracy: 82.30
Round 115, Train loss: 1.631, Test loss: 1.637, Test accuracy: 82.34
Round 116, Train loss: 1.636, Test loss: 1.637, Test accuracy: 82.37
Round 117, Train loss: 1.537, Test loss: 1.636, Test accuracy: 82.48
Round 118, Train loss: 1.631, Test loss: 1.636, Test accuracy: 82.43
Round 119, Train loss: 1.634, Test loss: 1.637, Test accuracy: 82.38
Round 120, Train loss: 1.603, Test loss: 1.637, Test accuracy: 82.37
Round 121, Train loss: 1.536, Test loss: 1.636, Test accuracy: 82.43
Round 122, Train loss: 1.695, Test loss: 1.636, Test accuracy: 82.32
Round 123, Train loss: 1.569, Test loss: 1.635, Test accuracy: 82.50
Round 124, Train loss: 1.632, Test loss: 1.636, Test accuracy: 82.51
Round 125, Train loss: 1.663, Test loss: 1.636, Test accuracy: 82.45
Round 126, Train loss: 1.631, Test loss: 1.635, Test accuracy: 82.55
Round 127, Train loss: 1.568, Test loss: 1.636, Test accuracy: 82.44
Round 128, Train loss: 1.539, Test loss: 1.635, Test accuracy: 82.54
Round 129, Train loss: 1.628, Test loss: 1.636, Test accuracy: 82.49
Round 130, Train loss: 1.504, Test loss: 1.635, Test accuracy: 82.52
Round 131, Train loss: 1.602, Test loss: 1.635, Test accuracy: 82.52
Round 132, Train loss: 1.658, Test loss: 1.635, Test accuracy: 82.46
Round 133, Train loss: 1.692, Test loss: 1.636, Test accuracy: 82.37
Round 134, Train loss: 1.598, Test loss: 1.635, Test accuracy: 82.44
Round 135, Train loss: 1.668, Test loss: 1.636, Test accuracy: 82.40
Round 136, Train loss: 1.628, Test loss: 1.636, Test accuracy: 82.42
Round 137, Train loss: 1.602, Test loss: 1.635, Test accuracy: 82.45
Round 138, Train loss: 1.604, Test loss: 1.635, Test accuracy: 82.44
Round 139, Train loss: 1.633, Test loss: 1.635, Test accuracy: 82.51
Round 140, Train loss: 1.535, Test loss: 1.635, Test accuracy: 82.47
Round 141, Train loss: 1.696, Test loss: 1.635, Test accuracy: 82.39
Round 142, Train loss: 1.630, Test loss: 1.635, Test accuracy: 82.38
Round 143, Train loss: 1.634, Test loss: 1.635, Test accuracy: 82.54
Round 144, Train loss: 1.596, Test loss: 1.635, Test accuracy: 82.44
Round 145, Train loss: 1.630, Test loss: 1.635, Test accuracy: 82.43
Round 146, Train loss: 1.628, Test loss: 1.635, Test accuracy: 82.45
Round 147, Train loss: 1.630, Test loss: 1.635, Test accuracy: 82.42
Round 148, Train loss: 1.600, Test loss: 1.635, Test accuracy: 82.55
Round 149, Train loss: 1.632, Test loss: 1.635, Test accuracy: 82.53
Round 150, Train loss: 1.626, Test loss: 1.635, Test accuracy: 82.47
Round 151, Train loss: 1.556, Test loss: 1.630, Test accuracy: 83.10
Round 152, Train loss: 1.571, Test loss: 1.630, Test accuracy: 83.09
Round 153, Train loss: 1.632, Test loss: 1.631, Test accuracy: 82.98
Round 154, Train loss: 1.599, Test loss: 1.632, Test accuracy: 82.84
Round 155, Train loss: 1.536, Test loss: 1.627, Test accuracy: 83.39
Round 156, Train loss: 1.665, Test loss: 1.627, Test accuracy: 83.42
Round 157, Train loss: 1.590, Test loss: 1.620, Test accuracy: 84.29
Round 158, Train loss: 1.570, Test loss: 1.620, Test accuracy: 84.23
Round 159, Train loss: 1.599, Test loss: 1.616, Test accuracy: 84.73
Round 160, Train loss: 1.506, Test loss: 1.614, Test accuracy: 84.88
Round 161, Train loss: 1.602, Test loss: 1.614, Test accuracy: 84.80
Round 162, Train loss: 1.502, Test loss: 1.614, Test accuracy: 84.86
Round 163, Train loss: 1.662, Test loss: 1.614, Test accuracy: 84.79
Round 164, Train loss: 1.534, Test loss: 1.613, Test accuracy: 84.85
Round 165, Train loss: 1.667, Test loss: 1.610, Test accuracy: 85.11
Round 166, Train loss: 1.538, Test loss: 1.609, Test accuracy: 85.23
Round 167, Train loss: 1.538, Test loss: 1.609, Test accuracy: 85.27
Round 168, Train loss: 1.606, Test loss: 1.609, Test accuracy: 85.12
Round 169, Train loss: 1.569, Test loss: 1.609, Test accuracy: 85.23
Round 170, Train loss: 1.633, Test loss: 1.609, Test accuracy: 85.19
Round 171, Train loss: 1.534, Test loss: 1.609, Test accuracy: 85.23
Round 172, Train loss: 1.602, Test loss: 1.609, Test accuracy: 85.23
Round 173, Train loss: 1.631, Test loss: 1.609, Test accuracy: 85.19
Round 174, Train loss: 1.564, Test loss: 1.608, Test accuracy: 85.22
Round 175, Train loss: 1.661, Test loss: 1.609, Test accuracy: 85.20
Round 176, Train loss: 1.568, Test loss: 1.609, Test accuracy: 85.22
Round 177, Train loss: 1.597, Test loss: 1.608, Test accuracy: 85.24
Round 178, Train loss: 1.598, Test loss: 1.609, Test accuracy: 85.24
Round 179, Train loss: 1.504, Test loss: 1.608, Test accuracy: 85.21
Round 180, Train loss: 1.535, Test loss: 1.608, Test accuracy: 85.28
Round 181, Train loss: 1.569, Test loss: 1.608, Test accuracy: 85.27
Round 182, Train loss: 1.630, Test loss: 1.608, Test accuracy: 85.22
Round 183, Train loss: 1.566, Test loss: 1.608, Test accuracy: 85.32
Round 184, Train loss: 1.597, Test loss: 1.608, Test accuracy: 85.33
Round 185, Train loss: 1.535, Test loss: 1.607, Test accuracy: 85.37
Round 186, Train loss: 1.539, Test loss: 1.607, Test accuracy: 85.35
Round 187, Train loss: 1.502, Test loss: 1.607, Test accuracy: 85.28
Round 188, Train loss: 1.597, Test loss: 1.608, Test accuracy: 85.25
Round 189, Train loss: 1.630, Test loss: 1.607, Test accuracy: 85.35
Round 190, Train loss: 1.626, Test loss: 1.608, Test accuracy: 85.31
Round 191, Train loss: 1.534, Test loss: 1.607, Test accuracy: 85.43
Round 192, Train loss: 1.500, Test loss: 1.607, Test accuracy: 85.36
Round 193, Train loss: 1.533, Test loss: 1.607, Test accuracy: 85.37
Round 194, Train loss: 1.565, Test loss: 1.608, Test accuracy: 85.33
Round 195, Train loss: 1.538, Test loss: 1.607, Test accuracy: 85.34
Round 196, Train loss: 1.598, Test loss: 1.608, Test accuracy: 85.34
Round 197, Train loss: 1.535, Test loss: 1.607, Test accuracy: 85.36
Round 198, Train loss: 1.597, Test loss: 1.608, Test accuracy: 85.36
Round 199, Train loss: 1.564, Test loss: 1.607, Test accuracy: 85.45
Final Round, Train loss: 1.576, Test loss: 1.606, Test accuracy: 85.57
Average accuracy final 10 rounds: 85.365 

1968.787578344345
[0.9122152328491211, 1.8244304656982422, 2.5675384998321533, 3.3106465339660645, 4.020164966583252, 4.7296833992004395, 5.585015296936035, 6.440347194671631, 7.236496210098267, 8.032645225524902, 8.840065240859985, 9.647485256195068, 10.50820255279541, 11.368919849395752, 12.175998210906982, 12.983076572418213, 13.777495384216309, 14.571914196014404, 15.387046813964844, 16.202179431915283, 16.962252140045166, 17.72232484817505, 18.537919521331787, 19.353514194488525, 20.089387893676758, 20.82526159286499, 21.637573719024658, 22.449885845184326, 23.24656653404236, 24.04324722290039, 24.838509798049927, 25.633772373199463, 26.425352334976196, 27.21693229675293, 28.036466360092163, 28.856000423431396, 29.632028579711914, 30.40805673599243, 31.239423274993896, 32.07078981399536, 32.85404086112976, 33.63729190826416, 34.429229736328125, 35.22116756439209, 35.965898513793945, 36.7106294631958, 37.506171226501465, 38.30171298980713, 39.09139394760132, 39.88107490539551, 40.746129512786865, 41.61118412017822, 42.342607498168945, 43.07403087615967, 43.86816120147705, 44.662291526794434, 45.45214033126831, 46.24198913574219, 47.00047516822815, 47.75896120071411, 48.53295040130615, 49.30693960189819, 50.0924768447876, 50.878014087677, 51.663811922073364, 52.44960975646973, 53.219534397125244, 53.98945903778076, 54.82305574417114, 55.65665245056152, 56.41858100891113, 57.18050956726074, 57.97445464134216, 58.768399715423584, 59.56200551986694, 60.3556113243103, 61.170501708984375, 61.98539209365845, 62.77064251899719, 63.55589294433594, 64.32884216308594, 65.10179138183594, 65.95583868026733, 66.80988597869873, 67.6098747253418, 68.40986347198486, 69.16710615158081, 69.92434883117676, 70.93156170845032, 71.93877458572388, 72.76730370521545, 73.59583282470703, 74.44288349151611, 75.2899341583252, 76.1165623664856, 76.943190574646, 77.78833389282227, 78.63347721099854, 79.46713161468506, 80.30078601837158, 81.15774917602539, 82.0147123336792, 82.83891654014587, 83.66312074661255, 84.53629994392395, 85.40947914123535, 86.21440815925598, 87.01933717727661, 87.77710485458374, 88.53487253189087, 89.31939482688904, 90.1039171218872, 90.86867022514343, 91.63342332839966, 92.41116642951965, 93.18890953063965, 93.95232272148132, 94.715735912323, 95.47433733940125, 96.23293876647949, 96.99819731712341, 97.76345586776733, 98.5208477973938, 99.27823972702026, 100.03809428215027, 100.79794883728027, 101.54675579071045, 102.29556274414062, 103.06725120544434, 103.83893966674805, 104.59875750541687, 105.3585753440857, 106.13364553451538, 106.90871572494507, 107.6471700668335, 108.38562440872192, 109.14333748817444, 109.90105056762695, 110.67092204093933, 111.44079351425171, 112.19996237754822, 112.95913124084473, 113.7397940158844, 114.52045679092407, 115.30417084693909, 116.0878849029541, 116.84631729125977, 117.60474967956543, 118.37366676330566, 119.1425838470459, 119.89932441711426, 120.65606498718262, 121.40582990646362, 122.15559482574463, 122.93119883537292, 123.70680284500122, 124.49394106864929, 125.28107929229736, 126.07992553710938, 126.87877178192139, 127.6427493095398, 128.4067268371582, 129.15244674682617, 129.89816665649414, 130.65664339065552, 131.4151201248169, 132.168762922287, 132.92240571975708, 133.67242217063904, 134.422438621521, 135.29297924041748, 136.16351985931396, 136.97191262245178, 137.7803053855896, 138.6201617717743, 139.46001815795898, 140.27485752105713, 141.08969688415527, 141.9038369655609, 142.71797704696655, 143.5372085571289, 144.35644006729126, 145.1901376247406, 146.02383518218994, 146.89841151237488, 147.77298784255981, 148.57612705230713, 149.37926626205444, 150.19295024871826, 151.00663423538208, 152.09768295288086, 153.18873167037964, 154.09521794319153, 155.00170421600342, 155.81715726852417, 156.63261032104492, 157.4979169368744, 158.36322355270386, 159.17569208145142, 159.98816061019897, 160.86586833000183, 161.7435760498047, 162.63407015800476, 163.52456426620483, 164.3534927368164, 165.18242120742798, 166.09296679496765, 167.00351238250732, 167.80110883712769, 168.59870529174805, 169.4466998577118, 170.29469442367554, 171.10964512825012, 171.9245958328247, 172.7431116104126, 173.5616273880005, 174.3523669242859, 175.1431064605713, 175.94090461730957, 176.73870277404785, 177.5653727054596, 178.39204263687134, 179.29733777046204, 180.20263290405273, 181.13581109046936, 182.068989276886, 182.87364745140076, 183.67830562591553, 184.5461745262146, 185.41404342651367, 186.18330812454224, 186.9525728225708, 187.7782497406006, 188.60392665863037, 189.39372539520264, 190.1835241317749, 191.01082348823547, 191.83812284469604, 192.6491060256958, 193.46008920669556, 194.26263999938965, 195.06519079208374, 195.9094090461731, 196.75362730026245, 197.5995283126831, 198.44542932510376, 199.2753050327301, 200.10518074035645, 200.8853566646576, 201.66553258895874, 202.41907477378845, 203.17261695861816, 204.02992725372314, 204.88723754882812, 205.73159289360046, 206.5759482383728, 207.42338967323303, 208.27083110809326, 209.14888525009155, 210.02693939208984, 210.8783085346222, 211.72967767715454, 212.56176614761353, 213.3938546180725, 214.2101068496704, 215.0263590812683, 215.83644318580627, 216.64652729034424, 217.48479223251343, 218.32305717468262, 219.11797761917114, 219.91289806365967, 220.68426036834717, 221.45562267303467, 222.19984459877014, 222.94406652450562, 223.717520236969, 224.49097394943237, 225.2681324481964, 226.04529094696045, 226.80428814888, 227.56328535079956, 228.34985494613647, 229.1364245414734, 229.88069200515747, 230.62495946884155, 231.4110164642334, 232.19707345962524, 232.96248292922974, 233.72789239883423, 234.50109362602234, 235.27429485321045, 236.01418018341064, 236.75406551361084, 237.51744294166565, 238.28082036972046, 239.06238174438477, 239.84394311904907, 240.5793673992157, 241.31479167938232, 242.09005618095398, 242.86532068252563, 243.61740851402283, 244.36949634552002, 245.13719367980957, 245.90489101409912, 246.6616952419281, 247.41849946975708, 248.16723942756653, 248.91597938537598, 249.6884961128235, 250.461012840271, 251.22034740447998, 251.97968196868896, 252.75112438201904, 253.52256679534912, 254.23312497138977, 254.94368314743042, 255.70470714569092, 256.4657311439514, 257.23408579826355, 258.0024404525757, 258.75696873664856, 259.51149702072144, 260.2737739086151, 261.0360507965088, 261.77002143859863, 262.5039920806885, 263.2649886608124, 264.0259852409363, 264.7496542930603, 265.4733233451843, 266.2492697238922, 267.0252161026001, 267.77395009994507, 268.52268409729004, 269.30110263824463, 270.0795211791992, 270.83607816696167, 271.5926351547241, 272.35147428512573, 273.11031341552734, 273.8711824417114, 274.6320514678955, 275.3742778301239, 276.1165041923523, 276.86679100990295, 277.6170778274536, 278.3658742904663, 279.114670753479, 279.8937849998474, 280.6728992462158, 281.4409739971161, 282.20904874801636, 282.95480728149414, 283.7005658149719, 284.4835031032562, 285.2664403915405, 286.0086090564728, 286.75077772140503, 287.5111927986145, 288.271607875824, 289.02647256851196, 289.78133726119995, 290.55648970603943, 291.3316421508789, 292.114137172699, 292.89663219451904, 293.66125440597534, 294.42587661743164, 295.1897644996643, 295.953652381897, 296.70132184028625, 297.44899129867554, 298.22590804100037, 299.0028247833252, 299.7651183605194, 300.5274119377136, 301.30346488952637, 302.0795178413391, 302.8216061592102, 303.5636944770813, 304.31478571891785, 305.0658769607544, 305.8443400859833, 306.62280321121216, 307.37909269332886, 308.13538217544556, 308.91343212127686, 309.69148206710815, 310.4483289718628, 311.20517587661743, 311.9842221736908, 312.76326847076416, 313.5226573944092, 314.2820463180542, 315.05375933647156, 315.8254723548889, 316.5844917297363, 317.34351110458374, 318.76072931289673, 320.1779475212097]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[14.32, 14.32, 15.02, 15.02, 21.32, 21.32, 22.36, 22.36, 32.15, 32.15, 40.37, 40.37, 42.39, 42.39, 49.25, 49.25, 52.63, 52.63, 52.45, 52.45, 58.99, 58.99, 61.74, 61.74, 62.85, 62.85, 63.26, 63.26, 64.01, 64.01, 65.48, 65.48, 67.57, 67.57, 68.93, 68.93, 69.59, 69.59, 70.49, 70.49, 72.03, 72.03, 73.18, 73.18, 73.64, 73.64, 74.14, 74.14, 74.12, 74.12, 74.8, 74.8, 75.09, 75.09, 75.66, 75.66, 76.31, 76.31, 76.66, 76.66, 76.79, 76.79, 76.94, 76.94, 77.45, 77.45, 77.2, 77.2, 77.18, 77.18, 76.88, 76.88, 77.89, 77.89, 78.1, 78.1, 78.12, 78.12, 78.06, 78.06, 78.25, 78.25, 78.34, 78.34, 79.15, 79.15, 79.26, 79.26, 79.02, 79.02, 79.37, 79.37, 79.31, 79.31, 79.45, 79.45, 79.47, 79.47, 79.5, 79.5, 79.42, 79.42, 79.48, 79.48, 79.62, 79.62, 79.82, 79.82, 80.02, 80.02, 79.7, 79.7, 79.62, 79.62, 80.23, 80.23, 80.71, 80.71, 80.66, 80.66, 80.51, 80.51, 80.71, 80.71, 80.65, 80.65, 80.63, 80.63, 80.71, 80.71, 80.51, 80.51, 80.98, 80.98, 80.78, 80.78, 80.77, 80.77, 80.81, 80.81, 80.87, 80.87, 80.78, 80.78, 80.69, 80.69, 81.06, 81.06, 81.04, 81.04, 81.01, 81.01, 81.07, 81.07, 81.02, 81.02, 81.09, 81.09, 80.96, 80.96, 81.07, 81.07, 81.11, 81.11, 81.18, 81.18, 81.25, 81.25, 81.31, 81.31, 81.16, 81.16, 81.08, 81.08, 81.28, 81.28, 81.09, 81.09, 81.07, 81.07, 81.11, 81.11, 81.15, 81.15, 81.16, 81.16, 81.08, 81.08, 81.18, 81.18, 81.18, 81.18, 81.11, 81.11, 82.0, 82.0, 82.09, 82.09, 82.05, 82.05, 82.06, 82.06, 82.13, 82.13, 82.1, 82.1, 82.06, 82.06, 82.08, 82.08, 82.08, 82.08, 82.13, 82.13, 82.16, 82.16, 82.19, 82.19, 82.27, 82.27, 82.25, 82.25, 82.24, 82.24, 82.26, 82.26, 82.3, 82.3, 82.3, 82.3, 82.34, 82.34, 82.37, 82.37, 82.48, 82.48, 82.43, 82.43, 82.38, 82.38, 82.37, 82.37, 82.43, 82.43, 82.32, 82.32, 82.5, 82.5, 82.51, 82.51, 82.45, 82.45, 82.55, 82.55, 82.44, 82.44, 82.54, 82.54, 82.49, 82.49, 82.52, 82.52, 82.52, 82.52, 82.46, 82.46, 82.37, 82.37, 82.44, 82.44, 82.4, 82.4, 82.42, 82.42, 82.45, 82.45, 82.44, 82.44, 82.51, 82.51, 82.47, 82.47, 82.39, 82.39, 82.38, 82.38, 82.54, 82.54, 82.44, 82.44, 82.43, 82.43, 82.45, 82.45, 82.42, 82.42, 82.55, 82.55, 82.53, 82.53, 82.47, 82.47, 83.1, 83.1, 83.09, 83.09, 82.98, 82.98, 82.84, 82.84, 83.39, 83.39, 83.42, 83.42, 84.29, 84.29, 84.23, 84.23, 84.73, 84.73, 84.88, 84.88, 84.8, 84.8, 84.86, 84.86, 84.79, 84.79, 84.85, 84.85, 85.11, 85.11, 85.23, 85.23, 85.27, 85.27, 85.12, 85.12, 85.23, 85.23, 85.19, 85.19, 85.23, 85.23, 85.23, 85.23, 85.19, 85.19, 85.22, 85.22, 85.2, 85.2, 85.22, 85.22, 85.24, 85.24, 85.24, 85.24, 85.21, 85.21, 85.28, 85.28, 85.27, 85.27, 85.22, 85.22, 85.32, 85.32, 85.33, 85.33, 85.37, 85.37, 85.35, 85.35, 85.28, 85.28, 85.25, 85.25, 85.35, 85.35, 85.31, 85.31, 85.43, 85.43, 85.36, 85.36, 85.37, 85.37, 85.33, 85.33, 85.34, 85.34, 85.34, 85.34, 85.36, 85.36, 85.36, 85.36, 85.45, 85.45, 85.57, 85.57]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.297, Test accuracy: 16.74
Round   1, Train loss: 2.234, Test loss: 2.275, Test accuracy: 12.95
Round   2, Train loss: 2.080, Test loss: 2.208, Test accuracy: 28.61
Round   3, Train loss: 2.023, Test loss: 2.124, Test accuracy: 37.10
Round   4, Train loss: 1.905, Test loss: 2.027, Test accuracy: 48.26
Round   5, Train loss: 1.739, Test loss: 1.974, Test accuracy: 53.23
Round   6, Train loss: 1.803, Test loss: 1.912, Test accuracy: 60.24
Round   7, Train loss: 1.732, Test loss: 1.887, Test accuracy: 62.00
Round   8, Train loss: 1.663, Test loss: 1.840, Test accuracy: 65.08
Round   9, Train loss: 1.713, Test loss: 1.786, Test accuracy: 69.19
Round  10, Train loss: 1.644, Test loss: 1.738, Test accuracy: 75.50
Round  11, Train loss: 1.517, Test loss: 1.715, Test accuracy: 77.30
Round  12, Train loss: 1.651, Test loss: 1.680, Test accuracy: 80.90
Round  13, Train loss: 1.555, Test loss: 1.656, Test accuracy: 83.80
Round  14, Train loss: 1.518, Test loss: 1.640, Test accuracy: 84.85
Round  15, Train loss: 1.501, Test loss: 1.626, Test accuracy: 86.10
Round  16, Train loss: 1.535, Test loss: 1.602, Test accuracy: 87.95
Round  17, Train loss: 1.517, Test loss: 1.593, Test accuracy: 88.80
Round  18, Train loss: 1.510, Test loss: 1.589, Test accuracy: 88.90
Round  19, Train loss: 1.505, Test loss: 1.574, Test accuracy: 90.21
Round  20, Train loss: 1.515, Test loss: 1.571, Test accuracy: 90.25
Round  21, Train loss: 1.505, Test loss: 1.568, Test accuracy: 90.40
Round  22, Train loss: 1.494, Test loss: 1.560, Test accuracy: 91.20
Round  23, Train loss: 1.504, Test loss: 1.557, Test accuracy: 91.51
Round  24, Train loss: 1.477, Test loss: 1.555, Test accuracy: 91.55
Round  25, Train loss: 1.484, Test loss: 1.552, Test accuracy: 91.82
Round  26, Train loss: 1.475, Test loss: 1.550, Test accuracy: 91.85
Round  27, Train loss: 1.472, Test loss: 1.549, Test accuracy: 91.92
Round  28, Train loss: 1.472, Test loss: 1.548, Test accuracy: 91.94
Round  29, Train loss: 1.474, Test loss: 1.548, Test accuracy: 92.00
Round  30, Train loss: 1.470, Test loss: 1.548, Test accuracy: 91.99
Round  31, Train loss: 1.470, Test loss: 1.547, Test accuracy: 92.03
Round  32, Train loss: 1.505, Test loss: 1.547, Test accuracy: 92.00
Round  33, Train loss: 1.470, Test loss: 1.547, Test accuracy: 92.12
Round  34, Train loss: 1.470, Test loss: 1.546, Test accuracy: 92.10
Round  35, Train loss: 1.502, Test loss: 1.546, Test accuracy: 92.09
Round  36, Train loss: 1.469, Test loss: 1.546, Test accuracy: 92.13
Round  37, Train loss: 1.469, Test loss: 1.546, Test accuracy: 92.13
Round  38, Train loss: 1.499, Test loss: 1.546, Test accuracy: 92.14
Round  39, Train loss: 1.470, Test loss: 1.546, Test accuracy: 92.21
Round  40, Train loss: 1.469, Test loss: 1.545, Test accuracy: 92.14
Round  41, Train loss: 1.469, Test loss: 1.545, Test accuracy: 92.15
Round  42, Train loss: 1.502, Test loss: 1.545, Test accuracy: 92.14
Round  43, Train loss: 1.499, Test loss: 1.545, Test accuracy: 92.18
Round  44, Train loss: 1.469, Test loss: 1.544, Test accuracy: 92.22
Round  45, Train loss: 1.467, Test loss: 1.545, Test accuracy: 92.22
Round  46, Train loss: 1.470, Test loss: 1.544, Test accuracy: 92.20
Round  47, Train loss: 1.467, Test loss: 1.545, Test accuracy: 92.19
Round  48, Train loss: 1.469, Test loss: 1.545, Test accuracy: 92.22
Round  49, Train loss: 1.467, Test loss: 1.544, Test accuracy: 92.18
Round  50, Train loss: 1.468, Test loss: 1.544, Test accuracy: 92.17
Round  51, Train loss: 1.469, Test loss: 1.544, Test accuracy: 92.17
Round  52, Train loss: 1.467, Test loss: 1.544, Test accuracy: 92.17
Round  53, Train loss: 1.469, Test loss: 1.544, Test accuracy: 92.18
Round  54, Train loss: 1.468, Test loss: 1.544, Test accuracy: 92.20
Round  55, Train loss: 1.466, Test loss: 1.544, Test accuracy: 92.18
Round  56, Train loss: 1.470, Test loss: 1.544, Test accuracy: 92.19
Round  57, Train loss: 1.502, Test loss: 1.544, Test accuracy: 92.14
Round  58, Train loss: 1.470, Test loss: 1.544, Test accuracy: 92.23
Round  59, Train loss: 1.498, Test loss: 1.544, Test accuracy: 92.17
Round  60, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.19
Round  61, Train loss: 1.466, Test loss: 1.543, Test accuracy: 92.17
Round  62, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.20
Round  63, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.20
Round  64, Train loss: 1.499, Test loss: 1.543, Test accuracy: 92.22
Round  65, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.20
Round  66, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.22
Round  67, Train loss: 1.499, Test loss: 1.543, Test accuracy: 92.21
Round  68, Train loss: 1.500, Test loss: 1.543, Test accuracy: 92.19
Round  69, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.21
Round  70, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.22
Round  71, Train loss: 1.471, Test loss: 1.543, Test accuracy: 92.17
Round  72, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.17
Round  73, Train loss: 1.500, Test loss: 1.543, Test accuracy: 92.14
Round  74, Train loss: 1.470, Test loss: 1.543, Test accuracy: 92.15
Round  75, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.15
Round  76, Train loss: 1.498, Test loss: 1.543, Test accuracy: 92.14
Round  77, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.14
Round  78, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.13
Round  79, Train loss: 1.498, Test loss: 1.543, Test accuracy: 92.16
Round  80, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.14
Round  81, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.16
Round  82, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.16
Round  83, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.16
Round  84, Train loss: 1.498, Test loss: 1.543, Test accuracy: 92.13
Round  85, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.15
Round  86, Train loss: 1.499, Test loss: 1.543, Test accuracy: 92.12
Round  87, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.14
Round  88, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.14
Round  89, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.15
Round  90, Train loss: 1.499, Test loss: 1.543, Test accuracy: 92.14
Round  91, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.18
Round  92, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.17
Round  93, Train loss: 1.466, Test loss: 1.543, Test accuracy: 92.19
Round  94, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.16
Round  95, Train loss: 1.467, Test loss: 1.543, Test accuracy: 92.17
Round  96, Train loss: 1.466, Test loss: 1.543, Test accuracy: 92.16
Round  97, Train loss: 1.469, Test loss: 1.543, Test accuracy: 92.15
Round  98, Train loss: 1.468, Test loss: 1.543, Test accuracy: 92.15
Round  99, Train loss: 1.466, Test loss: 1.543, Test accuracy: 92.15/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.477, Test loss: 1.542, Test accuracy: 92.17
Average accuracy final 10 rounds: 92.162 

966.2068836688995
[0.9290823936462402, 1.8581647872924805, 2.6911818981170654, 3.5241990089416504, 4.380247592926025, 5.2362961769104, 6.114994287490845, 6.993692398071289, 7.8510026931762695, 8.70831298828125, 9.564168930053711, 10.420024871826172, 11.201608896255493, 11.983192920684814, 12.842480421066284, 13.701767921447754, 14.47361135482788, 15.245454788208008, 16.017411947250366, 16.789369106292725, 17.540361642837524, 18.291354179382324, 19.04609179496765, 19.80082941055298, 20.55510401725769, 21.309378623962402, 22.092546463012695, 22.87571430206299, 23.646480083465576, 24.417245864868164, 25.191400051116943, 25.965554237365723, 26.755969047546387, 27.54638385772705, 28.310486793518066, 29.074589729309082, 29.816043615341187, 30.55749750137329, 31.301944494247437, 32.04639148712158, 32.799766540527344, 33.553141593933105, 34.32472324371338, 35.09630489349365, 35.86522889137268, 36.63415288925171, 37.39811706542969, 38.162081241607666, 38.93645644187927, 39.71083164215088, 40.4831964969635, 41.25556135177612, 41.997129917144775, 42.73869848251343, 43.47811794281006, 44.21753740310669, 44.98366832733154, 45.7497992515564, 46.5341010093689, 47.3184027671814, 48.09350085258484, 48.86859893798828, 49.64065194129944, 50.412704944610596, 51.17594242095947, 51.93917989730835, 52.68979811668396, 53.44041633605957, 54.19136095046997, 54.94230556488037, 55.707988023757935, 56.4736704826355, 57.28010678291321, 58.08654308319092, 58.886204957962036, 59.685866832733154, 60.454814195632935, 61.223761558532715, 62.01612591743469, 62.80849027633667, 63.56557607650757, 64.32266187667847, 65.10348773002625, 65.88431358337402, 66.63796949386597, 67.39162540435791, 68.15234518051147, 68.91306495666504, 69.6765468120575, 70.44002866744995, 71.2113196849823, 71.98261070251465, 72.76391506195068, 73.54521942138672, 74.31547355651855, 75.08572769165039, 75.92295408248901, 76.76018047332764, 77.59876823425293, 78.43735599517822, 79.20171475410461, 79.966073513031, 80.7277820110321, 81.4894905090332, 82.22463369369507, 82.95977687835693, 83.72245073318481, 84.4851245880127, 85.23024535179138, 85.97536611557007, 86.74311566352844, 87.51086521148682, 88.24229288101196, 88.97372055053711, 89.73122429847717, 90.48872804641724, 91.25993847846985, 92.03114891052246, 92.79909062385559, 93.56703233718872, 94.33768463134766, 95.10833692550659, 95.87409591674805, 96.6398549079895, 97.40095543861389, 98.16205596923828, 98.86831331253052, 99.57457065582275, 100.35745620727539, 101.14034175872803, 101.90274047851562, 102.66513919830322, 103.42563581466675, 104.18613243103027, 104.93318748474121, 105.68024253845215, 106.43129992485046, 107.18235731124878, 107.94371461868286, 108.70507192611694, 109.45225620269775, 110.19944047927856, 110.94087648391724, 111.68231248855591, 112.43428468704224, 113.18625688552856, 113.9437518119812, 114.70124673843384, 115.45590353012085, 116.21056032180786, 116.95258140563965, 117.69460248947144, 118.4378890991211, 119.18117570877075, 119.9138855934143, 120.64659547805786, 121.36954092979431, 122.09248638153076, 122.83234906196594, 123.57221174240112, 124.33189296722412, 125.09157419204712, 125.83262538909912, 126.57367658615112, 127.32830572128296, 128.0829348564148, 128.82564163208008, 129.56834840774536, 130.30806756019592, 131.04778671264648, 131.75453925132751, 132.46129179000854, 133.2038984298706, 133.94650506973267, 134.6911325454712, 135.43576002120972, 136.17701196670532, 136.91826391220093, 137.65007829666138, 138.38189268112183, 139.12585377693176, 139.8698148727417, 140.61493372917175, 141.3600525856018, 142.09997034072876, 142.8398880958557, 143.565927028656, 144.2919659614563, 145.03659510612488, 145.78122425079346, 146.51789236068726, 147.25456047058105, 147.9844422340393, 148.71432399749756, 149.4763216972351, 150.23831939697266, 150.99341344833374, 151.74850749969482, 152.49012327194214, 153.23173904418945, 154.6276638507843, 156.02358865737915]
[16.74, 16.74, 12.95, 12.95, 28.61, 28.61, 37.1, 37.1, 48.26, 48.26, 53.23, 53.23, 60.24, 60.24, 62.0, 62.0, 65.08, 65.08, 69.19, 69.19, 75.5, 75.5, 77.3, 77.3, 80.9, 80.9, 83.8, 83.8, 84.85, 84.85, 86.1, 86.1, 87.95, 87.95, 88.8, 88.8, 88.9, 88.9, 90.21, 90.21, 90.25, 90.25, 90.4, 90.4, 91.2, 91.2, 91.51, 91.51, 91.55, 91.55, 91.82, 91.82, 91.85, 91.85, 91.92, 91.92, 91.94, 91.94, 92.0, 92.0, 91.99, 91.99, 92.03, 92.03, 92.0, 92.0, 92.12, 92.12, 92.1, 92.1, 92.09, 92.09, 92.13, 92.13, 92.13, 92.13, 92.14, 92.14, 92.21, 92.21, 92.14, 92.14, 92.15, 92.15, 92.14, 92.14, 92.18, 92.18, 92.22, 92.22, 92.22, 92.22, 92.2, 92.2, 92.19, 92.19, 92.22, 92.22, 92.18, 92.18, 92.17, 92.17, 92.17, 92.17, 92.17, 92.17, 92.18, 92.18, 92.2, 92.2, 92.18, 92.18, 92.19, 92.19, 92.14, 92.14, 92.23, 92.23, 92.17, 92.17, 92.19, 92.19, 92.17, 92.17, 92.2, 92.2, 92.2, 92.2, 92.22, 92.22, 92.2, 92.2, 92.22, 92.22, 92.21, 92.21, 92.19, 92.19, 92.21, 92.21, 92.22, 92.22, 92.17, 92.17, 92.17, 92.17, 92.14, 92.14, 92.15, 92.15, 92.15, 92.15, 92.14, 92.14, 92.14, 92.14, 92.13, 92.13, 92.16, 92.16, 92.14, 92.14, 92.16, 92.16, 92.16, 92.16, 92.16, 92.16, 92.13, 92.13, 92.15, 92.15, 92.12, 92.12, 92.14, 92.14, 92.14, 92.14, 92.15, 92.15, 92.14, 92.14, 92.18, 92.18, 92.17, 92.17, 92.19, 92.19, 92.16, 92.16, 92.17, 92.17, 92.16, 92.16, 92.15, 92.15, 92.15, 92.15, 92.15, 92.15, 92.17, 92.17]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.590, Test loss: 2.272, Test accuracy: 28.85
Round   1, Train loss: 1.413, Test loss: 2.191, Test accuracy: 38.87
Round   2, Train loss: 1.318, Test loss: 2.121, Test accuracy: 42.61
Round   3, Train loss: 1.458, Test loss: 2.069, Test accuracy: 49.14
Round   4, Train loss: 1.389, Test loss: 2.002, Test accuracy: 57.24
Round   5, Train loss: 1.346, Test loss: 1.954, Test accuracy: 60.50
Round   6, Train loss: 1.275, Test loss: 1.916, Test accuracy: 62.15
Round   7, Train loss: 1.410, Test loss: 1.884, Test accuracy: 65.67
Round   8, Train loss: 1.268, Test loss: 1.853, Test accuracy: 68.03
Round   9, Train loss: 1.257, Test loss: 1.852, Test accuracy: 68.20
Round  10, Train loss: 1.240, Test loss: 1.830, Test accuracy: 69.64
Round  11, Train loss: 1.191, Test loss: 1.813, Test accuracy: 70.77
Round  12, Train loss: 1.183, Test loss: 1.803, Test accuracy: 71.01
Round  13, Train loss: 1.214, Test loss: 1.791, Test accuracy: 71.64
Round  14, Train loss: 1.212, Test loss: 1.767, Test accuracy: 74.03
Round  15, Train loss: 1.269, Test loss: 1.756, Test accuracy: 74.63
Round  16, Train loss: 1.245, Test loss: 1.742, Test accuracy: 75.56
Round  17, Train loss: 1.304, Test loss: 1.743, Test accuracy: 74.73
Round  18, Train loss: 1.281, Test loss: 1.727, Test accuracy: 76.19
Round  19, Train loss: 1.163, Test loss: 1.721, Test accuracy: 76.68
Round  20, Train loss: 1.190, Test loss: 1.722, Test accuracy: 76.29
Round  21, Train loss: 1.239, Test loss: 1.719, Test accuracy: 76.35
Round  22, Train loss: 1.209, Test loss: 1.714, Test accuracy: 76.98
Round  23, Train loss: 1.166, Test loss: 1.713, Test accuracy: 77.06
Round  24, Train loss: 1.232, Test loss: 1.713, Test accuracy: 76.97
Round  25, Train loss: 1.184, Test loss: 1.722, Test accuracy: 75.90
Round  26, Train loss: 1.160, Test loss: 1.719, Test accuracy: 75.92
Round  27, Train loss: 1.230, Test loss: 1.719, Test accuracy: 75.78
Round  28, Train loss: 1.279, Test loss: 1.717, Test accuracy: 75.97
Round  29, Train loss: 1.183, Test loss: 1.720, Test accuracy: 75.49
Round  30, Train loss: 1.184, Test loss: 1.720, Test accuracy: 75.30
Round  31, Train loss: 1.278, Test loss: 1.718, Test accuracy: 75.58
Round  32, Train loss: 1.231, Test loss: 1.720, Test accuracy: 75.15
Round  33, Train loss: 1.228, Test loss: 1.720, Test accuracy: 75.09
Round  34, Train loss: 1.157, Test loss: 1.723, Test accuracy: 74.67
Round  35, Train loss: 1.230, Test loss: 1.724, Test accuracy: 74.48
Round  36, Train loss: 1.180, Test loss: 1.720, Test accuracy: 75.08
Round  37, Train loss: 1.159, Test loss: 1.719, Test accuracy: 75.05
Round  38, Train loss: 1.229, Test loss: 1.722, Test accuracy: 74.76
Round  39, Train loss: 1.251, Test loss: 1.726, Test accuracy: 74.27
Round  40, Train loss: 1.230, Test loss: 1.727, Test accuracy: 74.17
Round  41, Train loss: 1.179, Test loss: 1.726, Test accuracy: 74.15
Round  42, Train loss: 1.178, Test loss: 1.723, Test accuracy: 74.51
Round  43, Train loss: 1.203, Test loss: 1.725, Test accuracy: 74.23
Round  44, Train loss: 1.228, Test loss: 1.733, Test accuracy: 73.53
Round  45, Train loss: 1.202, Test loss: 1.733, Test accuracy: 73.62
Round  46, Train loss: 1.228, Test loss: 1.733, Test accuracy: 73.55
Round  47, Train loss: 1.155, Test loss: 1.737, Test accuracy: 73.12
Round  48, Train loss: 1.229, Test loss: 1.732, Test accuracy: 73.49
Round  49, Train loss: 1.155, Test loss: 1.732, Test accuracy: 73.50
Round  50, Train loss: 1.178, Test loss: 1.733, Test accuracy: 73.41
Round  51, Train loss: 1.226, Test loss: 1.734, Test accuracy: 73.20
Round  52, Train loss: 1.181, Test loss: 1.740, Test accuracy: 72.57
Round  53, Train loss: 1.203, Test loss: 1.738, Test accuracy: 72.85
Round  54, Train loss: 1.204, Test loss: 1.736, Test accuracy: 73.11
Round  55, Train loss: 1.204, Test loss: 1.741, Test accuracy: 72.48
Round  56, Train loss: 1.202, Test loss: 1.744, Test accuracy: 72.14
Round  57, Train loss: 1.154, Test loss: 1.748, Test accuracy: 71.87
Round  58, Train loss: 1.252, Test loss: 1.748, Test accuracy: 71.72
Round  59, Train loss: 1.180, Test loss: 1.751, Test accuracy: 71.43
Round  60, Train loss: 1.276, Test loss: 1.751, Test accuracy: 71.41
Round  61, Train loss: 1.263, Test loss: 1.755, Test accuracy: 70.97
Round  62, Train loss: 1.154, Test loss: 1.758, Test accuracy: 70.58
Round  63, Train loss: 1.202, Test loss: 1.756, Test accuracy: 70.71
Round  64, Train loss: 1.226, Test loss: 1.758, Test accuracy: 70.58
Round  65, Train loss: 1.228, Test loss: 1.758, Test accuracy: 70.50
Round  66, Train loss: 1.203, Test loss: 1.754, Test accuracy: 71.01
Round  67, Train loss: 1.202, Test loss: 1.756, Test accuracy: 70.63
Round  68, Train loss: 1.226, Test loss: 1.761, Test accuracy: 70.10
Round  69, Train loss: 1.178, Test loss: 1.756, Test accuracy: 70.45
Round  70, Train loss: 1.153, Test loss: 1.762, Test accuracy: 69.75
Round  71, Train loss: 1.203, Test loss: 1.766, Test accuracy: 69.45
Round  72, Train loss: 1.202, Test loss: 1.769, Test accuracy: 69.24
Round  73, Train loss: 1.153, Test loss: 1.774, Test accuracy: 68.49
Round  74, Train loss: 1.153, Test loss: 1.777, Test accuracy: 68.36
Round  75, Train loss: 1.251, Test loss: 1.779, Test accuracy: 68.17
Round  76, Train loss: 1.249, Test loss: 1.781, Test accuracy: 68.09
Round  77, Train loss: 1.201, Test loss: 1.782, Test accuracy: 68.00
Round  78, Train loss: 1.177, Test loss: 1.787, Test accuracy: 67.46
Round  79, Train loss: 1.202, Test loss: 1.784, Test accuracy: 67.70
Round  80, Train loss: 1.178, Test loss: 1.790, Test accuracy: 67.20
Round  81, Train loss: 1.177, Test loss: 1.785, Test accuracy: 67.72
Round  82, Train loss: 1.227, Test loss: 1.785, Test accuracy: 67.72
Round  83, Train loss: 1.225, Test loss: 1.787, Test accuracy: 67.44
Round  84, Train loss: 1.104, Test loss: 1.784, Test accuracy: 67.85
Round  85, Train loss: 1.178, Test loss: 1.788, Test accuracy: 67.43
Round  86, Train loss: 1.177, Test loss: 1.790, Test accuracy: 67.11
Round  87, Train loss: 1.247, Test loss: 1.790, Test accuracy: 67.23
Round  88, Train loss: 1.251, Test loss: 1.787, Test accuracy: 67.55
Round  89, Train loss: 1.250, Test loss: 1.791, Test accuracy: 67.08
Round  90, Train loss: 1.225, Test loss: 1.788, Test accuracy: 67.36
Round  91, Train loss: 1.202, Test loss: 1.790, Test accuracy: 67.13
Round  92, Train loss: 1.178, Test loss: 1.791, Test accuracy: 67.03
Round  93, Train loss: 1.226, Test loss: 1.792, Test accuracy: 66.77
Round  94, Train loss: 1.203, Test loss: 1.795, Test accuracy: 66.53
Round  95, Train loss: 1.127, Test loss: 1.797, Test accuracy: 66.48
Round  96, Train loss: 1.251, Test loss: 1.792, Test accuracy: 66.90
Round  97, Train loss: 1.225, Test loss: 1.793, Test accuracy: 66.91
Round  98, Train loss: 1.225, Test loss: 1.788, Test accuracy: 67.41
Round  99, Train loss: 1.176, Test loss: 1.790, Test accuracy: 67.18
Final Round, Train loss: 1.199, Test loss: 1.796, Test accuracy: 66.39
Average accuracy final 10 rounds: 66.97
1171.1510274410248
[]
[28.85, 38.87, 42.61, 49.14, 57.24, 60.5, 62.15, 65.67, 68.03, 68.2, 69.64, 70.77, 71.01, 71.64, 74.03, 74.63, 75.56, 74.73, 76.19, 76.68, 76.29, 76.35, 76.98, 77.06, 76.97, 75.9, 75.92, 75.78, 75.97, 75.49, 75.3, 75.58, 75.15, 75.09, 74.67, 74.48, 75.08, 75.05, 74.76, 74.27, 74.17, 74.15, 74.51, 74.23, 73.53, 73.62, 73.55, 73.12, 73.49, 73.5, 73.41, 73.2, 72.57, 72.85, 73.11, 72.48, 72.14, 71.87, 71.72, 71.43, 71.41, 70.97, 70.58, 70.71, 70.58, 70.5, 71.01, 70.63, 70.1, 70.45, 69.75, 69.45, 69.24, 68.49, 68.36, 68.17, 68.09, 68.0, 67.46, 67.7, 67.2, 67.72, 67.72, 67.44, 67.85, 67.43, 67.11, 67.23, 67.55, 67.08, 67.36, 67.13, 67.03, 66.77, 66.53, 66.48, 66.9, 66.91, 67.41, 67.18, 66.39]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.291, Test loss: 2.292, Test accuracy: 16.80
Round   1, Train loss: 2.282, Test loss: 2.290, Test accuracy: 20.59
Round   2, Train loss: 2.282, Test loss: 2.294, Test accuracy: 17.33
Round   3, Train loss: 2.269, Test loss: 2.277, Test accuracy: 20.73
Round   4, Train loss: 2.270, Test loss: 2.290, Test accuracy: 13.00
Round   5, Train loss: 2.277, Test loss: 2.268, Test accuracy: 20.81
Round   6, Train loss: 2.117, Test loss: 2.223, Test accuracy: 25.23
Round   7, Train loss: 2.106, Test loss: 2.215, Test accuracy: 25.43
Round   8, Train loss: 2.118, Test loss: 2.212, Test accuracy: 23.95
Round   9, Train loss: 2.029, Test loss: 2.190, Test accuracy: 26.11
Round  10, Train loss: 1.728, Test loss: 2.158, Test accuracy: 28.56
Round  11, Train loss: 2.021, Test loss: 2.196, Test accuracy: 28.57
Round  12, Train loss: 1.793, Test loss: 2.169, Test accuracy: 29.56
Round  13, Train loss: 1.272, Test loss: 2.024, Test accuracy: 45.51
Round  14, Train loss: 1.620, Test loss: 2.029, Test accuracy: 47.52
Round  15, Train loss: 1.837, Test loss: 2.059, Test accuracy: 41.58
Round  16, Train loss: 0.709, Test loss: 1.992, Test accuracy: 47.89
Round  17, Train loss: 1.235, Test loss: 1.904, Test accuracy: 58.28
Round  18, Train loss: 0.830, Test loss: 1.929, Test accuracy: 55.89
Round  19, Train loss: 1.107, Test loss: 1.942, Test accuracy: 55.23
Round  20, Train loss: 1.285, Test loss: 2.000, Test accuracy: 49.37
Round  21, Train loss: 0.817, Test loss: 1.984, Test accuracy: 48.91
Round  22, Train loss: -0.285, Test loss: 1.838, Test accuracy: 64.62
Round  23, Train loss: 1.134, Test loss: 1.895, Test accuracy: 59.31
Round  24, Train loss: -0.310, Test loss: 1.790, Test accuracy: 69.89
Round  25, Train loss: 0.477, Test loss: 1.826, Test accuracy: 65.87
Round  26, Train loss: 0.328, Test loss: 1.850, Test accuracy: 63.65
Round  27, Train loss: 0.141, Test loss: 1.828, Test accuracy: 65.32
Round  28, Train loss: -1.068, Test loss: 1.758, Test accuracy: 72.72
Round  29, Train loss: -0.072, Test loss: 1.800, Test accuracy: 69.61
Round  30, Train loss: -0.621, Test loss: 1.774, Test accuracy: 70.91
Round  31, Train loss: -0.354, Test loss: 1.783, Test accuracy: 71.40
Round  32, Train loss: -1.099, Test loss: 1.699, Test accuracy: 78.28
Round  33, Train loss: -1.135, Test loss: 1.692, Test accuracy: 78.11
Round  34, Train loss: -0.194, Test loss: 1.738, Test accuracy: 73.28
Round  35, Train loss: -0.599, Test loss: 1.753, Test accuracy: 71.73
Round  36, Train loss: -0.892, Test loss: 1.729, Test accuracy: 74.69
Round  37, Train loss: -2.054, Test loss: 1.722, Test accuracy: 74.97
Round  38, Train loss: -1.112, Test loss: 1.750, Test accuracy: 72.96
Round  39, Train loss: -2.238, Test loss: 1.669, Test accuracy: 79.44
Round  40, Train loss: -0.671, Test loss: 1.687, Test accuracy: 77.86
Round  41, Train loss: -1.797, Test loss: 1.652, Test accuracy: 81.35
Round  42, Train loss: -1.903, Test loss: 1.651, Test accuracy: 81.32
Round  43, Train loss: -1.510, Test loss: 1.644, Test accuracy: 81.91
Round  44, Train loss: -1.350, Test loss: 1.644, Test accuracy: 81.84
Round  45, Train loss: -1.963, Test loss: 1.655, Test accuracy: 80.88
Round  46, Train loss: -1.399, Test loss: 1.643, Test accuracy: 82.04
Round  47, Train loss: -2.487, Test loss: 1.636, Test accuracy: 82.84
Round  48, Train loss: -1.806, Test loss: 1.641, Test accuracy: 82.37
Round  49, Train loss: -2.637, Test loss: 1.668, Test accuracy: 79.54
Round  50, Train loss: -2.894, Test loss: 1.642, Test accuracy: 82.17
Round  51, Train loss: -3.100, Test loss: 1.615, Test accuracy: 84.66
Round  52, Train loss: -2.950, Test loss: 1.627, Test accuracy: 83.42
Round  53, Train loss: -1.859, Test loss: 1.634, Test accuracy: 82.73
Round  54, Train loss: -2.309, Test loss: 1.630, Test accuracy: 83.12
Round  55, Train loss: -2.231, Test loss: 1.600, Test accuracy: 86.16
Round  56, Train loss: -2.566, Test loss: 1.610, Test accuracy: 85.16
Round  57, Train loss: -2.804, Test loss: 1.621, Test accuracy: 84.05
Round  58, Train loss: -2.691, Test loss: 1.637, Test accuracy: 82.41
Round  59, Train loss: -2.570, Test loss: 1.629, Test accuracy: 83.33
Round  60, Train loss: -2.860, Test loss: 1.619, Test accuracy: 84.18
Round  61, Train loss: -2.866, Test loss: 1.621, Test accuracy: 84.00
Round  62, Train loss: -3.242, Test loss: 1.613, Test accuracy: 84.81
Round  63, Train loss: -3.094, Test loss: 1.629, Test accuracy: 83.14
Round  64, Train loss: -2.873, Test loss: 1.640, Test accuracy: 82.22
Round  65, Train loss: -3.041, Test loss: 1.622, Test accuracy: 83.94
Round  66, Train loss: -2.780, Test loss: 1.626, Test accuracy: 83.60
Round  67, Train loss: -3.180, Test loss: 1.621, Test accuracy: 83.96
Round  68, Train loss: -3.618, Test loss: 1.615, Test accuracy: 84.65
Round  69, Train loss: -3.018, Test loss: 1.619, Test accuracy: 84.22
Round  70, Train loss: -3.018, Test loss: 1.632, Test accuracy: 82.85
Round  71, Train loss: -3.265, Test loss: 1.632, Test accuracy: 82.86
Round  72, Train loss: -2.855, Test loss: 1.640, Test accuracy: 82.08
Round  73, Train loss: -2.719, Test loss: 1.632, Test accuracy: 82.88
Round  74, Train loss: -2.950, Test loss: 1.638, Test accuracy: 82.34
Round  75, Train loss: -2.825, Test loss: 1.636, Test accuracy: 82.51
Round  76, Train loss: -1.965, Test loss: 1.637, Test accuracy: 82.42
Round  77, Train loss: -3.196, Test loss: 1.630, Test accuracy: 83.05
Round  78, Train loss: -3.177, Test loss: 1.621, Test accuracy: 84.03
Round  79, Train loss: -3.176, Test loss: 1.628, Test accuracy: 83.39
Round  80, Train loss: -2.802, Test loss: 1.618, Test accuracy: 84.33
Round  81, Train loss: -3.817, Test loss: 1.601, Test accuracy: 86.04
Round  82, Train loss: -2.726, Test loss: 1.609, Test accuracy: 85.19
Round  83, Train loss: -3.165, Test loss: 1.585, Test accuracy: 87.63
Round  84, Train loss: -3.569, Test loss: 1.610, Test accuracy: 85.07
Round  85, Train loss: -2.425, Test loss: 1.587, Test accuracy: 87.45
Round  86, Train loss: -3.209, Test loss: 1.594, Test accuracy: 86.73
Round  87, Train loss: -2.899, Test loss: 1.612, Test accuracy: 84.86
Round  88, Train loss: -3.058, Test loss: 1.603, Test accuracy: 85.80
Round  89, Train loss: -2.209, Test loss: 1.615, Test accuracy: 84.63
Round  90, Train loss: -3.239, Test loss: 1.616, Test accuracy: 84.50
Round  91, Train loss: -3.634, Test loss: 1.622, Test accuracy: 83.83
Round  92, Train loss: -3.296, Test loss: 1.597, Test accuracy: 86.31
Round  93, Train loss: -3.239, Test loss: 1.598, Test accuracy: 86.40
Round  94, Train loss: -2.675, Test loss: 1.613, Test accuracy: 84.87
Round  95, Train loss: -2.807, Test loss: 1.602, Test accuracy: 85.94
Round  96, Train loss: -3.268, Test loss: 1.604, Test accuracy: 85.81
Round  97, Train loss: -3.234, Test loss: 1.596, Test accuracy: 86.57
Round  98, Train loss: -3.579, Test loss: 1.592, Test accuracy: 86.91
Round  99, Train loss: -2.619, Test loss: 1.585, Test accuracy: 87.68
Final Round, Train loss: 1.777, Test loss: 1.710, Test accuracy: 76.20
Average accuracy final 10 rounds: 85.882
Average global accuracy final 10 rounds: 85.882
891.855387210846
[]
[16.8, 20.59, 17.33, 20.73, 13.0, 20.81, 25.23, 25.43, 23.95, 26.11, 28.56, 28.57, 29.56, 45.51, 47.52, 41.58, 47.89, 58.28, 55.89, 55.23, 49.37, 48.91, 64.62, 59.31, 69.89, 65.87, 63.65, 65.32, 72.72, 69.61, 70.91, 71.4, 78.28, 78.11, 73.28, 71.73, 74.69, 74.97, 72.96, 79.44, 77.86, 81.35, 81.32, 81.91, 81.84, 80.88, 82.04, 82.84, 82.37, 79.54, 82.17, 84.66, 83.42, 82.73, 83.12, 86.16, 85.16, 84.05, 82.41, 83.33, 84.18, 84.0, 84.81, 83.14, 82.22, 83.94, 83.6, 83.96, 84.65, 84.22, 82.85, 82.86, 82.08, 82.88, 82.34, 82.51, 82.42, 83.05, 84.03, 83.39, 84.33, 86.04, 85.19, 87.63, 85.07, 87.45, 86.73, 84.86, 85.8, 84.63, 84.5, 83.83, 86.31, 86.4, 84.87, 85.94, 85.81, 86.57, 86.91, 87.68, 76.2]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.293, Test loss: 2.296, Test accuracy: 17.35
Round   0, Global train loss: 2.293, Global test loss: 2.301, Global test accuracy: 13.00
Round   1, Train loss: 2.278, Test loss: 2.277, Test accuracy: 21.54
Round   1, Global train loss: 2.278, Global test loss: 2.299, Global test accuracy: 15.31
Round   2, Train loss: 2.235, Test loss: 2.233, Test accuracy: 26.37
Round   2, Global train loss: 2.235, Global test loss: 2.294, Global test accuracy: 16.09
Round   3, Train loss: 2.114, Test loss: 2.140, Test accuracy: 38.32
Round   3, Global train loss: 2.114, Global test loss: 2.281, Global test accuracy: 16.66
Round   4, Train loss: 1.965, Test loss: 2.039, Test accuracy: 47.52
Round   4, Global train loss: 1.965, Global test loss: 2.264, Global test accuracy: 17.53
Round   5, Train loss: 1.964, Test loss: 1.997, Test accuracy: 49.94
Round   5, Global train loss: 1.964, Global test loss: 2.264, Global test accuracy: 17.17
Round   6, Train loss: 1.907, Test loss: 1.948, Test accuracy: 55.16
Round   6, Global train loss: 1.907, Global test loss: 2.269, Global test accuracy: 17.18
Round   7, Train loss: 1.926, Test loss: 1.944, Test accuracy: 55.21
Round   7, Global train loss: 1.926, Global test loss: 2.250, Global test accuracy: 19.64
Round   8, Train loss: 1.922, Test loss: 1.938, Test accuracy: 55.44
Round   8, Global train loss: 1.922, Global test loss: 2.249, Global test accuracy: 19.82
Round   9, Train loss: 1.948, Test loss: 1.934, Test accuracy: 55.33
Round   9, Global train loss: 1.948, Global test loss: 2.250, Global test accuracy: 19.28
Round  10, Train loss: 1.872, Test loss: 1.909, Test accuracy: 57.89
Round  10, Global train loss: 1.872, Global test loss: 2.267, Global test accuracy: 15.72
Round  11, Train loss: 1.843, Test loss: 1.886, Test accuracy: 59.24
Round  11, Global train loss: 1.843, Global test loss: 2.261, Global test accuracy: 17.51
Round  12, Train loss: 1.955, Test loss: 1.878, Test accuracy: 59.67
Round  12, Global train loss: 1.955, Global test loss: 2.256, Global test accuracy: 18.03
Round  13, Train loss: 1.784, Test loss: 1.869, Test accuracy: 60.54
Round  13, Global train loss: 1.784, Global test loss: 2.263, Global test accuracy: 17.47
Round  14, Train loss: 1.912, Test loss: 1.865, Test accuracy: 60.89
Round  14, Global train loss: 1.912, Global test loss: 2.264, Global test accuracy: 16.98
Round  15, Train loss: 1.920, Test loss: 1.864, Test accuracy: 60.47
Round  15, Global train loss: 1.920, Global test loss: 2.289, Global test accuracy: 14.46
Round  16, Train loss: 1.918, Test loss: 1.866, Test accuracy: 60.24
Round  16, Global train loss: 1.918, Global test loss: 2.264, Global test accuracy: 17.31
Round  17, Train loss: 1.787, Test loss: 1.863, Test accuracy: 60.39
Round  17, Global train loss: 1.787, Global test loss: 2.248, Global test accuracy: 19.45
Round  18, Train loss: 1.862, Test loss: 1.846, Test accuracy: 62.04
Round  18, Global train loss: 1.862, Global test loss: 2.261, Global test accuracy: 17.59
Round  19, Train loss: 1.827, Test loss: 1.845, Test accuracy: 62.17
Round  19, Global train loss: 1.827, Global test loss: 2.238, Global test accuracy: 20.51
Round  20, Train loss: 1.906, Test loss: 1.850, Test accuracy: 61.49
Round  20, Global train loss: 1.906, Global test loss: 2.229, Global test accuracy: 22.39
Round  21, Train loss: 1.914, Test loss: 1.865, Test accuracy: 59.88
Round  21, Global train loss: 1.914, Global test loss: 2.250, Global test accuracy: 18.94
Round  22, Train loss: 1.926, Test loss: 1.854, Test accuracy: 61.09
Round  22, Global train loss: 1.926, Global test loss: 2.248, Global test accuracy: 18.89
Round  23, Train loss: 1.981, Test loss: 1.847, Test accuracy: 61.89
Round  23, Global train loss: 1.981, Global test loss: 2.260, Global test accuracy: 17.55
Round  24, Train loss: 1.942, Test loss: 1.837, Test accuracy: 62.85
Round  24, Global train loss: 1.942, Global test loss: 2.246, Global test accuracy: 19.19
Round  25, Train loss: 1.821, Test loss: 1.836, Test accuracy: 62.97
Round  25, Global train loss: 1.821, Global test loss: 2.244, Global test accuracy: 19.90
Round  26, Train loss: 1.772, Test loss: 1.837, Test accuracy: 62.79
Round  26, Global train loss: 1.772, Global test loss: 2.247, Global test accuracy: 19.35
Round  27, Train loss: 1.893, Test loss: 1.837, Test accuracy: 62.80
Round  27, Global train loss: 1.893, Global test loss: 2.247, Global test accuracy: 19.04
Round  28, Train loss: 1.900, Test loss: 1.836, Test accuracy: 62.82
Round  28, Global train loss: 1.900, Global test loss: 2.249, Global test accuracy: 18.97
Round  29, Train loss: 1.872, Test loss: 1.829, Test accuracy: 63.54
Round  29, Global train loss: 1.872, Global test loss: 2.267, Global test accuracy: 17.25
Round  30, Train loss: 1.784, Test loss: 1.829, Test accuracy: 63.54
Round  30, Global train loss: 1.784, Global test loss: 2.231, Global test accuracy: 21.83
Round  31, Train loss: 1.870, Test loss: 1.829, Test accuracy: 63.53
Round  31, Global train loss: 1.870, Global test loss: 2.245, Global test accuracy: 19.65
Round  32, Train loss: 1.832, Test loss: 1.829, Test accuracy: 63.56
Round  32, Global train loss: 1.832, Global test loss: 2.261, Global test accuracy: 17.68
Round  33, Train loss: 1.832, Test loss: 1.829, Test accuracy: 63.58
Round  33, Global train loss: 1.832, Global test loss: 2.252, Global test accuracy: 18.90
Round  34, Train loss: 1.882, Test loss: 1.827, Test accuracy: 63.63
Round  34, Global train loss: 1.882, Global test loss: 2.257, Global test accuracy: 18.89
Round  35, Train loss: 1.877, Test loss: 1.823, Test accuracy: 64.32
Round  35, Global train loss: 1.877, Global test loss: 2.259, Global test accuracy: 18.00
Round  36, Train loss: 1.855, Test loss: 1.815, Test accuracy: 65.15
Round  36, Global train loss: 1.855, Global test loss: 2.236, Global test accuracy: 21.50
Round  37, Train loss: 1.836, Test loss: 1.795, Test accuracy: 67.26
Round  37, Global train loss: 1.836, Global test loss: 2.236, Global test accuracy: 20.79
Round  38, Train loss: 1.893, Test loss: 1.795, Test accuracy: 67.22
Round  38, Global train loss: 1.893, Global test loss: 2.242, Global test accuracy: 20.20
Round  39, Train loss: 1.792, Test loss: 1.795, Test accuracy: 67.19
Round  39, Global train loss: 1.792, Global test loss: 2.247, Global test accuracy: 19.37
Round  40, Train loss: 1.823, Test loss: 1.795, Test accuracy: 67.17
Round  40, Global train loss: 1.823, Global test loss: 2.278, Global test accuracy: 15.81
Round  41, Train loss: 1.866, Test loss: 1.796, Test accuracy: 67.06
Round  41, Global train loss: 1.866, Global test loss: 2.268, Global test accuracy: 16.76
Round  42, Train loss: 1.699, Test loss: 1.797, Test accuracy: 66.83
Round  42, Global train loss: 1.699, Global test loss: 2.227, Global test accuracy: 22.07
Round  43, Train loss: 1.742, Test loss: 1.791, Test accuracy: 67.32
Round  43, Global train loss: 1.742, Global test loss: 2.235, Global test accuracy: 21.14
Round  44, Train loss: 1.846, Test loss: 1.790, Test accuracy: 67.44
Round  44, Global train loss: 1.846, Global test loss: 2.215, Global test accuracy: 23.65
Round  45, Train loss: 1.761, Test loss: 1.782, Test accuracy: 68.26
Round  45, Global train loss: 1.761, Global test loss: 2.206, Global test accuracy: 24.62
Round  46, Train loss: 1.790, Test loss: 1.782, Test accuracy: 68.17
Round  46, Global train loss: 1.790, Global test loss: 2.215, Global test accuracy: 23.82
Round  47, Train loss: 1.855, Test loss: 1.781, Test accuracy: 68.30
Round  47, Global train loss: 1.855, Global test loss: 2.231, Global test accuracy: 21.07
Round  48, Train loss: 1.840, Test loss: 1.790, Test accuracy: 67.29
Round  48, Global train loss: 1.840, Global test loss: 2.201, Global test accuracy: 25.48
Round  49, Train loss: 1.711, Test loss: 1.789, Test accuracy: 67.43
Round  49, Global train loss: 1.711, Global test loss: 2.209, Global test accuracy: 24.61
Round  50, Train loss: 1.877, Test loss: 1.798, Test accuracy: 66.46
Round  50, Global train loss: 1.877, Global test loss: 2.201, Global test accuracy: 25.54
Round  51, Train loss: 1.823, Test loss: 1.799, Test accuracy: 66.35
Round  51, Global train loss: 1.823, Global test loss: 2.223, Global test accuracy: 22.26
Round  52, Train loss: 1.892, Test loss: 1.806, Test accuracy: 65.65
Round  52, Global train loss: 1.892, Global test loss: 2.217, Global test accuracy: 23.51
Round  53, Train loss: 1.812, Test loss: 1.797, Test accuracy: 66.45
Round  53, Global train loss: 1.812, Global test loss: 2.219, Global test accuracy: 23.29
Round  54, Train loss: 1.795, Test loss: 1.789, Test accuracy: 67.35
Round  54, Global train loss: 1.795, Global test loss: 2.228, Global test accuracy: 21.79
Round  55, Train loss: 1.797, Test loss: 1.788, Test accuracy: 67.40
Round  55, Global train loss: 1.797, Global test loss: 2.220, Global test accuracy: 22.06
Round  56, Train loss: 1.788, Test loss: 1.787, Test accuracy: 67.48
Round  56, Global train loss: 1.788, Global test loss: 2.204, Global test accuracy: 24.18
Round  57, Train loss: 1.767, Test loss: 1.787, Test accuracy: 67.50
Round  57, Global train loss: 1.767, Global test loss: 2.210, Global test accuracy: 23.32
Round  58, Train loss: 1.819, Test loss: 1.786, Test accuracy: 67.56
Round  58, Global train loss: 1.819, Global test loss: 2.212, Global test accuracy: 23.69
Round  59, Train loss: 1.815, Test loss: 1.787, Test accuracy: 67.52
Round  59, Global train loss: 1.815, Global test loss: 2.227, Global test accuracy: 21.88
Round  60, Train loss: 1.864, Test loss: 1.787, Test accuracy: 67.55
Round  60, Global train loss: 1.864, Global test loss: 2.225, Global test accuracy: 22.43
Round  61, Train loss: 1.721, Test loss: 1.787, Test accuracy: 67.58
Round  61, Global train loss: 1.721, Global test loss: 2.217, Global test accuracy: 23.46
Round  62, Train loss: 1.720, Test loss: 1.786, Test accuracy: 67.59
Round  62, Global train loss: 1.720, Global test loss: 2.214, Global test accuracy: 23.72
Round  63, Train loss: 1.783, Test loss: 1.785, Test accuracy: 67.63
Round  63, Global train loss: 1.783, Global test loss: 2.227, Global test accuracy: 22.10
Round  64, Train loss: 1.694, Test loss: 1.788, Test accuracy: 67.35
Round  64, Global train loss: 1.694, Global test loss: 2.212, Global test accuracy: 23.89
Round  65, Train loss: 1.854, Test loss: 1.788, Test accuracy: 67.33
Round  65, Global train loss: 1.854, Global test loss: 2.217, Global test accuracy: 23.35
Round  66, Train loss: 1.788, Test loss: 1.779, Test accuracy: 68.27
Round  66, Global train loss: 1.788, Global test loss: 2.221, Global test accuracy: 22.14
Round  67, Train loss: 1.784, Test loss: 1.779, Test accuracy: 68.28
Round  67, Global train loss: 1.784, Global test loss: 2.239, Global test accuracy: 20.10
Round  68, Train loss: 1.722, Test loss: 1.777, Test accuracy: 68.58
Round  68, Global train loss: 1.722, Global test loss: 2.208, Global test accuracy: 24.08
Round  69, Train loss: 1.754, Test loss: 1.776, Test accuracy: 68.59
Round  69, Global train loss: 1.754, Global test loss: 2.210, Global test accuracy: 23.90
Round  70, Train loss: 1.714, Test loss: 1.776, Test accuracy: 68.56
Round  70, Global train loss: 1.714, Global test loss: 2.200, Global test accuracy: 25.55
Round  71, Train loss: 1.746, Test loss: 1.785, Test accuracy: 67.71
Round  71, Global train loss: 1.746, Global test loss: 2.211, Global test accuracy: 23.50
Round  72, Train loss: 1.851, Test loss: 1.762, Test accuracy: 70.02
Round  72, Global train loss: 1.851, Global test loss: 2.221, Global test accuracy: 22.35
Round  73, Train loss: 1.739, Test loss: 1.762, Test accuracy: 70.27
Round  73, Global train loss: 1.739, Global test loss: 2.207, Global test accuracy: 24.26
Round  74, Train loss: 1.778, Test loss: 1.768, Test accuracy: 69.56
Round  74, Global train loss: 1.778, Global test loss: 2.230, Global test accuracy: 21.50
Round  75, Train loss: 1.630, Test loss: 1.767, Test accuracy: 69.64
Round  75, Global train loss: 1.630, Global test loss: 2.210, Global test accuracy: 24.32
Round  76, Train loss: 1.750, Test loss: 1.767, Test accuracy: 69.62
Round  76, Global train loss: 1.750, Global test loss: 2.222, Global test accuracy: 22.44
Round  77, Train loss: 1.668, Test loss: 1.762, Test accuracy: 70.20
Round  77, Global train loss: 1.668, Global test loss: 2.209, Global test accuracy: 23.71
Round  78, Train loss: 1.745, Test loss: 1.761, Test accuracy: 70.16
Round  78, Global train loss: 1.745, Global test loss: 2.223, Global test accuracy: 22.25
Round  79, Train loss: 1.661, Test loss: 1.759, Test accuracy: 70.27
Round  79, Global train loss: 1.661, Global test loss: 2.208, Global test accuracy: 24.19
Round  80, Train loss: 1.809, Test loss: 1.760, Test accuracy: 70.24
Round  80, Global train loss: 1.809, Global test loss: 2.238, Global test accuracy: 20.80
Round  81, Train loss: 1.758, Test loss: 1.761, Test accuracy: 70.14
Round  81, Global train loss: 1.758, Global test loss: 2.217, Global test accuracy: 23.05
Round  82, Train loss: 1.766, Test loss: 1.755, Test accuracy: 70.76
Round  82, Global train loss: 1.766, Global test loss: 2.211, Global test accuracy: 23.54
Round  83, Train loss: 1.703, Test loss: 1.754, Test accuracy: 70.82
Round  83, Global train loss: 1.703, Global test loss: 2.232, Global test accuracy: 20.87
Round  84, Train loss: 1.830, Test loss: 1.753, Test accuracy: 71.02
Round  84, Global train loss: 1.830, Global test loss: 2.220, Global test accuracy: 22.70
Round  85, Train loss: 1.731, Test loss: 1.753, Test accuracy: 71.08
Round  85, Global train loss: 1.731, Global test loss: 2.205, Global test accuracy: 24.60
Round  86, Train loss: 1.781, Test loss: 1.752, Test accuracy: 71.11
Round  86, Global train loss: 1.781, Global test loss: 2.212, Global test accuracy: 23.11
Round  87, Train loss: 1.729, Test loss: 1.752, Test accuracy: 71.21
Round  87, Global train loss: 1.729, Global test loss: 2.203, Global test accuracy: 24.90
Round  88, Train loss: 1.755, Test loss: 1.753, Test accuracy: 71.15
Round  88, Global train loss: 1.755, Global test loss: 2.204, Global test accuracy: 24.93
Round  89, Train loss: 1.712, Test loss: 1.745, Test accuracy: 71.93
Round  89, Global train loss: 1.712, Global test loss: 2.216, Global test accuracy: 23.47
Round  90, Train loss: 1.718, Test loss: 1.745, Test accuracy: 71.99
Round  90, Global train loss: 1.718, Global test loss: 2.205, Global test accuracy: 24.11
Round  91, Train loss: 1.727, Test loss: 1.761, Test accuracy: 70.18
Round  91, Global train loss: 1.727, Global test loss: 2.218, Global test accuracy: 22.41
Round  92, Train loss: 1.700, Test loss: 1.760, Test accuracy: 70.37
Round  92, Global train loss: 1.700, Global test loss: 2.210, Global test accuracy: 23.63
Round  93, Train loss: 1.721, Test loss: 1.759, Test accuracy: 70.37
Round  93, Global train loss: 1.721, Global test loss: 2.213, Global test accuracy: 23.84
Round  94, Train loss: 1.719, Test loss: 1.759, Test accuracy: 70.43
Round  94, Global train loss: 1.719, Global test loss: 2.208, Global test accuracy: 24.01
Round  95, Train loss: 1.675, Test loss: 1.759, Test accuracy: 70.37
Round  95, Global train loss: 1.675, Global test loss: 2.207, Global test accuracy: 24.01/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.830, Test loss: 1.759, Test accuracy: 70.34
Round  96, Global train loss: 1.830, Global test loss: 2.226, Global test accuracy: 22.30
Round  97, Train loss: 1.780, Test loss: 1.741, Test accuracy: 72.25
Round  97, Global train loss: 1.780, Global test loss: 2.218, Global test accuracy: 23.12
Round  98, Train loss: 1.772, Test loss: 1.750, Test accuracy: 71.33
Round  98, Global train loss: 1.772, Global test loss: 2.219, Global test accuracy: 22.58
Round  99, Train loss: 1.760, Test loss: 1.751, Test accuracy: 71.22
Round  99, Global train loss: 1.760, Global test loss: 2.205, Global test accuracy: 24.37
Final Round, Train loss: 1.714, Test loss: 1.743, Test accuracy: 72.10
Final Round, Global train loss: 1.714, Global test loss: 2.205, Global test accuracy: 24.37
Average accuracy final 10 rounds: 70.885 

Average global accuracy final 10 rounds: 23.438000000000002 

1243.2524256706238
[0.9756631851196289, 1.9513263702392578, 2.7642366886138916, 3.5771470069885254, 4.412205696105957, 5.247264385223389, 6.1433563232421875, 7.039448261260986, 7.869165420532227, 8.698882579803467, 9.522669792175293, 10.34645700454712, 11.156201362609863, 11.965945720672607, 12.784159421920776, 13.602373123168945, 14.41643738746643, 15.230501651763916, 16.045654773712158, 16.8608078956604, 17.6582453250885, 18.4556827545166, 19.275299549102783, 20.094916343688965, 20.916174173355103, 21.73743200302124, 22.5711510181427, 23.40487003326416, 24.25229835510254, 25.099726676940918, 25.9172785282135, 26.734830379486084, 27.57142162322998, 28.408012866973877, 29.26553177833557, 30.123050689697266, 30.952834844589233, 31.7826189994812, 32.61953783035278, 33.456456661224365, 34.274832248687744, 35.09320783615112, 35.90820026397705, 36.72319269180298, 37.54313516616821, 38.36307764053345, 39.16654944419861, 39.97002124786377, 40.77990460395813, 41.58978796005249, 42.39622354507446, 43.202659130096436, 44.03835129737854, 44.874043464660645, 45.685033082962036, 46.49602270126343, 47.301870822906494, 48.10771894454956, 48.90842652320862, 49.709134101867676, 50.50973176956177, 51.31032943725586, 52.10239887237549, 52.89446830749512, 53.69590878486633, 54.49734926223755, 55.277573108673096, 56.05779695510864, 56.871237993240356, 57.68467903137207, 58.498215675354004, 59.31175231933594, 60.122427463531494, 60.93310260772705, 61.75265431404114, 62.572206020355225, 63.383172273635864, 64.1941385269165, 64.95639252662659, 65.71864652633667, 66.50578689575195, 67.29292726516724, 68.06635999679565, 68.83979272842407, 69.63722658157349, 70.4346604347229, 71.2453498840332, 72.0560393333435, 72.87001013755798, 73.68398094177246, 74.49162650108337, 75.29927206039429, 76.07658553123474, 76.8538990020752, 77.63329887390137, 78.41269874572754, 79.21315240859985, 80.01360607147217, 80.80728459358215, 81.60096311569214, 82.39585328102112, 83.1907434463501, 83.9937391281128, 84.79673480987549, 85.61134052276611, 86.42594623565674, 87.2464554309845, 88.06696462631226, 88.88278245925903, 89.69860029220581, 90.51042366027832, 91.32224702835083, 92.14157485961914, 92.96090269088745, 93.77431726455688, 94.58773183822632, 95.40236568450928, 96.21699953079224, 97.02894997596741, 97.84090042114258, 98.65005493164062, 99.45920944213867, 100.26478505134583, 101.07036066055298, 101.89123249053955, 102.71210432052612, 103.53141975402832, 104.35073518753052, 105.17693185806274, 106.00312852859497, 106.83073806762695, 107.65834760665894, 108.47078800201416, 109.28322839736938, 110.1028184890747, 110.92240858078003, 111.73326444625854, 112.54412031173706, 113.37114906311035, 114.19817781448364, 115.01258993148804, 115.82700204849243, 116.64039611816406, 117.4537901878357, 118.26880049705505, 119.08381080627441, 119.89023399353027, 120.69665718078613, 121.51788210868835, 122.33910703659058, 123.1570975780487, 123.97508811950684, 124.79664587974548, 125.61820363998413, 126.44105458259583, 127.26390552520752, 128.09071612358093, 128.91752672195435, 129.73057436943054, 130.54362201690674, 131.36546158790588, 132.18730115890503, 133.00741624832153, 133.82753133773804, 134.65475249290466, 135.4819736480713, 136.2964403629303, 137.1109070777893, 137.93461275100708, 138.75831842422485, 139.58943390846252, 140.4205493927002, 141.2409930229187, 142.0614366531372, 142.88343214988708, 143.70542764663696, 144.55541944503784, 145.40541124343872, 146.2569477558136, 147.10848426818848, 147.98821353912354, 148.8679428100586, 149.71392273902893, 150.55990266799927, 151.46939396858215, 152.37888526916504, 153.20812010765076, 154.03735494613647, 155.00797605514526, 155.97859716415405, 156.83467364311218, 157.6907501220703, 158.52173709869385, 159.35272407531738, 160.2005798816681, 161.0484356880188, 161.87020564079285, 162.6919755935669, 163.51873326301575, 164.3454909324646, 166.09473323822021, 167.84397554397583]
[17.35, 17.35, 21.54, 21.54, 26.37, 26.37, 38.32, 38.32, 47.52, 47.52, 49.94, 49.94, 55.16, 55.16, 55.21, 55.21, 55.44, 55.44, 55.33, 55.33, 57.89, 57.89, 59.24, 59.24, 59.67, 59.67, 60.54, 60.54, 60.89, 60.89, 60.47, 60.47, 60.24, 60.24, 60.39, 60.39, 62.04, 62.04, 62.17, 62.17, 61.49, 61.49, 59.88, 59.88, 61.09, 61.09, 61.89, 61.89, 62.85, 62.85, 62.97, 62.97, 62.79, 62.79, 62.8, 62.8, 62.82, 62.82, 63.54, 63.54, 63.54, 63.54, 63.53, 63.53, 63.56, 63.56, 63.58, 63.58, 63.63, 63.63, 64.32, 64.32, 65.15, 65.15, 67.26, 67.26, 67.22, 67.22, 67.19, 67.19, 67.17, 67.17, 67.06, 67.06, 66.83, 66.83, 67.32, 67.32, 67.44, 67.44, 68.26, 68.26, 68.17, 68.17, 68.3, 68.3, 67.29, 67.29, 67.43, 67.43, 66.46, 66.46, 66.35, 66.35, 65.65, 65.65, 66.45, 66.45, 67.35, 67.35, 67.4, 67.4, 67.48, 67.48, 67.5, 67.5, 67.56, 67.56, 67.52, 67.52, 67.55, 67.55, 67.58, 67.58, 67.59, 67.59, 67.63, 67.63, 67.35, 67.35, 67.33, 67.33, 68.27, 68.27, 68.28, 68.28, 68.58, 68.58, 68.59, 68.59, 68.56, 68.56, 67.71, 67.71, 70.02, 70.02, 70.27, 70.27, 69.56, 69.56, 69.64, 69.64, 69.62, 69.62, 70.2, 70.2, 70.16, 70.16, 70.27, 70.27, 70.24, 70.24, 70.14, 70.14, 70.76, 70.76, 70.82, 70.82, 71.02, 71.02, 71.08, 71.08, 71.11, 71.11, 71.21, 71.21, 71.15, 71.15, 71.93, 71.93, 71.99, 71.99, 70.18, 70.18, 70.37, 70.37, 70.37, 70.37, 70.43, 70.43, 70.37, 70.37, 70.34, 70.34, 72.25, 72.25, 71.33, 71.33, 71.22, 71.22, 72.1, 72.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.296, Test loss: 2.301, Test accuracy: 14.08
Round   1, Train loss: 2.291, Test loss: 2.294, Test accuracy: 14.02
Round   2, Train loss: 2.234, Test loss: 2.276, Test accuracy: 15.25
Round   3, Train loss: 2.184, Test loss: 2.276, Test accuracy: 15.16
Round   4, Train loss: 2.057, Test loss: 2.269, Test accuracy: 15.95
Round   5, Train loss: 1.972, Test loss: 2.262, Test accuracy: 17.83
Round   6, Train loss: 1.903, Test loss: 2.255, Test accuracy: 17.68
Round   7, Train loss: 1.878, Test loss: 2.250, Test accuracy: 20.44
Round   8, Train loss: 1.846, Test loss: 2.276, Test accuracy: 15.91
Round   9, Train loss: 1.837, Test loss: 2.241, Test accuracy: 20.97
Round  10, Train loss: 1.788, Test loss: 2.250, Test accuracy: 20.03
Round  11, Train loss: 1.840, Test loss: 2.246, Test accuracy: 20.14
Round  12, Train loss: 1.820, Test loss: 2.243, Test accuracy: 19.75
Round  13, Train loss: 1.777, Test loss: 2.252, Test accuracy: 18.53
Round  14, Train loss: 1.873, Test loss: 2.261, Test accuracy: 17.25
Round  15, Train loss: 1.796, Test loss: 2.278, Test accuracy: 16.26
Round  16, Train loss: 1.812, Test loss: 2.262, Test accuracy: 17.70
Round  17, Train loss: 1.797, Test loss: 2.272, Test accuracy: 16.50
Round  18, Train loss: 1.962, Test loss: 2.248, Test accuracy: 20.17
Round  19, Train loss: 1.808, Test loss: 2.249, Test accuracy: 19.73
Round  20, Train loss: 1.802, Test loss: 2.241, Test accuracy: 21.18
Round  21, Train loss: 1.750, Test loss: 2.253, Test accuracy: 18.83
Round  22, Train loss: 1.713, Test loss: 2.259, Test accuracy: 17.65
Round  23, Train loss: 1.721, Test loss: 2.245, Test accuracy: 21.02
Round  24, Train loss: 1.727, Test loss: 2.237, Test accuracy: 20.94
Round  25, Train loss: 1.694, Test loss: 2.236, Test accuracy: 20.86
Round  26, Train loss: 1.638, Test loss: 2.225, Test accuracy: 22.89
Round  27, Train loss: 1.716, Test loss: 2.251, Test accuracy: 18.67
Round  28, Train loss: 1.770, Test loss: 2.245, Test accuracy: 19.80
Round  29, Train loss: 1.696, Test loss: 2.246, Test accuracy: 19.99
Round  30, Train loss: 1.720, Test loss: 2.236, Test accuracy: 21.09
Round  31, Train loss: 1.678, Test loss: 2.231, Test accuracy: 21.67
Round  32, Train loss: 1.666, Test loss: 2.226, Test accuracy: 22.19
Round  33, Train loss: 1.689, Test loss: 2.238, Test accuracy: 20.97
Round  34, Train loss: 1.693, Test loss: 2.244, Test accuracy: 20.49
Round  35, Train loss: 1.737, Test loss: 2.248, Test accuracy: 20.03
Round  36, Train loss: 1.656, Test loss: 2.239, Test accuracy: 20.76
Round  37, Train loss: 1.662, Test loss: 2.230, Test accuracy: 22.08
Round  38, Train loss: 1.714, Test loss: 2.243, Test accuracy: 20.43
Round  39, Train loss: 1.654, Test loss: 2.233, Test accuracy: 20.97
Round  40, Train loss: 1.656, Test loss: 2.237, Test accuracy: 21.39
Round  41, Train loss: 1.647, Test loss: 2.261, Test accuracy: 18.46
Round  42, Train loss: 1.682, Test loss: 2.247, Test accuracy: 20.90
Round  43, Train loss: 1.704, Test loss: 2.229, Test accuracy: 22.16
Round  44, Train loss: 1.629, Test loss: 2.248, Test accuracy: 20.19
Round  45, Train loss: 1.655, Test loss: 2.269, Test accuracy: 17.41
Round  46, Train loss: 1.650, Test loss: 2.269, Test accuracy: 17.31
Round  47, Train loss: 1.644, Test loss: 2.251, Test accuracy: 19.38
Round  48, Train loss: 1.679, Test loss: 2.252, Test accuracy: 19.67
Round  49, Train loss: 1.642, Test loss: 2.226, Test accuracy: 22.07
Round  50, Train loss: 1.637, Test loss: 2.239, Test accuracy: 21.15
Round  51, Train loss: 1.601, Test loss: 2.234, Test accuracy: 20.94
Round  52, Train loss: 1.612, Test loss: 2.242, Test accuracy: 21.12
Round  53, Train loss: 1.731, Test loss: 2.236, Test accuracy: 21.40
Round  54, Train loss: 1.634, Test loss: 2.236, Test accuracy: 21.37
Round  55, Train loss: 1.664, Test loss: 2.249, Test accuracy: 19.57
Round  56, Train loss: 1.615, Test loss: 2.253, Test accuracy: 19.38
Round  57, Train loss: 1.633, Test loss: 2.225, Test accuracy: 22.20
Round  58, Train loss: 1.672, Test loss: 2.219, Test accuracy: 23.23
Round  59, Train loss: 1.612, Test loss: 2.239, Test accuracy: 21.12
Round  60, Train loss: 1.634, Test loss: 2.236, Test accuracy: 20.60
Round  61, Train loss: 1.695, Test loss: 2.244, Test accuracy: 19.64
Round  62, Train loss: 1.714, Test loss: 2.230, Test accuracy: 21.97
Round  63, Train loss: 1.679, Test loss: 2.246, Test accuracy: 20.42
Round  64, Train loss: 1.583, Test loss: 2.233, Test accuracy: 21.52
Round  65, Train loss: 1.658, Test loss: 2.239, Test accuracy: 20.64
Round  66, Train loss: 1.676, Test loss: 2.232, Test accuracy: 21.55
Round  67, Train loss: 1.635, Test loss: 2.235, Test accuracy: 20.51
Round  68, Train loss: 1.593, Test loss: 2.254, Test accuracy: 18.33
Round  69, Train loss: 1.628, Test loss: 2.243, Test accuracy: 20.48
Round  70, Train loss: 1.641, Test loss: 2.240, Test accuracy: 20.75
Round  71, Train loss: 1.641, Test loss: 2.233, Test accuracy: 21.98
Round  72, Train loss: 1.581, Test loss: 2.248, Test accuracy: 19.92
Round  73, Train loss: 1.598, Test loss: 2.235, Test accuracy: 20.90
Round  74, Train loss: 1.629, Test loss: 2.242, Test accuracy: 20.38
Round  75, Train loss: 1.555, Test loss: 2.226, Test accuracy: 22.73
Round  76, Train loss: 1.657, Test loss: 2.235, Test accuracy: 21.14
Round  77, Train loss: 1.591, Test loss: 2.237, Test accuracy: 20.60
Round  78, Train loss: 1.626, Test loss: 2.243, Test accuracy: 19.90
Round  79, Train loss: 1.658, Test loss: 2.236, Test accuracy: 20.99
Round  80, Train loss: 1.532, Test loss: 2.237, Test accuracy: 21.09
Round  81, Train loss: 1.535, Test loss: 2.227, Test accuracy: 22.16
Round  82, Train loss: 1.658, Test loss: 2.225, Test accuracy: 22.21
Round  83, Train loss: 1.620, Test loss: 2.227, Test accuracy: 22.00
Round  84, Train loss: 1.621, Test loss: 2.227, Test accuracy: 21.87
Round  85, Train loss: 1.666, Test loss: 2.241, Test accuracy: 19.67
Round  86, Train loss: 1.562, Test loss: 2.229, Test accuracy: 21.63
Round  87, Train loss: 1.559, Test loss: 2.237, Test accuracy: 21.01
Round  88, Train loss: 1.714, Test loss: 2.235, Test accuracy: 21.09
Round  89, Train loss: 1.593, Test loss: 2.226, Test accuracy: 22.16
Round  90, Train loss: 1.625, Test loss: 2.248, Test accuracy: 19.07
Round  91, Train loss: 1.598, Test loss: 2.227, Test accuracy: 21.98
Round  92, Train loss: 1.618, Test loss: 2.251, Test accuracy: 19.12
Round  93, Train loss: 1.620, Test loss: 2.259, Test accuracy: 18.37
Round  94, Train loss: 1.649, Test loss: 2.247, Test accuracy: 18.72
Round  95, Train loss: 1.585, Test loss: 2.231, Test accuracy: 21.55
Round  96, Train loss: 1.647, Test loss: 2.234, Test accuracy: 21.17
Round  97, Train loss: 1.556, Test loss: 2.241, Test accuracy: 20.98
Round  98, Train loss: 1.619, Test loss: 2.246, Test accuracy: 20.05
Round  99, Train loss: 1.617, Test loss: 2.239, Test accuracy: 20.49
Final Round, Train loss: 1.604, Test loss: 2.229, Test accuracy: 21.29
Average accuracy final 10 rounds: 20.15
1485.0171825885773
[2.2765071392059326, 4.360938549041748, 6.615097284317017, 8.683512926101685, 10.773552656173706, 12.832271337509155, 15.00044870376587, 17.163814067840576, 19.237683534622192, 21.2644784450531, 23.277164936065674, 25.30936861038208, 27.330992221832275, 29.341328382492065, 31.35041332244873, 33.399757385253906, 35.4529812335968, 37.53226137161255, 39.626413106918335, 41.7180073261261, 43.87105846405029, 45.94968914985657, 48.01558566093445, 50.12293219566345, 52.17085289955139, 54.25729036331177, 56.3025016784668, 58.363227128982544, 60.529675245285034, 62.5941116809845, 64.66819834709167, 66.69266200065613, 68.71589589118958, 70.96610140800476, 73.24048614501953, 75.33320426940918, 77.41188526153564, 79.45877027511597, 81.54481649398804, 83.71067786216736, 85.87455129623413, 88.04863595962524, 90.27458620071411, 92.41785836219788, 94.55224251747131, 96.7758526802063, 98.9773519039154, 101.07524514198303, 103.27085709571838, 105.29681134223938, 107.99809503555298, 110.35677170753479, 112.69680523872375, 114.92811560630798, 117.09423542022705, 119.15116882324219, 121.33604693412781, 123.52140092849731, 125.56267786026001, 127.57524538040161, 129.8509554862976, 131.9511866569519, 133.9648096561432, 136.1063516139984, 138.538920879364, 140.79747891426086, 142.81305265426636, 145.15231585502625, 147.35663533210754, 149.39557909965515, 151.45098567008972, 153.56268954277039, 155.60412549972534, 157.596613407135, 159.48755407333374, 161.39963674545288, 163.26949524879456, 165.1594958305359, 167.03582310676575, 168.90398335456848, 170.8058898448944, 172.7364146709442, 174.65105891227722, 176.56412839889526, 178.4845941066742, 180.40126085281372, 182.3204803466797, 184.36199378967285, 186.39233565330505, 188.42551565170288, 190.456072807312, 192.48053765296936, 194.4982738494873, 196.5354826450348, 198.57581543922424, 200.5281584262848, 202.4621090888977, 204.36406421661377, 206.2473976612091, 208.1415045261383, 210.06751441955566]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[14.08, 14.02, 15.25, 15.16, 15.95, 17.83, 17.68, 20.44, 15.91, 20.97, 20.03, 20.14, 19.75, 18.53, 17.25, 16.26, 17.7, 16.5, 20.17, 19.73, 21.18, 18.83, 17.65, 21.02, 20.94, 20.86, 22.89, 18.67, 19.8, 19.99, 21.09, 21.67, 22.19, 20.97, 20.49, 20.03, 20.76, 22.08, 20.43, 20.97, 21.39, 18.46, 20.9, 22.16, 20.19, 17.41, 17.31, 19.38, 19.67, 22.07, 21.15, 20.94, 21.12, 21.4, 21.37, 19.57, 19.38, 22.2, 23.23, 21.12, 20.6, 19.64, 21.97, 20.42, 21.52, 20.64, 21.55, 20.51, 18.33, 20.48, 20.75, 21.98, 19.92, 20.9, 20.38, 22.73, 21.14, 20.6, 19.9, 20.99, 21.09, 22.16, 22.21, 22.0, 21.87, 19.67, 21.63, 21.01, 21.09, 22.16, 19.07, 21.98, 19.12, 18.37, 18.72, 21.55, 21.17, 20.98, 20.05, 20.49, 21.29]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.304, Test accuracy: 5.01
Round   0, Global train loss: 2.302, Global test loss: 2.304, Global test accuracy: 4.98
Round   1, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.01
Round   1, Global train loss: 2.303, Global test loss: 2.304, Global test accuracy: 4.98
Round   2, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.04
Round   2, Global train loss: 2.303, Global test loss: 2.304, Global test accuracy: 4.99
Round   3, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.06
Round   3, Global train loss: 2.302, Global test loss: 2.304, Global test accuracy: 5.00
Round   4, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.08
Round   4, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.01
Round   5, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.13
Round   5, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.02
Round   6, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.14
Round   6, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.02
Round   7, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.14
Round   7, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.03
Round   8, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.14
Round   8, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.03
Round   9, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.15
Round   9, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.03
Round  10, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.18
Round  10, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.03
Round  11, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.19
Round  11, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.02
Round  12, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.21
Round  12, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.07
Round  13, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.24
Round  13, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.08
Round  14, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.29
Round  14, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.11
Round  15, Train loss: 2.305, Test loss: 2.303, Test accuracy: 5.30
Round  15, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 5.09
Round  16, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.33
Round  16, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.13
Round  17, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.40
Round  17, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.19
Round  18, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.40
Round  18, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.20
Round  19, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.40
Round  19, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.22
Round  20, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.40
Round  20, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.24
Round  21, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.41
Round  21, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.24
Round  22, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.42
Round  22, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.24
Round  23, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.42
Round  23, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.24
Round  24, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.39
Round  24, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.24
Round  25, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.36
Round  25, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.25
Round  26, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.40
Round  26, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.25
Round  27, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.44
Round  27, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.25
Round  28, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.45
Round  28, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.29
Round  29, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.51
Round  29, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.29
Round  30, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.54
Round  30, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.32
Round  31, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.54
Round  31, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.33
Round  32, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.50
Round  32, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.33
Round  33, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.45
Round  33, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.36
Round  34, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.49
Round  34, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.36
Round  35, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.51
Round  35, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.36
Round  36, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.54
Round  36, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.33
Round  37, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.52
Round  37, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.34
Round  38, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.57
Round  38, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.37
Round  39, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.58
Round  39, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.38
Round  40, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.67
Round  40, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.44
Round  41, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.70
Round  41, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.44
Round  42, Train loss: 2.301, Test loss: 2.303, Test accuracy: 5.74
Round  42, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 5.50
Round  43, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.84
Round  43, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.54
Round  44, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.87
Round  44, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.59
Round  45, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.85
Round  45, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.61
Round  46, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.84
Round  46, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.59
Round  47, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.92
Round  47, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.64
Round  48, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.96
Round  48, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.72
Round  49, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.91
Round  49, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.72
Round  50, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.90
Round  50, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.72
Round  51, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.94
Round  51, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.75
Round  52, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.87
Round  52, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.78
Round  53, Train loss: 2.302, Test loss: 2.303, Test accuracy: 5.90
Round  53, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.79
Round  54, Train loss: 2.304, Test loss: 2.303, Test accuracy: 5.88
Round  54, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.81
Round  55, Train loss: 2.303, Test loss: 2.303, Test accuracy: 5.96
Round  55, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.83
Round  56, Train loss: 2.302, Test loss: 2.303, Test accuracy: 6.01
Round  56, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.87
Round  57, Train loss: 2.302, Test loss: 2.303, Test accuracy: 6.02
Round  57, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.92
Round  58, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.12
Round  58, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 5.96
Round  59, Train loss: 2.302, Test loss: 2.303, Test accuracy: 6.10
Round  59, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.97
Round  60, Train loss: 2.302, Test loss: 2.303, Test accuracy: 6.11
Round  60, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 5.96
Round  61, Train loss: 2.304, Test loss: 2.303, Test accuracy: 6.21
Round  61, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 5.96
Round  62, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.27
Round  62, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.07
Round  63, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.29
Round  63, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.10
Round  64, Train loss: 2.304, Test loss: 2.303, Test accuracy: 6.31
Round  64, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 6.14
Round  65, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.30
Round  65, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.15
Round  66, Train loss: 2.304, Test loss: 2.303, Test accuracy: 6.30
Round  66, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 6.19
Round  67, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.28
Round  67, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.26
Round  68, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.41
Round  68, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.31
Round  69, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.50
Round  69, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.35
Round  70, Train loss: 2.302, Test loss: 2.303, Test accuracy: 6.56
Round  70, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 6.39
Round  71, Train loss: 2.302, Test loss: 2.303, Test accuracy: 6.72
Round  71, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 6.50
Round  72, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.77
Round  72, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.51
Round  73, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.82
Round  73, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.55
Round  74, Train loss: 2.303, Test loss: 2.303, Test accuracy: 6.93
Round  74, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.69
Round  75, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.04
Round  75, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.83
Round  76, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.17
Round  76, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 6.94
Round  77, Train loss: 2.304, Test loss: 2.303, Test accuracy: 7.16
Round  77, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 6.99
Round  78, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.28
Round  78, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 6.99
Round  79, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.30
Round  79, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.05
Round  80, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.35
Round  80, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.10
Round  81, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.36
Round  81, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.10
Round  82, Train loss: 2.304, Test loss: 2.303, Test accuracy: 7.40
Round  82, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.19
Round  83, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.43
Round  83, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.18
Round  84, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.46
Round  84, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.18
Round  85, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.56
Round  85, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.26
Round  86, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.64
Round  86, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.30
Round  87, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.75
Round  87, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.40
Round  88, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.83
Round  88, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.48
Round  89, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.98
Round  89, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.59
Round  90, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.06
Round  90, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.66
Round  91, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.10
Round  91, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.71
Round  92, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.22
Round  92, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.80
Round  93, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.20
Round  93, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.86
Round  94, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.23
Round  94, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.93
Round  95, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.15
Round  95, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.97
Round  96, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.28
Round  96, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.98
Round  97, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.34
Round  97, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.01
Round  98, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.36
Round  98, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.10
Round  99, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.42
Round  99, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.27
Round 100, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.53
Round 100, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.38
Round 101, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.58
Round 101, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.42
Round 102, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.69
Round 102, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.44
Round 103, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.75
Round 103, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.49
Round 104, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.87
Round 104, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.62
Round 105, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.96
Round 105, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.71
Round 106, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.97
Round 106, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.75
Round 107, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.02
Round 107, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.74
Round 108, Train loss: 2.302, Test loss: 2.303, Test accuracy: 9.07
Round 108, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.84
Round 109, Train loss: 2.302, Test loss: 2.303, Test accuracy: 9.19
Round 109, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.93
Round 110, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.18
Round 110, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.87
Round 111, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.20
Round 111, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.97
Round 112, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.28
Round 112, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 9.00
Round 113, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.40
Round 113, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 9.12
Round 114, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.47
Round 114, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 9.09
Round 115, Train loss: 2.304, Test loss: 2.302, Test accuracy: 9.53
Round 115, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 9.15
Round 116, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.54
Round 116, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 9.34
Round 117, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.67
Round 117, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 9.44
Round 118, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.75
Round 118, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 9.56
Round 119, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.83
Round 119, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 9.66
Round 120, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.84
Round 120, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.73
Round 121, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.86
Round 121, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.83
Round 122, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.92
Round 122, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.73
Round 123, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.98
Round 123, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.77
Round 124, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.04
Round 124, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.90
Round 125, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.27
Round 125, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.97
Round 126, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.32
Round 126, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.04
Round 127, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.37
Round 127, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.15
Round 128, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.50
Round 128, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.16
Round 129, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.60
Round 129, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.18
Round 130, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.64
Round 130, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.40
Round 131, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.76
Round 131, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.41
Round 132, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.74
Round 132, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.49
Round 133, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.84
Round 133, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.51
Round 134, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.95
Round 134, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.61
Round 135, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.97
Round 135, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.62
Round 136, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.01
Round 136, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.64
Round 137, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.02
Round 137, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.73
Round 138, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.12
Round 138, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.83
Round 139, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.06
Round 139, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.88
Round 140, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.21
Round 140, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.98
Round 141, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.30
Round 141, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.02
Round 142, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.37
Round 142, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.08
Round 143, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.43
Round 143, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.06
Round 144, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.45
Round 144, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.15
Round 145, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.45
Round 145, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.14
Round 146, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.48
Round 146, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.25
Round 147, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.51
Round 147, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.32
Round 148, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.55
Round 148, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.39
Round 149, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.64
Round 149, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.44
Round 150, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.75
Round 150, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.55
Round 151, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.88
Round 151, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.61
Round 152, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.94
Round 152, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.72
Round 153, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.02
Round 153, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.79
Round 154, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.08
Round 154, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.85
Round 155, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.11
Round 155, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.86
Round 156, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.06
Round 156, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.89
Round 157, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.15
Round 157, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.94
Round 158, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.32
Round 158, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.03
Round 159, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.42
Round 159, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.17
Round 160, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.51
Round 160, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.23
Round 161, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.54
Round 161, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.23
Round 162, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.58
Round 162, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.22
Round 163, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.67
Round 163, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.31
Round 164, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.67
Round 164, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.30
Round 165, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.69
Round 165, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.38
Round 166, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.72
Round 166, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.41
Round 167, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.70
Round 167, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.43
Round 168, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.72
Round 168, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.49
Round 169, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.78
Round 169, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.47
Round 170, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.78
Round 170, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.50
Round 171, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.77
Round 171, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.51
Round 172, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.84
Round 172, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.60
Round 173, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.88
Round 173, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.54
Round 174, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.83
Round 174, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.52
Round 175, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.86
Round 175, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.55
Round 176, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.93
Round 176, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.59
Round 177, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.86
Round 177, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.61
Round 178, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.83
Round 178, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.67
Round 179, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.87
Round 179, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.67
Round 180, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.92
Round 180, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.68
Round 181, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.92
Round 181, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.73
Round 182, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.99
Round 182, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.73
Round 183, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.00
Round 183, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.82
Round 184, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.02
Round 184, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.84
Round 185, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.08
Round 185, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.83
Round 186, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.09
Round 186, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.80
Round 187, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.06
Round 187, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.78
Round 188, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.07
Round 188, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.80
Round 189, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.17
Round 189, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.82
Round 190, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.18
Round 190, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.81
Round 191, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.19
Round 191, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.84
Round 192, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.23
Round 192, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.86
Round 193, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.19
Round 193, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.82
Round 194, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.18
Round 194, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.88
Round 195, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.18
Round 195, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.92
Round 196, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.17
Round 196, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.92
Round 197, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.21
Round 197, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.95
Round 198, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.17
Round 198, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.95
Round 199, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.18
Round 199, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.01
Round 200, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.22
Round 200, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.09
Round 201, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.32
Round 201, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.21
Round 202, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.29
Round 202, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.22
Round 203, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.38
Round 203, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.23
Round 204, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.44
Round 204, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.26
Round 205, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.45
Round 205, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.27
Round 206, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.42
Round 206, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.29
Round 207, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.48
Round 207, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.34
Round 208, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.51
Round 208, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.34
Round 209, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.58
Round 209, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.34
Round 210, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.61
Round 210, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.37
Round 211, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.60
Round 211, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.37
Round 212, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.65
Round 212, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.38
Round 213, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.68
Round 213, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.41
Round 214, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.63
Round 214, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.38
Round 215, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.64
Round 215, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.38
Round 216, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.63
Round 216, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.43
Round 217, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.67
Round 217, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.40
Round 218, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.64
Round 218, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.41
Round 219, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.67
Round 219, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.37
Round 220, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.64
Round 220, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.37
Round 221, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.61
Round 221, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.35
Round 222, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.63
Round 222, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.36
Round 223, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.60
Round 223, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.33
Round 224, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.63
Round 224, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.31
Round 225, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.59
Round 225, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.35
Round 226, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.56
Round 226, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.40
Round 227, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.62
Round 227, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.38
Round 228, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.62
Round 228, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.38
Round 229, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.62
Round 229, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.38
Round 230, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.67
Round 230, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.39
Round 231, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.59
Round 231, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.36
Round 232, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.57
Round 232, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.32
Round 233, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.55
Round 233, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.33
Round 234, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.54
Round 234, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 13.37
Round 235, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.56
Round 235, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.37
Round 236, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.56
Round 236, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.36
Round 237, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.60
Round 237, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.39
Round 238, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.65
Round 238, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.36
Round 239, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.64
Round 239, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.34
Round 240, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.68
Round 240, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.34
Round 241, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.70
Round 241, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.36
Round 242, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.71
Round 242, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.38
Round 243, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.67
Round 243, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.33
Round 244, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.56
Round 244, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.39
Round 245, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.57
Round 245, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.41
Round 246, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.56
Round 246, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.40
Round 247, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.64
Round 247, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.44
Round 248, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.61
Round 248, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.45
Round 249, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.60
Round 249, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.40
Round 250, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.64
Round 250, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.41
Round 251, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.63
Round 251, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.43
Round 252, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.64
Round 252, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.41
Round 253, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.66
Round 253, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.39
Round 254, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.66
Round 254, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.30
Round 255, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.64
Round 255, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.24
Round 256, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.59
Round 256, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.24
Round 257, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.58
Round 257, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.22
Round 258, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.52
Round 258, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.18
Round 259, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.57
Round 259, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.23
Round 260, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.56
Round 260, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.20
Round 261, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.53
Round 261, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.26
Round 262, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.57
Round 262, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.17
Round 263, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.50
Round 263, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.17
Round 264, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.48
Round 264, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.18
Round 265, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.45
Round 265, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.18
Round 266, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.48
Round 266, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.16
Round 267, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.46
Round 267, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.17
Round 268, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.44
Round 268, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.22
Round 269, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.44
Round 269, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.22
Round 270, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.47
Round 270, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.30
Round 271, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.47
Round 271, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.38
Round 272, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.47
Round 272, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.29
Round 273, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.50
Round 273, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.36
Round 274, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.53
Round 274, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.41
Round 275, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.60
Round 275, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.41
Round 276, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.60
Round 276, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.37
Round 277, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.56
Round 277, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.39
Round 278, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.55
Round 278, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.42
Round 279, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.56
Round 279, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.47
Round 280, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.67
Round 280, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.47
Round 281, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.69
Round 281, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.50
Round 282, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.67
Round 282, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.50
Round 283, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.74
Round 283, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.52
Round 284, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.72
Round 284, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.52
Round 285, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.71
Round 285, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.55
Round 286, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.70
Round 286, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.51
Round 287, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.74
Round 287, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.54
Round 288, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.74
Round 288, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.58
Round 289, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.70
Round 289, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.60
Round 290, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.75
Round 290, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.54
Round 291, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.77
Round 291, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.48
Round 292, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.78
Round 292, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.45
Round 293, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.80
Round 293, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.45
Round 294, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.81
Round 294, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.56
Round 295, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.77
Round 295, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.45
Round 296, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.81
Round 296, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.49
Round 297, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.82
Round 297, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.50
Round 298, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.74
Round 298, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.46
Round 299, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.76
Round 299, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.47
Round 300, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.80
Round 300, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.52
Round 301, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.81
Round 301, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.54
Round 302, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.84
Round 302, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.52
Round 303, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.83
Round 303, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.54
Round 304, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.85
Round 304, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.50
Round 305, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.79
Round 305, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.51
Round 306, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.82
Round 306, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.51
Round 307, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.85
Round 307, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.51
Round 308, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.81
Round 308, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.50
Round 309, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.83
Round 309, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.46
Round 310, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.83
Round 310, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.47
Round 311, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.84
Round 311, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.55
Round 312, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.86
Round 312, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.58
Round 313, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.94
Round 313, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.56
Round 314, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.97
Round 314, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.61
Round 315, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.92
Round 315, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.62
Round 316, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.87
Round 316, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.62
Round 317, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.87
Round 317, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.66
Round 318, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.92
Round 318, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.64
Round 319, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.95
Round 319, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.67
Round 320, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.97
Round 320, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.69
Round 321, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.99
Round 321, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.70
Round 322, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.06
Round 322, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.71
Round 323, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.06
Round 323, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.71
Round 324, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.02
Round 324, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.68
Round 325, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.04
Round 325, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.71
Round 326, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.04
Round 326, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.67
Round 327, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.00
Round 327, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.69
Round 328, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.03
Round 328, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.67
Round 329, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.01
Round 329, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.68
Round 330, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.01
Round 330, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.77
Round 331, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.06
Round 331, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.80
Round 332, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.05
Round 332, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.82
Round 333, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.10
Round 333, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.88
Round 334, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.11
Round 334, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.90
Round 335, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.14
Round 335, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.91
Round 336, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.14
Round 336, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.90
Round 337, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.19
Round 337, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.90
Round 338, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.17
Round 338, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.95
Round 339, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.16
Round 339, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.94
Round 340, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.16
Round 340, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.91
Round 341, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.18
Round 341, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.93
Round 342, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.20
Round 342, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.90
Round 343, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.21
Round 343, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.92
Round 344, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.19
Round 344, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.93
Round 345, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.18
Round 345, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.92
Round 346, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.22
Round 346, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.96
Round 347, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.21
Round 347, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.96
Round 348, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.21
Round 348, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.97
Round 349, Train loss: 2.303, Test loss: 2.300, Test accuracy: 14.26
Round 349, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.01
Round 350, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.28
Round 350, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.01
Round 351, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.29
Round 351, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.03
Round 352, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.33
Round 352, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.04
Round 353, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.36
Round 353, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.05
Round 354, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.39
Round 354, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.06
Round 355, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.44
Round 355, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.05
Round 356, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.45
Round 356, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.15
Round 357, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.46
Round 357, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.16
Round 358, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.42
Round 358, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.14
Round 359, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.41
Round 359, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.14
Round 360, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.41
Round 360, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.16
Round 361, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.39
Round 361, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 14.13
Round 362, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.39
Round 362, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.15
Round 363, Train loss: 2.298, Test loss: 2.300, Test accuracy: 14.40
Round 363, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 14.13
Round 364, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.43
Round 364, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.14
Round 365, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.40
Round 365, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.21
Round 366, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.39
Round 366, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.17
Round 367, Train loss: 2.298, Test loss: 2.300, Test accuracy: 14.43
Round 367, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 14.15
Round 368, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.45
Round 368, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.18
Round 369, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.49
Round 369, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.23
Round 370, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.48
Round 370, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.27
Round 371, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.45
Round 371, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.23
Round 372, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.51
Round 372, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.24
Round 373, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.54
Round 373, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.32
Round 374, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.59
Round 374, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.27
Round 375, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.61
Round 375, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.27
Round 376, Train loss: 2.302, Test loss: 2.300, Test accuracy: 14.58
Round 376, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 14.24
Round 377, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.57
Round 377, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.36
Round 378, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.57
Round 378, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.33
Round 379, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.60
Round 379, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.39
Round 380, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.68
Round 380, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.36
Round 381, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.66
Round 381, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.37
Round 382, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.62
Round 382, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.40
Round 383, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.58
Round 383, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.45
Round 384, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.59
Round 384, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.50
Round 385, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.60
Round 385, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.53
Round 386, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.77
Round 386, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.59
Round 387, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.80
Round 387, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.53
Round 388, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.83
Round 388, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.60
Round 389, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.85
Round 389, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.59
Round 390, Train loss: 2.298, Test loss: 2.300, Test accuracy: 14.87
Round 390, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 14.60
Round 391, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.80
Round 391, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.59
Round 392, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.85
Round 392, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.61
Round 393, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.85
Round 393, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.57
Round 394, Train loss: 2.298, Test loss: 2.300, Test accuracy: 14.85
Round 394, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 14.61
Round 395, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.89
Round 395, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.64
Round 396, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.84
Round 396, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.63
Round 397, Train loss: 2.299, Test loss: 2.300, Test accuracy: 14.95
Round 397, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 14.62
Round 398, Train loss: 2.300, Test loss: 2.300, Test accuracy: 14.96
Round 398, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.64
Round 399, Train loss: 2.301, Test loss: 2.300, Test accuracy: 14.95
Round 399, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.64
Final Round, Train loss: 2.300, Test loss: 2.300, Test accuracy: 15.33
Final Round, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 14.64
Average accuracy final 10 rounds: 14.880999999999998 

Average global accuracy final 10 rounds: 14.615000000000002 

3730.2650904655457
[0.9459145069122314, 1.7956011295318604, 2.5438079833984375, 3.321240186691284, 4.080490589141846, 4.843121290206909, 5.618907451629639, 6.396018028259277, 7.163238525390625, 7.955077648162842, 8.72077202796936, 9.505551099777222, 10.277985334396362, 11.047133684158325, 11.822980165481567, 12.5785231590271, 13.349344253540039, 14.12857699394226, 14.896947383880615, 15.658434867858887, 16.429746389389038, 17.197131156921387, 17.952197551727295, 18.72274351119995, 19.516512632369995, 20.28951382637024, 21.059670448303223, 21.833017826080322, 22.59859609603882, 23.339514017105103, 24.105106353759766, 24.87282705307007, 25.64275884628296, 26.410308122634888, 27.180461645126343, 27.94463872909546, 28.689998388290405, 29.482380867004395, 30.252177238464355, 31.022135496139526, 31.78475570678711, 32.57201552391052, 33.34127330780029, 34.11013388633728, 34.883838176727295, 35.65498161315918, 36.42454695701599, 37.19404053688049, 37.962305307388306, 38.72635865211487, 39.48991656303406, 40.25675106048584, 41.03729772567749, 41.8044319152832, 42.588536739349365, 43.34737730026245, 44.13782334327698, 44.904799461364746, 45.67649006843567, 46.451411962509155, 47.21194291114807, 47.97642803192139, 48.74388122558594, 49.51247310638428, 50.27731704711914, 51.055017948150635, 51.827991008758545, 52.59403085708618, 53.35191535949707, 54.118396043777466, 54.89460349082947, 55.66172170639038, 56.423420906066895, 57.19085931777954, 57.94527888298035, 58.70811486244202, 59.47736477851868, 60.248838901519775, 61.02340650558472, 61.78951048851013, 62.56193685531616, 63.31196880340576, 64.07935619354248, 64.8484570980072, 65.61960768699646, 66.38865041732788, 67.1707661151886, 67.9371030330658, 68.69937872886658, 69.4769721031189, 70.2513484954834, 71.00800395011902, 71.77720546722412, 72.54371070861816, 73.31402158737183, 74.09378051757812, 74.86533379554749, 75.6351089477539, 76.40739464759827, 77.17869567871094, 77.94948482513428, 78.72024607658386, 79.48955917358398, 80.25283408164978, 81.02284407615662, 81.79576015472412, 82.58627820014954, 83.34827303886414, 84.13259792327881, 84.90688896179199, 85.6694495677948, 86.43145656585693, 87.1958863735199, 87.97393703460693, 88.73844361305237, 89.53612923622131, 90.3067877292633, 91.08068704605103, 91.84959506988525, 92.60268115997314, 93.37453055381775, 94.14343309402466, 94.9184103012085, 95.68409490585327, 96.4582896232605, 97.22644281387329, 97.97286057472229, 98.73880314826965, 99.50659608840942, 100.26137590408325, 101.02708625793457, 101.79831957817078, 102.56361818313599, 103.31047940254211, 104.08013987541199, 104.84327960014343, 105.60948324203491, 106.37159538269043, 107.1460702419281, 107.91657400131226, 108.68725156784058, 109.44932579994202, 110.22575545310974, 110.99637484550476, 111.76394462585449, 112.53913831710815, 113.30182957649231, 114.05268573760986, 114.82670187950134, 115.59380793571472, 116.35086512565613, 117.12157416343689, 117.91100907325745, 118.68194341659546, 119.44983267784119, 120.21632432937622, 120.98039650917053, 121.72310471534729, 122.49330282211304, 123.25485682487488, 124.02507662773132, 124.79435300827026, 125.56378412246704, 126.32419300079346, 127.06705856323242, 127.8343231678009, 128.61390852928162, 129.3734588623047, 130.1493799686432, 130.91388869285583, 131.68019819259644, 132.43737864494324, 133.20251631736755, 133.9627821445465, 134.73296999931335, 135.52252340316772, 136.2861032485962, 137.06436133384705, 137.83636450767517, 138.6089527606964, 139.37791204452515, 140.13855624198914, 140.90022349357605, 141.6688356399536, 142.4331920146942, 143.19670176506042, 143.9819633960724, 144.74963212013245, 145.5079152584076, 146.28243350982666, 147.05774211883545, 147.82338690757751, 148.58923745155334, 149.38199162483215, 150.15233039855957, 150.91523694992065, 151.68587493896484, 152.45924735069275, 153.22887468338013, 153.99279069900513, 154.76054573059082, 155.52814865112305, 156.2901496887207, 157.0539948940277, 157.8286473751068, 158.59918570518494, 159.4300241470337, 160.26336479187012, 161.11794662475586, 161.96011519432068, 162.79965662956238, 163.6195993423462, 164.5191011428833, 165.4127323627472, 166.25676107406616, 167.0920934677124, 167.93236374855042, 168.82358574867249, 169.66438126564026, 170.50357818603516, 171.3925223350525, 172.29540085792542, 173.1566960811615, 173.97016668319702, 174.81516408920288, 175.67969346046448, 176.51503467559814, 177.3651101589203, 178.2477707862854, 179.11991429328918, 180.01901412010193, 180.91528272628784, 181.77561950683594, 182.63150715827942, 183.4993553161621, 184.36013650894165, 185.19219088554382, 186.04456114768982, 186.9972493648529, 187.94581723213196, 188.77804446220398, 189.6394112110138, 190.54159307479858, 191.44013738632202, 192.26233386993408, 193.1125569343567, 193.92952013015747, 194.77493977546692, 195.60323548316956, 196.43822693824768, 197.29116415977478, 198.15540409088135, 198.97032189369202, 199.85038113594055, 200.7062361240387, 201.82735180854797, 202.9600009918213, 204.09391856193542, 205.04433679580688, 206.01008939743042, 207.02679634094238, 207.86554551124573, 208.72430324554443, 209.58319115638733, 210.4935474395752, 211.40582036972046, 212.3258137702942, 213.16586351394653, 214.04323720932007, 214.8599922657013, 215.68643403053284, 216.5930733680725, 217.52335214614868, 218.32499051094055, 219.13677597045898, 219.96154117584229, 220.8228120803833, 221.9361126422882, 222.973228931427, 223.9589238166809, 224.863507270813, 225.67171621322632, 226.5033667087555, 227.2774531841278, 228.08754110336304, 228.89974188804626, 229.71215629577637, 230.5788505077362, 231.56406688690186, 232.36905550956726, 233.1965148448944, 233.92526197433472, 234.66442131996155, 235.4126238822937, 236.14913296699524, 236.89427638053894, 237.63937616348267, 238.38440918922424, 239.1115918159485, 239.87498092651367, 240.6159951686859, 241.3860068321228, 242.12380599975586, 242.89012598991394, 243.63307905197144, 244.36586785316467, 245.1375172138214, 245.8818814754486, 246.62545228004456, 247.39266228675842, 248.16442370414734, 248.92220306396484, 249.67580795288086, 250.44887900352478, 251.20292687416077, 251.97675466537476, 252.71658730506897, 253.47581791877747, 254.28924441337585, 255.2010109424591, 255.96058011054993, 256.7763738632202, 257.52264165878296, 258.3213472366333, 259.070428609848, 259.81256651878357, 260.5572934150696, 261.3076584339142, 262.0603621006012, 262.8122088909149, 263.56354570388794, 264.5234417915344, 265.2889094352722, 266.08808493614197, 266.89153933525085, 267.6462392807007, 268.4430594444275, 269.2516703605652, 270.34896326065063, 271.1240439414978, 271.8938913345337, 272.673458814621, 273.4277820587158, 274.42490553855896, 275.2083203792572, 276.00215673446655, 276.7617769241333, 277.5432300567627, 278.55385398864746, 279.34574699401855, 280.09562635421753, 280.89319038391113, 281.676718711853, 282.8551228046417, 283.6458683013916, 284.4598460197449, 285.2143099308014, 285.96664214134216, 286.969176530838, 287.9058337211609, 288.6876657009125, 289.46955966949463, 290.3184688091278, 291.3188533782959, 292.09723472595215, 292.87700867652893, 293.88985204696655, 294.8825993537903, 295.64751291275024, 296.44780802726746, 297.2450828552246, 298.514053106308, 299.31075286865234, 300.062203168869, 300.9646382331848, 301.74120330810547, 302.7476930618286, 303.5367658138275, 304.58003306388855, 305.3717694282532, 306.15296602249146, 307.10777258872986, 307.9103317260742, 308.6756761074066, 309.44083523750305, 310.2010736465454, 311.21801590919495, 311.9740195274353, 312.7335352897644, 313.49499797821045, 314.256254196167, 315.2802109718323, 316.03083205223083, 316.79456663131714, 317.6023585796356, 318.36831736564636, 319.3485767841339, 320.122620344162, 320.93828201293945, 321.77673506736755, 323.6614706516266]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[5.01, 5.01, 5.04, 5.06, 5.08, 5.13, 5.14, 5.14, 5.14, 5.15, 5.18, 5.19, 5.21, 5.24, 5.29, 5.3, 5.33, 5.4, 5.4, 5.4, 5.4, 5.41, 5.42, 5.42, 5.39, 5.36, 5.4, 5.44, 5.45, 5.51, 5.54, 5.54, 5.5, 5.45, 5.49, 5.51, 5.54, 5.52, 5.57, 5.58, 5.67, 5.7, 5.74, 5.84, 5.87, 5.85, 5.84, 5.92, 5.96, 5.91, 5.9, 5.94, 5.87, 5.9, 5.88, 5.96, 6.01, 6.02, 6.12, 6.1, 6.11, 6.21, 6.27, 6.29, 6.31, 6.3, 6.3, 6.28, 6.41, 6.5, 6.56, 6.72, 6.77, 6.82, 6.93, 7.04, 7.17, 7.16, 7.28, 7.3, 7.35, 7.36, 7.4, 7.43, 7.46, 7.56, 7.64, 7.75, 7.83, 7.98, 8.06, 8.1, 8.22, 8.2, 8.23, 8.15, 8.28, 8.34, 8.36, 8.42, 8.53, 8.58, 8.69, 8.75, 8.87, 8.96, 8.97, 9.02, 9.07, 9.19, 9.18, 9.2, 9.28, 9.4, 9.47, 9.53, 9.54, 9.67, 9.75, 9.83, 9.84, 9.86, 9.92, 9.98, 10.04, 10.27, 10.32, 10.37, 10.5, 10.6, 10.64, 10.76, 10.74, 10.84, 10.95, 10.97, 11.01, 11.02, 11.12, 11.06, 11.21, 11.3, 11.37, 11.43, 11.45, 11.45, 11.48, 11.51, 11.55, 11.64, 11.75, 11.88, 11.94, 12.02, 12.08, 12.11, 12.06, 12.15, 12.32, 12.42, 12.51, 12.54, 12.58, 12.67, 12.67, 12.69, 12.72, 12.7, 12.72, 12.78, 12.78, 12.77, 12.84, 12.88, 12.83, 12.86, 12.93, 12.86, 12.83, 12.87, 12.92, 12.92, 12.99, 13.0, 13.02, 13.08, 13.09, 13.06, 13.07, 13.17, 13.18, 13.19, 13.23, 13.19, 13.18, 13.18, 13.17, 13.21, 13.17, 13.18, 13.22, 13.32, 13.29, 13.38, 13.44, 13.45, 13.42, 13.48, 13.51, 13.58, 13.61, 13.6, 13.65, 13.68, 13.63, 13.64, 13.63, 13.67, 13.64, 13.67, 13.64, 13.61, 13.63, 13.6, 13.63, 13.59, 13.56, 13.62, 13.62, 13.62, 13.67, 13.59, 13.57, 13.55, 13.54, 13.56, 13.56, 13.6, 13.65, 13.64, 13.68, 13.7, 13.71, 13.67, 13.56, 13.57, 13.56, 13.64, 13.61, 13.6, 13.64, 13.63, 13.64, 13.66, 13.66, 13.64, 13.59, 13.58, 13.52, 13.57, 13.56, 13.53, 13.57, 13.5, 13.48, 13.45, 13.48, 13.46, 13.44, 13.44, 13.47, 13.47, 13.47, 13.5, 13.53, 13.6, 13.6, 13.56, 13.55, 13.56, 13.67, 13.69, 13.67, 13.74, 13.72, 13.71, 13.7, 13.74, 13.74, 13.7, 13.75, 13.77, 13.78, 13.8, 13.81, 13.77, 13.81, 13.82, 13.74, 13.76, 13.8, 13.81, 13.84, 13.83, 13.85, 13.79, 13.82, 13.85, 13.81, 13.83, 13.83, 13.84, 13.86, 13.94, 13.97, 13.92, 13.87, 13.87, 13.92, 13.95, 13.97, 13.99, 14.06, 14.06, 14.02, 14.04, 14.04, 14.0, 14.03, 14.01, 14.01, 14.06, 14.05, 14.1, 14.11, 14.14, 14.14, 14.19, 14.17, 14.16, 14.16, 14.18, 14.2, 14.21, 14.19, 14.18, 14.22, 14.21, 14.21, 14.26, 14.28, 14.29, 14.33, 14.36, 14.39, 14.44, 14.45, 14.46, 14.42, 14.41, 14.41, 14.39, 14.39, 14.4, 14.43, 14.4, 14.39, 14.43, 14.45, 14.49, 14.48, 14.45, 14.51, 14.54, 14.59, 14.61, 14.58, 14.57, 14.57, 14.6, 14.68, 14.66, 14.62, 14.58, 14.59, 14.6, 14.77, 14.8, 14.83, 14.85, 14.87, 14.8, 14.85, 14.85, 14.85, 14.89, 14.84, 14.95, 14.96, 14.95, 15.33]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.301, Test accuracy: 10.10
Round   1, Train loss: 2.291, Test loss: 2.299, Test accuracy: 14.07
Round   2, Train loss: 2.281, Test loss: 2.294, Test accuracy: 17.41
Round   3, Train loss: 2.251, Test loss: 2.279, Test accuracy: 20.69
Round   4, Train loss: 2.223, Test loss: 2.255, Test accuracy: 27.01
Round   5, Train loss: 2.148, Test loss: 2.217, Test accuracy: 28.44
Round   6, Train loss: 2.081, Test loss: 2.178, Test accuracy: 31.38
Round   7, Train loss: 2.002, Test loss: 2.139, Test accuracy: 34.89
Round   8, Train loss: 1.944, Test loss: 2.101, Test accuracy: 38.17
Round   9, Train loss: 1.983, Test loss: 2.074, Test accuracy: 42.86
Round  10, Train loss: 1.997, Test loss: 2.054, Test accuracy: 45.96
Round  11, Train loss: 1.948, Test loss: 2.038, Test accuracy: 46.31
Round  12, Train loss: 1.832, Test loss: 2.014, Test accuracy: 48.42
Round  13, Train loss: 1.931, Test loss: 2.002, Test accuracy: 49.51
Round  14, Train loss: 1.999, Test loss: 1.988, Test accuracy: 52.39
Round  15, Train loss: 2.061, Test loss: 1.984, Test accuracy: 53.25
Round  16, Train loss: 1.944, Test loss: 1.976, Test accuracy: 54.25
Round  17, Train loss: 1.914, Test loss: 1.959, Test accuracy: 54.99
Round  18, Train loss: 1.956, Test loss: 1.955, Test accuracy: 55.95
Round  19, Train loss: 1.837, Test loss: 1.918, Test accuracy: 59.86
Round  20, Train loss: 1.883, Test loss: 1.902, Test accuracy: 61.41
Round  21, Train loss: 1.944, Test loss: 1.899, Test accuracy: 63.51
Round  22, Train loss: 1.799, Test loss: 1.878, Test accuracy: 63.12
Round  23, Train loss: 1.808, Test loss: 1.877, Test accuracy: 62.56
Round  24, Train loss: 1.721, Test loss: 1.874, Test accuracy: 62.07
Round  25, Train loss: 1.824, Test loss: 1.858, Test accuracy: 63.80
Round  26, Train loss: 1.808, Test loss: 1.851, Test accuracy: 64.74
Round  27, Train loss: 1.888, Test loss: 1.845, Test accuracy: 66.61
Round  28, Train loss: 1.721, Test loss: 1.823, Test accuracy: 68.01
Round  29, Train loss: 1.804, Test loss: 1.813, Test accuracy: 70.52
Round  30, Train loss: 1.689, Test loss: 1.793, Test accuracy: 71.28
Round  31, Train loss: 1.725, Test loss: 1.790, Test accuracy: 71.28
Round  32, Train loss: 1.685, Test loss: 1.779, Test accuracy: 72.15
Round  33, Train loss: 1.667, Test loss: 1.772, Test accuracy: 72.66
Round  34, Train loss: 1.737, Test loss: 1.773, Test accuracy: 73.26
Round  35, Train loss: 1.792, Test loss: 1.777, Test accuracy: 73.07
Round  36, Train loss: 1.703, Test loss: 1.768, Test accuracy: 74.03
Round  37, Train loss: 1.784, Test loss: 1.769, Test accuracy: 74.01
Round  38, Train loss: 1.717, Test loss: 1.768, Test accuracy: 74.12
Round  39, Train loss: 1.803, Test loss: 1.773, Test accuracy: 74.08
Round  40, Train loss: 1.782, Test loss: 1.765, Test accuracy: 74.59
Round  41, Train loss: 1.805, Test loss: 1.767, Test accuracy: 74.60
Round  42, Train loss: 1.685, Test loss: 1.758, Test accuracy: 74.60
Round  43, Train loss: 1.659, Test loss: 1.747, Test accuracy: 74.68
Round  44, Train loss: 1.805, Test loss: 1.753, Test accuracy: 74.82
Round  45, Train loss: 1.726, Test loss: 1.742, Test accuracy: 75.90
Round  46, Train loss: 1.801, Test loss: 1.749, Test accuracy: 75.99
Round  47, Train loss: 1.738, Test loss: 1.746, Test accuracy: 75.81
Round  48, Train loss: 1.710, Test loss: 1.742, Test accuracy: 76.06
Round  49, Train loss: 1.731, Test loss: 1.745, Test accuracy: 75.93
Round  50, Train loss: 1.779, Test loss: 1.747, Test accuracy: 75.98
Round  51, Train loss: 1.738, Test loss: 1.743, Test accuracy: 76.15
Round  52, Train loss: 1.561, Test loss: 1.725, Test accuracy: 76.93
Round  53, Train loss: 1.789, Test loss: 1.746, Test accuracy: 76.23
Round  54, Train loss: 1.619, Test loss: 1.730, Test accuracy: 76.48
Round  55, Train loss: 1.668, Test loss: 1.728, Test accuracy: 76.83
Round  56, Train loss: 1.613, Test loss: 1.721, Test accuracy: 77.12
Round  57, Train loss: 1.579, Test loss: 1.722, Test accuracy: 76.89
Round  58, Train loss: 1.588, Test loss: 1.714, Test accuracy: 77.57
Round  59, Train loss: 1.607, Test loss: 1.710, Test accuracy: 77.84
Round  60, Train loss: 1.769, Test loss: 1.715, Test accuracy: 78.40
Round  61, Train loss: 1.677, Test loss: 1.716, Test accuracy: 78.77
Round  62, Train loss: 1.663, Test loss: 1.711, Test accuracy: 79.01
Round  63, Train loss: 1.730, Test loss: 1.715, Test accuracy: 78.75
Round  64, Train loss: 1.599, Test loss: 1.695, Test accuracy: 80.05
Round  65, Train loss: 1.747, Test loss: 1.700, Test accuracy: 80.90
Round  66, Train loss: 1.577, Test loss: 1.694, Test accuracy: 80.68
Round  67, Train loss: 1.676, Test loss: 1.689, Test accuracy: 81.60
Round  68, Train loss: 1.651, Test loss: 1.677, Test accuracy: 82.46
Round  69, Train loss: 1.636, Test loss: 1.679, Test accuracy: 82.32
Round  70, Train loss: 1.699, Test loss: 1.686, Test accuracy: 82.68
Round  71, Train loss: 1.586, Test loss: 1.671, Test accuracy: 82.88
Round  72, Train loss: 1.628, Test loss: 1.672, Test accuracy: 83.18
Round  73, Train loss: 1.525, Test loss: 1.662, Test accuracy: 83.40
Round  74, Train loss: 1.598, Test loss: 1.647, Test accuracy: 85.21
Round  75, Train loss: 1.540, Test loss: 1.646, Test accuracy: 84.87
Round  76, Train loss: 1.505, Test loss: 1.645, Test accuracy: 84.83
Round  77, Train loss: 1.573, Test loss: 1.645, Test accuracy: 85.16
Round  78, Train loss: 1.641, Test loss: 1.644, Test accuracy: 85.32
Round  79, Train loss: 1.540, Test loss: 1.641, Test accuracy: 85.39
Round  80, Train loss: 1.515, Test loss: 1.637, Test accuracy: 85.44
Round  81, Train loss: 1.604, Test loss: 1.640, Test accuracy: 85.16
Round  82, Train loss: 1.495, Test loss: 1.636, Test accuracy: 85.47
Round  83, Train loss: 1.502, Test loss: 1.633, Test accuracy: 85.49
Round  84, Train loss: 1.545, Test loss: 1.635, Test accuracy: 85.33
Round  85, Train loss: 1.631, Test loss: 1.637, Test accuracy: 85.46
Round  86, Train loss: 1.541, Test loss: 1.632, Test accuracy: 85.57
Round  87, Train loss: 1.593, Test loss: 1.641, Test accuracy: 85.35
Round  88, Train loss: 1.538, Test loss: 1.630, Test accuracy: 85.75
Round  89, Train loss: 1.503, Test loss: 1.628, Test accuracy: 85.71
Round  90, Train loss: 1.491, Test loss: 1.629, Test accuracy: 85.56
Round  91, Train loss: 1.724, Test loss: 1.642, Test accuracy: 85.47
Round  92, Train loss: 1.558, Test loss: 1.636, Test accuracy: 85.65
Round  93, Train loss: 1.664, Test loss: 1.639, Test accuracy: 85.63
Round  94, Train loss: 1.593, Test loss: 1.637, Test accuracy: 85.31
Round  95, Train loss: 1.618, Test loss: 1.635, Test accuracy: 85.76
Round  96, Train loss: 1.594, Test loss: 1.631, Test accuracy: 85.81
Round  97, Train loss: 1.653, Test loss: 1.640, Test accuracy: 85.42
Round  98, Train loss: 1.623, Test loss: 1.637, Test accuracy: 85.60
Round  99, Train loss: 1.708, Test loss: 1.642, Test accuracy: 85.38
Round 100, Train loss: 1.592, Test loss: 1.637, Test accuracy: 85.62
Round 101, Train loss: 1.698, Test loss: 1.639, Test accuracy: 85.63
Round 102, Train loss: 1.558, Test loss: 1.635, Test accuracy: 85.63
Round 103, Train loss: 1.692, Test loss: 1.636, Test accuracy: 86.25
Round 104, Train loss: 1.587, Test loss: 1.628, Test accuracy: 86.71
Round 105, Train loss: 1.690, Test loss: 1.633, Test accuracy: 86.67
Round 106, Train loss: 1.527, Test loss: 1.623, Test accuracy: 86.49
Round 107, Train loss: 1.618, Test loss: 1.623, Test accuracy: 86.82
Round 108, Train loss: 1.522, Test loss: 1.619, Test accuracy: 86.83
Round 109, Train loss: 1.550, Test loss: 1.619, Test accuracy: 86.71
Round 110, Train loss: 1.553, Test loss: 1.617, Test accuracy: 86.59
Round 111, Train loss: 1.712, Test loss: 1.630, Test accuracy: 86.65
Round 112, Train loss: 1.644, Test loss: 1.626, Test accuracy: 86.83
Round 113, Train loss: 1.559, Test loss: 1.622, Test accuracy: 86.68
Round 114, Train loss: 1.585, Test loss: 1.620, Test accuracy: 86.69
Round 115, Train loss: 1.584, Test loss: 1.622, Test accuracy: 86.80
Round 116, Train loss: 1.551, Test loss: 1.621, Test accuracy: 86.81
Round 117, Train loss: 1.551, Test loss: 1.618, Test accuracy: 86.86
Round 118, Train loss: 1.610, Test loss: 1.623, Test accuracy: 86.72
Round 119, Train loss: 1.493, Test loss: 1.616, Test accuracy: 86.88
Round 120, Train loss: 1.643, Test loss: 1.626, Test accuracy: 86.71
Round 121, Train loss: 1.624, Test loss: 1.621, Test accuracy: 86.86
Round 122, Train loss: 1.584, Test loss: 1.623, Test accuracy: 86.60
Round 123, Train loss: 1.490, Test loss: 1.615, Test accuracy: 86.78
Round 124, Train loss: 1.618, Test loss: 1.620, Test accuracy: 86.75
Round 125, Train loss: 1.581, Test loss: 1.616, Test accuracy: 86.95
Round 126, Train loss: 1.643, Test loss: 1.625, Test accuracy: 86.63
Round 127, Train loss: 1.711, Test loss: 1.627, Test accuracy: 86.76
Round 128, Train loss: 1.616, Test loss: 1.624, Test accuracy: 86.78
Round 129, Train loss: 1.551, Test loss: 1.614, Test accuracy: 86.97
Round 130, Train loss: 1.652, Test loss: 1.619, Test accuracy: 87.64
Round 131, Train loss: 1.576, Test loss: 1.614, Test accuracy: 87.65
Round 132, Train loss: 1.491, Test loss: 1.607, Test accuracy: 87.76
Round 133, Train loss: 1.487, Test loss: 1.604, Test accuracy: 87.79
Round 134, Train loss: 1.614, Test loss: 1.613, Test accuracy: 87.70
Round 135, Train loss: 1.612, Test loss: 1.616, Test accuracy: 87.55
Round 136, Train loss: 1.584, Test loss: 1.610, Test accuracy: 87.73
Round 137, Train loss: 1.528, Test loss: 1.602, Test accuracy: 88.72
Round 138, Train loss: 1.518, Test loss: 1.598, Test accuracy: 88.91
Round 139, Train loss: 1.616, Test loss: 1.600, Test accuracy: 88.96
Round 140, Train loss: 1.516, Test loss: 1.595, Test accuracy: 88.93
Round 141, Train loss: 1.548, Test loss: 1.602, Test accuracy: 88.49
Round 142, Train loss: 1.612, Test loss: 1.603, Test accuracy: 88.54
Round 143, Train loss: 1.676, Test loss: 1.611, Test accuracy: 88.33
Round 144, Train loss: 1.524, Test loss: 1.597, Test accuracy: 88.82
Round 145, Train loss: 1.481, Test loss: 1.595, Test accuracy: 88.89
Round 146, Train loss: 1.583, Test loss: 1.598, Test accuracy: 88.97
Round 147, Train loss: 1.520, Test loss: 1.594, Test accuracy: 89.06
Round 148, Train loss: 1.547, Test loss: 1.599, Test accuracy: 88.68
Round 149, Train loss: 1.644, Test loss: 1.601, Test accuracy: 88.71
Round 150, Train loss: 1.584, Test loss: 1.599, Test accuracy: 88.83
Round 151, Train loss: 1.516, Test loss: 1.594, Test accuracy: 88.95
Round 152, Train loss: 1.581, Test loss: 1.599, Test accuracy: 88.64
Round 153, Train loss: 1.479, Test loss: 1.593, Test accuracy: 88.70
Round 154, Train loss: 1.574, Test loss: 1.595, Test accuracy: 88.78
Round 155, Train loss: 1.636, Test loss: 1.608, Test accuracy: 88.33
Round 156, Train loss: 1.487, Test loss: 1.594, Test accuracy: 88.98
Round 157, Train loss: 1.547, Test loss: 1.592, Test accuracy: 89.04
Round 158, Train loss: 1.608, Test loss: 1.599, Test accuracy: 88.94
Round 159, Train loss: 1.620, Test loss: 1.595, Test accuracy: 89.70
Round 160, Train loss: 1.578, Test loss: 1.591, Test accuracy: 89.88
Round 161, Train loss: 1.487, Test loss: 1.586, Test accuracy: 89.88
Round 162, Train loss: 1.547, Test loss: 1.589, Test accuracy: 89.86
Round 163, Train loss: 1.580, Test loss: 1.588, Test accuracy: 89.92
Round 164, Train loss: 1.644, Test loss: 1.590, Test accuracy: 89.88
Round 165, Train loss: 1.545, Test loss: 1.587, Test accuracy: 89.93
Round 166, Train loss: 1.544, Test loss: 1.586, Test accuracy: 89.94
Round 167, Train loss: 1.516, Test loss: 1.585, Test accuracy: 90.02
Round 168, Train loss: 1.512, Test loss: 1.584, Test accuracy: 89.92
Round 169, Train loss: 1.543, Test loss: 1.586, Test accuracy: 89.83
Round 170, Train loss: 1.575, Test loss: 1.586, Test accuracy: 90.11
Round 171, Train loss: 1.544, Test loss: 1.589, Test accuracy: 89.92
Round 172, Train loss: 1.672, Test loss: 1.596, Test accuracy: 89.88
Round 173, Train loss: 1.547, Test loss: 1.582, Test accuracy: 90.36
Round 174, Train loss: 1.543, Test loss: 1.585, Test accuracy: 90.02
Round 175, Train loss: 1.573, Test loss: 1.587, Test accuracy: 90.03
Round 176, Train loss: 1.594, Test loss: 1.585, Test accuracy: 90.61
Round 177, Train loss: 1.552, Test loss: 1.583, Test accuracy: 90.73
Round 178, Train loss: 1.606, Test loss: 1.583, Test accuracy: 90.76
Round 179, Train loss: 1.483, Test loss: 1.578, Test accuracy: 90.86
Round 180, Train loss: 1.548, Test loss: 1.576, Test accuracy: 91.15
Round 181, Train loss: 1.542, Test loss: 1.578, Test accuracy: 90.91
Round 182, Train loss: 1.508, Test loss: 1.575, Test accuracy: 90.98
Round 183, Train loss: 1.516, Test loss: 1.576, Test accuracy: 90.85
Round 184, Train loss: 1.545, Test loss: 1.578, Test accuracy: 90.81
Round 185, Train loss: 1.511, Test loss: 1.576, Test accuracy: 90.87
Round 186, Train loss: 1.479, Test loss: 1.576, Test accuracy: 90.85
Round 187, Train loss: 1.541, Test loss: 1.579, Test accuracy: 90.62
Round 188, Train loss: 1.480, Test loss: 1.573, Test accuracy: 90.95
Round 189, Train loss: 1.477, Test loss: 1.574, Test accuracy: 90.87
Round 190, Train loss: 1.540, Test loss: 1.578, Test accuracy: 90.83
Round 191, Train loss: 1.515, Test loss: 1.578, Test accuracy: 90.75
Round 192, Train loss: 1.611, Test loss: 1.576, Test accuracy: 91.00
Round 193, Train loss: 1.545, Test loss: 1.573, Test accuracy: 91.03
Round 194, Train loss: 1.509, Test loss: 1.571, Test accuracy: 91.15
Round 195, Train loss: 1.542, Test loss: 1.574, Test accuracy: 90.92
Round 196, Train loss: 1.606, Test loss: 1.577, Test accuracy: 91.03
Round 197, Train loss: 1.546, Test loss: 1.576, Test accuracy: 90.95
Round 198, Train loss: 1.545, Test loss: 1.573, Test accuracy: 91.08
Round 199, Train loss: 1.481, Test loss: 1.572, Test accuracy: 90.94
Final Round, Train loss: 1.524, Test loss: 1.560, Test accuracy: 92.10
Average accuracy final 10 rounds: 90.968
1559.897382259369
[1.0637896060943604, 1.893096923828125, 2.9986679553985596, 3.8458120822906494, 4.7385804653167725, 5.949064493179321, 6.791409492492676, 7.653086423873901, 8.770814418792725, 9.609633445739746, 10.461825132369995, 11.499560832977295, 12.360331296920776, 13.23677396774292, 14.327288150787354, 15.211127519607544, 16.1131329536438, 17.18222975730896, 18.065203428268433, 18.927813291549683, 19.994956493377686, 20.859208345413208, 21.758315086364746, 23.070430994033813, 23.957743167877197, 24.849737405776978, 26.02778124809265, 26.904139041900635, 27.769116163253784, 28.85905385017395, 29.71432900428772, 30.59580421447754, 31.681214332580566, 32.56826186180115, 33.44706058502197, 34.64068150520325, 35.48654222488403, 36.36900329589844, 37.47835993766785, 38.36160683631897, 39.24690508842468, 40.35579180717468, 41.233760833740234, 42.121565103530884, 43.278539180755615, 44.163753032684326, 45.02540993690491, 46.085299015045166, 46.92905116081238, 47.7832989692688, 48.913193702697754, 49.80014967918396, 50.66131114959717, 51.67015838623047, 52.53185224533081, 53.48468041419983, 54.51205778121948, 55.3700225353241, 56.26958250999451, 57.23096323013306, 58.11536526679993, 59.19257593154907, 60.070725440979004, 61.08009099960327, 62.103028297424316, 63.05212211608887, 63.89298439025879, 64.81358933448792, 65.66272759437561, 66.61668992042542, 67.45303535461426, 68.4130163192749, 69.25437784194946, 70.123281955719, 71.06867933273315, 71.95162320137024, 72.9507086277008, 73.8012580871582, 74.77708983421326, 75.6659038066864, 76.67794132232666, 77.53948831558228, 78.56140375137329, 79.45530438423157, 80.29517793655396, 81.16243028640747, 82.09477162361145, 82.96555852890015, 83.8764283657074, 84.74235343933105, 85.6058599948883, 86.4351499080658, 87.30258536338806, 88.15877366065979, 89.02371072769165, 89.94491577148438, 90.78013277053833, 91.6408178806305, 92.48268055915833, 93.34160447120667, 94.24763226509094, 95.10627841949463, 95.98391842842102, 96.83111929893494, 97.68070387840271, 98.59282183647156, 99.44410991668701, 100.3530809879303, 101.20059418678284, 102.04928755760193, 102.91810870170593, 103.82326555252075, 104.81686472892761, 105.8476197719574, 106.87924361228943, 108.0203537940979, 109.15678691864014, 110.12932181358337, 111.17243790626526, 112.11822605133057, 113.07275152206421, 113.96869945526123, 114.93700766563416, 115.8344714641571, 116.94562792778015, 118.0894947052002, 119.08361625671387, 120.0614914894104, 121.0095796585083, 122.2487964630127, 123.24814319610596, 124.2435188293457, 125.25125932693481, 126.450040102005, 127.34774160385132, 128.38524842262268, 129.32281112670898, 130.22874999046326, 131.3018515110016, 132.25100898742676, 133.2193055152893, 134.1866843700409, 135.21882438659668, 136.16870975494385, 137.1383888721466, 138.1087658405304, 138.99942135810852, 139.94252514839172, 140.8423900604248, 141.8352017402649, 142.81915497779846, 143.87684392929077, 144.7926058769226, 145.77253699302673, 146.7951500415802, 147.76921486854553, 148.69805335998535, 149.7065896987915, 150.58872199058533, 151.54999780654907, 152.49764847755432, 153.50476002693176, 154.61951303482056, 155.55924224853516, 156.61308360099792, 157.52898740768433, 158.41754007339478, 159.33012557029724, 160.3440716266632, 161.32656812667847, 162.29626727104187, 163.3816318511963, 164.33357048034668, 165.3312532901764, 166.26390075683594, 167.2576937675476, 168.26741528511047, 169.1402304172516, 170.11120772361755, 171.07218527793884, 172.00220155715942, 172.96042847633362, 174.05349206924438, 174.94025015830994, 175.88849711418152, 176.81375765800476, 177.6944065093994, 178.5797576904297, 179.54256987571716, 180.56027150154114, 181.55889344215393, 182.4634234905243, 183.3915193080902, 184.41060733795166, 185.36570954322815, 186.47200083732605, 187.5102174282074, 188.41228675842285, 189.4292390346527, 190.43362426757812, 192.1377899646759]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[10.1, 14.07, 17.41, 20.69, 27.01, 28.44, 31.38, 34.89, 38.17, 42.86, 45.96, 46.31, 48.42, 49.51, 52.39, 53.25, 54.25, 54.99, 55.95, 59.86, 61.41, 63.51, 63.12, 62.56, 62.07, 63.8, 64.74, 66.61, 68.01, 70.52, 71.28, 71.28, 72.15, 72.66, 73.26, 73.07, 74.03, 74.01, 74.12, 74.08, 74.59, 74.6, 74.6, 74.68, 74.82, 75.9, 75.99, 75.81, 76.06, 75.93, 75.98, 76.15, 76.93, 76.23, 76.48, 76.83, 77.12, 76.89, 77.57, 77.84, 78.4, 78.77, 79.01, 78.75, 80.05, 80.9, 80.68, 81.6, 82.46, 82.32, 82.68, 82.88, 83.18, 83.4, 85.21, 84.87, 84.83, 85.16, 85.32, 85.39, 85.44, 85.16, 85.47, 85.49, 85.33, 85.46, 85.57, 85.35, 85.75, 85.71, 85.56, 85.47, 85.65, 85.63, 85.31, 85.76, 85.81, 85.42, 85.6, 85.38, 85.62, 85.63, 85.63, 86.25, 86.71, 86.67, 86.49, 86.82, 86.83, 86.71, 86.59, 86.65, 86.83, 86.68, 86.69, 86.8, 86.81, 86.86, 86.72, 86.88, 86.71, 86.86, 86.6, 86.78, 86.75, 86.95, 86.63, 86.76, 86.78, 86.97, 87.64, 87.65, 87.76, 87.79, 87.7, 87.55, 87.73, 88.72, 88.91, 88.96, 88.93, 88.49, 88.54, 88.33, 88.82, 88.89, 88.97, 89.06, 88.68, 88.71, 88.83, 88.95, 88.64, 88.7, 88.78, 88.33, 88.98, 89.04, 88.94, 89.7, 89.88, 89.88, 89.86, 89.92, 89.88, 89.93, 89.94, 90.02, 89.92, 89.83, 90.11, 89.92, 89.88, 90.36, 90.02, 90.03, 90.61, 90.73, 90.76, 90.86, 91.15, 90.91, 90.98, 90.85, 90.81, 90.87, 90.85, 90.62, 90.95, 90.87, 90.83, 90.75, 91.0, 91.03, 91.15, 90.92, 91.03, 90.95, 91.08, 90.94, 92.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 200, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.316, Test loss: 2.301, Test accuracy: 15.74
Round   1, Train loss: 2.301, Test loss: 2.296, Test accuracy: 14.65
Round   2, Train loss: 2.266, Test loss: 2.285, Test accuracy: 15.32
Round   3, Train loss: 2.238, Test loss: 2.269, Test accuracy: 17.90
Round   4, Train loss: 2.197, Test loss: 2.248, Test accuracy: 20.90
Round   5, Train loss: 2.180, Test loss: 2.227, Test accuracy: 28.35
Round   6, Train loss: 2.118, Test loss: 2.186, Test accuracy: 29.86
Round   7, Train loss: 2.092, Test loss: 2.140, Test accuracy: 33.69
Round   8, Train loss: 2.042, Test loss: 2.106, Test accuracy: 37.36
Round   9, Train loss: 1.963, Test loss: 2.071, Test accuracy: 42.84
Round  10, Train loss: 1.956, Test loss: 2.031, Test accuracy: 47.19
Round  11, Train loss: 1.932, Test loss: 2.009, Test accuracy: 49.93
Round  12, Train loss: 1.993, Test loss: 1.972, Test accuracy: 55.99
Round  13, Train loss: 1.874, Test loss: 1.956, Test accuracy: 57.26
Round  14, Train loss: 1.818, Test loss: 1.933, Test accuracy: 58.76
Round  15, Train loss: 1.899, Test loss: 1.918, Test accuracy: 60.62
Round  16, Train loss: 1.900, Test loss: 1.892, Test accuracy: 63.00
Round  17, Train loss: 1.813, Test loss: 1.884, Test accuracy: 65.10
Round  18, Train loss: 1.849, Test loss: 1.844, Test accuracy: 68.04
Round  19, Train loss: 1.799, Test loss: 1.823, Test accuracy: 69.46
Round  20, Train loss: 1.748, Test loss: 1.808, Test accuracy: 71.77
Round  21, Train loss: 1.824, Test loss: 1.801, Test accuracy: 73.79
Round  22, Train loss: 1.718, Test loss: 1.775, Test accuracy: 74.57
Round  23, Train loss: 1.744, Test loss: 1.760, Test accuracy: 77.08
Round  24, Train loss: 1.725, Test loss: 1.739, Test accuracy: 79.22
Round  25, Train loss: 1.736, Test loss: 1.718, Test accuracy: 81.55
Round  26, Train loss: 1.695, Test loss: 1.705, Test accuracy: 82.46
Round  27, Train loss: 1.693, Test loss: 1.690, Test accuracy: 85.50
Round  28, Train loss: 1.698, Test loss: 1.669, Test accuracy: 86.49
Round  29, Train loss: 1.632, Test loss: 1.666, Test accuracy: 86.87
Round  30, Train loss: 1.670, Test loss: 1.666, Test accuracy: 86.57
Round  31, Train loss: 1.648, Test loss: 1.648, Test accuracy: 87.67
Round  32, Train loss: 1.612, Test loss: 1.647, Test accuracy: 87.92
Round  33, Train loss: 1.588, Test loss: 1.635, Test accuracy: 88.66
Round  34, Train loss: 1.604, Test loss: 1.630, Test accuracy: 89.33
Round  35, Train loss: 1.639, Test loss: 1.632, Test accuracy: 89.30
Round  36, Train loss: 1.629, Test loss: 1.628, Test accuracy: 89.40
Round  37, Train loss: 1.605, Test loss: 1.626, Test accuracy: 89.54
Round  38, Train loss: 1.559, Test loss: 1.617, Test accuracy: 89.70
Round  39, Train loss: 1.603, Test loss: 1.617, Test accuracy: 89.69
Round  40, Train loss: 1.598, Test loss: 1.616, Test accuracy: 89.68
Round  41, Train loss: 1.619, Test loss: 1.610, Test accuracy: 89.71
Round  42, Train loss: 1.627, Test loss: 1.613, Test accuracy: 89.66
Round  43, Train loss: 1.690, Test loss: 1.618, Test accuracy: 89.76
Round  44, Train loss: 1.628, Test loss: 1.615, Test accuracy: 89.74
Round  45, Train loss: 1.663, Test loss: 1.614, Test accuracy: 89.71
Round  46, Train loss: 1.631, Test loss: 1.608, Test accuracy: 89.77
Round  47, Train loss: 1.543, Test loss: 1.600, Test accuracy: 89.88
Round  48, Train loss: 1.642, Test loss: 1.607, Test accuracy: 89.90
Round  49, Train loss: 1.570, Test loss: 1.600, Test accuracy: 89.99
Round  50, Train loss: 1.552, Test loss: 1.602, Test accuracy: 89.99
Round  51, Train loss: 1.615, Test loss: 1.602, Test accuracy: 89.97
Round  52, Train loss: 1.646, Test loss: 1.603, Test accuracy: 89.97
Round  53, Train loss: 1.580, Test loss: 1.602, Test accuracy: 90.06
Round  54, Train loss: 1.551, Test loss: 1.597, Test accuracy: 90.06
Round  55, Train loss: 1.585, Test loss: 1.597, Test accuracy: 90.07
Round  56, Train loss: 1.642, Test loss: 1.600, Test accuracy: 90.18
Round  57, Train loss: 1.607, Test loss: 1.596, Test accuracy: 90.18
Round  58, Train loss: 1.526, Test loss: 1.592, Test accuracy: 90.22
Round  59, Train loss: 1.573, Test loss: 1.596, Test accuracy: 90.27
Round  60, Train loss: 1.584, Test loss: 1.591, Test accuracy: 90.39
Round  61, Train loss: 1.601, Test loss: 1.596, Test accuracy: 90.41
Round  62, Train loss: 1.600, Test loss: 1.591, Test accuracy: 90.46
Round  63, Train loss: 1.577, Test loss: 1.584, Test accuracy: 91.25
Round  64, Train loss: 1.585, Test loss: 1.584, Test accuracy: 91.21
Round  65, Train loss: 1.514, Test loss: 1.582, Test accuracy: 90.94
Round  66, Train loss: 1.533, Test loss: 1.571, Test accuracy: 92.39
Round  67, Train loss: 1.582, Test loss: 1.569, Test accuracy: 92.35
Round  68, Train loss: 1.507, Test loss: 1.571, Test accuracy: 92.52
Round  69, Train loss: 1.578, Test loss: 1.570, Test accuracy: 92.42
Round  70, Train loss: 1.512, Test loss: 1.568, Test accuracy: 92.53
Round  71, Train loss: 1.570, Test loss: 1.571, Test accuracy: 92.42
Round  72, Train loss: 1.543, Test loss: 1.570, Test accuracy: 92.32
Round  73, Train loss: 1.568, Test loss: 1.571, Test accuracy: 92.37
Round  74, Train loss: 1.569, Test loss: 1.569, Test accuracy: 92.61
Round  75, Train loss: 1.597, Test loss: 1.572, Test accuracy: 92.59
Round  76, Train loss: 1.564, Test loss: 1.570, Test accuracy: 92.49
Round  77, Train loss: 1.534, Test loss: 1.569, Test accuracy: 92.63
Round  78, Train loss: 1.565, Test loss: 1.569, Test accuracy: 92.53
Round  79, Train loss: 1.563, Test loss: 1.567, Test accuracy: 92.62
Round  80, Train loss: 1.552, Test loss: 1.563, Test accuracy: 93.30
Round  81, Train loss: 1.534, Test loss: 1.564, Test accuracy: 93.23
Round  82, Train loss: 1.516, Test loss: 1.560, Test accuracy: 93.46
Round  83, Train loss: 1.535, Test loss: 1.561, Test accuracy: 93.37
Round  84, Train loss: 1.530, Test loss: 1.562, Test accuracy: 93.60
Round  85, Train loss: 1.529, Test loss: 1.562, Test accuracy: 93.45
Round  86, Train loss: 1.549, Test loss: 1.556, Test accuracy: 93.50
Round  87, Train loss: 1.597, Test loss: 1.560, Test accuracy: 93.51
Round  88, Train loss: 1.557, Test loss: 1.563, Test accuracy: 93.52
Round  89, Train loss: 1.539, Test loss: 1.558, Test accuracy: 93.67
Round  90, Train loss: 1.511, Test loss: 1.553, Test accuracy: 93.68
Round  91, Train loss: 1.537, Test loss: 1.553, Test accuracy: 93.66
Round  92, Train loss: 1.503, Test loss: 1.553, Test accuracy: 93.64
Round  93, Train loss: 1.532, Test loss: 1.554, Test accuracy: 93.47
Round  94, Train loss: 1.533, Test loss: 1.553, Test accuracy: 93.58
Round  95, Train loss: 1.562, Test loss: 1.551, Test accuracy: 93.65
Round  96, Train loss: 1.518, Test loss: 1.548, Test accuracy: 93.94
Round  97, Train loss: 1.538, Test loss: 1.547, Test accuracy: 94.56
Round  98, Train loss: 1.559, Test loss: 1.550, Test accuracy: 94.59
Round  99, Train loss: 1.554, Test loss: 1.549, Test accuracy: 94.64
Round 100, Train loss: 1.579, Test loss: 1.549, Test accuracy: 94.70
Round 101, Train loss: 1.508, Test loss: 1.544, Test accuracy: 94.61
Round 102, Train loss: 1.533, Test loss: 1.544, Test accuracy: 94.65
Round 103, Train loss: 1.498, Test loss: 1.545, Test accuracy: 94.58
Round 104, Train loss: 1.497, Test loss: 1.545, Test accuracy: 94.61
Round 105, Train loss: 1.532, Test loss: 1.545, Test accuracy: 94.55
Round 106, Train loss: 1.531, Test loss: 1.543, Test accuracy: 94.67
Round 107, Train loss: 1.552, Test loss: 1.536, Test accuracy: 95.40
Round 108, Train loss: 1.505, Test loss: 1.536, Test accuracy: 95.37
Round 109, Train loss: 1.528, Test loss: 1.539, Test accuracy: 95.41
Round 110, Train loss: 1.498, Test loss: 1.537, Test accuracy: 95.23
Round 111, Train loss: 1.523, Test loss: 1.539, Test accuracy: 95.45
Round 112, Train loss: 1.502, Test loss: 1.536, Test accuracy: 95.41
Round 113, Train loss: 1.528, Test loss: 1.537, Test accuracy: 95.37
Round 114, Train loss: 1.525, Test loss: 1.538, Test accuracy: 95.57
Round 115, Train loss: 1.529, Test loss: 1.538, Test accuracy: 95.57
Round 116, Train loss: 1.505, Test loss: 1.534, Test accuracy: 95.48
Round 117, Train loss: 1.525, Test loss: 1.535, Test accuracy: 95.53
Round 118, Train loss: 1.527, Test loss: 1.538, Test accuracy: 95.40
Round 119, Train loss: 1.524, Test loss: 1.537, Test accuracy: 95.45
Round 120, Train loss: 1.495, Test loss: 1.534, Test accuracy: 95.59
Round 121, Train loss: 1.565, Test loss: 1.534, Test accuracy: 95.47
Round 122, Train loss: 1.554, Test loss: 1.539, Test accuracy: 95.49
Round 123, Train loss: 1.504, Test loss: 1.531, Test accuracy: 95.59
Round 124, Train loss: 1.490, Test loss: 1.532, Test accuracy: 95.44
Round 125, Train loss: 1.493, Test loss: 1.533, Test accuracy: 95.48
Round 126, Train loss: 1.495, Test loss: 1.532, Test accuracy: 95.50
Round 127, Train loss: 1.492, Test loss: 1.533, Test accuracy: 95.44
Round 128, Train loss: 1.496, Test loss: 1.532, Test accuracy: 95.42
Round 129, Train loss: 1.493, Test loss: 1.532, Test accuracy: 95.57
Round 130, Train loss: 1.491, Test loss: 1.532, Test accuracy: 95.54
Round 131, Train loss: 1.521, Test loss: 1.533, Test accuracy: 95.62
Round 132, Train loss: 1.496, Test loss: 1.530, Test accuracy: 95.61
Round 133, Train loss: 1.496, Test loss: 1.531, Test accuracy: 95.44
Round 134, Train loss: 1.524, Test loss: 1.531, Test accuracy: 95.56
Round 135, Train loss: 1.525, Test loss: 1.531, Test accuracy: 95.70
Round 136, Train loss: 1.491, Test loss: 1.530, Test accuracy: 95.57
Round 137, Train loss: 1.522, Test loss: 1.531, Test accuracy: 95.61
Round 138, Train loss: 1.521, Test loss: 1.531, Test accuracy: 95.72
Round 139, Train loss: 1.520, Test loss: 1.532, Test accuracy: 95.71
Round 140, Train loss: 1.520, Test loss: 1.533, Test accuracy: 95.71
Round 141, Train loss: 1.493, Test loss: 1.530, Test accuracy: 95.53
Round 142, Train loss: 1.492, Test loss: 1.528, Test accuracy: 95.65
Round 143, Train loss: 1.489, Test loss: 1.530, Test accuracy: 95.56
Round 144, Train loss: 1.524, Test loss: 1.530, Test accuracy: 95.65
Round 145, Train loss: 1.521, Test loss: 1.529, Test accuracy: 95.63
Round 146, Train loss: 1.553, Test loss: 1.533, Test accuracy: 95.52
Round 147, Train loss: 1.520, Test loss: 1.531, Test accuracy: 95.65
Round 148, Train loss: 1.520, Test loss: 1.531, Test accuracy: 95.61
Round 149, Train loss: 1.489, Test loss: 1.529, Test accuracy: 95.71
Round 150, Train loss: 1.518, Test loss: 1.531, Test accuracy: 95.59
Round 151, Train loss: 1.489, Test loss: 1.527, Test accuracy: 95.73
Round 152, Train loss: 1.519, Test loss: 1.530, Test accuracy: 95.73
Round 153, Train loss: 1.489, Test loss: 1.527, Test accuracy: 95.77
Round 154, Train loss: 1.517, Test loss: 1.531, Test accuracy: 95.70
Round 155, Train loss: 1.518, Test loss: 1.530, Test accuracy: 95.53
Round 156, Train loss: 1.489, Test loss: 1.527, Test accuracy: 95.74
Round 157, Train loss: 1.487, Test loss: 1.528, Test accuracy: 95.59
Round 158, Train loss: 1.518, Test loss: 1.529, Test accuracy: 95.71
Round 159, Train loss: 1.515, Test loss: 1.529, Test accuracy: 95.73
Round 160, Train loss: 1.486, Test loss: 1.528, Test accuracy: 95.68
Round 161, Train loss: 1.486, Test loss: 1.529, Test accuracy: 95.57
Round 162, Train loss: 1.546, Test loss: 1.531, Test accuracy: 95.52
Round 163, Train loss: 1.486, Test loss: 1.529, Test accuracy: 95.72
Round 164, Train loss: 1.545, Test loss: 1.530, Test accuracy: 95.52
Round 165, Train loss: 1.534, Test loss: 1.527, Test accuracy: 95.80
Round 166, Train loss: 1.489, Test loss: 1.526, Test accuracy: 95.50
Round 167, Train loss: 1.485, Test loss: 1.526, Test accuracy: 95.58
Round 168, Train loss: 1.518, Test loss: 1.527, Test accuracy: 95.64
Round 169, Train loss: 1.526, Test loss: 1.523, Test accuracy: 96.53
Round 170, Train loss: 1.486, Test loss: 1.522, Test accuracy: 96.35
Round 171, Train loss: 1.487, Test loss: 1.522, Test accuracy: 96.43
Round 172, Train loss: 1.493, Test loss: 1.518, Test accuracy: 96.48
Round 173, Train loss: 1.517, Test loss: 1.521, Test accuracy: 96.62
Round 174, Train loss: 1.491, Test loss: 1.517, Test accuracy: 96.70
Round 175, Train loss: 1.521, Test loss: 1.518, Test accuracy: 96.73
Round 176, Train loss: 1.485, Test loss: 1.519, Test accuracy: 96.73
Round 177, Train loss: 1.487, Test loss: 1.519, Test accuracy: 96.49
Round 178, Train loss: 1.485, Test loss: 1.519, Test accuracy: 96.57
Round 179, Train loss: 1.485, Test loss: 1.519, Test accuracy: 96.59
Round 180, Train loss: 1.488, Test loss: 1.518, Test accuracy: 96.56
Round 181, Train loss: 1.485, Test loss: 1.519, Test accuracy: 96.60
Round 182, Train loss: 1.488, Test loss: 1.519, Test accuracy: 96.53
Round 183, Train loss: 1.485, Test loss: 1.518, Test accuracy: 96.66
Round 184, Train loss: 1.517, Test loss: 1.520, Test accuracy: 96.59
Round 185, Train loss: 1.519, Test loss: 1.518, Test accuracy: 96.62
Round 186, Train loss: 1.516, Test loss: 1.519, Test accuracy: 96.53
Round 187, Train loss: 1.518, Test loss: 1.519, Test accuracy: 96.67
Round 188, Train loss: 1.485, Test loss: 1.517, Test accuracy: 96.72
Round 189, Train loss: 1.516, Test loss: 1.518, Test accuracy: 96.71
Round 190, Train loss: 1.517, Test loss: 1.519, Test accuracy: 96.72
Round 191, Train loss: 1.484, Test loss: 1.517, Test accuracy: 96.66
Round 192, Train loss: 1.487, Test loss: 1.516, Test accuracy: 96.63
Round 193, Train loss: 1.483, Test loss: 1.518, Test accuracy: 96.69
Round 194, Train loss: 1.483, Test loss: 1.516, Test accuracy: 96.74
Round 195, Train loss: 1.514, Test loss: 1.517, Test accuracy: 96.82
Round 196, Train loss: 1.517, Test loss: 1.519, Test accuracy: 96.62
Round 197, Train loss: 1.484, Test loss: 1.518, Test accuracy: 96.64
Round 198, Train loss: 1.487, Test loss: 1.516, Test accuracy: 96.62
Round 199, Train loss: 1.484, Test loss: 1.516, Test accuracy: 96.62
Final Round, Train loss: 1.481, Test loss: 1.514, Test accuracy: 96.68
Average accuracy final 10 rounds: 96.67600000000002
2061.460938692093
[1.174565076828003, 2.349130153656006, 3.740109443664551, 5.131088733673096, 6.2366955280303955, 7.342302322387695, 8.408016681671143, 9.47373104095459, 10.614673614501953, 11.755616188049316, 13.2056565284729, 14.655696868896484, 15.963542938232422, 17.27138900756836, 18.683809518814087, 20.096230030059814, 21.309295415878296, 22.522360801696777, 23.56628155708313, 24.610202312469482, 25.742165565490723, 26.874128818511963, 28.12470316886902, 29.375277519226074, 30.75354790687561, 32.13181829452515, 33.29371738433838, 34.45561647415161, 35.705432653427124, 36.95524883270264, 38.323421001434326, 39.691593170166016, 40.67507529258728, 41.658557415008545, 42.5857207775116, 43.51288414001465, 44.43299865722656, 45.35311317443848, 46.20700407028198, 47.06089496612549, 47.929264068603516, 48.79763317108154, 49.67017674446106, 50.542720317840576, 51.49574303627014, 52.44876575469971, 53.384876012802124, 54.32098627090454, 55.26127576828003, 56.20156526565552, 57.11412215232849, 58.026679039001465, 58.88574552536011, 59.74481201171875, 60.746928215026855, 61.74904441833496, 62.73800873756409, 63.72697305679321, 64.71119284629822, 65.69541263580322, 66.92118716239929, 68.14696168899536, 69.22849225997925, 70.31002283096313, 71.25855112075806, 72.20707941055298, 73.19074773788452, 74.17441606521606, 75.19559526443481, 76.21677446365356, 77.19082069396973, 78.16486692428589, 79.12222576141357, 80.07958459854126, 81.13848423957825, 82.19738388061523, 83.16504406929016, 84.13270425796509, 85.1151556968689, 86.0976071357727, 87.05093455314636, 88.00426197052002, 89.12424206733704, 90.24422216415405, 91.2705750465393, 92.29692792892456, 93.32521104812622, 94.35349416732788, 95.29925203323364, 96.2450098991394, 97.17927956581116, 98.11354923248291, 99.14522886276245, 100.17690849304199, 101.14093327522278, 102.10495805740356, 103.05449843406677, 104.00403881072998, 105.08007025718689, 106.1561017036438, 107.12096810340881, 108.08583450317383, 109.1238763332367, 110.16191816329956, 111.14063692092896, 112.11935567855835, 113.09536337852478, 114.07137107849121, 115.11998438835144, 116.16859769821167, 117.14326167106628, 118.1179256439209, 119.04022169113159, 119.96251773834229, 120.90112090110779, 121.83972406387329, 122.81418657302856, 123.78864908218384, 124.79593586921692, 125.80322265625, 126.76230788230896, 127.72139310836792, 128.66773891448975, 129.61408472061157, 130.5571370124817, 131.5001893043518, 132.42737650871277, 133.35456371307373, 134.32297253608704, 135.29138135910034, 136.28544664382935, 137.27951192855835, 138.21522498130798, 139.15093803405762, 140.14980936050415, 141.14868068695068, 142.1304211616516, 143.11216163635254, 144.09772205352783, 145.08328247070312, 146.06142568588257, 147.039568901062, 147.9720687866211, 148.90456867218018, 150.00169730186462, 151.09882593154907, 152.03186702728271, 152.96490812301636, 154.01353192329407, 155.06215572357178, 156.04972767829895, 157.03729963302612, 157.95927739143372, 158.8812551498413, 159.81233143806458, 160.74340772628784, 161.6525480747223, 162.56168842315674, 163.66413021087646, 164.7665719985962, 165.75193905830383, 166.73730611801147, 167.67125391960144, 168.6052017211914, 169.66424942016602, 170.72329711914062, 171.7403712272644, 172.75744533538818, 173.85367894172668, 174.94991254806519, 175.88514685630798, 176.82038116455078, 177.71745800971985, 178.61453485488892, 179.47662711143494, 180.33871936798096, 181.28098368644714, 182.22324800491333, 183.1705219745636, 184.11779594421387, 185.01956820487976, 185.92134046554565, 186.8476619720459, 187.77398347854614, 188.78049612045288, 189.78700876235962, 190.71533918380737, 191.64366960525513, 192.5026195049286, 193.36156940460205, 194.30837678909302, 195.25518417358398, 196.23226141929626, 197.20933866500854, 198.1472465991974, 199.08515453338623, 199.8841094970703, 200.6830644607544, 201.56996297836304, 202.45686149597168, 203.36257195472717, 204.26828241348267, 205.16342687606812, 206.05857133865356, 207.0445213317871, 208.03047132492065, 209.02920627593994, 210.02794122695923, 211.07683444023132, 212.12572765350342, 213.08450269699097, 214.04327774047852, 214.9167103767395, 215.7901430130005, 216.71837615966797, 217.64660930633545, 218.52628183364868, 219.4059543609619, 220.35687971115112, 221.30780506134033, 222.29285621643066, 223.277907371521, 224.14735674858093, 225.01680612564087, 225.94869327545166, 226.88058042526245, 227.7612669467926, 228.64195346832275, 229.5406379699707, 230.43932247161865, 231.3485894203186, 232.25785636901855, 233.07305073738098, 233.8882451057434, 234.67051100730896, 235.4527769088745, 236.32283735275269, 237.19289779663086, 238.1057870388031, 239.01867628097534, 239.81994795799255, 240.62121963500977, 241.44903683662415, 242.27685403823853, 243.07634687423706, 243.8758397102356, 244.71205186843872, 245.54826402664185, 246.36103296279907, 247.1738018989563, 248.00005054473877, 248.82629919052124, 249.63203501701355, 250.43777084350586, 251.2868800163269, 252.13598918914795, 252.95281982421875, 253.76965045928955, 254.6239893436432, 255.47832822799683, 256.30425786972046, 257.1301875114441, 258.0313148498535, 258.93244218826294, 259.7578024864197, 260.5831627845764, 261.4228889942169, 262.2626152038574, 263.0803425312042, 263.898069858551, 264.96183729171753, 266.02560472488403, 266.9903337955475, 267.95506286621094, 268.9279501438141, 269.90083742141724, 270.85657691955566, 271.8123164176941, 272.75602746009827, 273.69973850250244, 274.56545782089233, 275.4311771392822, 276.3142285346985, 277.19727993011475, 278.1297516822815, 279.06222343444824, 280.05506682395935, 281.04791021347046, 281.93688225746155, 282.82585430145264, 283.82136940956116, 284.8168845176697, 285.7560193538666, 286.6951541900635, 287.6139783859253, 288.5328025817871, 289.47501587867737, 290.4172291755676, 291.3836283683777, 292.35002756118774, 293.31758213043213, 294.2851366996765, 295.18790197372437, 296.0906672477722, 297.08434200286865, 298.0780167579651, 298.9623453617096, 299.8466739654541, 300.80973768234253, 301.77280139923096, 302.718111038208, 303.66342067718506, 304.5483236312866, 305.4332265853882, 306.396356344223, 307.35948610305786, 308.2870376110077, 309.2145891189575, 310.15992856025696, 311.1052680015564, 311.9985361099243, 312.89180421829224, 313.81363463401794, 314.73546504974365, 315.59811210632324, 316.46075916290283, 317.4180266857147, 318.3752942085266, 319.3192183971405, 320.2631425857544, 321.1544108390808, 322.0456790924072, 323.0420615673065, 324.0384440422058, 325.0786712169647, 326.11889839172363, 327.047598361969, 327.97629833221436, 328.90427923202515, 329.83226013183594, 330.79259037971497, 331.752920627594, 332.9613435268402, 334.1697664260864, 335.1655502319336, 336.16133403778076, 337.03078174591064, 337.9002294540405, 338.9648189544678, 340.029408454895, 340.94675302505493, 341.86409759521484, 342.87997484207153, 343.8958520889282, 344.85059428215027, 345.8053364753723, 346.76072120666504, 347.71610593795776, 348.6217043399811, 349.5273027420044, 350.458340883255, 351.3893790245056, 352.2738444805145, 353.15830993652344, 354.05383682250977, 354.9493637084961, 355.91217732429504, 356.874990940094, 357.82356357574463, 358.77213621139526, 359.7340009212494, 360.6958656311035, 361.56693148612976, 362.437997341156, 363.552494764328, 364.6669921875, 365.6418528556824, 366.61671352386475, 367.5758991241455, 368.53508472442627, 369.5483932495117, 370.56170177459717, 371.434054851532, 372.3064079284668, 373.2131917476654, 374.119975566864, 375.01959919929504, 375.9192228317261, 376.73425006866455, 377.549277305603, 378.5664336681366, 379.58359003067017, 380.5335750579834, 381.48356008529663, 382.4022216796875, 383.32088327407837, 384.188280582428, 385.0556778907776, 386.0319299697876, 387.0081820487976, 388.6897814273834, 390.37138080596924]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[15.74, 15.74, 14.65, 14.65, 15.32, 15.32, 17.9, 17.9, 20.9, 20.9, 28.35, 28.35, 29.86, 29.86, 33.69, 33.69, 37.36, 37.36, 42.84, 42.84, 47.19, 47.19, 49.93, 49.93, 55.99, 55.99, 57.26, 57.26, 58.76, 58.76, 60.62, 60.62, 63.0, 63.0, 65.1, 65.1, 68.04, 68.04, 69.46, 69.46, 71.77, 71.77, 73.79, 73.79, 74.57, 74.57, 77.08, 77.08, 79.22, 79.22, 81.55, 81.55, 82.46, 82.46, 85.5, 85.5, 86.49, 86.49, 86.87, 86.87, 86.57, 86.57, 87.67, 87.67, 87.92, 87.92, 88.66, 88.66, 89.33, 89.33, 89.3, 89.3, 89.4, 89.4, 89.54, 89.54, 89.7, 89.7, 89.69, 89.69, 89.68, 89.68, 89.71, 89.71, 89.66, 89.66, 89.76, 89.76, 89.74, 89.74, 89.71, 89.71, 89.77, 89.77, 89.88, 89.88, 89.9, 89.9, 89.99, 89.99, 89.99, 89.99, 89.97, 89.97, 89.97, 89.97, 90.06, 90.06, 90.06, 90.06, 90.07, 90.07, 90.18, 90.18, 90.18, 90.18, 90.22, 90.22, 90.27, 90.27, 90.39, 90.39, 90.41, 90.41, 90.46, 90.46, 91.25, 91.25, 91.21, 91.21, 90.94, 90.94, 92.39, 92.39, 92.35, 92.35, 92.52, 92.52, 92.42, 92.42, 92.53, 92.53, 92.42, 92.42, 92.32, 92.32, 92.37, 92.37, 92.61, 92.61, 92.59, 92.59, 92.49, 92.49, 92.63, 92.63, 92.53, 92.53, 92.62, 92.62, 93.3, 93.3, 93.23, 93.23, 93.46, 93.46, 93.37, 93.37, 93.6, 93.6, 93.45, 93.45, 93.5, 93.5, 93.51, 93.51, 93.52, 93.52, 93.67, 93.67, 93.68, 93.68, 93.66, 93.66, 93.64, 93.64, 93.47, 93.47, 93.58, 93.58, 93.65, 93.65, 93.94, 93.94, 94.56, 94.56, 94.59, 94.59, 94.64, 94.64, 94.7, 94.7, 94.61, 94.61, 94.65, 94.65, 94.58, 94.58, 94.61, 94.61, 94.55, 94.55, 94.67, 94.67, 95.4, 95.4, 95.37, 95.37, 95.41, 95.41, 95.23, 95.23, 95.45, 95.45, 95.41, 95.41, 95.37, 95.37, 95.57, 95.57, 95.57, 95.57, 95.48, 95.48, 95.53, 95.53, 95.4, 95.4, 95.45, 95.45, 95.59, 95.59, 95.47, 95.47, 95.49, 95.49, 95.59, 95.59, 95.44, 95.44, 95.48, 95.48, 95.5, 95.5, 95.44, 95.44, 95.42, 95.42, 95.57, 95.57, 95.54, 95.54, 95.62, 95.62, 95.61, 95.61, 95.44, 95.44, 95.56, 95.56, 95.7, 95.7, 95.57, 95.57, 95.61, 95.61, 95.72, 95.72, 95.71, 95.71, 95.71, 95.71, 95.53, 95.53, 95.65, 95.65, 95.56, 95.56, 95.65, 95.65, 95.63, 95.63, 95.52, 95.52, 95.65, 95.65, 95.61, 95.61, 95.71, 95.71, 95.59, 95.59, 95.73, 95.73, 95.73, 95.73, 95.77, 95.77, 95.7, 95.7, 95.53, 95.53, 95.74, 95.74, 95.59, 95.59, 95.71, 95.71, 95.73, 95.73, 95.68, 95.68, 95.57, 95.57, 95.52, 95.52, 95.72, 95.72, 95.52, 95.52, 95.8, 95.8, 95.5, 95.5, 95.58, 95.58, 95.64, 95.64, 96.53, 96.53, 96.35, 96.35, 96.43, 96.43, 96.48, 96.48, 96.62, 96.62, 96.7, 96.7, 96.73, 96.73, 96.73, 96.73, 96.49, 96.49, 96.57, 96.57, 96.59, 96.59, 96.56, 96.56, 96.6, 96.6, 96.53, 96.53, 96.66, 96.66, 96.59, 96.59, 96.62, 96.62, 96.53, 96.53, 96.67, 96.67, 96.72, 96.72, 96.71, 96.71, 96.72, 96.72, 96.66, 96.66, 96.63, 96.63, 96.69, 96.69, 96.74, 96.74, 96.82, 96.82, 96.62, 96.62, 96.64, 96.64, 96.62, 96.62, 96.62, 96.62, 96.68, 96.68]
