nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.194, Test loss: 2.049, Test accuracy: 25.73 

Round   0, Global train loss: 2.194, Global test loss: 2.044, Global test accuracy: 26.86 

Round   1, Train loss: 1.999, Test loss: 1.945, Test accuracy: 27.97 

Round   1, Global train loss: 1.999, Global test loss: 1.885, Global test accuracy: 30.74 

Round   2, Train loss: 1.904, Test loss: 1.881, Test accuracy: 30.68 

Round   2, Global train loss: 1.904, Global test loss: 1.793, Global test accuracy: 34.70 

Round   3, Train loss: 1.788, Test loss: 1.841, Test accuracy: 32.73 

Round   3, Global train loss: 1.788, Global test loss: 1.725, Global test accuracy: 38.12 

Round   4, Train loss: 1.768, Test loss: 1.814, Test accuracy: 33.03 

Round   4, Global train loss: 1.768, Global test loss: 1.646, Global test accuracy: 39.89 

Round   5, Train loss: 1.695, Test loss: 1.792, Test accuracy: 34.02 

Round   5, Global train loss: 1.695, Global test loss: 1.636, Global test accuracy: 40.91 

Round   6, Train loss: 1.680, Test loss: 1.771, Test accuracy: 34.92 

Round   6, Global train loss: 1.680, Global test loss: 1.643, Global test accuracy: 40.47 

Round   7, Train loss: 1.699, Test loss: 1.769, Test accuracy: 35.28 

Round   7, Global train loss: 1.699, Global test loss: 1.674, Global test accuracy: 39.34 

Round   8, Train loss: 1.514, Test loss: 1.754, Test accuracy: 35.81 

Round   8, Global train loss: 1.514, Global test loss: 1.548, Global test accuracy: 43.97 

Round   9, Train loss: 1.517, Test loss: 1.754, Test accuracy: 35.90 

Round   9, Global train loss: 1.517, Global test loss: 1.529, Global test accuracy: 44.02 

Round  10, Train loss: 1.440, Test loss: 1.757, Test accuracy: 36.31 

Round  10, Global train loss: 1.440, Global test loss: 1.537, Global test accuracy: 44.52 

Round  11, Train loss: 1.419, Test loss: 1.739, Test accuracy: 37.33 

Round  11, Global train loss: 1.419, Global test loss: 1.495, Global test accuracy: 45.41 

Round  12, Train loss: 1.379, Test loss: 1.751, Test accuracy: 37.38 

Round  12, Global train loss: 1.379, Global test loss: 1.511, Global test accuracy: 45.19 

Round  13, Train loss: 1.372, Test loss: 1.767, Test accuracy: 37.58 

Round  13, Global train loss: 1.372, Global test loss: 1.526, Global test accuracy: 43.76 

Round  14, Train loss: 1.269, Test loss: 1.788, Test accuracy: 37.63 

Round  14, Global train loss: 1.269, Global test loss: 1.488, Global test accuracy: 45.84 

Round  15, Train loss: 1.487, Test loss: 1.789, Test accuracy: 38.33 

Round  15, Global train loss: 1.487, Global test loss: 1.585, Global test accuracy: 42.37 

Round  16, Train loss: 1.413, Test loss: 1.788, Test accuracy: 38.66 

Round  16, Global train loss: 1.413, Global test loss: 1.516, Global test accuracy: 45.33 

Round  17, Train loss: 1.142, Test loss: 1.800, Test accuracy: 39.09 

Round  17, Global train loss: 1.142, Global test loss: 1.489, Global test accuracy: 46.64 

Round  18, Train loss: 1.180, Test loss: 1.803, Test accuracy: 39.14 

Round  18, Global train loss: 1.180, Global test loss: 1.495, Global test accuracy: 45.84 

Round  19, Train loss: 1.272, Test loss: 1.808, Test accuracy: 39.63 

Round  19, Global train loss: 1.272, Global test loss: 1.491, Global test accuracy: 46.84 

Round  20, Train loss: 1.224, Test loss: 1.816, Test accuracy: 40.13 

Round  20, Global train loss: 1.224, Global test loss: 1.503, Global test accuracy: 45.30 

Round  21, Train loss: 1.107, Test loss: 1.846, Test accuracy: 40.02 

Round  21, Global train loss: 1.107, Global test loss: 1.502, Global test accuracy: 45.30 

Round  22, Train loss: 1.092, Test loss: 1.853, Test accuracy: 39.95 

Round  22, Global train loss: 1.092, Global test loss: 1.498, Global test accuracy: 46.18 

Round  23, Train loss: 1.096, Test loss: 1.866, Test accuracy: 40.27 

Round  23, Global train loss: 1.096, Global test loss: 1.483, Global test accuracy: 46.13 

Round  24, Train loss: 0.931, Test loss: 1.897, Test accuracy: 40.42 

Round  24, Global train loss: 0.931, Global test loss: 1.515, Global test accuracy: 45.77 

Round  25, Train loss: 1.103, Test loss: 1.908, Test accuracy: 40.20 

Round  25, Global train loss: 1.103, Global test loss: 1.469, Global test accuracy: 47.30 

Round  26, Train loss: 1.088, Test loss: 1.918, Test accuracy: 40.72 

Round  26, Global train loss: 1.088, Global test loss: 1.466, Global test accuracy: 47.60 

Round  27, Train loss: 0.958, Test loss: 1.957, Test accuracy: 40.68 

Round  27, Global train loss: 0.958, Global test loss: 1.482, Global test accuracy: 47.33 

Round  28, Train loss: 1.062, Test loss: 1.987, Test accuracy: 40.77 

Round  28, Global train loss: 1.062, Global test loss: 1.484, Global test accuracy: 47.34 

Round  29, Train loss: 0.973, Test loss: 2.022, Test accuracy: 40.48 

Round  29, Global train loss: 0.973, Global test loss: 1.466, Global test accuracy: 47.39 

Round  30, Train loss: 0.846, Test loss: 2.055, Test accuracy: 40.57 

Round  30, Global train loss: 0.846, Global test loss: 1.455, Global test accuracy: 47.93 

Round  31, Train loss: 0.721, Test loss: 2.066, Test accuracy: 40.83 

Round  31, Global train loss: 0.721, Global test loss: 1.471, Global test accuracy: 48.25 

Round  32, Train loss: 0.837, Test loss: 2.088, Test accuracy: 41.30 

Round  32, Global train loss: 0.837, Global test loss: 1.487, Global test accuracy: 47.97 

Round  33, Train loss: 0.814, Test loss: 2.121, Test accuracy: 41.17 

Round  33, Global train loss: 0.814, Global test loss: 1.476, Global test accuracy: 47.44 

Round  34, Train loss: 0.785, Test loss: 2.239, Test accuracy: 40.29 

Round  34, Global train loss: 0.785, Global test loss: 1.472, Global test accuracy: 47.58 

Round  35, Train loss: 0.726, Test loss: 2.184, Test accuracy: 40.82 

Round  35, Global train loss: 0.726, Global test loss: 1.476, Global test accuracy: 47.69 

Round  36, Train loss: 0.732, Test loss: 2.213, Test accuracy: 40.99 

Round  36, Global train loss: 0.732, Global test loss: 1.463, Global test accuracy: 47.95 

Round  37, Train loss: 0.843, Test loss: 2.267, Test accuracy: 40.94 

Round  37, Global train loss: 0.843, Global test loss: 1.480, Global test accuracy: 46.93 

Round  38, Train loss: 0.614, Test loss: 2.327, Test accuracy: 41.12 

Round  38, Global train loss: 0.614, Global test loss: 1.528, Global test accuracy: 46.91 

Round  39, Train loss: 0.664, Test loss: 2.349, Test accuracy: 41.36 

Round  39, Global train loss: 0.664, Global test loss: 1.515, Global test accuracy: 46.14 

Round  40, Train loss: 0.696, Test loss: 2.404, Test accuracy: 41.23 

Round  40, Global train loss: 0.696, Global test loss: 1.498, Global test accuracy: 46.58 

Round  41, Train loss: 0.619, Test loss: 2.419, Test accuracy: 41.11 

Round  41, Global train loss: 0.619, Global test loss: 1.537, Global test accuracy: 46.73 

Round  42, Train loss: 0.610, Test loss: 2.476, Test accuracy: 41.08 

Round  42, Global train loss: 0.610, Global test loss: 1.536, Global test accuracy: 48.19 

Round  43, Train loss: 0.604, Test loss: 2.448, Test accuracy: 41.92 

Round  43, Global train loss: 0.604, Global test loss: 1.499, Global test accuracy: 49.11 

Round  44, Train loss: 0.627, Test loss: 2.452, Test accuracy: 42.04 

Round  44, Global train loss: 0.627, Global test loss: 1.497, Global test accuracy: 47.78 

Round  45, Train loss: 0.574, Test loss: 2.508, Test accuracy: 41.98 

Round  45, Global train loss: 0.574, Global test loss: 1.543, Global test accuracy: 47.52 

Round  46, Train loss: 0.444, Test loss: 2.541, Test accuracy: 41.72 

Round  46, Global train loss: 0.444, Global test loss: 1.558, Global test accuracy: 49.41 

Round  47, Train loss: 0.435, Test loss: 2.595, Test accuracy: 41.95 

Round  47, Global train loss: 0.435, Global test loss: 1.551, Global test accuracy: 49.69 

Round  48, Train loss: 0.507, Test loss: 2.652, Test accuracy: 42.02 

Round  48, Global train loss: 0.507, Global test loss: 1.553, Global test accuracy: 46.42 

Round  49, Train loss: 0.490, Test loss: 2.718, Test accuracy: 41.70 

Round  49, Global train loss: 0.490, Global test loss: 1.499, Global test accuracy: 48.17 

Round  50, Train loss: 0.450, Test loss: 2.820, Test accuracy: 41.30 

Round  50, Global train loss: 0.450, Global test loss: 1.598, Global test accuracy: 48.58 

Round  51, Train loss: 0.398, Test loss: 2.822, Test accuracy: 41.34 

Round  51, Global train loss: 0.398, Global test loss: 1.538, Global test accuracy: 48.74 

Round  52, Train loss: 0.507, Test loss: 2.830, Test accuracy: 41.17 

Round  52, Global train loss: 0.507, Global test loss: 1.521, Global test accuracy: 47.34 

Round  53, Train loss: 0.420, Test loss: 2.879, Test accuracy: 41.42 

Round  53, Global train loss: 0.420, Global test loss: 1.643, Global test accuracy: 47.60 

Round  54, Train loss: 0.357, Test loss: 2.917, Test accuracy: 41.34 

Round  54, Global train loss: 0.357, Global test loss: 1.551, Global test accuracy: 48.77 

Round  55, Train loss: 0.364, Test loss: 2.911, Test accuracy: 40.94 

Round  55, Global train loss: 0.364, Global test loss: 1.536, Global test accuracy: 47.52 

Round  56, Train loss: 0.398, Test loss: 2.920, Test accuracy: 41.22 

Round  56, Global train loss: 0.398, Global test loss: 1.535, Global test accuracy: 46.52 

Round  57, Train loss: 0.428, Test loss: 2.965, Test accuracy: 41.23 

Round  57, Global train loss: 0.428, Global test loss: 1.575, Global test accuracy: 48.88 

Round  58, Train loss: 0.361, Test loss: 3.044, Test accuracy: 41.01 

Round  58, Global train loss: 0.361, Global test loss: 1.560, Global test accuracy: 47.99 

Round  59, Train loss: 0.326, Test loss: 3.067, Test accuracy: 41.26 

Round  59, Global train loss: 0.326, Global test loss: 1.555, Global test accuracy: 47.52 

Round  60, Train loss: 0.410, Test loss: 3.140, Test accuracy: 41.03 

Round  60, Global train loss: 0.410, Global test loss: 1.524, Global test accuracy: 47.48 

Round  61, Train loss: 0.286, Test loss: 3.162, Test accuracy: 41.06 

Round  61, Global train loss: 0.286, Global test loss: 1.581, Global test accuracy: 47.63 

Round  62, Train loss: 0.269, Test loss: 3.221, Test accuracy: 40.96 

Round  62, Global train loss: 0.269, Global test loss: 1.578, Global test accuracy: 47.59 

Round  63, Train loss: 0.321, Test loss: 3.208, Test accuracy: 40.88 

Round  63, Global train loss: 0.321, Global test loss: 1.569, Global test accuracy: 46.85 

Round  64, Train loss: 0.381, Test loss: 3.232, Test accuracy: 41.30 

Round  64, Global train loss: 0.381, Global test loss: 1.593, Global test accuracy: 47.98 

Round  65, Train loss: 0.287, Test loss: 3.264, Test accuracy: 41.72 

Round  65, Global train loss: 0.287, Global test loss: 1.589, Global test accuracy: 46.92 

Round  66, Train loss: 0.308, Test loss: 3.299, Test accuracy: 41.55 

Round  66, Global train loss: 0.308, Global test loss: 1.575, Global test accuracy: 47.56 

Round  67, Train loss: 0.312, Test loss: 3.318, Test accuracy: 41.23 

Round  67, Global train loss: 0.312, Global test loss: 1.620, Global test accuracy: 47.13 

Round  68, Train loss: 0.311, Test loss: 3.357, Test accuracy: 41.29 

Round  68, Global train loss: 0.311, Global test loss: 1.729, Global test accuracy: 47.84 

Round  69, Train loss: 0.339, Test loss: 3.350, Test accuracy: 41.45 

Round  69, Global train loss: 0.339, Global test loss: 1.574, Global test accuracy: 47.90 

Round  70, Train loss: 0.293, Test loss: 3.418, Test accuracy: 41.03 

Round  70, Global train loss: 0.293, Global test loss: 1.605, Global test accuracy: 46.67 

Round  71, Train loss: 0.286, Test loss: 3.417, Test accuracy: 41.13 

Round  71, Global train loss: 0.286, Global test loss: 1.575, Global test accuracy: 48.52 

Round  72, Train loss: 0.281, Test loss: 3.492, Test accuracy: 41.21 

Round  72, Global train loss: 0.281, Global test loss: 1.529, Global test accuracy: 49.11 

Round  73, Train loss: 0.231, Test loss: 3.544, Test accuracy: 41.59 

Round  73, Global train loss: 0.231, Global test loss: 1.561, Global test accuracy: 47.74 

Round  74, Train loss: 0.194, Test loss: 3.606, Test accuracy: 41.38 

Round  74, Global train loss: 0.194, Global test loss: 1.701, Global test accuracy: 49.01 

Round  75, Train loss: 0.280, Test loss: 3.622, Test accuracy: 41.44 

Round  75, Global train loss: 0.280, Global test loss: 1.594, Global test accuracy: 48.55 

Round  76, Train loss: 0.267, Test loss: 3.620, Test accuracy: 41.62 

Round  76, Global train loss: 0.267, Global test loss: 1.598, Global test accuracy: 48.44 

Round  77, Train loss: 0.217, Test loss: 3.698, Test accuracy: 41.55 

Round  77, Global train loss: 0.217, Global test loss: 1.636, Global test accuracy: 47.83 

Round  78, Train loss: 0.246, Test loss: 3.719, Test accuracy: 41.45 

Round  78, Global train loss: 0.246, Global test loss: 1.652, Global test accuracy: 48.14 

Round  79, Train loss: 0.243, Test loss: 3.698, Test accuracy: 41.82 

Round  79, Global train loss: 0.243, Global test loss: 1.573, Global test accuracy: 48.14 

Round  80, Train loss: 0.198, Test loss: 3.660, Test accuracy: 42.05 

Round  80, Global train loss: 0.198, Global test loss: 1.659, Global test accuracy: 47.64 

Round  81, Train loss: 0.195, Test loss: 3.716, Test accuracy: 41.88 

Round  81, Global train loss: 0.195, Global test loss: 1.632, Global test accuracy: 48.48 

Round  82, Train loss: 0.223, Test loss: 3.676, Test accuracy: 42.28 

Round  82, Global train loss: 0.223, Global test loss: 1.543, Global test accuracy: 46.53 

Round  83, Train loss: 0.172, Test loss: 3.782, Test accuracy: 42.09 

Round  83, Global train loss: 0.172, Global test loss: 1.728, Global test accuracy: 47.10 

Round  84, Train loss: 0.205, Test loss: 3.707, Test accuracy: 42.45 

Round  84, Global train loss: 0.205, Global test loss: 1.703, Global test accuracy: 47.95 

Round  85, Train loss: 0.185, Test loss: 3.726, Test accuracy: 42.44 

Round  85, Global train loss: 0.185, Global test loss: 1.572, Global test accuracy: 48.01 

Round  86, Train loss: 0.177, Test loss: 3.814, Test accuracy: 42.47 

Round  86, Global train loss: 0.177, Global test loss: 1.615, Global test accuracy: 47.78 

Round  87, Train loss: 0.191, Test loss: 3.837, Test accuracy: 41.85 

Round  87, Global train loss: 0.191, Global test loss: 1.620, Global test accuracy: 48.20 

Round  88, Train loss: 0.165, Test loss: 3.882, Test accuracy: 41.55 

Round  88, Global train loss: 0.165, Global test loss: 1.640, Global test accuracy: 48.02 

Round  89, Train loss: 0.141, Test loss: 3.953, Test accuracy: 41.52 

Round  89, Global train loss: 0.141, Global test loss: 1.691, Global test accuracy: 46.03 

Round  90, Train loss: 0.194, Test loss: 3.931, Test accuracy: 41.63 

Round  90, Global train loss: 0.194, Global test loss: 1.666, Global test accuracy: 48.24 

Round  91, Train loss: 0.169, Test loss: 3.934, Test accuracy: 42.02 

Round  91, Global train loss: 0.169, Global test loss: 1.623, Global test accuracy: 47.22 

Round  92, Train loss: 0.173, Test loss: 4.007, Test accuracy: 42.01 

Round  92, Global train loss: 0.173, Global test loss: 1.683, Global test accuracy: 46.98 

Round  93, Train loss: 0.156, Test loss: 4.003, Test accuracy: 41.94 

Round  93, Global train loss: 0.156, Global test loss: 1.611, Global test accuracy: 46.63 

Round  94, Train loss: 0.145, Test loss: 3.998, Test accuracy: 42.00 

Round  94, Global train loss: 0.145, Global test loss: 1.623, Global test accuracy: 47.58 

Round  95, Train loss: 0.172, Test loss: 4.047, Test accuracy: 42.24 

Round  95, Global train loss: 0.172, Global test loss: 1.594, Global test accuracy: 48.73 

Round  96, Train loss: 0.156, Test loss: 4.080, Test accuracy: 42.34 

Round  96, Global train loss: 0.156, Global test loss: 1.559, Global test accuracy: 48.22 

Round  97, Train loss: 0.178, Test loss: 4.097, Test accuracy: 41.95 

Round  97, Global train loss: 0.178, Global test loss: 1.621, Global test accuracy: 47.20 

Round  98, Train loss: 0.159, Test loss: 4.107, Test accuracy: 42.05 

Round  98, Global train loss: 0.159, Global test loss: 1.722, Global test accuracy: 49.37 

Round  99, Train loss: 0.107, Test loss: 4.186, Test accuracy: 41.61 

Round  99, Global train loss: 0.107, Global test loss: 1.660, Global test accuracy: 48.59 

Final Round, Train loss: 0.150, Test loss: 4.201, Test accuracy: 42.53 

Final Round, Global train loss: 0.150, Global test loss: 1.660, Global test accuracy: 48.59 

Average accuracy final 10 rounds: 41.980500000000006 

Average global accuracy final 10 rounds: 47.875499999999995 

1625.7046048641205
[1.4107215404510498, 2.6066784858703613, 3.791586399078369, 4.9764320850372314, 6.160577058792114, 7.3351569175720215, 8.485170841217041, 9.658104419708252, 10.80582857131958, 11.959965229034424, 13.113332271575928, 14.267178535461426, 15.27042007446289, 16.27569890022278, 17.271764039993286, 18.278539180755615, 19.28255581855774, 20.282487392425537, 21.28527069091797, 22.286160230636597, 23.287416219711304, 24.289369106292725, 25.285737991333008, 26.289658069610596, 27.29811453819275, 28.29683566093445, 29.29808282852173, 30.30992555618286, 31.31972312927246, 32.32567095756531, 33.337013483047485, 34.345354080200195, 35.356725454330444, 36.35947632789612, 37.3656210899353, 38.37241268157959, 39.377341747283936, 40.3821747303009, 41.392622232437134, 42.406471252441406, 43.419238328933716, 44.431926250457764, 45.444958209991455, 46.4479775428772, 47.44541263580322, 48.45076107978821, 49.45350670814514, 50.45711326599121, 51.462260484695435, 52.46583914756775, 53.46766901016235, 54.469167947769165, 55.466809034347534, 56.47118663787842, 57.47257661819458, 58.46927738189697, 59.47465515136719, 60.4704270362854, 61.474432706832886, 62.47453188896179, 63.47332191467285, 64.4775013923645, 65.48147535324097, 66.47829699516296, 67.48950242996216, 68.50196528434753, 69.51191806793213, 70.5232470035553, 71.53482604026794, 72.55079221725464, 73.56238722801208, 74.57519125938416, 75.58707571029663, 76.60296440124512, 77.60913181304932, 78.6222836971283, 79.62345623970032, 80.61988997459412, 81.62450695037842, 82.6270797252655, 83.62983798980713, 84.64065790176392, 85.65163040161133, 86.66656517982483, 87.67883396148682, 88.68353986740112, 89.69852614402771, 90.7147388458252, 91.71053528785706, 92.71289086341858, 93.71199083328247, 94.72035241127014, 95.72917747497559, 96.72627639770508, 97.74809861183167, 98.80115938186646, 99.80434560775757, 100.80600214004517, 101.80359840393066, 102.8026134967804, 104.80126643180847]
[25.735, 27.97, 30.68, 32.725, 33.035, 34.025, 34.92, 35.285, 35.81, 35.9, 36.31, 37.33, 37.385, 37.575, 37.635, 38.325, 38.655, 39.085, 39.14, 39.63, 40.135, 40.015, 39.95, 40.27, 40.42, 40.195, 40.715, 40.68, 40.765, 40.48, 40.57, 40.825, 41.305, 41.175, 40.29, 40.82, 40.99, 40.94, 41.115, 41.36, 41.225, 41.11, 41.08, 41.92, 42.04, 41.98, 41.72, 41.95, 42.015, 41.705, 41.295, 41.335, 41.175, 41.42, 41.335, 40.935, 41.215, 41.23, 41.01, 41.26, 41.035, 41.065, 40.96, 40.88, 41.295, 41.72, 41.555, 41.225, 41.29, 41.455, 41.035, 41.135, 41.21, 41.585, 41.375, 41.44, 41.625, 41.545, 41.455, 41.82, 42.045, 41.875, 42.285, 42.095, 42.455, 42.435, 42.47, 41.855, 41.55, 41.52, 41.63, 42.025, 42.01, 41.935, 42.0, 42.245, 42.345, 41.95, 42.055, 41.61, 42.53]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.241, Test loss: 2.121, Test accuracy: 22.23 

Round   0, Global train loss: 2.241, Global test loss: 2.118, Global test accuracy: 22.96 

Round   1, Train loss: 2.043, Test loss: 1.957, Test accuracy: 28.16 

Round   1, Global train loss: 2.043, Global test loss: 1.894, Global test accuracy: 31.64 

Round   2, Train loss: 1.892, Test loss: 1.855, Test accuracy: 31.60 

Round   2, Global train loss: 1.892, Global test loss: 1.742, Global test accuracy: 36.92 

Round   3, Train loss: 1.792, Test loss: 1.780, Test accuracy: 34.16 

Round   3, Global train loss: 1.792, Global test loss: 1.643, Global test accuracy: 39.97 

Round   4, Train loss: 1.729, Test loss: 1.714, Test accuracy: 37.34 

Round   4, Global train loss: 1.729, Global test loss: 1.565, Global test accuracy: 43.76 

Round   5, Train loss: 1.650, Test loss: 1.685, Test accuracy: 38.46 

Round   5, Global train loss: 1.650, Global test loss: 1.530, Global test accuracy: 45.03 

Round   6, Train loss: 1.620, Test loss: 1.620, Test accuracy: 40.48 

Round   6, Global train loss: 1.620, Global test loss: 1.476, Global test accuracy: 46.29 

Round   7, Train loss: 1.542, Test loss: 1.600, Test accuracy: 41.12 

Round   7, Global train loss: 1.542, Global test loss: 1.441, Global test accuracy: 47.84 

Round   8, Train loss: 1.541, Test loss: 1.573, Test accuracy: 42.48 

Round   8, Global train loss: 1.541, Global test loss: 1.409, Global test accuracy: 49.44 

Round   9, Train loss: 1.466, Test loss: 1.568, Test accuracy: 42.92 

Round   9, Global train loss: 1.466, Global test loss: 1.371, Global test accuracy: 50.30 

Round  10, Train loss: 1.442, Test loss: 1.539, Test accuracy: 43.98 

Round  10, Global train loss: 1.442, Global test loss: 1.355, Global test accuracy: 50.97 

Round  11, Train loss: 1.388, Test loss: 1.528, Test accuracy: 44.98 

Round  11, Global train loss: 1.388, Global test loss: 1.324, Global test accuracy: 52.34 

Round  12, Train loss: 1.346, Test loss: 1.519, Test accuracy: 45.41 

Round  12, Global train loss: 1.346, Global test loss: 1.293, Global test accuracy: 54.57 

Round  13, Train loss: 1.373, Test loss: 1.482, Test accuracy: 46.98 

Round  13, Global train loss: 1.373, Global test loss: 1.266, Global test accuracy: 55.15 

Round  14, Train loss: 1.309, Test loss: 1.480, Test accuracy: 46.98 

Round  14, Global train loss: 1.309, Global test loss: 1.258, Global test accuracy: 55.32 

Round  15, Train loss: 1.279, Test loss: 1.473, Test accuracy: 47.54 

Round  15, Global train loss: 1.279, Global test loss: 1.221, Global test accuracy: 56.81 

Round  16, Train loss: 1.266, Test loss: 1.447, Test accuracy: 48.39 

Round  16, Global train loss: 1.266, Global test loss: 1.216, Global test accuracy: 57.03 

Round  17, Train loss: 1.207, Test loss: 1.445, Test accuracy: 48.62 

Round  17, Global train loss: 1.207, Global test loss: 1.199, Global test accuracy: 57.27 

Round  18, Train loss: 1.182, Test loss: 1.414, Test accuracy: 49.70 

Round  18, Global train loss: 1.182, Global test loss: 1.180, Global test accuracy: 58.33 

Round  19, Train loss: 1.145, Test loss: 1.415, Test accuracy: 50.07 

Round  19, Global train loss: 1.145, Global test loss: 1.195, Global test accuracy: 57.97 

Round  20, Train loss: 1.156, Test loss: 1.393, Test accuracy: 50.92 

Round  20, Global train loss: 1.156, Global test loss: 1.146, Global test accuracy: 59.48 

Round  21, Train loss: 1.120, Test loss: 1.387, Test accuracy: 51.38 

Round  21, Global train loss: 1.120, Global test loss: 1.147, Global test accuracy: 60.04 

Round  22, Train loss: 1.087, Test loss: 1.383, Test accuracy: 52.07 

Round  22, Global train loss: 1.087, Global test loss: 1.146, Global test accuracy: 59.74 

Round  23, Train loss: 1.046, Test loss: 1.381, Test accuracy: 52.23 

Round  23, Global train loss: 1.046, Global test loss: 1.142, Global test accuracy: 59.77 

Round  24, Train loss: 1.081, Test loss: 1.364, Test accuracy: 53.02 

Round  24, Global train loss: 1.081, Global test loss: 1.116, Global test accuracy: 60.47 

Round  25, Train loss: 1.036, Test loss: 1.383, Test accuracy: 52.83 

Round  25, Global train loss: 1.036, Global test loss: 1.139, Global test accuracy: 60.02 

Round  26, Train loss: 1.005, Test loss: 1.380, Test accuracy: 52.94 

Round  26, Global train loss: 1.005, Global test loss: 1.104, Global test accuracy: 60.85 

Round  27, Train loss: 1.001, Test loss: 1.376, Test accuracy: 53.40 

Round  27, Global train loss: 1.001, Global test loss: 1.097, Global test accuracy: 61.53 

Round  28, Train loss: 0.977, Test loss: 1.361, Test accuracy: 53.88 

Round  28, Global train loss: 0.977, Global test loss: 1.095, Global test accuracy: 61.52 

Round  29, Train loss: 0.947, Test loss: 1.362, Test accuracy: 54.40 

Round  29, Global train loss: 0.947, Global test loss: 1.097, Global test accuracy: 61.13 

Round  30, Train loss: 0.914, Test loss: 1.368, Test accuracy: 54.53 

Round  30, Global train loss: 0.914, Global test loss: 1.100, Global test accuracy: 61.85 

Round  31, Train loss: 0.962, Test loss: 1.350, Test accuracy: 55.13 

Round  31, Global train loss: 0.962, Global test loss: 1.078, Global test accuracy: 62.02 

Round  32, Train loss: 0.936, Test loss: 1.343, Test accuracy: 55.59 

Round  32, Global train loss: 0.936, Global test loss: 1.063, Global test accuracy: 62.90 

Round  33, Train loss: 0.879, Test loss: 1.354, Test accuracy: 55.38 

Round  33, Global train loss: 0.879, Global test loss: 1.080, Global test accuracy: 62.76 

Round  34, Train loss: 0.892, Test loss: 1.357, Test accuracy: 55.67 

Round  34, Global train loss: 0.892, Global test loss: 1.058, Global test accuracy: 63.52 

Round  35, Train loss: 0.873, Test loss: 1.358, Test accuracy: 55.72 

Round  35, Global train loss: 0.873, Global test loss: 1.056, Global test accuracy: 63.81 

Round  36, Train loss: 0.849, Test loss: 1.366, Test accuracy: 55.84 

Round  36, Global train loss: 0.849, Global test loss: 1.072, Global test accuracy: 63.44 

Round  37, Train loss: 0.812, Test loss: 1.362, Test accuracy: 56.25 

Round  37, Global train loss: 0.812, Global test loss: 1.087, Global test accuracy: 63.59 

Round  38, Train loss: 0.847, Test loss: 1.374, Test accuracy: 56.20 

Round  38, Global train loss: 0.847, Global test loss: 1.059, Global test accuracy: 63.74 

Round  39, Train loss: 0.831, Test loss: 1.387, Test accuracy: 56.19 

Round  39, Global train loss: 0.831, Global test loss: 1.064, Global test accuracy: 64.10 

Round  40, Train loss: 0.812, Test loss: 1.393, Test accuracy: 56.33 

Round  40, Global train loss: 0.812, Global test loss: 1.061, Global test accuracy: 63.95 

Round  41, Train loss: 0.836, Test loss: 1.382, Test accuracy: 56.78 

Round  41, Global train loss: 0.836, Global test loss: 1.045, Global test accuracy: 64.56 

Round  42, Train loss: 0.800, Test loss: 1.393, Test accuracy: 56.44 

Round  42, Global train loss: 0.800, Global test loss: 1.050, Global test accuracy: 64.39 

Round  43, Train loss: 0.758, Test loss: 1.401, Test accuracy: 56.88 

Round  43, Global train loss: 0.758, Global test loss: 1.084, Global test accuracy: 64.50 

Round  44, Train loss: 0.741, Test loss: 1.398, Test accuracy: 56.99 

Round  44, Global train loss: 0.741, Global test loss: 1.044, Global test accuracy: 65.42 

Round  45, Train loss: 0.790, Test loss: 1.397, Test accuracy: 57.51 

Round  45, Global train loss: 0.790, Global test loss: 1.037, Global test accuracy: 65.11 

Round  46, Train loss: 0.731, Test loss: 1.396, Test accuracy: 57.54 

Round  46, Global train loss: 0.731, Global test loss: 1.033, Global test accuracy: 65.50 

Round  47, Train loss: 0.686, Test loss: 1.413, Test accuracy: 57.16 

Round  47, Global train loss: 0.686, Global test loss: 1.063, Global test accuracy: 65.30 

Round  48, Train loss: 0.736, Test loss: 1.410, Test accuracy: 57.62 

Round  48, Global train loss: 0.736, Global test loss: 1.066, Global test accuracy: 65.27 

Round  49, Train loss: 0.710, Test loss: 1.405, Test accuracy: 58.12 

Round  49, Global train loss: 0.710, Global test loss: 1.067, Global test accuracy: 65.52 

Round  50, Train loss: 0.642, Test loss: 1.399, Test accuracy: 58.49 

Round  50, Global train loss: 0.642, Global test loss: 1.063, Global test accuracy: 66.28 

Round  51, Train loss: 0.627, Test loss: 1.408, Test accuracy: 58.30 

Round  51, Global train loss: 0.627, Global test loss: 1.092, Global test accuracy: 65.06 

Round  52, Train loss: 0.700, Test loss: 1.410, Test accuracy: 58.78 

Round  52, Global train loss: 0.700, Global test loss: 1.065, Global test accuracy: 66.05 

Round  53, Train loss: 0.659, Test loss: 1.412, Test accuracy: 58.65 

Round  53, Global train loss: 0.659, Global test loss: 1.076, Global test accuracy: 65.31 

Round  54, Train loss: 0.678, Test loss: 1.421, Test accuracy: 58.67 

Round  54, Global train loss: 0.678, Global test loss: 1.056, Global test accuracy: 65.94 

Round  55, Train loss: 0.693, Test loss: 1.415, Test accuracy: 58.77 

Round  55, Global train loss: 0.693, Global test loss: 1.037, Global test accuracy: 65.72 

Round  56, Train loss: 0.675, Test loss: 1.414, Test accuracy: 58.76 

Round  56, Global train loss: 0.675, Global test loss: 1.041, Global test accuracy: 65.59 

Round  57, Train loss: 0.612, Test loss: 1.417, Test accuracy: 58.70 

Round  57, Global train loss: 0.612, Global test loss: 1.082, Global test accuracy: 66.11 

Round  58, Train loss: 0.616, Test loss: 1.408, Test accuracy: 59.06 

Round  58, Global train loss: 0.616, Global test loss: 1.067, Global test accuracy: 66.69 

Round  59, Train loss: 0.679, Test loss: 1.423, Test accuracy: 59.09 

Round  59, Global train loss: 0.679, Global test loss: 1.039, Global test accuracy: 66.74 

Round  60, Train loss: 0.681, Test loss: 1.416, Test accuracy: 59.20 

Round  60, Global train loss: 0.681, Global test loss: 1.043, Global test accuracy: 66.64 

Round  61, Train loss: 0.632, Test loss: 1.422, Test accuracy: 59.36 

Round  61, Global train loss: 0.632, Global test loss: 1.065, Global test accuracy: 66.23 

Round  62, Train loss: 0.590, Test loss: 1.431, Test accuracy: 59.28 

Round  62, Global train loss: 0.590, Global test loss: 1.094, Global test accuracy: 66.22 

Round  63, Train loss: 0.618, Test loss: 1.405, Test accuracy: 59.89 

Round  63, Global train loss: 0.618, Global test loss: 1.064, Global test accuracy: 66.28 

Round  64, Train loss: 0.593, Test loss: 1.414, Test accuracy: 59.99 

Round  64, Global train loss: 0.593, Global test loss: 1.071, Global test accuracy: 65.74 

Round  65, Train loss: 0.583, Test loss: 1.405, Test accuracy: 60.14 

Round  65, Global train loss: 0.583, Global test loss: 1.073, Global test accuracy: 66.20 

Round  66, Train loss: 0.644, Test loss: 1.421, Test accuracy: 60.24 

Round  66, Global train loss: 0.644, Global test loss: 1.051, Global test accuracy: 66.27 

Round  67, Train loss: 0.579, Test loss: 1.405, Test accuracy: 60.62 

Round  67, Global train loss: 0.579, Global test loss: 1.055, Global test accuracy: 67.17 

Round  68, Train loss: 0.555, Test loss: 1.428, Test accuracy: 60.58 

Round  68, Global train loss: 0.555, Global test loss: 1.096, Global test accuracy: 66.78 

Round  69, Train loss: 0.563, Test loss: 1.418, Test accuracy: 60.36 

Round  69, Global train loss: 0.563, Global test loss: 1.058, Global test accuracy: 67.09 

Round  70, Train loss: 0.531, Test loss: 1.420, Test accuracy: 60.44 

Round  70, Global train loss: 0.531, Global test loss: 1.074, Global test accuracy: 67.19 

Round  71, Train loss: 0.532, Test loss: 1.442, Test accuracy: 60.57 

Round  71, Global train loss: 0.532, Global test loss: 1.088, Global test accuracy: 66.79 

Round  72, Train loss: 0.601, Test loss: 1.439, Test accuracy: 60.60 

Round  72, Global train loss: 0.601, Global test loss: 1.054, Global test accuracy: 66.69 

Round  73, Train loss: 0.512, Test loss: 1.448, Test accuracy: 60.67 

Round  73, Global train loss: 0.512, Global test loss: 1.085, Global test accuracy: 67.12 

Round  74, Train loss: 0.535, Test loss: 1.463, Test accuracy: 60.36 

Round  74, Global train loss: 0.535, Global test loss: 1.056, Global test accuracy: 67.31 

Round  75, Train loss: 0.596, Test loss: 1.469, Test accuracy: 60.62 

Round  75, Global train loss: 0.596, Global test loss: 1.051, Global test accuracy: 67.27 

Round  76, Train loss: 0.507, Test loss: 1.462, Test accuracy: 60.77 

Round  76, Global train loss: 0.507, Global test loss: 1.086, Global test accuracy: 67.14 

Round  77, Train loss: 0.479, Test loss: 1.459, Test accuracy: 60.93 

Round  77, Global train loss: 0.479, Global test loss: 1.101, Global test accuracy: 66.94 

Round  78, Train loss: 0.531, Test loss: 1.443, Test accuracy: 61.09 

Round  78, Global train loss: 0.531, Global test loss: 1.107, Global test accuracy: 66.96 

Round  79, Train loss: 0.541, Test loss: 1.427, Test accuracy: 61.45 

Round  79, Global train loss: 0.541, Global test loss: 1.078, Global test accuracy: 66.92 

Round  80, Train loss: 0.561, Test loss: 1.438, Test accuracy: 61.55 

Round  80, Global train loss: 0.561, Global test loss: 1.100, Global test accuracy: 66.44 

Round  81, Train loss: 0.447, Test loss: 1.446, Test accuracy: 61.47 

Round  81, Global train loss: 0.447, Global test loss: 1.136, Global test accuracy: 67.13 

Round  82, Train loss: 0.470, Test loss: 1.456, Test accuracy: 61.52 

Round  82, Global train loss: 0.470, Global test loss: 1.123, Global test accuracy: 67.04 

Round  83, Train loss: 0.501, Test loss: 1.472, Test accuracy: 61.27 

Round  83, Global train loss: 0.501, Global test loss: 1.098, Global test accuracy: 67.66 

Round  84, Train loss: 0.464, Test loss: 1.492, Test accuracy: 61.06 

Round  84, Global train loss: 0.464, Global test loss: 1.120, Global test accuracy: 67.46 

Round  85, Train loss: 0.517, Test loss: 1.495, Test accuracy: 61.34 

Round  85, Global train loss: 0.517, Global test loss: 1.110, Global test accuracy: 67.20 

Round  86, Train loss: 0.502, Test loss: 1.500, Test accuracy: 61.35 

Round  86, Global train loss: 0.502, Global test loss: 1.105, Global test accuracy: 67.73 

Round  87, Train loss: 0.498, Test loss: 1.488, Test accuracy: 61.57 

Round  87, Global train loss: 0.498, Global test loss: 1.089, Global test accuracy: 67.65 

Round  88, Train loss: 0.474, Test loss: 1.484, Test accuracy: 61.63 

Round  88, Global train loss: 0.474, Global test loss: 1.098, Global test accuracy: 67.51 

Round  89, Train loss: 0.480, Test loss: 1.482, Test accuracy: 61.77 

Round  89, Global train loss: 0.480, Global test loss: 1.107, Global test accuracy: 67.23 

Round  90, Train loss: 0.473, Test loss: 1.489, Test accuracy: 61.63 

Round  90, Global train loss: 0.473, Global test loss: 1.132, Global test accuracy: 67.25 

Round  91, Train loss: 0.499, Test loss: 1.479, Test accuracy: 61.72 

Round  91, Global train loss: 0.499, Global test loss: 1.102, Global test accuracy: 67.18 

Round  92, Train loss: 0.474, Test loss: 1.473, Test accuracy: 61.91 

Round  92, Global train loss: 0.474, Global test loss: 1.077, Global test accuracy: 68.14 

Round  93, Train loss: 0.472, Test loss: 1.469, Test accuracy: 62.13 

Round  93, Global train loss: 0.472, Global test loss: 1.116, Global test accuracy: 67.97 

Round  94, Train loss: 0.439, Test loss: 1.466, Test accuracy: 62.23 

Round  94, Global train loss: 0.439, Global test loss: 1.122, Global test accuracy: 68.00 

Round  95, Train loss: 0.453, Test loss: 1.451, Test accuracy: 62.44 

Round  95, Global train loss: 0.453, Global test loss: 1.101, Global test accuracy: 67.53 

Round  96, Train loss: 0.428, Test loss: 1.479, Test accuracy: 62.10 

Round  96, Global train loss: 0.428, Global test loss: 1.130, Global test accuracy: 67.28 

Round  97, Train loss: 0.489, Test loss: 1.496, Test accuracy: 61.80 

Round  97, Global train loss: 0.489, Global test loss: 1.096, Global test accuracy: 67.83 

Round  98, Train loss: 0.440, Test loss: 1.514, Test accuracy: 61.84 

Round  98, Global train loss: 0.440, Global test loss: 1.136, Global test accuracy: 67.69 

Round  99, Train loss: 0.412, Test loss: 1.515, Test accuracy: 62.06 

Round  99, Global train loss: 0.412, Global test loss: 1.130, Global test accuracy: 67.75 

Final Round, Train loss: 0.357, Test loss: 1.699, Test accuracy: 61.42 

Final Round, Global train loss: 0.357, Global test loss: 1.130, Global test accuracy: 67.75 

Average accuracy final 10 rounds: 61.987999999999985 

Average global accuracy final 10 rounds: 67.66250000000001 

1666.8765189647675
[1.4057204723358154, 2.576388359069824, 3.746497392654419, 4.923750638961792, 6.094012022018433, 7.2472991943359375, 8.251859903335571, 9.256609439849854, 10.266149520874023, 11.280958414077759, 12.291461706161499, 13.300305128097534, 14.316766500473022, 15.329249858856201, 16.3352313041687, 17.344037532806396, 18.353434562683105, 19.361270666122437, 20.37628936767578, 21.388036489486694, 22.398042917251587, 23.415350914001465, 24.427356719970703, 25.447031259536743, 26.456247806549072, 27.46368145942688, 28.471533060073853, 29.4819495677948, 30.49040937423706, 31.50115942955017, 32.508464097976685, 33.51286220550537, 34.515650033950806, 35.52650022506714, 36.53094458580017, 37.54060387611389, 38.54411172866821, 39.54850459098816, 40.564730167388916, 41.564557790756226, 42.58098912239075, 43.58735918998718, 44.59097361564636, 45.59943079948425, 46.60723948478699, 47.6133553981781, 48.620927572250366, 49.63375377655029, 50.6471164226532, 51.65885543823242, 52.66581320762634, 53.67413902282715, 54.694868326187134, 55.705827951431274, 56.71767258644104, 57.73475766181946, 58.74394917488098, 59.76013970375061, 60.77934169769287, 61.79377484321594, 62.80630803108215, 63.810641050338745, 64.82377362251282, 65.83466148376465, 66.84501576423645, 67.85005736351013, 68.85651755332947, 70.01486706733704, 71.192941904068, 72.3684196472168, 73.5457775592804, 74.7218828201294, 75.89516472816467, 77.06824064254761, 78.24275827407837, 79.4158046245575, 80.58600616455078, 81.75580358505249, 82.92936515808105, 84.10125470161438, 85.27479934692383, 86.45119905471802, 87.63296413421631, 88.81036853790283, 89.98561596870422, 91.16084289550781, 92.33360862731934, 93.51341438293457, 94.68718147277832, 95.86126661300659, 97.03181743621826, 98.20411801338196, 99.3678686618805, 100.53096175193787, 101.68570446968079, 102.82856154441833, 103.97825264930725, 105.1361231803894, 106.29771304130554, 107.4616334438324, 109.78929901123047]
[22.225, 28.155, 31.6, 34.155, 37.34, 38.46, 40.475, 41.115, 42.485, 42.92, 43.975, 44.975, 45.405, 46.985, 46.98, 47.54, 48.39, 48.615, 49.7, 50.07, 50.92, 51.385, 52.07, 52.225, 53.015, 52.83, 52.935, 53.4, 53.875, 54.395, 54.53, 55.135, 55.585, 55.38, 55.67, 55.72, 55.84, 56.25, 56.195, 56.185, 56.325, 56.785, 56.44, 56.88, 56.99, 57.505, 57.54, 57.155, 57.625, 58.125, 58.49, 58.305, 58.78, 58.645, 58.675, 58.775, 58.76, 58.705, 59.065, 59.085, 59.195, 59.36, 59.285, 59.89, 59.995, 60.14, 60.245, 60.625, 60.575, 60.36, 60.44, 60.57, 60.6, 60.67, 60.36, 60.615, 60.775, 60.93, 61.095, 61.45, 61.55, 61.465, 61.525, 61.275, 61.065, 61.345, 61.35, 61.57, 61.635, 61.765, 61.635, 61.72, 61.91, 62.135, 62.235, 62.435, 62.105, 61.8, 61.84, 62.065, 61.425]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.231, Test accuracy: 20.91 

Round   1, Train loss: 2.163, Test loss: 2.061, Test accuracy: 24.00 

Round   2, Train loss: 2.020, Test loss: 1.959, Test accuracy: 28.79 

Round   3, Train loss: 1.960, Test loss: 1.864, Test accuracy: 31.03 

Round   4, Train loss: 1.858, Test loss: 1.797, Test accuracy: 33.67 

Round   5, Train loss: 1.815, Test loss: 1.728, Test accuracy: 35.79 

Round   6, Train loss: 1.754, Test loss: 1.674, Test accuracy: 38.35 

Round   7, Train loss: 1.697, Test loss: 1.654, Test accuracy: 39.56 

Round   8, Train loss: 1.681, Test loss: 1.608, Test accuracy: 41.89 

Round   9, Train loss: 1.652, Test loss: 1.576, Test accuracy: 42.42 

Round  10, Train loss: 1.616, Test loss: 1.552, Test accuracy: 43.55 

Round  11, Train loss: 1.589, Test loss: 1.537, Test accuracy: 43.74 

Round  12, Train loss: 1.558, Test loss: 1.527, Test accuracy: 43.84 

Round  13, Train loss: 1.547, Test loss: 1.489, Test accuracy: 45.49 

Round  14, Train loss: 1.525, Test loss: 1.480, Test accuracy: 46.33 

Round  15, Train loss: 1.494, Test loss: 1.491, Test accuracy: 45.95 

Round  16, Train loss: 1.463, Test loss: 1.459, Test accuracy: 46.83 

Round  17, Train loss: 1.454, Test loss: 1.434, Test accuracy: 47.51 

Round  18, Train loss: 1.449, Test loss: 1.430, Test accuracy: 47.95 

Round  19, Train loss: 1.402, Test loss: 1.425, Test accuracy: 47.99 

Round  20, Train loss: 1.389, Test loss: 1.408, Test accuracy: 48.78 

Round  21, Train loss: 1.366, Test loss: 1.404, Test accuracy: 48.98 

Round  22, Train loss: 1.376, Test loss: 1.396, Test accuracy: 49.42 

Round  23, Train loss: 1.326, Test loss: 1.383, Test accuracy: 49.91 

Round  24, Train loss: 1.335, Test loss: 1.379, Test accuracy: 50.12 

Round  25, Train loss: 1.300, Test loss: 1.371, Test accuracy: 50.95 

Round  26, Train loss: 1.309, Test loss: 1.357, Test accuracy: 51.81 

Round  27, Train loss: 1.265, Test loss: 1.328, Test accuracy: 52.21 

Round  28, Train loss: 1.248, Test loss: 1.314, Test accuracy: 53.09 

Round  29, Train loss: 1.212, Test loss: 1.309, Test accuracy: 53.06 

Round  30, Train loss: 1.241, Test loss: 1.293, Test accuracy: 53.76 

Round  31, Train loss: 1.193, Test loss: 1.294, Test accuracy: 53.73 

Round  32, Train loss: 1.204, Test loss: 1.310, Test accuracy: 52.86 

Round  33, Train loss: 1.163, Test loss: 1.285, Test accuracy: 54.26 

Round  34, Train loss: 1.170, Test loss: 1.272, Test accuracy: 55.17 

Round  35, Train loss: 1.171, Test loss: 1.230, Test accuracy: 56.19 

Round  36, Train loss: 1.120, Test loss: 1.212, Test accuracy: 57.06 

Round  37, Train loss: 1.090, Test loss: 1.216, Test accuracy: 56.94 

Round  38, Train loss: 1.105, Test loss: 1.212, Test accuracy: 56.88 

Round  39, Train loss: 1.095, Test loss: 1.198, Test accuracy: 57.80 

Round  40, Train loss: 1.121, Test loss: 1.193, Test accuracy: 58.04 

Round  41, Train loss: 1.031, Test loss: 1.197, Test accuracy: 57.64 

Round  42, Train loss: 1.057, Test loss: 1.197, Test accuracy: 58.20 

Round  43, Train loss: 1.065, Test loss: 1.203, Test accuracy: 57.37 

Round  44, Train loss: 1.043, Test loss: 1.205, Test accuracy: 57.71 

Round  45, Train loss: 1.023, Test loss: 1.170, Test accuracy: 58.92 

Round  46, Train loss: 0.987, Test loss: 1.151, Test accuracy: 59.58 

Round  47, Train loss: 0.964, Test loss: 1.162, Test accuracy: 59.27 

Round  48, Train loss: 0.978, Test loss: 1.160, Test accuracy: 59.51 

Round  49, Train loss: 1.016, Test loss: 1.179, Test accuracy: 58.90 

Round  50, Train loss: 0.978, Test loss: 1.160, Test accuracy: 59.41 

Round  51, Train loss: 0.954, Test loss: 1.145, Test accuracy: 60.02 

Round  52, Train loss: 0.990, Test loss: 1.151, Test accuracy: 60.07 

Round  53, Train loss: 0.956, Test loss: 1.154, Test accuracy: 59.97 

Round  54, Train loss: 0.898, Test loss: 1.137, Test accuracy: 60.80 

Round  55, Train loss: 0.936, Test loss: 1.138, Test accuracy: 60.62 

Round  56, Train loss: 0.935, Test loss: 1.150, Test accuracy: 60.56 

Round  57, Train loss: 0.898, Test loss: 1.154, Test accuracy: 60.91 

Round  58, Train loss: 0.885, Test loss: 1.149, Test accuracy: 60.88 

Round  59, Train loss: 0.880, Test loss: 1.164, Test accuracy: 60.41 

Round  60, Train loss: 0.868, Test loss: 1.164, Test accuracy: 60.90 

Round  61, Train loss: 0.855, Test loss: 1.150, Test accuracy: 61.34 

Round  62, Train loss: 0.837, Test loss: 1.157, Test accuracy: 60.91 

Round  63, Train loss: 0.859, Test loss: 1.154, Test accuracy: 61.06 

Round  64, Train loss: 0.804, Test loss: 1.162, Test accuracy: 61.56 

Round  65, Train loss: 0.864, Test loss: 1.140, Test accuracy: 61.91 

Round  66, Train loss: 0.829, Test loss: 1.144, Test accuracy: 61.79 

Round  67, Train loss: 0.771, Test loss: 1.175, Test accuracy: 61.63 

Round  68, Train loss: 0.790, Test loss: 1.162, Test accuracy: 61.22 

Round  69, Train loss: 0.825, Test loss: 1.159, Test accuracy: 61.41 

Round  70, Train loss: 0.804, Test loss: 1.147, Test accuracy: 62.52 

Round  71, Train loss: 0.778, Test loss: 1.159, Test accuracy: 62.19 

Round  72, Train loss: 0.791, Test loss: 1.177, Test accuracy: 61.73 

Round  73, Train loss: 0.758, Test loss: 1.155, Test accuracy: 62.33 

Round  74, Train loss: 0.772, Test loss: 1.156, Test accuracy: 62.48 

Round  75, Train loss: 0.743, Test loss: 1.167, Test accuracy: 62.38 

Round  76, Train loss: 0.764, Test loss: 1.165, Test accuracy: 62.26 

Round  77, Train loss: 0.701, Test loss: 1.188, Test accuracy: 62.47 

Round  78, Train loss: 0.755, Test loss: 1.165, Test accuracy: 62.98 

Round  79, Train loss: 0.720, Test loss: 1.176, Test accuracy: 62.63 

Round  80, Train loss: 0.722, Test loss: 1.153, Test accuracy: 63.18 

Round  81, Train loss: 0.683, Test loss: 1.153, Test accuracy: 63.52 

Round  82, Train loss: 0.698, Test loss: 1.151, Test accuracy: 63.31 

Round  83, Train loss: 0.667, Test loss: 1.169, Test accuracy: 63.02 

Round  84, Train loss: 0.710, Test loss: 1.180, Test accuracy: 63.30 

Round  85, Train loss: 0.708, Test loss: 1.172, Test accuracy: 63.53 

Round  86, Train loss: 0.685, Test loss: 1.163, Test accuracy: 63.73 

Round  87, Train loss: 0.681, Test loss: 1.178, Test accuracy: 63.28 

Round  88, Train loss: 0.681, Test loss: 1.162, Test accuracy: 63.77 

Round  89, Train loss: 0.643, Test loss: 1.196, Test accuracy: 63.36 

Round  90, Train loss: 0.661, Test loss: 1.191, Test accuracy: 63.17 

Round  91, Train loss: 0.658, Test loss: 1.192, Test accuracy: 63.26 

Round  92, Train loss: 0.604, Test loss: 1.205, Test accuracy: 63.52 

Round  93, Train loss: 0.613, Test loss: 1.199, Test accuracy: 63.18 

Round  94, Train loss: 0.661, Test loss: 1.209, Test accuracy: 63.55 

Round  95, Train loss: 0.613, Test loss: 1.185, Test accuracy: 63.74 

Round  96, Train loss: 0.623, Test loss: 1.236, Test accuracy: 63.10 

Round  97, Train loss: 0.604, Test loss: 1.240, Test accuracy: 63.72 

Round  98, Train loss: 0.618, Test loss: 1.217, Test accuracy: 63.66 

Round  99, Train loss: 0.610, Test loss: 1.235, Test accuracy: 63.51 

Final Round, Train loss: 0.528, Test loss: 1.251, Test accuracy: 63.56 

Average accuracy final 10 rounds: 63.441500000000005 

1116.2676136493683
[1.2919604778289795, 2.3441436290740967, 3.3893401622772217, 4.441296577453613, 5.49261999130249, 6.542142629623413, 7.601166009902954, 8.654693603515625, 9.71192479133606, 10.764424324035645, 11.81873106956482, 12.868006229400635, 13.918468713760376, 14.969772815704346, 16.01321005821228, 17.063915967941284, 18.112386465072632, 19.16358494758606, 20.21312975883484, 21.259902954101562, 22.308213710784912, 23.35343074798584, 24.412716388702393, 25.467550039291382, 26.51521873474121, 27.564622402191162, 28.61437201499939, 29.661816120147705, 30.722732305526733, 31.778239011764526, 32.82533144950867, 33.876875162124634, 34.92578649520874, 35.97241711616516, 37.02439284324646, 37.96757650375366, 38.91149616241455, 39.85587501525879, 40.80016493797302, 41.742865562438965, 42.68708634376526, 43.6335084438324, 44.57602906227112, 45.520148038864136, 46.46321129798889, 47.40567088127136, 48.34992957115173, 49.29589056968689, 50.241950273513794, 51.18793034553528, 52.13507103919983, 53.08965039253235, 54.043331146240234, 54.99338459968567, 55.947643756866455, 56.89920520782471, 57.85344624519348, 58.8071174621582, 59.75557041168213, 60.70741033554077, 61.66007971763611, 62.61103439331055, 63.56629180908203, 64.51670908927917, 65.46921467781067, 66.41903853416443, 67.36824417114258, 68.3204607963562, 69.27307677268982, 70.22561502456665, 71.18019247055054, 72.13016605377197, 73.08181643486023, 74.0359034538269, 74.98479056358337, 75.928213596344, 76.87728786468506, 77.82605862617493, 78.7808005809784, 79.73148727416992, 80.68087100982666, 81.63412356376648, 82.58521318435669, 83.53380751609802, 84.48561882972717, 85.43929123878479, 86.39132642745972, 87.3430118560791, 88.29487156867981, 89.24460291862488, 90.19709730148315, 91.14887404441833, 92.10375332832336, 93.12979555130005, 94.14990282058716, 95.16326427459717, 96.18080615997314, 97.23082113265991, 98.24965715408325, 99.3004879951477, 101.18980145454407]
[20.915, 24.005, 28.785, 31.03, 33.67, 35.79, 38.35, 39.56, 41.89, 42.425, 43.555, 43.74, 43.845, 45.495, 46.325, 45.945, 46.83, 47.505, 47.95, 47.99, 48.785, 48.975, 49.425, 49.905, 50.125, 50.955, 51.81, 52.21, 53.085, 53.06, 53.76, 53.725, 52.86, 54.255, 55.175, 56.19, 57.065, 56.935, 56.88, 57.805, 58.04, 57.64, 58.2, 57.37, 57.71, 58.925, 59.58, 59.275, 59.51, 58.895, 59.41, 60.025, 60.07, 59.965, 60.805, 60.62, 60.565, 60.905, 60.88, 60.405, 60.9, 61.34, 60.915, 61.06, 61.565, 61.905, 61.79, 61.63, 61.22, 61.41, 62.52, 62.185, 61.73, 62.33, 62.485, 62.385, 62.255, 62.47, 62.985, 62.63, 63.18, 63.525, 63.31, 63.02, 63.305, 63.53, 63.725, 63.28, 63.765, 63.36, 63.175, 63.255, 63.525, 63.18, 63.555, 63.74, 63.1, 63.715, 63.665, 63.505, 63.565]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.210, Test loss: 2.068, Test accuracy: 26.53 

Round   1, Train loss: 2.008, Test loss: 1.894, Test accuracy: 30.75 

Round   2, Train loss: 1.901, Test loss: 1.778, Test accuracy: 35.37 

Round   3, Train loss: 1.773, Test loss: 1.686, Test accuracy: 37.88 

Round   4, Train loss: 1.724, Test loss: 1.610, Test accuracy: 40.41 

Round   5, Train loss: 1.648, Test loss: 1.559, Test accuracy: 42.23 

Round   6, Train loss: 1.608, Test loss: 1.522, Test accuracy: 43.12 

Round   7, Train loss: 1.576, Test loss: 1.475, Test accuracy: 46.24 

Round   8, Train loss: 1.511, Test loss: 1.449, Test accuracy: 47.36 

Round   9, Train loss: 1.475, Test loss: 1.431, Test accuracy: 47.94 

Round  10, Train loss: 1.474, Test loss: 1.404, Test accuracy: 48.96 

Round  11, Train loss: 1.399, Test loss: 1.377, Test accuracy: 50.27 

Round  12, Train loss: 1.354, Test loss: 1.349, Test accuracy: 51.35 

Round  13, Train loss: 1.325, Test loss: 1.326, Test accuracy: 52.77 

Round  14, Train loss: 1.295, Test loss: 1.321, Test accuracy: 52.44 

Round  15, Train loss: 1.263, Test loss: 1.309, Test accuracy: 53.28 

Round  16, Train loss: 1.297, Test loss: 1.285, Test accuracy: 54.30 

Round  17, Train loss: 1.196, Test loss: 1.267, Test accuracy: 55.13 

Round  18, Train loss: 1.229, Test loss: 1.248, Test accuracy: 56.27 

Round  19, Train loss: 1.163, Test loss: 1.242, Test accuracy: 56.41 

Round  20, Train loss: 1.160, Test loss: 1.258, Test accuracy: 56.02 

Round  21, Train loss: 1.117, Test loss: 1.215, Test accuracy: 57.27 

Round  22, Train loss: 1.056, Test loss: 1.229, Test accuracy: 56.84 

Round  23, Train loss: 1.093, Test loss: 1.209, Test accuracy: 57.51 

Round  24, Train loss: 1.039, Test loss: 1.193, Test accuracy: 58.16 

Round  25, Train loss: 1.049, Test loss: 1.196, Test accuracy: 58.62 

Round  26, Train loss: 1.011, Test loss: 1.196, Test accuracy: 58.90 

Round  27, Train loss: 0.976, Test loss: 1.180, Test accuracy: 59.46 

Round  28, Train loss: 0.959, Test loss: 1.167, Test accuracy: 59.73 

Round  29, Train loss: 0.948, Test loss: 1.193, Test accuracy: 59.25 

Round  30, Train loss: 0.923, Test loss: 1.182, Test accuracy: 59.70 

Round  31, Train loss: 0.954, Test loss: 1.163, Test accuracy: 60.04 

Round  32, Train loss: 0.905, Test loss: 1.195, Test accuracy: 59.80 

Round  33, Train loss: 0.891, Test loss: 1.199, Test accuracy: 59.96 

Round  34, Train loss: 0.890, Test loss: 1.191, Test accuracy: 60.13 

Round  35, Train loss: 0.839, Test loss: 1.194, Test accuracy: 60.52 

Round  36, Train loss: 0.866, Test loss: 1.179, Test accuracy: 60.38 

Round  37, Train loss: 0.838, Test loss: 1.192, Test accuracy: 60.70 

Round  38, Train loss: 0.860, Test loss: 1.195, Test accuracy: 61.14 

Round  39, Train loss: 0.797, Test loss: 1.201, Test accuracy: 60.97 

Round  40, Train loss: 0.801, Test loss: 1.210, Test accuracy: 60.84 

Round  41, Train loss: 0.763, Test loss: 1.194, Test accuracy: 60.97 

Round  42, Train loss: 0.766, Test loss: 1.200, Test accuracy: 61.04 

Round  43, Train loss: 0.758, Test loss: 1.209, Test accuracy: 61.16 

Round  44, Train loss: 0.742, Test loss: 1.210, Test accuracy: 61.66 

Round  45, Train loss: 0.742, Test loss: 1.233, Test accuracy: 60.84 

Round  46, Train loss: 0.723, Test loss: 1.225, Test accuracy: 61.48 

Round  47, Train loss: 0.696, Test loss: 1.239, Test accuracy: 61.56 

Round  48, Train loss: 0.697, Test loss: 1.273, Test accuracy: 60.77 

Round  49, Train loss: 0.652, Test loss: 1.264, Test accuracy: 61.10 

Round  50, Train loss: 0.615, Test loss: 1.289, Test accuracy: 61.48 

Round  51, Train loss: 0.682, Test loss: 1.249, Test accuracy: 61.58 

Round  52, Train loss: 0.694, Test loss: 1.235, Test accuracy: 62.02 

Round  53, Train loss: 0.618, Test loss: 1.295, Test accuracy: 61.60 

Round  54, Train loss: 0.656, Test loss: 1.266, Test accuracy: 62.15 

Round  55, Train loss: 0.618, Test loss: 1.291, Test accuracy: 61.53 

Round  56, Train loss: 0.588, Test loss: 1.299, Test accuracy: 61.06 

Round  57, Train loss: 0.613, Test loss: 1.313, Test accuracy: 61.35 

Round  58, Train loss: 0.584, Test loss: 1.339, Test accuracy: 61.42 

Round  59, Train loss: 0.636, Test loss: 1.306, Test accuracy: 61.98 

Round  60, Train loss: 0.552, Test loss: 1.325, Test accuracy: 61.38 

Round  61, Train loss: 0.569, Test loss: 1.345, Test accuracy: 61.34 

Round  62, Train loss: 0.573, Test loss: 1.347, Test accuracy: 61.66 

Round  63, Train loss: 0.569, Test loss: 1.326, Test accuracy: 61.23 

Round  64, Train loss: 0.540, Test loss: 1.365, Test accuracy: 61.47 

Round  65, Train loss: 0.504, Test loss: 1.408, Test accuracy: 60.83 

Round  66, Train loss: 0.529, Test loss: 1.392, Test accuracy: 61.38 

Round  67, Train loss: 0.526, Test loss: 1.420, Test accuracy: 61.33 

Round  68, Train loss: 0.542, Test loss: 1.389, Test accuracy: 61.54 

Round  69, Train loss: 0.513, Test loss: 1.416, Test accuracy: 61.58 

Round  70, Train loss: 0.560, Test loss: 1.335, Test accuracy: 61.86 

Round  71, Train loss: 0.572, Test loss: 1.372, Test accuracy: 61.78 

Round  72, Train loss: 0.458, Test loss: 1.426, Test accuracy: 61.46 

Round  73, Train loss: 0.526, Test loss: 1.455, Test accuracy: 61.75 

Round  74, Train loss: 0.490, Test loss: 1.454, Test accuracy: 61.39 

Round  75, Train loss: 0.458, Test loss: 1.454, Test accuracy: 62.02 

Round  76, Train loss: 0.459, Test loss: 1.454, Test accuracy: 61.80 

Round  77, Train loss: 0.491, Test loss: 1.441, Test accuracy: 61.96 

Round  78, Train loss: 0.477, Test loss: 1.450, Test accuracy: 61.58 

Round  79, Train loss: 0.455, Test loss: 1.448, Test accuracy: 62.02 

Round  80, Train loss: 0.465, Test loss: 1.491, Test accuracy: 61.54 

Round  81, Train loss: 0.437, Test loss: 1.478, Test accuracy: 61.42 

Round  82, Train loss: 0.483, Test loss: 1.530, Test accuracy: 60.69 

Round  83, Train loss: 0.465, Test loss: 1.494, Test accuracy: 61.34 

Round  84, Train loss: 0.484, Test loss: 1.502, Test accuracy: 61.52 

Round  85, Train loss: 0.450, Test loss: 1.539, Test accuracy: 61.12 

Round  86, Train loss: 0.433, Test loss: 1.514, Test accuracy: 61.48 

Round  87, Train loss: 0.445, Test loss: 1.540, Test accuracy: 61.61 

Round  88, Train loss: 0.429, Test loss: 1.546, Test accuracy: 61.53 

Round  89, Train loss: 0.418, Test loss: 1.548, Test accuracy: 61.47 

Round  90, Train loss: 0.410, Test loss: 1.540, Test accuracy: 61.75 

Round  91, Train loss: 0.374, Test loss: 1.608, Test accuracy: 61.82 

Round  92, Train loss: 0.431, Test loss: 1.543, Test accuracy: 61.77 

Round  93, Train loss: 0.412, Test loss: 1.577, Test accuracy: 61.54 

Round  94, Train loss: 0.360, Test loss: 1.584, Test accuracy: 61.67 

Round  95, Train loss: 0.443, Test loss: 1.545, Test accuracy: 61.32 

Round  96, Train loss: 0.387, Test loss: 1.605, Test accuracy: 61.67 

Round  97, Train loss: 0.414, Test loss: 1.612, Test accuracy: 61.35 

Round  98, Train loss: 0.400, Test loss: 1.629, Test accuracy: 61.80 

Round  99, Train loss: 0.414, Test loss: 1.573, Test accuracy: 61.35 

Final Round, Train loss: 0.308, Test loss: 1.577, Test accuracy: 61.99 

Average accuracy final 10 rounds: 61.605 

1219.0744998455048
[1.3918890953063965, 2.559023141860962, 3.7248899936676025, 4.890986680984497, 6.059067010879517, 7.224210739135742, 8.388441562652588, 9.55515170097351, 10.712522983551025, 11.879395246505737, 13.037549018859863, 14.194890260696411, 15.352315902709961, 16.515185356140137, 17.67935562133789, 18.85153579711914, 20.008575677871704, 21.169155597686768, 22.33172845840454, 23.493481397628784, 24.653743982315063, 25.81199359893799, 26.973185300827026, 28.137044191360474, 29.300060749053955, 30.46945571899414, 31.640165328979492, 32.80870175361633, 33.97389316558838, 35.13527989387512, 36.29476451873779, 37.45963454246521, 38.61530351638794, 39.78016424179077, 40.939541816711426, 42.09699726104736, 43.2540488243103, 44.412394285202026, 45.578951597213745, 46.74440789222717, 47.90589714050293, 49.07059121131897, 50.231295585632324, 51.38981914520264, 52.54937696456909, 53.70343995094299, 54.86244058609009, 56.021265506744385, 57.179134130477905, 58.33234357833862, 59.491089820861816, 60.648741722106934, 61.806148529052734, 62.96241116523743, 64.12230634689331, 65.2804172039032, 66.44026470184326, 67.59453845024109, 68.74783515930176, 69.90106916427612, 71.05499386787415, 72.21453356742859, 73.37910008430481, 74.54655623435974, 75.71778535842896, 76.88090920448303, 78.04256916046143, 79.21011805534363, 80.37875580787659, 81.54631519317627, 82.71512269973755, 83.884441614151, 85.05281829833984, 86.22889590263367, 87.4020402431488, 88.56932091712952, 89.74130702018738, 90.89846205711365, 92.05519223213196, 93.21529603004456, 94.37256741523743, 95.53040838241577, 96.693767786026, 97.85891056060791, 99.02112412452698, 100.18333601951599, 101.34453392028809, 102.5018413066864, 103.66446447372437, 104.83372569084167, 106.00400686264038, 107.17718291282654, 108.351487159729, 109.5253369808197, 110.69797825813293, 111.8750946521759, 113.04950141906738, 114.21589207649231, 115.38939070701599, 116.55646467208862, 118.45335412025452]
[26.53, 30.755, 35.365, 37.875, 40.405, 42.23, 43.125, 46.245, 47.36, 47.94, 48.96, 50.275, 51.355, 52.77, 52.435, 53.285, 54.295, 55.135, 56.27, 56.41, 56.015, 57.275, 56.84, 57.505, 58.165, 58.625, 58.9, 59.46, 59.735, 59.25, 59.7, 60.04, 59.795, 59.96, 60.13, 60.515, 60.385, 60.695, 61.14, 60.965, 60.845, 60.97, 61.04, 61.155, 61.655, 60.835, 61.485, 61.565, 60.775, 61.1, 61.485, 61.58, 62.025, 61.6, 62.15, 61.53, 61.065, 61.35, 61.425, 61.975, 61.38, 61.335, 61.66, 61.225, 61.465, 60.83, 61.385, 61.325, 61.54, 61.575, 61.86, 61.78, 61.46, 61.75, 61.39, 62.025, 61.805, 61.96, 61.58, 62.02, 61.54, 61.425, 60.685, 61.335, 61.52, 61.12, 61.485, 61.61, 61.53, 61.47, 61.75, 61.82, 61.77, 61.54, 61.675, 61.32, 61.67, 61.35, 61.8, 61.355, 61.995]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 8394 (global); Percentage 2.73 (8394/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.222, Test loss: 2.050, Test accuracy: 26.54 

Round   1, Train loss: 2.022, Test loss: 1.925, Test accuracy: 30.11 

Round   2, Train loss: 1.936, Test loss: 1.836, Test accuracy: 32.95 

Round   3, Train loss: 1.878, Test loss: 1.783, Test accuracy: 35.19 

Round   4, Train loss: 1.788, Test loss: 1.737, Test accuracy: 36.14 

Round   5, Train loss: 1.719, Test loss: 1.719, Test accuracy: 37.48 

Round   6, Train loss: 1.666, Test loss: 1.701, Test accuracy: 38.03 

Round   7, Train loss: 1.614, Test loss: 1.706, Test accuracy: 38.27 

Round   8, Train loss: 1.610, Test loss: 1.677, Test accuracy: 39.24 

Round   9, Train loss: 1.541, Test loss: 1.669, Test accuracy: 39.77 

Round  10, Train loss: 1.576, Test loss: 1.668, Test accuracy: 39.96 

Round  11, Train loss: 1.451, Test loss: 1.671, Test accuracy: 40.38 

Round  12, Train loss: 1.473, Test loss: 1.671, Test accuracy: 40.60 

Round  13, Train loss: 1.471, Test loss: 1.673, Test accuracy: 40.48 

Round  14, Train loss: 1.412, Test loss: 1.689, Test accuracy: 40.82 

Round  15, Train loss: 1.282, Test loss: 1.702, Test accuracy: 40.45 

Round  16, Train loss: 1.328, Test loss: 1.702, Test accuracy: 40.81 

Round  17, Train loss: 1.264, Test loss: 1.713, Test accuracy: 41.11 

Round  18, Train loss: 1.178, Test loss: 1.756, Test accuracy: 41.10 

Round  19, Train loss: 1.133, Test loss: 1.767, Test accuracy: 40.90 

Round  20, Train loss: 1.112, Test loss: 1.790, Test accuracy: 40.64 

Round  21, Train loss: 1.028, Test loss: 1.793, Test accuracy: 41.26 

Round  22, Train loss: 1.099, Test loss: 1.834, Test accuracy: 41.51 

Round  23, Train loss: 1.114, Test loss: 1.841, Test accuracy: 41.73 

Round  24, Train loss: 0.997, Test loss: 1.847, Test accuracy: 41.80 

Round  25, Train loss: 1.048, Test loss: 1.885, Test accuracy: 41.20 

Round  26, Train loss: 1.005, Test loss: 1.903, Test accuracy: 41.63 

Round  27, Train loss: 0.870, Test loss: 1.950, Test accuracy: 41.68 

Round  28, Train loss: 0.912, Test loss: 1.990, Test accuracy: 41.77 

Round  29, Train loss: 0.926, Test loss: 2.017, Test accuracy: 42.02 

Round  30, Train loss: 0.757, Test loss: 2.051, Test accuracy: 41.78 

Round  31, Train loss: 0.827, Test loss: 2.076, Test accuracy: 41.95 

Round  32, Train loss: 0.786, Test loss: 2.116, Test accuracy: 42.06 

Round  33, Train loss: 0.792, Test loss: 2.128, Test accuracy: 42.00 

Round  34, Train loss: 0.708, Test loss: 2.220, Test accuracy: 41.83 

Round  35, Train loss: 0.666, Test loss: 2.241, Test accuracy: 41.98 

Round  36, Train loss: 0.617, Test loss: 2.285, Test accuracy: 41.85 

Round  37, Train loss: 0.609, Test loss: 2.307, Test accuracy: 41.94 

Round  38, Train loss: 0.587, Test loss: 2.309, Test accuracy: 42.44 

Round  39, Train loss: 0.594, Test loss: 2.343, Test accuracy: 42.30 

Round  40, Train loss: 0.515, Test loss: 2.362, Test accuracy: 42.27 

Round  41, Train loss: 0.575, Test loss: 2.412, Test accuracy: 42.25 

Round  42, Train loss: 0.501, Test loss: 2.485, Test accuracy: 42.27 

Round  43, Train loss: 0.535, Test loss: 2.542, Test accuracy: 42.05 

Round  44, Train loss: 0.492, Test loss: 2.547, Test accuracy: 42.33 

Round  45, Train loss: 0.482, Test loss: 2.550, Test accuracy: 42.17 

Round  46, Train loss: 0.429, Test loss: 2.674, Test accuracy: 42.35 

Round  47, Train loss: 0.469, Test loss: 2.699, Test accuracy: 42.32 

Round  48, Train loss: 0.472, Test loss: 2.741, Test accuracy: 42.27 

Round  49, Train loss: 0.388, Test loss: 2.779, Test accuracy: 41.72 

Round  50, Train loss: 0.439, Test loss: 2.832, Test accuracy: 41.89 

Round  51, Train loss: 0.431, Test loss: 2.842, Test accuracy: 41.59 

Round  52, Train loss: 0.348, Test loss: 2.884, Test accuracy: 41.96 

Round  53, Train loss: 0.397, Test loss: 2.886, Test accuracy: 42.17 

Round  54, Train loss: 0.318, Test loss: 2.948, Test accuracy: 42.06 

Round  55, Train loss: 0.335, Test loss: 2.954, Test accuracy: 41.63 

Round  56, Train loss: 0.392, Test loss: 2.929, Test accuracy: 41.97 

Round  57, Train loss: 0.335, Test loss: 2.947, Test accuracy: 41.56 

Round  58, Train loss: 0.346, Test loss: 2.962, Test accuracy: 41.82 

Round  59, Train loss: 0.278, Test loss: 3.024, Test accuracy: 41.94 

Round  60, Train loss: 0.264, Test loss: 3.068, Test accuracy: 42.18 

Round  61, Train loss: 0.267, Test loss: 3.086, Test accuracy: 42.13 

Round  62, Train loss: 0.268, Test loss: 3.164, Test accuracy: 41.87 

Round  63, Train loss: 0.282, Test loss: 3.126, Test accuracy: 42.00 

Round  64, Train loss: 0.258, Test loss: 3.171, Test accuracy: 42.27 

Round  65, Train loss: 0.275, Test loss: 3.194, Test accuracy: 42.10 

Round  66, Train loss: 0.272, Test loss: 3.220, Test accuracy: 41.99 

Round  67, Train loss: 0.322, Test loss: 3.226, Test accuracy: 41.84 

Round  68, Train loss: 0.258, Test loss: 3.284, Test accuracy: 41.85 

Round  69, Train loss: 0.207, Test loss: 3.253, Test accuracy: 42.06 

Round  70, Train loss: 0.225, Test loss: 3.315, Test accuracy: 42.20 

Round  71, Train loss: 0.257, Test loss: 3.340, Test accuracy: 42.24 

Round  72, Train loss: 0.270, Test loss: 3.313, Test accuracy: 42.17 

Round  73, Train loss: 0.182, Test loss: 3.353, Test accuracy: 42.19 

Round  74, Train loss: 0.235, Test loss: 3.418, Test accuracy: 42.15 

Round  75, Train loss: 0.190, Test loss: 3.465, Test accuracy: 42.22 

Round  76, Train loss: 0.218, Test loss: 3.457, Test accuracy: 42.40 

Round  77, Train loss: 0.183, Test loss: 3.522, Test accuracy: 42.58 

Round  78, Train loss: 0.181, Test loss: 3.592, Test accuracy: 42.45 

Round  79, Train loss: 0.214, Test loss: 3.517, Test accuracy: 42.47 

Round  80, Train loss: 0.225, Test loss: 3.662, Test accuracy: 41.95 

Round  81, Train loss: 0.184, Test loss: 3.633, Test accuracy: 42.24 

Round  82, Train loss: 0.174, Test loss: 3.683, Test accuracy: 42.27 

Round  83, Train loss: 0.164, Test loss: 3.648, Test accuracy: 42.30 

Round  84, Train loss: 0.176, Test loss: 3.654, Test accuracy: 42.60 

Round  85, Train loss: 0.171, Test loss: 3.673, Test accuracy: 42.34 

Round  86, Train loss: 0.180, Test loss: 3.733, Test accuracy: 42.52 

Round  87, Train loss: 0.157, Test loss: 3.797, Test accuracy: 42.34 

Round  88, Train loss: 0.133, Test loss: 3.910, Test accuracy: 42.35 

Round  89, Train loss: 0.153, Test loss: 3.892, Test accuracy: 42.13 

Round  90, Train loss: 0.164, Test loss: 3.806, Test accuracy: 42.23 

Round  91, Train loss: 0.158, Test loss: 3.757, Test accuracy: 42.72 

Round  92, Train loss: 0.136, Test loss: 3.829, Test accuracy: 42.24 

Round  93, Train loss: 0.160, Test loss: 3.842, Test accuracy: 42.63 

Round  94, Train loss: 0.170, Test loss: 3.860, Test accuracy: 42.52 

Round  95, Train loss: 0.133, Test loss: 3.847, Test accuracy: 42.41 

Round  96, Train loss: 0.161, Test loss: 3.848, Test accuracy: 42.52 

Round  97, Train loss: 0.183, Test loss: 3.771, Test accuracy: 42.78 

Round  98, Train loss: 0.102, Test loss: 3.868, Test accuracy: 42.86 

Round  99, Train loss: 0.128, Test loss: 3.924, Test accuracy: 42.62 

Final Round, Train loss: 0.093, Test loss: 4.212, Test accuracy: 42.75 

Average accuracy final 10 rounds: 42.55400000000001 

1214.2542839050293
[1.396937370300293, 2.5605762004852295, 3.7342615127563477, 4.898889780044556, 6.065981149673462, 7.238376617431641, 8.40987229347229, 9.581272840499878, 10.74654746055603, 11.91136908531189, 13.09850263595581, 14.287176847457886, 15.470447063446045, 16.64793848991394, 17.825961589813232, 19.002665519714355, 20.18385887145996, 21.3616144657135, 22.537096977233887, 23.710856199264526, 24.809473037719727, 25.977967500686646, 27.15444588661194, 28.333137035369873, 29.51078152656555, 30.68688201904297, 31.868404865264893, 33.04663276672363, 34.227885484695435, 35.41118812561035, 36.59056282043457, 37.768680810928345, 38.94773721694946, 40.12412691116333, 41.299766063690186, 42.480684995651245, 43.65592551231384, 44.83568286895752, 46.01354360580444, 47.193588972091675, 48.36961555480957, 49.544899225234985, 50.73049235343933, 51.91310787200928, 53.093475580215454, 54.26866602897644, 55.44377946853638, 56.623948097229004, 57.80041432380676, 58.980735063552856, 60.16446280479431, 61.34889507293701, 62.52924180030823, 63.70847201347351, 64.88567781448364, 66.06580471992493, 67.24515056610107, 68.41853427886963, 69.59965348243713, 70.77942204475403, 71.95969867706299, 73.13963747024536, 74.31412243843079, 75.48871302604675, 76.66713190078735, 77.84246397018433, 78.93354225158691, 80.0954430103302, 81.26507091522217, 82.42645406723022, 83.59091711044312, 84.75415825843811, 85.91307711601257, 87.07910704612732, 88.2497947216034, 89.41845917701721, 90.58575129508972, 91.74837017059326, 92.91306257247925, 94.07970476150513, 95.23718881607056, 96.39834666252136, 97.56178140640259, 98.72365474700928, 99.88206076622009, 101.04461455345154, 102.20612382888794, 103.36479997634888, 104.37363719940186, 105.37936544418335, 106.39276552200317, 107.4030933380127, 108.40790390968323, 109.41780805587769, 110.42349672317505, 111.42815852165222, 112.43769884109497, 113.44108414649963, 114.44636368751526, 115.4526915550232, 117.40250420570374]
[26.535, 30.115, 32.95, 35.19, 36.14, 37.485, 38.03, 38.27, 39.245, 39.775, 39.96, 40.375, 40.605, 40.475, 40.82, 40.445, 40.815, 41.11, 41.105, 40.895, 40.64, 41.26, 41.505, 41.735, 41.795, 41.2, 41.63, 41.68, 41.77, 42.02, 41.785, 41.95, 42.06, 42.0, 41.83, 41.985, 41.855, 41.935, 42.44, 42.295, 42.265, 42.25, 42.265, 42.05, 42.33, 42.175, 42.355, 42.32, 42.275, 41.72, 41.89, 41.595, 41.96, 42.175, 42.06, 41.635, 41.965, 41.56, 41.82, 41.94, 42.18, 42.13, 41.865, 42.0, 42.265, 42.105, 41.99, 41.845, 41.855, 42.06, 42.2, 42.24, 42.175, 42.19, 42.15, 42.215, 42.4, 42.58, 42.445, 42.465, 41.945, 42.245, 42.27, 42.305, 42.605, 42.335, 42.525, 42.345, 42.355, 42.13, 42.225, 42.715, 42.245, 42.635, 42.52, 42.405, 42.525, 42.785, 42.86, 42.625, 42.75]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac.py", line 61, in <module>
    dataset_train.targets = np.load('data/sample/dataset_train_target.npy', allow_pickle=True)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/lib/npyio.py", line 417, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'data/sample/dataset_train_target.npy'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 2.266, Test loss: 2.061, Test accuracy: 25.74
Round   1, Train loss: 2.033, Test loss: 1.900, Test accuracy: 30.41
Round   2, Train loss: 1.953, Test loss: 1.756, Test accuracy: 35.15
Round   3, Train loss: 1.885, Test loss: 1.636, Test accuracy: 40.41
Round   4, Train loss: 1.742, Test loss: 1.566, Test accuracy: 42.03
Round   5, Train loss: 1.675, Test loss: 1.508, Test accuracy: 45.37
Round   6, Train loss: 1.668, Test loss: 1.461, Test accuracy: 47.23
Round   7, Train loss: 1.580, Test loss: 1.424, Test accuracy: 48.82
Round   8, Train loss: 1.510, Test loss: 1.388, Test accuracy: 49.82
Round   9, Train loss: 1.524, Test loss: 1.349, Test accuracy: 51.35
Round  10, Train loss: 1.529, Test loss: 1.329, Test accuracy: 52.77
Round  11, Train loss: 1.416, Test loss: 1.309, Test accuracy: 53.19
Round  12, Train loss: 1.439, Test loss: 1.283, Test accuracy: 55.05
Round  13, Train loss: 1.356, Test loss: 1.254, Test accuracy: 55.23
Round  14, Train loss: 1.286, Test loss: 1.256, Test accuracy: 55.03
Round  15, Train loss: 1.266, Test loss: 1.221, Test accuracy: 56.66
Round  16, Train loss: 1.284, Test loss: 1.191, Test accuracy: 57.55
Round  17, Train loss: 1.217, Test loss: 1.188, Test accuracy: 58.22
Round  18, Train loss: 1.161, Test loss: 1.179, Test accuracy: 58.46
Round  19, Train loss: 1.226, Test loss: 1.149, Test accuracy: 59.15
Round  20, Train loss: 1.167, Test loss: 1.140, Test accuracy: 59.13
Round  21, Train loss: 1.106, Test loss: 1.126, Test accuracy: 59.69
Round  22, Train loss: 1.084, Test loss: 1.122, Test accuracy: 60.16
Round  23, Train loss: 1.071, Test loss: 1.096, Test accuracy: 61.52
Round  24, Train loss: 1.045, Test loss: 1.100, Test accuracy: 61.38
Round  25, Train loss: 1.001, Test loss: 1.099, Test accuracy: 61.92
Round  26, Train loss: 0.992, Test loss: 1.082, Test accuracy: 62.02
Round  27, Train loss: 1.017, Test loss: 1.069, Test accuracy: 62.95
Round  28, Train loss: 0.957, Test loss: 1.054, Test accuracy: 63.53
Round  29, Train loss: 0.932, Test loss: 1.072, Test accuracy: 63.01
Round  30, Train loss: 0.931, Test loss: 1.066, Test accuracy: 62.98
Round  31, Train loss: 0.897, Test loss: 1.049, Test accuracy: 64.54
Round  32, Train loss: 0.883, Test loss: 1.052, Test accuracy: 64.14
Round  33, Train loss: 0.878, Test loss: 1.034, Test accuracy: 64.35
Round  34, Train loss: 0.865, Test loss: 1.033, Test accuracy: 65.20
Round  35, Train loss: 0.825, Test loss: 1.058, Test accuracy: 63.91
Round  36, Train loss: 0.814, Test loss: 1.033, Test accuracy: 64.48
Round  37, Train loss: 0.789, Test loss: 1.032, Test accuracy: 65.44
Round  38, Train loss: 0.832, Test loss: 1.035, Test accuracy: 65.32
Round  39, Train loss: 0.776, Test loss: 1.039, Test accuracy: 65.41
Round  40, Train loss: 0.729, Test loss: 1.039, Test accuracy: 65.63
Round  41, Train loss: 0.733, Test loss: 1.015, Test accuracy: 66.60
Round  42, Train loss: 0.727, Test loss: 1.022, Test accuracy: 66.36
Round  43, Train loss: 0.717, Test loss: 1.012, Test accuracy: 66.65
Round  44, Train loss: 0.698, Test loss: 1.034, Test accuracy: 65.70
Round  45, Train loss: 0.687, Test loss: 1.031, Test accuracy: 66.81
Round  46, Train loss: 0.711, Test loss: 1.024, Test accuracy: 66.60
Round  47, Train loss: 0.675, Test loss: 1.020, Test accuracy: 67.00
Round  48, Train loss: 0.672, Test loss: 1.015, Test accuracy: 66.94
Round  49, Train loss: 0.665, Test loss: 1.021, Test accuracy: 66.62
Round  50, Train loss: 0.631, Test loss: 1.033, Test accuracy: 66.66
Round  51, Train loss: 0.577, Test loss: 1.038, Test accuracy: 67.38
Round  52, Train loss: 0.695, Test loss: 1.024, Test accuracy: 67.02
Round  53, Train loss: 0.583, Test loss: 1.012, Test accuracy: 67.52
Round  54, Train loss: 0.627, Test loss: 0.998, Test accuracy: 67.92
Round  55, Train loss: 0.623, Test loss: 0.999, Test accuracy: 67.83
Round  56, Train loss: 0.609, Test loss: 1.025, Test accuracy: 67.97
Round  57, Train loss: 0.564, Test loss: 1.010, Test accuracy: 68.08
Round  58, Train loss: 0.565, Test loss: 1.014, Test accuracy: 68.13
Round  59, Train loss: 0.588, Test loss: 1.014, Test accuracy: 68.02
Round  60, Train loss: 0.535, Test loss: 1.056, Test accuracy: 67.91
Round  61, Train loss: 0.600, Test loss: 1.004, Test accuracy: 67.98
Round  62, Train loss: 0.527, Test loss: 1.041, Test accuracy: 68.17
Round  63, Train loss: 0.543, Test loss: 1.007, Test accuracy: 68.25
Round  64, Train loss: 0.474, Test loss: 1.037, Test accuracy: 68.83
Round  65, Train loss: 0.462, Test loss: 1.053, Test accuracy: 68.34
Round  66, Train loss: 0.470, Test loss: 1.057, Test accuracy: 68.40
Round  67, Train loss: 0.550, Test loss: 1.013, Test accuracy: 68.68
Round  68, Train loss: 0.450, Test loss: 1.061, Test accuracy: 68.38
Round  69, Train loss: 0.509, Test loss: 1.049, Test accuracy: 67.93
Round  70, Train loss: 0.499, Test loss: 1.034, Test accuracy: 68.56
Round  71, Train loss: 0.506, Test loss: 1.033, Test accuracy: 68.41
Round  72, Train loss: 0.516, Test loss: 1.044, Test accuracy: 68.14
Round  73, Train loss: 0.471, Test loss: 1.020, Test accuracy: 68.73
Round  74, Train loss: 0.428, Test loss: 1.038, Test accuracy: 69.16
Round  75, Train loss: 0.375, Test loss: 1.072, Test accuracy: 69.19
Round  76, Train loss: 0.515, Test loss: 1.036, Test accuracy: 68.63
Round  77, Train loss: 0.459, Test loss: 1.050, Test accuracy: 68.90
Round  78, Train loss: 0.462, Test loss: 1.027, Test accuracy: 68.66
Round  79, Train loss: 0.448, Test loss: 1.045, Test accuracy: 68.88
Round  80, Train loss: 0.448, Test loss: 1.061, Test accuracy: 68.05
Round  81, Train loss: 0.465, Test loss: 1.051, Test accuracy: 68.68
Round  82, Train loss: 0.424, Test loss: 1.059, Test accuracy: 68.85
Round  83, Train loss: 0.452, Test loss: 1.045, Test accuracy: 68.68
Round  84, Train loss: 0.402, Test loss: 1.076, Test accuracy: 68.80
Round  85, Train loss: 0.421, Test loss: 1.051, Test accuracy: 68.64
Round  86, Train loss: 0.391, Test loss: 1.096, Test accuracy: 68.16
Round  87, Train loss: 0.375, Test loss: 1.104, Test accuracy: 68.55
Round  88, Train loss: 0.391, Test loss: 1.070, Test accuracy: 68.92
Round  89, Train loss: 0.417, Test loss: 1.057, Test accuracy: 68.83
Round  90, Train loss: 0.412, Test loss: 1.077, Test accuracy: 68.61
Round  91, Train loss: 0.392, Test loss: 1.078, Test accuracy: 68.77
Round  92, Train loss: 0.388, Test loss: 1.084, Test accuracy: 68.28
Round  93, Train loss: 0.407, Test loss: 1.095, Test accuracy: 68.28
Round  94, Train loss: 0.371, Test loss: 1.078, Test accuracy: 69.16
Round  95, Train loss: 0.376, Test loss: 1.091, Test accuracy: 68.67
Round  96, Train loss: 0.387, Test loss: 1.079, Test accuracy: 68.53
Round  97, Train loss: 0.354, Test loss: 1.086, Test accuracy: 68.99
Round  98, Train loss: 0.382, Test loss: 1.091, Test accuracy: 69.05
Round  99, Train loss: 0.350, Test loss: 1.091, Test accuracy: 68.92
Final Round, Train loss: 0.355, Test loss: 1.052, Test accuracy: 69.83
Average accuracy final 10 rounds: 68.72399999999999
2119.329320907593
[3.201371192932129, 6.132176160812378, 8.784167051315308, 11.440967082977295, 14.093348026275635, 16.74153757095337, 19.385292291641235, 22.02302074432373, 24.66661548614502, 27.30319857597351, 29.93893003463745, 32.59069776535034, 35.241910219192505, 37.894214391708374, 40.55153703689575, 43.21154427528381, 45.85787010192871, 48.49425435066223, 51.1328239440918, 53.79688382148743, 56.46228742599487, 59.13557314872742, 61.80424118041992, 64.47331404685974, 67.14141774177551, 69.77699112892151, 72.43524503707886, 75.08468461036682, 77.72431898117065, 80.3729829788208, 83.0266706943512, 85.68072152137756, 88.3334846496582, 90.97990345954895, 93.62638783454895, 96.27311587333679, 98.91772270202637, 101.55008673667908, 104.19247698783875, 106.85269284248352, 109.51661920547485, 112.17531132698059, 114.83651447296143, 117.49563264846802, 120.16317009925842, 122.82737398147583, 125.4869544506073, 128.15124773979187, 130.80724668502808, 133.47003841400146, 136.1243188381195, 138.78164172172546, 141.44004797935486, 144.07149267196655, 146.71158742904663, 149.33723139762878, 151.9667103290558, 154.59689736366272, 157.2247588634491, 159.8532633781433, 162.48454308509827, 165.1229293346405, 167.7564673423767, 170.38365387916565, 173.01610898971558, 175.64615964889526, 178.27565836906433, 180.90612816810608, 183.5368320941925, 186.16961097717285, 188.80225944519043, 191.4346776008606, 194.07069325447083, 196.71511340141296, 199.36819553375244, 202.02694439888, 204.68328475952148, 207.33123898506165, 209.97948503494263, 212.61628675460815, 215.25318837165833, 217.89332699775696, 220.53149676322937, 223.17570543289185, 225.81026196479797, 228.44200825691223, 231.07433772087097, 233.7079529762268, 236.33616733551025, 238.9765965938568, 241.61234736442566, 244.24372720718384, 246.88484597206116, 249.5139729976654, 252.1468780040741, 254.7809534072876, 257.41193413734436, 260.0461754798889, 262.6769423484802, 265.31484818458557, 267.95573258399963]
[25.74, 30.405, 35.15, 40.405, 42.03, 45.37, 47.225, 48.82, 49.82, 51.35, 52.775, 53.185, 55.045, 55.225, 55.035, 56.665, 57.555, 58.22, 58.46, 59.145, 59.135, 59.685, 60.165, 61.52, 61.385, 61.925, 62.02, 62.945, 63.53, 63.01, 62.985, 64.54, 64.135, 64.35, 65.205, 63.905, 64.485, 65.445, 65.32, 65.41, 65.63, 66.6, 66.365, 66.65, 65.705, 66.81, 66.6, 66.995, 66.945, 66.625, 66.66, 67.375, 67.02, 67.515, 67.92, 67.835, 67.97, 68.085, 68.13, 68.02, 67.905, 67.98, 68.175, 68.245, 68.825, 68.345, 68.4, 68.68, 68.375, 67.93, 68.565, 68.41, 68.135, 68.735, 69.16, 69.195, 68.63, 68.9, 68.66, 68.875, 68.05, 68.68, 68.85, 68.68, 68.795, 68.635, 68.16, 68.545, 68.925, 68.825, 68.615, 68.765, 68.285, 68.28, 69.155, 68.665, 68.525, 68.99, 69.045, 68.915, 69.83]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 0.807, Test loss: 2.284, Test accuracy: 28.07
Round   1, Train loss: 0.697, Test loss: 2.458, Test accuracy: 25.63
Round   2, Train loss: 0.772, Test loss: 2.138, Test accuracy: 30.33
Round   3, Train loss: 0.680, Test loss: 2.070, Test accuracy: 41.85
Round   4, Train loss: 0.644, Test loss: 2.105, Test accuracy: 46.03
Round   5, Train loss: 0.540, Test loss: 2.065, Test accuracy: 45.62
Round   6, Train loss: 0.579, Test loss: 2.021, Test accuracy: 47.73
Round   7, Train loss: 0.594, Test loss: 1.997, Test accuracy: 46.67
Round   8, Train loss: 0.464, Test loss: 1.960, Test accuracy: 48.70
Round   9, Train loss: 0.501, Test loss: 1.883, Test accuracy: 50.65
Round  10, Train loss: 0.502, Test loss: 1.875, Test accuracy: 50.35
Round  11, Train loss: 0.465, Test loss: 1.800, Test accuracy: 52.27
Round  12, Train loss: 0.433, Test loss: 1.804, Test accuracy: 52.07
Round  13, Train loss: 0.437, Test loss: 1.778, Test accuracy: 52.10
Round  14, Train loss: 0.427, Test loss: 1.784, Test accuracy: 53.12
Round  15, Train loss: 0.439, Test loss: 1.740, Test accuracy: 55.32
Round  16, Train loss: 0.451, Test loss: 1.718, Test accuracy: 54.57
Round  17, Train loss: 0.428, Test loss: 1.694, Test accuracy: 55.15
Round  18, Train loss: 0.396, Test loss: 1.676, Test accuracy: 55.92
Round  19, Train loss: 0.357, Test loss: 1.644, Test accuracy: 57.28
Round  20, Train loss: 0.375, Test loss: 1.636, Test accuracy: 56.37
Round  21, Train loss: 0.328, Test loss: 1.627, Test accuracy: 56.42
Round  22, Train loss: 0.308, Test loss: 1.582, Test accuracy: 56.77
Round  23, Train loss: 0.329, Test loss: 1.549, Test accuracy: 57.92
Round  24, Train loss: 0.305, Test loss: 1.546, Test accuracy: 56.87
Round  25, Train loss: 0.307, Test loss: 1.517, Test accuracy: 58.15
Round  26, Train loss: 0.285, Test loss: 1.495, Test accuracy: 58.08
Round  27, Train loss: 0.287, Test loss: 1.480, Test accuracy: 58.45
Round  28, Train loss: 0.286, Test loss: 1.467, Test accuracy: 57.53
Round  29, Train loss: 0.310, Test loss: 1.453, Test accuracy: 57.80
Round  30, Train loss: 0.265, Test loss: 1.439, Test accuracy: 57.85
Round  31, Train loss: 0.269, Test loss: 1.404, Test accuracy: 57.83
Round  32, Train loss: 0.276, Test loss: 1.382, Test accuracy: 58.63
Round  33, Train loss: 0.282, Test loss: 1.368, Test accuracy: 57.67
Round  34, Train loss: 0.222, Test loss: 1.348, Test accuracy: 58.30
Round  35, Train loss: 0.252, Test loss: 1.320, Test accuracy: 59.77
Round  36, Train loss: 0.230, Test loss: 1.307, Test accuracy: 60.18
Round  37, Train loss: 0.161, Test loss: 1.278, Test accuracy: 60.00
Round  38, Train loss: 0.254, Test loss: 1.272, Test accuracy: 59.83
Round  39, Train loss: 0.201, Test loss: 1.242, Test accuracy: 60.88
Round  40, Train loss: 0.231, Test loss: 1.237, Test accuracy: 60.15
Round  41, Train loss: 0.230, Test loss: 1.234, Test accuracy: 59.45
Round  42, Train loss: 0.165, Test loss: 1.206, Test accuracy: 59.70
Round  43, Train loss: 0.176, Test loss: 1.195, Test accuracy: 60.20
Round  44, Train loss: 0.150, Test loss: 1.185, Test accuracy: 61.13
Round  45, Train loss: 0.193, Test loss: 1.173, Test accuracy: 61.12
Round  46, Train loss: 0.148, Test loss: 1.172, Test accuracy: 60.52
Round  47, Train loss: 0.182, Test loss: 1.160, Test accuracy: 60.45
Round  48, Train loss: 0.213, Test loss: 1.139, Test accuracy: 61.78
Round  49, Train loss: 0.156, Test loss: 1.132, Test accuracy: 61.42
Round  50, Train loss: 0.123, Test loss: 1.101, Test accuracy: 61.85
Round  51, Train loss: 0.171, Test loss: 1.092, Test accuracy: 61.57
Round  52, Train loss: 0.153, Test loss: 1.092, Test accuracy: 60.63
Round  53, Train loss: 0.113, Test loss: 1.080, Test accuracy: 61.48
Round  54, Train loss: 0.143, Test loss: 1.073, Test accuracy: 60.67
Round  55, Train loss: 0.133, Test loss: 1.066, Test accuracy: 59.67
Round  56, Train loss: 0.193, Test loss: 1.071, Test accuracy: 59.78
Round  57, Train loss: 0.118, Test loss: 1.047, Test accuracy: 61.68
Round  58, Train loss: 0.157, Test loss: 1.036, Test accuracy: 61.97
Round  59, Train loss: 0.098, Test loss: 1.030, Test accuracy: 60.88
Round  60, Train loss: 0.186, Test loss: 1.032, Test accuracy: 60.75
Round  61, Train loss: 0.134, Test loss: 1.011, Test accuracy: 62.60
Round  62, Train loss: 0.119, Test loss: 1.001, Test accuracy: 61.85
Round  63, Train loss: 0.112, Test loss: 1.004, Test accuracy: 61.28
Round  64, Train loss: 0.132, Test loss: 1.004, Test accuracy: 61.15
Round  65, Train loss: 0.122, Test loss: 0.980, Test accuracy: 62.53
Round  66, Train loss: 0.098, Test loss: 0.982, Test accuracy: 61.50
Round  67, Train loss: 0.093, Test loss: 0.977, Test accuracy: 61.48
Round  68, Train loss: 0.135, Test loss: 0.971, Test accuracy: 61.90
Round  69, Train loss: 0.108, Test loss: 0.959, Test accuracy: 61.87
Round  70, Train loss: 0.115, Test loss: 0.947, Test accuracy: 61.50
Round  71, Train loss: 0.126, Test loss: 0.944, Test accuracy: 61.78
Round  72, Train loss: 0.121, Test loss: 0.940, Test accuracy: 61.37
Round  73, Train loss: 0.088, Test loss: 0.917, Test accuracy: 63.38
Round  74, Train loss: 0.092, Test loss: 0.912, Test accuracy: 63.10
Round  75, Train loss: 0.087, Test loss: 0.895, Test accuracy: 64.50
Round  76, Train loss: 0.102, Test loss: 0.890, Test accuracy: 65.23
Round  77, Train loss: 0.098, Test loss: 0.879, Test accuracy: 65.23
Round  78, Train loss: 0.105, Test loss: 0.873, Test accuracy: 65.87
Round  79, Train loss: 0.097, Test loss: 0.871, Test accuracy: 65.65
Round  80, Train loss: 0.097, Test loss: 0.874, Test accuracy: 65.45
Round  81, Train loss: 0.064, Test loss: 0.873, Test accuracy: 64.87
Round  82, Train loss: 0.084, Test loss: 0.858, Test accuracy: 66.28
Round  83, Train loss: 0.072, Test loss: 0.856, Test accuracy: 65.98
Round  84, Train loss: 0.082, Test loss: 0.858, Test accuracy: 65.20
Round  85, Train loss: 0.082, Test loss: 0.846, Test accuracy: 65.12
Round  86, Train loss: 0.067, Test loss: 0.830, Test accuracy: 66.62
Round  87, Train loss: 0.083, Test loss: 0.832, Test accuracy: 66.33
Round  88, Train loss: 0.089, Test loss: 0.837, Test accuracy: 65.35
Round  89, Train loss: 0.074, Test loss: 0.830, Test accuracy: 65.97
Round  90, Train loss: 0.082, Test loss: 0.828, Test accuracy: 65.87
Round  91, Train loss: 0.059, Test loss: 0.824, Test accuracy: 65.95
Round  92, Train loss: 0.076, Test loss: 0.833, Test accuracy: 65.65
Round  93, Train loss: 0.089, Test loss: 0.832, Test accuracy: 65.72
Round  94, Train loss: 0.059, Test loss: 0.828, Test accuracy: 65.83
Round  95, Train loss: 0.055, Test loss: 0.815, Test accuracy: 66.38
Round  96, Train loss: 0.046, Test loss: 0.809, Test accuracy: 67.12
Round  97, Train loss: 0.060, Test loss: 0.807, Test accuracy: 66.70
Round  98, Train loss: 0.069, Test loss: 0.812, Test accuracy: 65.83
Round  99, Train loss: 0.057, Test loss: 0.805, Test accuracy: 65.32
Final Round, Train loss: 0.068, Test loss: 0.817, Test accuracy: 65.20
Average accuracy final 10 rounds: 66.03666666666668
988.8053274154663
[]
[28.066666666666666, 25.633333333333333, 30.333333333333332, 41.85, 46.03333333333333, 45.61666666666667, 47.733333333333334, 46.666666666666664, 48.7, 50.65, 50.35, 52.266666666666666, 52.06666666666667, 52.1, 53.11666666666667, 55.31666666666667, 54.56666666666667, 55.15, 55.916666666666664, 57.28333333333333, 56.36666666666667, 56.416666666666664, 56.766666666666666, 57.916666666666664, 56.86666666666667, 58.15, 58.083333333333336, 58.45, 57.53333333333333, 57.8, 57.85, 57.833333333333336, 58.63333333333333, 57.666666666666664, 58.3, 59.766666666666666, 60.18333333333333, 60.0, 59.833333333333336, 60.88333333333333, 60.15, 59.45, 59.7, 60.2, 61.13333333333333, 61.11666666666667, 60.516666666666666, 60.45, 61.78333333333333, 61.416666666666664, 61.85, 61.56666666666667, 60.63333333333333, 61.483333333333334, 60.666666666666664, 59.666666666666664, 59.78333333333333, 61.68333333333333, 61.96666666666667, 60.88333333333333, 60.75, 62.6, 61.85, 61.28333333333333, 61.15, 62.53333333333333, 61.5, 61.483333333333334, 61.9, 61.86666666666667, 61.5, 61.78333333333333, 61.36666666666667, 63.38333333333333, 63.1, 64.5, 65.23333333333333, 65.23333333333333, 65.86666666666666, 65.65, 65.45, 64.86666666666666, 66.28333333333333, 65.98333333333333, 65.2, 65.11666666666666, 66.61666666666666, 66.33333333333333, 65.35, 65.96666666666667, 65.86666666666666, 65.95, 65.65, 65.71666666666667, 65.83333333333333, 66.38333333333334, 67.11666666666666, 66.7, 65.83333333333333, 65.31666666666666, 65.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.183, Test loss: 1.900, Test accuracy: 21.68
Round   0: Global train loss: 1.183, Global test loss: 2.305, Global test accuracy: 8.58
Round   1, Train loss: 1.051, Test loss: 1.564, Test accuracy: 34.27
Round   1: Global train loss: 1.051, Global test loss: 2.296, Global test accuracy: 15.42
Round   2, Train loss: 1.065, Test loss: 1.393, Test accuracy: 40.92
Round   2: Global train loss: 1.065, Global test loss: 2.288, Global test accuracy: 19.15
Round   3, Train loss: 0.927, Test loss: 1.287, Test accuracy: 42.52
Round   3: Global train loss: 0.927, Global test loss: 2.281, Global test accuracy: 20.82
Round   4, Train loss: 0.631, Test loss: 1.148, Test accuracy: 49.43
Round   4: Global train loss: 0.631, Global test loss: 2.267, Global test accuracy: 21.92
Round   5, Train loss: 0.489, Test loss: 1.097, Test accuracy: 52.50
Round   5: Global train loss: 0.489, Global test loss: 2.252, Global test accuracy: 22.42
Round   6, Train loss: 0.253, Test loss: 1.086, Test accuracy: 53.35
Round   6: Global train loss: 0.253, Global test loss: 2.242, Global test accuracy: 24.25
Round   7, Train loss: 0.346, Test loss: 0.978, Test accuracy: 56.33
Round   7: Global train loss: 0.346, Global test loss: 2.226, Global test accuracy: 25.73
Round   8, Train loss: 0.184, Test loss: 0.983, Test accuracy: 57.00
Round   8: Global train loss: 0.184, Global test loss: 2.213, Global test accuracy: 26.15
Round   9, Train loss: 0.555, Test loss: 0.999, Test accuracy: 55.15
Round   9: Global train loss: 0.555, Global test loss: 2.205, Global test accuracy: 26.53
Round  10, Train loss: 0.169, Test loss: 1.010, Test accuracy: 53.52
Round  10: Global train loss: 0.169, Global test loss: 2.195, Global test accuracy: 26.00
Round  11, Train loss: 0.151, Test loss: 1.003, Test accuracy: 53.50
Round  11: Global train loss: 0.151, Global test loss: 2.186, Global test accuracy: 25.67
Round  12, Train loss: -0.188, Test loss: 1.001, Test accuracy: 53.97
Round  12: Global train loss: -0.188, Global test loss: 2.175, Global test accuracy: 26.27
Round  13, Train loss: -0.276, Test loss: 0.912, Test accuracy: 56.98
Round  13: Global train loss: -0.276, Global test loss: 2.161, Global test accuracy: 25.32
Round  14, Train loss: -0.590, Test loss: 0.899, Test accuracy: 58.37
Round  14: Global train loss: -0.590, Global test loss: 2.154, Global test accuracy: 25.43
Round  15, Train loss: -0.368, Test loss: 0.893, Test accuracy: 59.18
Round  15: Global train loss: -0.368, Global test loss: 2.143, Global test accuracy: 25.23
Round  16, Train loss: -0.229, Test loss: 0.869, Test accuracy: 61.52
Round  16: Global train loss: -0.229, Global test loss: 2.134, Global test accuracy: 25.18
Round  17, Train loss: -0.238, Test loss: 0.846, Test accuracy: 62.48
Round  17: Global train loss: -0.238, Global test loss: 2.124, Global test accuracy: 26.30
Round  18, Train loss: -0.942, Test loss: 0.846, Test accuracy: 62.43
Round  18: Global train loss: -0.942, Global test loss: 2.114, Global test accuracy: 26.93
Round  19, Train loss: -0.435, Test loss: 0.852, Test accuracy: 62.23
Round  19: Global train loss: -0.435, Global test loss: 2.105, Global test accuracy: 27.17
Round  20, Train loss: -0.431, Test loss: 0.853, Test accuracy: 61.72
Round  20: Global train loss: -0.431, Global test loss: 2.101, Global test accuracy: 26.73
Round  21, Train loss: -0.983, Test loss: 0.841, Test accuracy: 62.33
Round  21: Global train loss: -0.983, Global test loss: 2.091, Global test accuracy: 27.23
Round  22, Train loss: -0.404, Test loss: 0.828, Test accuracy: 63.58
Round  22: Global train loss: -0.404, Global test loss: 2.082, Global test accuracy: 27.98
Round  23, Train loss: -1.375, Test loss: 0.826, Test accuracy: 63.53
Round  23: Global train loss: -1.375, Global test loss: 2.070, Global test accuracy: 28.50
Round  24, Train loss: -0.851, Test loss: 0.820, Test accuracy: 63.23
Round  24: Global train loss: -0.851, Global test loss: 2.065, Global test accuracy: 28.42
Round  25, Train loss: -1.231, Test loss: 0.801, Test accuracy: 64.82
Round  25: Global train loss: -1.231, Global test loss: 2.055, Global test accuracy: 28.95
Round  26, Train loss: -1.096, Test loss: 0.806, Test accuracy: 64.63
Round  26: Global train loss: -1.096, Global test loss: 2.049, Global test accuracy: 29.23
Round  27, Train loss: -1.337, Test loss: 0.791, Test accuracy: 65.35
Round  27: Global train loss: -1.337, Global test loss: 2.039, Global test accuracy: 29.67
Round  28, Train loss: -1.399, Test loss: 0.798, Test accuracy: 65.47
Round  28: Global train loss: -1.399, Global test loss: 2.027, Global test accuracy: 29.30
Round  29, Train loss: -1.363, Test loss: 0.806, Test accuracy: 64.67
Round  29: Global train loss: -1.363, Global test loss: 2.023, Global test accuracy: 28.97
Round  30, Train loss: -1.573, Test loss: 0.807, Test accuracy: 64.85
Round  30: Global train loss: -1.573, Global test loss: 2.018, Global test accuracy: 29.55
Round  31, Train loss: -1.526, Test loss: 0.816, Test accuracy: 64.15
Round  31: Global train loss: -1.526, Global test loss: 2.014, Global test accuracy: 29.27
Round  32, Train loss: -1.948, Test loss: 0.809, Test accuracy: 64.65
Round  32: Global train loss: -1.948, Global test loss: 2.009, Global test accuracy: 30.27
Round  33, Train loss: -1.922, Test loss: 0.825, Test accuracy: 64.07
Round  33: Global train loss: -1.922, Global test loss: 2.005, Global test accuracy: 30.00
Round  34, Train loss: -1.468, Test loss: 0.815, Test accuracy: 64.78
Round  34: Global train loss: -1.468, Global test loss: 1.999, Global test accuracy: 30.75
Round  35, Train loss: -1.723, Test loss: 0.795, Test accuracy: 66.00
Round  35: Global train loss: -1.723, Global test loss: 1.994, Global test accuracy: 30.72
Round  36, Train loss: -1.967, Test loss: 0.767, Test accuracy: 67.35
Round  36: Global train loss: -1.967, Global test loss: 1.988, Global test accuracy: 31.38
Round  37, Train loss: -1.846, Test loss: 0.756, Test accuracy: 68.15
Round  37: Global train loss: -1.846, Global test loss: 1.980, Global test accuracy: 31.55
Round  38, Train loss: -2.289, Test loss: 0.751, Test accuracy: 67.90
Round  38: Global train loss: -2.289, Global test loss: 1.975, Global test accuracy: 32.08
Round  39, Train loss: -2.250, Test loss: 0.768, Test accuracy: 67.32
Round  39: Global train loss: -2.250, Global test loss: 1.967, Global test accuracy: 32.67
Round  40, Train loss: -1.814, Test loss: 0.773, Test accuracy: 67.25
Round  40: Global train loss: -1.814, Global test loss: 1.964, Global test accuracy: 32.73
Round  41, Train loss: -1.886, Test loss: 0.777, Test accuracy: 67.50
Round  41: Global train loss: -1.886, Global test loss: 1.960, Global test accuracy: 33.18
Round  42, Train loss: -2.105, Test loss: 0.762, Test accuracy: 67.92
Round  42: Global train loss: -2.105, Global test loss: 1.947, Global test accuracy: 33.38
Round  43, Train loss: -2.318, Test loss: 0.758, Test accuracy: 67.58
Round  43: Global train loss: -2.318, Global test loss: 1.945, Global test accuracy: 33.20
Round  44, Train loss: -2.029, Test loss: 0.750, Test accuracy: 68.48
Round  44: Global train loss: -2.029, Global test loss: 1.939, Global test accuracy: 33.18
Round  45, Train loss: -2.268, Test loss: 0.756, Test accuracy: 68.32
Round  45: Global train loss: -2.268, Global test loss: 1.937, Global test accuracy: 33.38
Round  46, Train loss: -2.466, Test loss: 0.748, Test accuracy: 68.30
Round  46: Global train loss: -2.466, Global test loss: 1.931, Global test accuracy: 33.73
Round  47, Train loss: -2.690, Test loss: 0.733, Test accuracy: 69.22
Round  47: Global train loss: -2.690, Global test loss: 1.928, Global test accuracy: 34.02
Round  48, Train loss: -2.732, Test loss: 0.756, Test accuracy: 68.80
Round  48: Global train loss: -2.732, Global test loss: 1.925, Global test accuracy: 33.53
Round  49, Train loss: -2.424, Test loss: 0.771, Test accuracy: 68.38
Round  49: Global train loss: -2.424, Global test loss: 1.923, Global test accuracy: 33.58
Round  50, Train loss: -2.971, Test loss: 0.772, Test accuracy: 68.40
Round  50: Global train loss: -2.971, Global test loss: 1.919, Global test accuracy: 34.17
Round  51, Train loss: -2.732, Test loss: 0.762, Test accuracy: 68.35
Round  51: Global train loss: -2.732, Global test loss: 1.913, Global test accuracy: 34.07
Round  52, Train loss: -2.963, Test loss: 0.750, Test accuracy: 68.45
Round  52: Global train loss: -2.963, Global test loss: 1.905, Global test accuracy: 34.03
Round  53, Train loss: -2.942, Test loss: 0.763, Test accuracy: 68.05
Round  53: Global train loss: -2.942, Global test loss: 1.903, Global test accuracy: 34.42
Round  54, Train loss: -3.205, Test loss: 0.747, Test accuracy: 69.25
Round  54: Global train loss: -3.205, Global test loss: 1.897, Global test accuracy: 34.38
Round  55, Train loss: -3.029, Test loss: 0.757, Test accuracy: 68.38
Round  55: Global train loss: -3.029, Global test loss: 1.895, Global test accuracy: 34.43
Round  56, Train loss: -3.503, Test loss: 0.776, Test accuracy: 68.58
Round  56: Global train loss: -3.503, Global test loss: 1.891, Global test accuracy: 34.07
Round  57, Train loss: -3.409, Test loss: 0.769, Test accuracy: 68.97
Round  57: Global train loss: -3.409, Global test loss: 1.885, Global test accuracy: 34.80
Round  58, Train loss: -3.211, Test loss: 0.786, Test accuracy: 68.87
Round  58: Global train loss: -3.211, Global test loss: 1.879, Global test accuracy: 35.28
Round  59, Train loss: -3.157, Test loss: 0.769, Test accuracy: 69.02
Round  59: Global train loss: -3.157, Global test loss: 1.874, Global test accuracy: 35.83
Round  60, Train loss: -3.624, Test loss: 0.774, Test accuracy: 69.18
Round  60: Global train loss: -3.624, Global test loss: 1.869, Global test accuracy: 35.63
Round  61, Train loss: -3.605, Test loss: 0.759, Test accuracy: 69.63
Round  61: Global train loss: -3.605, Global test loss: 1.871, Global test accuracy: 35.65
Round  62, Train loss: -3.387, Test loss: 0.761, Test accuracy: 70.12
Round  62: Global train loss: -3.387, Global test loss: 1.863, Global test accuracy: 36.12
Round  63, Train loss: -3.035, Test loss: 0.751, Test accuracy: 70.12
Round  63: Global train loss: -3.035, Global test loss: 1.855, Global test accuracy: 36.45
Round  64, Train loss: -3.931, Test loss: 0.757, Test accuracy: 69.98
Round  64: Global train loss: -3.931, Global test loss: 1.849, Global test accuracy: 36.92
Round  65, Train loss: -3.684, Test loss: 0.779, Test accuracy: 69.18
Round  65: Global train loss: -3.684, Global test loss: 1.848, Global test accuracy: 36.77
Round  66, Train loss: -3.370, Test loss: 0.760, Test accuracy: 69.63
Round  66: Global train loss: -3.370, Global test loss: 1.841, Global test accuracy: 37.25
Round  67, Train loss: -3.851, Test loss: 0.762, Test accuracy: 69.65
Round  67: Global train loss: -3.851, Global test loss: 1.833, Global test accuracy: 37.92
Round  68, Train loss: -3.364, Test loss: 0.740, Test accuracy: 70.33
Round  68: Global train loss: -3.364, Global test loss: 1.835, Global test accuracy: 37.92
Round  69, Train loss: -3.371, Test loss: 0.726, Test accuracy: 71.23
Round  69: Global train loss: -3.371, Global test loss: 1.829, Global test accuracy: 38.10
Round  70, Train loss: -3.807, Test loss: 0.729, Test accuracy: 70.80
Round  70: Global train loss: -3.807, Global test loss: 1.830, Global test accuracy: 37.22
Round  71, Train loss: -3.468, Test loss: 0.733, Test accuracy: 70.88
Round  71: Global train loss: -3.468, Global test loss: 1.821, Global test accuracy: 38.07
Round  72, Train loss: -3.593, Test loss: 0.738, Test accuracy: 70.15
Round  72: Global train loss: -3.593, Global test loss: 1.817, Global test accuracy: 38.27
Round  73, Train loss: -3.719, Test loss: 0.756, Test accuracy: 69.95
Round  73: Global train loss: -3.719, Global test loss: 1.814, Global test accuracy: 38.52
Round  74, Train loss: -3.520, Test loss: 0.742, Test accuracy: 70.43
Round  74: Global train loss: -3.520, Global test loss: 1.805, Global test accuracy: 38.40
Round  75, Train loss: -3.903, Test loss: 0.755, Test accuracy: 70.22
Round  75: Global train loss: -3.903, Global test loss: 1.801, Global test accuracy: 38.55
Round  76, Train loss: -4.112, Test loss: 0.762, Test accuracy: 70.42
Round  76: Global train loss: -4.112, Global test loss: 1.792, Global test accuracy: 38.72
Round  77, Train loss: -3.668, Test loss: 0.755, Test accuracy: 70.80
Round  77: Global train loss: -3.668, Global test loss: 1.785, Global test accuracy: 39.72
Round  78, Train loss: -3.677, Test loss: 0.735, Test accuracy: 71.35
Round  78: Global train loss: -3.677, Global test loss: 1.783, Global test accuracy: 39.35
Round  79, Train loss: -3.774, Test loss: 0.730, Test accuracy: 71.27
Round  79: Global train loss: -3.774, Global test loss: 1.783, Global test accuracy: 39.47
Round  80, Train loss: -4.391, Test loss: 0.718, Test accuracy: 71.88
Round  80: Global train loss: -4.391, Global test loss: 1.777, Global test accuracy: 39.03
Round  81, Train loss: -4.170, Test loss: 0.720, Test accuracy: 71.88
Round  81: Global train loss: -4.170, Global test loss: 1.774, Global test accuracy: 39.43
Round  82, Train loss: -3.820, Test loss: 0.715, Test accuracy: 72.30
Round  82: Global train loss: -3.820, Global test loss: 1.767, Global test accuracy: 40.17
Round  83, Train loss: -4.122, Test loss: 0.730, Test accuracy: 72.38
Round  83: Global train loss: -4.122, Global test loss: 1.765, Global test accuracy: 40.45
Round  84, Train loss: -4.084, Test loss: 0.736, Test accuracy: 71.82
Round  84: Global train loss: -4.084, Global test loss: 1.767, Global test accuracy: 39.92
Round  85, Train loss: -3.804, Test loss: 0.720, Test accuracy: 72.37
Round  85: Global train loss: -3.804, Global test loss: 1.759, Global test accuracy: 39.93
Round  86, Train loss: -4.140, Test loss: 0.728, Test accuracy: 72.17
Round  86: Global train loss: -4.140, Global test loss: 1.753, Global test accuracy: 40.73
Round  87, Train loss: -4.050, Test loss: 0.738, Test accuracy: 71.72
Round  87: Global train loss: -4.050, Global test loss: 1.748, Global test accuracy: 41.23
Round  88, Train loss: -4.154, Test loss: 0.732, Test accuracy: 71.60
Round  88: Global train loss: -4.154, Global test loss: 1.747, Global test accuracy: 41.35
Round  89, Train loss: -3.642, Test loss: 0.725, Test accuracy: 71.20
Round  89: Global train loss: -3.642, Global test loss: 1.744, Global test accuracy: 41.65
Round  90, Train loss: -4.084, Test loss: 0.737, Test accuracy: 70.78
Round  90: Global train loss: -4.084, Global test loss: 1.743, Global test accuracy: 41.30
Round  91, Train loss: -4.232, Test loss: 0.756, Test accuracy: 70.93
Round  91: Global train loss: -4.232, Global test loss: 1.742, Global test accuracy: 41.58
Round  92, Train loss: -3.898, Test loss: 0.745, Test accuracy: 71.05
Round  92: Global train loss: -3.898, Global test loss: 1.739, Global test accuracy: 42.05
Round  93, Train loss: -4.357, Test loss: 0.745, Test accuracy: 71.03
Round  93: Global train loss: -4.357, Global test loss: 1.734, Global test accuracy: 42.03
Round  94, Train loss: -4.316, Test loss: 0.756, Test accuracy: 70.75
Round  94: Global train loss: -4.316, Global test loss: 1.733, Global test accuracy: 41.55
Round  95, Train loss: -4.206, Test loss: 0.731, Test accuracy: 71.43
Round  95: Global train loss: -4.206, Global test loss: 1.725, Global test accuracy: 41.68
Round  96, Train loss: -4.056, Test loss: 0.732, Test accuracy: 71.60
Round  96: Global train loss: -4.056, Global test loss: 1.724, Global test accuracy: 41.82
Round  97, Train loss: -4.662, Test loss: 0.758, Test accuracy: 71.07
Round  97: Global train loss: -4.662, Global test loss: 1.719, Global test accuracy: 41.97
Round  98, Train loss: -4.059, Test loss: 0.761, Test accuracy: 70.90
Round  98: Global train loss: -4.059, Global test loss: 1.717, Global test accuracy: 42.20
Round  99, Train loss: -3.654, Test loss: 0.750, Test accuracy: 70.73
Round  99: Global train loss: -3.654, Global test loss: 1.715, Global test accuracy: 42.77
Final Round: Train loss: 0.704, Test loss: 0.668, Test accuracy: 71.95
Final Round: Global train loss: 0.704, Global test loss: 1.703, Global test accuracy: 42.88
Average accuracy final 10 rounds: 71.02833333333334
Average global accuracy final 10 rounds: 41.894999999999996
772.0395095348358
[]
[21.683333333333334, 34.266666666666666, 40.916666666666664, 42.516666666666666, 49.43333333333333, 52.5, 53.35, 56.333333333333336, 57.0, 55.15, 53.516666666666666, 53.5, 53.96666666666667, 56.983333333333334, 58.36666666666667, 59.18333333333333, 61.516666666666666, 62.483333333333334, 62.43333333333333, 62.233333333333334, 61.71666666666667, 62.333333333333336, 63.583333333333336, 63.53333333333333, 63.233333333333334, 64.81666666666666, 64.63333333333334, 65.35, 65.46666666666667, 64.66666666666667, 64.85, 64.15, 64.65, 64.06666666666666, 64.78333333333333, 66.0, 67.35, 68.15, 67.9, 67.31666666666666, 67.25, 67.5, 67.91666666666667, 67.58333333333333, 68.48333333333333, 68.31666666666666, 68.3, 69.21666666666667, 68.8, 68.38333333333334, 68.4, 68.35, 68.45, 68.05, 69.25, 68.38333333333334, 68.58333333333333, 68.96666666666667, 68.86666666666666, 69.01666666666667, 69.18333333333334, 69.63333333333334, 70.11666666666666, 70.11666666666666, 69.98333333333333, 69.18333333333334, 69.63333333333334, 69.65, 70.33333333333333, 71.23333333333333, 70.8, 70.88333333333334, 70.15, 69.95, 70.43333333333334, 70.21666666666667, 70.41666666666667, 70.8, 71.35, 71.26666666666667, 71.88333333333334, 71.88333333333334, 72.3, 72.38333333333334, 71.81666666666666, 72.36666666666666, 72.16666666666667, 71.71666666666667, 71.6, 71.2, 70.78333333333333, 70.93333333333334, 71.05, 71.03333333333333, 70.75, 71.43333333333334, 71.6, 71.06666666666666, 70.9, 70.73333333333333, 71.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.286, Test loss: 2.307, Test accuracy: 6.97 

Round   0, Global train loss: 2.286, Global test loss: 2.311, Global test accuracy: 7.02 

Round   1, Train loss: 2.284, Test loss: 2.306, Test accuracy: 9.50 

Round   1, Global train loss: 2.284, Global test loss: 2.310, Global test accuracy: 9.43 

Round   2, Train loss: 2.281, Test loss: 2.306, Test accuracy: 11.47 

Round   2, Global train loss: 2.281, Global test loss: 2.309, Global test accuracy: 11.70 

Round   3, Train loss: 2.287, Test loss: 2.309, Test accuracy: 11.75 

Round   3, Global train loss: 2.287, Global test loss: 2.309, Global test accuracy: 12.95 

Round   4, Train loss: 2.314, Test loss: 2.311, Test accuracy: 11.88 

Round   4, Global train loss: 2.314, Global test loss: 2.307, Global test accuracy: 13.33 

Round   5, Train loss: nan, Test loss: nan, Test accuracy: 11.68 

Round   5, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round   6, Train loss: nan, Test loss: nan, Test accuracy: 11.68 

Round   6, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round   7, Train loss: nan, Test loss: nan, Test accuracy: 11.72 

Round   7, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round   8, Train loss: nan, Test loss: nan, Test accuracy: 12.52 

Round   8, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round   9, Train loss: nan, Test loss: nan, Test accuracy: 12.55 

Round   9, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  10, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  10, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  11, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  11, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  12, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  12, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  13, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  13, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  14, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  14, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  15, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  15, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  16, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  16, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  17, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  17, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  18, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  18, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  19, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  19, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  20, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  20, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  21, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  21, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  22, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  22, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  23, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  23, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  24, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  24, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  25, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  25, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  26, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  26, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  27, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  27, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  28, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  28, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  29, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  29, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  30, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  30, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  31, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  31, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  32, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  32, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  33, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  33, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  34, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  34, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  35, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  35, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  36, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  36, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  37, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  37, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  38, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  38, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  39, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  39, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  40, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  40, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  41, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  41, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  42, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  42, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  43, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  43, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  44, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  44, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  45, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  45, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  46, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  46, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  47, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  47, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  48, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  48, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  49, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  49, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  50, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  50, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  51, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  51, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  52, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  52, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  53, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  53, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  54, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  54, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  55, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  55, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  56, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  56, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  57, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  57, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  58, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  58, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  59, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  59, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  60, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  60, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  61, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  61, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  62, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  62, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  63, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  63, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  64, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  64, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  65, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  65, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  66, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  66, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  67, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  67, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  68, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  68, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  69, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  69, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  70, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  70, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  71, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  71, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  72, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  72, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  73, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  73, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  74, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  74, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  75, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  75, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  76, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  76, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  77, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  77, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  78, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  78, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  79, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  79, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  80, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  80, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  81, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  81, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  82, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  82, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  83, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  83, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  84, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  84, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  85, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  85, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  86, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  86, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  87, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  87, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  88, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  88, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  89, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  89, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  90, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  90, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  91, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  91, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  92, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  92, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  93, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  93, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  94, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  94, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  95, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  95, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  96, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  96, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  97, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  97, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  98, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  98, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  99, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  99, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 100, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 100, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 101, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 101, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 102, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 102, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 103, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 103, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 104, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 104, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 105, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 105, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 106, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 106, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 107, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 107, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 108, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 108, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 109, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 109, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 110, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 110, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 111, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 111, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 112, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 112, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 113, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 113, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 114, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 114, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 115, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 115, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 116, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 116, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 117, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 117, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 118, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 118, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 119, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 119, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 120, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 120, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 121, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 121, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 122, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 122, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 123, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 123, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 124, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 124, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 125, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 125, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 126, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 126, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 127, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 127, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 128, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 128, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 129, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 129, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 130, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 130, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 131, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 131, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 132, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 132, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 133, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 133, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 134, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 134, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 135, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 135, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 136, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 136, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 137, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 137, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 138, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 138, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 139, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 139, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 140, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 140, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 141, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 141, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 142, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 142, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 143, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 143, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 144, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 144, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 145, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 145, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 146, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 146, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 147, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 147, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 148, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 148, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 149, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 149, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 150, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 150, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 151, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 151, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 152, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 152, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 153, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 153, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 154, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 154, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 155, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 155, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 156, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 156, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 157, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 157, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 158, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 158, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 159, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 159, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 160, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 160, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 161, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 161, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 162, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 162, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 163, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 163, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 164, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 164, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 165, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 165, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 166, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 166, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 167, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 167, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 168, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 168, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 169, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 169, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 170, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 170, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 171, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 171, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 172, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 172, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 173, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 173, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 174, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 174, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 175, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 175, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 176, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 176, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 177, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 177, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 178, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 178, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 179, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 179, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 180, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 180, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 181, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 181, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 182, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 182, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 183, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 183, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 184, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 184, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 185, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 185, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 186, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 186, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 187, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 187, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 188, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 188, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 189, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 189, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 190, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 190, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Average accuracy final 10 rounds: 13.333333333333337 

Average global accuracy final 10 rounds: 13.333333333333337 

2111.3643715381622
[0.984760046005249, 1.7461581230163574, 2.5038743019104004, 3.249898910522461, 4.002043008804321, 4.755427360534668, 5.5140464305877686, 6.267615795135498, 7.024605751037598, 7.780689001083374, 8.536330938339233, 9.295185327529907, 10.0485200881958, 10.806936025619507, 11.562339544296265, 12.319454431533813, 13.074677467346191, 13.833966970443726, 14.587214946746826, 15.339988708496094, 16.094449520111084, 16.85122513771057, 17.604812622070312, 18.360063076019287, 19.11344027519226, 19.872312307357788, 20.630178451538086, 21.386109352111816, 22.142802953720093, 22.899943113327026, 23.65735125541687, 24.414122581481934, 25.168102741241455, 25.92572784423828, 26.684443712234497, 27.43894052505493, 28.196707487106323, 28.952154874801636, 29.706140279769897, 30.461732149124146, 31.215744972229004, 31.972265243530273, 32.725005865097046, 33.48114633560181, 34.23526573181152, 34.99328064918518, 35.747036933898926, 36.50352382659912, 37.258352279663086, 38.0152690410614, 38.772621154785156, 39.52696990966797, 40.2810480594635, 41.03704619407654, 41.79307413101196, 42.5486946105957, 43.30692911148071, 44.0630829334259, 44.81978797912598, 45.57802772521973, 46.33398509025574, 47.091636657714844, 47.849862575531006, 48.60578465461731, 49.36351466178894, 50.12122082710266, 50.876267433166504, 51.63141703605652, 52.38634371757507, 53.14297914505005, 53.898462772369385, 54.65350031852722, 55.40982532501221, 56.168360471725464, 56.923309326171875, 57.67876076698303, 58.43407201766968, 59.192126989364624, 59.95089626312256, 60.70667314529419, 61.46024298667908, 62.21363282203674, 62.97028350830078, 63.72468852996826, 64.48190212249756, 65.23716282844543, 65.9908447265625, 66.74404811859131, 67.50276565551758, 68.25802874565125, 69.01240253448486, 69.76829242706299, 70.5281400680542, 71.28594446182251, 72.04147720336914, 72.80268621444702, 73.55601930618286, 74.31221580505371, 75.02849793434143, 75.68606042861938, 76.34633588790894, 77.00408053398132, 77.66293501853943, 78.32235646247864, 78.98043918609619, 79.63919186592102, 80.30009627342224, 80.9608747959137, 81.62082028388977, 82.2801365852356, 82.93842458724976, 83.59684443473816, 84.25412201881409, 84.91373991966248, 85.5739893913269, 86.23317742347717, 86.89341139793396, 87.55269289016724, 88.21063685417175, 88.86947536468506, 89.52931690216064, 90.19042634963989, 90.85138177871704, 91.51229906082153, 92.17275071144104, 92.83223295211792, 93.49072265625, 94.15196180343628, 94.81016135215759, 95.46954989433289, 96.13041615486145, 96.79057908058167, 97.45132088661194, 98.11153483390808, 98.76976704597473, 99.43208503723145, 100.09126949310303, 100.74865245819092, 101.4085693359375, 102.06781792640686, 102.72549366950989, 103.385018825531, 104.04622983932495, 104.70372080802917, 105.36214327812195, 106.019122838974, 106.67873573303223, 107.33656930923462, 108.00900602340698, 108.6672637462616, 109.32553815841675, 109.98363852500916, 110.64110398292542, 111.29893517494202, 111.95508170127869, 112.61546039581299, 113.2760751247406, 113.93345046043396, 114.5919497013092, 115.24815964698792, 115.90524125099182, 116.56353425979614, 117.22324776649475, 117.88052415847778, 118.53822255134583, 119.19656872749329, 119.85393238067627, 120.51259279251099, 121.17164373397827, 121.8303575515747, 122.51147723197937, 123.16789364814758, 123.82081985473633, 124.47885346412659, 125.13180994987488, 125.78985095024109, 126.45100259780884, 127.10458135604858, 127.76211428642273, 128.41684818267822, 129.07510089874268, 129.73266172409058, 130.39045190811157, 131.04584550857544, 131.6990134716034, 132.35491585731506, 133.01398587226868, 133.6717038154602, 134.3304569721222, 134.98263359069824, 135.6402130126953, 136.29340076446533, 136.9490532875061, 137.60419178009033, 138.25763535499573, 138.91639947891235, 139.5707492828369, 140.22633028030396, 140.88728046417236, 141.54354619979858, 142.2020387649536, 142.85407638549805, 143.51192617416382, 144.16992020606995, 144.82842636108398, 145.48882913589478, 146.14269018173218, 146.80005168914795, 147.45439672470093, 148.10909485816956, 148.76579976081848, 149.42086958885193, 150.07647395133972, 150.72990369796753, 151.38537430763245, 152.04125928878784, 152.69672441482544, 153.35172629356384, 154.00552916526794, 154.66070914268494, 155.3173954486847, 155.97135472297668, 156.6281361579895, 157.28231263160706, 157.9405333995819, 158.60066485404968, 159.25637936592102, 159.9137179851532, 160.56747198104858, 161.22395586967468, 161.88072419166565, 162.53875279426575, 163.19580054283142, 163.848778963089, 164.5051634311676, 165.1588213443756, 165.81546568870544, 166.47537302970886, 167.1284613609314, 167.7847864627838, 168.43798446655273, 169.09405755996704, 169.74998259544373, 170.4025182723999, 171.06032586097717, 171.71493935585022, 172.37281274795532, 173.03091144561768, 173.68631052970886, 174.348326921463, 175.00355315208435, 175.66178035736084, 176.31600785255432, 176.97566413879395, 177.63376879692078, 178.28977346420288, 178.94889187812805, 179.60264492034912, 180.2583887577057, 180.91624546051025, 181.57021141052246, 182.22728657722473, 182.87988471984863, 183.53874921798706, 184.19861245155334, 184.85241436958313, 185.50856733322144, 186.16126608848572, 186.8184871673584, 187.47727179527283, 188.13453364372253, 188.79148840904236, 189.44578075408936, 190.10301327705383, 190.76124334335327, 191.4188358783722, 192.07627773284912, 192.72979950904846, 193.39051032066345, 194.04425501823425, 194.701993227005, 195.35870885849, 196.01324653625488, 196.67219591140747, 197.3241240978241, 197.98284244537354, 198.64267539978027, 199.29589319229126, 199.95072746276855, 200.60317277908325, 201.26086521148682, 201.91538262367249, 202.5723717212677, 203.22832560539246, 203.88412475585938, 204.54002904891968, 205.19432878494263, 205.84697008132935, 206.50343465805054, 207.15803837776184, 208.47371172904968]
[6.966666666666667, 9.5, 11.466666666666667, 11.75, 11.883333333333333, 11.683333333333334, 11.683333333333334, 11.716666666666667, 12.516666666666667, 12.55, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.186, Test loss: 2.152, Test accuracy: 27.60 

Round   0, Global train loss: 1.186, Global test loss: 2.485, Global test accuracy: 21.47 

Round   1, Train loss: 0.954, Test loss: 1.604, Test accuracy: 38.17 

Round   1, Global train loss: 0.954, Global test loss: 2.159, Global test accuracy: 23.33 

Round   2, Train loss: 0.916, Test loss: 1.442, Test accuracy: 48.93 

Round   2, Global train loss: 0.916, Global test loss: 2.319, Global test accuracy: 24.32 

Round   3, Train loss: 0.888, Test loss: 1.013, Test accuracy: 57.80 

Round   3, Global train loss: 0.888, Global test loss: 2.138, Global test accuracy: 25.63 

Round   4, Train loss: 0.832, Test loss: 0.926, Test accuracy: 59.60 

Round   4, Global train loss: 0.832, Global test loss: 2.004, Global test accuracy: 23.87 

Round   5, Train loss: 0.759, Test loss: 0.842, Test accuracy: 63.48 

Round   5, Global train loss: 0.759, Global test loss: 2.073, Global test accuracy: 27.38 

Round   6, Train loss: 0.707, Test loss: 0.833, Test accuracy: 62.87 

Round   6, Global train loss: 0.707, Global test loss: 2.061, Global test accuracy: 24.35 

Round   7, Train loss: 0.629, Test loss: 0.836, Test accuracy: 63.72 

Round   7, Global train loss: 0.629, Global test loss: 2.257, Global test accuracy: 28.93 

Round   8, Train loss: 0.687, Test loss: 0.802, Test accuracy: 65.27 

Round   8, Global train loss: 0.687, Global test loss: 2.119, Global test accuracy: 30.42 

Round   9, Train loss: 0.689, Test loss: 0.826, Test accuracy: 64.22 

Round   9, Global train loss: 0.689, Global test loss: 2.050, Global test accuracy: 29.97 

Round  10, Train loss: 0.746, Test loss: 0.721, Test accuracy: 68.47 

Round  10, Global train loss: 0.746, Global test loss: 2.137, Global test accuracy: 23.28 

Round  11, Train loss: 0.491, Test loss: 0.729, Test accuracy: 67.95 

Round  11, Global train loss: 0.491, Global test loss: 2.132, Global test accuracy: 28.30 

Round  12, Train loss: 0.626, Test loss: 0.714, Test accuracy: 68.80 

Round  12, Global train loss: 0.626, Global test loss: 2.014, Global test accuracy: 32.25 

Round  13, Train loss: 0.625, Test loss: 0.711, Test accuracy: 69.33 

Round  13, Global train loss: 0.625, Global test loss: 2.220, Global test accuracy: 20.60 

Round  14, Train loss: 0.547, Test loss: 0.725, Test accuracy: 69.02 

Round  14, Global train loss: 0.547, Global test loss: 2.307, Global test accuracy: 24.40 

Round  15, Train loss: 0.520, Test loss: 0.717, Test accuracy: 69.05 

Round  15, Global train loss: 0.520, Global test loss: 2.097, Global test accuracy: 20.62 

Round  16, Train loss: 0.513, Test loss: 0.720, Test accuracy: 69.42 

Round  16, Global train loss: 0.513, Global test loss: 2.240, Global test accuracy: 30.42 

Round  17, Train loss: 0.467, Test loss: 0.731, Test accuracy: 69.47 

Round  17, Global train loss: 0.467, Global test loss: 2.078, Global test accuracy: 31.07 

Round  18, Train loss: 0.614, Test loss: 0.738, Test accuracy: 69.47 

Round  18, Global train loss: 0.614, Global test loss: 2.284, Global test accuracy: 17.03 

Round  19, Train loss: 0.606, Test loss: 0.714, Test accuracy: 70.98 

Round  19, Global train loss: 0.606, Global test loss: 2.249, Global test accuracy: 23.57 

Round  20, Train loss: 0.564, Test loss: 0.697, Test accuracy: 71.55 

Round  20, Global train loss: 0.564, Global test loss: 2.441, Global test accuracy: 16.70 

Round  21, Train loss: 0.537, Test loss: 0.700, Test accuracy: 71.38 

Round  21, Global train loss: 0.537, Global test loss: 2.099, Global test accuracy: 26.07 

Round  22, Train loss: 0.460, Test loss: 0.690, Test accuracy: 71.63 

Round  22, Global train loss: 0.460, Global test loss: 2.130, Global test accuracy: 22.10 

Round  23, Train loss: 0.425, Test loss: 0.727, Test accuracy: 71.03 

Round  23, Global train loss: 0.425, Global test loss: 2.105, Global test accuracy: 26.77 

Round  24, Train loss: 0.456, Test loss: 0.721, Test accuracy: 71.23 

Round  24, Global train loss: 0.456, Global test loss: 2.171, Global test accuracy: 28.90 

Round  25, Train loss: 0.588, Test loss: 0.707, Test accuracy: 71.68 

Round  25, Global train loss: 0.588, Global test loss: 2.477, Global test accuracy: 16.82 

Round  26, Train loss: 0.467, Test loss: 0.700, Test accuracy: 72.35 

Round  26, Global train loss: 0.467, Global test loss: 2.260, Global test accuracy: 26.83 

Round  27, Train loss: 0.504, Test loss: 0.713, Test accuracy: 72.63 

Round  27, Global train loss: 0.504, Global test loss: 2.162, Global test accuracy: 21.62 

Round  28, Train loss: 0.364, Test loss: 0.694, Test accuracy: 73.20 

Round  28, Global train loss: 0.364, Global test loss: 2.065, Global test accuracy: 26.17 

Round  29, Train loss: 0.463, Test loss: 0.686, Test accuracy: 73.50 

Round  29, Global train loss: 0.463, Global test loss: 2.085, Global test accuracy: 24.62 

Round  30, Train loss: 0.395, Test loss: 0.682, Test accuracy: 73.83 

Round  30, Global train loss: 0.395, Global test loss: 2.201, Global test accuracy: 25.80 

Round  31, Train loss: 0.392, Test loss: 0.683, Test accuracy: 73.92 

Round  31, Global train loss: 0.392, Global test loss: 2.083, Global test accuracy: 24.63 

Round  32, Train loss: 0.469, Test loss: 0.689, Test accuracy: 73.95 

Round  32, Global train loss: 0.469, Global test loss: 2.278, Global test accuracy: 15.62 

Round  33, Train loss: 0.378, Test loss: 0.689, Test accuracy: 74.40 

Round  33, Global train loss: 0.378, Global test loss: 2.204, Global test accuracy: 19.18 

Round  34, Train loss: 0.367, Test loss: 0.702, Test accuracy: 74.23 

Round  34, Global train loss: 0.367, Global test loss: 2.039, Global test accuracy: 28.63 

Round  35, Train loss: 0.367, Test loss: 0.691, Test accuracy: 74.80 

Round  35, Global train loss: 0.367, Global test loss: 1.970, Global test accuracy: 33.82 

Round  36, Train loss: 0.370, Test loss: 0.704, Test accuracy: 74.87 

Round  36, Global train loss: 0.370, Global test loss: 2.880, Global test accuracy: 20.55 

Round  37, Train loss: 0.264, Test loss: 0.704, Test accuracy: 74.72 

Round  37, Global train loss: 0.264, Global test loss: 1.966, Global test accuracy: 26.87 

Round  38, Train loss: 0.359, Test loss: 0.741, Test accuracy: 73.88 

Round  38, Global train loss: 0.359, Global test loss: 2.145, Global test accuracy: 26.43 

Round  39, Train loss: 0.342, Test loss: 0.705, Test accuracy: 74.83 

Round  39, Global train loss: 0.342, Global test loss: 2.102, Global test accuracy: 25.18 

Round  40, Train loss: 0.283, Test loss: 0.700, Test accuracy: 75.28 

Round  40, Global train loss: 0.283, Global test loss: 2.116, Global test accuracy: 27.30 

Round  41, Train loss: 0.229, Test loss: 0.712, Test accuracy: 75.37 

Round  41, Global train loss: 0.229, Global test loss: 2.038, Global test accuracy: 28.37 

Round  42, Train loss: 0.207, Test loss: 0.749, Test accuracy: 74.92 

Round  42, Global train loss: 0.207, Global test loss: 2.328, Global test accuracy: 22.35 

Round  43, Train loss: 0.329, Test loss: 0.769, Test accuracy: 75.22 

Round  43, Global train loss: 0.329, Global test loss: 2.179, Global test accuracy: 21.82 

Round  44, Train loss: 0.254, Test loss: 0.794, Test accuracy: 75.02 

Round  44, Global train loss: 0.254, Global test loss: 2.002, Global test accuracy: 29.75 

Round  45, Train loss: 0.288, Test loss: 0.779, Test accuracy: 74.83 

Round  45, Global train loss: 0.288, Global test loss: 1.984, Global test accuracy: 27.50 

Round  46, Train loss: 0.254, Test loss: 0.775, Test accuracy: 75.35 

Round  46, Global train loss: 0.254, Global test loss: 1.950, Global test accuracy: 29.47 

Round  47, Train loss: 0.253, Test loss: 0.801, Test accuracy: 75.33 

Round  47, Global train loss: 0.253, Global test loss: 2.180, Global test accuracy: 33.82 

Round  48, Train loss: 0.171, Test loss: 0.782, Test accuracy: 75.02 

Round  48, Global train loss: 0.171, Global test loss: 2.237, Global test accuracy: 24.28 

Round  49, Train loss: 0.242, Test loss: 0.787, Test accuracy: 75.50 

Round  49, Global train loss: 0.242, Global test loss: 2.058, Global test accuracy: 30.35 

Round  50, Train loss: 0.182, Test loss: 0.805, Test accuracy: 75.52 

Round  50, Global train loss: 0.182, Global test loss: 2.097, Global test accuracy: 24.88 

Round  51, Train loss: 0.292, Test loss: 0.804, Test accuracy: 75.92 

Round  51, Global train loss: 0.292, Global test loss: 2.038, Global test accuracy: 30.60 

Round  52, Train loss: 0.178, Test loss: 0.798, Test accuracy: 76.17 

Round  52, Global train loss: 0.178, Global test loss: 2.472, Global test accuracy: 26.40 

Round  53, Train loss: 0.232, Test loss: 0.798, Test accuracy: 76.33 

Round  53, Global train loss: 0.232, Global test loss: 2.140, Global test accuracy: 32.30 

Round  54, Train loss: 0.158, Test loss: 0.812, Test accuracy: 76.08 

Round  54, Global train loss: 0.158, Global test loss: 2.456, Global test accuracy: 28.58 

Round  55, Train loss: 0.173, Test loss: 0.809, Test accuracy: 75.85 

Round  55, Global train loss: 0.173, Global test loss: 2.185, Global test accuracy: 21.08 

Round  56, Train loss: 0.226, Test loss: 0.814, Test accuracy: 75.92 

Round  56, Global train loss: 0.226, Global test loss: 2.160, Global test accuracy: 19.72 

Round  57, Train loss: 0.218, Test loss: 0.837, Test accuracy: 75.68 

Round  57, Global train loss: 0.218, Global test loss: 2.153, Global test accuracy: 20.18 

Round  58, Train loss: 0.170, Test loss: 0.829, Test accuracy: 76.00 

Round  58, Global train loss: 0.170, Global test loss: 2.031, Global test accuracy: 31.60 

Round  59, Train loss: 0.176, Test loss: 0.834, Test accuracy: 76.22 

Round  59, Global train loss: 0.176, Global test loss: 2.184, Global test accuracy: 25.20 

Round  60, Train loss: 0.187, Test loss: 0.854, Test accuracy: 75.73 

Round  60, Global train loss: 0.187, Global test loss: 2.188, Global test accuracy: 23.23 

Round  61, Train loss: 0.217, Test loss: 0.866, Test accuracy: 75.67 

Round  61, Global train loss: 0.217, Global test loss: 2.462, Global test accuracy: 22.77 

Round  62, Train loss: 0.192, Test loss: 0.884, Test accuracy: 75.47 

Round  62, Global train loss: 0.192, Global test loss: 2.001, Global test accuracy: 33.05 

Round  63, Train loss: 0.160, Test loss: 0.885, Test accuracy: 75.50 

Round  63, Global train loss: 0.160, Global test loss: 2.174, Global test accuracy: 30.32 

Round  64, Train loss: 0.215, Test loss: 0.889, Test accuracy: 76.17 

Round  64, Global train loss: 0.215, Global test loss: 2.141, Global test accuracy: 22.32 

Round  65, Train loss: 0.155, Test loss: 0.886, Test accuracy: 76.17 

Round  65, Global train loss: 0.155, Global test loss: 2.096, Global test accuracy: 27.77 

Round  66, Train loss: 0.122, Test loss: 0.886, Test accuracy: 76.60 

Round  66, Global train loss: 0.122, Global test loss: 2.132, Global test accuracy: 21.17 

Round  67, Train loss: 0.137, Test loss: 0.873, Test accuracy: 76.58 

Round  67, Global train loss: 0.137, Global test loss: 2.122, Global test accuracy: 23.12 

Round  68, Train loss: 0.175, Test loss: 0.910, Test accuracy: 76.43 

Round  68, Global train loss: 0.175, Global test loss: 2.438, Global test accuracy: 16.82 

Round  69, Train loss: 0.104, Test loss: 0.901, Test accuracy: 77.02 

Round  69, Global train loss: 0.104, Global test loss: 2.223, Global test accuracy: 27.60 

Round  70, Train loss: 0.135, Test loss: 0.892, Test accuracy: 77.17 

Round  70, Global train loss: 0.135, Global test loss: 2.052, Global test accuracy: 21.80 

Round  71, Train loss: 0.125, Test loss: 0.909, Test accuracy: 77.07 

Round  71, Global train loss: 0.125, Global test loss: 1.902, Global test accuracy: 32.43 

Round  72, Train loss: 0.099, Test loss: 0.941, Test accuracy: 76.90 

Round  72, Global train loss: 0.099, Global test loss: 2.041, Global test accuracy: 23.78 

Round  73, Train loss: 0.108, Test loss: 0.963, Test accuracy: 76.50 

Round  73, Global train loss: 0.108, Global test loss: 2.099, Global test accuracy: 20.48 

Round  74, Train loss: 0.123, Test loss: 0.977, Test accuracy: 76.27 

Round  74, Global train loss: 0.123, Global test loss: 2.137, Global test accuracy: 24.27 

Round  75, Train loss: 0.132, Test loss: 0.974, Test accuracy: 76.35 

Round  75, Global train loss: 0.132, Global test loss: 2.073, Global test accuracy: 22.12 

Round  76, Train loss: 0.146, Test loss: 0.984, Test accuracy: 76.03 

Round  76, Global train loss: 0.146, Global test loss: 2.060, Global test accuracy: 24.32 

Round  77, Train loss: 0.094, Test loss: 0.998, Test accuracy: 75.98 

Round  77, Global train loss: 0.094, Global test loss: 2.147, Global test accuracy: 24.45 

Round  78, Train loss: 0.102, Test loss: 1.007, Test accuracy: 75.88 

Round  78, Global train loss: 0.102, Global test loss: 2.102, Global test accuracy: 22.23 

Round  79, Train loss: 0.114, Test loss: 1.023, Test accuracy: 76.12 

Round  79, Global train loss: 0.114, Global test loss: 2.454, Global test accuracy: 19.45 

Round  80, Train loss: 0.085, Test loss: 1.032, Test accuracy: 76.22 

Round  80, Global train loss: 0.085, Global test loss: 2.096, Global test accuracy: 23.60 

Round  81, Train loss: 0.128, Test loss: 1.005, Test accuracy: 76.65 

Round  81, Global train loss: 0.128, Global test loss: 2.189, Global test accuracy: 18.87 

Round  82, Train loss: 0.090, Test loss: 1.004, Test accuracy: 77.05 

Round  82, Global train loss: 0.090, Global test loss: 2.049, Global test accuracy: 26.65 

Round  83, Train loss: 0.079, Test loss: 1.006, Test accuracy: 77.20 

Round  83, Global train loss: 0.079, Global test loss: 2.041, Global test accuracy: 25.07 

Round  84, Train loss: 0.074, Test loss: 1.036, Test accuracy: 76.88 

Round  84, Global train loss: 0.074, Global test loss: 1.956, Global test accuracy: 33.08 

Round  85, Train loss: 0.072, Test loss: 1.040, Test accuracy: 76.93 

Round  85, Global train loss: 0.072, Global test loss: 2.141, Global test accuracy: 24.27 

Round  86, Train loss: 0.102, Test loss: 1.059, Test accuracy: 76.78 

Round  86, Global train loss: 0.102, Global test loss: 2.015, Global test accuracy: 32.37 

Round  87, Train loss: 0.072, Test loss: 1.061, Test accuracy: 76.72 

Round  87, Global train loss: 0.072, Global test loss: 2.037, Global test accuracy: 35.53 

Round  88, Train loss: 0.100, Test loss: 1.072, Test accuracy: 76.70 

Round  88, Global train loss: 0.100, Global test loss: 2.154, Global test accuracy: 17.50 

Round  89, Train loss: 0.075, Test loss: 1.112, Test accuracy: 76.22 

Round  89, Global train loss: 0.075, Global test loss: 2.512, Global test accuracy: 18.87 

Round  90, Train loss: 0.067, Test loss: 1.113, Test accuracy: 75.88 

Round  90, Global train loss: 0.067, Global test loss: 1.886, Global test accuracy: 35.05 

Round  91, Train loss: 0.091, Test loss: 1.076, Test accuracy: 76.22 

Round  91, Global train loss: 0.091, Global test loss: 2.026, Global test accuracy: 28.32 

Round  92, Train loss: 0.083, Test loss: 1.092, Test accuracy: 76.00 

Round  92, Global train loss: 0.083, Global test loss: 2.102, Global test accuracy: 27.70 

Round  93, Train loss: 0.084, Test loss: 1.112, Test accuracy: 75.83 

Round  93, Global train loss: 0.084, Global test loss: 1.989, Global test accuracy: 28.55 

Round  94, Train loss: 0.087, Test loss: 1.107, Test accuracy: 76.45 

Round  94, Global train loss: 0.087, Global test loss: 2.167, Global test accuracy: 31.08 

Round  95, Train loss: 0.067, Test loss: 1.126, Test accuracy: 76.73 

Round  95, Global train loss: 0.067, Global test loss: 2.218, Global test accuracy: 24.87 

Round  96, Train loss: 0.088, Test loss: 1.107, Test accuracy: 76.90 

Round  96, Global train loss: 0.088, Global test loss: 2.165, Global test accuracy: 29.27 

Round  97, Train loss: 0.079, Test loss: 1.126, Test accuracy: 76.47 

Round  97, Global train loss: 0.079, Global test loss: 2.140, Global test accuracy: 21.50 

Round  98, Train loss: 0.099, Test loss: 1.146, Test accuracy: 76.63 

Round  98, Global train loss: 0.099, Global test loss: 2.308, Global test accuracy: 16.32 

Round  99, Train loss: 0.080, Test loss: 1.171, Test accuracy: 76.48 

Round  99, Global train loss: 0.080, Global test loss: 2.129, Global test accuracy: 21.75 

Final Round, Train loss: 0.066, Test loss: 1.175, Test accuracy: 76.60 

Final Round, Global train loss: 0.066, Global test loss: 2.129, Global test accuracy: 21.75 

Average accuracy final 10 rounds: 76.36000000000001 

Average global accuracy final 10 rounds: 26.44 

721.8561205863953
[0.8930599689483643, 1.5545291900634766, 2.2192890644073486, 2.8790252208709717, 3.537165880203247, 4.197411060333252, 4.854288816452026, 5.513638734817505, 6.226978302001953, 6.931794881820679, 7.634299039840698, 8.338053703308105, 9.04163408279419, 9.75565505027771, 10.467972993850708, 11.176090955734253, 11.879343748092651, 12.592931270599365, 13.301241159439087, 14.01030969619751, 14.71830940246582, 15.419541120529175, 16.12500762939453, 16.834479808807373, 17.538957118988037, 18.24685549736023, 18.956267833709717, 19.665531158447266, 20.36786675453186, 21.071399688720703, 21.771254301071167, 22.46969699859619, 23.174983263015747, 23.875337839126587, 24.580182790756226, 25.291508197784424, 25.9899640083313, 26.693819046020508, 27.399301528930664, 28.098257303237915, 28.79750919342041, 29.49609351158142, 30.197558879852295, 30.89363956451416, 31.5895357131958, 32.26868438720703, 32.95498991012573, 33.64144849777222, 34.329277992248535, 35.02196717262268, 35.71241879463196, 36.40187454223633, 37.09066724777222, 37.780375480651855, 38.468918800354004, 39.156673431396484, 39.84336447715759, 40.53136229515076, 41.2183141708374, 41.903114795684814, 42.59564566612244, 43.290501832962036, 43.982683181762695, 44.67862248420715, 45.36816596984863, 46.059574842453, 46.751705169677734, 47.44451117515564, 48.13483762741089, 48.824965953826904, 49.52437472343445, 50.222158432006836, 50.91574811935425, 51.60967421531677, 52.30204749107361, 52.9973509311676, 53.69437217712402, 54.39081382751465, 55.090917348861694, 55.784991979599, 56.48249173164368, 57.180731534957886, 57.878060817718506, 58.57434320449829, 59.26326322555542, 59.95374345779419, 60.645090103149414, 61.33323359489441, 62.0264618396759, 62.71972131729126, 63.41083121299744, 64.10270881652832, 64.79589295387268, 65.48716378211975, 66.17966771125793, 66.8718729019165, 67.56143069267273, 68.25178146362305, 68.94385957717896, 69.63473701477051, 71.0255708694458]
[27.6, 38.166666666666664, 48.93333333333333, 57.8, 59.6, 63.483333333333334, 62.86666666666667, 63.71666666666667, 65.26666666666667, 64.21666666666667, 68.46666666666667, 67.95, 68.8, 69.33333333333333, 69.01666666666667, 69.05, 69.41666666666667, 69.46666666666667, 69.46666666666667, 70.98333333333333, 71.55, 71.38333333333334, 71.63333333333334, 71.03333333333333, 71.23333333333333, 71.68333333333334, 72.35, 72.63333333333334, 73.2, 73.5, 73.83333333333333, 73.91666666666667, 73.95, 74.4, 74.23333333333333, 74.8, 74.86666666666666, 74.71666666666667, 73.88333333333334, 74.83333333333333, 75.28333333333333, 75.36666666666666, 74.91666666666667, 75.21666666666667, 75.01666666666667, 74.83333333333333, 75.35, 75.33333333333333, 75.01666666666667, 75.5, 75.51666666666667, 75.91666666666667, 76.16666666666667, 76.33333333333333, 76.08333333333333, 75.85, 75.91666666666667, 75.68333333333334, 76.0, 76.21666666666667, 75.73333333333333, 75.66666666666667, 75.46666666666667, 75.5, 76.16666666666667, 76.16666666666667, 76.6, 76.58333333333333, 76.43333333333334, 77.01666666666667, 77.16666666666667, 77.06666666666666, 76.9, 76.5, 76.26666666666667, 76.35, 76.03333333333333, 75.98333333333333, 75.88333333333334, 76.11666666666666, 76.21666666666667, 76.65, 77.05, 77.2, 76.88333333333334, 76.93333333333334, 76.78333333333333, 76.71666666666667, 76.7, 76.21666666666667, 75.88333333333334, 76.21666666666667, 76.0, 75.83333333333333, 76.45, 76.73333333333333, 76.9, 76.46666666666667, 76.63333333333334, 76.48333333333333, 76.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.195, Test loss: 1.864, Test accuracy: 28.32 

Round   0, Global train loss: 1.195, Global test loss: 2.246, Global test accuracy: 16.90 

Round   1, Train loss: 1.011, Test loss: 1.771, Test accuracy: 34.52 

Round   1, Global train loss: 1.011, Global test loss: 2.431, Global test accuracy: 18.93 

Round   2, Train loss: 0.901, Test loss: 1.359, Test accuracy: 48.28 

Round   2, Global train loss: 0.901, Global test loss: 2.385, Global test accuracy: 21.92 

Round   3, Train loss: 0.985, Test loss: 1.082, Test accuracy: 53.33 

Round   3, Global train loss: 0.985, Global test loss: 2.141, Global test accuracy: 21.75 

Round   4, Train loss: 0.906, Test loss: 1.155, Test accuracy: 53.57 

Round   4, Global train loss: 0.906, Global test loss: 2.345, Global test accuracy: 21.92 

Round   5, Train loss: 0.806, Test loss: 0.963, Test accuracy: 59.12 

Round   5, Global train loss: 0.806, Global test loss: 1.934, Global test accuracy: 31.78 

Round   6, Train loss: 0.821, Test loss: 0.958, Test accuracy: 60.42 

Round   6, Global train loss: 0.821, Global test loss: 2.194, Global test accuracy: 30.60 

Round   7, Train loss: 0.761, Test loss: 0.894, Test accuracy: 62.83 

Round   7, Global train loss: 0.761, Global test loss: 1.893, Global test accuracy: 34.50 

Round   8, Train loss: 0.794, Test loss: 0.758, Test accuracy: 67.33 

Round   8, Global train loss: 0.794, Global test loss: 1.838, Global test accuracy: 35.37 

Round   9, Train loss: 0.810, Test loss: 0.719, Test accuracy: 68.78 

Round   9, Global train loss: 0.810, Global test loss: 1.972, Global test accuracy: 34.53 

Round  10, Train loss: 0.666, Test loss: 0.711, Test accuracy: 69.42 

Round  10, Global train loss: 0.666, Global test loss: 1.773, Global test accuracy: 39.82 

Round  11, Train loss: 0.726, Test loss: 0.714, Test accuracy: 69.73 

Round  11, Global train loss: 0.726, Global test loss: 1.863, Global test accuracy: 32.98 

Round  12, Train loss: 0.619, Test loss: 0.704, Test accuracy: 70.18 

Round  12, Global train loss: 0.619, Global test loss: 1.927, Global test accuracy: 33.98 

Round  13, Train loss: 0.671, Test loss: 0.684, Test accuracy: 71.02 

Round  13, Global train loss: 0.671, Global test loss: 1.719, Global test accuracy: 40.48 

Round  14, Train loss: 0.703, Test loss: 0.678, Test accuracy: 71.30 

Round  14, Global train loss: 0.703, Global test loss: 1.722, Global test accuracy: 39.78 

Round  15, Train loss: 0.596, Test loss: 0.677, Test accuracy: 71.85 

Round  15, Global train loss: 0.596, Global test loss: 1.831, Global test accuracy: 39.23 

Round  16, Train loss: 0.605, Test loss: 0.660, Test accuracy: 72.68 

Round  16, Global train loss: 0.605, Global test loss: 1.586, Global test accuracy: 44.40 

Round  17, Train loss: 0.590, Test loss: 0.653, Test accuracy: 73.32 

Round  17, Global train loss: 0.590, Global test loss: 1.491, Global test accuracy: 48.37 

Round  18, Train loss: 0.612, Test loss: 0.637, Test accuracy: 73.85 

Round  18, Global train loss: 0.612, Global test loss: 1.603, Global test accuracy: 42.55 

Round  19, Train loss: 0.534, Test loss: 0.631, Test accuracy: 74.00 

Round  19, Global train loss: 0.534, Global test loss: 1.640, Global test accuracy: 42.97 

Round  20, Train loss: 0.585, Test loss: 0.623, Test accuracy: 74.57 

Round  20, Global train loss: 0.585, Global test loss: 1.729, Global test accuracy: 39.37 

Round  21, Train loss: 0.528, Test loss: 0.611, Test accuracy: 75.52 

Round  21, Global train loss: 0.528, Global test loss: 1.596, Global test accuracy: 45.17 

Round  22, Train loss: 0.462, Test loss: 0.594, Test accuracy: 76.17 

Round  22, Global train loss: 0.462, Global test loss: 2.051, Global test accuracy: 36.07 

Round  23, Train loss: 0.578, Test loss: 0.590, Test accuracy: 76.35 

Round  23, Global train loss: 0.578, Global test loss: 1.534, Global test accuracy: 43.48 

Round  24, Train loss: 0.524, Test loss: 0.589, Test accuracy: 76.43 

Round  24, Global train loss: 0.524, Global test loss: 1.517, Global test accuracy: 46.28 

Round  25, Train loss: 0.549, Test loss: 0.612, Test accuracy: 75.43 

Round  25, Global train loss: 0.549, Global test loss: 1.463, Global test accuracy: 48.10 

Round  26, Train loss: 0.553, Test loss: 0.615, Test accuracy: 75.17 

Round  26, Global train loss: 0.553, Global test loss: 1.527, Global test accuracy: 44.05 

Round  27, Train loss: 0.498, Test loss: 0.619, Test accuracy: 74.92 

Round  27, Global train loss: 0.498, Global test loss: 1.512, Global test accuracy: 47.45 

Round  28, Train loss: 0.432, Test loss: 0.604, Test accuracy: 75.65 

Round  28, Global train loss: 0.432, Global test loss: 1.491, Global test accuracy: 48.70 

Round  29, Train loss: 0.518, Test loss: 0.589, Test accuracy: 76.53 

Round  29, Global train loss: 0.518, Global test loss: 1.423, Global test accuracy: 51.17 

Round  30, Train loss: 0.416, Test loss: 0.591, Test accuracy: 76.33 

Round  30, Global train loss: 0.416, Global test loss: 1.527, Global test accuracy: 47.17 

Round  31, Train loss: 0.533, Test loss: 0.562, Test accuracy: 77.73 

Round  31, Global train loss: 0.533, Global test loss: 1.593, Global test accuracy: 47.37 

Round  32, Train loss: 0.603, Test loss: 0.558, Test accuracy: 77.90 

Round  32, Global train loss: 0.603, Global test loss: 1.752, Global test accuracy: 36.95 

Round  33, Train loss: 0.466, Test loss: 0.555, Test accuracy: 78.28 

Round  33, Global train loss: 0.466, Global test loss: 1.494, Global test accuracy: 48.93 

Round  34, Train loss: 0.397, Test loss: 0.569, Test accuracy: 77.63 

Round  34, Global train loss: 0.397, Global test loss: 1.369, Global test accuracy: 50.23 

Round  35, Train loss: 0.456, Test loss: 0.593, Test accuracy: 76.90 

Round  35, Global train loss: 0.456, Global test loss: 1.564, Global test accuracy: 48.80 

Round  36, Train loss: 0.466, Test loss: 0.565, Test accuracy: 77.93 

Round  36, Global train loss: 0.466, Global test loss: 1.338, Global test accuracy: 53.38 

Round  37, Train loss: 0.388, Test loss: 0.587, Test accuracy: 77.47 

Round  37, Global train loss: 0.388, Global test loss: 1.461, Global test accuracy: 51.40 

Round  38, Train loss: 0.410, Test loss: 0.594, Test accuracy: 77.48 

Round  38, Global train loss: 0.410, Global test loss: 1.683, Global test accuracy: 46.73 

Round  39, Train loss: 0.374, Test loss: 0.590, Test accuracy: 77.63 

Round  39, Global train loss: 0.374, Global test loss: 1.461, Global test accuracy: 48.77 

Round  40, Train loss: 0.329, Test loss: 0.589, Test accuracy: 77.52 

Round  40, Global train loss: 0.329, Global test loss: 1.913, Global test accuracy: 41.92 

Round  41, Train loss: 0.414, Test loss: 0.569, Test accuracy: 78.12 

Round  41, Global train loss: 0.414, Global test loss: 1.745, Global test accuracy: 48.13 

Round  42, Train loss: 0.415, Test loss: 0.580, Test accuracy: 77.93 

Round  42, Global train loss: 0.415, Global test loss: 1.529, Global test accuracy: 50.00 

Round  43, Train loss: 0.477, Test loss: 0.575, Test accuracy: 78.50 

Round  43, Global train loss: 0.477, Global test loss: 1.413, Global test accuracy: 50.57 

Round  44, Train loss: 0.454, Test loss: 0.607, Test accuracy: 77.65 

Round  44, Global train loss: 0.454, Global test loss: 1.443, Global test accuracy: 52.53 

Round  45, Train loss: 0.445, Test loss: 0.596, Test accuracy: 77.63 

Round  45, Global train loss: 0.445, Global test loss: 1.547, Global test accuracy: 50.32 

Round  46, Train loss: 0.520, Test loss: 0.607, Test accuracy: 77.45 

Round  46, Global train loss: 0.520, Global test loss: 1.599, Global test accuracy: 47.07 

Round  47, Train loss: 0.336, Test loss: 0.565, Test accuracy: 78.77 

Round  47, Global train loss: 0.336, Global test loss: 1.444, Global test accuracy: 51.65 

Round  48, Train loss: 0.442, Test loss: 0.575, Test accuracy: 78.52 

Round  48, Global train loss: 0.442, Global test loss: 1.512, Global test accuracy: 49.92 

Round  49, Train loss: 0.321, Test loss: 0.578, Test accuracy: 78.78 

Round  49, Global train loss: 0.321, Global test loss: 1.455, Global test accuracy: 55.28 

Round  50, Train loss: 0.405, Test loss: 0.601, Test accuracy: 78.00 

Round  50, Global train loss: 0.405, Global test loss: 1.564, Global test accuracy: 48.40 

Round  51, Train loss: 0.355, Test loss: 0.601, Test accuracy: 78.20 

Round  51, Global train loss: 0.355, Global test loss: 1.627, Global test accuracy: 44.50 

Round  52, Train loss: 0.383, Test loss: 0.591, Test accuracy: 78.07 

Round  52, Global train loss: 0.383, Global test loss: 1.460, Global test accuracy: 51.30 

Round  53, Train loss: 0.441, Test loss: 0.552, Test accuracy: 79.43 

Round  53, Global train loss: 0.441, Global test loss: 1.490, Global test accuracy: 49.73 

Round  54, Train loss: 0.402, Test loss: 0.559, Test accuracy: 79.98 

Round  54, Global train loss: 0.402, Global test loss: 1.419, Global test accuracy: 52.78 

Round  55, Train loss: 0.435, Test loss: 0.570, Test accuracy: 79.25 

Round  55, Global train loss: 0.435, Global test loss: 1.502, Global test accuracy: 47.27 

Round  56, Train loss: 0.393, Test loss: 0.570, Test accuracy: 79.62 

Round  56, Global train loss: 0.393, Global test loss: 1.472, Global test accuracy: 49.37 

Round  57, Train loss: 0.374, Test loss: 0.594, Test accuracy: 78.58 

Round  57, Global train loss: 0.374, Global test loss: 1.580, Global test accuracy: 47.17 

Round  58, Train loss: 0.354, Test loss: 0.585, Test accuracy: 78.97 

Round  58, Global train loss: 0.354, Global test loss: 1.391, Global test accuracy: 54.55 

Round  59, Train loss: 0.309, Test loss: 0.594, Test accuracy: 78.60 

Round  59, Global train loss: 0.309, Global test loss: 1.618, Global test accuracy: 49.80 

Round  60, Train loss: 0.348, Test loss: 0.585, Test accuracy: 78.83 

Round  60, Global train loss: 0.348, Global test loss: 1.419, Global test accuracy: 54.87 

Round  61, Train loss: 0.339, Test loss: 0.569, Test accuracy: 79.47 

Round  61, Global train loss: 0.339, Global test loss: 1.688, Global test accuracy: 48.63 

Round  62, Train loss: 0.390, Test loss: 0.568, Test accuracy: 79.77 

Round  62, Global train loss: 0.390, Global test loss: 1.526, Global test accuracy: 50.33 

Round  63, Train loss: 0.354, Test loss: 0.569, Test accuracy: 80.03 

Round  63, Global train loss: 0.354, Global test loss: 1.764, Global test accuracy: 44.22 

Round  64, Train loss: 0.292, Test loss: 0.556, Test accuracy: 80.50 

Round  64, Global train loss: 0.292, Global test loss: 1.767, Global test accuracy: 48.98 

Round  65, Train loss: 0.338, Test loss: 0.563, Test accuracy: 80.20 

Round  65, Global train loss: 0.338, Global test loss: 1.467, Global test accuracy: 54.77 

Round  66, Train loss: 0.343, Test loss: 0.556, Test accuracy: 80.70 

Round  66, Global train loss: 0.343, Global test loss: 1.357, Global test accuracy: 55.22 

Round  67, Train loss: 0.323, Test loss: 0.566, Test accuracy: 80.37 

Round  67, Global train loss: 0.323, Global test loss: 1.488, Global test accuracy: 50.87 

Round  68, Train loss: 0.299, Test loss: 0.556, Test accuracy: 80.72 

Round  68, Global train loss: 0.299, Global test loss: 1.559, Global test accuracy: 46.32 

Round  69, Train loss: 0.363, Test loss: 0.555, Test accuracy: 81.13 

Round  69, Global train loss: 0.363, Global test loss: 1.638, Global test accuracy: 49.35 

Round  70, Train loss: 0.311, Test loss: 0.568, Test accuracy: 80.92 

Round  70, Global train loss: 0.311, Global test loss: 1.420, Global test accuracy: 56.65 

Round  71, Train loss: 0.320, Test loss: 0.556, Test accuracy: 81.28 

Round  71, Global train loss: 0.320, Global test loss: 1.541, Global test accuracy: 50.30 

Round  72, Train loss: 0.283, Test loss: 0.560, Test accuracy: 80.97 

Round  72, Global train loss: 0.283, Global test loss: 1.666, Global test accuracy: 47.83 

Round  73, Train loss: 0.313, Test loss: 0.558, Test accuracy: 80.77 

Round  73, Global train loss: 0.313, Global test loss: 1.706, Global test accuracy: 47.73 

Round  74, Train loss: 0.301, Test loss: 0.577, Test accuracy: 80.42 

Round  74, Global train loss: 0.301, Global test loss: 1.507, Global test accuracy: 51.92 

Round  75, Train loss: 0.343, Test loss: 0.566, Test accuracy: 80.40 

Round  75, Global train loss: 0.343, Global test loss: 1.618, Global test accuracy: 49.63 

Round  76, Train loss: 0.310, Test loss: 0.569, Test accuracy: 80.57 

Round  76, Global train loss: 0.310, Global test loss: 1.453, Global test accuracy: 56.77 

Round  77, Train loss: 0.235, Test loss: 0.582, Test accuracy: 80.30 

Round  77, Global train loss: 0.235, Global test loss: 1.526, Global test accuracy: 56.78 

Round  78, Train loss: 0.255, Test loss: 0.566, Test accuracy: 80.67 

Round  78, Global train loss: 0.255, Global test loss: 1.335, Global test accuracy: 56.52 

Round  79, Train loss: 0.232, Test loss: 0.554, Test accuracy: 81.18 

Round  79, Global train loss: 0.232, Global test loss: 1.370, Global test accuracy: 59.27 

Round  80, Train loss: 0.340, Test loss: 0.574, Test accuracy: 80.62 

Round  80, Global train loss: 0.340, Global test loss: 1.558, Global test accuracy: 48.82 

Round  81, Train loss: 0.228, Test loss: 0.581, Test accuracy: 80.87 

Round  81, Global train loss: 0.228, Global test loss: 1.497, Global test accuracy: 56.12 

Round  82, Train loss: 0.261, Test loss: 0.576, Test accuracy: 80.80 

Round  82, Global train loss: 0.261, Global test loss: 1.393, Global test accuracy: 54.87 

Round  83, Train loss: 0.248, Test loss: 0.589, Test accuracy: 80.95 

Round  83, Global train loss: 0.248, Global test loss: 1.552, Global test accuracy: 55.37 

Round  84, Train loss: 0.237, Test loss: 0.573, Test accuracy: 81.62 

Round  84, Global train loss: 0.237, Global test loss: 1.521, Global test accuracy: 56.80 

Round  85, Train loss: 0.265, Test loss: 0.569, Test accuracy: 81.87 

Round  85, Global train loss: 0.265, Global test loss: 1.520, Global test accuracy: 53.32 

Round  86, Train loss: 0.220, Test loss: 0.582, Test accuracy: 81.72 

Round  86, Global train loss: 0.220, Global test loss: 1.455, Global test accuracy: 54.80 

Round  87, Train loss: 0.224, Test loss: 0.593, Test accuracy: 81.37 

Round  87, Global train loss: 0.224, Global test loss: 1.929, Global test accuracy: 51.77 

Round  88, Train loss: 0.216, Test loss: 0.584, Test accuracy: 81.35 

Round  88, Global train loss: 0.216, Global test loss: 1.488, Global test accuracy: 54.58 

Round  89, Train loss: 0.245, Test loss: 0.568, Test accuracy: 81.63 

Round  89, Global train loss: 0.245, Global test loss: 1.413, Global test accuracy: 56.58 

Round  90, Train loss: 0.260, Test loss: 0.595, Test accuracy: 81.02 

Round  90, Global train loss: 0.260, Global test loss: 1.532, Global test accuracy: 53.83 

Round  91, Train loss: 0.222, Test loss: 0.583, Test accuracy: 81.75 

Round  91, Global train loss: 0.222, Global test loss: 1.397, Global test accuracy: 58.13 

Round  92, Train loss: 0.268, Test loss: 0.609, Test accuracy: 81.38 

Round  92, Global train loss: 0.268, Global test loss: 1.539, Global test accuracy: 51.70 

Round  93, Train loss: 0.205, Test loss: 0.593, Test accuracy: 81.85 

Round  93, Global train loss: 0.205, Global test loss: 1.574, Global test accuracy: 54.83 

Round  94, Train loss: 0.231, Test loss: 0.601, Test accuracy: 82.07 

Round  94, Global train loss: 0.231, Global test loss: 1.501, Global test accuracy: 54.17 

Round  95, Train loss: 0.245, Test loss: 0.585, Test accuracy: 82.42 

Round  95, Global train loss: 0.245, Global test loss: 1.567, Global test accuracy: 56.88 

Round  96, Train loss: 0.177, Test loss: 0.625, Test accuracy: 81.60 

Round  96, Global train loss: 0.177, Global test loss: 1.784, Global test accuracy: 52.18 

Round  97, Train loss: 0.249, Test loss: 0.627, Test accuracy: 81.38 

Round  97, Global train loss: 0.249, Global test loss: 1.302, Global test accuracy: 57.63 

Round  98, Train loss: 0.228, Test loss: 0.630, Test accuracy: 81.22 

Round  98, Global train loss: 0.228, Global test loss: 1.470, Global test accuracy: 54.22 

Round  99, Train loss: 0.194, Test loss: 0.651, Test accuracy: 81.02 

Round  99, Global train loss: 0.194, Global test loss: 1.385, Global test accuracy: 58.98 

Final Round, Train loss: 0.176, Test loss: 0.664, Test accuracy: 81.45 

Final Round, Global train loss: 0.176, Global test loss: 1.385, Global test accuracy: 58.98 

Average accuracy final 10 rounds: 81.57 

Average global accuracy final 10 rounds: 55.25666666666667 

723.5057032108307
[0.9152414798736572, 1.6121470928192139, 2.3078999519348145, 3.0017507076263428, 3.691452741622925, 4.3848793506622314, 5.0736401081085205, 5.768985986709595, 6.4590113162994385, 7.149232864379883, 7.840460300445557, 8.529095649719238, 9.219870328903198, 9.90789532661438, 10.603907823562622, 11.295033693313599, 11.983581304550171, 12.669400691986084, 13.359670639038086, 14.048990488052368, 14.738107919692993, 15.428405046463013, 16.121495723724365, 16.812711000442505, 17.503475666046143, 18.192710876464844, 18.88617181777954, 19.578423023223877, 20.271183252334595, 20.962440967559814, 21.655689239501953, 22.349793195724487, 23.04293990135193, 23.73628544807434, 24.423792362213135, 25.116488933563232, 25.806482315063477, 26.503130435943604, 27.195652723312378, 27.886103868484497, 28.575690507888794, 29.263664960861206, 29.953571319580078, 30.64737629890442, 31.33695888519287, 32.02697730064392, 32.71652388572693, 33.41310405731201, 34.104822635650635, 34.798585653305054, 35.49136972427368, 36.185142040252686, 36.876569509506226, 37.57003355026245, 38.26193952560425, 38.954017877578735, 39.64770007133484, 40.34109807014465, 41.03179144859314, 41.72284150123596, 42.41408443450928, 43.10737705230713, 43.796204805374146, 44.490456104278564, 45.18046593666077, 45.87228083610535, 46.563244581222534, 47.25706887245178, 47.950554609298706, 48.64108753204346, 49.33464741706848, 50.03111457824707, 50.72684025764465, 51.42237687110901, 52.11540937423706, 52.810627698898315, 53.50300717353821, 54.19975137710571, 54.89557242393494, 55.59038782119751, 56.283496379852295, 56.97705554962158, 57.67244863510132, 58.36845827102661, 59.06063628196716, 59.752934217453, 60.44343566894531, 61.137242794036865, 61.83107399940491, 62.52517652511597, 63.215500354766846, 63.91089987754822, 64.60040950775146, 65.29233884811401, 65.98573350906372, 66.6841688156128, 67.37597870826721, 68.06802177429199, 68.75900721549988, 69.45305728912354, 70.83743858337402]
[28.316666666666666, 34.516666666666666, 48.28333333333333, 53.333333333333336, 53.56666666666667, 59.11666666666667, 60.416666666666664, 62.833333333333336, 67.33333333333333, 68.78333333333333, 69.41666666666667, 69.73333333333333, 70.18333333333334, 71.01666666666667, 71.3, 71.85, 72.68333333333334, 73.31666666666666, 73.85, 74.0, 74.56666666666666, 75.51666666666667, 76.16666666666667, 76.35, 76.43333333333334, 75.43333333333334, 75.16666666666667, 74.91666666666667, 75.65, 76.53333333333333, 76.33333333333333, 77.73333333333333, 77.9, 78.28333333333333, 77.63333333333334, 76.9, 77.93333333333334, 77.46666666666667, 77.48333333333333, 77.63333333333334, 77.51666666666667, 78.11666666666666, 77.93333333333334, 78.5, 77.65, 77.63333333333334, 77.45, 78.76666666666667, 78.51666666666667, 78.78333333333333, 78.0, 78.2, 78.06666666666666, 79.43333333333334, 79.98333333333333, 79.25, 79.61666666666666, 78.58333333333333, 78.96666666666667, 78.6, 78.83333333333333, 79.46666666666667, 79.76666666666667, 80.03333333333333, 80.5, 80.2, 80.7, 80.36666666666666, 80.71666666666667, 81.13333333333334, 80.91666666666667, 81.28333333333333, 80.96666666666667, 80.76666666666667, 80.41666666666667, 80.4, 80.56666666666666, 80.3, 80.66666666666667, 81.18333333333334, 80.61666666666666, 80.86666666666666, 80.8, 80.95, 81.61666666666666, 81.86666666666666, 81.71666666666667, 81.36666666666666, 81.35, 81.63333333333334, 81.01666666666667, 81.75, 81.38333333333334, 81.85, 82.06666666666666, 82.41666666666667, 81.6, 81.38333333333334, 81.21666666666667, 81.01666666666667, 81.45]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.635, Test loss: 2.098, Test accuracy: 19.72 

Round   1, Train loss: 1.116, Test loss: 2.430, Test accuracy: 22.02 

Round   2, Train loss: 0.994, Test loss: 1.560, Test accuracy: 37.87 

Round   3, Train loss: 0.907, Test loss: 1.653, Test accuracy: 43.62 

Round   4, Train loss: 0.983, Test loss: 1.317, Test accuracy: 52.92 

Round   5, Train loss: 0.902, Test loss: 1.033, Test accuracy: 56.07 

Round   6, Train loss: 0.887, Test loss: 0.887, Test accuracy: 61.00 

Round   7, Train loss: 0.795, Test loss: 0.785, Test accuracy: 64.80 

Round   8, Train loss: 0.754, Test loss: 0.773, Test accuracy: 65.13 

Round   9, Train loss: 0.840, Test loss: 0.765, Test accuracy: 65.85 

Round  10, Train loss: 0.737, Test loss: 0.746, Test accuracy: 66.85 

Round  11, Train loss: 0.715, Test loss: 0.706, Test accuracy: 69.48 

Round  12, Train loss: 0.754, Test loss: 0.688, Test accuracy: 70.58 

Round  13, Train loss: 0.773, Test loss: 0.678, Test accuracy: 71.02 

Round  14, Train loss: 0.653, Test loss: 0.663, Test accuracy: 71.08 

Round  15, Train loss: 0.583, Test loss: 0.636, Test accuracy: 72.55 

Round  16, Train loss: 0.701, Test loss: 0.637, Test accuracy: 73.25 

Round  17, Train loss: 0.664, Test loss: 0.628, Test accuracy: 73.75 

Round  18, Train loss: 0.677, Test loss: 0.634, Test accuracy: 73.42 

Round  19, Train loss: 0.621, Test loss: 0.618, Test accuracy: 73.45 

Round  20, Train loss: 0.582, Test loss: 0.613, Test accuracy: 73.92 

Round  21, Train loss: 0.580, Test loss: 0.604, Test accuracy: 74.25 

Round  22, Train loss: 0.597, Test loss: 0.603, Test accuracy: 74.73 

Round  23, Train loss: 0.604, Test loss: 0.604, Test accuracy: 74.40 

Round  24, Train loss: 0.606, Test loss: 0.582, Test accuracy: 75.77 

Round  25, Train loss: 0.559, Test loss: 0.578, Test accuracy: 75.93 

Round  26, Train loss: 0.522, Test loss: 0.569, Test accuracy: 76.27 

Round  27, Train loss: 0.602, Test loss: 0.588, Test accuracy: 75.35 

Round  28, Train loss: 0.485, Test loss: 0.572, Test accuracy: 75.68 

Round  29, Train loss: 0.543, Test loss: 0.572, Test accuracy: 76.12 

Round  30, Train loss: 0.518, Test loss: 0.550, Test accuracy: 76.97 

Round  31, Train loss: 0.536, Test loss: 0.553, Test accuracy: 76.42 

Round  32, Train loss: 0.561, Test loss: 0.544, Test accuracy: 77.38 

Round  33, Train loss: 0.637, Test loss: 0.538, Test accuracy: 77.90 

Round  34, Train loss: 0.564, Test loss: 0.536, Test accuracy: 77.72 

Round  35, Train loss: 0.567, Test loss: 0.543, Test accuracy: 77.78 

Round  36, Train loss: 0.520, Test loss: 0.534, Test accuracy: 77.72 

Round  37, Train loss: 0.437, Test loss: 0.533, Test accuracy: 77.67 

Round  38, Train loss: 0.409, Test loss: 0.517, Test accuracy: 78.10 

Round  39, Train loss: 0.522, Test loss: 0.515, Test accuracy: 78.43 

Round  40, Train loss: 0.479, Test loss: 0.502, Test accuracy: 79.10 

Round  41, Train loss: 0.462, Test loss: 0.497, Test accuracy: 79.42 

Round  42, Train loss: 0.544, Test loss: 0.498, Test accuracy: 79.37 

Round  43, Train loss: 0.449, Test loss: 0.488, Test accuracy: 79.62 

Round  44, Train loss: 0.476, Test loss: 0.493, Test accuracy: 79.17 

Round  45, Train loss: 0.391, Test loss: 0.492, Test accuracy: 79.43 

Round  46, Train loss: 0.389, Test loss: 0.489, Test accuracy: 79.47 

Round  47, Train loss: 0.439, Test loss: 0.483, Test accuracy: 79.85 

Round  48, Train loss: 0.478, Test loss: 0.481, Test accuracy: 80.48 

Round  49, Train loss: 0.470, Test loss: 0.473, Test accuracy: 80.45 

Round  50, Train loss: 0.473, Test loss: 0.472, Test accuracy: 80.25 

Round  51, Train loss: 0.476, Test loss: 0.484, Test accuracy: 79.77 

Round  52, Train loss: 0.405, Test loss: 0.467, Test accuracy: 80.30 

Round  53, Train loss: 0.414, Test loss: 0.466, Test accuracy: 80.65 

Round  54, Train loss: 0.476, Test loss: 0.474, Test accuracy: 80.45 

Round  55, Train loss: 0.434, Test loss: 0.477, Test accuracy: 80.25 

Round  56, Train loss: 0.409, Test loss: 0.472, Test accuracy: 80.60 

Round  57, Train loss: 0.441, Test loss: 0.472, Test accuracy: 80.78 

Round  58, Train loss: 0.446, Test loss: 0.470, Test accuracy: 80.57 

Round  59, Train loss: 0.425, Test loss: 0.468, Test accuracy: 80.62 

Round  60, Train loss: 0.456, Test loss: 0.463, Test accuracy: 80.82 

Round  61, Train loss: 0.333, Test loss: 0.476, Test accuracy: 80.92 

Round  62, Train loss: 0.451, Test loss: 0.472, Test accuracy: 80.75 

Round  63, Train loss: 0.356, Test loss: 0.462, Test accuracy: 81.07 

Round  64, Train loss: 0.389, Test loss: 0.472, Test accuracy: 80.48 

Round  65, Train loss: 0.417, Test loss: 0.477, Test accuracy: 80.77 

Round  66, Train loss: 0.331, Test loss: 0.466, Test accuracy: 81.38 

Round  67, Train loss: 0.471, Test loss: 0.463, Test accuracy: 81.07 

Round  68, Train loss: 0.401, Test loss: 0.461, Test accuracy: 81.30 

Round  69, Train loss: 0.381, Test loss: 0.472, Test accuracy: 80.80 

Round  70, Train loss: 0.366, Test loss: 0.450, Test accuracy: 81.68 

Round  71, Train loss: 0.330, Test loss: 0.436, Test accuracy: 82.25 

Round  72, Train loss: 0.370, Test loss: 0.441, Test accuracy: 81.95 

Round  73, Train loss: 0.316, Test loss: 0.455, Test accuracy: 81.60 

Round  74, Train loss: 0.390, Test loss: 0.448, Test accuracy: 81.62 

Round  75, Train loss: 0.341, Test loss: 0.439, Test accuracy: 82.12 

Round  76, Train loss: 0.327, Test loss: 0.437, Test accuracy: 82.33 

Round  77, Train loss: 0.399, Test loss: 0.436, Test accuracy: 82.25 

Round  78, Train loss: 0.399, Test loss: 0.436, Test accuracy: 82.17 

Round  79, Train loss: 0.277, Test loss: 0.443, Test accuracy: 82.15 

Round  80, Train loss: 0.335, Test loss: 0.438, Test accuracy: 82.57 

Round  81, Train loss: 0.367, Test loss: 0.446, Test accuracy: 82.22 

Round  82, Train loss: 0.280, Test loss: 0.438, Test accuracy: 82.22 

Round  83, Train loss: 0.333, Test loss: 0.457, Test accuracy: 81.88 

Round  84, Train loss: 0.328, Test loss: 0.444, Test accuracy: 82.20 

Round  85, Train loss: 0.361, Test loss: 0.435, Test accuracy: 82.53 

Round  86, Train loss: 0.281, Test loss: 0.436, Test accuracy: 82.77 

Round  87, Train loss: 0.344, Test loss: 0.446, Test accuracy: 82.03 

Round  88, Train loss: 0.307, Test loss: 0.442, Test accuracy: 82.92 

Round  89, Train loss: 0.274, Test loss: 0.449, Test accuracy: 82.68 

Round  90, Train loss: 0.267, Test loss: 0.443, Test accuracy: 82.88 

Round  91, Train loss: 0.306, Test loss: 0.431, Test accuracy: 82.92 

Round  92, Train loss: 0.302, Test loss: 0.444, Test accuracy: 82.77 

Round  93, Train loss: 0.304, Test loss: 0.440, Test accuracy: 82.55 

Round  94, Train loss: 0.272, Test loss: 0.437, Test accuracy: 83.02 

Round  95, Train loss: 0.302, Test loss: 0.439, Test accuracy: 82.95 

Round  96, Train loss: 0.258, Test loss: 0.433, Test accuracy: 83.08 

Round  97, Train loss: 0.329, Test loss: 0.451, Test accuracy: 82.60 

Round  98, Train loss: 0.220, Test loss: 0.438, Test accuracy: 82.97 

Round  99, Train loss: 0.289, Test loss: 0.433, Test accuracy: 83.17 

Final Round, Train loss: 0.251, Test loss: 0.448, Test accuracy: 82.78 

Average accuracy final 10 rounds: 82.89 

539.1791398525238
[0.886775016784668, 1.5159523487091064, 2.145561933517456, 2.7772216796875, 3.406111478805542, 4.034162521362305, 4.662420272827148, 5.292591094970703, 5.922510385513306, 6.552264213562012, 7.182695150375366, 7.811790466308594, 8.438890218734741, 9.067229270935059, 9.695522546768188, 10.32590937614441, 10.960617780685425, 11.591928482055664, 12.218764066696167, 12.846424341201782, 13.472298622131348, 14.100128650665283, 14.726964712142944, 15.35469365119934, 15.984202146530151, 16.611108541488647, 17.235823392868042, 17.862561225891113, 18.48885726928711, 19.11523723602295, 19.740867853164673, 20.371469497680664, 21.00118374824524, 21.635256052017212, 22.26197099685669, 22.891316413879395, 23.52059841156006, 24.150053024291992, 24.783287286758423, 25.412886381149292, 26.04320502281189, 26.676172971725464, 27.30604338645935, 27.935822248458862, 28.56443691253662, 29.19427752494812, 29.823557376861572, 30.45192813873291, 31.079861640930176, 31.71055316925049, 32.33842420578003, 32.9691903591156, 33.60259747505188, 34.22997713088989, 34.858843088150024, 35.48802089691162, 36.11862802505493, 36.754435539245605, 37.38712978363037, 38.020681381225586, 38.655611991882324, 39.28859829902649, 39.91840934753418, 40.54849290847778, 41.179431438446045, 41.80940341949463, 42.4396812915802, 43.07605051994324, 43.713085651397705, 44.34693503379822, 44.98387360572815, 45.61679220199585, 46.252872467041016, 46.88583755493164, 47.52401661872864, 48.155428886413574, 48.787094831466675, 49.42005109786987, 50.05569052696228, 50.6876482963562, 51.319685220718384, 51.95647573471069, 52.58720946311951, 53.22168302536011, 53.85284352302551, 54.48530840873718, 55.118837118148804, 55.74889802932739, 56.3770956993103, 57.01140737533569, 57.644127368927, 58.27689337730408, 58.909088373184204, 59.540802001953125, 60.17364454269409, 60.80941438674927, 61.440922498703, 62.07648682594299, 62.709161043167114, 63.344308614730835, 64.4604823589325]
[19.716666666666665, 22.016666666666666, 37.86666666666667, 43.61666666666667, 52.916666666666664, 56.06666666666667, 61.0, 64.8, 65.13333333333334, 65.85, 66.85, 69.48333333333333, 70.58333333333333, 71.01666666666667, 71.08333333333333, 72.55, 73.25, 73.75, 73.41666666666667, 73.45, 73.91666666666667, 74.25, 74.73333333333333, 74.4, 75.76666666666667, 75.93333333333334, 76.26666666666667, 75.35, 75.68333333333334, 76.11666666666666, 76.96666666666667, 76.41666666666667, 77.38333333333334, 77.9, 77.71666666666667, 77.78333333333333, 77.71666666666667, 77.66666666666667, 78.1, 78.43333333333334, 79.1, 79.41666666666667, 79.36666666666666, 79.61666666666666, 79.16666666666667, 79.43333333333334, 79.46666666666667, 79.85, 80.48333333333333, 80.45, 80.25, 79.76666666666667, 80.3, 80.65, 80.45, 80.25, 80.6, 80.78333333333333, 80.56666666666666, 80.61666666666666, 80.81666666666666, 80.91666666666667, 80.75, 81.06666666666666, 80.48333333333333, 80.76666666666667, 81.38333333333334, 81.06666666666666, 81.3, 80.8, 81.68333333333334, 82.25, 81.95, 81.6, 81.61666666666666, 82.11666666666666, 82.33333333333333, 82.25, 82.16666666666667, 82.15, 82.56666666666666, 82.21666666666667, 82.21666666666667, 81.88333333333334, 82.2, 82.53333333333333, 82.76666666666667, 82.03333333333333, 82.91666666666667, 82.68333333333334, 82.88333333333334, 82.91666666666667, 82.76666666666667, 82.55, 83.01666666666667, 82.95, 83.08333333333333, 82.6, 82.96666666666667, 83.16666666666667, 82.78333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.246, Test loss: 2.094, Test accuracy: 23.38 

Round   1, Train loss: 1.030, Test loss: 2.022, Test accuracy: 28.45 

Round   2, Train loss: 0.997, Test loss: 1.500, Test accuracy: 45.37 

Round   3, Train loss: 0.899, Test loss: 1.386, Test accuracy: 46.00 

Round   4, Train loss: 0.799, Test loss: 1.075, Test accuracy: 60.23 

Round   5, Train loss: 0.789, Test loss: 0.975, Test accuracy: 62.33 

Round   6, Train loss: 0.780, Test loss: 0.884, Test accuracy: 64.67 

Round   7, Train loss: 0.782, Test loss: 0.820, Test accuracy: 65.92 

Round   8, Train loss: 0.724, Test loss: 0.748, Test accuracy: 71.15 

Round   9, Train loss: 0.645, Test loss: 0.712, Test accuracy: 72.20 

Round  10, Train loss: 0.631, Test loss: 0.687, Test accuracy: 72.00 

Round  11, Train loss: 0.590, Test loss: 0.685, Test accuracy: 72.15 

Round  12, Train loss: 0.537, Test loss: 0.678, Test accuracy: 72.37 

Round  13, Train loss: 0.535, Test loss: 0.628, Test accuracy: 74.42 

Round  14, Train loss: 0.584, Test loss: 0.639, Test accuracy: 73.43 

Round  15, Train loss: 0.488, Test loss: 0.615, Test accuracy: 74.22 

Round  16, Train loss: 0.614, Test loss: 0.618, Test accuracy: 73.82 

Round  17, Train loss: 0.542, Test loss: 0.591, Test accuracy: 74.65 

Round  18, Train loss: 0.506, Test loss: 0.594, Test accuracy: 74.58 

Round  19, Train loss: 0.500, Test loss: 0.578, Test accuracy: 75.40 

Round  20, Train loss: 0.627, Test loss: 0.567, Test accuracy: 76.27 

Round  21, Train loss: 0.469, Test loss: 0.556, Test accuracy: 76.48 

Round  22, Train loss: 0.521, Test loss: 0.557, Test accuracy: 77.30 

Round  23, Train loss: 0.533, Test loss: 0.541, Test accuracy: 77.50 

Round  24, Train loss: 0.497, Test loss: 0.545, Test accuracy: 77.57 

Round  25, Train loss: 0.531, Test loss: 0.539, Test accuracy: 78.02 

Round  26, Train loss: 0.531, Test loss: 0.523, Test accuracy: 78.75 

Round  27, Train loss: 0.376, Test loss: 0.516, Test accuracy: 78.87 

Round  28, Train loss: 0.443, Test loss: 0.520, Test accuracy: 79.07 

Round  29, Train loss: 0.409, Test loss: 0.508, Test accuracy: 79.73 

Round  30, Train loss: 0.426, Test loss: 0.513, Test accuracy: 79.20 

Round  31, Train loss: 0.436, Test loss: 0.515, Test accuracy: 78.92 

Round  32, Train loss: 0.446, Test loss: 0.518, Test accuracy: 78.78 

Round  33, Train loss: 0.418, Test loss: 0.502, Test accuracy: 80.00 

Round  34, Train loss: 0.363, Test loss: 0.492, Test accuracy: 79.98 

Round  35, Train loss: 0.437, Test loss: 0.508, Test accuracy: 79.87 

Round  36, Train loss: 0.464, Test loss: 0.493, Test accuracy: 80.25 

Round  37, Train loss: 0.381, Test loss: 0.503, Test accuracy: 80.00 

Round  38, Train loss: 0.363, Test loss: 0.503, Test accuracy: 80.42 

Round  39, Train loss: 0.529, Test loss: 0.486, Test accuracy: 80.92 

Round  40, Train loss: 0.343, Test loss: 0.479, Test accuracy: 81.13 

Round  41, Train loss: 0.363, Test loss: 0.480, Test accuracy: 80.92 

Round  42, Train loss: 0.273, Test loss: 0.485, Test accuracy: 81.23 

Round  43, Train loss: 0.363, Test loss: 0.476, Test accuracy: 81.12 

Round  44, Train loss: 0.420, Test loss: 0.478, Test accuracy: 81.55 

Round  45, Train loss: 0.360, Test loss: 0.478, Test accuracy: 81.50 

Round  46, Train loss: 0.328, Test loss: 0.487, Test accuracy: 81.48 

Round  47, Train loss: 0.407, Test loss: 0.479, Test accuracy: 81.45 

Round  48, Train loss: 0.381, Test loss: 0.476, Test accuracy: 81.50 

Round  49, Train loss: 0.403, Test loss: 0.468, Test accuracy: 81.95 

Round  50, Train loss: 0.342, Test loss: 0.483, Test accuracy: 81.32 

Round  51, Train loss: 0.372, Test loss: 0.477, Test accuracy: 81.12 

Round  52, Train loss: 0.296, Test loss: 0.470, Test accuracy: 81.63 

Round  53, Train loss: 0.273, Test loss: 0.474, Test accuracy: 81.38 

Round  54, Train loss: 0.356, Test loss: 0.463, Test accuracy: 81.93 

Round  55, Train loss: 0.301, Test loss: 0.469, Test accuracy: 81.85 

Round  56, Train loss: 0.311, Test loss: 0.468, Test accuracy: 82.28 

Round  57, Train loss: 0.326, Test loss: 0.466, Test accuracy: 82.17 

Round  58, Train loss: 0.275, Test loss: 0.484, Test accuracy: 82.12 

Round  59, Train loss: 0.244, Test loss: 0.465, Test accuracy: 82.23 

Round  60, Train loss: 0.300, Test loss: 0.474, Test accuracy: 82.70 

Round  61, Train loss: 0.273, Test loss: 0.464, Test accuracy: 82.65 

Round  62, Train loss: 0.327, Test loss: 0.459, Test accuracy: 82.83 

Round  63, Train loss: 0.290, Test loss: 0.462, Test accuracy: 82.95 

Round  64, Train loss: 0.263, Test loss: 0.475, Test accuracy: 82.67 

Round  65, Train loss: 0.338, Test loss: 0.472, Test accuracy: 82.57 

Round  66, Train loss: 0.273, Test loss: 0.474, Test accuracy: 82.55 

Round  67, Train loss: 0.223, Test loss: 0.480, Test accuracy: 82.83 

Round  68, Train loss: 0.266, Test loss: 0.486, Test accuracy: 82.45 

Round  69, Train loss: 0.197, Test loss: 0.475, Test accuracy: 83.07 

Round  70, Train loss: 0.166, Test loss: 0.476, Test accuracy: 83.15 

Round  71, Train loss: 0.249, Test loss: 0.488, Test accuracy: 82.30 

Round  72, Train loss: 0.226, Test loss: 0.510, Test accuracy: 82.42 

Round  73, Train loss: 0.306, Test loss: 0.480, Test accuracy: 82.58 

Round  74, Train loss: 0.274, Test loss: 0.477, Test accuracy: 82.85 

Round  75, Train loss: 0.253, Test loss: 0.490, Test accuracy: 82.60 

Round  76, Train loss: 0.252, Test loss: 0.493, Test accuracy: 82.35 

Round  77, Train loss: 0.231, Test loss: 0.495, Test accuracy: 82.83 

Round  78, Train loss: 0.202, Test loss: 0.511, Test accuracy: 82.83 

Round  79, Train loss: 0.245, Test loss: 0.494, Test accuracy: 82.82 

Round  80, Train loss: 0.241, Test loss: 0.502, Test accuracy: 82.52 

Round  81, Train loss: 0.223, Test loss: 0.518, Test accuracy: 82.38 

Round  82, Train loss: 0.245, Test loss: 0.514, Test accuracy: 82.18 

Round  83, Train loss: 0.180, Test loss: 0.507, Test accuracy: 82.45 

Round  84, Train loss: 0.213, Test loss: 0.513, Test accuracy: 82.58 

Round  85, Train loss: 0.205, Test loss: 0.502, Test accuracy: 82.92 

Round  86, Train loss: 0.168, Test loss: 0.517, Test accuracy: 83.05 

Round  87, Train loss: 0.143, Test loss: 0.520, Test accuracy: 82.80 

Round  88, Train loss: 0.202, Test loss: 0.503, Test accuracy: 82.63 

Round  89, Train loss: 0.154, Test loss: 0.525, Test accuracy: 82.92 

Round  90, Train loss: 0.132, Test loss: 0.524, Test accuracy: 82.92 

Round  91, Train loss: 0.124, Test loss: 0.522, Test accuracy: 82.90 

Round  92, Train loss: 0.236, Test loss: 0.507, Test accuracy: 82.80 

Round  93, Train loss: 0.224, Test loss: 0.538, Test accuracy: 82.20 

Round  94, Train loss: 0.198, Test loss: 0.523, Test accuracy: 82.85 

Round  95, Train loss: 0.187, Test loss: 0.549, Test accuracy: 82.45 

Round  96, Train loss: 0.180, Test loss: 0.548, Test accuracy: 82.07 

Round  97, Train loss: 0.206, Test loss: 0.537, Test accuracy: 82.08 

Round  98, Train loss: 0.178, Test loss: 0.552, Test accuracy: 82.10 

Round  99, Train loss: 0.173, Test loss: 0.563, Test accuracy: 81.80 

Final Round, Train loss: 0.140, Test loss: 0.549, Test accuracy: 82.83 

Average accuracy final 10 rounds: 82.41666666666666 

520.3152987957001
[0.8865742683410645, 1.5470788478851318, 2.206979990005493, 2.8646163940429688, 3.5185108184814453, 4.200225353240967, 4.799659967422485, 5.394917249679565, 5.993027925491333, 6.592972993850708, 7.19025182723999, 7.78762412071228, 8.386938095092773, 8.98382306098938, 9.581828355789185, 10.181421756744385, 10.77451467514038, 11.369916439056396, 11.964991092681885, 12.561266422271729, 13.159364938735962, 13.760313987731934, 14.357917547225952, 14.958148002624512, 15.558764696121216, 16.155442237854004, 16.753427028656006, 17.3516366481781, 17.94469666481018, 18.538333892822266, 19.132458448410034, 19.724937915802002, 20.319634914398193, 20.91232681274414, 21.505319595336914, 22.099313259124756, 22.693792819976807, 23.28738784790039, 23.8850200176239, 24.484410285949707, 25.082117795944214, 25.678983449935913, 26.27778697013855, 26.875690698623657, 27.472009420394897, 28.072756052017212, 28.67171335220337, 29.268372058868408, 29.867260694503784, 30.465931177139282, 31.063432216644287, 31.66158437728882, 32.25953197479248, 32.85697960853577, 33.455106258392334, 34.050708532333374, 34.64442825317383, 35.23862981796265, 35.833022594451904, 36.42713236808777, 37.02237629890442, 37.617658615112305, 38.210498571395874, 38.804686069488525, 39.40022611618042, 39.99426078796387, 40.58986186981201, 41.187872648239136, 41.78586792945862, 42.381232500076294, 42.98014426231384, 43.57922172546387, 44.176398515701294, 44.77337336540222, 45.37176012992859, 45.968672037124634, 46.56723952293396, 47.165061950683594, 47.757805585861206, 48.35197377204895, 48.945932388305664, 49.53933620452881, 50.132245779037476, 50.726107120513916, 51.32046961784363, 51.91545605659485, 52.51118302345276, 53.10711121559143, 53.70514225959778, 54.302253007888794, 54.89656114578247, 55.49155831336975, 56.088531255722046, 56.685765743255615, 57.28140616416931, 57.878684759140015, 58.47419452667236, 59.07122206687927, 59.66974139213562, 60.267455101013184, 61.32422947883606]
[23.383333333333333, 28.45, 45.36666666666667, 46.0, 60.233333333333334, 62.333333333333336, 64.66666666666667, 65.91666666666667, 71.15, 72.2, 72.0, 72.15, 72.36666666666666, 74.41666666666667, 73.43333333333334, 74.21666666666667, 73.81666666666666, 74.65, 74.58333333333333, 75.4, 76.26666666666667, 76.48333333333333, 77.3, 77.5, 77.56666666666666, 78.01666666666667, 78.75, 78.86666666666666, 79.06666666666666, 79.73333333333333, 79.2, 78.91666666666667, 78.78333333333333, 80.0, 79.98333333333333, 79.86666666666666, 80.25, 80.0, 80.41666666666667, 80.91666666666667, 81.13333333333334, 80.91666666666667, 81.23333333333333, 81.11666666666666, 81.55, 81.5, 81.48333333333333, 81.45, 81.5, 81.95, 81.31666666666666, 81.11666666666666, 81.63333333333334, 81.38333333333334, 81.93333333333334, 81.85, 82.28333333333333, 82.16666666666667, 82.11666666666666, 82.23333333333333, 82.7, 82.65, 82.83333333333333, 82.95, 82.66666666666667, 82.56666666666666, 82.55, 82.83333333333333, 82.45, 83.06666666666666, 83.15, 82.3, 82.41666666666667, 82.58333333333333, 82.85, 82.6, 82.35, 82.83333333333333, 82.83333333333333, 82.81666666666666, 82.51666666666667, 82.38333333333334, 82.18333333333334, 82.45, 82.58333333333333, 82.91666666666667, 83.05, 82.8, 82.63333333333334, 82.91666666666667, 82.91666666666667, 82.9, 82.8, 82.2, 82.85, 82.45, 82.06666666666666, 82.08333333333333, 82.1, 81.8, 82.83333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 8394 (global); Percentage 2.73 (8394/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.211, Test loss: 2.160, Test accuracy: 19.25 

Round   1, Train loss: 1.116, Test loss: 2.070, Test accuracy: 21.70 

Round   2, Train loss: 0.949, Test loss: 1.814, Test accuracy: 34.47 

Round   3, Train loss: 0.830, Test loss: 1.611, Test accuracy: 45.00 

Round   4, Train loss: 0.842, Test loss: 1.439, Test accuracy: 51.07 

Round   5, Train loss: 0.864, Test loss: 1.334, Test accuracy: 49.38 

Round   6, Train loss: 0.755, Test loss: 1.375, Test accuracy: 50.98 

Round   7, Train loss: 0.780, Test loss: 1.174, Test accuracy: 56.15 

Round   8, Train loss: 0.734, Test loss: 1.218, Test accuracy: 57.25 

Round   9, Train loss: 0.670, Test loss: 1.159, Test accuracy: 58.33 

Round  10, Train loss: 0.730, Test loss: 1.151, Test accuracy: 60.83 

Round  11, Train loss: 0.714, Test loss: 0.998, Test accuracy: 64.33 

Round  12, Train loss: 0.536, Test loss: 1.041, Test accuracy: 63.60 

Round  13, Train loss: 0.728, Test loss: 0.966, Test accuracy: 64.82 

Round  14, Train loss: 0.587, Test loss: 0.886, Test accuracy: 67.12 

Round  15, Train loss: 0.598, Test loss: 0.811, Test accuracy: 70.68 

Round  16, Train loss: 0.611, Test loss: 0.839, Test accuracy: 68.95 

Round  17, Train loss: 0.552, Test loss: 0.822, Test accuracy: 70.15 

Round  18, Train loss: 0.599, Test loss: 0.746, Test accuracy: 71.95 

Round  19, Train loss: 0.510, Test loss: 0.753, Test accuracy: 71.62 

Round  20, Train loss: 0.439, Test loss: 0.762, Test accuracy: 72.17 

Round  21, Train loss: 0.499, Test loss: 0.734, Test accuracy: 73.27 

Round  22, Train loss: 0.480, Test loss: 0.732, Test accuracy: 73.12 

Round  23, Train loss: 0.420, Test loss: 0.720, Test accuracy: 73.70 

Round  24, Train loss: 0.526, Test loss: 0.711, Test accuracy: 73.83 

Round  25, Train loss: 0.416, Test loss: 0.725, Test accuracy: 73.23 

Round  26, Train loss: 0.504, Test loss: 0.705, Test accuracy: 74.08 

Round  27, Train loss: 0.353, Test loss: 0.714, Test accuracy: 74.10 

Round  28, Train loss: 0.375, Test loss: 0.746, Test accuracy: 73.58 

Round  29, Train loss: 0.486, Test loss: 0.736, Test accuracy: 74.23 

Round  30, Train loss: 0.374, Test loss: 0.747, Test accuracy: 73.98 

Round  31, Train loss: 0.384, Test loss: 0.738, Test accuracy: 74.37 

Round  32, Train loss: 0.472, Test loss: 0.724, Test accuracy: 74.65 

Round  33, Train loss: 0.246, Test loss: 0.733, Test accuracy: 74.70 

Round  34, Train loss: 0.258, Test loss: 0.720, Test accuracy: 74.82 

Round  35, Train loss: 0.335, Test loss: 0.739, Test accuracy: 74.90 

Round  36, Train loss: 0.426, Test loss: 0.755, Test accuracy: 74.78 

Round  37, Train loss: 0.217, Test loss: 0.751, Test accuracy: 75.03 

Round  38, Train loss: 0.367, Test loss: 0.745, Test accuracy: 75.15 

Round  39, Train loss: 0.243, Test loss: 0.756, Test accuracy: 75.08 

Round  40, Train loss: 0.276, Test loss: 0.741, Test accuracy: 75.28 

Round  41, Train loss: 0.300, Test loss: 0.772, Test accuracy: 75.52 

Round  42, Train loss: 0.242, Test loss: 0.783, Test accuracy: 75.73 

Round  43, Train loss: 0.262, Test loss: 0.764, Test accuracy: 76.02 

Round  44, Train loss: 0.251, Test loss: 0.779, Test accuracy: 76.02 

Round  45, Train loss: 0.372, Test loss: 0.793, Test accuracy: 76.42 

Round  46, Train loss: 0.193, Test loss: 0.799, Test accuracy: 76.30 

Round  47, Train loss: 0.298, Test loss: 0.810, Test accuracy: 76.10 

Round  48, Train loss: 0.293, Test loss: 0.838, Test accuracy: 75.65 

Round  49, Train loss: 0.261, Test loss: 0.848, Test accuracy: 75.18 

Round  50, Train loss: 0.252, Test loss: 0.832, Test accuracy: 75.18 

Round  51, Train loss: 0.305, Test loss: 0.828, Test accuracy: 75.72 

Round  52, Train loss: 0.208, Test loss: 0.837, Test accuracy: 75.78 

Round  53, Train loss: 0.268, Test loss: 0.823, Test accuracy: 76.25 

Round  54, Train loss: 0.158, Test loss: 0.839, Test accuracy: 76.58 

Round  55, Train loss: 0.227, Test loss: 0.857, Test accuracy: 76.35 

Round  56, Train loss: 0.148, Test loss: 0.872, Test accuracy: 75.95 

Round  57, Train loss: 0.184, Test loss: 0.851, Test accuracy: 76.27 

Round  58, Train loss: 0.240, Test loss: 0.833, Test accuracy: 76.52 

Round  59, Train loss: 0.147, Test loss: 0.829, Test accuracy: 76.58 

Round  60, Train loss: 0.195, Test loss: 0.839, Test accuracy: 76.80 

Round  61, Train loss: 0.169, Test loss: 0.867, Test accuracy: 76.82 

Round  62, Train loss: 0.132, Test loss: 0.877, Test accuracy: 76.62 

Round  63, Train loss: 0.183, Test loss: 0.883, Test accuracy: 76.93 

Round  64, Train loss: 0.193, Test loss: 0.894, Test accuracy: 76.90 

Round  65, Train loss: 0.147, Test loss: 0.906, Test accuracy: 76.50 

Round  66, Train loss: 0.157, Test loss: 0.918, Test accuracy: 76.35 

Round  67, Train loss: 0.144, Test loss: 0.928, Test accuracy: 76.15 

Round  68, Train loss: 0.170, Test loss: 0.912, Test accuracy: 76.25 

Round  69, Train loss: 0.177, Test loss: 0.948, Test accuracy: 76.38 

Round  70, Train loss: 0.157, Test loss: 0.976, Test accuracy: 76.18 

Round  71, Train loss: 0.074, Test loss: 1.004, Test accuracy: 76.00 

Round  72, Train loss: 0.174, Test loss: 0.999, Test accuracy: 76.23 

Round  73, Train loss: 0.151, Test loss: 1.006, Test accuracy: 76.50 

Round  74, Train loss: 0.143, Test loss: 1.001, Test accuracy: 76.67 

Round  75, Train loss: 0.122, Test loss: 1.003, Test accuracy: 76.58 

Round  76, Train loss: 0.125, Test loss: 1.001, Test accuracy: 76.53 

Round  77, Train loss: 0.126, Test loss: 0.988, Test accuracy: 76.55 

Round  78, Train loss: 0.150, Test loss: 1.014, Test accuracy: 76.68 

Round  79, Train loss: 0.116, Test loss: 1.030, Test accuracy: 76.83 

Round  80, Train loss: 0.060, Test loss: 1.058, Test accuracy: 76.32 

Round  81, Train loss: 0.084, Test loss: 1.041, Test accuracy: 76.77 

Round  82, Train loss: 0.082, Test loss: 1.034, Test accuracy: 76.85 

Round  83, Train loss: 0.097, Test loss: 1.066, Test accuracy: 76.85 

Round  84, Train loss: 0.071, Test loss: 1.087, Test accuracy: 77.05 

Round  85, Train loss: 0.082, Test loss: 1.092, Test accuracy: 77.10 

Round  86, Train loss: 0.114, Test loss: 1.097, Test accuracy: 77.05 

Round  87, Train loss: 0.114, Test loss: 1.105, Test accuracy: 76.65 

Round  88, Train loss: 0.073, Test loss: 1.093, Test accuracy: 76.72 

Round  89, Train loss: 0.104, Test loss: 1.086, Test accuracy: 77.20 

Round  90, Train loss: 0.089, Test loss: 1.097, Test accuracy: 77.23 

Round  91, Train loss: 0.120, Test loss: 1.099, Test accuracy: 77.72 

Round  92, Train loss: 0.098, Test loss: 1.088, Test accuracy: 77.13 

Round  93, Train loss: 0.073, Test loss: 1.100, Test accuracy: 76.97 

Round  94, Train loss: 0.099, Test loss: 1.107, Test accuracy: 77.07 

Round  95, Train loss: 0.067, Test loss: 1.150, Test accuracy: 76.90 

Round  96, Train loss: 0.053, Test loss: 1.145, Test accuracy: 76.87 

Round  97, Train loss: 0.093, Test loss: 1.116, Test accuracy: 77.18 

Round  98, Train loss: 0.062, Test loss: 1.153, Test accuracy: 76.72 

Round  99, Train loss: 0.078, Test loss: 1.169, Test accuracy: 76.97 

Final Round, Train loss: 0.058, Test loss: 1.224, Test accuracy: 77.63 

Average accuracy final 10 rounds: 77.075 

582.6331582069397
[0.8927669525146484, 1.5840976238250732, 2.276207208633423, 2.966506004333496, 3.6573519706726074, 4.350402593612671, 5.040657043457031, 5.732721328735352, 6.4260170459747314, 7.119548797607422, 7.8094141483306885, 8.499285697937012, 9.19209885597229, 9.887933492660522, 10.584375619888306, 11.278754234313965, 11.97469449043274, 12.672734498977661, 13.37518310546875, 14.071301221847534, 14.765679121017456, 15.463800191879272, 16.159172773361206, 16.85453701019287, 17.547375440597534, 18.245227098464966, 18.94610095024109, 19.64246892929077, 20.337382316589355, 21.03372883796692, 21.729796886444092, 22.425986766815186, 23.12239646911621, 23.819042205810547, 24.517560482025146, 25.217546224594116, 25.91379451751709, 26.609813690185547, 27.30890393257141, 28.00569200515747, 28.70274519920349, 29.399492025375366, 30.101037979125977, 30.80040192604065, 31.500630855560303, 32.196757316589355, 32.89561748504639, 33.59258532524109, 34.29063630104065, 34.98972821235657, 35.68263792991638, 36.3752064704895, 37.066932678222656, 37.758071422576904, 38.44702482223511, 39.137967109680176, 39.83003330230713, 40.52796673774719, 41.222606897354126, 41.92127585411072, 42.61753702163696, 43.31409049034119, 44.01288461685181, 44.70860266685486, 45.405741930007935, 46.10386943817139, 46.802340269088745, 47.498406171798706, 48.196380615234375, 48.89615845680237, 49.597119092941284, 50.29595232009888, 50.99281573295593, 51.69304871559143, 52.389827251434326, 53.086822509765625, 53.787354469299316, 54.48664116859436, 55.182785987854004, 55.884580850601196, 56.58161211013794, 57.27813386917114, 57.975704193115234, 58.67394971847534, 59.373151540756226, 60.0698664188385, 60.76667618751526, 61.46273899078369, 62.15906596183777, 62.85841202735901, 63.55703926086426, 64.25655484199524, 64.95332479476929, 65.65148735046387, 66.34912252426147, 67.04924416542053, 67.74635863304138, 68.44285774230957, 69.13930821418762, 69.83827304840088, 71.14811134338379]
[19.25, 21.7, 34.46666666666667, 45.0, 51.06666666666667, 49.38333333333333, 50.983333333333334, 56.15, 57.25, 58.333333333333336, 60.833333333333336, 64.33333333333333, 63.6, 64.81666666666666, 67.11666666666666, 70.68333333333334, 68.95, 70.15, 71.95, 71.61666666666666, 72.16666666666667, 73.26666666666667, 73.11666666666666, 73.7, 73.83333333333333, 73.23333333333333, 74.08333333333333, 74.1, 73.58333333333333, 74.23333333333333, 73.98333333333333, 74.36666666666666, 74.65, 74.7, 74.81666666666666, 74.9, 74.78333333333333, 75.03333333333333, 75.15, 75.08333333333333, 75.28333333333333, 75.51666666666667, 75.73333333333333, 76.01666666666667, 76.01666666666667, 76.41666666666667, 76.3, 76.1, 75.65, 75.18333333333334, 75.18333333333334, 75.71666666666667, 75.78333333333333, 76.25, 76.58333333333333, 76.35, 75.95, 76.26666666666667, 76.51666666666667, 76.58333333333333, 76.8, 76.81666666666666, 76.61666666666666, 76.93333333333334, 76.9, 76.5, 76.35, 76.15, 76.25, 76.38333333333334, 76.18333333333334, 76.0, 76.23333333333333, 76.5, 76.66666666666667, 76.58333333333333, 76.53333333333333, 76.55, 76.68333333333334, 76.83333333333333, 76.31666666666666, 76.76666666666667, 76.85, 76.85, 77.05, 77.1, 77.05, 76.65, 76.71666666666667, 77.2, 77.23333333333333, 77.71666666666667, 77.13333333333334, 76.96666666666667, 77.06666666666666, 76.9, 76.86666666666666, 77.18333333333334, 76.71666666666667, 76.96666666666667, 77.63333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac.py", line 61, in <module>
    dataset_train.targets = np.load('data/sample/dataset_train_target.npy', allow_pickle=True)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/lib/npyio.py", line 417, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'data/sample/dataset_train_target.npy'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.236, Test loss: 2.530, Test accuracy: 17.47
Round   1, Train loss: 1.046, Test loss: 2.139, Test accuracy: 21.60
Round   2, Train loss: 0.905, Test loss: 2.023, Test accuracy: 27.53
Round   3, Train loss: 0.875, Test loss: 2.212, Test accuracy: 28.83
Round   4, Train loss: 0.948, Test loss: 2.040, Test accuracy: 25.23
Round   5, Train loss: 0.885, Test loss: 1.861, Test accuracy: 33.05
Round   6, Train loss: 0.778, Test loss: 1.825, Test accuracy: 32.55
Round   7, Train loss: 0.734, Test loss: 1.861, Test accuracy: 34.15
Round   8, Train loss: 0.705, Test loss: 1.682, Test accuracy: 39.37
Round   9, Train loss: 0.785, Test loss: 1.976, Test accuracy: 27.98
Round  10, Train loss: 0.740, Test loss: 2.139, Test accuracy: 23.42
Round  11, Train loss: 0.653, Test loss: 1.649, Test accuracy: 39.63
Round  12, Train loss: 0.720, Test loss: 1.865, Test accuracy: 36.62
Round  13, Train loss: 0.640, Test loss: 1.818, Test accuracy: 34.48
Round  14, Train loss: 0.671, Test loss: 1.585, Test accuracy: 43.10
Round  15, Train loss: 0.613, Test loss: 1.599, Test accuracy: 41.07
Round  16, Train loss: 0.632, Test loss: 1.580, Test accuracy: 43.30
Round  17, Train loss: 0.682, Test loss: 1.846, Test accuracy: 36.02
Round  18, Train loss: 0.602, Test loss: 1.502, Test accuracy: 45.90
Round  19, Train loss: 0.604, Test loss: 1.840, Test accuracy: 34.48
Round  20, Train loss: 0.543, Test loss: 1.748, Test accuracy: 43.92
Round  21, Train loss: 0.576, Test loss: 1.779, Test accuracy: 41.95
Round  22, Train loss: 0.595, Test loss: 1.586, Test accuracy: 42.72
Round  23, Train loss: 0.537, Test loss: 2.059, Test accuracy: 34.00
Round  24, Train loss: 0.550, Test loss: 1.634, Test accuracy: 43.03
Round  25, Train loss: 0.561, Test loss: 1.783, Test accuracy: 37.50
Round  26, Train loss: 0.506, Test loss: 1.562, Test accuracy: 43.90
Round  27, Train loss: 0.538, Test loss: 1.422, Test accuracy: 52.23
Round  28, Train loss: 0.536, Test loss: 1.564, Test accuracy: 45.73
Round  29, Train loss: 0.513, Test loss: 1.880, Test accuracy: 36.20
Round  30, Train loss: 0.485, Test loss: 1.557, Test accuracy: 47.70
Round  31, Train loss: 0.558, Test loss: 1.715, Test accuracy: 40.33
Round  32, Train loss: 0.449, Test loss: 1.672, Test accuracy: 42.27
Round  33, Train loss: 0.450, Test loss: 1.443, Test accuracy: 48.70
Round  34, Train loss: 0.493, Test loss: 1.446, Test accuracy: 50.23
Round  35, Train loss: 0.498, Test loss: 1.605, Test accuracy: 44.97
Round  36, Train loss: 0.384, Test loss: 1.554, Test accuracy: 46.10
Round  37, Train loss: 0.439, Test loss: 1.394, Test accuracy: 53.13
Round  38, Train loss: 0.343, Test loss: 1.595, Test accuracy: 48.32
Round  39, Train loss: 0.435, Test loss: 1.643, Test accuracy: 43.60
Round  40, Train loss: 0.460, Test loss: 1.404, Test accuracy: 51.80
Round  41, Train loss: 0.325, Test loss: 1.581, Test accuracy: 50.98
Round  42, Train loss: 0.365, Test loss: 1.450, Test accuracy: 52.68
Round  43, Train loss: 0.352, Test loss: 1.603, Test accuracy: 52.10
Round  44, Train loss: 0.424, Test loss: 1.598, Test accuracy: 43.25
Round  45, Train loss: 0.351, Test loss: 1.367, Test accuracy: 54.53
Round  46, Train loss: 0.382, Test loss: 1.477, Test accuracy: 53.10
Round  47, Train loss: 0.379, Test loss: 1.429, Test accuracy: 50.57
Round  48, Train loss: 0.400, Test loss: 1.537, Test accuracy: 52.30
Round  49, Train loss: 0.352, Test loss: 1.544, Test accuracy: 50.32
Round  50, Train loss: 0.295, Test loss: 1.428, Test accuracy: 55.20
Round  51, Train loss: 0.365, Test loss: 1.399, Test accuracy: 50.02
Round  52, Train loss: 0.314, Test loss: 1.545, Test accuracy: 48.20
Round  53, Train loss: 0.364, Test loss: 1.483, Test accuracy: 53.47
Round  54, Train loss: 0.305, Test loss: 1.666, Test accuracy: 49.32
Round  55, Train loss: 0.378, Test loss: 1.511, Test accuracy: 52.63
Round  56, Train loss: 0.288, Test loss: 1.498, Test accuracy: 56.50
Round  57, Train loss: 0.276, Test loss: 1.703, Test accuracy: 49.98
Round  58, Train loss: 0.267, Test loss: 1.735, Test accuracy: 49.08
Round  59, Train loss: 0.353, Test loss: 1.508, Test accuracy: 49.82
Round  60, Train loss: 0.263, Test loss: 1.349, Test accuracy: 55.70
Round  61, Train loss: 0.258, Test loss: 1.390, Test accuracy: 55.03
Round  62, Train loss: 0.369, Test loss: 1.434, Test accuracy: 53.00
Round  63, Train loss: 0.276, Test loss: 1.683, Test accuracy: 50.17
Round  64, Train loss: 0.291, Test loss: 1.527, Test accuracy: 55.35
Round  65, Train loss: 0.216, Test loss: 2.086, Test accuracy: 47.78
Round  66, Train loss: 0.264, Test loss: 1.543, Test accuracy: 52.15
Round  67, Train loss: 0.306, Test loss: 1.572, Test accuracy: 49.90
Round  68, Train loss: 0.284, Test loss: 1.594, Test accuracy: 52.30
Round  69, Train loss: 0.206, Test loss: 1.568, Test accuracy: 56.30
Round  70, Train loss: 0.229, Test loss: 1.494, Test accuracy: 54.20
Round  71, Train loss: 0.257, Test loss: 1.380, Test accuracy: 54.42
Round  72, Train loss: 0.184, Test loss: 1.802, Test accuracy: 51.20
Round  73, Train loss: 0.257, Test loss: 1.341, Test accuracy: 56.77
Round  74, Train loss: 0.278, Test loss: 1.512, Test accuracy: 50.67
Round  75, Train loss: 0.203, Test loss: 1.538, Test accuracy: 52.17
Round  76, Train loss: 0.224, Test loss: 1.395, Test accuracy: 53.85
Round  77, Train loss: 0.238, Test loss: 1.419, Test accuracy: 53.52
Round  78, Train loss: 0.184, Test loss: 1.549, Test accuracy: 54.97
Round  79, Train loss: 0.221, Test loss: 1.638, Test accuracy: 50.97
Round  80, Train loss: 0.179, Test loss: 1.593, Test accuracy: 54.47
Round  81, Train loss: 0.228, Test loss: 1.559, Test accuracy: 52.17
Round  82, Train loss: 0.240, Test loss: 1.462, Test accuracy: 55.45
Round  83, Train loss: 0.195, Test loss: 1.472, Test accuracy: 55.53
Round  84, Train loss: 0.187, Test loss: 1.678, Test accuracy: 52.75
Round  85, Train loss: 0.238, Test loss: 1.411, Test accuracy: 56.07
Round  86, Train loss: 0.243, Test loss: 1.579, Test accuracy: 52.43
Round  87, Train loss: 0.200, Test loss: 1.471, Test accuracy: 56.77
Round  88, Train loss: 0.219, Test loss: 1.560, Test accuracy: 53.10
Round  89, Train loss: 0.128, Test loss: 2.001, Test accuracy: 51.25
Round  90, Train loss: 0.182, Test loss: 1.908, Test accuracy: 46.15
Round  91, Train loss: 0.206, Test loss: 1.577, Test accuracy: 53.55
Round  92, Train loss: 0.165, Test loss: 1.464, Test accuracy: 55.58
Round  93, Train loss: 0.202, Test loss: 1.553, Test accuracy: 52.90
Round  94, Train loss: 0.193, Test loss: 1.342, Test accuracy: 58.80
Round  95, Train loss: 0.134, Test loss: 1.563, Test accuracy: 55.70
Round  96, Train loss: 0.158, Test loss: 1.471, Test accuracy: 55.53
Round  97, Train loss: 0.192, Test loss: 1.656, Test accuracy: 55.30
Round  98, Train loss: 0.181, Test loss: 1.367, Test accuracy: 59.28
Round  99, Train loss: 0.137, Test loss: 1.719, Test accuracy: 53.18
Final Round, Train loss: 0.162, Test loss: 1.267, Test accuracy: 61.08
Average accuracy final 10 rounds: 54.598333333333336
1123.8644552230835
[1.9737889766693115, 3.7148196697235107, 5.44719672203064, 7.204026937484741, 8.962260723114014, 10.721958875656128, 12.478917598724365, 14.230834245681763, 15.995188236236572, 17.76085066795349, 19.51383686065674, 21.271545886993408, 23.02086901664734, 24.772812128067017, 26.52548313140869, 28.282487630844116, 30.037696599960327, 31.781571865081787, 33.34051012992859, 34.90331172943115, 36.47592735290527, 38.053555488586426, 39.62217688560486, 41.19337320327759, 42.76699757575989, 44.336541414260864, 45.90783715248108, 47.46948194503784, 49.04278922080994, 50.6161744594574, 52.18394875526428, 53.74397253990173, 55.315014600753784, 56.880351543426514, 58.45197916030884, 60.01756739616394, 61.59081029891968, 63.16552734375, 64.71160054206848, 66.25984811782837, 67.8040702342987, 69.35333824157715, 70.90910363197327, 72.45140790939331, 73.99750757217407, 75.53670644760132, 77.09276628494263, 78.65254545211792, 80.22365617752075, 81.78539943695068, 83.34528183937073, 84.9058907032013, 86.46944427490234, 88.03291773796082, 89.60265398025513, 91.15790295600891, 92.71425151824951, 94.27388834953308, 95.83885288238525, 97.40083408355713, 98.96253871917725, 100.53856301307678, 102.09285998344421, 103.65431451797485, 105.2098777294159, 106.76586174964905, 108.32953715324402, 109.89120578765869, 111.4556736946106, 113.02260327339172, 114.59542560577393, 116.15765380859375, 117.72460055351257, 119.28622889518738, 120.85304760932922, 122.40598392486572, 123.96282505989075, 125.52582740783691, 127.0779983997345, 128.63667798042297, 130.21095991134644, 131.77553868293762, 133.3490855693817, 134.9167332649231, 136.48003840446472, 138.05297756195068, 139.6271390914917, 141.18138885498047, 142.74117922782898, 144.29485058784485, 145.8550102710724, 147.4185450077057, 148.9819037914276, 150.53652596473694, 152.1032657623291, 153.66403365135193, 155.22284269332886, 156.78116917610168, 158.340026140213, 159.90460348129272, 161.47383642196655]
[17.466666666666665, 21.6, 27.533333333333335, 28.833333333333332, 25.233333333333334, 33.05, 32.55, 34.15, 39.36666666666667, 27.983333333333334, 23.416666666666668, 39.63333333333333, 36.61666666666667, 34.483333333333334, 43.1, 41.06666666666667, 43.3, 36.016666666666666, 45.9, 34.483333333333334, 43.916666666666664, 41.95, 42.71666666666667, 34.0, 43.03333333333333, 37.5, 43.9, 52.233333333333334, 45.733333333333334, 36.2, 47.7, 40.333333333333336, 42.266666666666666, 48.7, 50.233333333333334, 44.96666666666667, 46.1, 53.13333333333333, 48.31666666666667, 43.6, 51.8, 50.983333333333334, 52.68333333333333, 52.1, 43.25, 54.53333333333333, 53.1, 50.56666666666667, 52.3, 50.31666666666667, 55.2, 50.016666666666666, 48.2, 53.46666666666667, 49.31666666666667, 52.63333333333333, 56.5, 49.983333333333334, 49.083333333333336, 49.81666666666667, 55.7, 55.03333333333333, 53.0, 50.166666666666664, 55.35, 47.78333333333333, 52.15, 49.9, 52.3, 56.3, 54.2, 54.416666666666664, 51.2, 56.766666666666666, 50.666666666666664, 52.166666666666664, 53.85, 53.516666666666666, 54.96666666666667, 50.96666666666667, 54.46666666666667, 52.166666666666664, 55.45, 55.53333333333333, 52.75, 56.06666666666667, 52.43333333333333, 56.766666666666666, 53.1, 51.25, 46.15, 53.55, 55.583333333333336, 52.9, 58.8, 55.7, 55.53333333333333, 55.3, 59.28333333333333, 53.18333333333333, 61.083333333333336]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 0.841, Test loss: 2.320, Test accuracy: 20.98
Round   1, Train loss: 0.791, Test loss: 2.192, Test accuracy: 25.28
Round   2, Train loss: 0.706, Test loss: 2.099, Test accuracy: 37.73
Round   3, Train loss: 0.655, Test loss: 2.093, Test accuracy: 40.95
Round   4, Train loss: 0.627, Test loss: 2.112, Test accuracy: 46.18
Round   5, Train loss: 0.517, Test loss: 2.026, Test accuracy: 46.63
Round   6, Train loss: 0.544, Test loss: 2.057, Test accuracy: 48.83
Round   7, Train loss: 0.619, Test loss: 1.968, Test accuracy: 49.05
Round   8, Train loss: 0.465, Test loss: 1.960, Test accuracy: 50.73
Round   9, Train loss: 0.479, Test loss: 1.899, Test accuracy: 51.30
Round  10, Train loss: 0.431, Test loss: 1.872, Test accuracy: 52.62
Round  11, Train loss: 0.430, Test loss: 1.849, Test accuracy: 52.90
Round  12, Train loss: 0.396, Test loss: 1.810, Test accuracy: 53.52
Round  13, Train loss: 0.413, Test loss: 1.793, Test accuracy: 53.27
Round  14, Train loss: 0.378, Test loss: 1.769, Test accuracy: 53.93
Round  15, Train loss: 0.372, Test loss: 1.744, Test accuracy: 53.75
Round  16, Train loss: 0.424, Test loss: 1.718, Test accuracy: 52.83
Round  17, Train loss: 0.414, Test loss: 1.720, Test accuracy: 52.68
Round  18, Train loss: 0.348, Test loss: 1.669, Test accuracy: 54.55
Round  19, Train loss: 0.361, Test loss: 1.669, Test accuracy: 52.98
Round  20, Train loss: 0.306, Test loss: 1.620, Test accuracy: 54.53
Round  21, Train loss: 0.331, Test loss: 1.592, Test accuracy: 55.32
Round  22, Train loss: 0.331, Test loss: 1.581, Test accuracy: 55.35
Round  23, Train loss: 0.267, Test loss: 1.558, Test accuracy: 56.12
Round  24, Train loss: 0.256, Test loss: 1.528, Test accuracy: 57.77
Round  25, Train loss: 0.308, Test loss: 1.523, Test accuracy: 56.78
Round  26, Train loss: 0.265, Test loss: 1.501, Test accuracy: 56.15
Round  27, Train loss: 0.250, Test loss: 1.486, Test accuracy: 56.45
Round  28, Train loss: 0.257, Test loss: 1.462, Test accuracy: 55.82
Round  29, Train loss: 0.270, Test loss: 1.438, Test accuracy: 55.33
Round  30, Train loss: 0.252, Test loss: 1.443, Test accuracy: 55.95
Round  31, Train loss: 0.292, Test loss: 1.417, Test accuracy: 57.47
Round  32, Train loss: 0.227, Test loss: 1.395, Test accuracy: 57.45
Round  33, Train loss: 0.257, Test loss: 1.379, Test accuracy: 57.70
Round  34, Train loss: 0.275, Test loss: 1.367, Test accuracy: 58.13
Round  35, Train loss: 0.243, Test loss: 1.338, Test accuracy: 58.95
Round  36, Train loss: 0.259, Test loss: 1.323, Test accuracy: 58.87
Round  37, Train loss: 0.220, Test loss: 1.299, Test accuracy: 59.07
Round  38, Train loss: 0.239, Test loss: 1.298, Test accuracy: 58.08
Round  39, Train loss: 0.279, Test loss: 1.295, Test accuracy: 56.70
Round  40, Train loss: 0.176, Test loss: 1.273, Test accuracy: 58.60
Round  41, Train loss: 0.157, Test loss: 1.244, Test accuracy: 59.00
Round  42, Train loss: 0.195, Test loss: 1.227, Test accuracy: 57.77
Round  43, Train loss: 0.209, Test loss: 1.229, Test accuracy: 58.10
Round  44, Train loss: 0.202, Test loss: 1.197, Test accuracy: 58.63
Round  45, Train loss: 0.177, Test loss: 1.196, Test accuracy: 60.03
Round  46, Train loss: 0.188, Test loss: 1.194, Test accuracy: 58.10
Round  47, Train loss: 0.189, Test loss: 1.174, Test accuracy: 57.95
Round  48, Train loss: 0.177, Test loss: 1.173, Test accuracy: 58.35
Round  49, Train loss: 0.178, Test loss: 1.145, Test accuracy: 60.12
Round  50, Train loss: 0.187, Test loss: 1.124, Test accuracy: 61.72
Round  51, Train loss: 0.136, Test loss: 1.100, Test accuracy: 61.87
Round  52, Train loss: 0.140, Test loss: 1.081, Test accuracy: 62.72
Round  53, Train loss: 0.108, Test loss: 1.069, Test accuracy: 64.07
Round  54, Train loss: 0.140, Test loss: 1.060, Test accuracy: 64.60
Round  55, Train loss: 0.114, Test loss: 1.037, Test accuracy: 63.42
Round  56, Train loss: 0.135, Test loss: 1.035, Test accuracy: 62.75
Round  57, Train loss: 0.120, Test loss: 1.026, Test accuracy: 64.32
Round  58, Train loss: 0.129, Test loss: 0.998, Test accuracy: 64.15
Round  59, Train loss: 0.116, Test loss: 0.983, Test accuracy: 65.20
Round  60, Train loss: 0.127, Test loss: 0.964, Test accuracy: 64.97
Round  61, Train loss: 0.136, Test loss: 0.966, Test accuracy: 64.25
Round  62, Train loss: 0.121, Test loss: 0.975, Test accuracy: 63.43
Round  63, Train loss: 0.097, Test loss: 0.959, Test accuracy: 64.52
Round  64, Train loss: 0.097, Test loss: 0.956, Test accuracy: 63.55
Round  65, Train loss: 0.094, Test loss: 0.941, Test accuracy: 65.02
Round  66, Train loss: 0.112, Test loss: 0.937, Test accuracy: 65.40
Round  67, Train loss: 0.105, Test loss: 0.934, Test accuracy: 64.20
Round  68, Train loss: 0.091, Test loss: 0.924, Test accuracy: 65.25
Round  69, Train loss: 0.106, Test loss: 0.919, Test accuracy: 64.98
Round  70, Train loss: 0.091, Test loss: 0.910, Test accuracy: 65.47
Round  71, Train loss: 0.108, Test loss: 0.895, Test accuracy: 65.95
Round  72, Train loss: 0.108, Test loss: 0.882, Test accuracy: 66.45
Round  73, Train loss: 0.087, Test loss: 0.868, Test accuracy: 67.20
Round  74, Train loss: 0.093, Test loss: 0.863, Test accuracy: 66.95
Round  75, Train loss: 0.104, Test loss: 0.873, Test accuracy: 65.18
Round  76, Train loss: 0.094, Test loss: 0.879, Test accuracy: 64.85
Round  77, Train loss: 0.072, Test loss: 0.852, Test accuracy: 66.67
Round  78, Train loss: 0.087, Test loss: 0.859, Test accuracy: 66.73
Round  79, Train loss: 0.072, Test loss: 0.857, Test accuracy: 66.23
Round  80, Train loss: 0.057, Test loss: 0.840, Test accuracy: 67.82
Round  81, Train loss: 0.088, Test loss: 0.851, Test accuracy: 66.90
Round  82, Train loss: 0.072, Test loss: 0.840, Test accuracy: 67.32
Round  83, Train loss: 0.074, Test loss: 0.832, Test accuracy: 67.33
Round  84, Train loss: 0.098, Test loss: 0.829, Test accuracy: 66.83
Round  85, Train loss: 0.067, Test loss: 0.822, Test accuracy: 66.55
Round  86, Train loss: 0.078, Test loss: 0.822, Test accuracy: 67.02
Round  87, Train loss: 0.067, Test loss: 0.817, Test accuracy: 67.03
Round  88, Train loss: 0.081, Test loss: 0.822, Test accuracy: 67.47
Round  89, Train loss: 0.073, Test loss: 0.826, Test accuracy: 66.82
Round  90, Train loss: 0.067, Test loss: 0.810, Test accuracy: 67.97
Round  91, Train loss: 0.065, Test loss: 0.812, Test accuracy: 67.52
Round  92, Train loss: 0.055, Test loss: 0.804, Test accuracy: 67.37
Round  93, Train loss: 0.080, Test loss: 0.794, Test accuracy: 67.27
Round  94, Train loss: 0.054, Test loss: 0.785, Test accuracy: 68.20
Round  95, Train loss: 0.056, Test loss: 0.786, Test accuracy: 67.88
Round  96, Train loss: 0.063, Test loss: 0.788, Test accuracy: 68.05
Round  97, Train loss: 0.066, Test loss: 0.781, Test accuracy: 68.23
Round  98, Train loss: 0.089, Test loss: 0.798, Test accuracy: 67.22
Round  99, Train loss: 0.054, Test loss: 0.787, Test accuracy: 67.57
Final Round, Train loss: 0.062, Test loss: 0.783, Test accuracy: 67.92
Average accuracy final 10 rounds: 67.72666666666666
846.9347467422485
[]
[20.983333333333334, 25.283333333333335, 37.733333333333334, 40.95, 46.18333333333333, 46.63333333333333, 48.833333333333336, 49.05, 50.733333333333334, 51.3, 52.61666666666667, 52.9, 53.516666666666666, 53.266666666666666, 53.93333333333333, 53.75, 52.833333333333336, 52.68333333333333, 54.55, 52.983333333333334, 54.53333333333333, 55.31666666666667, 55.35, 56.11666666666667, 57.766666666666666, 56.78333333333333, 56.15, 56.45, 55.81666666666667, 55.333333333333336, 55.95, 57.46666666666667, 57.45, 57.7, 58.13333333333333, 58.95, 58.86666666666667, 59.06666666666667, 58.083333333333336, 56.7, 58.6, 59.0, 57.766666666666666, 58.1, 58.63333333333333, 60.03333333333333, 58.1, 57.95, 58.35, 60.11666666666667, 61.71666666666667, 61.86666666666667, 62.71666666666667, 64.06666666666666, 64.6, 63.416666666666664, 62.75, 64.31666666666666, 64.15, 65.2, 64.96666666666667, 64.25, 63.43333333333333, 64.51666666666667, 63.55, 65.01666666666667, 65.4, 64.2, 65.25, 64.98333333333333, 65.46666666666667, 65.95, 66.45, 67.2, 66.95, 65.18333333333334, 64.85, 66.66666666666667, 66.73333333333333, 66.23333333333333, 67.81666666666666, 66.9, 67.31666666666666, 67.33333333333333, 66.83333333333333, 66.55, 67.01666666666667, 67.03333333333333, 67.46666666666667, 66.81666666666666, 67.96666666666667, 67.51666666666667, 67.36666666666666, 67.26666666666667, 68.2, 67.88333333333334, 68.05, 68.23333333333333, 67.21666666666667, 67.56666666666666, 67.91666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.136, Test loss: 2.197, Test accuracy: 17.55
Round   0: Global train loss: 2.136, Global test loss: 2.296, Global test accuracy: 13.32
Round   1, Train loss: 1.940, Test loss: 2.103, Test accuracy: 21.75
Round   1: Global train loss: 1.940, Global test loss: 2.286, Global test accuracy: 14.14
Round   2, Train loss: 1.885, Test loss: 2.037, Test accuracy: 25.32
Round   2: Global train loss: 1.885, Global test loss: 2.273, Global test accuracy: 16.40
Round   3, Train loss: 1.711, Test loss: 1.958, Test accuracy: 28.89
Round   3: Global train loss: 1.711, Global test loss: 2.257, Global test accuracy: 20.73
Round   4, Train loss: 1.520, Test loss: 1.907, Test accuracy: 31.00
Round   4: Global train loss: 1.520, Global test loss: 2.242, Global test accuracy: 22.77
Round   5, Train loss: 1.421, Test loss: 1.888, Test accuracy: 31.56
Round   5: Global train loss: 1.421, Global test loss: 2.233, Global test accuracy: 23.71
Round   6, Train loss: 1.308, Test loss: 1.841, Test accuracy: 33.17
Round   6: Global train loss: 1.308, Global test loss: 2.216, Global test accuracy: 26.42
Round   7, Train loss: 0.726, Test loss: 1.774, Test accuracy: 35.31
Round   7: Global train loss: 0.726, Global test loss: 2.195, Global test accuracy: 28.00
Round   8, Train loss: 1.067, Test loss: 1.738, Test accuracy: 36.67
Round   8: Global train loss: 1.067, Global test loss: 2.176, Global test accuracy: 29.64
Round   9, Train loss: 1.140, Test loss: 1.733, Test accuracy: 36.99
Round   9: Global train loss: 1.140, Global test loss: 2.159, Global test accuracy: 30.66
Round  10, Train loss: 0.842, Test loss: 1.709, Test accuracy: 37.81
Round  10: Global train loss: 0.842, Global test loss: 2.141, Global test accuracy: 31.80
Round  11, Train loss: 0.340, Test loss: 1.658, Test accuracy: 38.98
Round  11: Global train loss: 0.340, Global test loss: 2.115, Global test accuracy: 33.68
Round  12, Train loss: 0.374, Test loss: 1.636, Test accuracy: 40.00
Round  12: Global train loss: 0.374, Global test loss: 2.094, Global test accuracy: 35.34
Round  13, Train loss: 0.156, Test loss: 1.645, Test accuracy: 39.92
Round  13: Global train loss: 0.156, Global test loss: 2.068, Global test accuracy: 36.39
Round  14, Train loss: 0.141, Test loss: 1.647, Test accuracy: 39.84
Round  14: Global train loss: 0.141, Global test loss: 2.053, Global test accuracy: 36.55
Round  15, Train loss: -0.167, Test loss: 1.663, Test accuracy: 40.09
Round  15: Global train loss: -0.167, Global test loss: 2.024, Global test accuracy: 38.05
Round  16, Train loss: 0.189, Test loss: 1.635, Test accuracy: 41.12
Round  16: Global train loss: 0.189, Global test loss: 1.998, Global test accuracy: 38.34
Round  17, Train loss: 0.233, Test loss: 1.631, Test accuracy: 41.27
Round  17: Global train loss: 0.233, Global test loss: 1.980, Global test accuracy: 38.81
Round  18, Train loss: -0.956, Test loss: 1.618, Test accuracy: 41.74
Round  18: Global train loss: -0.956, Global test loss: 1.947, Global test accuracy: 40.52
Round  19, Train loss: -0.596, Test loss: 1.590, Test accuracy: 42.77
Round  19: Global train loss: -0.596, Global test loss: 1.924, Global test accuracy: 41.38
Round  20, Train loss: -0.485, Test loss: 1.591, Test accuracy: 42.39
Round  20: Global train loss: -0.485, Global test loss: 1.910, Global test accuracy: 41.45
Round  21, Train loss: 0.559, Test loss: 1.591, Test accuracy: 42.90
Round  21: Global train loss: 0.559, Global test loss: 1.906, Global test accuracy: 41.95
Round  22, Train loss: -0.513, Test loss: 1.595, Test accuracy: 42.52
Round  22: Global train loss: -0.513, Global test loss: 1.901, Global test accuracy: 41.70
Round  23, Train loss: -0.474, Test loss: 1.590, Test accuracy: 42.99
Round  23: Global train loss: -0.474, Global test loss: 1.881, Global test accuracy: 42.26
Round  24, Train loss: -0.615, Test loss: 1.570, Test accuracy: 43.58
Round  24: Global train loss: -0.615, Global test loss: 1.872, Global test accuracy: 42.45
Round  25, Train loss: -1.055, Test loss: 1.585, Test accuracy: 43.57
Round  25: Global train loss: -1.055, Global test loss: 1.858, Global test accuracy: 42.44
Round  26, Train loss: -1.155, Test loss: 1.588, Test accuracy: 43.81
Round  26: Global train loss: -1.155, Global test loss: 1.835, Global test accuracy: 42.85
Round  27, Train loss: -1.638, Test loss: 1.587, Test accuracy: 44.02
Round  27: Global train loss: -1.638, Global test loss: 1.822, Global test accuracy: 43.66
Round  28, Train loss: -1.512, Test loss: 1.566, Test accuracy: 44.58
Round  28: Global train loss: -1.512, Global test loss: 1.808, Global test accuracy: 44.07
Round  29, Train loss: -1.712, Test loss: 1.568, Test accuracy: 44.76
Round  29: Global train loss: -1.712, Global test loss: 1.801, Global test accuracy: 44.08
Round  30, Train loss: -1.872, Test loss: 1.569, Test accuracy: 44.73
Round  30: Global train loss: -1.872, Global test loss: 1.789, Global test accuracy: 44.53
Round  31, Train loss: -1.641, Test loss: 1.592, Test accuracy: 44.88
Round  31: Global train loss: -1.641, Global test loss: 1.770, Global test accuracy: 45.29
Round  32, Train loss: -1.970, Test loss: 1.601, Test accuracy: 44.47
Round  32: Global train loss: -1.970, Global test loss: 1.758, Global test accuracy: 45.19
Round  33, Train loss: -2.272, Test loss: 1.617, Test accuracy: 44.36
Round  33: Global train loss: -2.272, Global test loss: 1.748, Global test accuracy: 45.35
Round  34, Train loss: -2.387, Test loss: 1.600, Test accuracy: 44.92
Round  34: Global train loss: -2.387, Global test loss: 1.735, Global test accuracy: 45.94
Round  35, Train loss: -2.038, Test loss: 1.596, Test accuracy: 44.98
Round  35: Global train loss: -2.038, Global test loss: 1.725, Global test accuracy: 46.02
Round  36, Train loss: -2.614, Test loss: 1.615, Test accuracy: 44.32
Round  36: Global train loss: -2.614, Global test loss: 1.715, Global test accuracy: 46.16
Round  37, Train loss: -2.609, Test loss: 1.622, Test accuracy: 44.13
Round  37: Global train loss: -2.609, Global test loss: 1.711, Global test accuracy: 46.11
Round  38, Train loss: -2.617, Test loss: 1.616, Test accuracy: 44.30
Round  38: Global train loss: -2.617, Global test loss: 1.703, Global test accuracy: 46.34
Round  39, Train loss: -3.266, Test loss: 1.620, Test accuracy: 44.41
Round  39: Global train loss: -3.266, Global test loss: 1.686, Global test accuracy: 46.55
Round  40, Train loss: -3.520, Test loss: 1.643, Test accuracy: 45.23
Round  40: Global train loss: -3.520, Global test loss: 1.668, Global test accuracy: 47.03
Round  41, Train loss: -3.649, Test loss: 1.594, Test accuracy: 45.80
Round  41: Global train loss: -3.649, Global test loss: 1.653, Global test accuracy: 47.78
Round  42, Train loss: -3.399, Test loss: 1.608, Test accuracy: 45.25
Round  42: Global train loss: -3.399, Global test loss: 1.644, Global test accuracy: 48.15
Round  43, Train loss: -3.275, Test loss: 1.614, Test accuracy: 45.83
Round  43: Global train loss: -3.275, Global test loss: 1.631, Global test accuracy: 48.23
Round  44, Train loss: -4.546, Test loss: 1.611, Test accuracy: 46.65
Round  44: Global train loss: -4.546, Global test loss: 1.611, Global test accuracy: 49.09
Round  45, Train loss: -3.303, Test loss: 1.594, Test accuracy: 46.73
Round  45: Global train loss: -3.303, Global test loss: 1.609, Global test accuracy: 49.14
Round  46, Train loss: -3.936, Test loss: 1.616, Test accuracy: 46.48
Round  46: Global train loss: -3.936, Global test loss: 1.595, Global test accuracy: 49.56
Round  47, Train loss: -3.095, Test loss: 1.615, Test accuracy: 46.38
Round  47: Global train loss: -3.095, Global test loss: 1.589, Global test accuracy: 49.61
Round  48, Train loss: -3.577, Test loss: 1.626, Test accuracy: 46.15
Round  48: Global train loss: -3.577, Global test loss: 1.583, Global test accuracy: 49.86
Round  49, Train loss: -4.042, Test loss: 1.674, Test accuracy: 45.69
Round  49: Global train loss: -4.042, Global test loss: 1.569, Global test accuracy: 50.27
Round  50, Train loss: -4.532, Test loss: 1.679, Test accuracy: 46.47
Round  50: Global train loss: -4.532, Global test loss: 1.547, Global test accuracy: 50.79
Round  51, Train loss: -3.779, Test loss: 1.664, Test accuracy: 46.75
Round  51: Global train loss: -3.779, Global test loss: 1.542, Global test accuracy: 50.41
Round  52, Train loss: -4.618, Test loss: 1.669, Test accuracy: 46.78
Round  52: Global train loss: -4.618, Global test loss: 1.527, Global test accuracy: 50.99
Round  53, Train loss: -3.923, Test loss: 1.646, Test accuracy: 46.72
Round  53: Global train loss: -3.923, Global test loss: 1.524, Global test accuracy: 50.87
Round  54, Train loss: -4.121, Test loss: 1.637, Test accuracy: 46.80
Round  54: Global train loss: -4.121, Global test loss: 1.519, Global test accuracy: 51.02
Round  55, Train loss: -4.444, Test loss: 1.685, Test accuracy: 46.83
Round  55: Global train loss: -4.444, Global test loss: 1.500, Global test accuracy: 51.48
Round  56, Train loss: -4.940, Test loss: 1.696, Test accuracy: 46.97
Round  56: Global train loss: -4.940, Global test loss: 1.485, Global test accuracy: 51.94
Round  57, Train loss: -4.017, Test loss: 1.658, Test accuracy: 47.19
Round  57: Global train loss: -4.017, Global test loss: 1.484, Global test accuracy: 51.78
Round  58, Train loss: -4.251, Test loss: 1.639, Test accuracy: 47.25
Round  58: Global train loss: -4.251, Global test loss: 1.477, Global test accuracy: 52.13
Round  59, Train loss: -4.392, Test loss: 1.659, Test accuracy: 46.81
Round  59: Global train loss: -4.392, Global test loss: 1.468, Global test accuracy: 52.44
Round  60, Train loss: -4.738, Test loss: 1.641, Test accuracy: 46.99
Round  60: Global train loss: -4.738, Global test loss: 1.463, Global test accuracy: 52.84
Round  61, Train loss: -4.275, Test loss: 1.646, Test accuracy: 46.49
Round  61: Global train loss: -4.275, Global test loss: 1.454, Global test accuracy: 52.80
Round  62, Train loss: -4.819, Test loss: 1.647, Test accuracy: 46.96
Round  62: Global train loss: -4.819, Global test loss: 1.448, Global test accuracy: 52.82
Round  63, Train loss: -4.959, Test loss: 1.654, Test accuracy: 46.97
Round  63: Global train loss: -4.959, Global test loss: 1.436, Global test accuracy: 53.13
Round  64, Train loss: -5.228, Test loss: 1.649, Test accuracy: 47.27
Round  64: Global train loss: -5.228, Global test loss: 1.430, Global test accuracy: 53.45
Round  65, Train loss: -4.473, Test loss: 1.640, Test accuracy: 47.42
Round  65: Global train loss: -4.473, Global test loss: 1.425, Global test accuracy: 53.53
Round  66, Train loss: -5.012, Test loss: 1.670, Test accuracy: 47.70
Round  66: Global train loss: -5.012, Global test loss: 1.410, Global test accuracy: 53.86
Round  67, Train loss: -6.029, Test loss: 1.726, Test accuracy: 46.96
Round  67: Global train loss: -6.029, Global test loss: 1.403, Global test accuracy: 53.98
Round  68, Train loss: -4.510, Test loss: 1.698, Test accuracy: 47.85
Round  68: Global train loss: -4.510, Global test loss: 1.394, Global test accuracy: 54.25
Round  69, Train loss: -5.267, Test loss: 1.683, Test accuracy: 48.16
Round  69: Global train loss: -5.267, Global test loss: 1.387, Global test accuracy: 54.35
Round  70, Train loss: -5.059, Test loss: 1.677, Test accuracy: 48.29
Round  70: Global train loss: -5.059, Global test loss: 1.382, Global test accuracy: 54.69
Round  71, Train loss: -5.322, Test loss: 1.667, Test accuracy: 48.65
Round  71: Global train loss: -5.322, Global test loss: 1.375, Global test accuracy: 54.70
Round  72, Train loss: -4.884, Test loss: 1.674, Test accuracy: 48.58
Round  72: Global train loss: -4.884, Global test loss: 1.369, Global test accuracy: 54.80
Round  73, Train loss: -5.248, Test loss: 1.652, Test accuracy: 48.37
Round  73: Global train loss: -5.248, Global test loss: 1.356, Global test accuracy: 55.25
Round  74, Train loss: -4.989, Test loss: 1.669, Test accuracy: 48.45
Round  74: Global train loss: -4.989, Global test loss: 1.350, Global test accuracy: 55.73
Round  75, Train loss: -5.134, Test loss: 1.649, Test accuracy: 48.98
Round  75: Global train loss: -5.134, Global test loss: 1.343, Global test accuracy: 55.81
Round  76, Train loss: -4.709, Test loss: 1.647, Test accuracy: 48.66
Round  76: Global train loss: -4.709, Global test loss: 1.334, Global test accuracy: 55.81
Round  77, Train loss: -5.086, Test loss: 1.647, Test accuracy: 48.77
Round  77: Global train loss: -5.086, Global test loss: 1.325, Global test accuracy: 56.00
Round  78, Train loss: -5.204, Test loss: 1.632, Test accuracy: 49.01
Round  78: Global train loss: -5.204, Global test loss: 1.317, Global test accuracy: 56.26
Round  79, Train loss: -5.242, Test loss: 1.645, Test accuracy: 48.70
Round  79: Global train loss: -5.242, Global test loss: 1.310, Global test accuracy: 56.55
Round  80, Train loss: -5.138, Test loss: 1.676, Test accuracy: 48.09
Round  80: Global train loss: -5.138, Global test loss: 1.304, Global test accuracy: 56.62
Round  81, Train loss: -4.716, Test loss: 1.662, Test accuracy: 48.40
Round  81: Global train loss: -4.716, Global test loss: 1.300, Global test accuracy: 56.80
Round  82, Train loss: -5.493, Test loss: 1.678, Test accuracy: 48.78
Round  82: Global train loss: -5.493, Global test loss: 1.296, Global test accuracy: 56.83
Round  83, Train loss: -5.435, Test loss: 1.679, Test accuracy: 48.62
Round  83: Global train loss: -5.435, Global test loss: 1.289, Global test accuracy: 57.15
Round  84, Train loss: -5.486, Test loss: 1.701, Test accuracy: 48.30
Round  84: Global train loss: -5.486, Global test loss: 1.280, Global test accuracy: 57.28
Round  85, Train loss: -5.110, Test loss: 1.721, Test accuracy: 48.34
Round  85: Global train loss: -5.110, Global test loss: 1.271, Global test accuracy: 57.30
Round  86, Train loss: -5.689, Test loss: 1.707, Test accuracy: 48.73
Round  86: Global train loss: -5.689, Global test loss: 1.264, Global test accuracy: 57.84
Round  87, Train loss: -5.730, Test loss: 1.718, Test accuracy: 48.47
Round  87: Global train loss: -5.730, Global test loss: 1.255, Global test accuracy: 57.85
Round  88, Train loss: -5.197, Test loss: 1.705, Test accuracy: 48.73
Round  88: Global train loss: -5.197, Global test loss: 1.248, Global test accuracy: 57.91
Round  89, Train loss: -4.901, Test loss: 1.656, Test accuracy: 49.27
Round  89: Global train loss: -4.901, Global test loss: 1.248, Global test accuracy: 57.93
Round  90, Train loss: -5.233, Test loss: 1.676, Test accuracy: 48.92
Round  90: Global train loss: -5.233, Global test loss: 1.241, Global test accuracy: 58.12
Round  91, Train loss: -5.661, Test loss: 1.692, Test accuracy: 49.22
Round  91: Global train loss: -5.661, Global test loss: 1.234, Global test accuracy: 58.12
Round  92, Train loss: -4.930, Test loss: 1.646, Test accuracy: 49.58
Round  92: Global train loss: -4.930, Global test loss: 1.229, Global test accuracy: 58.28
Round  93, Train loss: -5.294, Test loss: 1.664, Test accuracy: 49.47
Round  93: Global train loss: -5.294, Global test loss: 1.228, Global test accuracy: 58.14
Round  94, Train loss: -4.908, Test loss: 1.647, Test accuracy: 49.66
Round  94: Global train loss: -4.908, Global test loss: 1.219, Global test accuracy: 58.28
Round  95, Train loss: -5.023, Test loss: 1.650, Test accuracy: 49.77
Round  95: Global train loss: -5.023, Global test loss: 1.214, Global test accuracy: 58.90
Round  96, Train loss: -5.317, Test loss: 1.673, Test accuracy: 49.84
Round  96: Global train loss: -5.317, Global test loss: 1.211, Global test accuracy: 58.63
Round  97, Train loss: -5.275, Test loss: 1.693, Test accuracy: 50.06
Round  97: Global train loss: -5.275, Global test loss: 1.204, Global test accuracy: 59.16
Round  98, Train loss: -4.855, Test loss: 1.654, Test accuracy: 50.29
Round  98: Global train loss: -4.855, Global test loss: 1.201, Global test accuracy: 59.21
Round  99, Train loss: -4.951, Test loss: 1.629, Test accuracy: 50.51
Round  99: Global train loss: -4.951, Global test loss: 1.196, Global test accuracy: 59.37
Final Round: Train loss: 1.108, Test loss: 1.356, Test accuracy: 54.24
Final Round: Global train loss: 1.108, Global test loss: 1.177, Global test accuracy: 59.80
Average accuracy final 10 rounds: 49.732
Average global accuracy final 10 rounds: 58.6195
2517.4234714508057
[]
[17.545, 21.745, 25.32, 28.885, 31.005, 31.56, 33.175, 35.31, 36.67, 36.995, 37.815, 38.98, 40.0, 39.92, 39.84, 40.085, 41.115, 41.275, 41.74, 42.775, 42.39, 42.895, 42.525, 42.995, 43.575, 43.57, 43.815, 44.025, 44.575, 44.76, 44.735, 44.875, 44.47, 44.36, 44.92, 44.985, 44.32, 44.13, 44.3, 44.415, 45.225, 45.805, 45.25, 45.83, 46.645, 46.735, 46.485, 46.385, 46.145, 45.685, 46.47, 46.75, 46.78, 46.72, 46.795, 46.83, 46.97, 47.185, 47.25, 46.81, 46.99, 46.49, 46.96, 46.97, 47.275, 47.425, 47.7, 46.96, 47.855, 48.155, 48.29, 48.65, 48.58, 48.365, 48.445, 48.975, 48.66, 48.765, 49.005, 48.705, 48.085, 48.395, 48.785, 48.615, 48.295, 48.34, 48.73, 48.47, 48.735, 49.265, 48.925, 49.215, 49.58, 49.47, 49.665, 49.77, 49.835, 50.06, 50.29, 50.51, 54.24]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.306, Test loss: 2.305, Test accuracy: 10.10 

Round   0, Global train loss: 2.306, Global test loss: 2.305, Global test accuracy: 10.10 

Round   1, Train loss: 2.306, Test loss: 2.305, Test accuracy: 10.09 

Round   1, Global train loss: 2.306, Global test loss: 2.305, Global test accuracy: 10.10 

Round   2, Train loss: 2.305, Test loss: 2.305, Test accuracy: 10.10 

Round   2, Global train loss: 2.305, Global test loss: 2.305, Global test accuracy: 10.14 

Round   3, Train loss: 2.305, Test loss: 2.305, Test accuracy: 10.07 

Round   3, Global train loss: 2.305, Global test loss: 2.305, Global test accuracy: 10.14 

Round   4, Train loss: 2.305, Test loss: 2.305, Test accuracy: 10.13 

Round   4, Global train loss: 2.305, Global test loss: 2.305, Global test accuracy: 10.16 

Round   5, Train loss: 2.304, Test loss: 2.305, Test accuracy: 10.13 

Round   5, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 10.16 

Round   6, Train loss: 2.304, Test loss: 2.304, Test accuracy: 10.20 

Round   6, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 10.20 

Round   7, Train loss: 2.304, Test loss: 2.304, Test accuracy: 10.21 

Round   7, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 10.24 

Round   8, Train loss: 2.304, Test loss: 2.304, Test accuracy: 10.21 

Round   8, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 10.32 

Round   9, Train loss: 2.304, Test loss: 2.304, Test accuracy: 10.28 

Round   9, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 10.23 

Round  10, Train loss: 2.305, Test loss: 2.304, Test accuracy: 10.38 

Round  10, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 10.37 

Round  11, Train loss: 2.304, Test loss: 2.304, Test accuracy: 10.35 

Round  11, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.48 

Round  12, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.38 

Round  12, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.41 

Round  13, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.51 

Round  13, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.49 

Round  14, Train loss: 2.305, Test loss: 2.303, Test accuracy: 10.46 

Round  14, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 10.64 

Round  15, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.56 

Round  15, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.69 

Round  16, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.56 

Round  16, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.74 

Round  17, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.55 

Round  17, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.63 

Round  18, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.63 

Round  18, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.89 

Round  19, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.63 

Round  19, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.85 

Round  20, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.66 

Round  20, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 10.89 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.76 

Round  21, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.04 

Round  22, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.75 

Round  22, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.88 

Round  23, Train loss: 2.303, Test loss: 2.301, Test accuracy: 10.74 

Round  23, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 10.99 

Round  24, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.91 

Round  24, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.13 

Round  25, Train loss: 2.302, Test loss: 2.301, Test accuracy: 10.85 

Round  25, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 10.87 

Round  26, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.93 

Round  26, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 11.39 

Round  27, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.09 

Round  27, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 11.52 

Round  28, Train loss: 2.299, Test loss: 2.300, Test accuracy: 11.18 

Round  28, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 11.55 

Round  29, Train loss: 2.301, Test loss: 2.300, Test accuracy: 11.23 

Round  29, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 11.35 

Round  30, Train loss: 2.300, Test loss: 2.300, Test accuracy: 11.31 

Round  30, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 11.36 

Round  31, Train loss: 2.300, Test loss: 2.299, Test accuracy: 11.38 

Round  31, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 11.54 

Round  32, Train loss: 2.300, Test loss: 2.299, Test accuracy: 11.49 

Round  32, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 11.77 

Round  33, Train loss: 2.299, Test loss: 2.299, Test accuracy: 11.60 

Round  33, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 11.71 

Round  34, Train loss: 2.299, Test loss: 2.299, Test accuracy: 11.57 

Round  34, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 11.80 

Round  35, Train loss: 2.299, Test loss: 2.299, Test accuracy: 11.71 

Round  35, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 11.86 

Round  36, Train loss: 2.299, Test loss: 2.299, Test accuracy: 11.77 

Round  36, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 12.11 

Round  37, Train loss: 2.298, Test loss: 2.298, Test accuracy: 11.95 

Round  37, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 12.16 

Round  38, Train loss: 2.297, Test loss: 2.298, Test accuracy: 12.17 

Round  38, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 12.69 

Round  39, Train loss: 2.297, Test loss: 2.298, Test accuracy: 12.15 

Round  39, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 12.61 

Round  40, Train loss: 2.298, Test loss: 2.297, Test accuracy: 12.30 

Round  40, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 13.40 

Round  41, Train loss: 2.296, Test loss: 2.297, Test accuracy: 12.82 

Round  41, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 13.91 

Round  42, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.13 

Round  42, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 14.05 

Round  43, Train loss: 2.298, Test loss: 2.296, Test accuracy: 13.54 

Round  43, Global train loss: 2.298, Global test loss: 2.295, Global test accuracy: 14.43 

Round  44, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.77 

Round  44, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 14.21 

Round  45, Train loss: 2.297, Test loss: 2.296, Test accuracy: 13.84 

Round  45, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 14.76 

Round  46, Train loss: 2.295, Test loss: 2.296, Test accuracy: 14.18 

Round  46, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 14.70 

Round  47, Train loss: 2.296, Test loss: 2.295, Test accuracy: 14.60 

Round  47, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 15.38 

Round  48, Train loss: 2.296, Test loss: 2.295, Test accuracy: 14.71 

Round  48, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 15.43 

Round  49, Train loss: 2.295, Test loss: 2.294, Test accuracy: 14.98 

Round  49, Global train loss: 2.295, Global test loss: 2.293, Global test accuracy: 15.68 

Round  50, Train loss: 2.294, Test loss: 2.294, Test accuracy: 15.12 

Round  50, Global train loss: 2.294, Global test loss: 2.293, Global test accuracy: 15.76 

Round  51, Train loss: 2.295, Test loss: 2.293, Test accuracy: 15.34 

Round  51, Global train loss: 2.295, Global test loss: 2.292, Global test accuracy: 15.96 

Round  52, Train loss: 2.293, Test loss: 2.293, Test accuracy: 15.53 

Round  52, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 15.88 

Round  53, Train loss: 2.293, Test loss: 2.293, Test accuracy: 15.56 

Round  53, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 16.12 

Round  54, Train loss: 2.293, Test loss: 2.292, Test accuracy: 15.57 

Round  54, Global train loss: 2.293, Global test loss: 2.291, Global test accuracy: 15.76 

Round  55, Train loss: 2.293, Test loss: 2.292, Test accuracy: 15.87 

Round  55, Global train loss: 2.293, Global test loss: 2.291, Global test accuracy: 16.25 

Round  56, Train loss: 2.293, Test loss: 2.291, Test accuracy: 16.25 

Round  56, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 16.59 

Round  57, Train loss: 2.293, Test loss: 2.291, Test accuracy: 16.27 

Round  57, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 16.84 

Round  58, Train loss: 2.292, Test loss: 2.290, Test accuracy: 16.51 

Round  58, Global train loss: 2.292, Global test loss: 2.289, Global test accuracy: 16.98 

Round  59, Train loss: 2.291, Test loss: 2.290, Test accuracy: 16.45 

Round  59, Global train loss: 2.291, Global test loss: 2.289, Global test accuracy: 16.93 

Round  60, Train loss: 2.291, Test loss: 2.289, Test accuracy: 16.66 

Round  60, Global train loss: 2.291, Global test loss: 2.288, Global test accuracy: 16.82 

Round  61, Train loss: 2.292, Test loss: 2.289, Test accuracy: 16.66 

Round  61, Global train loss: 2.292, Global test loss: 2.288, Global test accuracy: 17.07 

Round  62, Train loss: 2.290, Test loss: 2.288, Test accuracy: 16.75 

Round  62, Global train loss: 2.290, Global test loss: 2.287, Global test accuracy: 17.19 

Round  63, Train loss: 2.289, Test loss: 2.288, Test accuracy: 16.73 

Round  63, Global train loss: 2.289, Global test loss: 2.287, Global test accuracy: 17.12 

Round  64, Train loss: 2.289, Test loss: 2.287, Test accuracy: 16.75 

Round  64, Global train loss: 2.289, Global test loss: 2.286, Global test accuracy: 17.11 

Round  65, Train loss: 2.288, Test loss: 2.287, Test accuracy: 16.73 

Round  65, Global train loss: 2.288, Global test loss: 2.286, Global test accuracy: 17.16 

Round  66, Train loss: 2.288, Test loss: 2.286, Test accuracy: 16.75 

Round  66, Global train loss: 2.288, Global test loss: 2.285, Global test accuracy: 16.75 

Round  67, Train loss: 2.286, Test loss: 2.285, Test accuracy: 16.68 

Round  67, Global train loss: 2.286, Global test loss: 2.284, Global test accuracy: 16.92 

Round  68, Train loss: 2.286, Test loss: 2.285, Test accuracy: 16.84 

Round  68, Global train loss: 2.286, Global test loss: 2.283, Global test accuracy: 17.14 

Round  69, Train loss: 2.286, Test loss: 2.284, Test accuracy: 16.89 

Round  69, Global train loss: 2.286, Global test loss: 2.283, Global test accuracy: 17.06 

Round  70, Train loss: 2.286, Test loss: 2.283, Test accuracy: 16.93 

Round  70, Global train loss: 2.286, Global test loss: 2.282, Global test accuracy: 17.04 

Round  71, Train loss: 2.285, Test loss: 2.282, Test accuracy: 16.94 

Round  71, Global train loss: 2.285, Global test loss: 2.281, Global test accuracy: 17.07 

Round  72, Train loss: 2.285, Test loss: 2.282, Test accuracy: 16.86 

Round  72, Global train loss: 2.285, Global test loss: 2.281, Global test accuracy: 16.75 

Round  73, Train loss: 2.284, Test loss: 2.282, Test accuracy: 16.75 

Round  73, Global train loss: 2.284, Global test loss: 2.280, Global test accuracy: 16.35 

Round  74, Train loss: 2.284, Test loss: 2.281, Test accuracy: 16.66 

Round  74, Global train loss: 2.284, Global test loss: 2.279, Global test accuracy: 16.12 

Round  75, Train loss: 2.283, Test loss: 2.280, Test accuracy: 16.52 

Round  75, Global train loss: 2.283, Global test loss: 2.278, Global test accuracy: 16.52 

Round  76, Train loss: 2.282, Test loss: 2.279, Test accuracy: 16.59 

Round  76, Global train loss: 2.282, Global test loss: 2.278, Global test accuracy: 16.64 

Round  77, Train loss: 2.282, Test loss: 2.279, Test accuracy: 16.71 

Round  77, Global train loss: 2.282, Global test loss: 2.277, Global test accuracy: 16.74 

Round  78, Train loss: 2.281, Test loss: 2.278, Test accuracy: 16.57 

Round  78, Global train loss: 2.281, Global test loss: 2.276, Global test accuracy: 16.80 

Round  79, Train loss: 2.282, Test loss: 2.277, Test accuracy: 16.91 

Round  79, Global train loss: 2.282, Global test loss: 2.276, Global test accuracy: 17.40 

Round  80, Train loss: 2.281, Test loss: 2.277, Test accuracy: 16.98 

Round  80, Global train loss: 2.281, Global test loss: 2.275, Global test accuracy: 17.39 

Round  81, Train loss: 2.279, Test loss: 2.276, Test accuracy: 16.98 

Round  81, Global train loss: 2.279, Global test loss: 2.274, Global test accuracy: 17.18 

Round  82, Train loss: 2.277, Test loss: 2.275, Test accuracy: 17.02 

Round  82, Global train loss: 2.277, Global test loss: 2.273, Global test accuracy: 16.75 

Round  83, Train loss: 2.276, Test loss: 2.274, Test accuracy: 16.87 

Round  83, Global train loss: 2.276, Global test loss: 2.272, Global test accuracy: 16.82 

Round  84, Train loss: 2.279, Test loss: 2.273, Test accuracy: 16.98 

Round  84, Global train loss: 2.279, Global test loss: 2.271, Global test accuracy: 17.00 

Round  85, Train loss: 2.275, Test loss: 2.273, Test accuracy: 16.98 

Round  85, Global train loss: 2.275, Global test loss: 2.270, Global test accuracy: 16.93 

Round  86, Train loss: 2.280, Test loss: 2.272, Test accuracy: 17.07 

Round  86, Global train loss: 2.280, Global test loss: 2.269, Global test accuracy: 17.40 

Round  87, Train loss: 2.274, Test loss: 2.270, Test accuracy: 17.31 

Round  87, Global train loss: 2.274, Global test loss: 2.268, Global test accuracy: 18.03 

Round  88, Train loss: 2.274, Test loss: 2.269, Test accuracy: 17.50 

Round  88, Global train loss: 2.274, Global test loss: 2.266, Global test accuracy: 17.61 

Round  89, Train loss: 2.271, Test loss: 2.268, Test accuracy: 17.54 

Round  89, Global train loss: 2.271, Global test loss: 2.266, Global test accuracy: 17.44 

Round  90, Train loss: 2.271, Test loss: 2.267, Test accuracy: 17.85 

Round  90, Global train loss: 2.271, Global test loss: 2.265, Global test accuracy: 17.34 

Round  91, Train loss: 2.270, Test loss: 2.266, Test accuracy: 17.87 

Round  91, Global train loss: 2.270, Global test loss: 2.264, Global test accuracy: 17.67 

Round  92, Train loss: 2.270, Test loss: 2.265, Test accuracy: 17.80 

Round  92, Global train loss: 2.270, Global test loss: 2.263, Global test accuracy: 17.67 

Round  93, Train loss: 2.273, Test loss: 2.264, Test accuracy: 17.58 

Round  93, Global train loss: 2.273, Global test loss: 2.262, Global test accuracy: 17.51 

Round  94, Train loss: 2.271, Test loss: 2.263, Test accuracy: 17.50 

Round  94, Global train loss: 2.271, Global test loss: 2.261, Global test accuracy: 17.55 

Round  95, Train loss: 2.269, Test loss: 2.262, Test accuracy: 17.45 

Round  95, Global train loss: 2.269, Global test loss: 2.260, Global test accuracy: 18.03 

Round  96, Train loss: 2.269, Test loss: 2.261, Test accuracy: 17.59 

Round  96, Global train loss: 2.269, Global test loss: 2.259, Global test accuracy: 18.16 

Round  97, Train loss: 2.267, Test loss: 2.260, Test accuracy: 17.67 

Round  97, Global train loss: 2.267, Global test loss: 2.258, Global test accuracy: 18.11 

Round  98, Train loss: 2.267, Test loss: 2.260, Test accuracy: 17.79 

Round  98, Global train loss: 2.267, Global test loss: 2.257, Global test accuracy: 17.89 

Round  99, Train loss: 2.263, Test loss: 2.258, Test accuracy: 17.92 

Round  99, Global train loss: 2.263, Global test loss: 2.255, Global test accuracy: 17.88 

Round 100, Train loss: 2.264, Test loss: 2.257, Test accuracy: 17.77 

Round 100, Global train loss: 2.264, Global test loss: 2.254, Global test accuracy: 17.61 

Round 101, Train loss: 2.264, Test loss: 2.255, Test accuracy: 17.79 

Round 101, Global train loss: 2.264, Global test loss: 2.253, Global test accuracy: 17.70 

Round 102, Train loss: 2.266, Test loss: 2.254, Test accuracy: 17.67 

Round 102, Global train loss: 2.266, Global test loss: 2.252, Global test accuracy: 17.57 

Round 103, Train loss: 2.261, Test loss: 2.253, Test accuracy: 17.75 

Round 103, Global train loss: 2.261, Global test loss: 2.250, Global test accuracy: 17.78 

Round 104, Train loss: 2.258, Test loss: 2.252, Test accuracy: 17.88 

Round 104, Global train loss: 2.258, Global test loss: 2.249, Global test accuracy: 18.18 

Round 105, Train loss: 2.260, Test loss: 2.250, Test accuracy: 17.82 

Round 105, Global train loss: 2.260, Global test loss: 2.248, Global test accuracy: 18.47 

Round 106, Train loss: 2.261, Test loss: 2.249, Test accuracy: 17.98 

Round 106, Global train loss: 2.261, Global test loss: 2.247, Global test accuracy: 18.59 

Round 107, Train loss: 2.261, Test loss: 2.249, Test accuracy: 18.14 

Round 107, Global train loss: 2.261, Global test loss: 2.246, Global test accuracy: 18.70 

Round 108, Train loss: 2.262, Test loss: 2.248, Test accuracy: 18.32 

Round 108, Global train loss: 2.262, Global test loss: 2.245, Global test accuracy: 18.45 

Round 109, Train loss: 2.257, Test loss: 2.246, Test accuracy: 18.24 

Round 109, Global train loss: 2.257, Global test loss: 2.242, Global test accuracy: 18.54 

Round 110, Train loss: 2.260, Test loss: 2.245, Test accuracy: 18.30 

Round 110, Global train loss: 2.260, Global test loss: 2.241, Global test accuracy: 18.43 

Round 111, Train loss: 2.255, Test loss: 2.243, Test accuracy: 18.46 

Round 111, Global train loss: 2.255, Global test loss: 2.240, Global test accuracy: 18.64 

Round 112, Train loss: 2.252, Test loss: 2.241, Test accuracy: 18.30 

Round 112, Global train loss: 2.252, Global test loss: 2.238, Global test accuracy: 18.96 

Round 113, Train loss: 2.253, Test loss: 2.240, Test accuracy: 18.36 

Round 113, Global train loss: 2.253, Global test loss: 2.237, Global test accuracy: 18.43 

Round 114, Train loss: 2.254, Test loss: 2.239, Test accuracy: 18.22 

Round 114, Global train loss: 2.254, Global test loss: 2.235, Global test accuracy: 18.62 

Round 115, Train loss: 2.253, Test loss: 2.238, Test accuracy: 18.30 

Round 115, Global train loss: 2.253, Global test loss: 2.234, Global test accuracy: 18.71 

Round 116, Train loss: 2.248, Test loss: 2.237, Test accuracy: 18.52 

Round 116, Global train loss: 2.248, Global test loss: 2.233, Global test accuracy: 18.84 

Round 117, Train loss: 2.251, Test loss: 2.235, Test accuracy: 18.61 

Round 117, Global train loss: 2.251, Global test loss: 2.233, Global test accuracy: 18.73 

Round 118, Train loss: 2.252, Test loss: 2.234, Test accuracy: 18.77 

Round 118, Global train loss: 2.252, Global test loss: 2.231, Global test accuracy: 18.95 

Round 119, Train loss: 2.250, Test loss: 2.233, Test accuracy: 18.84 

Round 119, Global train loss: 2.250, Global test loss: 2.229, Global test accuracy: 19.56 

Round 120, Train loss: 2.249, Test loss: 2.232, Test accuracy: 18.97 

Round 120, Global train loss: 2.249, Global test loss: 2.228, Global test accuracy: 19.23 

Round 121, Train loss: 2.256, Test loss: 2.231, Test accuracy: 19.08 

Round 121, Global train loss: 2.256, Global test loss: 2.229, Global test accuracy: 19.77 

Round 122, Train loss: 2.244, Test loss: 2.231, Test accuracy: 19.00 

Round 122, Global train loss: 2.244, Global test loss: 2.228, Global test accuracy: 20.12 

Round 123, Train loss: 2.245, Test loss: 2.230, Test accuracy: 19.20 

Round 123, Global train loss: 2.245, Global test loss: 2.227, Global test accuracy: 20.48 

Round 124, Train loss: 2.245, Test loss: 2.228, Test accuracy: 19.51 

Round 124, Global train loss: 2.245, Global test loss: 2.225, Global test accuracy: 20.70 

Round 125, Train loss: 2.243, Test loss: 2.227, Test accuracy: 19.75 

Round 125, Global train loss: 2.243, Global test loss: 2.223, Global test accuracy: 20.82 

Round 126, Train loss: 2.241, Test loss: 2.225, Test accuracy: 20.02 

Round 126, Global train loss: 2.241, Global test loss: 2.221, Global test accuracy: 20.52 

Round 127, Train loss: 2.248, Test loss: 2.224, Test accuracy: 20.02 

Round 127, Global train loss: 2.248, Global test loss: 2.220, Global test accuracy: 20.86 

Round 128, Train loss: 2.239, Test loss: 2.222, Test accuracy: 19.96 

Round 128, Global train loss: 2.239, Global test loss: 2.219, Global test accuracy: 20.59 

Round 129, Train loss: 2.238, Test loss: 2.221, Test accuracy: 19.95 

Round 129, Global train loss: 2.238, Global test loss: 2.218, Global test accuracy: 20.04 

Round 130, Train loss: 2.239, Test loss: 2.220, Test accuracy: 20.00 

Round 130, Global train loss: 2.239, Global test loss: 2.217, Global test accuracy: 20.48 

Round 131, Train loss: 2.239, Test loss: 2.218, Test accuracy: 20.00 

Round 131, Global train loss: 2.239, Global test loss: 2.215, Global test accuracy: 20.39 

Round 132, Train loss: 2.235, Test loss: 2.217, Test accuracy: 19.88 

Round 132, Global train loss: 2.235, Global test loss: 2.214, Global test accuracy: 19.82 

Round 133, Train loss: 2.236, Test loss: 2.216, Test accuracy: 19.80 

Round 133, Global train loss: 2.236, Global test loss: 2.213, Global test accuracy: 20.05 

Round 134, Train loss: 2.239, Test loss: 2.214, Test accuracy: 19.90 

Round 134, Global train loss: 2.239, Global test loss: 2.211, Global test accuracy: 20.12 

Round 135, Train loss: 2.242, Test loss: 2.213, Test accuracy: 19.73 

Round 135, Global train loss: 2.242, Global test loss: 2.211, Global test accuracy: 20.45 

Round 136, Train loss: 2.226, Test loss: 2.212, Test accuracy: 20.07 

Round 136, Global train loss: 2.226, Global test loss: 2.210, Global test accuracy: 21.46 

Round 137, Train loss: 2.237, Test loss: 2.211, Test accuracy: 20.41 

Round 137, Global train loss: 2.237, Global test loss: 2.208, Global test accuracy: 21.36 

Round 138, Train loss: 2.239, Test loss: 2.210, Test accuracy: 20.94 

Round 138, Global train loss: 2.239, Global test loss: 2.209, Global test accuracy: 21.21 

Round 139, Train loss: 2.236, Test loss: 2.210, Test accuracy: 20.70 

Round 139, Global train loss: 2.236, Global test loss: 2.208, Global test accuracy: 20.96 

Round 140, Train loss: 2.237, Test loss: 2.209, Test accuracy: 20.87 

Round 140, Global train loss: 2.237, Global test loss: 2.206, Global test accuracy: 21.48 

Round 141, Train loss: 2.230, Test loss: 2.207, Test accuracy: 20.94 

Round 141, Global train loss: 2.230, Global test loss: 2.203, Global test accuracy: 21.36 

Round 142, Train loss: 2.230, Test loss: 2.205, Test accuracy: 20.88 

Round 142, Global train loss: 2.230, Global test loss: 2.200, Global test accuracy: 20.89 

Round 143, Train loss: 2.230, Test loss: 2.202, Test accuracy: 20.88 

Round 143, Global train loss: 2.230, Global test loss: 2.197, Global test accuracy: 20.56 

Round 144, Train loss: 2.233, Test loss: 2.201, Test accuracy: 20.68 

Round 144, Global train loss: 2.233, Global test loss: 2.197, Global test accuracy: 20.34 

Round 145, Train loss: 2.240, Test loss: 2.200, Test accuracy: 20.35 

Round 145, Global train loss: 2.240, Global test loss: 2.195, Global test accuracy: 20.70 

Round 146, Train loss: 2.239, Test loss: 2.198, Test accuracy: 20.33 

Round 146, Global train loss: 2.239, Global test loss: 2.194, Global test accuracy: 20.60 

Round 147, Train loss: 2.240, Test loss: 2.196, Test accuracy: 20.50 

Round 147, Global train loss: 2.240, Global test loss: 2.193, Global test accuracy: 20.59 

Round 148, Train loss: 2.238, Test loss: 2.196, Test accuracy: 20.47 

Round 148, Global train loss: 2.238, Global test loss: 2.192, Global test accuracy: 20.95 

Round 149, Train loss: 2.227, Test loss: 2.194, Test accuracy: 20.52 

Round 149, Global train loss: 2.227, Global test loss: 2.191, Global test accuracy: 21.14 

Round 150, Train loss: 2.219, Test loss: 2.193, Test accuracy: 20.34 

Round 150, Global train loss: 2.219, Global test loss: 2.188, Global test accuracy: 20.25 

Round 151, Train loss: 2.227, Test loss: 2.191, Test accuracy: 20.43 

Round 151, Global train loss: 2.227, Global test loss: 2.187, Global test accuracy: 20.64 

Round 152, Train loss: 2.224, Test loss: 2.190, Test accuracy: 19.96 

Round 152, Global train loss: 2.224, Global test loss: 2.184, Global test accuracy: 20.11 

Round 153, Train loss: 2.223, Test loss: 2.188, Test accuracy: 20.16 

Round 153, Global train loss: 2.223, Global test loss: 2.185, Global test accuracy: 20.99 

Round 154, Train loss: 2.229, Test loss: 2.188, Test accuracy: 20.49 

Round 154, Global train loss: 2.229, Global test loss: 2.184, Global test accuracy: 21.04 

Round 155, Train loss: 2.225, Test loss: 2.187, Test accuracy: 20.89 

Round 155, Global train loss: 2.225, Global test loss: 2.184, Global test accuracy: 21.79 

Round 156, Train loss: 2.223, Test loss: 2.186, Test accuracy: 21.07 

Round 156, Global train loss: 2.223, Global test loss: 2.182, Global test accuracy: 21.86 

Round 157, Train loss: 2.235, Test loss: 2.185, Test accuracy: 20.98 

Round 157, Global train loss: 2.235, Global test loss: 2.182, Global test accuracy: 21.82 

Round 158, Train loss: 2.219, Test loss: 2.184, Test accuracy: 21.28 

Round 158, Global train loss: 2.219, Global test loss: 2.179, Global test accuracy: 21.59 

Round 159, Train loss: 2.224, Test loss: 2.183, Test accuracy: 21.25 

Round 159, Global train loss: 2.224, Global test loss: 2.180, Global test accuracy: 21.76 

Round 160, Train loss: 2.221, Test loss: 2.183, Test accuracy: 21.40 

Round 160, Global train loss: 2.221, Global test loss: 2.180, Global test accuracy: 22.27 

Round 161, Train loss: 2.231, Test loss: 2.182, Test accuracy: 21.57 

Round 161, Global train loss: 2.231, Global test loss: 2.180, Global test accuracy: 22.29 

Round 162, Train loss: 2.219, Test loss: 2.181, Test accuracy: 21.48 

Round 162, Global train loss: 2.219, Global test loss: 2.179, Global test accuracy: 21.88 

Round 163, Train loss: 2.214, Test loss: 2.180, Test accuracy: 21.73 

Round 163, Global train loss: 2.214, Global test loss: 2.176, Global test accuracy: 21.80 

Round 164, Train loss: 2.227, Test loss: 2.178, Test accuracy: 21.82 

Round 164, Global train loss: 2.227, Global test loss: 2.175, Global test accuracy: 21.79 

Round 165, Train loss: 2.215, Test loss: 2.178, Test accuracy: 21.50 

Round 165, Global train loss: 2.215, Global test loss: 2.174, Global test accuracy: 21.20 

Round 166, Train loss: 2.212, Test loss: 2.177, Test accuracy: 21.27 

Round 166, Global train loss: 2.212, Global test loss: 2.176, Global test accuracy: 21.39 

Round 167, Train loss: 2.218, Test loss: 2.176, Test accuracy: 21.13 

Round 167, Global train loss: 2.218, Global test loss: 2.175, Global test accuracy: 21.46 

Round 168, Train loss: 2.214, Test loss: 2.175, Test accuracy: 21.45 

Round 168, Global train loss: 2.214, Global test loss: 2.170, Global test accuracy: 21.36 

Round 169, Train loss: 2.210, Test loss: 2.174, Test accuracy: 21.43 

Round 169, Global train loss: 2.210, Global test loss: 2.171, Global test accuracy: 21.80 

Round 170, Train loss: 2.206, Test loss: 2.173, Test accuracy: 21.61 

Round 170, Global train loss: 2.206, Global test loss: 2.169, Global test accuracy: 21.82 

Round 171, Train loss: nan, Test loss: nan, Test accuracy: 21.17 

Round 171, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 172, Train loss: nan, Test loss: nan, Test accuracy: 18.34 

Round 172, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 173, Train loss: nan, Test loss: nan, Test accuracy: 16.01 

Round 173, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 174, Train loss: nan, Test loss: nan, Test accuracy: 14.80 

Round 174, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 175, Train loss: nan, Test loss: nan, Test accuracy: 13.05 

Round 175, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 176, Train loss: nan, Test loss: nan, Test accuracy: 13.05 

Round 176, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 177, Train loss: nan, Test loss: nan, Test accuracy: 11.85 

Round 177, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 178, Train loss: nan, Test loss: nan, Test accuracy: 10.56 

Round 178, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 179, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 179, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 180, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 180, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 181, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 181, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 182, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 182, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 183, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 183, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 184, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 184, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 185, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 185, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 186, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 186, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 187, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 187, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 188, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 188, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 189, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 189, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 190, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 190, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Average accuracy final 10 rounds: 10.0 

Average global accuracy final 10 rounds: 10.0 

4927.758755683899
[1.466712236404419, 2.7236335277557373, 3.978339433670044, 5.232625961303711, 6.485891819000244, 7.740081787109375, 8.994297981262207, 10.249079465866089, 11.506065368652344, 12.759115934371948, 14.013778448104858, 15.272258996963501, 16.52525758743286, 17.778409719467163, 19.033945560455322, 20.291788339614868, 21.548319816589355, 22.80437445640564, 24.059430599212646, 25.313444137573242, 26.566450834274292, 27.82225775718689, 29.077772617340088, 30.33394956588745, 31.590067148208618, 32.84569430351257, 34.098621129989624, 35.3551025390625, 36.60916519165039, 37.86421489715576, 39.1199107170105, 40.373859167099, 41.63034987449646, 42.887250900268555, 44.144726276397705, 45.40307879447937, 46.65567994117737, 47.91016411781311, 49.169267892837524, 50.424912214279175, 51.68072175979614, 52.93556833267212, 54.189576148986816, 55.44371223449707, 56.70344591140747, 57.95997929573059, 59.214969873428345, 60.47101831436157, 61.725276947021484, 62.979323625564575, 64.23258972167969, 65.4866406917572, 66.74074339866638, 67.9968159198761, 69.25147008895874, 70.5057852268219, 71.76142883300781, 73.01971125602722, 74.2713315486908, 75.52512073516846, 76.77223014831543, 78.01799774169922, 79.27097511291504, 80.5202796459198, 81.76730155944824, 83.01287364959717, 84.26167821884155, 85.50741004943848, 86.75692081451416, 88.00292181968689, 89.25381135940552, 90.5047345161438, 91.75387215614319, 92.9954264163971, 94.24270606040955, 95.48290467262268, 96.72759532928467, 97.97529172897339, 99.21912169456482, 100.4634439945221, 101.71463251113892, 102.96060585975647, 104.20422697067261, 105.45011401176453, 106.69875359535217, 107.94423174858093, 109.18814992904663, 110.43472623825073, 111.67774152755737, 112.92261695861816, 114.17019581794739, 115.41840767860413, 116.66331791877747, 117.86600422859192, 119.04875493049622, 120.24573922157288, 121.4501633644104, 122.6559944152832, 123.86325454711914, 125.05443143844604, 126.29251194000244, 127.52804327011108, 128.76281714439392, 130.00960993766785, 131.24997282028198, 132.49240684509277, 133.72869777679443, 134.96863079071045, 136.20804357528687, 137.44813871383667, 138.68933081626892, 139.9342164993286, 141.17193174362183, 142.4131214618683, 143.65452432632446, 144.89147853851318, 146.1286497116089, 147.36715745925903, 148.6050579547882, 149.84223747253418, 151.07457637786865, 152.3108034133911, 153.54476046562195, 154.7797815799713, 156.02010297775269, 157.26455450057983, 158.50318717956543, 159.74116444587708, 160.97790789604187, 162.21510219573975, 163.45227336883545, 164.68818879127502, 165.9256772994995, 167.16660499572754, 168.40793800354004, 169.65022659301758, 170.8910562992096, 172.13056302070618, 173.36828017234802, 174.60939478874207, 175.85065984725952, 177.09135270118713, 178.32923340797424, 179.5691409111023, 180.80978918075562, 182.04451274871826, 183.27880597114563, 184.5222806930542, 185.75427556037903, 186.99180579185486, 188.22704410552979, 189.46735167503357, 190.70662355422974, 191.9483814239502, 193.18729162216187, 194.42660975456238, 195.66982173919678, 196.91193437576294, 198.14900398254395, 199.3873417377472, 200.62810826301575, 201.86547327041626, 203.10077953338623, 204.34261870384216, 205.44905400276184, 206.55542922019958, 207.66432428359985, 208.77288794517517, 209.87891721725464, 210.9813516139984, 212.08338379859924, 213.19073963165283, 214.29072642326355, 215.39291834831238, 216.49737119674683, 217.60041189193726, 218.70631074905396, 219.81078720092773, 220.913494348526, 222.01697826385498, 223.12141394615173, 224.223162651062, 225.3323256969452, 226.43539714813232, 227.53696966171265, 228.64392137527466, 229.75577807426453, 230.8677361011505, 231.97688460350037, 233.08684635162354, 234.2011649608612, 235.3090465068817, 236.4165267944336, 237.52791953086853, 238.63919115066528, 239.74684500694275, 240.84945940971375, 241.95810794830322, 243.0694432258606, 244.177152633667, 245.2859709262848, 246.39456462860107, 247.50613617897034, 248.6189739704132, 249.7321171760559, 250.84125423431396, 251.95507073402405, 253.06179428100586, 254.17202234268188, 255.27891731262207, 256.385703086853, 257.49319410324097, 258.6001362800598, 259.7078900337219, 260.81698870658875, 261.9259066581726, 263.03516721725464, 264.1451451778412, 265.25180768966675, 266.3636405467987, 267.4773371219635, 268.57483434677124, 269.68136525154114, 270.79253697395325, 271.903888463974, 273.0085971355438, 274.1171786785126, 275.22236156463623, 276.332612991333, 277.4419524669647, 278.54916167259216, 279.65652418136597, 280.762788772583, 281.87161898612976, 282.9821548461914, 284.0899782180786, 285.1978991031647, 286.3037848472595, 287.4112310409546, 288.5203449726105, 289.6263818740845, 290.73489689826965, 291.84182357788086, 292.9493360519409, 294.0550992488861, 295.16070532798767, 296.2682418823242, 297.37720131874084, 298.4864430427551, 299.5971565246582, 300.70518946647644, 301.8134820461273, 302.9185378551483, 304.02481961250305, 305.13174533843994, 306.2406885623932, 307.34725189208984, 308.4559152126312, 309.56559658050537, 310.67430305480957, 311.78249979019165, 312.8894257545471, 313.996041059494, 315.10746574401855, 316.2158443927765, 317.3256437778473, 318.4349672794342, 319.54105043411255, 320.6508951187134, 321.7578582763672, 322.8478126525879, 323.95387601852417, 325.0618236064911, 326.15746331214905, 327.2484290599823, 328.3406698703766, 329.4419548511505, 330.54103803634644, 331.63864374160767, 332.7376399040222, 333.8421378135681, 334.94292545318604, 336.047785282135, 337.1502342224121, 338.2513463497162, 339.35628724098206, 340.4596092700958, 341.5623245239258, 342.6669318675995, 343.7685580253601, 344.8684515953064, 345.97383403778076, 347.0723614692688, 348.17166781425476, 349.272851228714, 350.3773400783539, 351.4786376953125, 352.58115887641907, 353.6837270259857, 354.78550910949707, 356.98344683647156]
[10.1, 10.085, 10.1, 10.075, 10.13, 10.13, 10.2, 10.215, 10.21, 10.275, 10.375, 10.35, 10.385, 10.51, 10.46, 10.56, 10.56, 10.555, 10.635, 10.635, 10.66, 10.755, 10.75, 10.745, 10.91, 10.85, 10.925, 11.09, 11.175, 11.235, 11.315, 11.385, 11.495, 11.595, 11.57, 11.71, 11.765, 11.945, 12.17, 12.155, 12.3, 12.825, 13.135, 13.545, 13.77, 13.84, 14.175, 14.595, 14.71, 14.98, 15.115, 15.34, 15.53, 15.565, 15.575, 15.87, 16.245, 16.27, 16.51, 16.445, 16.655, 16.66, 16.755, 16.73, 16.75, 16.73, 16.755, 16.685, 16.835, 16.895, 16.93, 16.94, 16.855, 16.755, 16.66, 16.525, 16.59, 16.71, 16.575, 16.905, 16.985, 16.98, 17.025, 16.87, 16.98, 16.985, 17.07, 17.31, 17.495, 17.54, 17.85, 17.87, 17.8, 17.58, 17.495, 17.445, 17.595, 17.67, 17.79, 17.92, 17.765, 17.785, 17.67, 17.745, 17.875, 17.82, 17.98, 18.145, 18.325, 18.24, 18.3, 18.465, 18.3, 18.365, 18.22, 18.3, 18.515, 18.615, 18.775, 18.835, 18.97, 19.08, 19.0, 19.205, 19.51, 19.75, 20.015, 20.02, 19.96, 19.95, 20.0, 20.0, 19.88, 19.805, 19.9, 19.73, 20.075, 20.405, 20.94, 20.705, 20.87, 20.94, 20.875, 20.875, 20.675, 20.35, 20.33, 20.505, 20.47, 20.525, 20.335, 20.435, 19.96, 20.16, 20.49, 20.885, 21.07, 20.98, 21.28, 21.255, 21.4, 21.575, 21.485, 21.725, 21.825, 21.5, 21.265, 21.13, 21.45, 21.425, 21.605, 21.17, 18.335, 16.01, 14.805, 13.055, 13.055, 11.85, 10.565, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.989, Test loss: 1.048, Test accuracy: 41.82 

Round   0, Global train loss: 0.989, Global test loss: 1.104, Global test accuracy: 35.65 

Round   1, Train loss: 0.903, Test loss: 0.986, Test accuracy: 46.97 

Round   1, Global train loss: 0.903, Global test loss: 1.118, Global test accuracy: 35.43 

Round   2, Train loss: 0.785, Test loss: 0.938, Test accuracy: 51.33 

Round   2, Global train loss: 0.785, Global test loss: 1.183, Global test accuracy: 35.35 

Round   3, Train loss: 0.719, Test loss: 0.837, Test accuracy: 59.00 

Round   3, Global train loss: 0.719, Global test loss: 1.128, Global test accuracy: 38.10 

Round   4, Train loss: 0.685, Test loss: 0.804, Test accuracy: 60.63 

Round   4, Global train loss: 0.685, Global test loss: 1.154, Global test accuracy: 37.77 

Round   5, Train loss: 0.748, Test loss: 0.736, Test accuracy: 65.67 

Round   5, Global train loss: 0.748, Global test loss: 1.117, Global test accuracy: 38.33 

Round   6, Train loss: 0.661, Test loss: 0.721, Test accuracy: 66.72 

Round   6, Global train loss: 0.661, Global test loss: 1.221, Global test accuracy: 34.88 

Round   7, Train loss: 0.631, Test loss: 0.706, Test accuracy: 67.85 

Round   7, Global train loss: 0.631, Global test loss: 1.176, Global test accuracy: 37.12 

Round   8, Train loss: 0.592, Test loss: 0.699, Test accuracy: 67.87 

Round   8, Global train loss: 0.592, Global test loss: 1.163, Global test accuracy: 35.90 

Round   9, Train loss: 0.588, Test loss: 0.682, Test accuracy: 68.38 

Round   9, Global train loss: 0.588, Global test loss: 1.225, Global test accuracy: 33.33 

Round  10, Train loss: 0.578, Test loss: 0.689, Test accuracy: 67.90 

Round  10, Global train loss: 0.578, Global test loss: 1.200, Global test accuracy: 34.98 

Round  11, Train loss: 0.654, Test loss: 0.676, Test accuracy: 69.27 

Round  11, Global train loss: 0.654, Global test loss: 1.120, Global test accuracy: 37.98 

Round  12, Train loss: 0.584, Test loss: 0.674, Test accuracy: 69.70 

Round  12, Global train loss: 0.584, Global test loss: 1.173, Global test accuracy: 35.35 

Round  13, Train loss: 0.555, Test loss: 0.663, Test accuracy: 71.17 

Round  13, Global train loss: 0.555, Global test loss: 1.214, Global test accuracy: 34.43 

Round  14, Train loss: 0.544, Test loss: 0.663, Test accuracy: 71.52 

Round  14, Global train loss: 0.544, Global test loss: 1.148, Global test accuracy: 36.98 

Round  15, Train loss: 0.513, Test loss: 0.660, Test accuracy: 71.33 

Round  15, Global train loss: 0.513, Global test loss: 1.169, Global test accuracy: 36.03 

Round  16, Train loss: 0.471, Test loss: 0.666, Test accuracy: 71.88 

Round  16, Global train loss: 0.471, Global test loss: 1.211, Global test accuracy: 34.45 

Round  17, Train loss: 0.504, Test loss: 0.685, Test accuracy: 71.10 

Round  17, Global train loss: 0.504, Global test loss: 1.538, Global test accuracy: 36.07 

Round  18, Train loss: 0.415, Test loss: 0.661, Test accuracy: 72.63 

Round  18, Global train loss: 0.415, Global test loss: 1.245, Global test accuracy: 36.65 

Round  19, Train loss: 0.457, Test loss: 0.652, Test accuracy: 73.02 

Round  19, Global train loss: 0.457, Global test loss: 1.195, Global test accuracy: 34.65 

Round  20, Train loss: 0.461, Test loss: 0.647, Test accuracy: 73.33 

Round  20, Global train loss: 0.461, Global test loss: 1.193, Global test accuracy: 37.83 

Round  21, Train loss: 0.398, Test loss: 0.662, Test accuracy: 73.00 

Round  21, Global train loss: 0.398, Global test loss: 1.364, Global test accuracy: 31.33 

Round  22, Train loss: 0.371, Test loss: 0.667, Test accuracy: 73.55 

Round  22, Global train loss: 0.371, Global test loss: 1.312, Global test accuracy: 33.80 

Round  23, Train loss: 0.409, Test loss: 0.681, Test accuracy: 73.37 

Round  23, Global train loss: 0.409, Global test loss: 1.150, Global test accuracy: 37.42 

Round  24, Train loss: 0.395, Test loss: 0.697, Test accuracy: 72.93 

Round  24, Global train loss: 0.395, Global test loss: 1.343, Global test accuracy: 35.43 

Round  25, Train loss: 0.390, Test loss: 0.685, Test accuracy: 73.80 

Round  25, Global train loss: 0.390, Global test loss: 1.132, Global test accuracy: 38.08 

Round  26, Train loss: 0.399, Test loss: 0.668, Test accuracy: 73.87 

Round  26, Global train loss: 0.399, Global test loss: 1.205, Global test accuracy: 35.78 

Round  27, Train loss: 0.345, Test loss: 0.672, Test accuracy: 73.97 

Round  27, Global train loss: 0.345, Global test loss: 1.345, Global test accuracy: 35.97 

Round  28, Train loss: 0.362, Test loss: 0.679, Test accuracy: 74.15 

Round  28, Global train loss: 0.362, Global test loss: 1.155, Global test accuracy: 39.12 

Round  29, Train loss: 0.363, Test loss: 0.679, Test accuracy: 74.42 

Round  29, Global train loss: 0.363, Global test loss: 1.501, Global test accuracy: 38.32 

Round  30, Train loss: 0.372, Test loss: 0.671, Test accuracy: 74.88 

Round  30, Global train loss: 0.372, Global test loss: 1.211, Global test accuracy: 37.38 

Round  31, Train loss: 0.363, Test loss: 0.671, Test accuracy: 75.02 

Round  31, Global train loss: 0.363, Global test loss: 1.357, Global test accuracy: 37.93 

Round  32, Train loss: 0.341, Test loss: 0.671, Test accuracy: 75.63 

Round  32, Global train loss: 0.341, Global test loss: 1.363, Global test accuracy: 37.28 

Round  33, Train loss: 0.306, Test loss: 0.678, Test accuracy: 75.17 

Round  33, Global train loss: 0.306, Global test loss: 1.206, Global test accuracy: 37.05 

Round  34, Train loss: 0.309, Test loss: 0.688, Test accuracy: 74.85 

Round  34, Global train loss: 0.309, Global test loss: 1.226, Global test accuracy: 36.63 

Round  35, Train loss: 0.311, Test loss: 0.681, Test accuracy: 74.98 

Round  35, Global train loss: 0.311, Global test loss: 1.468, Global test accuracy: 35.58 

Round  36, Train loss: 0.336, Test loss: 0.696, Test accuracy: 75.22 

Round  36, Global train loss: 0.336, Global test loss: 1.198, Global test accuracy: 34.73 

Round  37, Train loss: 0.280, Test loss: 0.704, Test accuracy: 75.05 

Round  37, Global train loss: 0.280, Global test loss: 1.232, Global test accuracy: 35.02 

Round  38, Train loss: 0.357, Test loss: 0.720, Test accuracy: 74.92 

Round  38, Global train loss: 0.357, Global test loss: 1.590, Global test accuracy: 37.28 

Round  39, Train loss: 0.306, Test loss: 0.726, Test accuracy: 74.58 

Round  39, Global train loss: 0.306, Global test loss: 1.149, Global test accuracy: 39.73 

Round  40, Train loss: 0.242, Test loss: 0.720, Test accuracy: 75.07 

Round  40, Global train loss: 0.242, Global test loss: 1.464, Global test accuracy: 35.97 

Round  41, Train loss: 0.330, Test loss: 0.727, Test accuracy: 75.02 

Round  41, Global train loss: 0.330, Global test loss: 1.231, Global test accuracy: 33.20 

Round  42, Train loss: 0.248, Test loss: 0.739, Test accuracy: 75.27 

Round  42, Global train loss: 0.248, Global test loss: 1.902, Global test accuracy: 35.77 

Round  43, Train loss: 0.243, Test loss: 0.785, Test accuracy: 74.93 

Round  43, Global train loss: 0.243, Global test loss: 1.614, Global test accuracy: 37.08 

Round  44, Train loss: 0.243, Test loss: 0.771, Test accuracy: 75.45 

Round  44, Global train loss: 0.243, Global test loss: 1.377, Global test accuracy: 35.57 

Round  45, Train loss: 0.181, Test loss: 0.771, Test accuracy: 75.72 

Round  45, Global train loss: 0.181, Global test loss: 1.795, Global test accuracy: 35.10 

Round  46, Train loss: 0.225, Test loss: 0.778, Test accuracy: 75.10 

Round  46, Global train loss: 0.225, Global test loss: 1.275, Global test accuracy: 40.53 

Round  47, Train loss: 0.244, Test loss: 0.808, Test accuracy: 74.87 

Round  47, Global train loss: 0.244, Global test loss: 1.457, Global test accuracy: 37.15 

Round  48, Train loss: 0.274, Test loss: 0.781, Test accuracy: 75.53 

Round  48, Global train loss: 0.274, Global test loss: 1.224, Global test accuracy: 36.85 

Round  49, Train loss: 0.209, Test loss: 0.796, Test accuracy: 75.67 

Round  49, Global train loss: 0.209, Global test loss: 1.284, Global test accuracy: 34.72 

Round  50, Train loss: 0.164, Test loss: 0.796, Test accuracy: 75.73 

Round  50, Global train loss: 0.164, Global test loss: 1.664, Global test accuracy: 37.37 

Round  51, Train loss: 0.166, Test loss: 0.822, Test accuracy: 75.95 

Round  51, Global train loss: 0.166, Global test loss: 1.527, Global test accuracy: 35.70 

Round  52, Train loss: 0.182, Test loss: 0.820, Test accuracy: 75.95 

Round  52, Global train loss: 0.182, Global test loss: 1.234, Global test accuracy: 37.28 

Round  53, Train loss: 0.178, Test loss: 0.807, Test accuracy: 76.50 

Round  53, Global train loss: 0.178, Global test loss: 1.349, Global test accuracy: 38.25 

Round  54, Train loss: 0.148, Test loss: 0.824, Test accuracy: 76.28 

Round  54, Global train loss: 0.148, Global test loss: 1.583, Global test accuracy: 32.73 

Round  55, Train loss: 0.168, Test loss: 0.841, Test accuracy: 75.88 

Round  55, Global train loss: 0.168, Global test loss: 1.259, Global test accuracy: 34.55 

Round  56, Train loss: 0.179, Test loss: 0.845, Test accuracy: 75.38 

Round  56, Global train loss: 0.179, Global test loss: 1.394, Global test accuracy: 36.50 

Round  57, Train loss: 0.137, Test loss: 0.866, Test accuracy: 75.62 

Round  57, Global train loss: 0.137, Global test loss: 1.647, Global test accuracy: 37.73 

Round  58, Train loss: 0.193, Test loss: 0.855, Test accuracy: 75.93 

Round  58, Global train loss: 0.193, Global test loss: 1.285, Global test accuracy: 35.65 

Round  59, Train loss: 0.209, Test loss: 0.834, Test accuracy: 75.98 

Round  59, Global train loss: 0.209, Global test loss: 1.303, Global test accuracy: 37.60 

Round  60, Train loss: 0.163, Test loss: 0.858, Test accuracy: 75.85 

Round  60, Global train loss: 0.163, Global test loss: 1.264, Global test accuracy: 39.38 

Round  61, Train loss: 0.174, Test loss: 0.872, Test accuracy: 75.98 

Round  61, Global train loss: 0.174, Global test loss: 1.242, Global test accuracy: 37.97 

Round  62, Train loss: 0.118, Test loss: 0.899, Test accuracy: 75.50 

Round  62, Global train loss: 0.118, Global test loss: 1.283, Global test accuracy: 38.35 

Round  63, Train loss: 0.111, Test loss: 0.925, Test accuracy: 75.37 

Round  63, Global train loss: 0.111, Global test loss: 2.231, Global test accuracy: 37.85 

Round  64, Train loss: 0.099, Test loss: 0.961, Test accuracy: 74.97 

Round  64, Global train loss: 0.099, Global test loss: 1.279, Global test accuracy: 33.80 

Round  65, Train loss: 0.132, Test loss: 0.930, Test accuracy: 75.90 

Round  65, Global train loss: 0.132, Global test loss: 1.617, Global test accuracy: 37.05 

Round  66, Train loss: 0.112, Test loss: 0.955, Test accuracy: 75.33 

Round  66, Global train loss: 0.112, Global test loss: 1.246, Global test accuracy: 36.75 

Round  67, Train loss: 0.138, Test loss: 0.969, Test accuracy: 75.42 

Round  67, Global train loss: 0.138, Global test loss: 1.685, Global test accuracy: 36.27 

Round  68, Train loss: 0.110, Test loss: 0.965, Test accuracy: 76.08 

Round  68, Global train loss: 0.110, Global test loss: 1.671, Global test accuracy: 34.75 

Round  69, Train loss: 0.135, Test loss: 0.955, Test accuracy: 76.58 

Round  69, Global train loss: 0.135, Global test loss: 1.330, Global test accuracy: 37.52 

Round  70, Train loss: 0.114, Test loss: 0.950, Test accuracy: 76.92 

Round  70, Global train loss: 0.114, Global test loss: 1.578, Global test accuracy: 34.48 

Round  71, Train loss: 0.123, Test loss: 0.984, Test accuracy: 76.50 

Round  71, Global train loss: 0.123, Global test loss: 1.557, Global test accuracy: 36.42 

Round  72, Train loss: 0.106, Test loss: 0.998, Test accuracy: 76.53 

Round  72, Global train loss: 0.106, Global test loss: 1.761, Global test accuracy: 36.20 

Round  73, Train loss: 0.097, Test loss: 0.978, Test accuracy: 77.02 

Round  73, Global train loss: 0.097, Global test loss: 2.065, Global test accuracy: 35.93 

Round  74, Train loss: 0.125, Test loss: 0.979, Test accuracy: 77.08 

Round  74, Global train loss: 0.125, Global test loss: 1.697, Global test accuracy: 37.57 

Round  75, Train loss: 0.103, Test loss: 0.994, Test accuracy: 76.57 

Round  75, Global train loss: 0.103, Global test loss: 1.655, Global test accuracy: 35.25 

Round  76, Train loss: 0.100, Test loss: 1.001, Test accuracy: 76.60 

Round  76, Global train loss: 0.100, Global test loss: 1.257, Global test accuracy: 35.90 

Round  77, Train loss: 0.114, Test loss: 1.020, Test accuracy: 76.47 

Round  77, Global train loss: 0.114, Global test loss: 1.516, Global test accuracy: 37.38 

Round  78, Train loss: 0.101, Test loss: 1.022, Test accuracy: 76.32 

Round  78, Global train loss: 0.101, Global test loss: 1.283, Global test accuracy: 37.62 

Round  79, Train loss: 0.142, Test loss: 1.034, Test accuracy: 76.23 

Round  79, Global train loss: 0.142, Global test loss: 1.300, Global test accuracy: 38.93 

Round  80, Train loss: 0.094, Test loss: 1.036, Test accuracy: 76.25 

Round  80, Global train loss: 0.094, Global test loss: 1.402, Global test accuracy: 34.70 

Round  81, Train loss: 0.061, Test loss: 1.041, Test accuracy: 76.32 

Round  81, Global train loss: 0.061, Global test loss: 1.568, Global test accuracy: 39.02 

Round  82, Train loss: 0.098, Test loss: 1.034, Test accuracy: 76.20 

Round  82, Global train loss: 0.098, Global test loss: 1.304, Global test accuracy: 37.75 

Round  83, Train loss: 0.082, Test loss: 1.046, Test accuracy: 76.13 

Round  83, Global train loss: 0.082, Global test loss: 1.221, Global test accuracy: 35.35 

Round  84, Train loss: 0.108, Test loss: 1.065, Test accuracy: 76.20 

Round  84, Global train loss: 0.108, Global test loss: 1.359, Global test accuracy: 39.40 

Round  85, Train loss: 0.060, Test loss: 1.088, Test accuracy: 76.02 

Round  85, Global train loss: 0.060, Global test loss: 1.832, Global test accuracy: 36.87 

Round  86, Train loss: 0.090, Test loss: 1.085, Test accuracy: 75.95 

Round  86, Global train loss: 0.090, Global test loss: 1.318, Global test accuracy: 34.55 

Round  87, Train loss: 0.066, Test loss: 1.128, Test accuracy: 75.73 

Round  87, Global train loss: 0.066, Global test loss: 1.529, Global test accuracy: 36.32 

Round  88, Train loss: 0.115, Test loss: 1.146, Test accuracy: 75.63 

Round  88, Global train loss: 0.115, Global test loss: 1.325, Global test accuracy: 35.53 

Round  89, Train loss: 0.086, Test loss: 1.162, Test accuracy: 75.97 

Round  89, Global train loss: 0.086, Global test loss: 1.435, Global test accuracy: 36.17 

Round  90, Train loss: 0.080, Test loss: 1.160, Test accuracy: 76.07 

Round  90, Global train loss: 0.080, Global test loss: 1.495, Global test accuracy: 39.85 

Round  91, Train loss: 0.071, Test loss: 1.116, Test accuracy: 76.55 

Round  91, Global train loss: 0.071, Global test loss: 2.152, Global test accuracy: 34.15 

Round  92, Train loss: 0.063, Test loss: 1.215, Test accuracy: 75.58 

Round  92, Global train loss: 0.063, Global test loss: 1.463, Global test accuracy: 36.60 

Round  93, Train loss: 0.086, Test loss: 1.206, Test accuracy: 75.75 

Round  93, Global train loss: 0.086, Global test loss: 1.326, Global test accuracy: 31.57 

Round  94, Train loss: 0.081, Test loss: 1.124, Test accuracy: 76.53 

Round  94, Global train loss: 0.081, Global test loss: 1.455, Global test accuracy: 35.45 

Round  95, Train loss: 0.059, Test loss: 1.145, Test accuracy: 76.22 

Round  95, Global train loss: 0.059, Global test loss: 1.974, Global test accuracy: 35.73 

Round  96, Train loss: 0.074, Test loss: 1.157, Test accuracy: 76.13 

Round  96, Global train loss: 0.074, Global test loss: 1.537, Global test accuracy: 37.08 

Round  97, Train loss: 0.055, Test loss: 1.152, Test accuracy: 76.42 

Round  97, Global train loss: 0.055, Global test loss: 1.758, Global test accuracy: 37.12 

Round  98, Train loss: 0.045, Test loss: 1.178, Test accuracy: 76.20 

Round  98, Global train loss: 0.045, Global test loss: 1.405, Global test accuracy: 34.62 

Round  99, Train loss: 0.073, Test loss: 1.143, Test accuracy: 76.80 

Round  99, Global train loss: 0.073, Global test loss: 1.676, Global test accuracy: 38.55 

Final Round, Train loss: 0.061, Test loss: 1.195, Test accuracy: 76.27 

Final Round, Global train loss: 0.061, Global test loss: 1.676, Global test accuracy: 38.55 

Average accuracy final 10 rounds: 76.225 

Average global accuracy final 10 rounds: 36.071666666666665 

722.5871198177338
[0.9218835830688477, 1.6185333728790283, 2.3209476470947266, 3.0246589183807373, 3.727982521057129, 4.427566766738892, 5.122441291809082, 5.81853985786438, 6.5117621421813965, 7.210034608840942, 7.905099630355835, 8.605513334274292, 9.307677030563354, 10.006454706192017, 10.704431056976318, 11.400212287902832, 12.096696376800537, 12.794545888900757, 13.493293523788452, 14.190524101257324, 14.89089035987854, 15.586651086807251, 16.283572673797607, 16.97909164428711, 17.67746615409851, 18.37653088569641, 19.075366497039795, 19.77293872833252, 20.472245693206787, 21.168445348739624, 21.866695404052734, 22.563560009002686, 23.26149559020996, 23.962178230285645, 24.66262650489807, 25.359566926956177, 26.051939725875854, 26.74265456199646, 27.435314178466797, 28.12867546081543, 28.81982731819153, 29.51209783554077, 30.205121517181396, 30.9022057056427, 31.597675323486328, 32.29168391227722, 32.98549795150757, 33.681551933288574, 34.380098819732666, 35.07489991188049, 35.76637530326843, 36.46137976646423, 37.15604853630066, 37.8535635471344, 38.546141624450684, 39.241668939590454, 39.93640971183777, 40.63245177268982, 41.324437618255615, 42.02441883087158, 42.718323945999146, 43.41345548629761, 44.11376237869263, 44.8038535118103, 45.49504566192627, 46.18683838844299, 46.87877416610718, 47.57880258560181, 48.274024963378906, 48.9679000377655, 49.6590371131897, 50.3538920879364, 51.04613542556763, 51.73527979850769, 52.426748275756836, 53.11666250228882, 53.81096959114075, 54.50636863708496, 55.19710373878479, 55.88890838623047, 56.585432291030884, 57.278265714645386, 57.96995806694031, 58.66392922401428, 59.357709884643555, 60.05583572387695, 60.75241136550903, 61.443758487701416, 62.140395164489746, 62.83590245246887, 63.528618574142456, 64.22254538536072, 64.91542863845825, 65.61146664619446, 66.30859589576721, 67.002610206604, 67.70508050918579, 68.40074634552002, 69.09242129325867, 69.78976488113403, 71.1782693862915]
[41.81666666666667, 46.96666666666667, 51.333333333333336, 59.0, 60.63333333333333, 65.66666666666667, 66.71666666666667, 67.85, 67.86666666666666, 68.38333333333334, 67.9, 69.26666666666667, 69.7, 71.16666666666667, 71.51666666666667, 71.33333333333333, 71.88333333333334, 71.1, 72.63333333333334, 73.01666666666667, 73.33333333333333, 73.0, 73.55, 73.36666666666666, 72.93333333333334, 73.8, 73.86666666666666, 73.96666666666667, 74.15, 74.41666666666667, 74.88333333333334, 75.01666666666667, 75.63333333333334, 75.16666666666667, 74.85, 74.98333333333333, 75.21666666666667, 75.05, 74.91666666666667, 74.58333333333333, 75.06666666666666, 75.01666666666667, 75.26666666666667, 74.93333333333334, 75.45, 75.71666666666667, 75.1, 74.86666666666666, 75.53333333333333, 75.66666666666667, 75.73333333333333, 75.95, 75.95, 76.5, 76.28333333333333, 75.88333333333334, 75.38333333333334, 75.61666666666666, 75.93333333333334, 75.98333333333333, 75.85, 75.98333333333333, 75.5, 75.36666666666666, 74.96666666666667, 75.9, 75.33333333333333, 75.41666666666667, 76.08333333333333, 76.58333333333333, 76.91666666666667, 76.5, 76.53333333333333, 77.01666666666667, 77.08333333333333, 76.56666666666666, 76.6, 76.46666666666667, 76.31666666666666, 76.23333333333333, 76.25, 76.31666666666666, 76.2, 76.13333333333334, 76.2, 76.01666666666667, 75.95, 75.73333333333333, 75.63333333333334, 75.96666666666667, 76.06666666666666, 76.55, 75.58333333333333, 75.75, 76.53333333333333, 76.21666666666667, 76.13333333333334, 76.41666666666667, 76.2, 76.8, 76.26666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.997, Test loss: 1.087, Test accuracy: 36.55 

Round   0, Global train loss: 0.997, Global test loss: 1.133, Global test accuracy: 32.97 

Round   1, Train loss: 0.850, Test loss: 1.160, Test accuracy: 39.88 

Round   1, Global train loss: 0.850, Global test loss: 1.274, Global test accuracy: 33.37 

Round   2, Train loss: 0.822, Test loss: 1.006, Test accuracy: 46.57 

Round   2, Global train loss: 0.822, Global test loss: 1.195, Global test accuracy: 36.30 

Round   3, Train loss: 0.787, Test loss: 0.891, Test accuracy: 54.98 

Round   3, Global train loss: 0.787, Global test loss: 1.160, Global test accuracy: 38.37 

Round   4, Train loss: 0.807, Test loss: 0.808, Test accuracy: 58.80 

Round   4, Global train loss: 0.807, Global test loss: 1.155, Global test accuracy: 36.02 

Round   5, Train loss: 0.690, Test loss: 0.718, Test accuracy: 65.95 

Round   5, Global train loss: 0.690, Global test loss: 1.116, Global test accuracy: 38.07 

Round   6, Train loss: 0.690, Test loss: 0.702, Test accuracy: 66.88 

Round   6, Global train loss: 0.690, Global test loss: 1.125, Global test accuracy: 38.13 

Round   7, Train loss: 0.658, Test loss: 0.668, Test accuracy: 69.28 

Round   7, Global train loss: 0.658, Global test loss: 1.275, Global test accuracy: 39.05 

Round   8, Train loss: 0.729, Test loss: 0.666, Test accuracy: 70.00 

Round   8, Global train loss: 0.729, Global test loss: 1.304, Global test accuracy: 36.12 

Round   9, Train loss: 0.670, Test loss: 0.655, Test accuracy: 71.08 

Round   9, Global train loss: 0.670, Global test loss: 1.600, Global test accuracy: 35.22 

Round  10, Train loss: 0.670, Test loss: 0.648, Test accuracy: 71.35 

Round  10, Global train loss: 0.670, Global test loss: 1.208, Global test accuracy: 38.17 

Round  11, Train loss: 0.587, Test loss: 0.646, Test accuracy: 71.38 

Round  11, Global train loss: 0.587, Global test loss: 1.446, Global test accuracy: 37.47 

Round  12, Train loss: 0.678, Test loss: 0.651, Test accuracy: 70.92 

Round  12, Global train loss: 0.678, Global test loss: 1.222, Global test accuracy: 35.23 

Round  13, Train loss: 0.638, Test loss: 0.649, Test accuracy: 71.07 

Round  13, Global train loss: 0.638, Global test loss: 1.172, Global test accuracy: 40.77 

Round  14, Train loss: 0.654, Test loss: 0.630, Test accuracy: 72.00 

Round  14, Global train loss: 0.654, Global test loss: 1.361, Global test accuracy: 38.87 

Round  15, Train loss: 0.713, Test loss: 0.621, Test accuracy: 72.12 

Round  15, Global train loss: 0.713, Global test loss: 1.246, Global test accuracy: 37.37 

Round  16, Train loss: 0.625, Test loss: 0.618, Test accuracy: 72.17 

Round  16, Global train loss: 0.625, Global test loss: 1.239, Global test accuracy: 39.62 

Round  17, Train loss: 0.614, Test loss: 0.616, Test accuracy: 72.53 

Round  17, Global train loss: 0.614, Global test loss: 1.316, Global test accuracy: 38.53 

Round  18, Train loss: 0.628, Test loss: 0.606, Test accuracy: 73.15 

Round  18, Global train loss: 0.628, Global test loss: 1.265, Global test accuracy: 37.60 

Round  19, Train loss: 0.596, Test loss: 0.613, Test accuracy: 72.93 

Round  19, Global train loss: 0.596, Global test loss: 1.208, Global test accuracy: 39.57 

Round  20, Train loss: 0.617, Test loss: 0.612, Test accuracy: 72.77 

Round  20, Global train loss: 0.617, Global test loss: 1.300, Global test accuracy: 39.67 

Round  21, Train loss: 0.553, Test loss: 0.612, Test accuracy: 72.57 

Round  21, Global train loss: 0.553, Global test loss: 1.668, Global test accuracy: 36.28 

Round  22, Train loss: 0.499, Test loss: 0.612, Test accuracy: 72.87 

Round  22, Global train loss: 0.499, Global test loss: 1.307, Global test accuracy: 37.65 

Round  23, Train loss: 0.622, Test loss: 0.615, Test accuracy: 72.87 

Round  23, Global train loss: 0.622, Global test loss: 1.185, Global test accuracy: 40.90 

Round  24, Train loss: 0.587, Test loss: 0.619, Test accuracy: 73.60 

Round  24, Global train loss: 0.587, Global test loss: 1.228, Global test accuracy: 39.08 

Round  25, Train loss: 0.480, Test loss: 0.595, Test accuracy: 74.03 

Round  25, Global train loss: 0.480, Global test loss: 1.377, Global test accuracy: 39.53 

Round  26, Train loss: 0.575, Test loss: 0.588, Test accuracy: 74.08 

Round  26, Global train loss: 0.575, Global test loss: 1.187, Global test accuracy: 40.67 

Round  27, Train loss: 0.519, Test loss: 0.582, Test accuracy: 74.97 

Round  27, Global train loss: 0.519, Global test loss: 1.594, Global test accuracy: 37.58 

Round  28, Train loss: 0.533, Test loss: 0.588, Test accuracy: 74.85 

Round  28, Global train loss: 0.533, Global test loss: 1.459, Global test accuracy: 39.17 

Round  29, Train loss: 0.504, Test loss: 0.588, Test accuracy: 74.93 

Round  29, Global train loss: 0.504, Global test loss: 1.393, Global test accuracy: 40.02 

Round  30, Train loss: 0.536, Test loss: 0.586, Test accuracy: 75.15 

Round  30, Global train loss: 0.536, Global test loss: 1.265, Global test accuracy: 39.08 

Round  31, Train loss: 0.530, Test loss: 0.604, Test accuracy: 74.75 

Round  31, Global train loss: 0.530, Global test loss: 1.318, Global test accuracy: 40.40 

Round  32, Train loss: 0.485, Test loss: 0.606, Test accuracy: 74.72 

Round  32, Global train loss: 0.485, Global test loss: 1.434, Global test accuracy: 37.83 

Round  33, Train loss: 0.521, Test loss: 0.589, Test accuracy: 74.98 

Round  33, Global train loss: 0.521, Global test loss: 1.224, Global test accuracy: 39.30 

Round  34, Train loss: 0.481, Test loss: 0.601, Test accuracy: 74.97 

Round  34, Global train loss: 0.481, Global test loss: 2.070, Global test accuracy: 35.42 

Round  35, Train loss: 0.510, Test loss: 0.608, Test accuracy: 74.52 

Round  35, Global train loss: 0.510, Global test loss: 1.208, Global test accuracy: 40.03 

Round  36, Train loss: 0.442, Test loss: 0.612, Test accuracy: 75.07 

Round  36, Global train loss: 0.442, Global test loss: 1.387, Global test accuracy: 39.43 

Round  37, Train loss: 0.453, Test loss: 0.602, Test accuracy: 75.25 

Round  37, Global train loss: 0.453, Global test loss: 1.952, Global test accuracy: 37.67 

Round  38, Train loss: 0.455, Test loss: 0.585, Test accuracy: 75.80 

Round  38, Global train loss: 0.455, Global test loss: 1.398, Global test accuracy: 40.40 

Round  39, Train loss: 0.425, Test loss: 0.590, Test accuracy: 75.78 

Round  39, Global train loss: 0.425, Global test loss: 1.361, Global test accuracy: 39.57 

Round  40, Train loss: 0.417, Test loss: 0.609, Test accuracy: 75.02 

Round  40, Global train loss: 0.417, Global test loss: 1.713, Global test accuracy: 36.35 

Round  41, Train loss: 0.454, Test loss: 0.600, Test accuracy: 75.78 

Round  41, Global train loss: 0.454, Global test loss: 1.408, Global test accuracy: 39.65 

Round  42, Train loss: 0.365, Test loss: 0.589, Test accuracy: 75.90 

Round  42, Global train loss: 0.365, Global test loss: 1.299, Global test accuracy: 38.80 

Round  43, Train loss: 0.467, Test loss: 0.578, Test accuracy: 76.32 

Round  43, Global train loss: 0.467, Global test loss: 1.411, Global test accuracy: 40.45 

Round  44, Train loss: 0.475, Test loss: 0.585, Test accuracy: 76.38 

Round  44, Global train loss: 0.475, Global test loss: 1.313, Global test accuracy: 37.83 

Round  45, Train loss: 0.419, Test loss: 0.584, Test accuracy: 76.43 

Round  45, Global train loss: 0.419, Global test loss: 1.297, Global test accuracy: 40.83 

Round  46, Train loss: 0.496, Test loss: 0.584, Test accuracy: 77.20 

Round  46, Global train loss: 0.496, Global test loss: 1.318, Global test accuracy: 41.58 

Round  47, Train loss: 0.436, Test loss: 0.587, Test accuracy: 77.43 

Round  47, Global train loss: 0.436, Global test loss: 1.327, Global test accuracy: 39.28 

Round  48, Train loss: 0.386, Test loss: 0.576, Test accuracy: 77.92 

Round  48, Global train loss: 0.386, Global test loss: 1.479, Global test accuracy: 40.45 

Round  49, Train loss: 0.389, Test loss: 0.579, Test accuracy: 77.60 

Round  49, Global train loss: 0.389, Global test loss: 1.584, Global test accuracy: 38.08 

Round  50, Train loss: 0.372, Test loss: 0.606, Test accuracy: 76.58 

Round  50, Global train loss: 0.372, Global test loss: 1.327, Global test accuracy: 41.18 

Round  51, Train loss: 0.403, Test loss: 0.611, Test accuracy: 76.30 

Round  51, Global train loss: 0.403, Global test loss: 1.687, Global test accuracy: 36.65 

Round  52, Train loss: 0.436, Test loss: 0.604, Test accuracy: 77.18 

Round  52, Global train loss: 0.436, Global test loss: 1.689, Global test accuracy: 37.60 

Round  53, Train loss: 0.410, Test loss: 0.604, Test accuracy: 76.83 

Round  53, Global train loss: 0.410, Global test loss: 1.743, Global test accuracy: 37.18 

Round  54, Train loss: 0.365, Test loss: 0.598, Test accuracy: 76.75 

Round  54, Global train loss: 0.365, Global test loss: 1.385, Global test accuracy: 40.15 

Round  55, Train loss: 0.342, Test loss: 0.608, Test accuracy: 76.52 

Round  55, Global train loss: 0.342, Global test loss: 1.444, Global test accuracy: 37.27 

Round  56, Train loss: 0.353, Test loss: 0.608, Test accuracy: 76.85 

Round  56, Global train loss: 0.353, Global test loss: 1.411, Global test accuracy: 39.42 

Round  57, Train loss: 0.422, Test loss: 0.620, Test accuracy: 76.68 

Round  57, Global train loss: 0.422, Global test loss: 1.478, Global test accuracy: 38.57 

Round  58, Train loss: 0.406, Test loss: 0.606, Test accuracy: 76.67 

Round  58, Global train loss: 0.406, Global test loss: 1.385, Global test accuracy: 40.02 

Round  59, Train loss: 0.423, Test loss: 0.614, Test accuracy: 76.22 

Round  59, Global train loss: 0.423, Global test loss: 1.475, Global test accuracy: 40.40 

Round  60, Train loss: 0.362, Test loss: 0.614, Test accuracy: 76.78 

Round  60, Global train loss: 0.362, Global test loss: 1.624, Global test accuracy: 36.97 

Round  61, Train loss: 0.350, Test loss: 0.623, Test accuracy: 76.73 

Round  61, Global train loss: 0.350, Global test loss: 1.393, Global test accuracy: 39.48 

Round  62, Train loss: 0.312, Test loss: 0.619, Test accuracy: 76.63 

Round  62, Global train loss: 0.312, Global test loss: 1.994, Global test accuracy: 37.63 

Round  63, Train loss: 0.378, Test loss: 0.624, Test accuracy: 76.68 

Round  63, Global train loss: 0.378, Global test loss: 1.488, Global test accuracy: 39.63 

Round  64, Train loss: 0.327, Test loss: 0.624, Test accuracy: 76.72 

Round  64, Global train loss: 0.327, Global test loss: 1.523, Global test accuracy: 41.63 

Round  65, Train loss: 0.380, Test loss: 0.620, Test accuracy: 77.02 

Round  65, Global train loss: 0.380, Global test loss: 1.758, Global test accuracy: 38.45 

Round  66, Train loss: 0.335, Test loss: 0.628, Test accuracy: 76.62 

Round  66, Global train loss: 0.335, Global test loss: 1.534, Global test accuracy: 40.40 

Round  67, Train loss: 0.324, Test loss: 0.640, Test accuracy: 76.48 

Round  67, Global train loss: 0.324, Global test loss: 1.589, Global test accuracy: 40.68 

Round  68, Train loss: 0.373, Test loss: 0.620, Test accuracy: 77.27 

Round  68, Global train loss: 0.373, Global test loss: 1.931, Global test accuracy: 39.18 

Round  69, Train loss: 0.371, Test loss: 0.642, Test accuracy: 76.60 

Round  69, Global train loss: 0.371, Global test loss: 1.807, Global test accuracy: 38.58 

Round  70, Train loss: 0.331, Test loss: 0.650, Test accuracy: 76.75 

Round  70, Global train loss: 0.331, Global test loss: 1.698, Global test accuracy: 39.18 

Round  71, Train loss: 0.301, Test loss: 0.662, Test accuracy: 76.50 

Round  71, Global train loss: 0.301, Global test loss: 1.961, Global test accuracy: 38.63 

Round  72, Train loss: 0.406, Test loss: 0.647, Test accuracy: 76.87 

Round  72, Global train loss: 0.406, Global test loss: 1.609, Global test accuracy: 39.70 

Round  73, Train loss: 0.296, Test loss: 0.630, Test accuracy: 77.28 

Round  73, Global train loss: 0.296, Global test loss: 2.061, Global test accuracy: 37.65 

Round  74, Train loss: 0.332, Test loss: 0.622, Test accuracy: 77.43 

Round  74, Global train loss: 0.332, Global test loss: 1.678, Global test accuracy: 40.13 

Round  75, Train loss: 0.337, Test loss: 0.631, Test accuracy: 77.43 

Round  75, Global train loss: 0.337, Global test loss: 1.727, Global test accuracy: 35.27 

Round  76, Train loss: 0.346, Test loss: 0.639, Test accuracy: 77.15 

Round  76, Global train loss: 0.346, Global test loss: 1.949, Global test accuracy: 38.38 

Round  77, Train loss: 0.335, Test loss: 0.657, Test accuracy: 76.78 

Round  77, Global train loss: 0.335, Global test loss: 2.032, Global test accuracy: 39.02 

Round  78, Train loss: 0.309, Test loss: 0.644, Test accuracy: 77.15 

Round  78, Global train loss: 0.309, Global test loss: 1.615, Global test accuracy: 37.90 

Round  79, Train loss: 0.339, Test loss: 0.622, Test accuracy: 77.72 

Round  79, Global train loss: 0.339, Global test loss: 1.652, Global test accuracy: 40.77 

Round  80, Train loss: 0.271, Test loss: 0.611, Test accuracy: 78.08 

Round  80, Global train loss: 0.271, Global test loss: 1.662, Global test accuracy: 39.28 

Round  81, Train loss: 0.290, Test loss: 0.637, Test accuracy: 78.07 

Round  81, Global train loss: 0.290, Global test loss: 1.743, Global test accuracy: 38.90 

Round  82, Train loss: 0.244, Test loss: 0.648, Test accuracy: 77.58 

Round  82, Global train loss: 0.244, Global test loss: 2.218, Global test accuracy: 39.30 

Round  83, Train loss: 0.355, Test loss: 0.640, Test accuracy: 77.58 

Round  83, Global train loss: 0.355, Global test loss: 1.603, Global test accuracy: 39.80 

Round  84, Train loss: 0.247, Test loss: 0.622, Test accuracy: 78.35 

Round  84, Global train loss: 0.247, Global test loss: 2.839, Global test accuracy: 37.83 

Round  85, Train loss: 0.324, Test loss: 0.629, Test accuracy: 77.97 

Round  85, Global train loss: 0.324, Global test loss: 1.555, Global test accuracy: 38.70 

Round  86, Train loss: 0.285, Test loss: 0.635, Test accuracy: 77.58 

Round  86, Global train loss: 0.285, Global test loss: 1.726, Global test accuracy: 38.52 

Round  87, Train loss: 0.276, Test loss: 0.647, Test accuracy: 77.58 

Round  87, Global train loss: 0.276, Global test loss: 1.666, Global test accuracy: 38.90 

Round  88, Train loss: 0.284, Test loss: 0.669, Test accuracy: 77.23 

Round  88, Global train loss: 0.284, Global test loss: 1.659, Global test accuracy: 38.95 

Round  89, Train loss: 0.263, Test loss: 0.682, Test accuracy: 76.58 

Round  89, Global train loss: 0.263, Global test loss: 2.104, Global test accuracy: 39.42 

Round  90, Train loss: 0.262, Test loss: 0.684, Test accuracy: 76.18 

Round  90, Global train loss: 0.262, Global test loss: 2.236, Global test accuracy: 36.87 

Round  91, Train loss: 0.256, Test loss: 0.670, Test accuracy: 76.52 

Round  91, Global train loss: 0.256, Global test loss: 2.000, Global test accuracy: 38.98 

Round  92, Train loss: 0.359, Test loss: 0.637, Test accuracy: 77.63 

Round  92, Global train loss: 0.359, Global test loss: 1.914, Global test accuracy: 39.62 

Round  93, Train loss: 0.314, Test loss: 0.653, Test accuracy: 77.37 

Round  93, Global train loss: 0.314, Global test loss: 1.577, Global test accuracy: 38.95 

Round  94, Train loss: 0.289, Test loss: 0.648, Test accuracy: 77.73 

Round  94, Global train loss: 0.289, Global test loss: 1.660, Global test accuracy: 40.53 

Round  95, Train loss: 0.306, Test loss: 0.665, Test accuracy: 77.28 

Round  95, Global train loss: 0.306, Global test loss: 1.474, Global test accuracy: 40.20 

Round  96, Train loss: 0.281, Test loss: 0.657, Test accuracy: 77.27 

Round  96, Global train loss: 0.281, Global test loss: 1.762, Global test accuracy: 39.88 

Round  97, Train loss: 0.286, Test loss: 0.655, Test accuracy: 77.23 

Round  97, Global train loss: 0.286, Global test loss: 1.766, Global test accuracy: 39.93 

Round  98, Train loss: 0.297, Test loss: 0.666, Test accuracy: 77.43 

Round  98, Global train loss: 0.297, Global test loss: 1.551, Global test accuracy: 40.35 

Round  99, Train loss: 0.248, Test loss: 0.668, Test accuracy: 77.63 

Round  99, Global train loss: 0.248, Global test loss: 1.804, Global test accuracy: 37.87 

Final Round, Train loss: 0.212, Test loss: 0.705, Test accuracy: 78.23 

Final Round, Global train loss: 0.212, Global test loss: 1.804, Global test accuracy: 37.87 

Average accuracy final 10 rounds: 77.22833333333334 

Average global accuracy final 10 rounds: 39.318333333333335 

664.6598126888275
[0.9206047058105469, 1.6166772842407227, 2.309502601623535, 3.0003275871276855, 3.691826343536377, 4.38657021522522, 5.084359645843506, 5.776538133621216, 6.371022462844849, 6.966843605041504, 7.561363697052002, 8.156400203704834, 8.754461288452148, 9.347538948059082, 9.946887016296387, 10.544645071029663, 11.142272233963013, 11.742678880691528, 12.34109878540039, 12.94319224357605, 13.541001081466675, 14.138991594314575, 14.739896297454834, 15.339054822921753, 15.93847131729126, 16.53528904914856, 17.133631467819214, 17.734504222869873, 18.33292818069458, 18.935176849365234, 19.532978773117065, 20.131032466888428, 20.73322629928589, 21.331620931625366, 21.93278479576111, 22.5285906791687, 23.127197265625, 23.728708028793335, 24.3266499042511, 24.927630186080933, 25.52419352531433, 26.122448921203613, 26.72318148612976, 27.320509672164917, 27.920421600341797, 28.513166189193726, 29.107484102249146, 29.70677089691162, 30.299622774124146, 30.894629955291748, 31.487657070159912, 32.08071279525757, 32.67498064041138, 33.266743421554565, 33.86292624473572, 34.4566535949707, 35.05078148841858, 35.64872717857361, 36.241872787475586, 36.8381712436676, 37.433640480041504, 38.027332067489624, 38.62588357925415, 39.22002291679382, 39.818543672561646, 40.41241121292114, 41.00666785240173, 41.60345697402954, 42.19489789009094, 42.79089713096619, 43.38551616668701, 43.98198366165161, 44.583399534225464, 45.18130874633789, 45.782599687576294, 46.37861180305481, 46.972315073013306, 47.56779670715332, 48.1588716506958, 48.75227212905884, 49.34714651107788, 49.93992853164673, 50.535550594329834, 51.128347635269165, 51.7277307510376, 52.32977223396301, 52.926186084747314, 53.52796411514282, 54.12467813491821, 54.72556447982788, 55.3269317150116, 55.92396855354309, 56.523454904556274, 57.1287887096405, 57.7323317527771, 58.33818554878235, 58.93847966194153, 59.53852605819702, 60.13523268699646, 60.73225498199463, 61.925276041030884]
[36.55, 39.88333333333333, 46.56666666666667, 54.983333333333334, 58.8, 65.95, 66.88333333333334, 69.28333333333333, 70.0, 71.08333333333333, 71.35, 71.38333333333334, 70.91666666666667, 71.06666666666666, 72.0, 72.11666666666666, 72.16666666666667, 72.53333333333333, 73.15, 72.93333333333334, 72.76666666666667, 72.56666666666666, 72.86666666666666, 72.86666666666666, 73.6, 74.03333333333333, 74.08333333333333, 74.96666666666667, 74.85, 74.93333333333334, 75.15, 74.75, 74.71666666666667, 74.98333333333333, 74.96666666666667, 74.51666666666667, 75.06666666666666, 75.25, 75.8, 75.78333333333333, 75.01666666666667, 75.78333333333333, 75.9, 76.31666666666666, 76.38333333333334, 76.43333333333334, 77.2, 77.43333333333334, 77.91666666666667, 77.6, 76.58333333333333, 76.3, 77.18333333333334, 76.83333333333333, 76.75, 76.51666666666667, 76.85, 76.68333333333334, 76.66666666666667, 76.21666666666667, 76.78333333333333, 76.73333333333333, 76.63333333333334, 76.68333333333334, 76.71666666666667, 77.01666666666667, 76.61666666666666, 76.48333333333333, 77.26666666666667, 76.6, 76.75, 76.5, 76.86666666666666, 77.28333333333333, 77.43333333333334, 77.43333333333334, 77.15, 76.78333333333333, 77.15, 77.71666666666667, 78.08333333333333, 78.06666666666666, 77.58333333333333, 77.58333333333333, 78.35, 77.96666666666667, 77.58333333333333, 77.58333333333333, 77.23333333333333, 76.58333333333333, 76.18333333333334, 76.51666666666667, 77.63333333333334, 77.36666666666666, 77.73333333333333, 77.28333333333333, 77.26666666666667, 77.23333333333333, 77.43333333333334, 77.63333333333334, 78.23333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.065, Test loss: 1.097, Test accuracy: 34.32 

Round   1, Train loss: 0.998, Test loss: 1.094, Test accuracy: 35.07 

Round   2, Train loss: 0.943, Test loss: 1.028, Test accuracy: 41.98 

Round   3, Train loss: 0.842, Test loss: 0.999, Test accuracy: 46.45 

Round   4, Train loss: 0.846, Test loss: 0.915, Test accuracy: 52.65 

Round   5, Train loss: 0.842, Test loss: 0.857, Test accuracy: 56.82 

Round   6, Train loss: 0.844, Test loss: 0.815, Test accuracy: 57.47 

Round   7, Train loss: 0.781, Test loss: 0.799, Test accuracy: 59.20 

Round   8, Train loss: 0.789, Test loss: 0.739, Test accuracy: 62.65 

Round   9, Train loss: 0.713, Test loss: 0.725, Test accuracy: 63.32 

Round  10, Train loss: 0.666, Test loss: 0.718, Test accuracy: 64.90 

Round  11, Train loss: 0.651, Test loss: 0.705, Test accuracy: 65.62 

Round  12, Train loss: 0.698, Test loss: 0.674, Test accuracy: 67.25 

Round  13, Train loss: 0.653, Test loss: 0.660, Test accuracy: 67.80 

Round  14, Train loss: 0.703, Test loss: 0.652, Test accuracy: 69.32 

Round  15, Train loss: 0.680, Test loss: 0.642, Test accuracy: 69.60 

Round  16, Train loss: 0.654, Test loss: 0.633, Test accuracy: 70.13 

Round  17, Train loss: 0.574, Test loss: 0.630, Test accuracy: 70.53 

Round  18, Train loss: 0.659, Test loss: 0.624, Test accuracy: 71.10 

Round  19, Train loss: 0.560, Test loss: 0.621, Test accuracy: 71.78 

Round  20, Train loss: 0.686, Test loss: 0.614, Test accuracy: 72.10 

Round  21, Train loss: 0.639, Test loss: 0.610, Test accuracy: 71.90 

Round  22, Train loss: 0.615, Test loss: 0.597, Test accuracy: 72.73 

Round  23, Train loss: 0.528, Test loss: 0.600, Test accuracy: 71.93 

Round  24, Train loss: 0.517, Test loss: 0.590, Test accuracy: 72.35 

Round  25, Train loss: 0.530, Test loss: 0.581, Test accuracy: 72.62 

Round  26, Train loss: 0.545, Test loss: 0.572, Test accuracy: 73.17 

Round  27, Train loss: 0.543, Test loss: 0.567, Test accuracy: 74.07 

Round  28, Train loss: 0.605, Test loss: 0.567, Test accuracy: 74.75 

Round  29, Train loss: 0.567, Test loss: 0.556, Test accuracy: 74.90 

Round  30, Train loss: 0.533, Test loss: 0.566, Test accuracy: 74.63 

Round  31, Train loss: 0.502, Test loss: 0.546, Test accuracy: 75.70 

Round  32, Train loss: 0.573, Test loss: 0.540, Test accuracy: 75.95 

Round  33, Train loss: 0.543, Test loss: 0.544, Test accuracy: 76.10 

Round  34, Train loss: 0.555, Test loss: 0.544, Test accuracy: 76.45 

Round  35, Train loss: 0.526, Test loss: 0.537, Test accuracy: 76.27 

Round  36, Train loss: 0.478, Test loss: 0.533, Test accuracy: 76.33 

Round  37, Train loss: 0.507, Test loss: 0.525, Test accuracy: 77.15 

Round  38, Train loss: 0.512, Test loss: 0.541, Test accuracy: 76.62 

Round  39, Train loss: 0.479, Test loss: 0.540, Test accuracy: 76.72 

Round  40, Train loss: 0.479, Test loss: 0.533, Test accuracy: 76.75 

Round  41, Train loss: 0.548, Test loss: 0.524, Test accuracy: 77.23 

Round  42, Train loss: 0.469, Test loss: 0.525, Test accuracy: 77.37 

Round  43, Train loss: 0.489, Test loss: 0.533, Test accuracy: 77.35 

Round  44, Train loss: 0.427, Test loss: 0.530, Test accuracy: 76.67 

Round  45, Train loss: 0.435, Test loss: 0.521, Test accuracy: 77.43 

Round  46, Train loss: 0.504, Test loss: 0.519, Test accuracy: 77.72 

Round  47, Train loss: 0.500, Test loss: 0.511, Test accuracy: 78.23 

Round  48, Train loss: 0.490, Test loss: 0.502, Test accuracy: 78.37 

Round  49, Train loss: 0.427, Test loss: 0.501, Test accuracy: 78.62 

Round  50, Train loss: 0.451, Test loss: 0.504, Test accuracy: 78.47 

Round  51, Train loss: 0.350, Test loss: 0.505, Test accuracy: 77.93 

Round  52, Train loss: 0.438, Test loss: 0.523, Test accuracy: 77.90 

Round  53, Train loss: 0.540, Test loss: 0.504, Test accuracy: 78.13 

Round  54, Train loss: 0.416, Test loss: 0.498, Test accuracy: 78.52 

Round  55, Train loss: 0.438, Test loss: 0.502, Test accuracy: 78.30 

Round  56, Train loss: 0.436, Test loss: 0.526, Test accuracy: 77.83 

Round  57, Train loss: 0.439, Test loss: 0.505, Test accuracy: 78.15 

Round  58, Train loss: 0.438, Test loss: 0.502, Test accuracy: 78.17 

Round  59, Train loss: 0.435, Test loss: 0.490, Test accuracy: 79.12 

Round  60, Train loss: 0.367, Test loss: 0.491, Test accuracy: 79.03 

Round  61, Train loss: 0.358, Test loss: 0.487, Test accuracy: 79.07 

Round  62, Train loss: 0.362, Test loss: 0.493, Test accuracy: 79.23 

Round  63, Train loss: 0.441, Test loss: 0.489, Test accuracy: 79.63 

Round  64, Train loss: 0.388, Test loss: 0.492, Test accuracy: 79.42 

Round  65, Train loss: 0.324, Test loss: 0.495, Test accuracy: 79.17 

Round  66, Train loss: 0.423, Test loss: 0.493, Test accuracy: 79.43 

Round  67, Train loss: 0.403, Test loss: 0.494, Test accuracy: 78.92 

Round  68, Train loss: 0.305, Test loss: 0.502, Test accuracy: 78.80 

Round  69, Train loss: 0.317, Test loss: 0.495, Test accuracy: 79.03 

Round  70, Train loss: 0.344, Test loss: 0.504, Test accuracy: 78.87 

Round  71, Train loss: 0.387, Test loss: 0.490, Test accuracy: 79.55 

Round  72, Train loss: 0.297, Test loss: 0.492, Test accuracy: 79.55 

Round  73, Train loss: 0.291, Test loss: 0.490, Test accuracy: 79.30 

Round  74, Train loss: 0.385, Test loss: 0.490, Test accuracy: 79.77 

Round  75, Train loss: 0.324, Test loss: 0.491, Test accuracy: 79.80 

Round  76, Train loss: 0.316, Test loss: 0.484, Test accuracy: 80.13 

Round  77, Train loss: 0.319, Test loss: 0.491, Test accuracy: 79.80 

Round  78, Train loss: 0.318, Test loss: 0.482, Test accuracy: 80.10 

Round  79, Train loss: 0.408, Test loss: 0.484, Test accuracy: 80.18 

Round  80, Train loss: 0.381, Test loss: 0.487, Test accuracy: 79.75 

Round  81, Train loss: 0.376, Test loss: 0.480, Test accuracy: 80.35 

Round  82, Train loss: 0.420, Test loss: 0.490, Test accuracy: 80.22 

Round  83, Train loss: 0.376, Test loss: 0.490, Test accuracy: 80.22 

Round  84, Train loss: 0.310, Test loss: 0.485, Test accuracy: 79.87 

Round  85, Train loss: 0.281, Test loss: 0.473, Test accuracy: 80.72 

Round  86, Train loss: 0.406, Test loss: 0.483, Test accuracy: 80.50 

Round  87, Train loss: 0.266, Test loss: 0.475, Test accuracy: 80.47 

Round  88, Train loss: 0.318, Test loss: 0.473, Test accuracy: 80.67 

Round  89, Train loss: 0.298, Test loss: 0.471, Test accuracy: 80.72 

Round  90, Train loss: 0.423, Test loss: 0.480, Test accuracy: 80.08 

Round  91, Train loss: 0.288, Test loss: 0.468, Test accuracy: 80.80 

Round  92, Train loss: 0.359, Test loss: 0.479, Test accuracy: 80.45 

Round  93, Train loss: 0.367, Test loss: 0.483, Test accuracy: 80.52 

Round  94, Train loss: 0.309, Test loss: 0.493, Test accuracy: 80.33 

Round  95, Train loss: 0.248, Test loss: 0.478, Test accuracy: 80.78 

Round  96, Train loss: 0.273, Test loss: 0.475, Test accuracy: 81.08 

Round  97, Train loss: 0.307, Test loss: 0.486, Test accuracy: 80.97 

Round  98, Train loss: 0.289, Test loss: 0.484, Test accuracy: 81.03 

Round  99, Train loss: 0.304, Test loss: 0.492, Test accuracy: 80.98 

Final Round, Train loss: 0.266, Test loss: 0.487, Test accuracy: 81.28 

Average accuracy final 10 rounds: 80.70333333333333 

514.0778286457062
[0.8847503662109375, 1.5225715637207031, 2.1581485271453857, 2.791228771209717, 3.427659034729004, 4.062436819076538, 4.69772744178772, 5.33323860168457, 5.9612603187561035, 6.601524353027344, 7.230998992919922, 7.8636767864227295, 8.498875141143799, 9.120383977890015, 9.745979070663452, 10.374520301818848, 11.003103733062744, 11.629818439483643, 12.259812831878662, 12.890183448791504, 13.51978087425232, 14.147114992141724, 14.71949553489685, 15.292300701141357, 15.866404056549072, 16.43784260749817, 17.00961947441101, 17.582290172576904, 18.154857397079468, 18.7263400554657, 19.298835515975952, 19.87185049057007, 20.44382381439209, 21.01665425300598, 21.589157819747925, 22.16154980659485, 22.733996629714966, 23.30642819404602, 23.878244400024414, 24.44976544380188, 25.02342128753662, 25.59616446495056, 26.167134761810303, 26.739551067352295, 27.31175684928894, 27.88485097885132, 28.456814765930176, 29.030761241912842, 29.604443311691284, 30.177313089370728, 30.751060962677002, 31.325639009475708, 31.89676332473755, 32.471372842788696, 33.04646921157837, 33.61842083930969, 34.192408323287964, 34.76712441444397, 35.339898347854614, 35.915059328079224, 36.48837471008301, 37.06276082992554, 37.637237787246704, 38.21034026145935, 38.78449487686157, 39.356961727142334, 39.930203676223755, 40.505046367645264, 41.078694343566895, 41.65333867073059, 42.22729802131653, 42.80148220062256, 43.374751567840576, 43.947580099105835, 44.52086019515991, 45.09404706954956, 45.66713881492615, 46.239813566207886, 46.8142032623291, 47.386996030807495, 47.96119832992554, 48.53548765182495, 49.10817241668701, 49.68057703971863, 50.25310444831848, 50.82643175125122, 51.40014696121216, 51.9734148979187, 52.546809673309326, 53.118834018707275, 53.691561222076416, 54.26709842681885, 54.83916711807251, 55.40894961357117, 55.981202840805054, 56.55226397514343, 57.12296009063721, 57.69487524032593, 58.27060413360596, 58.84340310096741, 59.91628861427307]
[34.31666666666667, 35.06666666666667, 41.983333333333334, 46.45, 52.65, 56.81666666666667, 57.46666666666667, 59.2, 62.65, 63.31666666666667, 64.9, 65.61666666666666, 67.25, 67.8, 69.31666666666666, 69.6, 70.13333333333334, 70.53333333333333, 71.1, 71.78333333333333, 72.1, 71.9, 72.73333333333333, 71.93333333333334, 72.35, 72.61666666666666, 73.16666666666667, 74.06666666666666, 74.75, 74.9, 74.63333333333334, 75.7, 75.95, 76.1, 76.45, 76.26666666666667, 76.33333333333333, 77.15, 76.61666666666666, 76.71666666666667, 76.75, 77.23333333333333, 77.36666666666666, 77.35, 76.66666666666667, 77.43333333333334, 77.71666666666667, 78.23333333333333, 78.36666666666666, 78.61666666666666, 78.46666666666667, 77.93333333333334, 77.9, 78.13333333333334, 78.51666666666667, 78.3, 77.83333333333333, 78.15, 78.16666666666667, 79.11666666666666, 79.03333333333333, 79.06666666666666, 79.23333333333333, 79.63333333333334, 79.41666666666667, 79.16666666666667, 79.43333333333334, 78.91666666666667, 78.8, 79.03333333333333, 78.86666666666666, 79.55, 79.55, 79.3, 79.76666666666667, 79.8, 80.13333333333334, 79.8, 80.1, 80.18333333333334, 79.75, 80.35, 80.21666666666667, 80.21666666666667, 79.86666666666666, 80.71666666666667, 80.5, 80.46666666666667, 80.66666666666667, 80.71666666666667, 80.08333333333333, 80.8, 80.45, 80.51666666666667, 80.33333333333333, 80.78333333333333, 81.08333333333333, 80.96666666666667, 81.03333333333333, 80.98333333333333, 81.28333333333333]
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 679, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 7939 (global); Percentage 2.58 (7939/307387 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 679, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 18, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 541, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 412, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 285, in train
    local_par_list = torch.cat((local_par_list, param.reshape(-1)), 0)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 849, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 19.95 

Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 20.50 

Round   1, Train loss: 2.298, Test loss: 2.296, Test accuracy: 26.53 

Round   1, Global train loss: 2.298, Global test loss: 2.295, Global test accuracy: 28.88 

Round   2, Train loss: 2.291, Test loss: 2.290, Test accuracy: 28.06 

Round   2, Global train loss: 2.291, Global test loss: 2.285, Global test accuracy: 31.54 

Round   3, Train loss: 2.261, Test loss: 2.264, Test accuracy: 27.07 

Round   3, Global train loss: 2.261, Global test loss: 2.230, Global test accuracy: 30.04 

Round   4, Train loss: 2.211, Test loss: 2.238, Test accuracy: 29.69 

Round   4, Global train loss: 2.211, Global test loss: 2.176, Global test accuracy: 38.20 

Round   5, Train loss: 2.241, Test loss: 2.228, Test accuracy: 33.28 

Round   5, Global train loss: 2.241, Global test loss: 2.235, Global test accuracy: 44.12 

Round   6, Train loss: 2.103, Test loss: 2.185, Test accuracy: 35.36 

Round   6, Global train loss: 2.103, Global test loss: 2.060, Global test accuracy: 41.83 

Round   7, Train loss: 2.106, Test loss: 2.158, Test accuracy: 38.45 

Round   7, Global train loss: 2.106, Global test loss: 2.093, Global test accuracy: 50.25 

Round   8, Train loss: 2.092, Test loss: 2.115, Test accuracy: 41.84 

Round   8, Global train loss: 2.092, Global test loss: 2.069, Global test accuracy: 58.12 

Round   9, Train loss: 2.012, Test loss: 2.094, Test accuracy: 43.98 

Round   9, Global train loss: 2.012, Global test loss: 2.028, Global test accuracy: 59.95 

Round  10, Train loss: 2.040, Test loss: 2.060, Test accuracy: 46.76 

Round  10, Global train loss: 2.040, Global test loss: 2.020, Global test accuracy: 52.08 

Round  11, Train loss: 1.989, Test loss: 2.027, Test accuracy: 49.20 

Round  11, Global train loss: 1.989, Global test loss: 1.994, Global test accuracy: 56.56 

Round  12, Train loss: 1.891, Test loss: 2.002, Test accuracy: 52.20 

Round  12, Global train loss: 1.891, Global test loss: 1.878, Global test accuracy: 64.21 

Round  13, Train loss: 1.851, Test loss: 1.972, Test accuracy: 54.95 

Round  13, Global train loss: 1.851, Global test loss: 1.860, Global test accuracy: 62.64 

Round  14, Train loss: 1.851, Test loss: 1.946, Test accuracy: 57.22 

Round  14, Global train loss: 1.851, Global test loss: 1.827, Global test accuracy: 78.30 

Round  15, Train loss: 1.790, Test loss: 1.917, Test accuracy: 59.66 

Round  15, Global train loss: 1.790, Global test loss: 1.853, Global test accuracy: 61.21 

Round  16, Train loss: 1.765, Test loss: 1.897, Test accuracy: 62.23 

Round  16, Global train loss: 1.765, Global test loss: 1.826, Global test accuracy: 65.20 

Round  17, Train loss: 1.635, Test loss: 1.891, Test accuracy: 62.49 

Round  17, Global train loss: 1.635, Global test loss: 1.769, Global test accuracy: 70.14 

Round  18, Train loss: 1.762, Test loss: 1.879, Test accuracy: 62.95 

Round  18, Global train loss: 1.762, Global test loss: 1.797, Global test accuracy: 73.42 

Round  19, Train loss: 1.874, Test loss: 1.853, Test accuracy: 64.16 

Round  19, Global train loss: 1.874, Global test loss: 1.893, Global test accuracy: 59.15 

Round  20, Train loss: 1.655, Test loss: 1.847, Test accuracy: 64.67 

Round  20, Global train loss: 1.655, Global test loss: 1.798, Global test accuracy: 67.56 

Round  21, Train loss: 1.927, Test loss: 1.830, Test accuracy: 65.12 

Round  21, Global train loss: 1.927, Global test loss: 1.943, Global test accuracy: 60.93 

Round  22, Train loss: 1.669, Test loss: 1.820, Test accuracy: 66.11 

Round  22, Global train loss: 1.669, Global test loss: 1.799, Global test accuracy: 66.11 

Round  23, Train loss: 1.847, Test loss: 1.807, Test accuracy: 68.14 

Round  23, Global train loss: 1.847, Global test loss: 1.885, Global test accuracy: 64.27 

Round  24, Train loss: 1.812, Test loss: 1.786, Test accuracy: 70.40 

Round  24, Global train loss: 1.812, Global test loss: 1.851, Global test accuracy: 66.17 

Round  25, Train loss: 1.752, Test loss: 1.762, Test accuracy: 72.64 

Round  25, Global train loss: 1.752, Global test loss: 1.815, Global test accuracy: 66.45 

Round  26, Train loss: 1.639, Test loss: 1.755, Test accuracy: 73.09 

Round  26, Global train loss: 1.639, Global test loss: 1.768, Global test accuracy: 71.02 

Round  27, Train loss: 1.662, Test loss: 1.747, Test accuracy: 73.39 

Round  27, Global train loss: 1.662, Global test loss: 1.816, Global test accuracy: 64.52 

Round  28, Train loss: 1.582, Test loss: 1.743, Test accuracy: 73.62 

Round  28, Global train loss: 1.582, Global test loss: 1.702, Global test accuracy: 77.47 

Round  29, Train loss: 1.626, Test loss: 1.738, Test accuracy: 74.03 

Round  29, Global train loss: 1.626, Global test loss: 1.758, Global test accuracy: 71.31 

Round  30, Train loss: 1.653, Test loss: 1.733, Test accuracy: 74.53 

Round  30, Global train loss: 1.653, Global test loss: 1.777, Global test accuracy: 69.90 

Round  31, Train loss: 1.680, Test loss: 1.724, Test accuracy: 75.55 

Round  31, Global train loss: 1.680, Global test loss: 1.795, Global test accuracy: 66.55 

Round  32, Train loss: 1.610, Test loss: 1.721, Test accuracy: 75.81 

Round  32, Global train loss: 1.610, Global test loss: 1.765, Global test accuracy: 70.30 

Round  33, Train loss: 1.571, Test loss: 1.716, Test accuracy: 76.22 

Round  33, Global train loss: 1.571, Global test loss: 1.717, Global test accuracy: 76.38 

Round  34, Train loss: 1.565, Test loss: 1.714, Test accuracy: 76.45 

Round  34, Global train loss: 1.565, Global test loss: 1.717, Global test accuracy: 75.39 

Round  35, Train loss: 1.551, Test loss: 1.713, Test accuracy: 76.44 

Round  35, Global train loss: 1.551, Global test loss: 1.717, Global test accuracy: 75.31 

Round  36, Train loss: 1.535, Test loss: 1.711, Test accuracy: 76.58 

Round  36, Global train loss: 1.535, Global test loss: 1.678, Global test accuracy: 79.63 

Round  37, Train loss: 1.567, Test loss: 1.709, Test accuracy: 76.67 

Round  37, Global train loss: 1.567, Global test loss: 1.726, Global test accuracy: 73.38 

Round  38, Train loss: 1.585, Test loss: 1.706, Test accuracy: 76.86 

Round  38, Global train loss: 1.585, Global test loss: 1.724, Global test accuracy: 75.91 

Round  39, Train loss: 1.614, Test loss: 1.701, Test accuracy: 77.43 

Round  39, Global train loss: 1.614, Global test loss: 1.768, Global test accuracy: 69.96 

Round  40, Train loss: 1.560, Test loss: 1.697, Test accuracy: 77.83 

Round  40, Global train loss: 1.560, Global test loss: 1.707, Global test accuracy: 76.50 

Round  41, Train loss: 1.562, Test loss: 1.696, Test accuracy: 77.77 

Round  41, Global train loss: 1.562, Global test loss: 1.717, Global test accuracy: 74.08 

Round  42, Train loss: 1.579, Test loss: 1.695, Test accuracy: 77.92 

Round  42, Global train loss: 1.579, Global test loss: 1.722, Global test accuracy: 74.91 

Round  43, Train loss: 1.556, Test loss: 1.694, Test accuracy: 77.94 

Round  43, Global train loss: 1.556, Global test loss: 1.735, Global test accuracy: 73.17 

Round  44, Train loss: 1.590, Test loss: 1.694, Test accuracy: 77.86 

Round  44, Global train loss: 1.590, Global test loss: 1.747, Global test accuracy: 71.54 

Round  45, Train loss: 1.568, Test loss: 1.693, Test accuracy: 77.86 

Round  45, Global train loss: 1.568, Global test loss: 1.725, Global test accuracy: 73.67 

Round  46, Train loss: 1.590, Test loss: 1.690, Test accuracy: 78.25 

Round  46, Global train loss: 1.590, Global test loss: 1.771, Global test accuracy: 68.46 

Round  47, Train loss: 1.539, Test loss: 1.690, Test accuracy: 78.21 

Round  47, Global train loss: 1.539, Global test loss: 1.674, Global test accuracy: 80.08 

Round  48, Train loss: 1.533, Test loss: 1.689, Test accuracy: 78.22 

Round  48, Global train loss: 1.533, Global test loss: 1.697, Global test accuracy: 76.77 

Round  49, Train loss: 1.577, Test loss: 1.687, Test accuracy: 78.38 

Round  49, Global train loss: 1.577, Global test loss: 1.755, Global test accuracy: 71.06 

Round  50, Train loss: 1.554, Test loss: 1.686, Test accuracy: 78.42 

Round  50, Global train loss: 1.554, Global test loss: 1.705, Global test accuracy: 76.77 

Round  51, Train loss: 1.527, Test loss: 1.686, Test accuracy: 78.46 

Round  51, Global train loss: 1.527, Global test loss: 1.698, Global test accuracy: 77.12 

Round  52, Train loss: 1.529, Test loss: 1.685, Test accuracy: 78.45 

Round  52, Global train loss: 1.529, Global test loss: 1.678, Global test accuracy: 79.05 

Round  53, Train loss: 1.559, Test loss: 1.685, Test accuracy: 78.48 

Round  53, Global train loss: 1.559, Global test loss: 1.703, Global test accuracy: 76.67 

Round  54, Train loss: 1.540, Test loss: 1.685, Test accuracy: 78.46 

Round  54, Global train loss: 1.540, Global test loss: 1.686, Global test accuracy: 77.66 

Round  55, Train loss: 1.585, Test loss: 1.685, Test accuracy: 78.44 

Round  55, Global train loss: 1.585, Global test loss: 1.740, Global test accuracy: 72.27 

Round  56, Train loss: 1.543, Test loss: 1.685, Test accuracy: 78.44 

Round  56, Global train loss: 1.543, Global test loss: 1.708, Global test accuracy: 75.30 

Round  57, Train loss: 1.559, Test loss: 1.685, Test accuracy: 78.38 

Round  57, Global train loss: 1.559, Global test loss: 1.715, Global test accuracy: 75.50 

Round  58, Train loss: 1.564, Test loss: 1.684, Test accuracy: 78.40 

Round  58, Global train loss: 1.564, Global test loss: 1.728, Global test accuracy: 73.61 

Round  59, Train loss: 1.523, Test loss: 1.684, Test accuracy: 78.36 

Round  59, Global train loss: 1.523, Global test loss: 1.655, Global test accuracy: 81.78 

Round  60, Train loss: 1.578, Test loss: 1.684, Test accuracy: 78.41 

Round  60, Global train loss: 1.578, Global test loss: 1.763, Global test accuracy: 69.91 

Round  61, Train loss: 1.555, Test loss: 1.684, Test accuracy: 78.42 

Round  61, Global train loss: 1.555, Global test loss: 1.713, Global test accuracy: 75.20 

Round  62, Train loss: 1.542, Test loss: 1.684, Test accuracy: 78.42 

Round  62, Global train loss: 1.542, Global test loss: 1.724, Global test accuracy: 73.95 

Round  63, Train loss: 1.583, Test loss: 1.683, Test accuracy: 78.44 

Round  63, Global train loss: 1.583, Global test loss: 1.752, Global test accuracy: 71.43 

Round  64, Train loss: 1.517, Test loss: 1.683, Test accuracy: 78.36 

Round  64, Global train loss: 1.517, Global test loss: 1.657, Global test accuracy: 80.51 

Round  65, Train loss: 1.508, Test loss: 1.683, Test accuracy: 78.38 

Round  65, Global train loss: 1.508, Global test loss: 1.668, Global test accuracy: 79.77 

Round  66, Train loss: 1.535, Test loss: 1.683, Test accuracy: 78.40 

Round  66, Global train loss: 1.535, Global test loss: 1.687, Global test accuracy: 77.94 

Round  67, Train loss: 1.552, Test loss: 1.683, Test accuracy: 78.41 

Round  67, Global train loss: 1.552, Global test loss: 1.704, Global test accuracy: 75.50 

Round  68, Train loss: 1.566, Test loss: 1.683, Test accuracy: 78.35 

Round  68, Global train loss: 1.566, Global test loss: 1.747, Global test accuracy: 71.31 

Round  69, Train loss: 1.549, Test loss: 1.683, Test accuracy: 78.39 

Round  69, Global train loss: 1.549, Global test loss: 1.730, Global test accuracy: 72.50 

Round  70, Train loss: 1.564, Test loss: 1.683, Test accuracy: 78.39 

Round  70, Global train loss: 1.564, Global test loss: 1.707, Global test accuracy: 76.03 

Round  71, Train loss: 1.545, Test loss: 1.680, Test accuracy: 78.78 

Round  71, Global train loss: 1.545, Global test loss: 1.671, Global test accuracy: 80.67 

Round  72, Train loss: 1.519, Test loss: 1.677, Test accuracy: 79.02 

Round  72, Global train loss: 1.519, Global test loss: 1.663, Global test accuracy: 80.77 

Round  73, Train loss: 1.522, Test loss: 1.677, Test accuracy: 79.03 

Round  73, Global train loss: 1.522, Global test loss: 1.684, Global test accuracy: 78.13 

Round  74, Train loss: 1.517, Test loss: 1.675, Test accuracy: 79.25 

Round  74, Global train loss: 1.517, Global test loss: 1.652, Global test accuracy: 82.20 

Round  75, Train loss: 1.497, Test loss: 1.675, Test accuracy: 79.31 

Round  75, Global train loss: 1.497, Global test loss: 1.652, Global test accuracy: 81.28 

Round  76, Train loss: 1.524, Test loss: 1.675, Test accuracy: 79.31 

Round  76, Global train loss: 1.524, Global test loss: 1.684, Global test accuracy: 78.22 

Round  77, Train loss: 1.480, Test loss: 1.674, Test accuracy: 79.33 

Round  77, Global train loss: 1.480, Global test loss: 1.606, Global test accuracy: 86.83 

Round  78, Train loss: 1.553, Test loss: 1.674, Test accuracy: 79.30 

Round  78, Global train loss: 1.553, Global test loss: 1.732, Global test accuracy: 72.73 

Round  79, Train loss: 1.525, Test loss: 1.674, Test accuracy: 79.36 

Round  79, Global train loss: 1.525, Global test loss: 1.664, Global test accuracy: 80.77 

Round  80, Train loss: 1.497, Test loss: 1.674, Test accuracy: 79.35 

Round  80, Global train loss: 1.497, Global test loss: 1.629, Global test accuracy: 83.90 

Round  81, Train loss: 1.566, Test loss: 1.673, Test accuracy: 79.33 

Round  81, Global train loss: 1.566, Global test loss: 1.735, Global test accuracy: 73.03 

Round  82, Train loss: 1.512, Test loss: 1.673, Test accuracy: 79.34 

Round  82, Global train loss: 1.512, Global test loss: 1.645, Global test accuracy: 82.77 

Round  83, Train loss: 1.510, Test loss: 1.673, Test accuracy: 79.35 

Round  83, Global train loss: 1.510, Global test loss: 1.654, Global test accuracy: 81.43 

Round  84, Train loss: 1.524, Test loss: 1.673, Test accuracy: 79.36 

Round  84, Global train loss: 1.524, Global test loss: 1.665, Global test accuracy: 80.14 

Round  85, Train loss: 1.513, Test loss: 1.673, Test accuracy: 79.39 

Round  85, Global train loss: 1.513, Global test loss: 1.664, Global test accuracy: 79.97 

Round  86, Train loss: 1.519, Test loss: 1.673, Test accuracy: 79.37 

Round  86, Global train loss: 1.519, Global test loss: 1.662, Global test accuracy: 80.81 

Round  87, Train loss: 1.508, Test loss: 1.673, Test accuracy: 79.36 

Round  87, Global train loss: 1.508, Global test loss: 1.658, Global test accuracy: 80.65 

Round  88, Train loss: 1.535, Test loss: 1.672, Test accuracy: 79.39 

Round  88, Global train loss: 1.535, Global test loss: 1.683, Global test accuracy: 78.05 

Round  89, Train loss: 1.544, Test loss: 1.671, Test accuracy: 79.52 

Round  89, Global train loss: 1.544, Global test loss: 1.708, Global test accuracy: 75.19 

Round  90, Train loss: 1.522, Test loss: 1.671, Test accuracy: 79.51 

Round  90, Global train loss: 1.522, Global test loss: 1.668, Global test accuracy: 80.04 

Round  91, Train loss: 1.540, Test loss: 1.671, Test accuracy: 79.52 

Round  91, Global train loss: 1.540, Global test loss: 1.689, Global test accuracy: 78.28 

Round  92, Train loss: 1.549, Test loss: 1.671, Test accuracy: 79.53 

Round  92, Global train loss: 1.549, Global test loss: 1.730, Global test accuracy: 73.13 

Round  93, Train loss: 1.523, Test loss: 1.673, Test accuracy: 79.27 

Round  93, Global train loss: 1.523, Global test loss: 1.686, Global test accuracy: 78.43 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.550, Test loss: 1.670, Test accuracy: 79.56 

Round  94, Global train loss: 1.550, Global test loss: 1.720, Global test accuracy: 74.91 

Round  95, Train loss: 1.512, Test loss: 1.670, Test accuracy: 79.56 

Round  95, Global train loss: 1.512, Global test loss: 1.647, Global test accuracy: 82.17 

Round  96, Train loss: 1.550, Test loss: 1.670, Test accuracy: 79.52 

Round  96, Global train loss: 1.550, Global test loss: 1.741, Global test accuracy: 72.18 

Round  97, Train loss: 1.554, Test loss: 1.670, Test accuracy: 79.54 

Round  97, Global train loss: 1.554, Global test loss: 1.698, Global test accuracy: 77.07 

Round  98, Train loss: 1.508, Test loss: 1.670, Test accuracy: 79.62 

Round  98, Global train loss: 1.508, Global test loss: 1.669, Global test accuracy: 80.20 

Round  99, Train loss: 1.548, Test loss: 1.670, Test accuracy: 79.60 

Round  99, Global train loss: 1.548, Global test loss: 1.733, Global test accuracy: 73.12 

Final Round, Train loss: 1.525, Test loss: 1.669, Test accuracy: 79.61 

Final Round, Global train loss: 1.525, Global test loss: 1.733, Global test accuracy: 73.12 

Average accuracy final 10 rounds: 79.5235 

Average global accuracy final 10 rounds: 76.9535 

1191.1079828739166
[0.8064196109771729, 1.5437607765197754, 2.279478073120117, 3.015970230102539, 3.7533071041107178, 4.500169992446899, 5.235451698303223, 5.963519334793091, 6.7025463581085205, 7.438294410705566, 8.173790216445923, 8.909171104431152, 9.643586874008179, 10.382200479507446, 11.118560552597046, 11.850610971450806, 12.58428144454956, 13.311901807785034, 14.03786826133728, 14.757784605026245, 15.371862173080444, 15.99372911453247, 16.620168447494507, 17.24152421951294, 17.85985279083252, 18.484673023223877, 19.11050057411194, 19.72915506362915, 20.34484553337097, 20.96707057952881, 21.59714698791504, 22.211557626724243, 22.822792768478394, 23.443702220916748, 24.070769786834717, 24.683826446533203, 25.29651641845703, 25.91893196105957, 26.546316623687744, 27.161282777786255, 27.778091192245483, 28.405717611312866, 29.03089141845703, 29.64750599861145, 30.26278281211853, 30.887871503829956, 31.517761945724487, 32.13319754600525, 32.74746084213257, 33.37414526939392, 33.993175983428955, 34.607348918914795, 35.221171140670776, 35.847413778305054, 36.47413229942322, 37.092047929763794, 37.715049028396606, 38.340091943740845, 38.95848369598389, 39.57461476325989, 40.197938680648804, 40.82382416725159, 41.44689202308655, 42.06476807594299, 42.69233441352844, 43.32066535949707, 43.93530893325806, 44.55226755142212, 45.178138971328735, 45.808114767074585, 46.42418384552002, 47.04400014877319, 47.6716034412384, 48.30120015144348, 48.91891384124756, 49.539477825164795, 50.16715145111084, 50.7934513092041, 51.410985708236694, 52.03066420555115, 52.657559871673584, 53.284510135650635, 53.89935374259949, 54.5169403553009, 55.144859790802, 55.77228760719299, 56.38953876495361, 57.005733489990234, 57.638813495635986, 58.26785111427307, 58.8864905834198, 59.502654790878296, 60.13392925262451, 60.76434063911438, 61.38250684738159, 62.01277756690979, 62.64418292045593, 63.27805018424988, 63.898043394088745, 64.52272534370422, 65.79292702674866]
[19.955, 26.53, 28.06, 27.07, 29.69, 33.28, 35.36, 38.45, 41.835, 43.98, 46.755, 49.205, 52.2, 54.945, 57.22, 59.66, 62.225, 62.495, 62.945, 64.16, 64.67, 65.125, 66.105, 68.145, 70.4, 72.635, 73.09, 73.385, 73.625, 74.03, 74.525, 75.55, 75.805, 76.22, 76.45, 76.435, 76.58, 76.675, 76.855, 77.43, 77.825, 77.77, 77.915, 77.935, 77.865, 77.865, 78.25, 78.21, 78.225, 78.38, 78.425, 78.46, 78.45, 78.48, 78.46, 78.44, 78.44, 78.38, 78.4, 78.365, 78.41, 78.42, 78.42, 78.445, 78.365, 78.375, 78.4, 78.41, 78.35, 78.385, 78.39, 78.785, 79.015, 79.025, 79.245, 79.31, 79.31, 79.33, 79.295, 79.365, 79.35, 79.325, 79.345, 79.35, 79.355, 79.385, 79.37, 79.365, 79.39, 79.515, 79.51, 79.52, 79.535, 79.265, 79.565, 79.56, 79.52, 79.54, 79.62, 79.6, 79.61]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.299, Test accuracy: 25.50 

Round   0, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 25.91 

Round   1, Train loss: 2.296, Test loss: 2.294, Test accuracy: 24.89 

Round   1, Global train loss: 2.296, Global test loss: 2.292, Global test accuracy: 25.50 

Round   2, Train loss: 2.278, Test loss: 2.270, Test accuracy: 19.26 

Round   2, Global train loss: 2.278, Global test loss: 2.254, Global test accuracy: 15.11 

Round   3, Train loss: 2.230, Test loss: 2.249, Test accuracy: 28.93 

Round   3, Global train loss: 2.230, Global test loss: 2.214, Global test accuracy: 36.92 

Round   4, Train loss: 2.181, Test loss: 2.209, Test accuracy: 36.15 

Round   4, Global train loss: 2.181, Global test loss: 2.141, Global test accuracy: 52.15 

Round   5, Train loss: 2.019, Test loss: 2.100, Test accuracy: 45.50 

Round   5, Global train loss: 2.019, Global test loss: 1.900, Global test accuracy: 66.90 

Round   6, Train loss: 1.792, Test loss: 2.002, Test accuracy: 54.05 

Round   6, Global train loss: 1.792, Global test loss: 1.732, Global test accuracy: 78.90 

Round   7, Train loss: 1.698, Test loss: 1.919, Test accuracy: 61.06 

Round   7, Global train loss: 1.698, Global test loss: 1.687, Global test accuracy: 80.51 

Round   8, Train loss: 1.670, Test loss: 1.809, Test accuracy: 71.06 

Round   8, Global train loss: 1.670, Global test loss: 1.665, Global test accuracy: 81.61 

Round   9, Train loss: 1.656, Test loss: 1.773, Test accuracy: 73.81 

Round   9, Global train loss: 1.656, Global test loss: 1.655, Global test accuracy: 81.86 

Round  10, Train loss: 1.637, Test loss: 1.732, Test accuracy: 76.17 

Round  10, Global train loss: 1.637, Global test loss: 1.650, Global test accuracy: 82.16 

Round  11, Train loss: 1.628, Test loss: 1.694, Test accuracy: 79.48 

Round  11, Global train loss: 1.628, Global test loss: 1.644, Global test accuracy: 82.56 

Round  12, Train loss: 1.628, Test loss: 1.688, Test accuracy: 79.86 

Round  12, Global train loss: 1.628, Global test loss: 1.641, Global test accuracy: 82.71 

Round  13, Train loss: 1.609, Test loss: 1.673, Test accuracy: 80.67 

Round  13, Global train loss: 1.609, Global test loss: 1.638, Global test accuracy: 82.99 

Round  14, Train loss: 1.610, Test loss: 1.670, Test accuracy: 80.83 

Round  14, Global train loss: 1.610, Global test loss: 1.636, Global test accuracy: 83.17 

Round  15, Train loss: 1.614, Test loss: 1.668, Test accuracy: 80.96 

Round  15, Global train loss: 1.614, Global test loss: 1.634, Global test accuracy: 83.30 

Round  16, Train loss: 1.617, Test loss: 1.658, Test accuracy: 81.56 

Round  16, Global train loss: 1.617, Global test loss: 1.631, Global test accuracy: 83.59 

Round  17, Train loss: 1.618, Test loss: 1.640, Test accuracy: 82.73 

Round  17, Global train loss: 1.618, Global test loss: 1.629, Global test accuracy: 83.61 

Round  18, Train loss: 1.605, Test loss: 1.638, Test accuracy: 82.88 

Round  18, Global train loss: 1.605, Global test loss: 1.629, Global test accuracy: 83.61 

Round  19, Train loss: 1.604, Test loss: 1.637, Test accuracy: 82.94 

Round  19, Global train loss: 1.604, Global test loss: 1.628, Global test accuracy: 83.78 

Round  20, Train loss: 1.604, Test loss: 1.637, Test accuracy: 82.97 

Round  20, Global train loss: 1.604, Global test loss: 1.626, Global test accuracy: 83.90 

Round  21, Train loss: 1.615, Test loss: 1.635, Test accuracy: 83.15 

Round  21, Global train loss: 1.615, Global test loss: 1.626, Global test accuracy: 83.81 

Round  22, Train loss: 1.609, Test loss: 1.633, Test accuracy: 83.26 

Round  22, Global train loss: 1.609, Global test loss: 1.626, Global test accuracy: 83.86 

Round  23, Train loss: 1.601, Test loss: 1.632, Test accuracy: 83.30 

Round  23, Global train loss: 1.601, Global test loss: 1.624, Global test accuracy: 83.92 

Round  24, Train loss: 1.594, Test loss: 1.631, Test accuracy: 83.38 

Round  24, Global train loss: 1.594, Global test loss: 1.623, Global test accuracy: 84.29 

Round  25, Train loss: 1.601, Test loss: 1.630, Test accuracy: 83.45 

Round  25, Global train loss: 1.601, Global test loss: 1.622, Global test accuracy: 84.36 

Round  26, Train loss: 1.589, Test loss: 1.630, Test accuracy: 83.49 

Round  26, Global train loss: 1.589, Global test loss: 1.622, Global test accuracy: 84.27 

Round  27, Train loss: 1.592, Test loss: 1.627, Test accuracy: 83.72 

Round  27, Global train loss: 1.592, Global test loss: 1.618, Global test accuracy: 84.35 

Round  28, Train loss: 1.554, Test loss: 1.618, Test accuracy: 84.82 

Round  28, Global train loss: 1.554, Global test loss: 1.578, Global test accuracy: 89.14 

Round  29, Train loss: 1.545, Test loss: 1.605, Test accuracy: 86.09 

Round  29, Global train loss: 1.545, Global test loss: 1.566, Global test accuracy: 90.36 

Round  30, Train loss: 1.528, Test loss: 1.597, Test accuracy: 86.92 

Round  30, Global train loss: 1.528, Global test loss: 1.559, Global test accuracy: 90.93 

Round  31, Train loss: 1.522, Test loss: 1.589, Test accuracy: 87.76 

Round  31, Global train loss: 1.522, Global test loss: 1.556, Global test accuracy: 91.15 

Round  32, Train loss: 1.519, Test loss: 1.578, Test accuracy: 88.83 

Round  32, Global train loss: 1.519, Global test loss: 1.555, Global test accuracy: 91.06 

Round  33, Train loss: 1.513, Test loss: 1.572, Test accuracy: 89.44 

Round  33, Global train loss: 1.513, Global test loss: 1.552, Global test accuracy: 91.36 

Round  34, Train loss: 1.517, Test loss: 1.565, Test accuracy: 90.20 

Round  34, Global train loss: 1.517, Global test loss: 1.549, Global test accuracy: 91.88 

Round  35, Train loss: 1.509, Test loss: 1.563, Test accuracy: 90.31 

Round  35, Global train loss: 1.509, Global test loss: 1.547, Global test accuracy: 91.95 

Round  36, Train loss: 1.506, Test loss: 1.561, Test accuracy: 90.53 

Round  36, Global train loss: 1.506, Global test loss: 1.546, Global test accuracy: 92.15 

Round  37, Train loss: 1.509, Test loss: 1.559, Test accuracy: 90.80 

Round  37, Global train loss: 1.509, Global test loss: 1.544, Global test accuracy: 92.04 

Round  38, Train loss: 1.500, Test loss: 1.558, Test accuracy: 90.83 

Round  38, Global train loss: 1.500, Global test loss: 1.544, Global test accuracy: 92.19 

Round  39, Train loss: 1.509, Test loss: 1.556, Test accuracy: 91.06 

Round  39, Global train loss: 1.509, Global test loss: 1.542, Global test accuracy: 92.39 

Round  40, Train loss: 1.510, Test loss: 1.554, Test accuracy: 91.23 

Round  40, Global train loss: 1.510, Global test loss: 1.540, Global test accuracy: 92.39 

Round  41, Train loss: 1.501, Test loss: 1.550, Test accuracy: 91.59 

Round  41, Global train loss: 1.501, Global test loss: 1.540, Global test accuracy: 92.61 

Round  42, Train loss: 1.499, Test loss: 1.549, Test accuracy: 91.69 

Round  42, Global train loss: 1.499, Global test loss: 1.539, Global test accuracy: 92.69 

Round  43, Train loss: 1.504, Test loss: 1.547, Test accuracy: 91.91 

Round  43, Global train loss: 1.504, Global test loss: 1.539, Global test accuracy: 92.68 

Round  44, Train loss: 1.492, Test loss: 1.547, Test accuracy: 91.84 

Round  44, Global train loss: 1.492, Global test loss: 1.537, Global test accuracy: 92.80 

Round  45, Train loss: 1.494, Test loss: 1.547, Test accuracy: 91.89 

Round  45, Global train loss: 1.494, Global test loss: 1.537, Global test accuracy: 92.68 

Round  46, Train loss: 1.502, Test loss: 1.546, Test accuracy: 91.98 

Round  46, Global train loss: 1.502, Global test loss: 1.536, Global test accuracy: 92.88 

Round  47, Train loss: 1.493, Test loss: 1.545, Test accuracy: 92.02 

Round  47, Global train loss: 1.493, Global test loss: 1.536, Global test accuracy: 92.91 

Round  48, Train loss: 1.501, Test loss: 1.543, Test accuracy: 92.14 

Round  48, Global train loss: 1.501, Global test loss: 1.535, Global test accuracy: 92.85 

Round  49, Train loss: 1.495, Test loss: 1.543, Test accuracy: 92.22 

Round  49, Global train loss: 1.495, Global test loss: 1.537, Global test accuracy: 92.81 

Round  50, Train loss: 1.493, Test loss: 1.542, Test accuracy: 92.26 

Round  50, Global train loss: 1.493, Global test loss: 1.536, Global test accuracy: 92.92 

Round  51, Train loss: 1.491, Test loss: 1.542, Test accuracy: 92.33 

Round  51, Global train loss: 1.491, Global test loss: 1.534, Global test accuracy: 92.86 

Round  52, Train loss: 1.494, Test loss: 1.541, Test accuracy: 92.34 

Round  52, Global train loss: 1.494, Global test loss: 1.534, Global test accuracy: 93.17 

Round  53, Train loss: 1.496, Test loss: 1.539, Test accuracy: 92.48 

Round  53, Global train loss: 1.496, Global test loss: 1.532, Global test accuracy: 93.10 

Round  54, Train loss: 1.498, Test loss: 1.539, Test accuracy: 92.52 

Round  54, Global train loss: 1.498, Global test loss: 1.532, Global test accuracy: 93.19 

Round  55, Train loss: 1.486, Test loss: 1.538, Test accuracy: 92.61 

Round  55, Global train loss: 1.486, Global test loss: 1.532, Global test accuracy: 93.14 

Round  56, Train loss: 1.490, Test loss: 1.537, Test accuracy: 92.72 

Round  56, Global train loss: 1.490, Global test loss: 1.531, Global test accuracy: 93.17 

Round  57, Train loss: 1.496, Test loss: 1.537, Test accuracy: 92.78 

Round  57, Global train loss: 1.496, Global test loss: 1.530, Global test accuracy: 93.30 

Round  58, Train loss: 1.495, Test loss: 1.537, Test accuracy: 92.79 

Round  58, Global train loss: 1.495, Global test loss: 1.530, Global test accuracy: 93.28 

Round  59, Train loss: 1.496, Test loss: 1.536, Test accuracy: 92.81 

Round  59, Global train loss: 1.496, Global test loss: 1.530, Global test accuracy: 93.39 

Round  60, Train loss: 1.489, Test loss: 1.536, Test accuracy: 92.85 

Round  60, Global train loss: 1.489, Global test loss: 1.530, Global test accuracy: 93.23 

Round  61, Train loss: 1.488, Test loss: 1.535, Test accuracy: 92.92 

Round  61, Global train loss: 1.488, Global test loss: 1.530, Global test accuracy: 93.22 

Round  62, Train loss: 1.486, Test loss: 1.534, Test accuracy: 92.99 

Round  62, Global train loss: 1.486, Global test loss: 1.530, Global test accuracy: 93.26 

Round  63, Train loss: 1.488, Test loss: 1.534, Test accuracy: 92.97 

Round  63, Global train loss: 1.488, Global test loss: 1.530, Global test accuracy: 93.34 

Round  64, Train loss: 1.485, Test loss: 1.534, Test accuracy: 92.98 

Round  64, Global train loss: 1.485, Global test loss: 1.529, Global test accuracy: 93.44 

Round  65, Train loss: 1.492, Test loss: 1.534, Test accuracy: 93.02 

Round  65, Global train loss: 1.492, Global test loss: 1.528, Global test accuracy: 93.56 

Round  66, Train loss: 1.484, Test loss: 1.533, Test accuracy: 93.16 

Round  66, Global train loss: 1.484, Global test loss: 1.528, Global test accuracy: 93.53 

Round  67, Train loss: 1.486, Test loss: 1.532, Test accuracy: 93.16 

Round  67, Global train loss: 1.486, Global test loss: 1.528, Global test accuracy: 93.53 

Round  68, Train loss: 1.484, Test loss: 1.532, Test accuracy: 93.20 

Round  68, Global train loss: 1.484, Global test loss: 1.527, Global test accuracy: 93.59 

Round  69, Train loss: 1.492, Test loss: 1.531, Test accuracy: 93.22 

Round  69, Global train loss: 1.492, Global test loss: 1.527, Global test accuracy: 93.56 

Round  70, Train loss: 1.484, Test loss: 1.531, Test accuracy: 93.28 

Round  70, Global train loss: 1.484, Global test loss: 1.527, Global test accuracy: 93.58 

Round  71, Train loss: 1.486, Test loss: 1.530, Test accuracy: 93.36 

Round  71, Global train loss: 1.486, Global test loss: 1.526, Global test accuracy: 93.54 

Round  72, Train loss: 1.484, Test loss: 1.530, Test accuracy: 93.41 

Round  72, Global train loss: 1.484, Global test loss: 1.527, Global test accuracy: 93.61 

Round  73, Train loss: 1.487, Test loss: 1.530, Test accuracy: 93.41 

Round  73, Global train loss: 1.487, Global test loss: 1.526, Global test accuracy: 93.73 

Round  74, Train loss: 1.483, Test loss: 1.530, Test accuracy: 93.37 

Round  74, Global train loss: 1.483, Global test loss: 1.526, Global test accuracy: 93.75 

Round  75, Train loss: 1.483, Test loss: 1.530, Test accuracy: 93.33 

Round  75, Global train loss: 1.483, Global test loss: 1.525, Global test accuracy: 93.86 

Round  76, Train loss: 1.486, Test loss: 1.529, Test accuracy: 93.39 

Round  76, Global train loss: 1.486, Global test loss: 1.525, Global test accuracy: 93.84 

Round  77, Train loss: 1.486, Test loss: 1.529, Test accuracy: 93.41 

Round  77, Global train loss: 1.486, Global test loss: 1.526, Global test accuracy: 93.72 

Round  78, Train loss: 1.486, Test loss: 1.529, Test accuracy: 93.44 

Round  78, Global train loss: 1.486, Global test loss: 1.525, Global test accuracy: 93.72 

Round  79, Train loss: 1.484, Test loss: 1.529, Test accuracy: 93.48 

Round  79, Global train loss: 1.484, Global test loss: 1.525, Global test accuracy: 93.64 

Round  80, Train loss: 1.483, Test loss: 1.529, Test accuracy: 93.47 

Round  80, Global train loss: 1.483, Global test loss: 1.525, Global test accuracy: 93.89 

Round  81, Train loss: 1.483, Test loss: 1.528, Test accuracy: 93.50 

Round  81, Global train loss: 1.483, Global test loss: 1.524, Global test accuracy: 93.89 

Round  82, Train loss: 1.480, Test loss: 1.528, Test accuracy: 93.56 

Round  82, Global train loss: 1.480, Global test loss: 1.524, Global test accuracy: 93.94 

Round  83, Train loss: 1.481, Test loss: 1.528, Test accuracy: 93.61 

Round  83, Global train loss: 1.481, Global test loss: 1.524, Global test accuracy: 93.92 

Round  84, Train loss: 1.482, Test loss: 1.527, Test accuracy: 93.64 

Round  84, Global train loss: 1.482, Global test loss: 1.524, Global test accuracy: 93.83 

Round  85, Train loss: 1.484, Test loss: 1.527, Test accuracy: 93.66 

Round  85, Global train loss: 1.484, Global test loss: 1.524, Global test accuracy: 93.97 

Round  86, Train loss: 1.483, Test loss: 1.527, Test accuracy: 93.70 

Round  86, Global train loss: 1.483, Global test loss: 1.524, Global test accuracy: 93.95 

Round  87, Train loss: 1.482, Test loss: 1.527, Test accuracy: 93.70 

Round  87, Global train loss: 1.482, Global test loss: 1.524, Global test accuracy: 93.98 

Round  88, Train loss: 1.481, Test loss: 1.527, Test accuracy: 93.67 

Round  88, Global train loss: 1.481, Global test loss: 1.524, Global test accuracy: 94.02 

Round  89, Train loss: 1.480, Test loss: 1.527, Test accuracy: 93.72 

Round  89, Global train loss: 1.480, Global test loss: 1.523, Global test accuracy: 94.07 

Round  90, Train loss: 1.480, Test loss: 1.527, Test accuracy: 93.73 

Round  90, Global train loss: 1.480, Global test loss: 1.523, Global test accuracy: 93.94 

Round  91, Train loss: 1.485, Test loss: 1.527, Test accuracy: 93.75 

Round  91, Global train loss: 1.485, Global test loss: 1.523, Global test accuracy: 94.05 

Round  92, Train loss: 1.480, Test loss: 1.526, Test accuracy: 93.81 

Round  92, Global train loss: 1.480, Global test loss: 1.522, Global test accuracy: 94.06 

Round  93, Train loss: 1.481, Test loss: 1.526, Test accuracy: 93.83 

Round  93, Global train loss: 1.481, Global test loss: 1.523, Global test accuracy: 94.00 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.487, Test loss: 1.525, Test accuracy: 93.89 

Round  94, Global train loss: 1.487, Global test loss: 1.523, Global test accuracy: 94.06 

Round  95, Train loss: 1.481, Test loss: 1.525, Test accuracy: 93.87 

Round  95, Global train loss: 1.481, Global test loss: 1.523, Global test accuracy: 93.89 

Round  96, Train loss: 1.480, Test loss: 1.526, Test accuracy: 93.83 

Round  96, Global train loss: 1.480, Global test loss: 1.522, Global test accuracy: 94.03 

Round  97, Train loss: 1.481, Test loss: 1.525, Test accuracy: 93.80 

Round  97, Global train loss: 1.481, Global test loss: 1.522, Global test accuracy: 94.02 

Round  98, Train loss: 1.479, Test loss: 1.525, Test accuracy: 93.84 

Round  98, Global train loss: 1.479, Global test loss: 1.522, Global test accuracy: 94.14 

Round  99, Train loss: 1.486, Test loss: 1.525, Test accuracy: 93.87 

Round  99, Global train loss: 1.486, Global test loss: 1.522, Global test accuracy: 94.17 

Final Round, Train loss: 1.480, Test loss: 1.524, Test accuracy: 93.92 

Final Round, Global train loss: 1.480, Global test loss: 1.522, Global test accuracy: 94.17 

Average accuracy final 10 rounds: 93.822 

Average global accuracy final 10 rounds: 94.036 

1161.3617684841156
[0.8112161159515381, 1.5260460376739502, 2.238520383834839, 2.9510130882263184, 3.660705327987671, 4.376731872558594, 5.089840412139893, 5.799418210983276, 6.50565767288208, 7.211488485336304, 7.918104410171509, 8.58570909500122, 9.294161796569824, 10.00820517539978, 10.723997831344604, 11.436811923980713, 12.154154300689697, 12.870086669921875, 13.588420152664185, 14.306971788406372, 15.022308826446533, 15.73517107963562, 16.447450399398804, 17.164807558059692, 17.88006901741028, 18.587271213531494, 19.299849271774292, 20.01700472831726, 20.732353925704956, 21.44963574409485, 22.166701078414917, 22.877376079559326, 23.59025812149048, 24.305328607559204, 25.016005516052246, 25.728102207183838, 26.442153453826904, 27.15819215774536, 27.87412190437317, 28.58609414100647, 29.30146813392639, 30.016462802886963, 30.7286593914032, 31.444804430007935, 32.156413316726685, 32.87379598617554, 33.59035658836365, 34.301976919174194, 35.01608467102051, 35.728493452072144, 36.43966817855835, 37.15656089782715, 37.87426471710205, 38.59243869781494, 39.303834199905396, 40.01837515830994, 40.73193168640137, 41.44284653663635, 42.1576566696167, 42.87742757797241, 43.595213174819946, 44.31166052818298, 45.02726435661316, 45.73702025413513, 46.40208458900452, 47.114776372909546, 47.827890396118164, 48.53893280029297, 49.251936197280884, 49.96350884437561, 50.68041658401489, 51.39810132980347, 52.113242387771606, 52.83056831359863, 53.5467894077301, 54.263331174850464, 54.980438232421875, 55.689547538757324, 56.4001944065094, 57.11552929878235, 57.8311288356781, 58.545336961746216, 59.2544732093811, 59.86284804344177, 60.46943140029907, 61.0827419757843, 61.697956800460815, 62.30596661567688, 62.90663504600525, 63.50815725326538, 64.10984444618225, 64.72801923751831, 65.33107924461365, 65.93691372871399, 66.5445659160614, 67.14914131164551, 67.75414991378784, 68.36159443855286, 68.96927785873413, 69.5760109424591, 70.78569006919861]
[25.505, 24.895, 19.26, 28.935, 36.15, 45.5, 54.045, 61.065, 71.06, 73.815, 76.175, 79.485, 79.86, 80.67, 80.83, 80.96, 81.565, 82.735, 82.875, 82.94, 82.975, 83.15, 83.26, 83.3, 83.38, 83.455, 83.49, 83.725, 84.82, 86.09, 86.92, 87.76, 88.835, 89.44, 90.2, 90.315, 90.535, 90.8, 90.825, 91.065, 91.235, 91.595, 91.685, 91.91, 91.845, 91.895, 91.985, 92.02, 92.14, 92.225, 92.26, 92.325, 92.34, 92.485, 92.515, 92.605, 92.715, 92.775, 92.79, 92.805, 92.85, 92.92, 92.99, 92.965, 92.985, 93.02, 93.155, 93.155, 93.2, 93.22, 93.275, 93.365, 93.405, 93.41, 93.37, 93.325, 93.39, 93.41, 93.435, 93.485, 93.465, 93.495, 93.565, 93.61, 93.64, 93.655, 93.705, 93.705, 93.665, 93.725, 93.73, 93.755, 93.805, 93.835, 93.89, 93.87, 93.825, 93.795, 93.845, 93.87, 93.925]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 28.84 

Round   1, Train loss: 2.299, Test loss: 2.297, Test accuracy: 35.20 

Round   2, Train loss: 2.296, Test loss: 2.293, Test accuracy: 37.40 

Round   3, Train loss: 2.292, Test loss: 2.288, Test accuracy: 41.59 

Round   4, Train loss: 2.286, Test loss: 2.279, Test accuracy: 46.63 

Round   5, Train loss: 2.274, Test loss: 2.260, Test accuracy: 46.92 

Round   6, Train loss: 2.239, Test loss: 2.199, Test accuracy: 43.20 

Round   7, Train loss: 2.142, Test loss: 2.086, Test accuracy: 46.91 

Round   8, Train loss: 2.043, Test loss: 1.998, Test accuracy: 55.72 

Round   9, Train loss: 1.950, Test loss: 1.912, Test accuracy: 63.94 

Round  10, Train loss: 1.856, Test loss: 1.846, Test accuracy: 67.72 

Round  11, Train loss: 1.809, Test loss: 1.810, Test accuracy: 69.88 

Round  12, Train loss: 1.785, Test loss: 1.787, Test accuracy: 71.08 

Round  13, Train loss: 1.752, Test loss: 1.761, Test accuracy: 72.60 

Round  14, Train loss: 1.726, Test loss: 1.739, Test accuracy: 74.37 

Round  15, Train loss: 1.702, Test loss: 1.721, Test accuracy: 75.83 

Round  16, Train loss: 1.685, Test loss: 1.707, Test accuracy: 77.25 

Round  17, Train loss: 1.675, Test loss: 1.693, Test accuracy: 79.06 

Round  18, Train loss: 1.662, Test loss: 1.686, Test accuracy: 79.38 

Round  19, Train loss: 1.661, Test loss: 1.678, Test accuracy: 80.11 

Round  20, Train loss: 1.654, Test loss: 1.673, Test accuracy: 80.50 

Round  21, Train loss: 1.652, Test loss: 1.668, Test accuracy: 80.81 

Round  22, Train loss: 1.643, Test loss: 1.663, Test accuracy: 81.12 

Round  23, Train loss: 1.641, Test loss: 1.662, Test accuracy: 81.11 

Round  24, Train loss: 1.640, Test loss: 1.652, Test accuracy: 81.97 

Round  25, Train loss: 1.641, Test loss: 1.649, Test accuracy: 82.22 

Round  26, Train loss: 1.623, Test loss: 1.644, Test accuracy: 82.83 

Round  27, Train loss: 1.619, Test loss: 1.640, Test accuracy: 83.19 

Round  28, Train loss: 1.617, Test loss: 1.639, Test accuracy: 83.25 

Round  29, Train loss: 1.618, Test loss: 1.636, Test accuracy: 83.58 

Round  30, Train loss: 1.590, Test loss: 1.627, Test accuracy: 84.53 

Round  31, Train loss: 1.581, Test loss: 1.625, Test accuracy: 84.85 

Round  32, Train loss: 1.582, Test loss: 1.624, Test accuracy: 84.83 

Round  33, Train loss: 1.561, Test loss: 1.612, Test accuracy: 85.94 

Round  34, Train loss: 1.559, Test loss: 1.606, Test accuracy: 86.65 

Round  35, Train loss: 1.554, Test loss: 1.601, Test accuracy: 87.01 

Round  36, Train loss: 1.559, Test loss: 1.593, Test accuracy: 87.94 

Round  37, Train loss: 1.549, Test loss: 1.585, Test accuracy: 88.59 

Round  38, Train loss: 1.548, Test loss: 1.582, Test accuracy: 88.82 

Round  39, Train loss: 1.540, Test loss: 1.577, Test accuracy: 89.53 

Round  40, Train loss: 1.537, Test loss: 1.577, Test accuracy: 89.39 

Round  41, Train loss: 1.542, Test loss: 1.575, Test accuracy: 89.64 

Round  42, Train loss: 1.544, Test loss: 1.575, Test accuracy: 89.43 

Round  43, Train loss: 1.541, Test loss: 1.575, Test accuracy: 89.39 

Round  44, Train loss: 1.535, Test loss: 1.572, Test accuracy: 89.71 

Round  45, Train loss: 1.533, Test loss: 1.570, Test accuracy: 89.84 

Round  46, Train loss: 1.528, Test loss: 1.571, Test accuracy: 89.83 

Round  47, Train loss: 1.530, Test loss: 1.571, Test accuracy: 89.78 

Round  48, Train loss: 1.527, Test loss: 1.570, Test accuracy: 89.75 

Round  49, Train loss: 1.525, Test loss: 1.570, Test accuracy: 89.67 

Round  50, Train loss: 1.531, Test loss: 1.565, Test accuracy: 90.30 

Round  51, Train loss: 1.524, Test loss: 1.565, Test accuracy: 90.37 

Round  52, Train loss: 1.520, Test loss: 1.564, Test accuracy: 90.38 

Round  53, Train loss: 1.522, Test loss: 1.563, Test accuracy: 90.43 

Round  54, Train loss: 1.521, Test loss: 1.563, Test accuracy: 90.42 

Round  55, Train loss: 1.527, Test loss: 1.563, Test accuracy: 90.40 

Round  56, Train loss: 1.522, Test loss: 1.562, Test accuracy: 90.44 

Round  57, Train loss: 1.516, Test loss: 1.563, Test accuracy: 90.42 

Round  58, Train loss: 1.519, Test loss: 1.563, Test accuracy: 90.39 

Round  59, Train loss: 1.518, Test loss: 1.562, Test accuracy: 90.42 

Round  60, Train loss: 1.513, Test loss: 1.563, Test accuracy: 90.25 

Round  61, Train loss: 1.517, Test loss: 1.562, Test accuracy: 90.38 

Round  62, Train loss: 1.512, Test loss: 1.563, Test accuracy: 90.29 

Round  63, Train loss: 1.514, Test loss: 1.561, Test accuracy: 90.57 

Round  64, Train loss: 1.511, Test loss: 1.560, Test accuracy: 90.62 

Round  65, Train loss: 1.507, Test loss: 1.560, Test accuracy: 90.69 

Round  66, Train loss: 1.508, Test loss: 1.559, Test accuracy: 90.66 

Round  67, Train loss: 1.514, Test loss: 1.559, Test accuracy: 90.60 

Round  68, Train loss: 1.511, Test loss: 1.559, Test accuracy: 90.55 

Round  69, Train loss: 1.509, Test loss: 1.559, Test accuracy: 90.55 

Round  70, Train loss: 1.508, Test loss: 1.559, Test accuracy: 90.53 

Round  71, Train loss: 1.509, Test loss: 1.559, Test accuracy: 90.50 

Round  72, Train loss: 1.509, Test loss: 1.559, Test accuracy: 90.57 

Round  73, Train loss: 1.503, Test loss: 1.559, Test accuracy: 90.52 

Round  74, Train loss: 1.510, Test loss: 1.559, Test accuracy: 90.54 

Round  75, Train loss: 1.507, Test loss: 1.558, Test accuracy: 90.61 

Round  76, Train loss: 1.505, Test loss: 1.558, Test accuracy: 90.77 

Round  77, Train loss: 1.508, Test loss: 1.557, Test accuracy: 90.68 

Round  78, Train loss: 1.510, Test loss: 1.556, Test accuracy: 90.88 

Round  79, Train loss: 1.505, Test loss: 1.556, Test accuracy: 90.92 

Round  80, Train loss: 1.503, Test loss: 1.555, Test accuracy: 90.93 

Round  81, Train loss: 1.500, Test loss: 1.556, Test accuracy: 90.84 

Round  82, Train loss: 1.508, Test loss: 1.557, Test accuracy: 90.78 

Round  83, Train loss: 1.504, Test loss: 1.557, Test accuracy: 90.73 

Round  84, Train loss: 1.506, Test loss: 1.556, Test accuracy: 90.77 

Round  85, Train loss: 1.508, Test loss: 1.556, Test accuracy: 90.81 

Round  86, Train loss: 1.500, Test loss: 1.557, Test accuracy: 90.70 

Round  87, Train loss: 1.507, Test loss: 1.557, Test accuracy: 90.70 

Round  88, Train loss: 1.509, Test loss: 1.556, Test accuracy: 90.79 

Round  89, Train loss: 1.501, Test loss: 1.556, Test accuracy: 90.78 

Round  90, Train loss: 1.496, Test loss: 1.555, Test accuracy: 90.87 

Round  91, Train loss: 1.502, Test loss: 1.555, Test accuracy: 90.89 

Round  92, Train loss: 1.503, Test loss: 1.554, Test accuracy: 90.89 

Round  93, Train loss: 1.505, Test loss: 1.555, Test accuracy: 90.89 

Round  94, Train loss: 1.499, Test loss: 1.554, Test accuracy: 90.97 

Round  95, Train loss: 1.500, Test loss: 1.554, Test accuracy: 90.92 

Round  96, Train loss: 1.507, Test loss: 1.554, Test accuracy: 90.91 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.502, Test loss: 1.553, Test accuracy: 91.03 

Round  98, Train loss: 1.497, Test loss: 1.553, Test accuracy: 91.05 

Round  99, Train loss: 1.499, Test loss: 1.553, Test accuracy: 91.02 

Final Round, Train loss: 1.501, Test loss: 1.553, Test accuracy: 91.00 

Average accuracy final 10 rounds: 90.9425 

728.0476379394531
[0.7043485641479492, 1.3471062183380127, 1.985994815826416, 2.6227476596832275, 3.257913827896118, 3.8910839557647705, 4.530951023101807, 5.169672727584839, 5.805259943008423, 6.442412376403809, 7.076236724853516, 7.7128190994262695, 8.351271867752075, 8.990419626235962, 9.630074739456177, 10.263288497924805, 10.899615049362183, 11.535357475280762, 12.17520260810852, 12.81593942642212, 13.455609321594238, 14.094892501831055, 14.734898328781128, 15.3739333152771, 15.932393312454224, 16.496023178100586, 17.06369686126709, 17.6324679851532, 18.204429388046265, 18.767217874526978, 19.32917022705078, 19.895833730697632, 20.50021195411682, 21.06554889678955, 21.635029315948486, 22.198557138442993, 22.768078327178955, 23.33813500404358, 23.90340542793274, 24.469881534576416, 25.034087896347046, 25.60303783416748, 26.17348551750183, 26.743855714797974, 27.311010360717773, 27.876951217651367, 28.442995309829712, 29.00868034362793, 29.578616619110107, 30.1463840007782, 30.71327304840088, 31.27561664581299, 31.844108819961548, 32.439176082611084, 33.00519108772278, 33.572521686553955, 34.13813018798828, 34.71320128440857, 35.281657695770264, 35.84690833091736, 36.41096830368042, 36.97630548477173, 37.54498815536499, 38.11458349227905, 38.682031869888306, 39.24690842628479, 39.81366205215454, 40.37955284118652, 40.946061849594116, 41.515076875686646, 42.08064246177673, 42.64963674545288, 43.21531796455383, 43.78692150115967, 44.35257935523987, 44.920586585998535, 45.485098123550415, 46.05588746070862, 46.62053656578064, 47.1858024597168, 47.750176191329956, 48.315293312072754, 48.883344888687134, 49.44699239730835, 50.01091766357422, 50.57524657249451, 51.154794216156006, 51.71967959403992, 52.28736448287964, 52.85666608810425, 53.42117786407471, 53.98428773880005, 54.548290967941284, 55.1325364112854, 55.694029808044434, 56.25775909423828, 56.8244948387146, 57.387540102005005, 57.953524112701416, 58.53691482543945, 59.64592885971069]
[28.84, 35.2, 37.4, 41.59, 46.635, 46.92, 43.195, 46.905, 55.715, 63.935, 67.72, 69.88, 71.075, 72.6, 74.37, 75.835, 77.25, 79.06, 79.375, 80.11, 80.495, 80.805, 81.12, 81.115, 81.965, 82.215, 82.83, 83.195, 83.25, 83.575, 84.535, 84.85, 84.835, 85.945, 86.65, 87.01, 87.945, 88.595, 88.82, 89.535, 89.39, 89.635, 89.43, 89.39, 89.71, 89.845, 89.83, 89.775, 89.755, 89.675, 90.295, 90.37, 90.38, 90.43, 90.415, 90.4, 90.44, 90.415, 90.385, 90.42, 90.25, 90.38, 90.29, 90.57, 90.62, 90.69, 90.66, 90.6, 90.545, 90.545, 90.525, 90.505, 90.57, 90.52, 90.54, 90.61, 90.765, 90.68, 90.88, 90.92, 90.93, 90.845, 90.785, 90.73, 90.77, 90.805, 90.7, 90.705, 90.79, 90.785, 90.87, 90.895, 90.885, 90.89, 90.97, 90.92, 90.905, 91.03, 91.045, 91.015, 90.995]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.299, Test accuracy: 17.12 

Round   1, Train loss: 2.297, Test loss: 2.295, Test accuracy: 24.86 

Round   2, Train loss: 2.289, Test loss: 2.284, Test accuracy: 18.13 

Round   3, Train loss: 2.268, Test loss: 2.247, Test accuracy: 23.55 

Round   4, Train loss: 2.183, Test loss: 2.127, Test accuracy: 50.96 

Round   5, Train loss: 1.972, Test loss: 1.952, Test accuracy: 59.40 

Round   6, Train loss: 1.849, Test loss: 1.861, Test accuracy: 65.37 

Round   7, Train loss: 1.777, Test loss: 1.803, Test accuracy: 69.98 

Round   8, Train loss: 1.737, Test loss: 1.768, Test accuracy: 72.43 

Round   9, Train loss: 1.713, Test loss: 1.743, Test accuracy: 74.52 

Round  10, Train loss: 1.680, Test loss: 1.724, Test accuracy: 76.19 

Round  11, Train loss: 1.653, Test loss: 1.711, Test accuracy: 77.28 

Round  12, Train loss: 1.639, Test loss: 1.692, Test accuracy: 78.98 

Round  13, Train loss: 1.641, Test loss: 1.663, Test accuracy: 81.54 

Round  14, Train loss: 1.628, Test loss: 1.655, Test accuracy: 82.02 

Round  15, Train loss: 1.613, Test loss: 1.649, Test accuracy: 82.27 

Round  16, Train loss: 1.616, Test loss: 1.643, Test accuracy: 82.80 

Round  17, Train loss: 1.596, Test loss: 1.634, Test accuracy: 83.66 

Round  18, Train loss: 1.603, Test loss: 1.631, Test accuracy: 83.97 

Round  19, Train loss: 1.607, Test loss: 1.625, Test accuracy: 84.64 

Round  20, Train loss: 1.559, Test loss: 1.620, Test accuracy: 84.95 

Round  21, Train loss: 1.589, Test loss: 1.618, Test accuracy: 85.07 

Round  22, Train loss: 1.569, Test loss: 1.615, Test accuracy: 85.27 

Round  23, Train loss: 1.568, Test loss: 1.602, Test accuracy: 86.61 

Round  24, Train loss: 1.550, Test loss: 1.595, Test accuracy: 87.44 

Round  25, Train loss: 1.541, Test loss: 1.591, Test accuracy: 87.73 

Round  26, Train loss: 1.525, Test loss: 1.587, Test accuracy: 88.08 

Round  27, Train loss: 1.527, Test loss: 1.584, Test accuracy: 88.40 

Round  28, Train loss: 1.534, Test loss: 1.582, Test accuracy: 88.48 

Round  29, Train loss: 1.542, Test loss: 1.581, Test accuracy: 88.69 

Round  30, Train loss: 1.537, Test loss: 1.580, Test accuracy: 88.67 

Round  31, Train loss: 1.536, Test loss: 1.575, Test accuracy: 89.27 

Round  32, Train loss: 1.527, Test loss: 1.574, Test accuracy: 89.36 

Round  33, Train loss: 1.540, Test loss: 1.573, Test accuracy: 89.31 

Round  34, Train loss: 1.516, Test loss: 1.571, Test accuracy: 89.52 

Round  35, Train loss: 1.538, Test loss: 1.570, Test accuracy: 89.67 

Round  36, Train loss: 1.523, Test loss: 1.568, Test accuracy: 89.79 

Round  37, Train loss: 1.520, Test loss: 1.568, Test accuracy: 89.79 

Round  38, Train loss: 1.508, Test loss: 1.568, Test accuracy: 89.81 

Round  39, Train loss: 1.522, Test loss: 1.567, Test accuracy: 89.83 

Round  40, Train loss: 1.512, Test loss: 1.567, Test accuracy: 89.89 

Round  41, Train loss: 1.501, Test loss: 1.566, Test accuracy: 89.92 

Round  42, Train loss: 1.518, Test loss: 1.563, Test accuracy: 90.17 

Round  43, Train loss: 1.501, Test loss: 1.561, Test accuracy: 90.44 

Round  44, Train loss: 1.514, Test loss: 1.561, Test accuracy: 90.39 

Round  45, Train loss: 1.497, Test loss: 1.560, Test accuracy: 90.55 

Round  46, Train loss: 1.498, Test loss: 1.560, Test accuracy: 90.45 

Round  47, Train loss: 1.499, Test loss: 1.560, Test accuracy: 90.48 

Round  48, Train loss: 1.499, Test loss: 1.559, Test accuracy: 90.61 

Round  49, Train loss: 1.526, Test loss: 1.559, Test accuracy: 90.54 

Round  50, Train loss: 1.515, Test loss: 1.559, Test accuracy: 90.55 

Round  51, Train loss: 1.514, Test loss: 1.555, Test accuracy: 90.88 

Round  52, Train loss: 1.511, Test loss: 1.554, Test accuracy: 91.03 

Round  53, Train loss: 1.506, Test loss: 1.554, Test accuracy: 91.11 

Round  54, Train loss: 1.495, Test loss: 1.553, Test accuracy: 91.21 

Round  55, Train loss: 1.509, Test loss: 1.554, Test accuracy: 91.05 

Round  56, Train loss: 1.506, Test loss: 1.553, Test accuracy: 91.12 

Round  57, Train loss: 1.498, Test loss: 1.552, Test accuracy: 91.28 

Round  58, Train loss: 1.510, Test loss: 1.553, Test accuracy: 91.28 

Round  59, Train loss: 1.507, Test loss: 1.552, Test accuracy: 91.23 

Round  60, Train loss: 1.497, Test loss: 1.552, Test accuracy: 91.22 

Round  61, Train loss: 1.496, Test loss: 1.552, Test accuracy: 91.17 

Round  62, Train loss: 1.496, Test loss: 1.552, Test accuracy: 91.28 

Round  63, Train loss: 1.493, Test loss: 1.551, Test accuracy: 91.22 

Round  64, Train loss: 1.492, Test loss: 1.550, Test accuracy: 91.38 

Round  65, Train loss: 1.491, Test loss: 1.550, Test accuracy: 91.35 

Round  66, Train loss: 1.505, Test loss: 1.550, Test accuracy: 91.27 

Round  67, Train loss: 1.492, Test loss: 1.550, Test accuracy: 91.31 

Round  68, Train loss: 1.493, Test loss: 1.550, Test accuracy: 91.37 

Round  69, Train loss: 1.501, Test loss: 1.549, Test accuracy: 91.43 

Round  70, Train loss: 1.490, Test loss: 1.549, Test accuracy: 91.42 

Round  71, Train loss: 1.492, Test loss: 1.549, Test accuracy: 91.42 

Round  72, Train loss: 1.505, Test loss: 1.549, Test accuracy: 91.42 

Round  73, Train loss: 1.504, Test loss: 1.549, Test accuracy: 91.45 

Round  74, Train loss: 1.490, Test loss: 1.549, Test accuracy: 91.43 

Round  75, Train loss: 1.487, Test loss: 1.548, Test accuracy: 91.55 

Round  76, Train loss: 1.488, Test loss: 1.548, Test accuracy: 91.53 

Round  77, Train loss: 1.491, Test loss: 1.548, Test accuracy: 91.46 

Round  78, Train loss: 1.504, Test loss: 1.549, Test accuracy: 91.42 

Round  79, Train loss: 1.491, Test loss: 1.548, Test accuracy: 91.53 

Round  80, Train loss: 1.489, Test loss: 1.548, Test accuracy: 91.53 

Round  81, Train loss: 1.489, Test loss: 1.548, Test accuracy: 91.52 

Round  82, Train loss: 1.503, Test loss: 1.548, Test accuracy: 91.47 

Round  83, Train loss: 1.504, Test loss: 1.548, Test accuracy: 91.50 

Round  84, Train loss: 1.503, Test loss: 1.548, Test accuracy: 91.50 

Round  85, Train loss: 1.488, Test loss: 1.548, Test accuracy: 91.53 

Round  86, Train loss: 1.489, Test loss: 1.548, Test accuracy: 91.55 

Round  87, Train loss: 1.485, Test loss: 1.548, Test accuracy: 91.61 

Round  88, Train loss: 1.488, Test loss: 1.548, Test accuracy: 91.58 

Round  89, Train loss: 1.491, Test loss: 1.548, Test accuracy: 91.53 

Round  90, Train loss: 1.487, Test loss: 1.548, Test accuracy: 91.61 

Round  91, Train loss: 1.501, Test loss: 1.548, Test accuracy: 91.60 

Round  92, Train loss: 1.501, Test loss: 1.547, Test accuracy: 91.61 

Round  93, Train loss: 1.503, Test loss: 1.547, Test accuracy: 91.61 

Round  94, Train loss: 1.499, Test loss: 1.547, Test accuracy: 91.56 

Round  95, Train loss: 1.500, Test loss: 1.547, Test accuracy: 91.66 

Round  96, Train loss: 1.488, Test loss: 1.547, Test accuracy: 91.69 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.486, Test loss: 1.547, Test accuracy: 91.67 

Round  98, Train loss: 1.488, Test loss: 1.547, Test accuracy: 91.62 

Round  99, Train loss: 1.501, Test loss: 1.547, Test accuracy: 91.67 

Final Round, Train loss: 1.492, Test loss: 1.548, Test accuracy: 91.52 

Average accuracy final 10 rounds: 91.63000000000001 

741.1406788825989
[0.7842221260070801, 1.488285779953003, 2.1932342052459717, 2.893866539001465, 3.5938963890075684, 4.295975208282471, 4.996628284454346, 5.697802305221558, 6.397310495376587, 7.098332405090332, 7.800387620925903, 8.50217080116272, 9.202027082443237, 9.906227111816406, 10.606735706329346, 11.305403232574463, 12.004100799560547, 12.705783128738403, 13.40681505203247, 14.108956336975098, 14.810372591018677, 15.402160882949829, 15.990482330322266, 16.58327555656433, 17.17449188232422, 17.77324604988098, 18.36731719970703, 18.960480213165283, 19.553102493286133, 20.16141700744629, 20.75202202796936, 21.343473434448242, 21.935765981674194, 22.527700185775757, 23.120651721954346, 23.71029806137085, 24.302127361297607, 24.89047145843506, 25.482638359069824, 26.07284450531006, 26.665329933166504, 27.25898241996765, 27.851988554000854, 28.44409966468811, 29.034879446029663, 29.62751317024231, 30.218430042266846, 30.81329846382141, 31.40567898750305, 31.99857258796692, 32.58737325668335, 33.17903113365173, 33.770559549331665, 34.36083436012268, 34.95657467842102, 35.54867148399353, 36.14055156707764, 36.73408508300781, 37.32344841957092, 37.91263699531555, 38.50345468521118, 39.096529722213745, 39.68955183029175, 40.28211951255798, 40.875447511672974, 41.46906089782715, 42.06381869316101, 42.65017628669739, 43.24267625808716, 43.83437776565552, 44.425421953201294, 45.01852631568909, 45.61105990409851, 46.203773975372314, 46.7968385219574, 47.395493507385254, 47.98428726196289, 48.57738208770752, 49.16654443740845, 49.754607915878296, 50.344926595687866, 50.943084955215454, 51.54282855987549, 52.14105010032654, 52.732436656951904, 53.32455229759216, 53.91346740722656, 54.50418281555176, 55.095234870910645, 55.68327522277832, 56.275078535079956, 56.8708074092865, 57.462557315826416, 58.05497860908508, 58.64740037918091, 59.2449107170105, 59.84413003921509, 60.4451220035553, 61.0386266708374, 61.63647747039795, 62.68266034126282]
[17.12, 24.865, 18.13, 23.545, 50.96, 59.395, 65.37, 69.985, 72.43, 74.515, 76.195, 77.285, 78.98, 81.54, 82.015, 82.27, 82.795, 83.66, 83.975, 84.64, 84.955, 85.07, 85.265, 86.61, 87.44, 87.73, 88.075, 88.4, 88.48, 88.69, 88.67, 89.27, 89.355, 89.31, 89.515, 89.675, 89.79, 89.79, 89.81, 89.825, 89.895, 89.925, 90.165, 90.445, 90.39, 90.55, 90.45, 90.485, 90.61, 90.54, 90.545, 90.88, 91.035, 91.11, 91.21, 91.045, 91.125, 91.285, 91.28, 91.23, 91.215, 91.175, 91.275, 91.22, 91.38, 91.35, 91.27, 91.305, 91.37, 91.43, 91.42, 91.42, 91.415, 91.45, 91.43, 91.55, 91.525, 91.46, 91.425, 91.525, 91.53, 91.515, 91.465, 91.495, 91.5, 91.53, 91.55, 91.605, 91.585, 91.525, 91.615, 91.6, 91.61, 91.61, 91.565, 91.655, 91.695, 91.665, 91.62, 91.665, 91.52]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.12 

Round   1, Train loss: 2.297, Test loss: 2.296, Test accuracy: 19.52 

Round   2, Train loss: 2.293, Test loss: 2.291, Test accuracy: 24.40 

Round   3, Train loss: 2.282, Test loss: 2.280, Test accuracy: 33.12 

Round   4, Train loss: 2.232, Test loss: 2.228, Test accuracy: 36.98 

Round   5, Train loss: 2.135, Test loss: 2.149, Test accuracy: 42.77 

Round   6, Train loss: 2.034, Test loss: 2.062, Test accuracy: 47.27 

Round   7, Train loss: 1.906, Test loss: 1.968, Test accuracy: 64.41 

Round   8, Train loss: 1.755, Test loss: 1.885, Test accuracy: 73.70 

Round   9, Train loss: 1.699, Test loss: 1.824, Test accuracy: 76.05 

Round  10, Train loss: 1.627, Test loss: 1.789, Test accuracy: 77.01 

Round  11, Train loss: 1.621, Test loss: 1.743, Test accuracy: 79.27 

Round  12, Train loss: 1.609, Test loss: 1.709, Test accuracy: 81.14 

Round  13, Train loss: 1.574, Test loss: 1.694, Test accuracy: 81.52 

Round  14, Train loss: 1.543, Test loss: 1.684, Test accuracy: 82.44 

Round  15, Train loss: 1.523, Test loss: 1.680, Test accuracy: 82.61 

Round  16, Train loss: 1.544, Test loss: 1.663, Test accuracy: 83.30 

Round  17, Train loss: 1.521, Test loss: 1.660, Test accuracy: 83.54 

Round  18, Train loss: 1.517, Test loss: 1.659, Test accuracy: 83.21 

Round  19, Train loss: 1.548, Test loss: 1.632, Test accuracy: 84.47 

Round  20, Train loss: 1.502, Test loss: 1.630, Test accuracy: 84.54 

Round  21, Train loss: 1.515, Test loss: 1.626, Test accuracy: 84.82 

Round  22, Train loss: 1.500, Test loss: 1.625, Test accuracy: 84.82 

Round  23, Train loss: 1.496, Test loss: 1.624, Test accuracy: 84.86 

Round  24, Train loss: 1.497, Test loss: 1.624, Test accuracy: 84.86 

Round  25, Train loss: 1.491, Test loss: 1.623, Test accuracy: 84.97 

Round  26, Train loss: 1.494, Test loss: 1.622, Test accuracy: 84.86 

Round  27, Train loss: 1.489, Test loss: 1.622, Test accuracy: 84.85 

Round  28, Train loss: 1.496, Test loss: 1.621, Test accuracy: 84.98 

Round  29, Train loss: 1.496, Test loss: 1.620, Test accuracy: 85.05 

Round  30, Train loss: 1.495, Test loss: 1.620, Test accuracy: 85.06 

Round  31, Train loss: 1.494, Test loss: 1.619, Test accuracy: 85.12 

Round  32, Train loss: 1.489, Test loss: 1.619, Test accuracy: 85.12 

Round  33, Train loss: 1.488, Test loss: 1.618, Test accuracy: 85.08 

Round  34, Train loss: 1.490, Test loss: 1.618, Test accuracy: 85.11 

Round  35, Train loss: 1.485, Test loss: 1.618, Test accuracy: 85.06 

Round  36, Train loss: 1.489, Test loss: 1.618, Test accuracy: 85.09 

Round  37, Train loss: 1.485, Test loss: 1.618, Test accuracy: 85.08 

Round  38, Train loss: 1.487, Test loss: 1.618, Test accuracy: 85.09 

Round  39, Train loss: 1.490, Test loss: 1.617, Test accuracy: 85.10 

Round  40, Train loss: 1.487, Test loss: 1.617, Test accuracy: 85.18 

Round  41, Train loss: 1.484, Test loss: 1.617, Test accuracy: 85.17 

Round  42, Train loss: 1.487, Test loss: 1.617, Test accuracy: 85.15 

Round  43, Train loss: 1.491, Test loss: 1.617, Test accuracy: 85.21 

Round  44, Train loss: 1.482, Test loss: 1.617, Test accuracy: 85.19 

Round  45, Train loss: 1.485, Test loss: 1.617, Test accuracy: 85.13 

Round  46, Train loss: 1.488, Test loss: 1.617, Test accuracy: 85.16 

Round  47, Train loss: 1.485, Test loss: 1.616, Test accuracy: 85.09 

Round  48, Train loss: 1.487, Test loss: 1.616, Test accuracy: 85.14 

Round  49, Train loss: 1.484, Test loss: 1.616, Test accuracy: 85.13 

Round  50, Train loss: 1.487, Test loss: 1.616, Test accuracy: 85.14 

Round  51, Train loss: 1.486, Test loss: 1.616, Test accuracy: 85.11 

Round  52, Train loss: 1.483, Test loss: 1.616, Test accuracy: 85.12 

Round  53, Train loss: 1.483, Test loss: 1.616, Test accuracy: 85.04 

Round  54, Train loss: 1.485, Test loss: 1.616, Test accuracy: 85.10 

Round  55, Train loss: 1.486, Test loss: 1.616, Test accuracy: 85.07 

Round  56, Train loss: 1.485, Test loss: 1.616, Test accuracy: 85.12 

Round  57, Train loss: 1.486, Test loss: 1.616, Test accuracy: 85.17 

Round  58, Train loss: 1.485, Test loss: 1.615, Test accuracy: 85.19 

Round  59, Train loss: 1.483, Test loss: 1.615, Test accuracy: 85.19 

Round  60, Train loss: 1.484, Test loss: 1.615, Test accuracy: 85.20 

Round  61, Train loss: 1.484, Test loss: 1.615, Test accuracy: 85.16 

Round  62, Train loss: 1.483, Test loss: 1.615, Test accuracy: 85.17 

Round  63, Train loss: 1.484, Test loss: 1.615, Test accuracy: 85.17 

Round  64, Train loss: 1.484, Test loss: 1.615, Test accuracy: 85.14 

Round  65, Train loss: 1.483, Test loss: 1.615, Test accuracy: 85.16 

Round  66, Train loss: 1.487, Test loss: 1.615, Test accuracy: 85.17 

Round  67, Train loss: 1.482, Test loss: 1.615, Test accuracy: 85.16 

Round  68, Train loss: 1.483, Test loss: 1.615, Test accuracy: 85.12 

Round  69, Train loss: 1.484, Test loss: 1.615, Test accuracy: 85.14 

Round  70, Train loss: 1.482, Test loss: 1.615, Test accuracy: 85.16 

Round  71, Train loss: 1.483, Test loss: 1.615, Test accuracy: 85.12 

Round  72, Train loss: 1.484, Test loss: 1.615, Test accuracy: 85.15 

Round  73, Train loss: 1.479, Test loss: 1.614, Test accuracy: 85.16 

Round  74, Train loss: 1.484, Test loss: 1.614, Test accuracy: 85.14 

Round  75, Train loss: 1.485, Test loss: 1.614, Test accuracy: 85.13 

Round  76, Train loss: 1.483, Test loss: 1.615, Test accuracy: 85.14 

Round  77, Train loss: 1.485, Test loss: 1.615, Test accuracy: 85.08 

Round  78, Train loss: 1.482, Test loss: 1.615, Test accuracy: 85.08 

Round  79, Train loss: 1.481, Test loss: 1.614, Test accuracy: 85.09 

Round  80, Train loss: 1.482, Test loss: 1.615, Test accuracy: 85.08 

Round  81, Train loss: 1.481, Test loss: 1.614, Test accuracy: 85.08 

Round  82, Train loss: 1.483, Test loss: 1.614, Test accuracy: 85.09 

Round  83, Train loss: 1.483, Test loss: 1.614, Test accuracy: 85.11 

Round  84, Train loss: 1.480, Test loss: 1.614, Test accuracy: 85.12 

Round  85, Train loss: 1.483, Test loss: 1.614, Test accuracy: 85.17 

Round  86, Train loss: 1.479, Test loss: 1.614, Test accuracy: 85.17 

Round  87, Train loss: 1.483, Test loss: 1.614, Test accuracy: 85.20 

Round  88, Train loss: 1.482, Test loss: 1.614, Test accuracy: 85.22 

Round  89, Train loss: 1.481, Test loss: 1.614, Test accuracy: 85.19 

Round  90, Train loss: 1.481, Test loss: 1.614, Test accuracy: 85.19 

Round  91, Train loss: 1.483, Test loss: 1.613, Test accuracy: 85.21 

Round  92, Train loss: 1.482, Test loss: 1.613, Test accuracy: 85.23 

Round  93, Train loss: 1.481, Test loss: 1.613, Test accuracy: 85.25 

Round  94, Train loss: 1.482, Test loss: 1.613, Test accuracy: 85.24 

Round  95, Train loss: 1.483, Test loss: 1.613, Test accuracy: 85.24 

Round  96, Train loss: 1.481, Test loss: 1.613, Test accuracy: 85.24 

Round  97, Train loss: 1.481, Test loss: 1.613, Test accuracy: 85.25 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  98, Train loss: 1.482, Test loss: 1.613, Test accuracy: 85.23 

Round  99, Train loss: 1.485, Test loss: 1.613, Test accuracy: 85.27 

Final Round, Train loss: 1.482, Test loss: 1.613, Test accuracy: 85.27 

Average accuracy final 10 rounds: 85.23599999999999 

757.6869611740112
[0.7625322341918945, 1.4664738178253174, 2.1666951179504395, 2.8639729022979736, 3.5599803924560547, 4.258249044418335, 4.962112665176392, 5.665680646896362, 6.329607725143433, 6.99265193939209, 7.65781307220459, 8.345553159713745, 9.04249882698059, 9.743268013000488, 10.44617486000061, 11.14989161491394, 11.852975606918335, 12.553919792175293, 13.256129503250122, 13.958595514297485, 14.662372827529907, 15.370842218399048, 16.07904839515686, 16.784799814224243, 17.486711502075195, 18.18961501121521, 18.89731001853943, 19.605659246444702, 20.31434154510498, 21.023155450820923, 21.72726798057556, 22.42734122276306, 23.13044309616089, 23.831181049346924, 24.4283664226532, 25.027161598205566, 25.62449359893799, 26.220529079437256, 26.81644582748413, 27.411003828048706, 28.007171869277954, 28.607290983200073, 29.20750331878662, 29.805294513702393, 30.401976585388184, 30.9997398853302, 31.59761071205139, 32.19553804397583, 32.79400634765625, 33.39327883720398, 33.989349126815796, 34.58631873130798, 35.18477201461792, 35.78339672088623, 36.38174533843994, 36.98134231567383, 37.580504179000854, 38.180158615112305, 38.7778537273407, 39.37600064277649, 39.97478270530701, 40.57302117347717, 41.17556571960449, 41.77546429634094, 42.37525415420532, 42.97279620170593, 43.57200813293457, 44.17117691040039, 44.770482540130615, 45.36897110939026, 45.968504428863525, 46.5683069229126, 47.167038679122925, 47.766557693481445, 48.36486291885376, 48.963815212249756, 49.56515836715698, 50.16472911834717, 50.76410675048828, 51.36178803443909, 51.95946025848389, 52.55774974822998, 53.15500235557556, 53.752779960632324, 54.352118492126465, 54.95105695724487, 55.54923987388611, 56.14740777015686, 56.744691133499146, 57.343629121780396, 57.94225740432739, 58.539151191711426, 59.13842153549194, 59.733933448791504, 60.32970714569092, 60.925509214401245, 61.521846294403076, 62.12124300003052, 62.7175657749176, 63.314820289611816, 64.4615831375122]
[13.125, 19.515, 24.4, 33.125, 36.985, 42.765, 47.27, 64.405, 73.7, 76.05, 77.01, 79.265, 81.145, 81.515, 82.435, 82.615, 83.295, 83.54, 83.21, 84.47, 84.54, 84.82, 84.82, 84.86, 84.86, 84.965, 84.855, 84.85, 84.985, 85.05, 85.055, 85.12, 85.12, 85.075, 85.115, 85.065, 85.095, 85.08, 85.095, 85.1, 85.18, 85.165, 85.15, 85.21, 85.19, 85.13, 85.16, 85.095, 85.135, 85.13, 85.145, 85.115, 85.125, 85.04, 85.1, 85.07, 85.125, 85.17, 85.195, 85.195, 85.205, 85.16, 85.17, 85.165, 85.135, 85.16, 85.165, 85.16, 85.12, 85.135, 85.155, 85.125, 85.15, 85.16, 85.145, 85.13, 85.135, 85.08, 85.085, 85.09, 85.08, 85.08, 85.09, 85.115, 85.12, 85.175, 85.17, 85.2, 85.215, 85.195, 85.195, 85.21, 85.235, 85.245, 85.24, 85.24, 85.24, 85.255, 85.235, 85.265, 85.27]
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

Traceback (most recent call last):
  File "main_fedpac.py", line 61, in <module>
    dataset_train.targets = np.load('data/sample/dataset_train_target.npy', allow_pickle=True)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/lib/npyio.py", line 417, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'data/sample/dataset_train_target.npy'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.302, Test loss: 2.300, Test accuracy: 22.75
Round   1, Train loss: 2.299, Test loss: 2.295, Test accuracy: 30.50
Round   2, Train loss: 2.294, Test loss: 2.282, Test accuracy: 30.33
Round   3, Train loss: 2.282, Test loss: 2.220, Test accuracy: 31.02
Round   4, Train loss: 2.212, Test loss: 2.094, Test accuracy: 45.88
Round   5, Train loss: 2.122, Test loss: 1.920, Test accuracy: 56.56
Round   6, Train loss: 1.948, Test loss: 1.787, Test accuracy: 73.18
Round   7, Train loss: 1.819, Test loss: 1.673, Test accuracy: 84.81
Round   8, Train loss: 1.731, Test loss: 1.627, Test accuracy: 86.46
Round   9, Train loss: 1.713, Test loss: 1.605, Test accuracy: 87.65
Round  10, Train loss: 1.609, Test loss: 1.595, Test accuracy: 88.25
Round  11, Train loss: 1.622, Test loss: 1.584, Test accuracy: 89.27
Round  12, Train loss: 1.610, Test loss: 1.578, Test accuracy: 89.44
Round  13, Train loss: 1.591, Test loss: 1.573, Test accuracy: 89.73
Round  14, Train loss: 1.558, Test loss: 1.570, Test accuracy: 89.89
Round  15, Train loss: 1.555, Test loss: 1.568, Test accuracy: 89.89
Round  16, Train loss: 1.576, Test loss: 1.563, Test accuracy: 90.50
Round  17, Train loss: 1.543, Test loss: 1.562, Test accuracy: 90.43
Round  18, Train loss: 1.540, Test loss: 1.560, Test accuracy: 90.67
Round  19, Train loss: 1.529, Test loss: 1.557, Test accuracy: 91.06
Round  20, Train loss: 1.522, Test loss: 1.555, Test accuracy: 91.22
Round  21, Train loss: 1.525, Test loss: 1.554, Test accuracy: 91.31
Round  22, Train loss: 1.530, Test loss: 1.553, Test accuracy: 91.26
Round  23, Train loss: 1.521, Test loss: 1.551, Test accuracy: 91.56
Round  24, Train loss: 1.528, Test loss: 1.549, Test accuracy: 91.73
Round  25, Train loss: 1.532, Test loss: 1.548, Test accuracy: 91.77
Round  26, Train loss: 1.524, Test loss: 1.545, Test accuracy: 92.12
Round  27, Train loss: 1.512, Test loss: 1.544, Test accuracy: 92.06
Round  28, Train loss: 1.507, Test loss: 1.544, Test accuracy: 92.11
Round  29, Train loss: 1.516, Test loss: 1.544, Test accuracy: 92.14
Round  30, Train loss: 1.507, Test loss: 1.542, Test accuracy: 92.32
Round  31, Train loss: 1.521, Test loss: 1.541, Test accuracy: 92.38
Round  32, Train loss: 1.513, Test loss: 1.541, Test accuracy: 92.41
Round  33, Train loss: 1.502, Test loss: 1.539, Test accuracy: 92.65
Round  34, Train loss: 1.508, Test loss: 1.537, Test accuracy: 92.70
Round  35, Train loss: 1.509, Test loss: 1.538, Test accuracy: 92.66
Round  36, Train loss: 1.503, Test loss: 1.537, Test accuracy: 92.75
Round  37, Train loss: 1.497, Test loss: 1.536, Test accuracy: 92.86
Round  38, Train loss: 1.500, Test loss: 1.535, Test accuracy: 92.96
Round  39, Train loss: 1.505, Test loss: 1.535, Test accuracy: 92.98
Round  40, Train loss: 1.497, Test loss: 1.534, Test accuracy: 93.12
Round  41, Train loss: 1.502, Test loss: 1.534, Test accuracy: 92.96
Round  42, Train loss: 1.497, Test loss: 1.533, Test accuracy: 93.06
Round  43, Train loss: 1.497, Test loss: 1.534, Test accuracy: 93.00
Round  44, Train loss: 1.500, Test loss: 1.533, Test accuracy: 93.22
Round  45, Train loss: 1.500, Test loss: 1.532, Test accuracy: 93.19
Round  46, Train loss: 1.499, Test loss: 1.532, Test accuracy: 93.19
Round  47, Train loss: 1.498, Test loss: 1.531, Test accuracy: 93.35
Round  48, Train loss: 1.493, Test loss: 1.531, Test accuracy: 93.28
Round  49, Train loss: 1.495, Test loss: 1.531, Test accuracy: 93.33
Round  50, Train loss: 1.494, Test loss: 1.531, Test accuracy: 93.15
Round  51, Train loss: 1.494, Test loss: 1.531, Test accuracy: 93.25
Round  52, Train loss: 1.503, Test loss: 1.529, Test accuracy: 93.43
Round  53, Train loss: 1.491, Test loss: 1.529, Test accuracy: 93.43
Round  54, Train loss: 1.495, Test loss: 1.529, Test accuracy: 93.42
Round  55, Train loss: 1.494, Test loss: 1.529, Test accuracy: 93.47
Round  56, Train loss: 1.493, Test loss: 1.528, Test accuracy: 93.47
Round  57, Train loss: 1.489, Test loss: 1.528, Test accuracy: 93.41
Round  58, Train loss: 1.491, Test loss: 1.527, Test accuracy: 93.59
Round  59, Train loss: 1.495, Test loss: 1.527, Test accuracy: 93.59
Round  60, Train loss: 1.488, Test loss: 1.527, Test accuracy: 93.59
Round  61, Train loss: 1.493, Test loss: 1.525, Test accuracy: 93.73
Round  62, Train loss: 1.489, Test loss: 1.526, Test accuracy: 93.77
Round  63, Train loss: 1.486, Test loss: 1.526, Test accuracy: 93.65
Round  64, Train loss: 1.491, Test loss: 1.526, Test accuracy: 93.69
Round  65, Train loss: 1.490, Test loss: 1.525, Test accuracy: 93.72
Round  66, Train loss: 1.489, Test loss: 1.525, Test accuracy: 93.76
Round  67, Train loss: 1.490, Test loss: 1.526, Test accuracy: 93.57
Round  68, Train loss: 1.492, Test loss: 1.526, Test accuracy: 93.69
Round  69, Train loss: 1.483, Test loss: 1.524, Test accuracy: 93.84
Round  70, Train loss: 1.486, Test loss: 1.524, Test accuracy: 93.89
Round  71, Train loss: 1.489, Test loss: 1.524, Test accuracy: 93.80
Round  72, Train loss: 1.485, Test loss: 1.524, Test accuracy: 93.98
Round  73, Train loss: 1.485, Test loss: 1.523, Test accuracy: 94.05
Round  74, Train loss: 1.486, Test loss: 1.523, Test accuracy: 93.94
Round  75, Train loss: 1.487, Test loss: 1.523, Test accuracy: 94.06
Round  76, Train loss: 1.489, Test loss: 1.523, Test accuracy: 94.17
Round  77, Train loss: 1.486, Test loss: 1.523, Test accuracy: 94.14
Round  78, Train loss: 1.489, Test loss: 1.523, Test accuracy: 94.00
Round  79, Train loss: 1.485, Test loss: 1.522, Test accuracy: 94.08
Round  80, Train loss: 1.487, Test loss: 1.522, Test accuracy: 94.20
Round  81, Train loss: 1.483, Test loss: 1.522, Test accuracy: 94.14
Round  82, Train loss: 1.484, Test loss: 1.522, Test accuracy: 94.19
Round  83, Train loss: 1.484, Test loss: 1.522, Test accuracy: 94.23
Round  84, Train loss: 1.487, Test loss: 1.522, Test accuracy: 94.09
Round  85, Train loss: 1.484, Test loss: 1.522, Test accuracy: 94.20
Round  86, Train loss: 1.482, Test loss: 1.522, Test accuracy: 94.22
Round  87, Train loss: 1.483, Test loss: 1.521, Test accuracy: 94.14
Round  88, Train loss: 1.484, Test loss: 1.521, Test accuracy: 94.19
Round  89, Train loss: 1.482, Test loss: 1.522, Test accuracy: 94.05
Round  90, Train loss: 1.484, Test loss: 1.522, Test accuracy: 94.08
Round  91, Train loss: 1.483, Test loss: 1.521, Test accuracy: 94.18
Round  92, Train loss: 1.485, Test loss: 1.521, Test accuracy: 94.27
Round  93, Train loss: 1.484, Test loss: 1.521, Test accuracy: 94.22
Round  94, Train loss: 1.485, Test loss: 1.520, Test accuracy: 94.39
Round  95, Train loss: 1.485, Test loss: 1.521, Test accuracy: 94.23
Round  96, Train loss: 1.484, Test loss: 1.520, Test accuracy: 94.20
Round  97, Train loss: 1.484, Test loss: 1.520, Test accuracy: 94.27
Round  98, Train loss: 1.482, Test loss: 1.520, Test accuracy: 94.39
Round  99, Train loss: 1.482, Test loss: 1.520, Test accuracy: 94.31
Final Round, Train loss: 1.483, Test loss: 1.520, Test accuracy: 94.39
Average accuracy final 10 rounds: 94.25450000000001
1433.9868705272675
[2.068789482116699, 4.019841909408569, 5.97381067276001, 7.927319288253784, 9.876099586486816, 11.827801704406738, 13.775655031204224, 15.725549936294556, 17.673921585083008, 19.390614986419678, 21.101468086242676, 22.827720880508423, 24.552162170410156, 26.277028799057007, 28.005404472351074, 29.732266664505005, 31.453351497650146, 33.183425426483154, 34.924100160598755, 36.66384482383728, 38.38779616355896, 40.11712694168091, 41.83455467224121, 43.55620503425598, 45.28606724739075, 47.01503109931946, 48.73240780830383, 50.45599150657654, 52.182512521743774, 53.90765380859375, 55.62560749053955, 57.344377279281616, 59.06431007385254, 60.774834871292114, 62.48405480384827, 64.20334434509277, 65.91693711280823, 67.62761068344116, 69.33907651901245, 71.04998207092285, 72.77268695831299, 74.5030128955841, 76.21725392341614, 77.93167424201965, 79.64373302459717, 81.35641860961914, 83.07767748832703, 84.83194375038147, 86.5503797531128, 88.26285457611084, 89.9699158668518, 91.6798038482666, 93.38976263999939, 95.10996627807617, 96.83685779571533, 98.55794930458069, 100.27474403381348, 101.9906656742096, 103.70639181137085, 105.4237220287323, 107.13369107246399, 108.84523367881775, 110.56503438949585, 112.27647662162781, 114.00311279296875, 115.71866941452026, 117.43341493606567, 119.1550440788269, 120.87834882736206, 122.60206460952759, 124.31700730323792, 126.03584384918213, 127.7546226978302, 129.484388589859, 131.2043330669403, 132.93753027915955, 134.6549928188324, 136.40720558166504, 138.14803099632263, 139.8693060874939, 141.62443447113037, 143.3727159500122, 145.0942084789276, 146.8724844455719, 148.6519296169281, 150.38304471969604, 152.11032557487488, 153.86415195465088, 155.58883023262024, 157.32487034797668, 159.04787063598633, 160.78904342651367, 162.52872943878174, 164.25021266937256, 165.9676969051361, 167.6854259967804, 169.46984767913818, 171.20154404640198, 172.9158320426941, 174.64089155197144, 176.38167524337769]/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[22.755, 30.495, 30.33, 31.015, 45.885, 56.565, 73.18, 84.805, 86.46, 87.65, 88.245, 89.265, 89.44, 89.735, 89.895, 89.895, 90.5, 90.43, 90.67, 91.055, 91.215, 91.315, 91.26, 91.555, 91.735, 91.765, 92.12, 92.065, 92.11, 92.145, 92.32, 92.38, 92.405, 92.65, 92.7, 92.655, 92.755, 92.855, 92.96, 92.985, 93.12, 92.96, 93.06, 93.005, 93.225, 93.19, 93.195, 93.35, 93.275, 93.335, 93.15, 93.255, 93.43, 93.43, 93.415, 93.465, 93.465, 93.41, 93.59, 93.59, 93.595, 93.73, 93.765, 93.65, 93.69, 93.725, 93.76, 93.57, 93.69, 93.84, 93.885, 93.8, 93.98, 94.05, 93.945, 94.06, 94.175, 94.145, 93.995, 94.075, 94.2, 94.135, 94.185, 94.23, 94.095, 94.2, 94.215, 94.135, 94.185, 94.045, 94.08, 94.18, 94.27, 94.225, 94.39, 94.235, 94.2, 94.265, 94.385, 94.315, 94.385]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.660, Test loss: 2.258, Test accuracy: 50.55
Round   1, Train loss: 1.354, Test loss: 1.978, Test accuracy: 70.43
Round   2, Train loss: 1.253, Test loss: 1.863, Test accuracy: 76.28
Round   3, Train loss: 1.226, Test loss: 1.836, Test accuracy: 77.61
Round   4, Train loss: 1.220, Test loss: 1.818, Test accuracy: 78.94
Round   5, Train loss: 1.219, Test loss: 1.811, Test accuracy: 79.77
Round   6, Train loss: 1.212, Test loss: 1.808, Test accuracy: 79.81
Round   7, Train loss: 1.204, Test loss: 1.804, Test accuracy: 79.77
Round   8, Train loss: 1.200, Test loss: 1.799, Test accuracy: 80.17
Round   9, Train loss: 1.197, Test loss: 1.796, Test accuracy: 80.13
Round  10, Train loss: 1.192, Test loss: 1.796, Test accuracy: 79.94
Round  11, Train loss: 1.200, Test loss: 1.795, Test accuracy: 79.97
Round  12, Train loss: 1.197, Test loss: 1.794, Test accuracy: 79.97
Round  13, Train loss: 1.194, Test loss: 1.795, Test accuracy: 79.64
Round  14, Train loss: 1.193, Test loss: 1.796, Test accuracy: 79.42
Round  15, Train loss: 1.193, Test loss: 1.796, Test accuracy: 79.28
Round  16, Train loss: 1.191, Test loss: 1.795, Test accuracy: 79.28
Round  17, Train loss: 1.191, Test loss: 1.794, Test accuracy: 79.18
Round  18, Train loss: 1.188, Test loss: 1.796, Test accuracy: 78.90
Round  19, Train loss: 1.187, Test loss: 1.796, Test accuracy: 78.81
Round  20, Train loss: 1.188, Test loss: 1.796, Test accuracy: 78.80
Round  21, Train loss: 1.189, Test loss: 1.797, Test accuracy: 78.58
Round  22, Train loss: 1.186, Test loss: 1.797, Test accuracy: 78.33
Round  23, Train loss: 1.188, Test loss: 1.797, Test accuracy: 78.34
Round  24, Train loss: 1.186, Test loss: 1.797, Test accuracy: 78.20
Round  25, Train loss: 1.187, Test loss: 1.800, Test accuracy: 78.02
Round  26, Train loss: 1.185, Test loss: 1.800, Test accuracy: 77.77
Round  27, Train loss: 1.186, Test loss: 1.802, Test accuracy: 77.39
Round  28, Train loss: 1.185, Test loss: 1.803, Test accuracy: 77.39
Round  29, Train loss: 1.183, Test loss: 1.804, Test accuracy: 77.06
Round  30, Train loss: 1.184, Test loss: 1.805, Test accuracy: 76.95
Round  31, Train loss: 1.184, Test loss: 1.806, Test accuracy: 76.94
Round  32, Train loss: 1.183, Test loss: 1.806, Test accuracy: 76.70
Round  33, Train loss: 1.183, Test loss: 1.808, Test accuracy: 76.46
Round  34, Train loss: 1.182, Test loss: 1.808, Test accuracy: 76.25
Round  35, Train loss: 1.182, Test loss: 1.808, Test accuracy: 76.15
Round  36, Train loss: 1.182, Test loss: 1.809, Test accuracy: 76.08
Round  37, Train loss: 1.180, Test loss: 1.809, Test accuracy: 76.01
Round  38, Train loss: 1.181, Test loss: 1.810, Test accuracy: 75.85
Round  39, Train loss: 1.182, Test loss: 1.811, Test accuracy: 75.85
Round  40, Train loss: 1.182, Test loss: 1.812, Test accuracy: 75.59
Round  41, Train loss: 1.181, Test loss: 1.813, Test accuracy: 75.44
Round  42, Train loss: 1.179, Test loss: 1.813, Test accuracy: 75.35
Round  43, Train loss: 1.180, Test loss: 1.813, Test accuracy: 75.25
Round  44, Train loss: 1.183, Test loss: 1.814, Test accuracy: 75.13
Round  45, Train loss: 1.183, Test loss: 1.815, Test accuracy: 75.03
Round  46, Train loss: 1.180, Test loss: 1.815, Test accuracy: 74.92
Round  47, Train loss: 1.179, Test loss: 1.817, Test accuracy: 74.72
Round  48, Train loss: 1.180, Test loss: 1.817, Test accuracy: 74.73
Round  49, Train loss: 1.179, Test loss: 1.818, Test accuracy: 74.64
Round  50, Train loss: 1.180, Test loss: 1.818, Test accuracy: 74.52
Round  51, Train loss: 1.180, Test loss: 1.818, Test accuracy: 74.44
Round  52, Train loss: 1.181, Test loss: 1.819, Test accuracy: 74.26
Round  53, Train loss: 1.182, Test loss: 1.820, Test accuracy: 74.25
Round  54, Train loss: 1.180, Test loss: 1.821, Test accuracy: 74.09
Round  55, Train loss: 1.179, Test loss: 1.822, Test accuracy: 73.92
Round  56, Train loss: 1.181, Test loss: 1.822, Test accuracy: 73.98
Round  57, Train loss: 1.181, Test loss: 1.823, Test accuracy: 73.84
Round  58, Train loss: 1.179, Test loss: 1.824, Test accuracy: 73.75
Round  59, Train loss: 1.179, Test loss: 1.825, Test accuracy: 73.60
Round  60, Train loss: 1.180, Test loss: 1.826, Test accuracy: 73.49
Round  61, Train loss: 1.178, Test loss: 1.827, Test accuracy: 73.25
Round  62, Train loss: 1.178, Test loss: 1.828, Test accuracy: 73.17
Round  63, Train loss: 1.178, Test loss: 1.828, Test accuracy: 73.12
Round  64, Train loss: 1.179, Test loss: 1.829, Test accuracy: 73.10
Round  65, Train loss: 1.178, Test loss: 1.829, Test accuracy: 73.12
Round  66, Train loss: 1.180, Test loss: 1.829, Test accuracy: 72.94
Round  67, Train loss: 1.177, Test loss: 1.830, Test accuracy: 72.94
Round  68, Train loss: 1.176, Test loss: 1.830, Test accuracy: 72.81
Round  69, Train loss: 1.178, Test loss: 1.831, Test accuracy: 72.80
Round  70, Train loss: 1.179, Test loss: 1.831, Test accuracy: 72.73
Round  71, Train loss: 1.178, Test loss: 1.832, Test accuracy: 72.62
Round  72, Train loss: 1.178, Test loss: 1.832, Test accuracy: 72.72
Round  73, Train loss: 1.177, Test loss: 1.833, Test accuracy: 72.60
Round  74, Train loss: 1.175, Test loss: 1.832, Test accuracy: 72.64
Round  75, Train loss: 1.178, Test loss: 1.833, Test accuracy: 72.47
Round  76, Train loss: 1.178, Test loss: 1.833, Test accuracy: 72.54
Round  77, Train loss: 1.179, Test loss: 1.834, Test accuracy: 72.47
Round  78, Train loss: 1.179, Test loss: 1.834, Test accuracy: 72.44
Round  79, Train loss: 1.178, Test loss: 1.834, Test accuracy: 72.43
Round  80, Train loss: 1.178, Test loss: 1.834, Test accuracy: 72.43
Round  81, Train loss: 1.176, Test loss: 1.835, Test accuracy: 72.38
Round  82, Train loss: 1.176, Test loss: 1.836, Test accuracy: 72.28
Round  83, Train loss: 1.178, Test loss: 1.837, Test accuracy: 72.24
Round  84, Train loss: 1.178, Test loss: 1.838, Test accuracy: 72.19
Round  85, Train loss: 1.178, Test loss: 1.839, Test accuracy: 72.06
Round  86, Train loss: 1.177, Test loss: 1.840, Test accuracy: 71.98
Round  87, Train loss: 1.177, Test loss: 1.840, Test accuracy: 71.92
Round  88, Train loss: 1.177, Test loss: 1.841, Test accuracy: 71.69
Round  89, Train loss: 1.177, Test loss: 1.841, Test accuracy: 71.64
Round  90, Train loss: 1.177, Test loss: 1.842, Test accuracy: 71.58
Round  91, Train loss: 1.175, Test loss: 1.842, Test accuracy: 71.53
Round  92, Train loss: 1.176, Test loss: 1.843, Test accuracy: 71.53
Round  93, Train loss: 1.177, Test loss: 1.844, Test accuracy: 71.45
Round  94, Train loss: 1.177, Test loss: 1.845, Test accuracy: 71.33
Round  95, Train loss: 1.177, Test loss: 1.845, Test accuracy: 71.27
Round  96, Train loss: 1.177, Test loss: 1.845, Test accuracy: 71.24
Round  97, Train loss: 1.175, Test loss: 1.846, Test accuracy: 71.30
Round  98, Train loss: 1.176, Test loss: 1.846, Test accuracy: 71.22
Round  99, Train loss: 1.176, Test loss: 1.846, Test accuracy: 71.16
Final Round, Train loss: 1.177, Test loss: 1.848, Test accuracy: 71.19
Average accuracy final 10 rounds: 71.36
2169.2060339450836
[]
[50.545, 70.43, 76.28, 77.61, 78.94, 79.77, 79.805, 79.765, 80.17, 80.13, 79.945, 79.97, 79.975, 79.645, 79.42, 79.285, 79.28, 79.18, 78.9, 78.805, 78.8, 78.585, 78.325, 78.345, 78.2, 78.02, 77.765, 77.395, 77.395, 77.06, 76.955, 76.94, 76.705, 76.46, 76.255, 76.15, 76.085, 76.01, 75.85, 75.85, 75.595, 75.435, 75.35, 75.25, 75.13, 75.035, 74.92, 74.72, 74.73, 74.64, 74.515, 74.44, 74.26, 74.255, 74.09, 73.92, 73.985, 73.84, 73.755, 73.6, 73.49, 73.255, 73.17, 73.125, 73.1, 73.12, 72.94, 72.935, 72.81, 72.795, 72.735, 72.625, 72.725, 72.6, 72.635, 72.47, 72.54, 72.465, 72.435, 72.43, 72.43, 72.38, 72.275, 72.24, 72.195, 72.06, 71.985, 71.915, 71.69, 71.64, 71.575, 71.53, 71.525, 71.45, 71.335, 71.265, 71.24, 71.295, 71.225, 71.16, 71.19]/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.298, Test loss: 2.299, Test accuracy: 18.05
Round   0: Global train loss: 2.298, Global test loss: 2.302, Global test accuracy: 11.78
Round   1, Train loss: 2.287, Test loss: 2.290, Test accuracy: 17.63
Round   1: Global train loss: 2.287, Global test loss: 2.301, Global test accuracy: 13.57
Round   2, Train loss: 2.251, Test loss: 2.268, Test accuracy: 25.57
Round   2: Global train loss: 2.251, Global test loss: 2.299, Global test accuracy: 21.34
Round   3, Train loss: 2.158, Test loss: 2.230, Test accuracy: 32.04
Round   3: Global train loss: 2.158, Global test loss: 2.296, Global test accuracy: 31.26
Round   4, Train loss: 2.174, Test loss: 2.224, Test accuracy: 35.37
Round   4: Global train loss: 2.174, Global test loss: 2.294, Global test accuracy: 34.56
Round   5, Train loss: 1.874, Test loss: 2.156, Test accuracy: 40.95
Round   5: Global train loss: 1.874, Global test loss: 2.287, Global test accuracy: 42.60
Round   6, Train loss: 2.288, Test loss: 2.181, Test accuracy: 34.66
Round   6: Global train loss: 2.288, Global test loss: 2.286, Global test accuracy: 35.43
Round   7, Train loss: 2.130, Test loss: 2.183, Test accuracy: 31.46
Round   7: Global train loss: 2.130, Global test loss: 2.285, Global test accuracy: 31.92
Round   8, Train loss: 1.614, Test loss: 2.131, Test accuracy: 35.88
Round   8: Global train loss: 1.614, Global test loss: 2.273, Global test accuracy: 34.98
Round   9, Train loss: 2.039, Test loss: 2.105, Test accuracy: 36.97
Round   9: Global train loss: 2.039, Global test loss: 2.265, Global test accuracy: 31.92
Round  10, Train loss: 1.746, Test loss: 2.046, Test accuracy: 44.35
Round  10: Global train loss: 1.746, Global test loss: 2.253, Global test accuracy: 38.45
Round  11, Train loss: 1.170, Test loss: 1.924, Test accuracy: 56.44
Round  11: Global train loss: 1.170, Global test loss: 2.223, Global test accuracy: 52.49
Round  12, Train loss: 1.891, Test loss: 1.945, Test accuracy: 52.97
Round  12: Global train loss: 1.891, Global test loss: 2.212, Global test accuracy: 53.02
Round  13, Train loss: 1.314, Test loss: 1.948, Test accuracy: 52.19
Round  13: Global train loss: 1.314, Global test loss: 2.198, Global test accuracy: 55.35
Round  14, Train loss: 1.842, Test loss: 1.992, Test accuracy: 46.81
Round  14: Global train loss: 1.842, Global test loss: 2.204, Global test accuracy: 48.12
Round  15, Train loss: 1.790, Test loss: 1.964, Test accuracy: 48.66
Round  15: Global train loss: 1.790, Global test loss: 2.201, Global test accuracy: 47.38
Round  16, Train loss: 1.637, Test loss: 2.002, Test accuracy: 44.88
Round  16: Global train loss: 1.637, Global test loss: 2.205, Global test accuracy: 41.81
Round  17, Train loss: 0.880, Test loss: 1.991, Test accuracy: 45.83
Round  17: Global train loss: 0.880, Global test loss: 2.202, Global test accuracy: 41.70
Round  18, Train loss: 0.936, Test loss: 1.938, Test accuracy: 51.47
Round  18: Global train loss: 0.936, Global test loss: 2.195, Global test accuracy: 43.13
Round  19, Train loss: 0.400, Test loss: 1.880, Test accuracy: 57.53
Round  19: Global train loss: 0.400, Global test loss: 2.178, Global test accuracy: 45.83
Round  20, Train loss: 1.337, Test loss: 1.938, Test accuracy: 52.14
Round  20: Global train loss: 1.337, Global test loss: 2.184, Global test accuracy: 44.12
Round  21, Train loss: 0.919, Test loss: 1.941, Test accuracy: 51.95
Round  21: Global train loss: 0.919, Global test loss: 2.178, Global test accuracy: 45.09
Round  22, Train loss: 0.160, Test loss: 1.889, Test accuracy: 57.58
Round  22: Global train loss: 0.160, Global test loss: 2.156, Global test accuracy: 48.67
Round  23, Train loss: 0.130, Test loss: 1.841, Test accuracy: 61.48
Round  23: Global train loss: 0.130, Global test loss: 2.125, Global test accuracy: 51.55
Round  24, Train loss: 0.181, Test loss: 1.801, Test accuracy: 66.03
Round  24: Global train loss: 0.181, Global test loss: 2.090, Global test accuracy: 53.66
Round  25, Train loss: 0.708, Test loss: 1.812, Test accuracy: 65.76
Round  25: Global train loss: 0.708, Global test loss: 2.070, Global test accuracy: 54.70
Round  26, Train loss: 0.600, Test loss: 1.820, Test accuracy: 66.25
Round  26: Global train loss: 0.600, Global test loss: 2.052, Global test accuracy: 54.48
Round  27, Train loss: 0.127, Test loss: 1.786, Test accuracy: 69.33
Round  27: Global train loss: 0.127, Global test loss: 2.027, Global test accuracy: 55.87
Round  28, Train loss: 0.214, Test loss: 1.755, Test accuracy: 72.37
Round  28: Global train loss: 0.214, Global test loss: 1.998, Global test accuracy: 58.26
Round  29, Train loss: 0.507, Test loss: 1.758, Test accuracy: 72.08
Round  29: Global train loss: 0.507, Global test loss: 1.991, Global test accuracy: 57.41
Round  30, Train loss: -0.281, Test loss: 1.717, Test accuracy: 75.93
Round  30: Global train loss: -0.281, Global test loss: 1.957, Global test accuracy: 59.20
Round  31, Train loss: 0.019, Test loss: 1.706, Test accuracy: 77.00
Round  31: Global train loss: 0.019, Global test loss: 1.942, Global test accuracy: 60.69
Round  32, Train loss: 0.026, Test loss: 1.715, Test accuracy: 76.06
Round  32: Global train loss: 0.026, Global test loss: 1.926, Global test accuracy: 62.37
Round  33, Train loss: -0.019, Test loss: 1.696, Test accuracy: 77.64
Round  33: Global train loss: -0.019, Global test loss: 1.908, Global test accuracy: 64.90
Round  34, Train loss: 0.289, Test loss: 1.715, Test accuracy: 75.99
Round  34: Global train loss: 0.289, Global test loss: 1.903, Global test accuracy: 65.40
Round  35, Train loss: -0.674, Test loss: 1.712, Test accuracy: 76.23
Round  35: Global train loss: -0.674, Global test loss: 1.894, Global test accuracy: 65.83
Round  36, Train loss: 0.038, Test loss: 1.677, Test accuracy: 79.42
Round  36: Global train loss: 0.038, Global test loss: 1.868, Global test accuracy: 68.58
Round  37, Train loss: -1.043, Test loss: 1.657, Test accuracy: 81.03
Round  37: Global train loss: -1.043, Global test loss: 1.829, Global test accuracy: 72.69
Round  38, Train loss: -0.781, Test loss: 1.652, Test accuracy: 81.83
Round  38: Global train loss: -0.781, Global test loss: 1.790, Global test accuracy: 76.61
Round  39, Train loss: 0.050, Test loss: 1.650, Test accuracy: 81.97
Round  39: Global train loss: 0.050, Global test loss: 1.771, Global test accuracy: 78.00
Round  40, Train loss: -0.299, Test loss: 1.647, Test accuracy: 82.19
Round  40: Global train loss: -0.299, Global test loss: 1.760, Global test accuracy: 78.73
Round  41, Train loss: -0.457, Test loss: 1.623, Test accuracy: 84.30
Round  41: Global train loss: -0.457, Global test loss: 1.729, Global test accuracy: 81.83
Round  42, Train loss: 0.227, Test loss: 1.625, Test accuracy: 84.32
Round  42: Global train loss: 0.227, Global test loss: 1.716, Global test accuracy: 83.25
Round  43, Train loss: -0.753, Test loss: 1.623, Test accuracy: 84.38
Round  43: Global train loss: -0.753, Global test loss: 1.689, Global test accuracy: 84.68
Round  44, Train loss: -0.466, Test loss: 1.612, Test accuracy: 85.45
Round  44: Global train loss: -0.466, Global test loss: 1.665, Global test accuracy: 85.88
Round  45, Train loss: -0.200, Test loss: 1.615, Test accuracy: 85.19
Round  45: Global train loss: -0.200, Global test loss: 1.661, Global test accuracy: 86.75
Round  46, Train loss: -0.530, Test loss: 1.613, Test accuracy: 85.36
Round  46: Global train loss: -0.530, Global test loss: 1.647, Global test accuracy: 87.59
Round  47, Train loss: -0.021, Test loss: 1.616, Test accuracy: 85.10
Round  47: Global train loss: -0.021, Global test loss: 1.652, Global test accuracy: 87.48
Round  48, Train loss: -0.327, Test loss: 1.612, Test accuracy: 85.38
Round  48: Global train loss: -0.327, Global test loss: 1.639, Global test accuracy: 87.97
Round  49, Train loss: -0.204, Test loss: 1.611, Test accuracy: 85.44
Round  49: Global train loss: -0.204, Global test loss: 1.632, Global test accuracy: 88.41
Round  50, Train loss: 0.112, Test loss: 1.613, Test accuracy: 85.32
Round  50: Global train loss: 0.112, Global test loss: 1.633, Global test accuracy: 88.35
Round  51, Train loss: 0.014, Test loss: 1.608, Test accuracy: 85.75
Round  51: Global train loss: 0.014, Global test loss: 1.629, Global test accuracy: 88.59
Round  52, Train loss: -0.328, Test loss: 1.608, Test accuracy: 85.75
Round  52: Global train loss: -0.328, Global test loss: 1.621, Global test accuracy: 88.92
Round  53, Train loss: 0.281, Test loss: 1.607, Test accuracy: 85.72
Round  53: Global train loss: 0.281, Global test loss: 1.618, Global test accuracy: 89.17
Round  54, Train loss: -0.031, Test loss: 1.604, Test accuracy: 86.16
Round  54: Global train loss: -0.031, Global test loss: 1.612, Global test accuracy: 89.37
Round  55, Train loss: -0.066, Test loss: 1.602, Test accuracy: 86.28
Round  55: Global train loss: -0.066, Global test loss: 1.614, Global test accuracy: 89.13
Round  56, Train loss: -0.114, Test loss: 1.602, Test accuracy: 86.12
Round  56: Global train loss: -0.114, Global test loss: 1.613, Global test accuracy: 89.06
Round  57, Train loss: -0.051, Test loss: 1.600, Test accuracy: 86.38
Round  57: Global train loss: -0.051, Global test loss: 1.606, Global test accuracy: 89.34
Round  58, Train loss: -0.087, Test loss: 1.600, Test accuracy: 86.42
Round  58: Global train loss: -0.087, Global test loss: 1.601, Global test accuracy: 89.48
Round  59, Train loss: 0.047, Test loss: 1.596, Test accuracy: 86.80
Round  59: Global train loss: 0.047, Global test loss: 1.597, Global test accuracy: 89.60
Round  60, Train loss: -0.179, Test loss: 1.598, Test accuracy: 86.56
Round  60: Global train loss: -0.179, Global test loss: 1.594, Global test accuracy: 89.72
Round  61, Train loss: -0.335, Test loss: 1.595, Test accuracy: 86.85
Round  61: Global train loss: -0.335, Global test loss: 1.592, Global test accuracy: 89.80
Round  62, Train loss: -0.040, Test loss: 1.600, Test accuracy: 86.39
Round  62: Global train loss: -0.040, Global test loss: 1.591, Global test accuracy: 89.89
Round  63, Train loss: -0.131, Test loss: 1.595, Test accuracy: 86.88
Round  63: Global train loss: -0.131, Global test loss: 1.587, Global test accuracy: 89.97
Round  64, Train loss: -0.065, Test loss: 1.591, Test accuracy: 87.26
Round  64: Global train loss: -0.065, Global test loss: 1.586, Global test accuracy: 90.03
Round  65, Train loss: -0.540, Test loss: 1.591, Test accuracy: 87.26
Round  65: Global train loss: -0.540, Global test loss: 1.583, Global test accuracy: 90.11
Round  66, Train loss: -0.157, Test loss: 1.593, Test accuracy: 87.16
Round  66: Global train loss: -0.157, Global test loss: 1.582, Global test accuracy: 90.22
Round  67, Train loss: -0.142, Test loss: 1.594, Test accuracy: 86.95
Round  67: Global train loss: -0.142, Global test loss: 1.579, Global test accuracy: 90.24
Round  68, Train loss: -0.013, Test loss: 1.593, Test accuracy: 86.99
Round  68: Global train loss: -0.013, Global test loss: 1.577, Global test accuracy: 90.39
Round  69, Train loss: -0.201, Test loss: 1.588, Test accuracy: 87.63
Round  69: Global train loss: -0.201, Global test loss: 1.574, Global test accuracy: 90.56
Round  70, Train loss: -0.059, Test loss: 1.586, Test accuracy: 87.86
Round  70: Global train loss: -0.059, Global test loss: 1.572, Global test accuracy: 90.44
Round  71, Train loss: 0.112, Test loss: 1.587, Test accuracy: 87.73
Round  71: Global train loss: 0.112, Global test loss: 1.571, Global test accuracy: 90.44
Round  72, Train loss: 0.329, Test loss: 1.596, Test accuracy: 86.81
Round  72: Global train loss: 0.329, Global test loss: 1.572, Global test accuracy: 90.52
Round  73, Train loss: 0.270, Test loss: 1.593, Test accuracy: 87.17
Round  73: Global train loss: 0.270, Global test loss: 1.571, Global test accuracy: 90.53
Round  74, Train loss: 0.166, Test loss: 1.595, Test accuracy: 86.95
Round  74: Global train loss: 0.166, Global test loss: 1.570, Global test accuracy: 90.61
Round  75, Train loss: -0.018, Test loss: 1.592, Test accuracy: 87.27
Round  75: Global train loss: -0.018, Global test loss: 1.569, Global test accuracy: 90.62
Round  76, Train loss: 0.282, Test loss: 1.594, Test accuracy: 87.12
Round  76: Global train loss: 0.282, Global test loss: 1.569, Global test accuracy: 90.67
Round  77, Train loss: 0.117, Test loss: 1.597, Test accuracy: 86.64
Round  77: Global train loss: 0.117, Global test loss: 1.569, Global test accuracy: 90.56
Round  78, Train loss: 0.039, Test loss: 1.596, Test accuracy: 86.64
Round  78: Global train loss: 0.039, Global test loss: 1.568, Global test accuracy: 90.67
Round  79, Train loss: 0.074, Test loss: 1.594, Test accuracy: 86.83
Round  79: Global train loss: 0.074, Global test loss: 1.567, Global test accuracy: 90.70
Round  80, Train loss: 0.223, Test loss: 1.593, Test accuracy: 86.88
Round  80: Global train loss: 0.223, Global test loss: 1.566, Global test accuracy: 90.81
Round  81, Train loss: 0.149, Test loss: 1.593, Test accuracy: 87.02
Round  81: Global train loss: 0.149, Global test loss: 1.566, Global test accuracy: 90.86
Round  82, Train loss: 0.033, Test loss: 1.591, Test accuracy: 87.25
Round  82: Global train loss: 0.033, Global test loss: 1.564, Global test accuracy: 90.95
Round  83, Train loss: 0.052, Test loss: 1.594, Test accuracy: 86.83
Round  83: Global train loss: 0.052, Global test loss: 1.564, Global test accuracy: 90.91
Round  84, Train loss: 0.382, Test loss: 1.596, Test accuracy: 86.79
Round  84: Global train loss: 0.382, Global test loss: 1.564, Global test accuracy: 90.92
Round  85, Train loss: 0.129, Test loss: 1.594, Test accuracy: 86.92
Round  85: Global train loss: 0.129, Global test loss: 1.564, Global test accuracy: 91.06
Round  86, Train loss: 0.050, Test loss: 1.590, Test accuracy: 87.27
Round  86: Global train loss: 0.050, Global test loss: 1.563, Global test accuracy: 90.97
Round  87, Train loss: 0.024, Test loss: 1.588, Test accuracy: 87.50
Round  87: Global train loss: 0.024, Global test loss: 1.562, Global test accuracy: 91.11
Round  88, Train loss: 0.308, Test loss: 1.588, Test accuracy: 87.58
Round  88: Global train loss: 0.308, Global test loss: 1.561, Global test accuracy: 91.17
Round  89, Train loss: 0.047, Test loss: 1.587, Test accuracy: 87.53
Round  89: Global train loss: 0.047, Global test loss: 1.560, Global test accuracy: 91.19
Round  90, Train loss: 0.113, Test loss: 1.591, Test accuracy: 87.22
Round  90: Global train loss: 0.113, Global test loss: 1.560, Global test accuracy: 91.25
Round  91, Train loss: 0.184, Test loss: 1.585, Test accuracy: 87.89
Round  91: Global train loss: 0.184, Global test loss: 1.559, Global test accuracy: 91.26
Round  92, Train loss: 0.196, Test loss: 1.583, Test accuracy: 88.09
Round  92: Global train loss: 0.196, Global test loss: 1.559, Global test accuracy: 91.40
Round  93, Train loss: 0.129, Test loss: 1.585, Test accuracy: 87.91
Round  93: Global train loss: 0.129, Global test loss: 1.559, Global test accuracy: 91.37
Round  94, Train loss: 0.340, Test loss: 1.588, Test accuracy: 87.65
Round  94: Global train loss: 0.340, Global test loss: 1.558, Global test accuracy: 91.45
Round  95, Train loss: 0.137, Test loss: 1.588, Test accuracy: 87.69
Round  95: Global train loss: 0.137, Global test loss: 1.558, Global test accuracy: 91.41
Round  96, Train loss: -0.130, Test loss: 1.587, Test accuracy: 87.67
Round  96: Global train loss: -0.130, Global test loss: 1.558, Global test accuracy: 91.47
Round  97, Train loss: 0.334, Test loss: 1.587, Test accuracy: 87.81
Round  97: Global train loss: 0.334, Global test loss: 1.557, Global test accuracy: 91.50
Round  98, Train loss: 0.338, Test loss: 1.585, Test accuracy: 87.99
Round  98: Global train loss: 0.338, Global test loss: 1.556, Global test accuracy: 91.52
Round  99, Train loss: 0.281, Test loss: 1.586, Test accuracy: 87.84/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99: Global train loss: 0.281, Global test loss: 1.556, Global test accuracy: 91.53
Final Round: Train loss: 1.521, Test loss: 1.561, Test accuracy: 90.77
Final Round: Global train loss: 1.521, Global test loss: 1.555, Global test accuracy: 91.58
Average accuracy final 10 rounds: 87.777
Average global accuracy final 10 rounds: 91.4175
1911.6143884658813
[]
[18.05, 17.63, 25.565, 32.04, 35.37, 40.955, 34.66, 31.46, 35.885, 36.97, 44.355, 56.435, 52.97, 52.185, 46.815, 48.66, 44.875, 45.83, 51.465, 57.535, 52.14, 51.955, 57.58, 61.475, 66.025, 65.76, 66.255, 69.33, 72.37, 72.08, 75.93, 76.995, 76.065, 77.645, 75.99, 76.235, 79.425, 81.03, 81.825, 81.975, 82.195, 84.3, 84.32, 84.38, 85.45, 85.185, 85.36, 85.1, 85.38, 85.435, 85.32, 85.745, 85.75, 85.725, 86.16, 86.275, 86.125, 86.38, 86.425, 86.795, 86.565, 86.85, 86.385, 86.875, 87.26, 87.26, 87.16, 86.955, 86.99, 87.63, 87.865, 87.735, 86.81, 87.165, 86.95, 87.27, 87.125, 86.64, 86.635, 86.835, 86.88, 87.015, 87.255, 86.825, 86.79, 86.925, 87.265, 87.495, 87.575, 87.535, 87.22, 87.89, 88.09, 87.91, 87.65, 87.695, 87.675, 87.805, 87.99, 87.845, 90.77]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.95 

Round   0, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 7.95 

Round   1, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.07 

Round   1, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.12 

Round   2, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.06 

Round   2, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.18 

Round   3, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.10 

Round   3, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.24 

Round   4, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.16 

Round   4, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.37 

Round   5, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.27 

Round   5, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.46 

Round   6, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.35 

Round   6, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.58 

Round   7, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.43 

Round   7, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.62 

Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.48 

Round   8, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.65 

Round   9, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.54 

Round   9, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.79 

Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.66 

Round  10, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.86 

Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.73 

Round  11, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.90 

Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.77 

Round  12, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.04 

Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.89 

Round  13, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.12 

Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.03 

Round  14, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.19 

Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.09 

Round  15, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.26 

Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.11 

Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.35 

Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.16 

Round  17, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.36 

Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.15 

Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.44 

Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.27 

Round  19, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.48 

Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.36 

Round  20, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.59 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.47 

Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.70 

Round  22, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.54 

Round  22, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.72 

Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.63 

Round  23, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.92 

Round  24, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.69 

Round  24, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.99 

Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.76 

Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.03 

Round  26, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.84 

Round  26, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.12 

Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.91 

Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.25 

Round  28, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.02 

Round  28, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.41 

Round  29, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.09 

Round  29, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.47 

Round  30, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.21 

Round  30, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.54 

Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.27 

Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.62 

Round  32, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.41 

Round  32, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.77 

Round  33, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.46 

Round  33, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.71 

Round  34, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.74 

Round  34, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.90 

Round  35, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.86 

Round  35, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.01 

Round  36, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.90 

Round  36, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.06 

Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.01 

Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.12 

Round  38, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.09 

Round  38, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.24 

Round  39, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.20 

Round  39, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.40 

Round  40, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.38 

Round  40, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.53 

Round  41, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.50 

Round  41, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.63 

Round  42, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.57 

Round  42, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.74 

Round  43, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.62 

Round  43, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.73 

Round  44, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.70 

Round  44, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.80 

Round  45, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.78 

Round  45, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.88 

Round  46, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.88 

Round  46, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.97 

Round  47, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.92 

Round  47, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.11 

Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.01 

Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.17 

Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.21 

Round  49, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.39 

Round  50, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.23 

Round  50, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.42 

Round  51, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.29 

Round  51, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.43 

Round  52, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.36 

Round  52, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.48 

Round  53, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.37 

Round  53, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.48 

Round  54, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.40 

Round  54, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.62 

Round  55, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.48 

Round  55, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.67 

Round  56, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.51 

Round  56, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.78 

Round  57, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.64 

Round  57, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.88 

Round  58, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.71 

Round  58, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.84 

Round  59, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.69 

Round  59, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.03 

Round  60, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.78 

Round  60, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.13 

Round  61, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.95 

Round  61, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.21 

Round  62, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.19 

Round  62, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.49 

Round  63, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.29 

Round  63, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.54 

Round  64, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.35 

Round  64, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.76 

Round  65, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.58 

Round  65, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.93 

Round  66, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.76 

Round  66, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.12 

Round  67, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.95 

Round  67, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.23 

Round  68, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.04 

Round  68, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.30 

Round  69, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.10 

Round  69, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.41 

Round  70, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.14 

Round  70, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.49 

Round  71, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.21 

Round  71, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.62 

Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.36 

Round  72, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.74 

Round  73, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.51 

Round  73, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.80 

Round  74, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.60 

Round  74, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.00 

Round  75, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.72 

Round  75, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.12 

Round  76, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.89 

Round  76, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.23 

Round  77, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.07 

Round  77, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.24 

Round  78, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.12 

Round  78, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.28 

Round  79, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.25 

Round  79, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.42 

Round  80, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.32 

Round  80, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.61 

Round  81, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.46 

Round  81, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.66 

Round  82, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.57 

Round  82, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.79 

Round  83, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.64 

Round  83, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.84 

Round  84, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.76 

Round  84, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.94 

Round  85, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.79 

Round  85, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.96 

Round  86, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.90 

Round  86, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.13 

Round  87, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.02 

Round  87, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.18 

Round  88, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.11 

Round  88, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.23 

Round  89, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.24 

Round  89, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.43 

Round  90, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.36 

Round  90, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.59 

Round  91, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.48 

Round  91, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.77 

Round  92, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.61 

Round  92, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.93 

Round  93, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.68 

Round  93, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.05 

Round  94, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.82 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.18 

Round  95, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.95 

Round  95, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.16 

Round  96, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.14 

Round  96, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.35 

Round  97, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.25 

Round  97, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.45 

Round  98, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.39 

Round  98, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.72 

Round  99, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.55 

Round  99, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.91 

Final Round, Train loss: 2.301, Test loss: 2.301, Test accuracy: 18.05 

Final Round, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.91 

Average accuracy final 10 rounds: 16.9215 

Average global accuracy final 10 rounds: 17.2125 

1180.6298305988312
[0.8516614437103271, 1.647390604019165, 2.4352357387542725, 3.221676826477051, 4.011252164840698, 4.804799795150757, 5.598989009857178, 6.3989269733428955, 7.198671817779541, 7.998497247695923, 8.797456741333008, 9.588688850402832, 10.384903192520142, 11.183043479919434, 11.975271463394165, 12.766305685043335, 13.556141138076782, 14.345995903015137, 15.140065908432007, 15.937657594680786, 16.730400800704956, 17.521623849868774, 18.310605764389038, 19.101528882980347, 19.88901448249817, 20.685169458389282, 21.48088550567627, 22.276604175567627, 23.073853492736816, 23.87224578857422, 24.668315172195435, 25.462846040725708, 26.259875774383545, 27.057243585586548, 27.853323221206665, 28.648847103118896, 29.332654237747192, 30.01840615272522, 30.705936431884766, 31.392842769622803, 32.07887673377991, 32.767329692840576, 33.455708503723145, 34.142815589904785, 34.824825048446655, 35.512046813964844, 36.198604583740234, 36.8858003616333, 37.56862211227417, 38.2545211315155, 38.94803714752197, 39.63392949104309, 40.320515155792236, 41.009416341781616, 41.69480299949646, 42.37982702255249, 43.0650429725647, 43.747628927230835, 44.43229365348816, 45.120012283325195, 45.80186986923218, 46.49978995323181, 47.18739032745361, 47.8817617893219, 48.56764197349548, 49.25139236450195, 49.93762707710266, 50.622241258621216, 51.31167674064636, 51.992459535598755, 52.67285871505737, 53.35690879821777, 54.04419684410095, 54.72892689704895, 55.41596984863281, 56.10374641418457, 56.79446816444397, 57.48115611076355, 58.1674644947052, 58.853517055511475, 59.539313077926636, 60.22460436820984, 60.90916180610657, 61.594202518463135, 62.278024196624756, 62.97182035446167, 63.654653787612915, 64.33897376060486, 65.02119135856628, 65.70652389526367, 66.39215230941772, 67.07697796821594, 67.76231503486633, 68.44459271430969, 69.13089060783386, 69.81480717658997, 70.50137400627136, 71.18585324287415, 71.87008833885193, 72.55508279800415, 73.91920924186707]
[7.945, 8.07, 8.06, 8.095, 8.165, 8.265, 8.345, 8.425, 8.485, 8.545, 8.66, 8.73, 8.77, 8.895, 9.025, 9.09, 9.11, 9.165, 9.155, 9.27, 9.36, 9.475, 9.54, 9.635, 9.69, 9.76, 9.835, 9.91, 10.02, 10.09, 10.215, 10.27, 10.41, 10.46, 10.74, 10.86, 10.905, 11.005, 11.09, 11.2, 11.38, 11.5, 11.575, 11.625, 11.695, 11.78, 11.88, 11.92, 12.005, 12.215, 12.235, 12.295, 12.355, 12.365, 12.405, 12.485, 12.51, 12.64, 12.705, 12.69, 12.78, 12.95, 13.185, 13.295, 13.35, 13.58, 13.755, 13.945, 14.04, 14.1, 14.14, 14.21, 14.355, 14.505, 14.6, 14.72, 14.895, 15.075, 15.115, 15.25, 15.32, 15.46, 15.57, 15.64, 15.755, 15.785, 15.9, 16.02, 16.105, 16.24, 16.355, 16.485, 16.61, 16.68, 16.815, 16.945, 17.135, 17.245, 17.395, 17.55, 18.045]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.296, Test loss: 2.296, Test accuracy: 21.85 

Round   0, Global train loss: 2.296, Global test loss: 2.302, Global test accuracy: 11.42 

Round   1, Train loss: 2.265, Test loss: 2.265, Test accuracy: 30.77 

Round   1, Global train loss: 2.265, Global test loss: 2.297, Global test accuracy: 16.50 

Round   2, Train loss: 2.105, Test loss: 2.144, Test accuracy: 39.58 

Round   2, Global train loss: 2.105, Global test loss: 2.278, Global test accuracy: 20.72 

Round   3, Train loss: 1.933, Test loss: 2.030, Test accuracy: 52.38 

Round   3, Global train loss: 1.933, Global test loss: 2.238, Global test accuracy: 18.63 

Round   4, Train loss: 1.727, Test loss: 1.929, Test accuracy: 62.77 

Round   4, Global train loss: 1.727, Global test loss: 2.177, Global test accuracy: 26.23 

Round   5, Train loss: 1.827, Test loss: 1.866, Test accuracy: 68.80 

Round   5, Global train loss: 1.827, Global test loss: 2.224, Global test accuracy: 23.55 

Round   6, Train loss: 1.756, Test loss: 1.746, Test accuracy: 82.37 

Round   6, Global train loss: 1.756, Global test loss: 2.179, Global test accuracy: 20.93 

Round   7, Train loss: 1.661, Test loss: 1.709, Test accuracy: 83.20 

Round   7, Global train loss: 1.661, Global test loss: 2.175, Global test accuracy: 35.98 

Round   8, Train loss: 1.691, Test loss: 1.653, Test accuracy: 86.48 

Round   8, Global train loss: 1.691, Global test loss: 2.111, Global test accuracy: 41.80 

Round   9, Train loss: 1.545, Test loss: 1.626, Test accuracy: 88.10 

Round   9, Global train loss: 1.545, Global test loss: 2.223, Global test accuracy: 18.70 

Round  10, Train loss: 1.572, Test loss: 1.610, Test accuracy: 88.70 

Round  10, Global train loss: 1.572, Global test loss: 2.168, Global test accuracy: 23.37 

Round  11, Train loss: 1.575, Test loss: 1.590, Test accuracy: 90.17 

Round  11, Global train loss: 1.575, Global test loss: 2.143, Global test accuracy: 34.50 

Round  12, Train loss: 1.591, Test loss: 1.555, Test accuracy: 94.08 

Round  12, Global train loss: 1.591, Global test loss: 2.173, Global test accuracy: 27.07 

Round  13, Train loss: 1.500, Test loss: 1.543, Test accuracy: 94.67 

Round  13, Global train loss: 1.500, Global test loss: 2.182, Global test accuracy: 24.13 

Round  14, Train loss: 1.505, Test loss: 1.520, Test accuracy: 95.50 

Round  14, Global train loss: 1.505, Global test loss: 2.132, Global test accuracy: 36.85 

Round  15, Train loss: 1.474, Test loss: 1.518, Test accuracy: 95.68 

Round  15, Global train loss: 1.474, Global test loss: 2.089, Global test accuracy: 36.53 

Round  16, Train loss: 1.480, Test loss: 1.515, Test accuracy: 95.93 

Round  16, Global train loss: 1.480, Global test loss: 2.112, Global test accuracy: 39.05 

Round  17, Train loss: 1.483, Test loss: 1.512, Test accuracy: 96.15 

Round  17, Global train loss: 1.483, Global test loss: 2.208, Global test accuracy: 24.65 

Round  18, Train loss: 1.477, Test loss: 1.511, Test accuracy: 96.27 

Round  18, Global train loss: 1.477, Global test loss: 2.082, Global test accuracy: 34.05 

Round  19, Train loss: 1.468, Test loss: 1.510, Test accuracy: 96.28 

Round  19, Global train loss: 1.468, Global test loss: 2.104, Global test accuracy: 41.85 

Round  20, Train loss: 1.473, Test loss: 1.509, Test accuracy: 96.27 

Round  20, Global train loss: 1.473, Global test loss: 2.086, Global test accuracy: 47.12 

Round  21, Train loss: 1.473, Test loss: 1.508, Test accuracy: 96.27 

Round  21, Global train loss: 1.473, Global test loss: 2.212, Global test accuracy: 21.68 

Round  22, Train loss: 1.468, Test loss: 1.507, Test accuracy: 96.28 

Round  22, Global train loss: 1.468, Global test loss: 2.136, Global test accuracy: 34.57 

Round  23, Train loss: 1.467, Test loss: 1.507, Test accuracy: 96.25 

Round  23, Global train loss: 1.467, Global test loss: 2.062, Global test accuracy: 41.38 

Round  24, Train loss: 1.468, Test loss: 1.506, Test accuracy: 96.30 

Round  24, Global train loss: 1.468, Global test loss: 2.135, Global test accuracy: 43.18 

Round  25, Train loss: 1.468, Test loss: 1.506, Test accuracy: 96.32 

Round  25, Global train loss: 1.468, Global test loss: 2.127, Global test accuracy: 31.13 

Round  26, Train loss: 1.470, Test loss: 1.505, Test accuracy: 96.30 

Round  26, Global train loss: 1.470, Global test loss: 2.073, Global test accuracy: 42.73 

Round  27, Train loss: 1.467, Test loss: 1.505, Test accuracy: 96.32 

Round  27, Global train loss: 1.467, Global test loss: 2.146, Global test accuracy: 28.48 

Round  28, Train loss: 1.469, Test loss: 1.504, Test accuracy: 96.33 

Round  28, Global train loss: 1.469, Global test loss: 2.239, Global test accuracy: 19.23 

Round  29, Train loss: 1.468, Test loss: 1.504, Test accuracy: 96.32 

Round  29, Global train loss: 1.468, Global test loss: 2.170, Global test accuracy: 27.95 

Round  30, Train loss: 1.467, Test loss: 1.503, Test accuracy: 96.32 

Round  30, Global train loss: 1.467, Global test loss: 2.110, Global test accuracy: 33.83 

Round  31, Train loss: 1.468, Test loss: 1.503, Test accuracy: 96.33 

Round  31, Global train loss: 1.468, Global test loss: 2.189, Global test accuracy: 29.63 

Round  32, Train loss: 1.467, Test loss: 1.503, Test accuracy: 96.35 

Round  32, Global train loss: 1.467, Global test loss: 2.213, Global test accuracy: 20.60 

Round  33, Train loss: 1.466, Test loss: 1.503, Test accuracy: 96.35 

Round  33, Global train loss: 1.466, Global test loss: 2.279, Global test accuracy: 11.62 

Round  34, Train loss: 1.467, Test loss: 1.503, Test accuracy: 96.35 

Round  34, Global train loss: 1.467, Global test loss: 2.109, Global test accuracy: 35.40 

Round  35, Train loss: 1.467, Test loss: 1.502, Test accuracy: 96.35 

Round  35, Global train loss: 1.467, Global test loss: 2.190, Global test accuracy: 42.67 

Round  36, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.35 

Round  36, Global train loss: 1.466, Global test loss: 2.181, Global test accuracy: 26.38 

Round  37, Train loss: 1.468, Test loss: 1.502, Test accuracy: 96.37 

Round  37, Global train loss: 1.468, Global test loss: 2.208, Global test accuracy: 18.82 

Round  38, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.37 

Round  38, Global train loss: 1.466, Global test loss: 2.123, Global test accuracy: 38.98 

Round  39, Train loss: 1.468, Test loss: 1.502, Test accuracy: 96.37 

Round  39, Global train loss: 1.468, Global test loss: 2.127, Global test accuracy: 33.28 

Round  40, Train loss: 1.467, Test loss: 1.502, Test accuracy: 96.35 

Round  40, Global train loss: 1.467, Global test loss: 2.048, Global test accuracy: 52.32 

Round  41, Train loss: 1.467, Test loss: 1.502, Test accuracy: 96.33 

Round  41, Global train loss: 1.467, Global test loss: 2.123, Global test accuracy: 39.50 

Round  42, Train loss: 1.467, Test loss: 1.502, Test accuracy: 96.33 

Round  42, Global train loss: 1.467, Global test loss: 2.099, Global test accuracy: 37.77 

Round  43, Train loss: 1.465, Test loss: 1.502, Test accuracy: 96.33 

Round  43, Global train loss: 1.465, Global test loss: 2.069, Global test accuracy: 38.85 

Round  44, Train loss: 1.465, Test loss: 1.502, Test accuracy: 96.33 

Round  44, Global train loss: 1.465, Global test loss: 2.118, Global test accuracy: 32.15 

Round  45, Train loss: 1.464, Test loss: 1.501, Test accuracy: 96.33 

Round  45, Global train loss: 1.464, Global test loss: 2.193, Global test accuracy: 22.92 

Round  46, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.37 

Round  46, Global train loss: 1.466, Global test loss: 2.121, Global test accuracy: 46.28 

Round  47, Train loss: 1.464, Test loss: 1.501, Test accuracy: 96.37 

Round  47, Global train loss: 1.464, Global test loss: 2.105, Global test accuracy: 40.83 

Round  48, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.38 

Round  48, Global train loss: 1.466, Global test loss: 2.140, Global test accuracy: 28.37 

Round  49, Train loss: 1.464, Test loss: 1.501, Test accuracy: 96.38 

Round  49, Global train loss: 1.464, Global test loss: 2.026, Global test accuracy: 43.62 

Round  50, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.37 

Round  50, Global train loss: 1.466, Global test loss: 2.088, Global test accuracy: 42.90 

Round  51, Train loss: 1.463, Test loss: 1.501, Test accuracy: 96.37 

Round  51, Global train loss: 1.463, Global test loss: 2.105, Global test accuracy: 41.58 

Round  52, Train loss: 1.464, Test loss: 1.501, Test accuracy: 96.37 

Round  52, Global train loss: 1.464, Global test loss: 2.123, Global test accuracy: 30.13 

Round  53, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.37 

Round  53, Global train loss: 1.466, Global test loss: 2.083, Global test accuracy: 47.83 

Round  54, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.37 

Round  54, Global train loss: 1.466, Global test loss: 2.191, Global test accuracy: 25.62 

Round  55, Train loss: 1.467, Test loss: 1.501, Test accuracy: 96.37 

Round  55, Global train loss: 1.467, Global test loss: 2.114, Global test accuracy: 41.08 

Round  56, Train loss: 1.465, Test loss: 1.501, Test accuracy: 96.37 

Round  56, Global train loss: 1.465, Global test loss: 2.160, Global test accuracy: 32.35 

Round  57, Train loss: 1.465, Test loss: 1.501, Test accuracy: 96.38 

Round  57, Global train loss: 1.465, Global test loss: 2.164, Global test accuracy: 35.73 

Round  58, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.40 

Round  58, Global train loss: 1.466, Global test loss: 2.087, Global test accuracy: 37.73 

Round  59, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.40 

Round  59, Global train loss: 1.466, Global test loss: 2.111, Global test accuracy: 53.95 

Round  60, Train loss: 1.464, Test loss: 1.501, Test accuracy: 96.40 

Round  60, Global train loss: 1.464, Global test loss: 2.113, Global test accuracy: 35.23 

Round  61, Train loss: 1.467, Test loss: 1.501, Test accuracy: 96.40 

Round  61, Global train loss: 1.467, Global test loss: 2.104, Global test accuracy: 33.23 

Round  62, Train loss: 1.464, Test loss: 1.501, Test accuracy: 96.40 

Round  62, Global train loss: 1.464, Global test loss: 2.110, Global test accuracy: 41.68 

Round  63, Train loss: 1.465, Test loss: 1.501, Test accuracy: 96.40 

Round  63, Global train loss: 1.465, Global test loss: 2.148, Global test accuracy: 30.43 

Round  64, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.40 

Round  64, Global train loss: 1.464, Global test loss: 2.103, Global test accuracy: 36.17 

Round  65, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.40 

Round  65, Global train loss: 1.464, Global test loss: 2.122, Global test accuracy: 28.87 

Round  66, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.40 

Round  66, Global train loss: 1.464, Global test loss: 2.145, Global test accuracy: 34.62 

Round  67, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.40 

Round  67, Global train loss: 1.465, Global test loss: 2.082, Global test accuracy: 51.55 

Round  68, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.40 

Round  68, Global train loss: 1.463, Global test loss: 2.199, Global test accuracy: 22.57 

Round  69, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.40 

Round  69, Global train loss: 1.465, Global test loss: 2.132, Global test accuracy: 33.10 

Round  70, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.40 

Round  70, Global train loss: 1.465, Global test loss: 2.031, Global test accuracy: 43.43 

Round  71, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.40 

Round  71, Global train loss: 1.465, Global test loss: 2.082, Global test accuracy: 40.52 

Round  72, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.40 

Round  72, Global train loss: 1.464, Global test loss: 2.252, Global test accuracy: 18.48 

Round  73, Train loss: 1.467, Test loss: 1.500, Test accuracy: 96.38 

Round  73, Global train loss: 1.467, Global test loss: 2.088, Global test accuracy: 39.88 

Round  74, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.38 

Round  74, Global train loss: 1.463, Global test loss: 2.081, Global test accuracy: 39.85 

Round  75, Train loss: 1.466, Test loss: 1.500, Test accuracy: 96.38 

Round  75, Global train loss: 1.466, Global test loss: 2.160, Global test accuracy: 30.50 

Round  76, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.38 

Round  76, Global train loss: 1.464, Global test loss: 2.131, Global test accuracy: 34.03 

Round  77, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.38 

Round  77, Global train loss: 1.463, Global test loss: 2.115, Global test accuracy: 36.78 

Round  78, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.38 

Round  78, Global train loss: 1.464, Global test loss: 2.166, Global test accuracy: 25.55 

Round  79, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.38 

Round  79, Global train loss: 1.465, Global test loss: 2.145, Global test accuracy: 30.78 

Round  80, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.38 

Round  80, Global train loss: 1.465, Global test loss: 2.108, Global test accuracy: 41.73 

Round  81, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.40 

Round  81, Global train loss: 1.465, Global test loss: 2.086, Global test accuracy: 45.42 

Round  82, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.38 

Round  82, Global train loss: 1.464, Global test loss: 2.161, Global test accuracy: 31.87 

Round  83, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.38 

Round  83, Global train loss: 1.463, Global test loss: 2.100, Global test accuracy: 41.32 

Round  84, Train loss: 1.466, Test loss: 1.500, Test accuracy: 96.38 

Round  84, Global train loss: 1.466, Global test loss: 2.167, Global test accuracy: 28.05 

Round  85, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.38 

Round  85, Global train loss: 1.464, Global test loss: 2.122, Global test accuracy: 31.78 

Round  86, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.38 

Round  86, Global train loss: 1.464, Global test loss: 2.102, Global test accuracy: 32.13 

Round  87, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.40 

Round  87, Global train loss: 1.465, Global test loss: 2.159, Global test accuracy: 28.38 

Round  88, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.42 

Round  88, Global train loss: 1.464, Global test loss: 2.085, Global test accuracy: 37.65 

Round  89, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.43 

Round  89, Global train loss: 1.463, Global test loss: 2.132, Global test accuracy: 27.03 

Round  90, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.43 

Round  90, Global train loss: 1.463, Global test loss: 2.116, Global test accuracy: 34.35 

Round  91, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.42 

Round  91, Global train loss: 1.465, Global test loss: 2.054, Global test accuracy: 44.52 

Round  92, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.42 

Round  92, Global train loss: 1.465, Global test loss: 2.143, Global test accuracy: 33.38 

Round  93, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.42 

Round  93, Global train loss: 1.464, Global test loss: 2.143, Global test accuracy: 26.43 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.462, Test loss: 1.500, Test accuracy: 96.42 

Round  94, Global train loss: 1.462, Global test loss: 2.150, Global test accuracy: 36.05 

Round  95, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.42 

Round  95, Global train loss: 1.463, Global test loss: 2.180, Global test accuracy: 22.52 

Round  96, Train loss: 1.466, Test loss: 1.500, Test accuracy: 96.42 

Round  96, Global train loss: 1.466, Global test loss: 2.172, Global test accuracy: 22.55 

Round  97, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.43 

Round  97, Global train loss: 1.464, Global test loss: 2.163, Global test accuracy: 31.48 

Round  98, Train loss: 1.463, Test loss: 1.500, Test accuracy: 96.43 

Round  98, Global train loss: 1.463, Global test loss: 2.128, Global test accuracy: 33.23 

Round  99, Train loss: 1.464, Test loss: 1.500, Test accuracy: 96.43 

Round  99, Global train loss: 1.464, Global test loss: 2.146, Global test accuracy: 25.77 

Final Round, Train loss: 1.465, Test loss: 1.499, Test accuracy: 96.43 

Final Round, Global train loss: 1.465, Global test loss: 2.146, Global test accuracy: 25.77 

Average accuracy final 10 rounds: 96.42333333333333 

Average global accuracy final 10 rounds: 31.028333333333332 

469.39461064338684
[0.5000033378601074, 0.9377715587615967, 1.3632729053497314, 1.7868423461914062, 2.2078676223754883, 2.626983642578125, 3.0479722023010254, 3.4679393768310547, 3.8898584842681885, 4.309295892715454, 4.729593515396118, 5.150839567184448, 5.571371078491211, 5.990130186080933, 6.4125447273254395, 6.83467435836792, 7.257806777954102, 7.680031776428223, 8.099295616149902, 8.52191972732544, 8.946828126907349, 9.372659921646118, 9.793364763259888, 10.216866254806519, 10.642768383026123, 11.064960479736328, 11.491152286529541, 11.921740770339966, 12.35211730003357, 12.780110359191895, 13.209548950195312, 13.64069151878357, 14.070866346359253, 14.49531102180481, 14.922568082809448, 15.348717212677002, 15.77578616142273, 16.203997135162354, 16.629942655563354, 17.053972005844116, 17.47895073890686, 17.903691053390503, 18.327617645263672, 18.752837657928467, 19.179229259490967, 19.605080127716064, 20.03193688392639, 20.457961559295654, 20.88759732246399, 21.314822673797607, 21.741861581802368, 22.17005491256714, 22.594610452651978, 23.019262552261353, 23.442752361297607, 23.871378421783447, 24.298850297927856, 24.722638607025146, 25.145615577697754, 25.569409608840942, 25.996695280075073, 26.423226356506348, 26.849425315856934, 27.27568244934082, 27.705878257751465, 28.06549334526062, 28.42579221725464, 28.785002946853638, 29.145759344100952, 29.504603147506714, 29.865119218826294, 30.224326610565186, 30.586079120635986, 30.948718309402466, 31.30961847305298, 31.670673847198486, 32.03137731552124, 32.391772508621216, 32.75228714942932, 33.1135630607605, 33.47434639930725, 33.835535526275635, 34.19653511047363, 34.55924987792969, 34.91922450065613, 35.2810263633728, 35.646132946014404, 36.00723600387573, 36.36971712112427, 36.73517155647278, 37.097312450408936, 37.46033787727356, 37.825092792510986, 38.18597912788391, 38.5470016002655, 38.90908193588257, 39.27064085006714, 39.634100675582886, 39.99617886543274, 40.360901832580566, 41.07965588569641]
[21.85, 30.766666666666666, 39.583333333333336, 52.38333333333333, 62.766666666666666, 68.8, 82.36666666666666, 83.2, 86.48333333333333, 88.1, 88.7, 90.16666666666667, 94.08333333333333, 94.66666666666667, 95.5, 95.68333333333334, 95.93333333333334, 96.15, 96.26666666666667, 96.28333333333333, 96.26666666666667, 96.26666666666667, 96.28333333333333, 96.25, 96.3, 96.31666666666666, 96.3, 96.31666666666666, 96.33333333333333, 96.31666666666666, 96.31666666666666, 96.33333333333333, 96.35, 96.35, 96.35, 96.35, 96.35, 96.36666666666666, 96.36666666666666, 96.36666666666666, 96.35, 96.33333333333333, 96.33333333333333, 96.33333333333333, 96.33333333333333, 96.33333333333333, 96.36666666666666, 96.36666666666666, 96.38333333333334, 96.38333333333334, 96.36666666666666, 96.36666666666666, 96.36666666666666, 96.36666666666666, 96.36666666666666, 96.36666666666666, 96.36666666666666, 96.38333333333334, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.4, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.4, 96.41666666666667, 96.43333333333334, 96.43333333333334, 96.41666666666667, 96.41666666666667, 96.41666666666667, 96.41666666666667, 96.41666666666667, 96.41666666666667, 96.43333333333334, 96.43333333333334, 96.43333333333334, 96.43333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.283, Test loss: 2.277, Test accuracy: 23.55 

Round   0, Global train loss: 2.283, Global test loss: 2.295, Global test accuracy: 18.33 

Round   1, Train loss: 2.200, Test loss: 2.182, Test accuracy: 32.87 

Round   1, Global train loss: 2.200, Global test loss: 2.257, Global test accuracy: 20.13 

Round   2, Train loss: 1.964, Test loss: 2.011, Test accuracy: 55.15 

Round   2, Global train loss: 1.964, Global test loss: 2.158, Global test accuracy: 48.73 

Round   3, Train loss: 1.742, Test loss: 1.855, Test accuracy: 64.15 

Round   3, Global train loss: 1.742, Global test loss: 2.033, Global test accuracy: 49.40 

Round   4, Train loss: 1.780, Test loss: 1.796, Test accuracy: 69.32 

Round   4, Global train loss: 1.780, Global test loss: 2.025, Global test accuracy: 45.58 

Round   5, Train loss: 1.597, Test loss: 1.769, Test accuracy: 71.57 

Round   5, Global train loss: 1.597, Global test loss: 1.945, Global test accuracy: 52.45 

Round   6, Train loss: 1.738, Test loss: 1.692, Test accuracy: 79.10 

Round   6, Global train loss: 1.738, Global test loss: 1.901, Global test accuracy: 60.93 

Round   7, Train loss: 1.583, Test loss: 1.674, Test accuracy: 81.08 

Round   7, Global train loss: 1.583, Global test loss: 1.864, Global test accuracy: 63.97 

Round   8, Train loss: 1.585, Test loss: 1.650, Test accuracy: 83.05 

Round   8, Global train loss: 1.585, Global test loss: 1.884, Global test accuracy: 59.08 

Round   9, Train loss: 1.715, Test loss: 1.632, Test accuracy: 84.77 

Round   9, Global train loss: 1.715, Global test loss: 1.802, Global test accuracy: 71.33 

Round  10, Train loss: 1.557, Test loss: 1.629, Test accuracy: 84.83 

Round  10, Global train loss: 1.557, Global test loss: 1.850, Global test accuracy: 61.70 

Round  11, Train loss: 1.601, Test loss: 1.627, Test accuracy: 84.97 

Round  11, Global train loss: 1.601, Global test loss: 1.829, Global test accuracy: 64.08 

Round  12, Train loss: 1.556, Test loss: 1.625, Test accuracy: 84.95 

Round  12, Global train loss: 1.556, Global test loss: 1.872, Global test accuracy: 59.77 

Round  13, Train loss: 1.555, Test loss: 1.623, Test accuracy: 85.08 

Round  13, Global train loss: 1.555, Global test loss: 1.823, Global test accuracy: 66.03 

Round  14, Train loss: 1.613, Test loss: 1.624, Test accuracy: 84.92 

Round  14, Global train loss: 1.613, Global test loss: 1.743, Global test accuracy: 75.78 

Round  15, Train loss: 1.548, Test loss: 1.597, Test accuracy: 87.22 

Round  15, Global train loss: 1.548, Global test loss: 1.740, Global test accuracy: 74.02 

Round  16, Train loss: 1.596, Test loss: 1.596, Test accuracy: 87.23 

Round  16, Global train loss: 1.596, Global test loss: 1.735, Global test accuracy: 74.42 

Round  17, Train loss: 1.507, Test loss: 1.594, Test accuracy: 87.23 

Round  17, Global train loss: 1.507, Global test loss: 1.719, Global test accuracy: 78.30 

Round  18, Train loss: 1.592, Test loss: 1.595, Test accuracy: 87.20 

Round  18, Global train loss: 1.592, Global test loss: 1.741, Global test accuracy: 73.10 

Round  19, Train loss: 1.557, Test loss: 1.593, Test accuracy: 87.45 

Round  19, Global train loss: 1.557, Global test loss: 1.719, Global test accuracy: 77.67 

Round  20, Train loss: 1.538, Test loss: 1.593, Test accuracy: 87.50 

Round  20, Global train loss: 1.538, Global test loss: 1.760, Global test accuracy: 71.73 

Round  21, Train loss: 1.596, Test loss: 1.592, Test accuracy: 87.43 

Round  21, Global train loss: 1.596, Global test loss: 1.689, Global test accuracy: 79.40 

Round  22, Train loss: 1.588, Test loss: 1.592, Test accuracy: 87.50 

Round  22, Global train loss: 1.588, Global test loss: 1.720, Global test accuracy: 75.88 

Round  23, Train loss: 1.600, Test loss: 1.590, Test accuracy: 87.67 

Round  23, Global train loss: 1.600, Global test loss: 1.770, Global test accuracy: 70.60 

Round  24, Train loss: 1.589, Test loss: 1.589, Test accuracy: 87.67 

Round  24, Global train loss: 1.589, Global test loss: 1.708, Global test accuracy: 77.42 

Round  25, Train loss: 1.541, Test loss: 1.589, Test accuracy: 87.72 

Round  25, Global train loss: 1.541, Global test loss: 1.668, Global test accuracy: 81.48 

Round  26, Train loss: 1.593, Test loss: 1.588, Test accuracy: 87.77 

Round  26, Global train loss: 1.593, Global test loss: 1.681, Global test accuracy: 79.97 

Round  27, Train loss: 1.582, Test loss: 1.588, Test accuracy: 87.72 

Round  27, Global train loss: 1.582, Global test loss: 1.763, Global test accuracy: 70.98 

Round  28, Train loss: 1.490, Test loss: 1.589, Test accuracy: 87.67 

Round  28, Global train loss: 1.490, Global test loss: 1.675, Global test accuracy: 80.32 

Round  29, Train loss: 1.641, Test loss: 1.589, Test accuracy: 87.63 

Round  29, Global train loss: 1.641, Global test loss: 1.670, Global test accuracy: 80.87 

Round  30, Train loss: 1.536, Test loss: 1.588, Test accuracy: 87.62 

Round  30, Global train loss: 1.536, Global test loss: 1.678, Global test accuracy: 79.65 

Round  31, Train loss: 1.541, Test loss: 1.589, Test accuracy: 87.63 

Round  31, Global train loss: 1.541, Global test loss: 1.671, Global test accuracy: 80.67 

Round  32, Train loss: 1.533, Test loss: 1.589, Test accuracy: 87.57 

Round  32, Global train loss: 1.533, Global test loss: 1.669, Global test accuracy: 80.18 

Round  33, Train loss: 1.584, Test loss: 1.588, Test accuracy: 87.65 

Round  33, Global train loss: 1.584, Global test loss: 1.693, Global test accuracy: 77.62 

Round  34, Train loss: 1.642, Test loss: 1.588, Test accuracy: 87.63 

Round  34, Global train loss: 1.642, Global test loss: 1.673, Global test accuracy: 80.45 

Round  35, Train loss: 1.584, Test loss: 1.588, Test accuracy: 87.58 

Round  35, Global train loss: 1.584, Global test loss: 1.658, Global test accuracy: 81.82 

Round  36, Train loss: 1.532, Test loss: 1.588, Test accuracy: 87.60 

Round  36, Global train loss: 1.532, Global test loss: 1.669, Global test accuracy: 80.63 

Round  37, Train loss: 1.640, Test loss: 1.587, Test accuracy: 87.57 

Round  37, Global train loss: 1.640, Global test loss: 1.672, Global test accuracy: 80.57 

Round  38, Train loss: 1.482, Test loss: 1.588, Test accuracy: 87.55 

Round  38, Global train loss: 1.482, Global test loss: 1.663, Global test accuracy: 81.03 

Round  39, Train loss: 1.534, Test loss: 1.588, Test accuracy: 87.52 

Round  39, Global train loss: 1.534, Global test loss: 1.712, Global test accuracy: 75.90 

Round  40, Train loss: 1.593, Test loss: 1.587, Test accuracy: 87.67 

Round  40, Global train loss: 1.593, Global test loss: 1.701, Global test accuracy: 77.32 

Round  41, Train loss: 1.637, Test loss: 1.587, Test accuracy: 87.60 

Round  41, Global train loss: 1.637, Global test loss: 1.663, Global test accuracy: 81.33 

Round  42, Train loss: 1.634, Test loss: 1.587, Test accuracy: 87.58 

Round  42, Global train loss: 1.634, Global test loss: 1.670, Global test accuracy: 80.12 

Round  43, Train loss: 1.533, Test loss: 1.586, Test accuracy: 87.65 

Round  43, Global train loss: 1.533, Global test loss: 1.657, Global test accuracy: 81.45 

Round  44, Train loss: 1.639, Test loss: 1.586, Test accuracy: 87.68 

Round  44, Global train loss: 1.639, Global test loss: 1.656, Global test accuracy: 81.88 

Round  45, Train loss: 1.637, Test loss: 1.586, Test accuracy: 87.62 

Round  45, Global train loss: 1.637, Global test loss: 1.659, Global test accuracy: 81.32 

Round  46, Train loss: 1.582, Test loss: 1.586, Test accuracy: 87.63 

Round  46, Global train loss: 1.582, Global test loss: 1.663, Global test accuracy: 80.67 

Round  47, Train loss: 1.581, Test loss: 1.586, Test accuracy: 87.62 

Round  47, Global train loss: 1.581, Global test loss: 1.668, Global test accuracy: 80.30 

Round  48, Train loss: 1.585, Test loss: 1.586, Test accuracy: 87.62 

Round  48, Global train loss: 1.585, Global test loss: 1.669, Global test accuracy: 80.55 

Round  49, Train loss: 1.530, Test loss: 1.586, Test accuracy: 87.67 

Round  49, Global train loss: 1.530, Global test loss: 1.655, Global test accuracy: 81.72 

Round  50, Train loss: 1.536, Test loss: 1.586, Test accuracy: 87.67 

Round  50, Global train loss: 1.536, Global test loss: 1.664, Global test accuracy: 80.95 

Round  51, Train loss: 1.635, Test loss: 1.586, Test accuracy: 87.67 

Round  51, Global train loss: 1.635, Global test loss: 1.647, Global test accuracy: 82.62 

Round  52, Train loss: 1.582, Test loss: 1.586, Test accuracy: 87.65 

Round  52, Global train loss: 1.582, Global test loss: 1.655, Global test accuracy: 81.40 

Round  53, Train loss: 1.639, Test loss: 1.586, Test accuracy: 87.65 

Round  53, Global train loss: 1.639, Global test loss: 1.668, Global test accuracy: 80.72 

Round  54, Train loss: 1.582, Test loss: 1.586, Test accuracy: 87.65 

Round  54, Global train loss: 1.582, Global test loss: 1.681, Global test accuracy: 78.65 

Round  55, Train loss: 1.532, Test loss: 1.586, Test accuracy: 87.75 

Round  55, Global train loss: 1.532, Global test loss: 1.644, Global test accuracy: 82.50 

Round  56, Train loss: 1.477, Test loss: 1.585, Test accuracy: 87.72 

Round  56, Global train loss: 1.477, Global test loss: 1.643, Global test accuracy: 83.00 

Round  57, Train loss: 1.636, Test loss: 1.585, Test accuracy: 87.68 

Round  57, Global train loss: 1.636, Global test loss: 1.661, Global test accuracy: 80.97 

Round  58, Train loss: 1.634, Test loss: 1.585, Test accuracy: 87.70 

Round  58, Global train loss: 1.634, Global test loss: 1.700, Global test accuracy: 77.08 

Round  59, Train loss: 1.582, Test loss: 1.585, Test accuracy: 87.78 

Round  59, Global train loss: 1.582, Global test loss: 1.640, Global test accuracy: 83.18 

Round  60, Train loss: 1.584, Test loss: 1.584, Test accuracy: 87.83 

Round  60, Global train loss: 1.584, Global test loss: 1.641, Global test accuracy: 82.80 

Round  61, Train loss: 1.636, Test loss: 1.584, Test accuracy: 87.77 

Round  61, Global train loss: 1.636, Global test loss: 1.644, Global test accuracy: 82.77 

Round  62, Train loss: 1.688, Test loss: 1.584, Test accuracy: 87.78 

Round  62, Global train loss: 1.688, Global test loss: 1.655, Global test accuracy: 81.65 

Round  63, Train loss: 1.582, Test loss: 1.585, Test accuracy: 87.82 

Round  63, Global train loss: 1.582, Global test loss: 1.648, Global test accuracy: 82.32 

Round  64, Train loss: 1.685, Test loss: 1.585, Test accuracy: 87.82 

Round  64, Global train loss: 1.685, Global test loss: 1.664, Global test accuracy: 80.83 

Round  65, Train loss: 1.476, Test loss: 1.585, Test accuracy: 87.80 

Round  65, Global train loss: 1.476, Global test loss: 1.664, Global test accuracy: 80.63 

Round  66, Train loss: 1.634, Test loss: 1.586, Test accuracy: 87.70 

Round  66, Global train loss: 1.634, Global test loss: 1.697, Global test accuracy: 77.48 

Round  67, Train loss: 1.585, Test loss: 1.586, Test accuracy: 87.67 

Round  67, Global train loss: 1.585, Global test loss: 1.634, Global test accuracy: 83.70 

Round  68, Train loss: 1.579, Test loss: 1.586, Test accuracy: 87.68 

Round  68, Global train loss: 1.579, Global test loss: 1.677, Global test accuracy: 79.07 

Round  69, Train loss: 1.578, Test loss: 1.586, Test accuracy: 87.73 

Round  69, Global train loss: 1.578, Global test loss: 1.676, Global test accuracy: 79.68 

Round  70, Train loss: 1.633, Test loss: 1.586, Test accuracy: 87.72 

Round  70, Global train loss: 1.633, Global test loss: 1.646, Global test accuracy: 82.17 

Round  71, Train loss: 1.631, Test loss: 1.586, Test accuracy: 87.77 

Round  71, Global train loss: 1.631, Global test loss: 1.652, Global test accuracy: 81.52 

Round  72, Train loss: 1.588, Test loss: 1.585, Test accuracy: 87.80 

Round  72, Global train loss: 1.588, Global test loss: 1.642, Global test accuracy: 82.83 

Round  73, Train loss: 1.580, Test loss: 1.585, Test accuracy: 87.85 

Round  73, Global train loss: 1.580, Global test loss: 1.636, Global test accuracy: 83.68 

Round  74, Train loss: 1.527, Test loss: 1.585, Test accuracy: 87.85 

Round  74, Global train loss: 1.527, Global test loss: 1.649, Global test accuracy: 81.83 

Round  75, Train loss: 1.579, Test loss: 1.585, Test accuracy: 87.87 

Round  75, Global train loss: 1.579, Global test loss: 1.636, Global test accuracy: 83.38 

Round  76, Train loss: 1.632, Test loss: 1.585, Test accuracy: 87.87 

Round  76, Global train loss: 1.632, Global test loss: 1.643, Global test accuracy: 82.73 

Round  77, Train loss: 1.526, Test loss: 1.585, Test accuracy: 87.87 

Round  77, Global train loss: 1.526, Global test loss: 1.647, Global test accuracy: 81.97 

Round  78, Train loss: 1.632, Test loss: 1.585, Test accuracy: 87.83 

Round  78, Global train loss: 1.632, Global test loss: 1.643, Global test accuracy: 82.57 

Round  79, Train loss: 1.528, Test loss: 1.584, Test accuracy: 87.83 

Round  79, Global train loss: 1.528, Global test loss: 1.652, Global test accuracy: 81.80 

Round  80, Train loss: 1.578, Test loss: 1.584, Test accuracy: 87.88 

Round  80, Global train loss: 1.578, Global test loss: 1.650, Global test accuracy: 82.15 

Round  81, Train loss: 1.579, Test loss: 1.584, Test accuracy: 87.92 

Round  81, Global train loss: 1.579, Global test loss: 1.641, Global test accuracy: 83.20 

Round  82, Train loss: 1.633, Test loss: 1.584, Test accuracy: 87.93 

Round  82, Global train loss: 1.633, Global test loss: 1.639, Global test accuracy: 83.13 

Round  83, Train loss: 1.578, Test loss: 1.584, Test accuracy: 87.97 

Round  83, Global train loss: 1.578, Global test loss: 1.677, Global test accuracy: 78.75 

Round  84, Train loss: 1.632, Test loss: 1.584, Test accuracy: 87.95 

Round  84, Global train loss: 1.632, Global test loss: 1.648, Global test accuracy: 82.08 

Round  85, Train loss: 1.633, Test loss: 1.584, Test accuracy: 88.02 

Round  85, Global train loss: 1.633, Global test loss: 1.657, Global test accuracy: 81.37 

Round  86, Train loss: 1.580, Test loss: 1.584, Test accuracy: 87.95 

Round  86, Global train loss: 1.580, Global test loss: 1.651, Global test accuracy: 81.62 

Round  87, Train loss: 1.578, Test loss: 1.584, Test accuracy: 87.90 

Round  87, Global train loss: 1.578, Global test loss: 1.627, Global test accuracy: 84.05 

Round  88, Train loss: 1.633, Test loss: 1.584, Test accuracy: 87.98 

Round  88, Global train loss: 1.633, Global test loss: 1.653, Global test accuracy: 81.70 

Round  89, Train loss: 1.632, Test loss: 1.584, Test accuracy: 88.00 

Round  89, Global train loss: 1.632, Global test loss: 1.631, Global test accuracy: 83.92 

Round  90, Train loss: 1.525, Test loss: 1.584, Test accuracy: 87.97 

Round  90, Global train loss: 1.525, Global test loss: 1.632, Global test accuracy: 83.90 

Round  91, Train loss: 1.523, Test loss: 1.583, Test accuracy: 88.07 

Round  91, Global train loss: 1.523, Global test loss: 1.663, Global test accuracy: 80.43 

Round  92, Train loss: 1.630, Test loss: 1.583, Test accuracy: 88.08 

Round  92, Global train loss: 1.630, Global test loss: 1.662, Global test accuracy: 80.93 

Round  93, Train loss: 1.525, Test loss: 1.583, Test accuracy: 88.07 

Round  93, Global train loss: 1.525, Global test loss: 1.662, Global test accuracy: 80.35 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.581, Test loss: 1.583, Test accuracy: 88.05 

Round  94, Global train loss: 1.581, Global test loss: 1.638, Global test accuracy: 83.08 

Round  95, Train loss: 1.576, Test loss: 1.583, Test accuracy: 88.00 

Round  95, Global train loss: 1.576, Global test loss: 1.674, Global test accuracy: 79.20 

Round  96, Train loss: 1.576, Test loss: 1.583, Test accuracy: 88.05 

Round  96, Global train loss: 1.576, Global test loss: 1.648, Global test accuracy: 81.98 

Round  97, Train loss: 1.584, Test loss: 1.583, Test accuracy: 87.97 

Round  97, Global train loss: 1.584, Global test loss: 1.644, Global test accuracy: 82.87 

Round  98, Train loss: 1.632, Test loss: 1.583, Test accuracy: 87.97 

Round  98, Global train loss: 1.632, Global test loss: 1.636, Global test accuracy: 83.52 

Round  99, Train loss: 1.579, Test loss: 1.583, Test accuracy: 88.02 

Round  99, Global train loss: 1.579, Global test loss: 1.635, Global test accuracy: 83.25 

Final Round, Train loss: 1.566, Test loss: 1.583, Test accuracy: 87.87 

Final Round, Global train loss: 1.566, Global test loss: 1.635, Global test accuracy: 83.25 

Average accuracy final 10 rounds: 88.02333333333334 

Average global accuracy final 10 rounds: 81.95166666666667 

456.741352558136
[0.5240128040313721, 0.9493539333343506, 1.3734276294708252, 1.8010213375091553, 2.2242684364318848, 2.6462557315826416, 3.0728557109832764, 3.500786542892456, 3.9325313568115234, 4.3637754917144775, 4.792235612869263, 5.219969749450684, 5.6474690437316895, 6.075910329818726, 6.504443883895874, 6.932778596878052, 7.3623948097229, 7.7887444496154785, 8.214382648468018, 8.642210960388184, 9.069777965545654, 9.499243259429932, 9.926603555679321, 10.352791786193848, 10.781924724578857, 11.210883855819702, 11.638946533203125, 12.065372705459595, 12.492650032043457, 12.917012691497803, 13.343468189239502, 13.769118785858154, 14.128845691680908, 14.488999605178833, 14.849880695343018, 15.20781135559082, 15.563764810562134, 15.921843767166138, 16.279486417770386, 16.637633562088013, 16.99635362625122, 17.354480743408203, 17.714865922927856, 18.073148250579834, 18.433104276657104, 18.792662382125854, 19.150086641311646, 19.509525775909424, 19.869698524475098, 20.229715585708618, 20.58958101272583, 20.94881510734558, 21.30803155899048, 21.667153358459473, 22.027705669403076, 22.387250661849976, 22.744183778762817, 23.10365343093872, 23.46360969543457, 23.82409381866455, 24.18490195274353, 24.545165538787842, 24.905733108520508, 25.265830039978027, 25.62622094154358, 25.985880136489868, 26.347158670425415, 26.70661950111389, 27.066551208496094, 27.428099632263184, 27.789586782455444, 28.15001916885376, 28.511445999145508, 28.873514652252197, 29.23395347595215, 29.594167470932007, 29.95416259765625, 30.314945220947266, 30.67478108406067, 31.034565687179565, 31.396049737930298, 31.755436897277832, 32.11675572395325, 32.47655129432678, 32.837079763412476, 33.194440603256226, 33.55218148231506, 33.910940408706665, 34.27180361747742, 34.63114523887634, 34.991042375564575, 35.349326848983765, 35.7076256275177, 36.066829681396484, 36.42774152755737, 36.78799295425415, 37.14713263511658, 37.507139682769775, 37.865461349487305, 38.227136850357056, 38.94091033935547]
[23.55, 32.86666666666667, 55.15, 64.15, 69.31666666666666, 71.56666666666666, 79.1, 81.08333333333333, 83.05, 84.76666666666667, 84.83333333333333, 84.96666666666667, 84.95, 85.08333333333333, 84.91666666666667, 87.21666666666667, 87.23333333333333, 87.23333333333333, 87.2, 87.45, 87.5, 87.43333333333334, 87.5, 87.66666666666667, 87.66666666666667, 87.71666666666667, 87.76666666666667, 87.71666666666667, 87.66666666666667, 87.63333333333334, 87.61666666666666, 87.63333333333334, 87.56666666666666, 87.65, 87.63333333333334, 87.58333333333333, 87.6, 87.56666666666666, 87.55, 87.51666666666667, 87.66666666666667, 87.6, 87.58333333333333, 87.65, 87.68333333333334, 87.61666666666666, 87.63333333333334, 87.61666666666666, 87.61666666666666, 87.66666666666667, 87.66666666666667, 87.66666666666667, 87.65, 87.65, 87.65, 87.75, 87.71666666666667, 87.68333333333334, 87.7, 87.78333333333333, 87.83333333333333, 87.76666666666667, 87.78333333333333, 87.81666666666666, 87.81666666666666, 87.8, 87.7, 87.66666666666667, 87.68333333333334, 87.73333333333333, 87.71666666666667, 87.76666666666667, 87.8, 87.85, 87.85, 87.86666666666666, 87.86666666666666, 87.86666666666666, 87.83333333333333, 87.83333333333333, 87.88333333333334, 87.91666666666667, 87.93333333333334, 87.96666666666667, 87.95, 88.01666666666667, 87.95, 87.9, 87.98333333333333, 88.0, 87.96666666666667, 88.06666666666666, 88.08333333333333, 88.06666666666666, 88.05, 88.0, 88.05, 87.96666666666667, 87.96666666666667, 88.01666666666667, 87.86666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.296, Test loss: 2.299, Test accuracy: 20.18 

Round   1, Train loss: 2.292, Test loss: 2.295, Test accuracy: 20.87 

Round   2, Train loss: 2.284, Test loss: 2.285, Test accuracy: 27.77 

Round   3, Train loss: 2.234, Test loss: 2.242, Test accuracy: 40.65 

Round   4, Train loss: 2.136, Test loss: 2.168, Test accuracy: 42.13 

Round   5, Train loss: 1.994, Test loss: 2.058, Test accuracy: 47.17 

Round   6, Train loss: 1.889, Test loss: 1.980, Test accuracy: 52.35 

Round   7, Train loss: 1.768, Test loss: 1.908, Test accuracy: 57.77 

Round   8, Train loss: 1.802, Test loss: 1.853, Test accuracy: 63.75 

Round   9, Train loss: 1.741, Test loss: 1.783, Test accuracy: 70.58 

Round  10, Train loss: 1.577, Test loss: 1.745, Test accuracy: 74.90 

Round  11, Train loss: 1.659, Test loss: 1.709, Test accuracy: 78.15 

Round  12, Train loss: 1.638, Test loss: 1.694, Test accuracy: 78.57 

Round  13, Train loss: 1.599, Test loss: 1.646, Test accuracy: 83.57 

Round  14, Train loss: 1.605, Test loss: 1.642, Test accuracy: 83.82 

Round  15, Train loss: 1.621, Test loss: 1.625, Test accuracy: 85.33 

Round  16, Train loss: 1.550, Test loss: 1.623, Test accuracy: 85.42 

Round  17, Train loss: 1.609, Test loss: 1.619, Test accuracy: 85.47 

Round  18, Train loss: 1.560, Test loss: 1.616, Test accuracy: 85.73 

Round  19, Train loss: 1.553, Test loss: 1.615, Test accuracy: 85.55 

Round  20, Train loss: 1.571, Test loss: 1.611, Test accuracy: 85.90 

Round  21, Train loss: 1.495, Test loss: 1.609, Test accuracy: 86.00 

Round  22, Train loss: 1.564, Test loss: 1.607, Test accuracy: 86.13 

Round  23, Train loss: 1.644, Test loss: 1.606, Test accuracy: 86.15 

Round  24, Train loss: 1.552, Test loss: 1.604, Test accuracy: 86.27 

Round  25, Train loss: 1.558, Test loss: 1.592, Test accuracy: 87.80 

Round  26, Train loss: 1.554, Test loss: 1.592, Test accuracy: 87.62 

Round  27, Train loss: 1.545, Test loss: 1.591, Test accuracy: 87.73 

Round  28, Train loss: 1.543, Test loss: 1.591, Test accuracy: 87.63 

Round  29, Train loss: 1.594, Test loss: 1.587, Test accuracy: 87.83 

Round  30, Train loss: 1.544, Test loss: 1.587, Test accuracy: 87.88 

Round  31, Train loss: 1.541, Test loss: 1.571, Test accuracy: 89.87 

Round  32, Train loss: 1.496, Test loss: 1.570, Test accuracy: 89.67 

Round  33, Train loss: 1.602, Test loss: 1.571, Test accuracy: 89.78 

Round  34, Train loss: 1.539, Test loss: 1.570, Test accuracy: 89.88 

Round  35, Train loss: 1.617, Test loss: 1.569, Test accuracy: 90.00 

Round  36, Train loss: 1.544, Test loss: 1.567, Test accuracy: 90.10 

Round  37, Train loss: 1.486, Test loss: 1.566, Test accuracy: 90.20 

Round  38, Train loss: 1.499, Test loss: 1.565, Test accuracy: 90.38 

Round  39, Train loss: 1.543, Test loss: 1.563, Test accuracy: 90.43 

Round  40, Train loss: 1.553, Test loss: 1.562, Test accuracy: 90.48 

Round  41, Train loss: 1.558, Test loss: 1.560, Test accuracy: 90.77 

Round  42, Train loss: 1.485, Test loss: 1.560, Test accuracy: 90.80 

Round  43, Train loss: 1.572, Test loss: 1.555, Test accuracy: 91.20 

Round  44, Train loss: 1.514, Test loss: 1.547, Test accuracy: 92.22 

Round  45, Train loss: 1.509, Test loss: 1.546, Test accuracy: 92.32 

Round  46, Train loss: 1.489, Test loss: 1.546, Test accuracy: 92.13 

Round  47, Train loss: 1.582, Test loss: 1.547, Test accuracy: 92.10 

Round  48, Train loss: 1.493, Test loss: 1.545, Test accuracy: 92.22 

Round  49, Train loss: 1.588, Test loss: 1.545, Test accuracy: 92.15 

Round  50, Train loss: 1.498, Test loss: 1.545, Test accuracy: 92.25 

Round  51, Train loss: 1.549, Test loss: 1.543, Test accuracy: 92.30 

Round  52, Train loss: 1.479, Test loss: 1.543, Test accuracy: 92.30 

Round  53, Train loss: 1.480, Test loss: 1.543, Test accuracy: 92.25 

Round  54, Train loss: 1.584, Test loss: 1.543, Test accuracy: 92.28 

Round  55, Train loss: 1.543, Test loss: 1.542, Test accuracy: 92.33 

Round  56, Train loss: 1.500, Test loss: 1.541, Test accuracy: 92.43 

Round  57, Train loss: 1.527, Test loss: 1.542, Test accuracy: 92.43 

Round  58, Train loss: 1.543, Test loss: 1.539, Test accuracy: 92.67 

Round  59, Train loss: 1.528, Test loss: 1.539, Test accuracy: 92.65 

Round  60, Train loss: 1.490, Test loss: 1.539, Test accuracy: 92.68 

Round  61, Train loss: 1.477, Test loss: 1.538, Test accuracy: 92.70 

Round  62, Train loss: 1.532, Test loss: 1.539, Test accuracy: 92.68 

Round  63, Train loss: 1.543, Test loss: 1.538, Test accuracy: 92.80 

Round  64, Train loss: 1.538, Test loss: 1.538, Test accuracy: 92.88 

Round  65, Train loss: 1.485, Test loss: 1.539, Test accuracy: 92.73 

Round  66, Train loss: 1.496, Test loss: 1.536, Test accuracy: 92.88 

Round  67, Train loss: 1.537, Test loss: 1.537, Test accuracy: 92.80 

Round  68, Train loss: 1.530, Test loss: 1.537, Test accuracy: 92.73 

Round  69, Train loss: 1.493, Test loss: 1.536, Test accuracy: 93.03 

Round  70, Train loss: 1.537, Test loss: 1.536, Test accuracy: 92.97 

Round  71, Train loss: 1.549, Test loss: 1.536, Test accuracy: 92.78 

Round  72, Train loss: 1.525, Test loss: 1.536, Test accuracy: 92.88 

Round  73, Train loss: 1.532, Test loss: 1.536, Test accuracy: 92.90 

Round  74, Train loss: 1.586, Test loss: 1.536, Test accuracy: 92.85 

Round  75, Train loss: 1.487, Test loss: 1.536, Test accuracy: 92.82 

Round  76, Train loss: 1.530, Test loss: 1.535, Test accuracy: 92.93 

Round  77, Train loss: 1.531, Test loss: 1.536, Test accuracy: 92.92 

Round  78, Train loss: 1.539, Test loss: 1.535, Test accuracy: 92.92 

Round  79, Train loss: 1.480, Test loss: 1.535, Test accuracy: 92.92 

Round  80, Train loss: 1.524, Test loss: 1.535, Test accuracy: 92.95 

Round  81, Train loss: 1.470, Test loss: 1.535, Test accuracy: 92.98 

Round  82, Train loss: 1.489, Test loss: 1.534, Test accuracy: 93.03 

Round  83, Train loss: 1.536, Test loss: 1.534, Test accuracy: 93.02 

Round  84, Train loss: 1.484, Test loss: 1.533, Test accuracy: 93.18 

Round  85, Train loss: 1.524, Test loss: 1.533, Test accuracy: 93.17 

Round  86, Train loss: 1.480, Test loss: 1.533, Test accuracy: 93.12 

Round  87, Train loss: 1.476, Test loss: 1.533, Test accuracy: 93.22 

Round  88, Train loss: 1.531, Test loss: 1.533, Test accuracy: 93.10 

Round  89, Train loss: 1.477, Test loss: 1.533, Test accuracy: 93.15 

Round  90, Train loss: 1.533, Test loss: 1.533, Test accuracy: 93.15 

Round  91, Train loss: 1.519, Test loss: 1.533, Test accuracy: 92.98 

Round  92, Train loss: 1.471, Test loss: 1.532, Test accuracy: 93.05 

Round  93, Train loss: 1.524, Test loss: 1.533, Test accuracy: 93.02 

Round  94, Train loss: 1.476, Test loss: 1.531, Test accuracy: 93.13 

Round  95, Train loss: 1.477, Test loss: 1.531, Test accuracy: 93.18 

Round  96, Train loss: 1.476, Test loss: 1.531, Test accuracy: 93.22 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.493, Test loss: 1.521, Test accuracy: 94.40 

Round  98, Train loss: 1.505, Test loss: 1.509, Test accuracy: 95.72 

Round  99, Train loss: 1.469, Test loss: 1.509, Test accuracy: 95.70 

Final Round, Train loss: 1.483, Test loss: 1.507, Test accuracy: 95.85 

Average accuracy final 10 rounds: 93.755 

336.66759276390076
[0.4955432415008545, 0.88018798828125, 1.2624671459197998, 1.645308256149292, 2.030745267868042, 2.416008472442627, 2.801135301589966, 3.1693572998046875, 3.532768964767456, 3.8973608016967773, 4.262529611587524, 4.626496076583862, 4.99219536781311, 5.354999542236328, 5.746260643005371, 6.127183198928833, 6.508731365203857, 6.892358779907227, 7.2762110233306885, 7.658537864685059, 8.043683528900146, 8.425156593322754, 8.809768676757812, 9.195595502853394, 9.576602220535278, 9.950601816177368, 10.325578927993774, 10.7008798122406, 11.077491521835327, 11.456404209136963, 11.83337950706482, 12.210978746414185, 12.585853338241577, 12.96362829208374, 13.340192794799805, 13.717821836471558, 14.093698501586914, 14.46931529045105, 14.845159769058228, 15.220590353012085, 15.594887018203735, 15.971835851669312, 16.351494312286377, 16.73218584060669, 17.110694408416748, 17.488635063171387, 17.870991468429565, 18.252209901809692, 18.63391613960266, 19.012025833129883, 19.392415285110474, 19.771761655807495, 20.149213075637817, 20.53018879890442, 20.911144495010376, 21.292217254638672, 21.67200779914856, 22.050776958465576, 22.43020987510681, 22.81175470352173, 23.19078516960144, 23.570001125335693, 23.948320627212524, 24.332005739212036, 24.674383401870728, 25.01476216316223, 25.3525128364563, 25.694734811782837, 26.038636684417725, 26.3743257522583, 26.718523263931274, 27.067843675613403, 27.41115164756775, 27.7549467086792, 28.097819566726685, 28.441498517990112, 28.78379797935486, 29.12882089614868, 29.471343755722046, 29.814714431762695, 30.149127960205078, 30.487658500671387, 30.82741904258728, 31.168558597564697, 31.51258611679077, 31.85725426673889, 32.199422121047974, 32.54079222679138, 32.8843092918396, 33.22766184806824, 33.57105326652527, 33.916550159454346, 34.25680685043335, 34.60027098655701, 34.945507764816284, 35.28725719451904, 35.6280357837677, 35.964816093444824, 36.30532503128052, 36.642027378082275, 37.26605558395386]
[20.183333333333334, 20.866666666666667, 27.766666666666666, 40.65, 42.13333333333333, 47.166666666666664, 52.35, 57.766666666666666, 63.75, 70.58333333333333, 74.9, 78.15, 78.56666666666666, 83.56666666666666, 83.81666666666666, 85.33333333333333, 85.41666666666667, 85.46666666666667, 85.73333333333333, 85.55, 85.9, 86.0, 86.13333333333334, 86.15, 86.26666666666667, 87.8, 87.61666666666666, 87.73333333333333, 87.63333333333334, 87.83333333333333, 87.88333333333334, 89.86666666666666, 89.66666666666667, 89.78333333333333, 89.88333333333334, 90.0, 90.1, 90.2, 90.38333333333334, 90.43333333333334, 90.48333333333333, 90.76666666666667, 90.8, 91.2, 92.21666666666667, 92.31666666666666, 92.13333333333334, 92.1, 92.21666666666667, 92.15, 92.25, 92.3, 92.3, 92.25, 92.28333333333333, 92.33333333333333, 92.43333333333334, 92.43333333333334, 92.66666666666667, 92.65, 92.68333333333334, 92.7, 92.68333333333334, 92.8, 92.88333333333334, 92.73333333333333, 92.88333333333334, 92.8, 92.73333333333333, 93.03333333333333, 92.96666666666667, 92.78333333333333, 92.88333333333334, 92.9, 92.85, 92.81666666666666, 92.93333333333334, 92.91666666666667, 92.91666666666667, 92.91666666666667, 92.95, 92.98333333333333, 93.03333333333333, 93.01666666666667, 93.18333333333334, 93.16666666666667, 93.11666666666666, 93.21666666666667, 93.1, 93.15, 93.15, 92.98333333333333, 93.05, 93.01666666666667, 93.13333333333334, 93.18333333333334, 93.21666666666667, 94.4, 95.71666666666667, 95.7, 95.85]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.297, Test accuracy: 14.52 

Round   1, Train loss: 2.243, Test loss: 2.274, Test accuracy: 24.98 

Round   2, Train loss: 2.053, Test loss: 2.155, Test accuracy: 49.72 

Round   3, Train loss: 1.822, Test loss: 2.000, Test accuracy: 50.80 

Round   4, Train loss: 1.739, Test loss: 1.852, Test accuracy: 66.27 

Round   5, Train loss: 1.650, Test loss: 1.738, Test accuracy: 77.17 

Round   6, Train loss: 1.555, Test loss: 1.691, Test accuracy: 80.22 

Round   7, Train loss: 1.566, Test loss: 1.655, Test accuracy: 83.92 

Round   8, Train loss: 1.546, Test loss: 1.607, Test accuracy: 87.67 

Round   9, Train loss: 1.502, Test loss: 1.598, Test accuracy: 88.63 

Round  10, Train loss: 1.506, Test loss: 1.585, Test accuracy: 89.30 

Round  11, Train loss: 1.502, Test loss: 1.577, Test accuracy: 89.62 

Round  12, Train loss: 1.512, Test loss: 1.572, Test accuracy: 90.03 

Round  13, Train loss: 1.501, Test loss: 1.567, Test accuracy: 90.30 

Round  14, Train loss: 1.500, Test loss: 1.565, Test accuracy: 90.35 

Round  15, Train loss: 1.495, Test loss: 1.559, Test accuracy: 90.88 

Round  16, Train loss: 1.502, Test loss: 1.551, Test accuracy: 92.10 

Round  17, Train loss: 1.478, Test loss: 1.552, Test accuracy: 92.03 

Round  18, Train loss: 1.496, Test loss: 1.545, Test accuracy: 92.17 

Round  19, Train loss: 1.486, Test loss: 1.542, Test accuracy: 92.58 

Round  20, Train loss: 1.495, Test loss: 1.541, Test accuracy: 92.55 

Round  21, Train loss: 1.494, Test loss: 1.535, Test accuracy: 93.23 

Round  22, Train loss: 1.485, Test loss: 1.535, Test accuracy: 93.30 

Round  23, Train loss: 1.484, Test loss: 1.533, Test accuracy: 93.43 

Round  24, Train loss: 1.481, Test loss: 1.532, Test accuracy: 93.53 

Round  25, Train loss: 1.486, Test loss: 1.531, Test accuracy: 93.60 

Round  26, Train loss: 1.480, Test loss: 1.530, Test accuracy: 93.73 

Round  27, Train loss: 1.487, Test loss: 1.529, Test accuracy: 93.73 

Round  28, Train loss: 1.492, Test loss: 1.516, Test accuracy: 95.15 

Round  29, Train loss: 1.479, Test loss: 1.514, Test accuracy: 95.30 

Round  30, Train loss: 1.485, Test loss: 1.514, Test accuracy: 95.20 

Round  31, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.30 

Round  32, Train loss: 1.481, Test loss: 1.512, Test accuracy: 95.40 

Round  33, Train loss: 1.472, Test loss: 1.511, Test accuracy: 95.68 

Round  34, Train loss: 1.476, Test loss: 1.510, Test accuracy: 95.72 

Round  35, Train loss: 1.481, Test loss: 1.510, Test accuracy: 95.67 

Round  36, Train loss: 1.481, Test loss: 1.508, Test accuracy: 95.87 

Round  37, Train loss: 1.480, Test loss: 1.506, Test accuracy: 95.97 

Round  38, Train loss: 1.476, Test loss: 1.506, Test accuracy: 96.02 

Round  39, Train loss: 1.474, Test loss: 1.506, Test accuracy: 96.00 

Round  40, Train loss: 1.471, Test loss: 1.506, Test accuracy: 96.02 

Round  41, Train loss: 1.477, Test loss: 1.506, Test accuracy: 95.97 

Round  42, Train loss: 1.476, Test loss: 1.505, Test accuracy: 96.07 

Round  43, Train loss: 1.473, Test loss: 1.505, Test accuracy: 96.07 

Round  44, Train loss: 1.475, Test loss: 1.504, Test accuracy: 96.12 

Round  45, Train loss: 1.471, Test loss: 1.505, Test accuracy: 96.03 

Round  46, Train loss: 1.472, Test loss: 1.504, Test accuracy: 96.12 

Round  47, Train loss: 1.475, Test loss: 1.503, Test accuracy: 96.12 

Round  48, Train loss: 1.476, Test loss: 1.503, Test accuracy: 96.28 

Round  49, Train loss: 1.472, Test loss: 1.503, Test accuracy: 96.15 

Round  50, Train loss: 1.474, Test loss: 1.503, Test accuracy: 96.23 

Round  51, Train loss: 1.467, Test loss: 1.503, Test accuracy: 96.22 

Round  52, Train loss: 1.468, Test loss: 1.502, Test accuracy: 96.27 

Round  53, Train loss: 1.474, Test loss: 1.501, Test accuracy: 96.28 

Round  54, Train loss: 1.472, Test loss: 1.502, Test accuracy: 96.28 

Round  55, Train loss: 1.471, Test loss: 1.502, Test accuracy: 96.23 

Round  56, Train loss: 1.470, Test loss: 1.501, Test accuracy: 96.37 

Round  57, Train loss: 1.467, Test loss: 1.501, Test accuracy: 96.48 

Round  58, Train loss: 1.468, Test loss: 1.500, Test accuracy: 96.52 

Round  59, Train loss: 1.467, Test loss: 1.500, Test accuracy: 96.40 

Round  60, Train loss: 1.471, Test loss: 1.501, Test accuracy: 96.33 

Round  61, Train loss: 1.468, Test loss: 1.500, Test accuracy: 96.30 

Round  62, Train loss: 1.473, Test loss: 1.500, Test accuracy: 96.43 

Round  63, Train loss: 1.469, Test loss: 1.500, Test accuracy: 96.30 

Round  64, Train loss: 1.473, Test loss: 1.500, Test accuracy: 96.37 

Round  65, Train loss: 1.469, Test loss: 1.500, Test accuracy: 96.40 

Round  66, Train loss: 1.470, Test loss: 1.499, Test accuracy: 96.43 

Round  67, Train loss: 1.472, Test loss: 1.500, Test accuracy: 96.37 

Round  68, Train loss: 1.472, Test loss: 1.500, Test accuracy: 96.38 

Round  69, Train loss: 1.470, Test loss: 1.500, Test accuracy: 96.42 

Round  70, Train loss: 1.469, Test loss: 1.500, Test accuracy: 96.42 

Round  71, Train loss: 1.470, Test loss: 1.499, Test accuracy: 96.53 

Round  72, Train loss: 1.473, Test loss: 1.499, Test accuracy: 96.45 

Round  73, Train loss: 1.474, Test loss: 1.499, Test accuracy: 96.45 

Round  74, Train loss: 1.471, Test loss: 1.500, Test accuracy: 96.40 

Round  75, Train loss: 1.466, Test loss: 1.499, Test accuracy: 96.43 

Round  76, Train loss: 1.470, Test loss: 1.499, Test accuracy: 96.48 

Round  77, Train loss: 1.470, Test loss: 1.499, Test accuracy: 96.45 

Round  78, Train loss: 1.469, Test loss: 1.498, Test accuracy: 96.52 

Round  79, Train loss: 1.471, Test loss: 1.498, Test accuracy: 96.48 

Round  80, Train loss: 1.472, Test loss: 1.499, Test accuracy: 96.43 

Round  81, Train loss: 1.469, Test loss: 1.499, Test accuracy: 96.50 

Round  82, Train loss: 1.470, Test loss: 1.498, Test accuracy: 96.47 

Round  83, Train loss: 1.469, Test loss: 1.498, Test accuracy: 96.45 

Round  84, Train loss: 1.468, Test loss: 1.499, Test accuracy: 96.45 

Round  85, Train loss: 1.469, Test loss: 1.499, Test accuracy: 96.50 

Round  86, Train loss: 1.468, Test loss: 1.499, Test accuracy: 96.42 

Round  87, Train loss: 1.469, Test loss: 1.499, Test accuracy: 96.47 

Round  88, Train loss: 1.469, Test loss: 1.499, Test accuracy: 96.43 

Round  89, Train loss: 1.473, Test loss: 1.498, Test accuracy: 96.52 

Round  90, Train loss: 1.466, Test loss: 1.498, Test accuracy: 96.53 

Round  91, Train loss: 1.465, Test loss: 1.498, Test accuracy: 96.58 

Round  92, Train loss: 1.471, Test loss: 1.498, Test accuracy: 96.55 

Round  93, Train loss: 1.471, Test loss: 1.499, Test accuracy: 96.47 

Round  94, Train loss: 1.469, Test loss: 1.499, Test accuracy: 96.52 

Round  95, Train loss: 1.470, Test loss: 1.499, Test accuracy: 96.52 

Round  96, Train loss: 1.472, Test loss: 1.498, Test accuracy: 96.53 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.470, Test loss: 1.498, Test accuracy: 96.45 

Round  98, Train loss: 1.472, Test loss: 1.498, Test accuracy: 96.47 

Round  99, Train loss: 1.468, Test loss: 1.498, Test accuracy: 96.47 

Final Round, Train loss: 1.470, Test loss: 1.498, Test accuracy: 96.53 

Average accuracy final 10 rounds: 96.50833333333333 

352.98004388809204
[0.5263359546661377, 0.9523401260375977, 1.378843069076538, 1.810659646987915, 2.2383382320404053, 2.6656718254089355, 3.091486692428589, 3.518526315689087, 3.945431709289551, 4.373927116394043, 4.799956321716309, 5.226307153701782, 5.653759479522705, 6.079406499862671, 6.507078647613525, 6.937445640563965, 7.368815660476685, 7.80890965461731, 8.238885879516602, 8.668622732162476, 9.098814964294434, 9.528985738754272, 9.959241151809692, 10.388614892959595, 10.819818496704102, 11.249499082565308, 11.678057432174683, 12.108107805252075, 12.538372278213501, 12.967910289764404, 13.398951053619385, 13.828031301498413, 14.257477283477783, 14.690105676651001, 15.119085311889648, 15.550203800201416, 15.965562343597412, 16.325639724731445, 16.691190004348755, 17.057024717330933, 17.422117710113525, 17.78739833831787, 18.15390634536743, 18.51976990699768, 18.887619733810425, 19.25346827507019, 19.619617223739624, 19.98462700843811, 20.349838256835938, 20.710212230682373, 21.06923270225525, 21.433240175247192, 21.794481992721558, 22.156745433807373, 22.517672538757324, 22.8792667388916, 23.24062442779541, 23.606009483337402, 23.973007917404175, 24.338879823684692, 24.69996404647827, 25.06184411048889, 25.42269206047058, 25.78423309326172, 26.14582633972168, 26.50781774520874, 26.868552207946777, 27.230026245117188, 27.590276956558228, 27.950841426849365, 28.312525510787964, 28.678422451019287, 29.042790174484253, 29.406753063201904, 29.77083945274353, 30.13491940498352, 30.499907732009888, 30.865195512771606, 31.231149673461914, 31.593913555145264, 31.955533027648926, 32.316399574279785, 32.680487871170044, 33.04720377922058, 33.40847039222717, 33.769903898239136, 34.1314582824707, 34.505043268203735, 34.86495876312256, 35.22647023200989, 35.58754205703735, 35.94847655296326, 36.31140398979187, 36.67378234863281, 37.05720019340515, 37.43830418586731, 37.80330753326416, 38.16801381111145, 38.53304743766785, 38.89848041534424, 39.53213882446289]
[14.516666666666667, 24.983333333333334, 49.71666666666667, 50.8, 66.26666666666667, 77.16666666666667, 80.21666666666667, 83.91666666666667, 87.66666666666667, 88.63333333333334, 89.3, 89.61666666666666, 90.03333333333333, 90.3, 90.35, 90.88333333333334, 92.1, 92.03333333333333, 92.16666666666667, 92.58333333333333, 92.55, 93.23333333333333, 93.3, 93.43333333333334, 93.53333333333333, 93.6, 93.73333333333333, 93.73333333333333, 95.15, 95.3, 95.2, 95.3, 95.4, 95.68333333333334, 95.71666666666667, 95.66666666666667, 95.86666666666666, 95.96666666666667, 96.01666666666667, 96.0, 96.01666666666667, 95.96666666666667, 96.06666666666666, 96.06666666666666, 96.11666666666666, 96.03333333333333, 96.11666666666666, 96.11666666666666, 96.28333333333333, 96.15, 96.23333333333333, 96.21666666666667, 96.26666666666667, 96.28333333333333, 96.28333333333333, 96.23333333333333, 96.36666666666666, 96.48333333333333, 96.51666666666667, 96.4, 96.33333333333333, 96.3, 96.43333333333334, 96.3, 96.36666666666666, 96.4, 96.43333333333334, 96.36666666666666, 96.38333333333334, 96.41666666666667, 96.41666666666667, 96.53333333333333, 96.45, 96.45, 96.4, 96.43333333333334, 96.48333333333333, 96.45, 96.51666666666667, 96.48333333333333, 96.43333333333334, 96.5, 96.46666666666667, 96.45, 96.45, 96.5, 96.41666666666667, 96.46666666666667, 96.43333333333334, 96.51666666666667, 96.53333333333333, 96.58333333333333, 96.55, 96.46666666666667, 96.51666666666667, 96.51666666666667, 96.53333333333333, 96.45, 96.46666666666667, 96.46666666666667, 96.53333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.281, Test loss: 2.292, Test accuracy: 30.28 

Round   1, Train loss: 2.204, Test loss: 2.231, Test accuracy: 27.83 

Round   2, Train loss: 2.035, Test loss: 2.142, Test accuracy: 46.48 

Round   3, Train loss: 1.814, Test loss: 2.016, Test accuracy: 54.25 

Round   4, Train loss: 1.777, Test loss: 1.936, Test accuracy: 60.37 

Round   5, Train loss: 1.684, Test loss: 1.866, Test accuracy: 65.75 

Round   6, Train loss: 1.604, Test loss: 1.820, Test accuracy: 68.08 

Round   7, Train loss: 1.655, Test loss: 1.782, Test accuracy: 72.32 

Round   8, Train loss: 1.740, Test loss: 1.734, Test accuracy: 75.63 

Round   9, Train loss: 1.578, Test loss: 1.710, Test accuracy: 78.03 

Round  10, Train loss: 1.635, Test loss: 1.675, Test accuracy: 80.45 

Round  11, Train loss: 1.545, Test loss: 1.644, Test accuracy: 84.02 

Round  12, Train loss: 1.574, Test loss: 1.622, Test accuracy: 86.17 

Round  13, Train loss: 1.543, Test loss: 1.605, Test accuracy: 87.58 

Round  14, Train loss: 1.485, Test loss: 1.601, Test accuracy: 87.60 

Round  15, Train loss: 1.482, Test loss: 1.591, Test accuracy: 88.52 

Round  16, Train loss: 1.494, Test loss: 1.585, Test accuracy: 88.48 

Round  17, Train loss: 1.512, Test loss: 1.565, Test accuracy: 91.18 

Round  18, Train loss: 1.479, Test loss: 1.557, Test accuracy: 91.80 

Round  19, Train loss: 1.494, Test loss: 1.542, Test accuracy: 94.00 

Round  20, Train loss: 1.476, Test loss: 1.535, Test accuracy: 94.43 

Round  21, Train loss: 1.478, Test loss: 1.528, Test accuracy: 94.93 

Round  22, Train loss: 1.474, Test loss: 1.525, Test accuracy: 95.12 

Round  23, Train loss: 1.474, Test loss: 1.523, Test accuracy: 95.10 

Round  24, Train loss: 1.472, Test loss: 1.522, Test accuracy: 95.10 

Round  25, Train loss: 1.472, Test loss: 1.519, Test accuracy: 95.40 

Round  26, Train loss: 1.470, Test loss: 1.518, Test accuracy: 95.47 

Round  27, Train loss: 1.472, Test loss: 1.514, Test accuracy: 95.70 

Round  28, Train loss: 1.467, Test loss: 1.514, Test accuracy: 95.60 

Round  29, Train loss: 1.470, Test loss: 1.511, Test accuracy: 95.93 

Round  30, Train loss: 1.465, Test loss: 1.510, Test accuracy: 96.02 

Round  31, Train loss: 1.468, Test loss: 1.509, Test accuracy: 96.03 

Round  32, Train loss: 1.465, Test loss: 1.509, Test accuracy: 96.03 

Round  33, Train loss: 1.467, Test loss: 1.509, Test accuracy: 95.92 

Round  34, Train loss: 1.469, Test loss: 1.509, Test accuracy: 96.05 

Round  35, Train loss: 1.469, Test loss: 1.508, Test accuracy: 96.05 

Round  36, Train loss: 1.467, Test loss: 1.509, Test accuracy: 96.08 

Round  37, Train loss: 1.469, Test loss: 1.508, Test accuracy: 96.12 

Round  38, Train loss: 1.465, Test loss: 1.507, Test accuracy: 96.15 

Round  39, Train loss: 1.467, Test loss: 1.508, Test accuracy: 96.10 

Round  40, Train loss: 1.467, Test loss: 1.508, Test accuracy: 96.05 

Round  41, Train loss: 1.467, Test loss: 1.507, Test accuracy: 96.15 

Round  42, Train loss: 1.466, Test loss: 1.507, Test accuracy: 96.13 

Round  43, Train loss: 1.466, Test loss: 1.506, Test accuracy: 96.22 

Round  44, Train loss: 1.465, Test loss: 1.505, Test accuracy: 96.17 

Round  45, Train loss: 1.468, Test loss: 1.505, Test accuracy: 96.23 

Round  46, Train loss: 1.467, Test loss: 1.505, Test accuracy: 96.23 

Round  47, Train loss: 1.468, Test loss: 1.505, Test accuracy: 96.22 

Round  48, Train loss: 1.469, Test loss: 1.504, Test accuracy: 96.23 

Round  49, Train loss: 1.467, Test loss: 1.504, Test accuracy: 96.25 

Round  50, Train loss: 1.466, Test loss: 1.504, Test accuracy: 96.25 

Round  51, Train loss: 1.465, Test loss: 1.504, Test accuracy: 96.20 

Round  52, Train loss: 1.467, Test loss: 1.504, Test accuracy: 96.18 

Round  53, Train loss: 1.466, Test loss: 1.504, Test accuracy: 96.17 

Round  54, Train loss: 1.466, Test loss: 1.504, Test accuracy: 96.17 

Round  55, Train loss: 1.464, Test loss: 1.504, Test accuracy: 96.17 

Round  56, Train loss: 1.466, Test loss: 1.504, Test accuracy: 96.15 

Round  57, Train loss: 1.465, Test loss: 1.504, Test accuracy: 96.15 

Round  58, Train loss: 1.466, Test loss: 1.504, Test accuracy: 96.12 

Round  59, Train loss: 1.468, Test loss: 1.504, Test accuracy: 96.13 

Round  60, Train loss: 1.466, Test loss: 1.504, Test accuracy: 96.10 

Round  61, Train loss: 1.464, Test loss: 1.504, Test accuracy: 96.08 

Round  62, Train loss: 1.464, Test loss: 1.504, Test accuracy: 96.08 

Round  63, Train loss: 1.464, Test loss: 1.504, Test accuracy: 96.10 

Round  64, Train loss: 1.464, Test loss: 1.503, Test accuracy: 96.12 

Round  65, Train loss: 1.467, Test loss: 1.503, Test accuracy: 96.10 

Round  66, Train loss: 1.464, Test loss: 1.503, Test accuracy: 96.07 

Round  67, Train loss: 1.466, Test loss: 1.503, Test accuracy: 96.12 

Round  68, Train loss: 1.464, Test loss: 1.503, Test accuracy: 96.10 

Round  69, Train loss: 1.463, Test loss: 1.503, Test accuracy: 96.13 

Round  70, Train loss: 1.465, Test loss: 1.503, Test accuracy: 96.12 

Round  71, Train loss: 1.464, Test loss: 1.503, Test accuracy: 96.13 

Round  72, Train loss: 1.466, Test loss: 1.503, Test accuracy: 96.17 

Round  73, Train loss: 1.463, Test loss: 1.503, Test accuracy: 96.10 

Round  74, Train loss: 1.467, Test loss: 1.503, Test accuracy: 96.08 

Round  75, Train loss: 1.464, Test loss: 1.503, Test accuracy: 96.07 

Round  76, Train loss: 1.466, Test loss: 1.503, Test accuracy: 96.10 

Round  77, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.15 

Round  78, Train loss: 1.465, Test loss: 1.502, Test accuracy: 96.17 

Round  79, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.15 

Round  80, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.12 

Round  81, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.15 

Round  82, Train loss: 1.464, Test loss: 1.502, Test accuracy: 96.13 

Round  83, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.13 

Round  84, Train loss: 1.465, Test loss: 1.502, Test accuracy: 96.15 

Round  85, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.13 

Round  86, Train loss: 1.462, Test loss: 1.502, Test accuracy: 96.12 

Round  87, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.07 

Round  88, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.08 

Round  89, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.08 

Round  90, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.08 

Round  91, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.12 

Round  92, Train loss: 1.462, Test loss: 1.502, Test accuracy: 96.13 

Round  93, Train loss: 1.465, Test loss: 1.502, Test accuracy: 96.08 

Round  94, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.08 

Round  95, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.08 

Round  96, Train loss: 1.466, Test loss: 1.502, Test accuracy: 96.05 

Round  97, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.07 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  98, Train loss: 1.465, Test loss: 1.502, Test accuracy: 96.10 

Round  99, Train loss: 1.463, Test loss: 1.502, Test accuracy: 96.05 

Final Round, Train loss: 1.464, Test loss: 1.502, Test accuracy: 96.07 

Average accuracy final 10 rounds: 96.08500000000001 

358.64313077926636
[0.5279321670532227, 0.9512014389038086, 1.3768362998962402, 1.8062431812286377, 2.235044479370117, 2.663041591644287, 3.0864241123199463, 3.5141937732696533, 3.938239812850952, 4.359075307846069, 4.780979871749878, 5.201689958572388, 5.621843099594116, 6.040114402770996, 6.458812713623047, 6.879122734069824, 7.300556898117065, 7.722277879714966, 8.142597198486328, 8.564425706863403, 8.990268468856812, 9.41714358329773, 9.839752912521362, 10.262095928192139, 10.68423080444336, 11.110254764556885, 11.535784721374512, 11.958146572113037, 12.382630825042725, 12.801054000854492, 13.220933675765991, 13.645616292953491, 14.069008588790894, 14.491708278656006, 14.917783737182617, 15.339933633804321, 15.758283615112305, 16.17758011817932, 16.599409103393555, 17.023074626922607, 17.447972774505615, 17.871020317077637, 18.29684567451477, 18.72079372406006, 19.14639186859131, 19.569833040237427, 19.99014925956726, 20.40875267982483, 20.831190824508667, 21.25513768196106, 21.677509784698486, 22.09923553466797, 22.520821809768677, 22.94666600227356, 23.36863946914673, 23.728736400604248, 24.08902406692505, 24.451231241226196, 24.81224274635315, 25.172178745269775, 25.531372547149658, 25.89382028579712, 26.256433963775635, 26.619609355926514, 26.978986024856567, 27.34373164176941, 27.706736087799072, 28.072357177734375, 28.438671588897705, 28.8053936958313, 29.170060634613037, 29.53125548362732, 29.893503189086914, 30.255117177963257, 30.617520093917847, 30.984321355819702, 31.34704303741455, 31.709530115127563, 32.07209539413452, 32.434609174728394, 32.795085191726685, 33.160035610198975, 33.52705645561218, 33.890071630477905, 34.25345969200134, 34.61654782295227, 34.982269287109375, 35.34828042984009, 35.7110013961792, 36.0770423412323, 36.441858768463135, 36.80258512496948, 37.16482949256897, 37.526899099349976, 37.89272356033325, 38.25517249107361, 38.61704397201538, 38.98050498962402, 39.34314680099487, 39.70443367958069, 40.39975881576538]
[30.283333333333335, 27.833333333333332, 46.483333333333334, 54.25, 60.36666666666667, 65.75, 68.08333333333333, 72.31666666666666, 75.63333333333334, 78.03333333333333, 80.45, 84.01666666666667, 86.16666666666667, 87.58333333333333, 87.6, 88.51666666666667, 88.48333333333333, 91.18333333333334, 91.8, 94.0, 94.43333333333334, 94.93333333333334, 95.11666666666666, 95.1, 95.1, 95.4, 95.46666666666667, 95.7, 95.6, 95.93333333333334, 96.01666666666667, 96.03333333333333, 96.03333333333333, 95.91666666666667, 96.05, 96.05, 96.08333333333333, 96.11666666666666, 96.15, 96.1, 96.05, 96.15, 96.13333333333334, 96.21666666666667, 96.16666666666667, 96.23333333333333, 96.23333333333333, 96.21666666666667, 96.23333333333333, 96.25, 96.25, 96.2, 96.18333333333334, 96.16666666666667, 96.16666666666667, 96.16666666666667, 96.15, 96.15, 96.11666666666666, 96.13333333333334, 96.1, 96.08333333333333, 96.08333333333333, 96.1, 96.11666666666666, 96.1, 96.06666666666666, 96.11666666666666, 96.1, 96.13333333333334, 96.11666666666666, 96.13333333333334, 96.16666666666667, 96.1, 96.08333333333333, 96.06666666666666, 96.1, 96.15, 96.16666666666667, 96.15, 96.11666666666666, 96.15, 96.13333333333334, 96.13333333333334, 96.15, 96.13333333333334, 96.11666666666666, 96.06666666666666, 96.08333333333333, 96.08333333333333, 96.08333333333333, 96.11666666666666, 96.13333333333334, 96.08333333333333, 96.08333333333333, 96.08333333333333, 96.05, 96.06666666666666, 96.1, 96.05, 96.06666666666666]
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

Traceback (most recent call last):
  File "main_fedpac.py", line 61, in <module>
    dataset_train.targets = np.load('data/sample/dataset_train_target.npy', allow_pickle=True)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/lib/npyio.py", line 417, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'data/sample/dataset_train_target.npy'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.292, Test loss: 2.291, Test accuracy: 18.33
Round   1, Train loss: 2.211, Test loss: 2.232, Test accuracy: 18.33
Round   2, Train loss: 2.055, Test loss: 2.184, Test accuracy: 28.33
Round   3, Train loss: 1.947, Test loss: 2.079, Test accuracy: 48.40
Round   4, Train loss: 1.644, Test loss: 1.957, Test accuracy: 57.27
Round   5, Train loss: 1.664, Test loss: 1.900, Test accuracy: 62.55
Round   6, Train loss: 1.614, Test loss: 1.927, Test accuracy: 56.38
Round   7, Train loss: 1.624, Test loss: 1.867, Test accuracy: 64.92
Round   8, Train loss: 1.629, Test loss: 1.848, Test accuracy: 67.05
Round   9, Train loss: 1.611, Test loss: 1.830, Test accuracy: 64.88
Round  10, Train loss: 1.550, Test loss: 1.810, Test accuracy: 65.90
Round  11, Train loss: 1.550, Test loss: 1.813, Test accuracy: 66.60
Round  12, Train loss: 1.611, Test loss: 1.749, Test accuracy: 74.23
Round  13, Train loss: 1.554, Test loss: 1.778, Test accuracy: 69.77
Round  14, Train loss: 1.494, Test loss: 1.805, Test accuracy: 66.27
Round  15, Train loss: 1.607, Test loss: 1.725, Test accuracy: 77.15
Round  16, Train loss: 1.599, Test loss: 1.737, Test accuracy: 74.57
Round  17, Train loss: 1.597, Test loss: 1.733, Test accuracy: 76.15
Round  18, Train loss: 1.591, Test loss: 1.709, Test accuracy: 78.52
Round  19, Train loss: 1.642, Test loss: 1.706, Test accuracy: 78.43
Round  20, Train loss: 1.543, Test loss: 1.721, Test accuracy: 75.20
Round  21, Train loss: 1.642, Test loss: 1.696, Test accuracy: 79.78
Round  22, Train loss: 1.590, Test loss: 1.715, Test accuracy: 77.47
Round  23, Train loss: 1.533, Test loss: 1.687, Test accuracy: 80.35
Round  24, Train loss: 1.490, Test loss: 1.739, Test accuracy: 73.73
Round  25, Train loss: 1.538, Test loss: 1.694, Test accuracy: 79.43
Round  26, Train loss: 1.488, Test loss: 1.685, Test accuracy: 79.77
Round  27, Train loss: 1.584, Test loss: 1.708, Test accuracy: 77.53
Round  28, Train loss: 1.527, Test loss: 1.726, Test accuracy: 74.58
Round  29, Train loss: 1.585, Test loss: 1.691, Test accuracy: 77.83
Round  30, Train loss: 1.691, Test loss: 1.695, Test accuracy: 78.38
Round  31, Train loss: 1.536, Test loss: 1.672, Test accuracy: 81.08
Round  32, Train loss: 1.582, Test loss: 1.663, Test accuracy: 81.82
Round  33, Train loss: 1.587, Test loss: 1.659, Test accuracy: 81.97
Round  34, Train loss: 1.481, Test loss: 1.660, Test accuracy: 81.92
Round  35, Train loss: 1.527, Test loss: 1.672, Test accuracy: 80.28
Round  36, Train loss: 1.478, Test loss: 1.654, Test accuracy: 82.12
Round  37, Train loss: 1.638, Test loss: 1.662, Test accuracy: 80.98
Round  38, Train loss: 1.585, Test loss: 1.665, Test accuracy: 80.93
Round  39, Train loss: 1.633, Test loss: 1.653, Test accuracy: 82.48
Round  40, Train loss: 1.529, Test loss: 1.664, Test accuracy: 81.65
Round  41, Train loss: 1.634, Test loss: 1.681, Test accuracy: 79.45
Round  42, Train loss: 1.580, Test loss: 1.661, Test accuracy: 81.27
Round  43, Train loss: 1.687, Test loss: 1.666, Test accuracy: 81.00
Round  44, Train loss: 1.640, Test loss: 1.641, Test accuracy: 83.53
Round  45, Train loss: 1.524, Test loss: 1.655, Test accuracy: 81.68
Round  46, Train loss: 1.584, Test loss: 1.662, Test accuracy: 81.47
Round  47, Train loss: 1.474, Test loss: 1.656, Test accuracy: 81.18
Round  48, Train loss: 1.579, Test loss: 1.664, Test accuracy: 81.45
Round  49, Train loss: 1.631, Test loss: 1.655, Test accuracy: 81.87
Round  50, Train loss: 1.473, Test loss: 1.644, Test accuracy: 82.83
Round  51, Train loss: 1.584, Test loss: 1.638, Test accuracy: 83.35
Round  52, Train loss: 1.579, Test loss: 1.650, Test accuracy: 82.47
Round  53, Train loss: 1.579, Test loss: 1.644, Test accuracy: 82.75
Round  54, Train loss: 1.529, Test loss: 1.673, Test accuracy: 80.58
Round  55, Train loss: 1.686, Test loss: 1.645, Test accuracy: 82.90
Round  56, Train loss: 1.579, Test loss: 1.651, Test accuracy: 82.07
Round  57, Train loss: 1.527, Test loss: 1.659, Test accuracy: 81.05
Round  58, Train loss: 1.530, Test loss: 1.647, Test accuracy: 81.98
Round  59, Train loss: 1.580, Test loss: 1.644, Test accuracy: 83.15
Round  60, Train loss: 1.523, Test loss: 1.669, Test accuracy: 79.88
Round  61, Train loss: 1.579, Test loss: 1.668, Test accuracy: 80.23
Round  62, Train loss: 1.633, Test loss: 1.638, Test accuracy: 83.48
Round  63, Train loss: 1.631, Test loss: 1.646, Test accuracy: 82.85
Round  64, Train loss: 1.576, Test loss: 1.640, Test accuracy: 83.28
Round  65, Train loss: 1.629, Test loss: 1.659, Test accuracy: 81.50
Round  66, Train loss: 1.527, Test loss: 1.635, Test accuracy: 83.40
Round  67, Train loss: 1.523, Test loss: 1.633, Test accuracy: 84.13
Round  68, Train loss: 1.578, Test loss: 1.644, Test accuracy: 82.82
Round  69, Train loss: 1.579, Test loss: 1.637, Test accuracy: 83.42
Round  70, Train loss: 1.471, Test loss: 1.640, Test accuracy: 82.73
Round  71, Train loss: 1.579, Test loss: 1.642, Test accuracy: 82.62
Round  72, Train loss: 1.577, Test loss: 1.662, Test accuracy: 80.70
Round  73, Train loss: 1.633, Test loss: 1.633, Test accuracy: 83.73
Round  74, Train loss: 1.683, Test loss: 1.666, Test accuracy: 81.00
Round  75, Train loss: 1.631, Test loss: 1.646, Test accuracy: 82.88
Round  76, Train loss: 1.576, Test loss: 1.639, Test accuracy: 83.38
Round  77, Train loss: 1.527, Test loss: 1.653, Test accuracy: 81.88
Round  78, Train loss: 1.634, Test loss: 1.641, Test accuracy: 82.93
Round  79, Train loss: 1.627, Test loss: 1.650, Test accuracy: 82.03
Round  80, Train loss: 1.578, Test loss: 1.639, Test accuracy: 83.27
Round  81, Train loss: 1.576, Test loss: 1.640, Test accuracy: 83.18
Round  82, Train loss: 1.576, Test loss: 1.636, Test accuracy: 83.48
Round  83, Train loss: 1.628, Test loss: 1.634, Test accuracy: 83.73
Round  84, Train loss: 1.629, Test loss: 1.642, Test accuracy: 82.77
Round  85, Train loss: 1.580, Test loss: 1.628, Test accuracy: 84.18
Round  86, Train loss: 1.522, Test loss: 1.637, Test accuracy: 83.47
Round  87, Train loss: 1.576, Test loss: 1.649, Test accuracy: 82.35
Round  88, Train loss: 1.576, Test loss: 1.681, Test accuracy: 78.97
Round  89, Train loss: 1.576, Test loss: 1.653, Test accuracy: 82.05
Round  90, Train loss: 1.521, Test loss: 1.635, Test accuracy: 83.38
Round  91, Train loss: 1.522, Test loss: 1.634, Test accuracy: 83.87
Round  92, Train loss: 1.633, Test loss: 1.629, Test accuracy: 83.85
Round  93, Train loss: 1.580, Test loss: 1.633, Test accuracy: 83.95
Round  94, Train loss: 1.574, Test loss: 1.632, Test accuracy: 83.82
Round  95, Train loss: 1.520, Test loss: 1.633, Test accuracy: 83.50
Round  96, Train loss: 1.521, Test loss: 1.632, Test accuracy: 83.87
Round  97, Train loss: 1.520, Test loss: 1.642, Test accuracy: 83.03
Round  98, Train loss: 1.682, Test loss: 1.645, Test accuracy: 82.77
Round  99, Train loss: 1.523, Test loss: 1.640, Test accuracy: 82.88
Final Round, Train loss: 1.565, Test loss: 1.627, Test accuracy: 84.45
Average accuracy final 10 rounds: 83.49166666666667
809.0955154895782
[1.253711462020874, 2.414515256881714, 3.5751378536224365, 4.738646745681763, 5.906495094299316, 7.072554349899292, 8.238714456558228, 9.404232740402222, 10.569958448410034, 11.734250545501709, 12.89771580696106, 14.064743518829346, 15.227779865264893, 16.395472288131714, 17.557989835739136, 18.71928644180298, 19.881272554397583, 21.041422843933105, 22.191922664642334, 23.34247350692749, 24.494624853134155, 25.6561598777771, 26.68976593017578, 27.723973989486694, 28.756577491760254, 29.783839464187622, 30.81217050552368, 31.844746112823486, 32.87603425979614, 33.90723705291748, 34.94038248062134, 35.97256898880005, 37.00694251060486, 38.03919005393982, 39.06298899650574, 40.10939955711365, 41.162572145462036, 42.244741678237915, 43.505621910095215, 44.75324749946594, 46.00644111633301, 47.26443362236023, 48.46909022331238, 49.73365235328674, 50.83978867530823, 52.37520384788513, 53.57159447669983, 54.89513039588928, 56.1992130279541, 57.492453813552856, 58.79818677902222, 60.06922650337219, 61.372530460357666, 62.52875328063965, 63.7910373210907, 65.05372667312622, 66.30214858055115, 67.59039235115051, 68.82551431655884, 70.06869316101074, 71.30595326423645, 72.54274034500122, 73.74621891975403, 74.99166011810303, 76.18302369117737, 77.36585068702698, 78.52599883079529, 79.69458818435669, 80.84870910644531, 82.00555038452148, 83.158531665802, 84.3376624584198, 85.48642897605896, 86.68845057487488, 87.86824059486389, 89.05151677131653, 90.20020246505737, 91.34335207939148, 92.37306475639343, 93.41327095031738, 94.44024610519409, 95.46727299690247, 96.49389839172363, 97.52969145774841, 98.56609559059143, 99.63889122009277, 100.69592213630676, 101.77445411682129, 102.84824442863464, 103.92634987831116, 104.96237468719482, 105.99547243118286, 107.02492094039917, 108.04828596115112, 109.07347178459167, 110.0959587097168, 111.1151192188263, 112.14251184463501, 113.17547464370728, 114.20954656600952, 115.24362921714783]/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[18.333333333333332, 18.333333333333332, 28.333333333333332, 48.4, 57.266666666666666, 62.55, 56.38333333333333, 64.91666666666667, 67.05, 64.88333333333334, 65.9, 66.6, 74.23333333333333, 69.76666666666667, 66.26666666666667, 77.15, 74.56666666666666, 76.15, 78.51666666666667, 78.43333333333334, 75.2, 79.78333333333333, 77.46666666666667, 80.35, 73.73333333333333, 79.43333333333334, 79.76666666666667, 77.53333333333333, 74.58333333333333, 77.83333333333333, 78.38333333333334, 81.08333333333333, 81.81666666666666, 81.96666666666667, 81.91666666666667, 80.28333333333333, 82.11666666666666, 80.98333333333333, 80.93333333333334, 82.48333333333333, 81.65, 79.45, 81.26666666666667, 81.0, 83.53333333333333, 81.68333333333334, 81.46666666666667, 81.18333333333334, 81.45, 81.86666666666666, 82.83333333333333, 83.35, 82.46666666666667, 82.75, 80.58333333333333, 82.9, 82.06666666666666, 81.05, 81.98333333333333, 83.15, 79.88333333333334, 80.23333333333333, 83.48333333333333, 82.85, 83.28333333333333, 81.5, 83.4, 84.13333333333334, 82.81666666666666, 83.41666666666667, 82.73333333333333, 82.61666666666666, 80.7, 83.73333333333333, 81.0, 82.88333333333334, 83.38333333333334, 81.88333333333334, 82.93333333333334, 82.03333333333333, 83.26666666666667, 83.18333333333334, 83.48333333333333, 83.73333333333333, 82.76666666666667, 84.18333333333334, 83.46666666666667, 82.35, 78.96666666666667, 82.05, 83.38333333333334, 83.86666666666666, 83.85, 83.95, 83.81666666666666, 83.5, 83.86666666666666, 83.03333333333333, 82.76666666666667, 82.88333333333334, 84.45]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.541, Test loss: 2.248, Test accuracy: 51.47
Round   1, Train loss: 1.276, Test loss: 2.086, Test accuracy: 64.60
Round   2, Train loss: 1.304, Test loss: 1.958, Test accuracy: 65.87
Round   3, Train loss: 1.190, Test loss: 1.919, Test accuracy: 67.87
Round   4, Train loss: 1.306, Test loss: 1.840, Test accuracy: 76.73
Round   5, Train loss: 1.255, Test loss: 1.784, Test accuracy: 80.33
Round   6, Train loss: 1.240, Test loss: 1.748, Test accuracy: 81.83
Round   7, Train loss: 1.197, Test loss: 1.755, Test accuracy: 79.37
Round   8, Train loss: 1.254, Test loss: 1.706, Test accuracy: 84.93
Round   9, Train loss: 1.159, Test loss: 1.674, Test accuracy: 87.23
Round  10, Train loss: 1.114, Test loss: 1.663, Test accuracy: 86.80
Round  11, Train loss: 1.144, Test loss: 1.657, Test accuracy: 86.97
Round  12, Train loss: 1.188, Test loss: 1.656, Test accuracy: 86.50
Round  13, Train loss: 1.113, Test loss: 1.648, Test accuracy: 86.57
Round  14, Train loss: 1.151, Test loss: 1.640, Test accuracy: 86.65
Round  15, Train loss: 1.107, Test loss: 1.635, Test accuracy: 86.68
Round  16, Train loss: 1.193, Test loss: 1.633, Test accuracy: 86.65
Round  17, Train loss: 1.145, Test loss: 1.629, Test accuracy: 86.78
Round  18, Train loss: 1.225, Test loss: 1.625, Test accuracy: 86.93
Round  19, Train loss: 1.268, Test loss: 1.625, Test accuracy: 86.83
Round  20, Train loss: 1.147, Test loss: 1.624, Test accuracy: 87.02
Round  21, Train loss: 1.102, Test loss: 1.624, Test accuracy: 86.55
Round  22, Train loss: 1.103, Test loss: 1.623, Test accuracy: 86.73
Round  23, Train loss: 1.143, Test loss: 1.624, Test accuracy: 86.37
Round  24, Train loss: 1.183, Test loss: 1.621, Test accuracy: 86.78
Round  25, Train loss: 1.184, Test loss: 1.619, Test accuracy: 86.85
Round  26, Train loss: 1.144, Test loss: 1.622, Test accuracy: 86.27
Round  27, Train loss: 1.142, Test loss: 1.621, Test accuracy: 86.35
Round  28, Train loss: 1.142, Test loss: 1.624, Test accuracy: 86.15
Round  29, Train loss: 1.141, Test loss: 1.625, Test accuracy: 85.92
Round  30, Train loss: 1.143, Test loss: 1.625, Test accuracy: 85.80
Round  31, Train loss: 1.140, Test loss: 1.625, Test accuracy: 85.70
Round  32, Train loss: 1.182, Test loss: 1.624, Test accuracy: 85.75
Round  33, Train loss: 1.185, Test loss: 1.623, Test accuracy: 85.78
Round  34, Train loss: 1.183, Test loss: 1.622, Test accuracy: 85.92
Round  35, Train loss: 1.101, Test loss: 1.623, Test accuracy: 85.55
Round  36, Train loss: 1.142, Test loss: 1.619, Test accuracy: 86.02
Round  37, Train loss: 1.182, Test loss: 1.622, Test accuracy: 85.47
Round  38, Train loss: 1.141, Test loss: 1.620, Test accuracy: 85.65
Round  39, Train loss: 1.182, Test loss: 1.621, Test accuracy: 85.30
Round  40, Train loss: 1.101, Test loss: 1.620, Test accuracy: 85.43
Round  41, Train loss: 1.183, Test loss: 1.618, Test accuracy: 85.77
Round  42, Train loss: 1.102, Test loss: 1.619, Test accuracy: 85.55
Round  43, Train loss: 1.141, Test loss: 1.617, Test accuracy: 85.98
Round  44, Train loss: 1.101, Test loss: 1.619, Test accuracy: 85.78
Round  45, Train loss: 1.141, Test loss: 1.620, Test accuracy: 85.53
Round  46, Train loss: 1.184, Test loss: 1.607, Test accuracy: 87.05
Round  47, Train loss: 1.101, Test loss: 1.608, Test accuracy: 86.90
Round  48, Train loss: 1.142, Test loss: 1.609, Test accuracy: 86.85
Round  49, Train loss: 1.142, Test loss: 1.610, Test accuracy: 86.72
Round  50, Train loss: 1.183, Test loss: 1.610, Test accuracy: 86.48
Round  51, Train loss: 1.182, Test loss: 1.609, Test accuracy: 86.62
Round  52, Train loss: 1.100, Test loss: 1.609, Test accuracy: 86.58
Round  53, Train loss: 1.182, Test loss: 1.608, Test accuracy: 86.58
Round  54, Train loss: 1.143, Test loss: 1.607, Test accuracy: 86.73
Round  55, Train loss: 1.181, Test loss: 1.608, Test accuracy: 86.68
Round  56, Train loss: 1.181, Test loss: 1.609, Test accuracy: 86.70
Round  57, Train loss: 1.185, Test loss: 1.611, Test accuracy: 86.62
Round  58, Train loss: 1.141, Test loss: 1.608, Test accuracy: 86.83
Round  59, Train loss: 1.142, Test loss: 1.608, Test accuracy: 86.72
Round  60, Train loss: 1.181, Test loss: 1.608, Test accuracy: 86.77
Round  61, Train loss: 1.183, Test loss: 1.608, Test accuracy: 86.48
Round  62, Train loss: 1.100, Test loss: 1.610, Test accuracy: 86.43
Round  63, Train loss: 1.100, Test loss: 1.610, Test accuracy: 86.42
Round  64, Train loss: 1.219, Test loss: 1.603, Test accuracy: 87.23
Round  65, Train loss: 1.144, Test loss: 1.598, Test accuracy: 87.73
Round  66, Train loss: 1.100, Test loss: 1.598, Test accuracy: 87.67
Round  67, Train loss: 1.140, Test loss: 1.600, Test accuracy: 87.42
Round  68, Train loss: 1.192, Test loss: 1.590, Test accuracy: 88.72
Round  69, Train loss: 1.140, Test loss: 1.590, Test accuracy: 88.82
Round  70, Train loss: 1.142, Test loss: 1.589, Test accuracy: 88.75
Round  71, Train loss: 1.186, Test loss: 1.587, Test accuracy: 88.82
Round  72, Train loss: 1.101, Test loss: 1.591, Test accuracy: 88.53
Round  73, Train loss: 1.139, Test loss: 1.588, Test accuracy: 88.80
Round  74, Train loss: 1.142, Test loss: 1.590, Test accuracy: 88.52
Round  75, Train loss: 1.143, Test loss: 1.591, Test accuracy: 88.48
Round  76, Train loss: 1.143, Test loss: 1.591, Test accuracy: 88.35
Round  77, Train loss: 1.185, Test loss: 1.590, Test accuracy: 88.25
Round  78, Train loss: 1.142, Test loss: 1.590, Test accuracy: 88.37
Round  79, Train loss: 1.141, Test loss: 1.589, Test accuracy: 88.43
Round  80, Train loss: 1.182, Test loss: 1.588, Test accuracy: 88.63
Round  81, Train loss: 1.141, Test loss: 1.589, Test accuracy: 88.40
Round  82, Train loss: 1.101, Test loss: 1.591, Test accuracy: 88.23
Round  83, Train loss: 1.140, Test loss: 1.588, Test accuracy: 88.40
Round  84, Train loss: 1.141, Test loss: 1.587, Test accuracy: 88.58
Round  85, Train loss: 1.182, Test loss: 1.589, Test accuracy: 88.50
Round  86, Train loss: 1.224, Test loss: 1.589, Test accuracy: 88.37
Round  87, Train loss: 1.143, Test loss: 1.589, Test accuracy: 88.35
Round  88, Train loss: 1.141, Test loss: 1.590, Test accuracy: 88.20
Round  89, Train loss: 1.143, Test loss: 1.590, Test accuracy: 88.17
Round  90, Train loss: 1.098, Test loss: 1.591, Test accuracy: 88.17
Round  91, Train loss: 1.180, Test loss: 1.589, Test accuracy: 88.30
Round  92, Train loss: 1.100, Test loss: 1.589, Test accuracy: 88.33
Round  93, Train loss: 1.182, Test loss: 1.595, Test accuracy: 87.62
Round  94, Train loss: 1.142, Test loss: 1.594, Test accuracy: 87.70
Round  95, Train loss: 1.140, Test loss: 1.594, Test accuracy: 87.88
Round  96, Train loss: 1.143, Test loss: 1.592, Test accuracy: 88.03
Round  97, Train loss: 1.185, Test loss: 1.593, Test accuracy: 87.87
Round  98, Train loss: 1.182, Test loss: 1.592, Test accuracy: 87.93
Round  99, Train loss: 1.140, Test loss: 1.592, Test accuracy: 87.92
Final Round, Train loss: 1.137, Test loss: 1.593, Test accuracy: 87.87
Average accuracy final 10 rounds: 87.97500000000001
713.2499766349792
[]
[51.46666666666667, 64.6, 65.86666666666666, 67.86666666666666, 76.73333333333333, 80.33333333333333, 81.83333333333333, 79.36666666666666, 84.93333333333334, 87.23333333333333, 86.8, 86.96666666666667, 86.5, 86.56666666666666, 86.65, 86.68333333333334, 86.65, 86.78333333333333, 86.93333333333334, 86.83333333333333, 87.01666666666667, 86.55, 86.73333333333333, 86.36666666666666, 86.78333333333333, 86.85, 86.26666666666667, 86.35, 86.15, 85.91666666666667, 85.8, 85.7, 85.75, 85.78333333333333, 85.91666666666667, 85.55, 86.01666666666667, 85.46666666666667, 85.65, 85.3, 85.43333333333334, 85.76666666666667, 85.55, 85.98333333333333, 85.78333333333333, 85.53333333333333, 87.05, 86.9, 86.85, 86.71666666666667, 86.48333333333333, 86.61666666666666, 86.58333333333333, 86.58333333333333, 86.73333333333333, 86.68333333333334, 86.7, 86.61666666666666, 86.83333333333333, 86.71666666666667, 86.76666666666667, 86.48333333333333, 86.43333333333334, 86.41666666666667, 87.23333333333333, 87.73333333333333, 87.66666666666667, 87.41666666666667, 88.71666666666667, 88.81666666666666, 88.75, 88.81666666666666, 88.53333333333333, 88.8, 88.51666666666667, 88.48333333333333, 88.35, 88.25, 88.36666666666666, 88.43333333333334, 88.63333333333334, 88.4, 88.23333333333333, 88.4, 88.58333333333333, 88.5, 88.36666666666666, 88.35, 88.2, 88.16666666666667, 88.16666666666667, 88.3, 88.33333333333333, 87.61666666666666, 87.7, 87.88333333333334, 88.03333333333333, 87.86666666666666, 87.93333333333334, 87.91666666666667, 87.86666666666666]/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.291, Test loss: 2.291, Test accuracy: 18.50
Round   0: Global train loss: 2.291, Global test loss: 2.302, Global test accuracy: 13.60
Round   1, Train loss: 2.280, Test loss: 2.270, Test accuracy: 30.63
Round   1: Global train loss: 2.280, Global test loss: 2.302, Global test accuracy: 14.32
Round   2, Train loss: 2.236, Test loss: 2.252, Test accuracy: 25.47
Round   2: Global train loss: 2.236, Global test loss: 2.301, Global test accuracy: 15.53
Round   3, Train loss: 2.216, Test loss: 2.253, Test accuracy: 22.42
Round   3: Global train loss: 2.216, Global test loss: 2.301, Global test accuracy: 16.80
Round   4, Train loss: 2.205, Test loss: 2.238, Test accuracy: 20.35
Round   4: Global train loss: 2.205, Global test loss: 2.301, Global test accuracy: 18.10
Round   5, Train loss: 2.140, Test loss: 2.187, Test accuracy: 21.97
Round   5: Global train loss: 2.140, Global test loss: 2.300, Global test accuracy: 17.83
Round   6, Train loss: 2.068, Test loss: 2.101, Test accuracy: 35.70
Round   6: Global train loss: 2.068, Global test loss: 2.299, Global test accuracy: 26.30
Round   7, Train loss: 2.120, Test loss: 2.126, Test accuracy: 31.55
Round   7: Global train loss: 2.120, Global test loss: 2.299, Global test accuracy: 26.97
Round   8, Train loss: 1.959, Test loss: 2.148, Test accuracy: 29.40
Round   8: Global train loss: 1.959, Global test loss: 2.300, Global test accuracy: 20.92
Round   9, Train loss: 1.563, Test loss: 2.123, Test accuracy: 31.98
Round   9: Global train loss: 1.563, Global test loss: 2.299, Global test accuracy: 25.90
Round  10, Train loss: 1.564, Test loss: 2.066, Test accuracy: 37.68
Round  10: Global train loss: 1.564, Global test loss: 2.298, Global test accuracy: 27.55
Round  11, Train loss: 1.439, Test loss: 2.027, Test accuracy: 46.23
Round  11: Global train loss: 1.439, Global test loss: 2.297, Global test accuracy: 31.88
Round  12, Train loss: 1.686, Test loss: 2.054, Test accuracy: 45.60
Round  12: Global train loss: 1.686, Global test loss: 2.297, Global test accuracy: 31.00
Round  13, Train loss: 0.772, Test loss: 1.964, Test accuracy: 54.35
Round  13: Global train loss: 0.772, Global test loss: 2.295, Global test accuracy: 35.83
Round  14, Train loss: 1.755, Test loss: 2.065, Test accuracy: 47.43
Round  14: Global train loss: 1.755, Global test loss: 2.297, Global test accuracy: 32.98
Round  15, Train loss: 0.668, Test loss: 2.000, Test accuracy: 50.50
Round  15: Global train loss: 0.668, Global test loss: 2.296, Global test accuracy: 31.77
Round  16, Train loss: 1.026, Test loss: 1.909, Test accuracy: 60.78
Round  16: Global train loss: 1.026, Global test loss: 2.293, Global test accuracy: 37.17
Round  17, Train loss: 0.891, Test loss: 1.903, Test accuracy: 61.62
Round  17: Global train loss: 0.891, Global test loss: 2.292, Global test accuracy: 39.72
Round  18, Train loss: 1.259, Test loss: 2.024, Test accuracy: 52.98
Round  18: Global train loss: 1.259, Global test loss: 2.295, Global test accuracy: 30.22
Round  19, Train loss: 0.527, Test loss: 1.935, Test accuracy: 59.87
Round  19: Global train loss: 0.527, Global test loss: 2.294, Global test accuracy: 25.93
Round  20, Train loss: -0.097, Test loss: 1.926, Test accuracy: 60.35
Round  20: Global train loss: -0.097, Global test loss: 2.294, Global test accuracy: 28.82
Round  21, Train loss: -0.110, Test loss: 1.915, Test accuracy: 58.88
Round  21: Global train loss: -0.110, Global test loss: 2.293, Global test accuracy: 30.20
Round  22, Train loss: -0.061, Test loss: 1.917, Test accuracy: 58.80
Round  22: Global train loss: -0.061, Global test loss: 2.292, Global test accuracy: 22.30
Round  23, Train loss: -0.483, Test loss: 1.829, Test accuracy: 66.55
Round  23: Global train loss: -0.483, Global test loss: 2.287, Global test accuracy: 15.58
Round  24, Train loss: -0.983, Test loss: 1.796, Test accuracy: 69.63
Round  24: Global train loss: -0.983, Global test loss: 2.279, Global test accuracy: 23.08
Round  25, Train loss: 0.577, Test loss: 1.865, Test accuracy: 61.85
Round  25: Global train loss: 0.577, Global test loss: 2.284, Global test accuracy: 17.60
Round  26, Train loss: 0.063, Test loss: 1.864, Test accuracy: 62.67
Round  26: Global train loss: 0.063, Global test loss: 2.283, Global test accuracy: 21.65
Round  27, Train loss: -0.440, Test loss: 1.889, Test accuracy: 59.58
Round  27: Global train loss: -0.440, Global test loss: 2.284, Global test accuracy: 26.22
Round  28, Train loss: -0.970, Test loss: 1.775, Test accuracy: 68.82
Round  28: Global train loss: -0.970, Global test loss: 2.271, Global test accuracy: 25.88
Round  29, Train loss: -0.376, Test loss: 1.764, Test accuracy: 70.38
Round  29: Global train loss: -0.376, Global test loss: 2.267, Global test accuracy: 25.38
Round  30, Train loss: -0.993, Test loss: 1.783, Test accuracy: 70.20
Round  30: Global train loss: -0.993, Global test loss: 2.264, Global test accuracy: 30.20
Round  31, Train loss: -0.138, Test loss: 1.807, Test accuracy: 66.75
Round  31: Global train loss: -0.138, Global test loss: 2.264, Global test accuracy: 30.58
Round  32, Train loss: -1.353, Test loss: 1.780, Test accuracy: 69.80
Round  32: Global train loss: -1.353, Global test loss: 2.261, Global test accuracy: 30.20
Round  33, Train loss: -1.727, Test loss: 1.688, Test accuracy: 79.10
Round  33: Global train loss: -1.727, Global test loss: 2.247, Global test accuracy: 31.75
Round  34, Train loss: -1.406, Test loss: 1.659, Test accuracy: 83.83
Round  34: Global train loss: -1.406, Global test loss: 2.238, Global test accuracy: 30.35
Round  35, Train loss: 0.008, Test loss: 1.708, Test accuracy: 79.10
Round  35: Global train loss: 0.008, Global test loss: 2.249, Global test accuracy: 30.20
Round  36, Train loss: -0.913, Test loss: 1.702, Test accuracy: 79.42
Round  36: Global train loss: -0.913, Global test loss: 2.252, Global test accuracy: 30.13
Round  37, Train loss: -1.359, Test loss: 1.656, Test accuracy: 82.47
Round  37: Global train loss: -1.359, Global test loss: 2.246, Global test accuracy: 29.25
Round  38, Train loss: -1.458, Test loss: 1.683, Test accuracy: 79.28
Round  38: Global train loss: -1.458, Global test loss: 2.255, Global test accuracy: 28.42
Round  39, Train loss: -1.894, Test loss: 1.677, Test accuracy: 79.38
Round  39: Global train loss: -1.894, Global test loss: 2.254, Global test accuracy: 23.73
Round  40, Train loss: -2.858, Test loss: 1.656, Test accuracy: 81.35
Round  40: Global train loss: -2.858, Global test loss: 2.247, Global test accuracy: 27.92
Round  41, Train loss: -2.586, Test loss: 1.627, Test accuracy: 84.12
Round  41: Global train loss: -2.586, Global test loss: 2.237, Global test accuracy: 28.18
Round  42, Train loss: -1.825, Test loss: 1.640, Test accuracy: 82.98
Round  42: Global train loss: -1.825, Global test loss: 2.237, Global test accuracy: 30.10
Round  43, Train loss: -1.300, Test loss: 1.657, Test accuracy: 82.17
Round  43: Global train loss: -1.300, Global test loss: 2.247, Global test accuracy: 34.97
Round  44, Train loss: -1.572, Test loss: 1.674, Test accuracy: 79.25
Round  44: Global train loss: -1.572, Global test loss: 2.250, Global test accuracy: 32.32
Round  45, Train loss: -2.069, Test loss: 1.695, Test accuracy: 76.47
Round  45: Global train loss: -2.069, Global test loss: 2.253, Global test accuracy: 36.20
Round  46, Train loss: -2.953, Test loss: 1.659, Test accuracy: 79.60
Round  46: Global train loss: -2.953, Global test loss: 2.250, Global test accuracy: 36.52
Round  47, Train loss: -2.381, Test loss: 1.643, Test accuracy: 81.17
Round  47: Global train loss: -2.381, Global test loss: 2.249, Global test accuracy: 37.40
Round  48, Train loss: -2.803, Test loss: 1.616, Test accuracy: 84.08
Round  48: Global train loss: -2.803, Global test loss: 2.241, Global test accuracy: 36.30
Round  49, Train loss: -3.247, Test loss: 1.636, Test accuracy: 82.33
Round  49: Global train loss: -3.247, Global test loss: 2.238, Global test accuracy: 35.82
Round  50, Train loss: -2.673, Test loss: 1.634, Test accuracy: 82.33
Round  50: Global train loss: -2.673, Global test loss: 2.241, Global test accuracy: 37.10
Round  51, Train loss: -2.788, Test loss: 1.638, Test accuracy: 82.08
Round  51: Global train loss: -2.788, Global test loss: 2.244, Global test accuracy: 37.32
Round  52, Train loss: -3.664, Test loss: 1.591, Test accuracy: 86.93
Round  52: Global train loss: -3.664, Global test loss: 2.243, Global test accuracy: 37.53
Round  53, Train loss: -3.565, Test loss: 1.592, Test accuracy: 87.15
Round  53: Global train loss: -3.565, Global test loss: 2.244, Global test accuracy: 38.67
Round  54, Train loss: -3.816, Test loss: 1.605, Test accuracy: 85.80
Round  54: Global train loss: -3.816, Global test loss: 2.242, Global test accuracy: 37.05
Round  55, Train loss: -2.466, Test loss: 1.615, Test accuracy: 84.60
Round  55: Global train loss: -2.466, Global test loss: 2.235, Global test accuracy: 36.00
Round  56, Train loss: -3.346, Test loss: 1.582, Test accuracy: 87.63
Round  56: Global train loss: -3.346, Global test loss: 2.227, Global test accuracy: 36.15
Round  57, Train loss: -3.267, Test loss: 1.602, Test accuracy: 85.45
Round  57: Global train loss: -3.267, Global test loss: 2.223, Global test accuracy: 36.17
Round  58, Train loss: -2.734, Test loss: 1.557, Test accuracy: 90.40
Round  58: Global train loss: -2.734, Global test loss: 2.219, Global test accuracy: 36.18
Round  59, Train loss: -3.668, Test loss: 1.588, Test accuracy: 87.22
Round  59: Global train loss: -3.668, Global test loss: 2.217, Global test accuracy: 36.60
Round  60, Train loss: -3.518, Test loss: 1.574, Test accuracy: 88.65
Round  60: Global train loss: -3.518, Global test loss: 2.210, Global test accuracy: 36.65
Round  61, Train loss: -3.095, Test loss: 1.574, Test accuracy: 88.78
Round  61: Global train loss: -3.095, Global test loss: 2.207, Global test accuracy: 31.63
Round  62, Train loss: -5.398, Test loss: 1.556, Test accuracy: 90.63
Round  62: Global train loss: -5.398, Global test loss: 2.196, Global test accuracy: 28.38
Round  63, Train loss: -3.662, Test loss: 1.555, Test accuracy: 90.60
Round  63: Global train loss: -3.662, Global test loss: 2.189, Global test accuracy: 28.20
Round  64, Train loss: -3.189, Test loss: 1.583, Test accuracy: 87.60
Round  64: Global train loss: -3.189, Global test loss: 2.184, Global test accuracy: 28.47
Round  65, Train loss: -4.173, Test loss: 1.539, Test accuracy: 92.23
Round  65: Global train loss: -4.173, Global test loss: 2.175, Global test accuracy: 29.17
Round  66, Train loss: -3.443, Test loss: 1.561, Test accuracy: 90.65
Round  66: Global train loss: -3.443, Global test loss: 2.174, Global test accuracy: 29.60
Round  67, Train loss: -4.084, Test loss: 1.555, Test accuracy: 90.57
Round  67: Global train loss: -4.084, Global test loss: 2.159, Global test accuracy: 32.90
Round  68, Train loss: -3.227, Test loss: 1.556, Test accuracy: 90.53
Round  68: Global train loss: -3.227, Global test loss: 2.153, Global test accuracy: 35.58
Round  69, Train loss: -3.646, Test loss: 1.571, Test accuracy: 89.17
Round  69: Global train loss: -3.646, Global test loss: 2.133, Global test accuracy: 43.38
Round  70, Train loss: -3.906, Test loss: 1.545, Test accuracy: 91.80
Round  70: Global train loss: -3.906, Global test loss: 2.123, Global test accuracy: 48.05
Round  71, Train loss: -4.194, Test loss: 1.562, Test accuracy: 90.07
Round  71: Global train loss: -4.194, Global test loss: 2.115, Global test accuracy: 50.08
Round  72, Train loss: -3.818, Test loss: 1.576, Test accuracy: 88.62
Round  72: Global train loss: -3.818, Global test loss: 2.102, Global test accuracy: 50.92
Round  73, Train loss: -3.919, Test loss: 1.590, Test accuracy: 87.30
Round  73: Global train loss: -3.919, Global test loss: 2.082, Global test accuracy: 51.37
Round  74, Train loss: -2.798, Test loss: 1.557, Test accuracy: 90.52
Round  74: Global train loss: -2.798, Global test loss: 2.069, Global test accuracy: 52.93
Round  75, Train loss: -3.395, Test loss: 1.561, Test accuracy: 90.12
Round  75: Global train loss: -3.395, Global test loss: 2.063, Global test accuracy: 53.17
Round  76, Train loss: -3.643, Test loss: 1.542, Test accuracy: 92.03
Round  76: Global train loss: -3.643, Global test loss: 2.055, Global test accuracy: 52.70
Round  77, Train loss: -2.472, Test loss: 1.541, Test accuracy: 92.03
Round  77: Global train loss: -2.472, Global test loss: 2.056, Global test accuracy: 53.43
Round  78, Train loss: -2.658, Test loss: 1.572, Test accuracy: 88.97
Round  78: Global train loss: -2.658, Global test loss: 2.063, Global test accuracy: 52.30
Round  79, Train loss: -3.012, Test loss: 1.588, Test accuracy: 87.40
Round  79: Global train loss: -3.012, Global test loss: 2.056, Global test accuracy: 51.95
Round  80, Train loss: -2.296, Test loss: 1.572, Test accuracy: 89.00
Round  80: Global train loss: -2.296, Global test loss: 2.049, Global test accuracy: 52.37
Round  81, Train loss: -3.189, Test loss: 1.541, Test accuracy: 92.07
Round  81: Global train loss: -3.189, Global test loss: 2.041, Global test accuracy: 52.58
Round  82, Train loss: -2.340, Test loss: 1.556, Test accuracy: 90.47
Round  82: Global train loss: -2.340, Global test loss: 2.051, Global test accuracy: 50.12
Round  83, Train loss: -2.878, Test loss: 1.554, Test accuracy: 90.75
Round  83: Global train loss: -2.878, Global test loss: 2.031, Global test accuracy: 53.48
Round  84, Train loss: -2.529, Test loss: 1.552, Test accuracy: 90.93
Round  84: Global train loss: -2.529, Global test loss: 2.023, Global test accuracy: 53.18
Round  85, Train loss: -2.338, Test loss: 1.555, Test accuracy: 90.65
Round  85: Global train loss: -2.338, Global test loss: 2.022, Global test accuracy: 53.47
Round  86, Train loss: -2.595, Test loss: 1.567, Test accuracy: 89.40
Round  86: Global train loss: -2.595, Global test loss: 2.018, Global test accuracy: 55.12
Round  87, Train loss: -2.266, Test loss: 1.552, Test accuracy: 90.85
Round  87: Global train loss: -2.266, Global test loss: 2.018, Global test accuracy: 57.18
Round  88, Train loss: -2.239, Test loss: 1.536, Test accuracy: 92.53
Round  88: Global train loss: -2.239, Global test loss: 2.005, Global test accuracy: 58.80
Round  89, Train loss: -2.693, Test loss: 1.569, Test accuracy: 89.25
Round  89: Global train loss: -2.693, Global test loss: 2.004, Global test accuracy: 58.70
Round  90, Train loss: -2.208, Test loss: 1.555, Test accuracy: 90.60
Round  90: Global train loss: -2.208, Global test loss: 2.008, Global test accuracy: 57.15
Round  91, Train loss: -2.872, Test loss: 1.554, Test accuracy: 90.68
Round  91: Global train loss: -2.872, Global test loss: 2.013, Global test accuracy: 55.02
Round  92, Train loss: -2.017, Test loss: 1.557, Test accuracy: 90.37
Round  92: Global train loss: -2.017, Global test loss: 2.002, Global test accuracy: 57.75
Round  93, Train loss: -2.722, Test loss: 1.541, Test accuracy: 92.00
Round  93: Global train loss: -2.722, Global test loss: 1.996, Global test accuracy: 59.73
Round  94, Train loss: -2.268, Test loss: 1.555, Test accuracy: 90.58
Round  94: Global train loss: -2.268, Global test loss: 1.992, Global test accuracy: 59.83
Round  95, Train loss: -2.907, Test loss: 1.557, Test accuracy: 90.40
Round  95: Global train loss: -2.907, Global test loss: 1.987, Global test accuracy: 59.87
Round  96, Train loss: -1.855, Test loss: 1.570, Test accuracy: 89.15
Round  96: Global train loss: -1.855, Global test loss: 1.989, Global test accuracy: 57.77
Round  97, Train loss: -2.088, Test loss: 1.601, Test accuracy: 86.03
Round  97: Global train loss: -2.088, Global test loss: 1.993, Global test accuracy: 56.67
Round  98, Train loss: -2.414, Test loss: 1.587, Test accuracy: 87.37
Round  98: Global train loss: -2.414, Global test loss: 1.980, Global test accuracy: 58.32/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: -2.556, Test loss: 1.571, Test accuracy: 88.97
Round  99: Global train loss: -2.556, Global test loss: 1.984, Global test accuracy: 57.08
Final Round: Train loss: 1.675, Test loss: 1.656, Test accuracy: 81.20
Final Round: Global train loss: 1.675, Global test loss: 1.975, Global test accuracy: 57.90
Average accuracy final 10 rounds: 89.615
Average global accuracy final 10 rounds: 57.91833333333333
569.5412840843201
[]
[18.5, 30.633333333333333, 25.466666666666665, 22.416666666666668, 20.35, 21.966666666666665, 35.7, 31.55, 29.4, 31.983333333333334, 37.68333333333333, 46.233333333333334, 45.6, 54.35, 47.43333333333333, 50.5, 60.78333333333333, 61.61666666666667, 52.983333333333334, 59.86666666666667, 60.35, 58.88333333333333, 58.8, 66.55, 69.63333333333334, 61.85, 62.666666666666664, 59.583333333333336, 68.81666666666666, 70.38333333333334, 70.2, 66.75, 69.8, 79.1, 83.83333333333333, 79.1, 79.41666666666667, 82.46666666666667, 79.28333333333333, 79.38333333333334, 81.35, 84.11666666666666, 82.98333333333333, 82.16666666666667, 79.25, 76.46666666666667, 79.6, 81.16666666666667, 84.08333333333333, 82.33333333333333, 82.33333333333333, 82.08333333333333, 86.93333333333334, 87.15, 85.8, 84.6, 87.63333333333334, 85.45, 90.4, 87.21666666666667, 88.65, 88.78333333333333, 90.63333333333334, 90.6, 87.6, 92.23333333333333, 90.65, 90.56666666666666, 90.53333333333333, 89.16666666666667, 91.8, 90.06666666666666, 88.61666666666666, 87.3, 90.51666666666667, 90.11666666666666, 92.03333333333333, 92.03333333333333, 88.96666666666667, 87.4, 89.0, 92.06666666666666, 90.46666666666667, 90.75, 90.93333333333334, 90.65, 89.4, 90.85, 92.53333333333333, 89.25, 90.6, 90.68333333333334, 90.36666666666666, 92.0, 90.58333333333333, 90.4, 89.15, 86.03333333333333, 87.36666666666666, 88.96666666666667, 81.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.48 

Round   0, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.43 

Round   1, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.57 

Round   1, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.48 

Round   2, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.72 

Round   2, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.55 

Round   3, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.75 

Round   3, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.73 

Round   4, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.82 

Round   4, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.77 

Round   5, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.87 

Round   5, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.98 

Round   6, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.93 

Round   6, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.03 

Round   7, Train loss: 2.301, Test loss: 2.301, Test accuracy: 9.20 

Round   7, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.07 

Round   8, Train loss: 2.302, Test loss: 2.301, Test accuracy: 9.32 

Round   8, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.23 

Round   9, Train loss: 2.299, Test loss: 2.301, Test accuracy: 9.33 

Round   9, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 9.33 

Round  10, Train loss: 2.299, Test loss: 2.301, Test accuracy: 9.45 

Round  10, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 9.40 

Round  11, Train loss: 2.301, Test loss: 2.301, Test accuracy: 9.60 

Round  11, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 9.47 

Round  12, Train loss: 2.300, Test loss: 2.301, Test accuracy: 9.80 

Round  12, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 9.70 

Round  13, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00 

Round  13, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 9.93 

Round  14, Train loss: 2.303, Test loss: 2.301, Test accuracy: 10.15 

Round  14, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 10.12 

Round  15, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.22 

Round  15, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 10.17 

Round  16, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.38 

Round  16, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 10.18 

Round  17, Train loss: 2.299, Test loss: 2.301, Test accuracy: 10.48 

Round  17, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 10.33 

Round  18, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.47 

Round  18, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 10.48 

Round  19, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.70 

Round  19, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.48 

Round  20, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.73 

Round  20, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.72 

Round  21, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.83 

Round  21, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.00 

Round  22, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.00 

Round  22, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.13 

Round  23, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.32 

Round  23, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.48 

Round  24, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.50 

Round  24, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.75 

Round  25, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.95 

Round  25, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.00 

Round  26, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.32 

Round  26, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.17 

Round  27, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.62 

Round  27, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.47 

Round  28, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.68 

Round  28, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.52 

Round  29, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.75 

Round  29, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.67 

Round  30, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.85 

Round  30, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.83 

Round  31, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.15 

Round  31, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.90 

Round  32, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.17 

Round  32, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.17 

Round  33, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.23 

Round  33, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.22 

Round  34, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.42 

Round  34, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.33 

Round  35, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.65 

Round  35, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.65 

Round  36, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.92 

Round  36, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 13.85 

Round  37, Train loss: 2.298, Test loss: 2.301, Test accuracy: 14.57 

Round  37, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 14.23 

Round  38, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.93 

Round  38, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.42 

Round  39, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.10 

Round  39, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.65 

Round  40, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.25 

Round  40, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.93 

Round  41, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.35 

Round  41, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.10 

Round  42, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.75 

Round  42, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.33 

Round  43, Train loss: 2.298, Test loss: 2.301, Test accuracy: 16.17 

Round  43, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 15.45 

Round  44, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.27 

Round  44, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.55 

Round  45, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.50 

Round  45, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.73 

Round  46, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.52 

Round  46, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.78 

Round  47, Train loss: 2.299, Test loss: 2.301, Test accuracy: 16.72 

Round  47, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 15.83 

Round  48, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.05 

Round  48, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.28 

Round  49, Train loss: 2.299, Test loss: 2.301, Test accuracy: 17.15 

Round  49, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 16.33 

Round  50, Train loss: 2.297, Test loss: 2.300, Test accuracy: 17.48 

Round  50, Global train loss: 2.297, Global test loss: 2.301, Global test accuracy: 16.83 

Round  51, Train loss: 2.299, Test loss: 2.300, Test accuracy: 17.55 

Round  51, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 16.93 

Round  52, Train loss: 2.302, Test loss: 2.300, Test accuracy: 17.48 

Round  52, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 17.37 

Round  53, Train loss: 2.298, Test loss: 2.300, Test accuracy: 17.78 

Round  53, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 17.67 

Round  54, Train loss: 2.299, Test loss: 2.300, Test accuracy: 17.88 

Round  54, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 17.85 

Round  55, Train loss: 2.301, Test loss: 2.300, Test accuracy: 18.10 

Round  55, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 17.90 

Round  56, Train loss: 2.301, Test loss: 2.300, Test accuracy: 18.37 

Round  56, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 18.38 

Round  57, Train loss: 2.300, Test loss: 2.300, Test accuracy: 18.82 

Round  57, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 18.50 

Round  58, Train loss: 2.304, Test loss: 2.300, Test accuracy: 18.85 

Round  58, Global train loss: 2.304, Global test loss: 2.300, Global test accuracy: 18.48 

Round  59, Train loss: 2.299, Test loss: 2.300, Test accuracy: 19.17 

Round  59, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 18.78 

Round  60, Train loss: 2.298, Test loss: 2.300, Test accuracy: 19.25 

Round  60, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 18.78 

Round  61, Train loss: 2.299, Test loss: 2.300, Test accuracy: 19.55 

Round  61, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 18.95 

Round  62, Train loss: 2.298, Test loss: 2.300, Test accuracy: 19.57 

Round  62, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 19.25 

Round  63, Train loss: 2.303, Test loss: 2.300, Test accuracy: 19.73 

Round  63, Global train loss: 2.303, Global test loss: 2.300, Global test accuracy: 19.55 

Round  64, Train loss: 2.299, Test loss: 2.300, Test accuracy: 19.98 

Round  64, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 19.57 

Round  65, Train loss: 2.299, Test loss: 2.300, Test accuracy: 20.42 

Round  65, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 19.88 

Round  66, Train loss: 2.302, Test loss: 2.300, Test accuracy: 20.83 

Round  66, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 20.12 

Round  67, Train loss: 2.297, Test loss: 2.300, Test accuracy: 20.95 

Round  67, Global train loss: 2.297, Global test loss: 2.300, Global test accuracy: 20.33 

Round  68, Train loss: 2.300, Test loss: 2.300, Test accuracy: 21.30 

Round  68, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 20.63 

Round  69, Train loss: 2.301, Test loss: 2.300, Test accuracy: 21.52 

Round  69, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 20.97 

Round  70, Train loss: 2.298, Test loss: 2.300, Test accuracy: 21.80 

Round  70, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 21.00 

Round  71, Train loss: 2.302, Test loss: 2.300, Test accuracy: 22.12 

Round  71, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 21.28 

Round  72, Train loss: 2.300, Test loss: 2.300, Test accuracy: 22.05 

Round  72, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 21.50 

Round  73, Train loss: 2.299, Test loss: 2.300, Test accuracy: 22.37 

Round  73, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 21.72 

Round  74, Train loss: 2.300, Test loss: 2.300, Test accuracy: 22.63 

Round  74, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 21.65 

Round  75, Train loss: 2.301, Test loss: 2.300, Test accuracy: 22.78 

Round  75, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 21.82 

Round  76, Train loss: 2.298, Test loss: 2.300, Test accuracy: 23.05 

Round  76, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 22.03 

Round  77, Train loss: 2.298, Test loss: 2.300, Test accuracy: 23.08 

Round  77, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 22.22 

Round  78, Train loss: 2.300, Test loss: 2.300, Test accuracy: 22.87 

Round  78, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 22.27 

Round  79, Train loss: 2.298, Test loss: 2.300, Test accuracy: 23.07 

Round  79, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 22.45 

Round  80, Train loss: 2.298, Test loss: 2.300, Test accuracy: 23.05 

Round  80, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 22.48 

Round  81, Train loss: 2.299, Test loss: 2.300, Test accuracy: 23.30 

Round  81, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 22.52 

Round  82, Train loss: 2.299, Test loss: 2.300, Test accuracy: 23.72 

Round  82, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 22.97 

Round  83, Train loss: 2.298, Test loss: 2.300, Test accuracy: 24.05 

Round  83, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 23.10 

Round  84, Train loss: 2.299, Test loss: 2.300, Test accuracy: 23.77 

Round  84, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 23.13 

Round  85, Train loss: 2.301, Test loss: 2.300, Test accuracy: 23.70 

Round  85, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 23.12 

Round  86, Train loss: 2.299, Test loss: 2.300, Test accuracy: 23.92 

Round  86, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 23.55 

Round  87, Train loss: 2.300, Test loss: 2.300, Test accuracy: 24.12 

Round  87, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 23.53 

Round  88, Train loss: 2.300, Test loss: 2.300, Test accuracy: 24.27 

Round  88, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 23.70 

Round  89, Train loss: 2.299, Test loss: 2.299, Test accuracy: 24.43 

Round  89, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 23.73 

Round  90, Train loss: 2.300, Test loss: 2.299, Test accuracy: 24.42 

Round  90, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 23.70 

Round  91, Train loss: 2.299, Test loss: 2.299, Test accuracy: 24.43 

Round  91, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 23.55 

Round  92, Train loss: 2.299, Test loss: 2.299, Test accuracy: 24.47 

Round  92, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 23.50 

Round  93, Train loss: 2.299, Test loss: 2.299, Test accuracy: 24.47 

Round  93, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 23.62 

Round  94, Train loss: 2.300, Test loss: 2.299, Test accuracy: 24.67 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 23.60 

Round  95, Train loss: 2.297, Test loss: 2.299, Test accuracy: 24.52 

Round  95, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 23.80 

Round  96, Train loss: 2.301, Test loss: 2.299, Test accuracy: 24.60 

Round  96, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 23.98 

Round  97, Train loss: 2.301, Test loss: 2.299, Test accuracy: 24.72 

Round  97, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 23.93 

Round  98, Train loss: 2.298, Test loss: 2.299, Test accuracy: 24.52 

Round  98, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 23.98 

Round  99, Train loss: 2.300, Test loss: 2.299, Test accuracy: 24.62 

Round  99, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 23.82 

Final Round, Train loss: 2.299, Test loss: 2.299, Test accuracy: 24.95 

Final Round, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 23.82 

Average accuracy final 10 rounds: 24.541666666666668 

Average global accuracy final 10 rounds: 23.748333333333335 

479.47752475738525
[0.57059645652771, 1.043327808380127, 1.5117125511169434, 1.9619567394256592, 2.434229612350464, 2.911006212234497, 3.394981622695923, 3.872039794921875, 4.349535703659058, 4.8256003856658936, 5.2348878383636475, 5.643101453781128, 6.051394701004028, 6.459501028060913, 6.867003917694092, 7.274859189987183, 7.68065333366394, 8.088284492492676, 8.496371746063232, 8.904867172241211, 9.311609029769897, 9.719275712966919, 10.126625299453735, 10.545853853225708, 10.968177318572998, 11.376188278198242, 11.781049489974976, 12.188665866851807, 12.59577465057373, 13.002969741821289, 13.409915685653687, 13.816579580307007, 14.224286794662476, 14.632715225219727, 15.039331197738647, 15.447477340698242, 15.854295253753662, 16.261775732040405, 16.669992923736572, 17.07791256904602, 17.495431661605835, 17.921196222305298, 18.32900619506836, 18.7369065284729, 19.14463186264038, 19.55226230621338, 19.962833881378174, 20.370069980621338, 20.7763409614563, 21.182780504226685, 21.63744306564331, 22.042970895767212, 22.44994616508484, 22.878531455993652, 23.29972267150879, 23.706968784332275, 24.114416122436523, 24.521865129470825, 24.929279804229736, 25.336437940597534, 25.745044708251953, 26.152020692825317, 26.55942130088806, 26.96567416191101, 27.372048377990723, 27.778620958328247, 28.18748140335083, 28.59406018257141, 29.00074863433838, 29.407283782958984, 29.818723917007446, 30.22626280784607, 30.63303852081299, 31.062881469726562, 31.469529390335083, 31.875474214553833, 32.28282904624939, 32.688852071762085, 33.09511065483093, 33.501800298690796, 33.90885591506958, 34.315043449401855, 34.72194981575012, 35.132333517074585, 35.53832530975342, 35.96759343147278, 36.40034103393555, 36.80673432350159, 37.213204860687256, 37.620041847229004, 38.02641773223877, 38.43391680717468, 38.84029769897461, 39.24752616882324, 39.654194831848145, 40.0614800453186, 40.46854066848755, 40.875242471694946, 41.28325891494751, 41.69138479232788, 42.49666619300842]
[8.483333333333333, 8.566666666666666, 8.716666666666667, 8.75, 8.816666666666666, 8.866666666666667, 8.933333333333334, 9.2, 9.316666666666666, 9.333333333333334, 9.45, 9.6, 9.8, 10.0, 10.15, 10.216666666666667, 10.383333333333333, 10.483333333333333, 10.466666666666667, 10.7, 10.733333333333333, 10.833333333333334, 11.0, 11.316666666666666, 11.5, 11.95, 12.316666666666666, 12.616666666666667, 12.683333333333334, 12.75, 12.85, 13.15, 13.166666666666666, 13.233333333333333, 13.416666666666666, 13.65, 13.916666666666666, 14.566666666666666, 14.933333333333334, 15.1, 15.25, 15.35, 15.75, 16.166666666666668, 16.266666666666666, 16.5, 16.516666666666666, 16.716666666666665, 17.05, 17.15, 17.483333333333334, 17.55, 17.483333333333334, 17.783333333333335, 17.883333333333333, 18.1, 18.366666666666667, 18.816666666666666, 18.85, 19.166666666666668, 19.25, 19.55, 19.566666666666666, 19.733333333333334, 19.983333333333334, 20.416666666666668, 20.833333333333332, 20.95, 21.3, 21.516666666666666, 21.8, 22.116666666666667, 22.05, 22.366666666666667, 22.633333333333333, 22.783333333333335, 23.05, 23.083333333333332, 22.866666666666667, 23.066666666666666, 23.05, 23.3, 23.716666666666665, 24.05, 23.766666666666666, 23.7, 23.916666666666668, 24.116666666666667, 24.266666666666666, 24.433333333333334, 24.416666666666668, 24.433333333333334, 24.466666666666665, 24.466666666666665, 24.666666666666668, 24.516666666666666, 24.6, 24.716666666666665, 24.516666666666666, 24.616666666666667, 24.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.262, Test accuracy: 37.47 

Round   0, Global train loss: 2.288, Global test loss: 2.265, Global test accuracy: 33.40 

Round   1, Train loss: 2.110, Test loss: 2.096, Test accuracy: 43.97 

Round   1, Global train loss: 2.110, Global test loss: 2.100, Global test accuracy: 33.92 

Round   2, Train loss: 1.788, Test loss: 1.984, Test accuracy: 52.50 

Round   2, Global train loss: 1.788, Global test loss: 2.066, Global test accuracy: 37.72 

Round   3, Train loss: 1.662, Test loss: 1.871, Test accuracy: 65.22 

Round   3, Global train loss: 1.662, Global test loss: 2.046, Global test accuracy: 40.47 

Round   4, Train loss: 1.566, Test loss: 1.799, Test accuracy: 73.33 

Round   4, Global train loss: 1.566, Global test loss: 2.063, Global test accuracy: 37.95 

Round   5, Train loss: 1.634, Test loss: 1.756, Test accuracy: 75.70 

Round   5, Global train loss: 1.634, Global test loss: 2.045, Global test accuracy: 40.67 

Round   6, Train loss: 1.653, Test loss: 1.719, Test accuracy: 79.45 

Round   6, Global train loss: 1.653, Global test loss: 2.047, Global test accuracy: 40.70 

Round   7, Train loss: 1.723, Test loss: 1.669, Test accuracy: 84.80 

Round   7, Global train loss: 1.723, Global test loss: 2.100, Global test accuracy: 32.88 

Round   8, Train loss: 1.503, Test loss: 1.654, Test accuracy: 85.22 

Round   8, Global train loss: 1.503, Global test loss: 2.052, Global test accuracy: 41.12 

Round   9, Train loss: 1.567, Test loss: 1.631, Test accuracy: 87.22 

Round   9, Global train loss: 1.567, Global test loss: 2.041, Global test accuracy: 40.58 

Round  10, Train loss: 1.528, Test loss: 1.630, Test accuracy: 87.25 

Round  10, Global train loss: 1.528, Global test loss: 2.007, Global test accuracy: 47.22 

Round  11, Train loss: 1.485, Test loss: 1.625, Test accuracy: 87.42 

Round  11, Global train loss: 1.485, Global test loss: 2.029, Global test accuracy: 42.57 

Round  12, Train loss: 1.475, Test loss: 1.623, Test accuracy: 87.45 

Round  12, Global train loss: 1.475, Global test loss: 2.050, Global test accuracy: 41.38 

Round  13, Train loss: 1.625, Test loss: 1.606, Test accuracy: 90.15 

Round  13, Global train loss: 1.625, Global test loss: 2.053, Global test accuracy: 40.42 

Round  14, Train loss: 1.578, Test loss: 1.591, Test accuracy: 89.88 

Round  14, Global train loss: 1.578, Global test loss: 2.019, Global test accuracy: 46.05 

Round  15, Train loss: 1.546, Test loss: 1.559, Test accuracy: 91.47 

Round  15, Global train loss: 1.546, Global test loss: 2.035, Global test accuracy: 42.37 

Round  16, Train loss: 1.474, Test loss: 1.559, Test accuracy: 91.43 

Round  16, Global train loss: 1.474, Global test loss: 2.064, Global test accuracy: 38.23 

Round  17, Train loss: 1.546, Test loss: 1.555, Test accuracy: 91.38 

Round  17, Global train loss: 1.546, Global test loss: 2.030, Global test accuracy: 43.03 

Round  18, Train loss: 1.579, Test loss: 1.555, Test accuracy: 91.30 

Round  18, Global train loss: 1.579, Global test loss: 2.091, Global test accuracy: 34.10 

Round  19, Train loss: 1.522, Test loss: 1.556, Test accuracy: 91.23 

Round  19, Global train loss: 1.522, Global test loss: 2.033, Global test accuracy: 41.55 

Round  20, Train loss: 1.501, Test loss: 1.541, Test accuracy: 92.82 

Round  20, Global train loss: 1.501, Global test loss: 2.018, Global test accuracy: 44.62 

Round  21, Train loss: 1.479, Test loss: 1.539, Test accuracy: 92.92 

Round  21, Global train loss: 1.479, Global test loss: 2.047, Global test accuracy: 40.12 

Round  22, Train loss: 1.468, Test loss: 1.539, Test accuracy: 92.92 

Round  22, Global train loss: 1.468, Global test loss: 2.053, Global test accuracy: 39.68 

Round  23, Train loss: 1.482, Test loss: 1.538, Test accuracy: 92.95 

Round  23, Global train loss: 1.482, Global test loss: 2.026, Global test accuracy: 44.90 

Round  24, Train loss: 1.471, Test loss: 1.538, Test accuracy: 93.05 

Round  24, Global train loss: 1.471, Global test loss: 2.059, Global test accuracy: 39.77 

Round  25, Train loss: 1.465, Test loss: 1.538, Test accuracy: 93.05 

Round  25, Global train loss: 1.465, Global test loss: 2.036, Global test accuracy: 41.42 

Round  26, Train loss: 1.468, Test loss: 1.537, Test accuracy: 93.07 

Round  26, Global train loss: 1.468, Global test loss: 2.000, Global test accuracy: 46.18 

Round  27, Train loss: 1.469, Test loss: 1.537, Test accuracy: 93.03 

Round  27, Global train loss: 1.469, Global test loss: 2.079, Global test accuracy: 35.98 

Round  28, Train loss: 1.467, Test loss: 1.537, Test accuracy: 93.02 

Round  28, Global train loss: 1.467, Global test loss: 2.034, Global test accuracy: 41.58 

Round  29, Train loss: 1.469, Test loss: 1.536, Test accuracy: 93.00 

Round  29, Global train loss: 1.469, Global test loss: 2.078, Global test accuracy: 36.95 

Round  30, Train loss: 1.524, Test loss: 1.536, Test accuracy: 92.98 

Round  30, Global train loss: 1.524, Global test loss: 2.030, Global test accuracy: 42.92 

Round  31, Train loss: 1.465, Test loss: 1.536, Test accuracy: 93.02 

Round  31, Global train loss: 1.465, Global test loss: 2.004, Global test accuracy: 45.40 

Round  32, Train loss: 1.507, Test loss: 1.525, Test accuracy: 94.30 

Round  32, Global train loss: 1.507, Global test loss: 2.025, Global test accuracy: 43.48 

Round  33, Train loss: 1.471, Test loss: 1.523, Test accuracy: 94.47 

Round  33, Global train loss: 1.471, Global test loss: 2.043, Global test accuracy: 41.30 

Round  34, Train loss: 1.466, Test loss: 1.522, Test accuracy: 94.50 

Round  34, Global train loss: 1.466, Global test loss: 1.994, Global test accuracy: 46.52 

Round  35, Train loss: 1.464, Test loss: 1.523, Test accuracy: 94.47 

Round  35, Global train loss: 1.464, Global test loss: 2.078, Global test accuracy: 36.87 

Round  36, Train loss: 1.467, Test loss: 1.522, Test accuracy: 94.43 

Round  36, Global train loss: 1.467, Global test loss: 2.025, Global test accuracy: 43.38 

Round  37, Train loss: 1.465, Test loss: 1.522, Test accuracy: 94.45 

Round  37, Global train loss: 1.465, Global test loss: 2.082, Global test accuracy: 34.92 

Round  38, Train loss: 1.465, Test loss: 1.522, Test accuracy: 94.47 

Round  38, Global train loss: 1.465, Global test loss: 2.079, Global test accuracy: 37.07 

Round  39, Train loss: 1.464, Test loss: 1.521, Test accuracy: 94.52 

Round  39, Global train loss: 1.464, Global test loss: 2.059, Global test accuracy: 38.97 

Round  40, Train loss: 1.464, Test loss: 1.521, Test accuracy: 94.50 

Round  40, Global train loss: 1.464, Global test loss: 2.038, Global test accuracy: 41.35 

Round  41, Train loss: 1.464, Test loss: 1.522, Test accuracy: 94.40 

Round  41, Global train loss: 1.464, Global test loss: 2.082, Global test accuracy: 35.73 

Round  42, Train loss: 1.467, Test loss: 1.521, Test accuracy: 94.42 

Round  42, Global train loss: 1.467, Global test loss: 2.050, Global test accuracy: 40.33 

Round  43, Train loss: 1.467, Test loss: 1.521, Test accuracy: 94.42 

Round  43, Global train loss: 1.467, Global test loss: 2.030, Global test accuracy: 42.43 

Round  44, Train loss: 1.465, Test loss: 1.521, Test accuracy: 94.43 

Round  44, Global train loss: 1.465, Global test loss: 2.041, Global test accuracy: 41.65 

Round  45, Train loss: 1.467, Test loss: 1.520, Test accuracy: 94.47 

Round  45, Global train loss: 1.467, Global test loss: 2.046, Global test accuracy: 40.78 

Round  46, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.47 

Round  46, Global train loss: 1.463, Global test loss: 2.047, Global test accuracy: 40.93 

Round  47, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.48 

Round  47, Global train loss: 1.465, Global test loss: 2.035, Global test accuracy: 42.00 

Round  48, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.47 

Round  48, Global train loss: 1.465, Global test loss: 2.021, Global test accuracy: 42.87 

Round  49, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.48 

Round  49, Global train loss: 1.465, Global test loss: 2.083, Global test accuracy: 34.65 

Round  50, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.48 

Round  50, Global train loss: 1.465, Global test loss: 2.061, Global test accuracy: 39.07 

Round  51, Train loss: 1.466, Test loss: 1.520, Test accuracy: 94.47 

Round  51, Global train loss: 1.466, Global test loss: 2.074, Global test accuracy: 38.23 

Round  52, Train loss: 1.466, Test loss: 1.520, Test accuracy: 94.48 

Round  52, Global train loss: 1.466, Global test loss: 2.078, Global test accuracy: 36.27 

Round  53, Train loss: 1.467, Test loss: 1.520, Test accuracy: 94.45 

Round  53, Global train loss: 1.467, Global test loss: 2.055, Global test accuracy: 39.82 

Round  54, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.47 

Round  54, Global train loss: 1.463, Global test loss: 2.026, Global test accuracy: 43.37 

Round  55, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.45 

Round  55, Global train loss: 1.464, Global test loss: 1.999, Global test accuracy: 46.13 

Round  56, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.47 

Round  56, Global train loss: 1.463, Global test loss: 2.043, Global test accuracy: 40.67 

Round  57, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.47 

Round  57, Global train loss: 1.463, Global test loss: 2.080, Global test accuracy: 35.07 

Round  58, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.43 

Round  58, Global train loss: 1.465, Global test loss: 2.057, Global test accuracy: 37.93 

Round  59, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.43 

Round  59, Global train loss: 1.463, Global test loss: 2.086, Global test accuracy: 34.45 

Round  60, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.42 

Round  60, Global train loss: 1.465, Global test loss: 2.011, Global test accuracy: 45.27 

Round  61, Train loss: 1.466, Test loss: 1.520, Test accuracy: 94.42 

Round  61, Global train loss: 1.466, Global test loss: 2.032, Global test accuracy: 42.07 

Round  62, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.42 

Round  62, Global train loss: 1.465, Global test loss: 2.033, Global test accuracy: 43.35 

Round  63, Train loss: 1.466, Test loss: 1.520, Test accuracy: 94.40 

Round  63, Global train loss: 1.466, Global test loss: 2.026, Global test accuracy: 42.50 

Round  64, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.40 

Round  64, Global train loss: 1.464, Global test loss: 1.997, Global test accuracy: 46.40 

Round  65, Train loss: 1.466, Test loss: 1.520, Test accuracy: 94.40 

Round  65, Global train loss: 1.466, Global test loss: 1.999, Global test accuracy: 46.08 

Round  66, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.42 

Round  66, Global train loss: 1.464, Global test loss: 2.015, Global test accuracy: 44.10 

Round  67, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.42 

Round  67, Global train loss: 1.463, Global test loss: 2.045, Global test accuracy: 39.37 

Round  68, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.40 

Round  68, Global train loss: 1.463, Global test loss: 2.075, Global test accuracy: 37.23 

Round  69, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.38 

Round  69, Global train loss: 1.463, Global test loss: 2.042, Global test accuracy: 40.63 

Round  70, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.37 

Round  70, Global train loss: 1.465, Global test loss: 2.072, Global test accuracy: 37.48 

Round  71, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.37 

Round  71, Global train loss: 1.464, Global test loss: 2.039, Global test accuracy: 41.10 

Round  72, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.35 

Round  72, Global train loss: 1.465, Global test loss: 2.059, Global test accuracy: 38.92 

Round  73, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.32 

Round  73, Global train loss: 1.464, Global test loss: 2.067, Global test accuracy: 38.63 

Round  74, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.32 

Round  74, Global train loss: 1.464, Global test loss: 2.021, Global test accuracy: 43.45 

Round  75, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.32 

Round  75, Global train loss: 1.465, Global test loss: 2.036, Global test accuracy: 41.87 

Round  76, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.32 

Round  76, Global train loss: 1.463, Global test loss: 2.022, Global test accuracy: 43.33 

Round  77, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.33 

Round  77, Global train loss: 1.463, Global test loss: 2.008, Global test accuracy: 45.50 

Round  78, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.33 

Round  78, Global train loss: 1.464, Global test loss: 2.047, Global test accuracy: 40.87 

Round  79, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.32 

Round  79, Global train loss: 1.463, Global test loss: 2.036, Global test accuracy: 41.18 

Round  80, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.32 

Round  80, Global train loss: 1.463, Global test loss: 2.058, Global test accuracy: 39.85 

Round  81, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.32 

Round  81, Global train loss: 1.464, Global test loss: 2.074, Global test accuracy: 37.10 

Round  82, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.32 

Round  82, Global train loss: 1.463, Global test loss: 2.030, Global test accuracy: 42.12 

Round  83, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.30 

Round  83, Global train loss: 1.464, Global test loss: 2.069, Global test accuracy: 38.38 

Round  84, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.30 

Round  84, Global train loss: 1.464, Global test loss: 2.053, Global test accuracy: 39.45 

Round  85, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.30 

Round  85, Global train loss: 1.463, Global test loss: 2.052, Global test accuracy: 40.05 

Round  86, Train loss: 1.462, Test loss: 1.520, Test accuracy: 94.30 

Round  86, Global train loss: 1.462, Global test loss: 2.011, Global test accuracy: 45.00 

Round  87, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.30 

Round  87, Global train loss: 1.464, Global test loss: 2.065, Global test accuracy: 37.67 

Round  88, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.30 

Round  88, Global train loss: 1.465, Global test loss: 2.084, Global test accuracy: 35.98 

Round  89, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.32 

Round  89, Global train loss: 1.464, Global test loss: 2.039, Global test accuracy: 41.78 

Round  90, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.28 

Round  90, Global train loss: 1.464, Global test loss: 2.069, Global test accuracy: 38.67 

Round  91, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.28 

Round  91, Global train loss: 1.465, Global test loss: 2.014, Global test accuracy: 44.85 

Round  92, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.28 

Round  92, Global train loss: 1.464, Global test loss: 2.067, Global test accuracy: 36.33 

Round  93, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.28 

Round  93, Global train loss: 1.464, Global test loss: 2.062, Global test accuracy: 39.48 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.28 

Round  94, Global train loss: 1.464, Global test loss: 2.033, Global test accuracy: 41.28 

Round  95, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.28 

Round  95, Global train loss: 1.465, Global test loss: 2.025, Global test accuracy: 43.90 

Round  96, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.28 

Round  96, Global train loss: 1.464, Global test loss: 2.064, Global test accuracy: 38.00 

Round  97, Train loss: 1.465, Test loss: 1.520, Test accuracy: 94.28 

Round  97, Global train loss: 1.465, Global test loss: 2.019, Global test accuracy: 43.30 

Round  98, Train loss: 1.462, Test loss: 1.520, Test accuracy: 94.28 

Round  98, Global train loss: 1.462, Global test loss: 2.068, Global test accuracy: 38.62 

Round  99, Train loss: 1.463, Test loss: 1.520, Test accuracy: 94.28 

Round  99, Global train loss: 1.463, Global test loss: 2.073, Global test accuracy: 35.73 

Final Round, Train loss: 1.464, Test loss: 1.520, Test accuracy: 94.30 

Final Round, Global train loss: 1.464, Global test loss: 2.073, Global test accuracy: 35.73 

Average accuracy final 10 rounds: 94.28333333333332 

Average global accuracy final 10 rounds: 40.016666666666666 

456.5047423839569
[0.5174992084503174, 0.9237565994262695, 1.3316597938537598, 1.7394099235534668, 2.14996075630188, 2.56235671043396, 2.9738879203796387, 3.3813724517822266, 3.8160669803619385, 4.249902009963989, 4.6846747398376465, 5.119309186935425, 5.551072835922241, 5.967875242233276, 6.33088493347168, 6.694193363189697, 7.057989120483398, 7.444138526916504, 7.807668685913086, 8.172183275222778, 8.5369393825531, 8.90143346786499, 9.267263174057007, 9.63103199005127, 9.994239330291748, 10.358150482177734, 10.74017882347107, 11.104205846786499, 11.468267679214478, 11.83462929725647, 12.197295427322388, 12.560189962387085, 12.932511329650879, 13.314090967178345, 13.676851987838745, 14.048805475234985, 14.425722122192383, 14.806162595748901, 15.1916024684906, 15.557791709899902, 15.944265604019165, 16.30763578414917, 16.672808170318604, 17.037156105041504, 17.400412797927856, 17.767555475234985, 18.13276696205139, 18.498442888259888, 18.862964391708374, 19.228073358535767, 19.590688705444336, 19.954664945602417, 20.34021520614624, 20.72821545600891, 21.092684268951416, 21.458134651184082, 21.823782444000244, 22.189751625061035, 22.554652452468872, 22.919039011001587, 23.28385639190674, 23.6469886302948, 24.0107319355011, 24.37385082244873, 24.738499641418457, 25.10148024559021, 25.465853691101074, 25.83049488067627, 26.19607162475586, 26.582955837249756, 26.962453842163086, 27.32574152946472, 27.690873622894287, 28.05629014968872, 28.420641660690308, 28.784848928451538, 29.14947533607483, 29.51360845565796, 29.877187252044678, 30.243608713150024, 30.607770919799805, 30.972115755081177, 31.33500075340271, 31.700073957443237, 32.06417798995972, 32.427409648895264, 32.7908890247345, 33.15538454055786, 33.518770933151245, 33.88284087181091, 34.24777960777283, 34.61146664619446, 34.97426915168762, 35.33891725540161, 35.70463800430298, 36.06965684890747, 36.4346866607666, 36.79901099205017, 37.16317415237427, 37.5266170501709, 38.24879598617554]
[37.46666666666667, 43.96666666666667, 52.5, 65.21666666666667, 73.33333333333333, 75.7, 79.45, 84.8, 85.21666666666667, 87.21666666666667, 87.25, 87.41666666666667, 87.45, 90.15, 89.88333333333334, 91.46666666666667, 91.43333333333334, 91.38333333333334, 91.3, 91.23333333333333, 92.81666666666666, 92.91666666666667, 92.91666666666667, 92.95, 93.05, 93.05, 93.06666666666666, 93.03333333333333, 93.01666666666667, 93.0, 92.98333333333333, 93.01666666666667, 94.3, 94.46666666666667, 94.5, 94.46666666666667, 94.43333333333334, 94.45, 94.46666666666667, 94.51666666666667, 94.5, 94.4, 94.41666666666667, 94.41666666666667, 94.43333333333334, 94.46666666666667, 94.46666666666667, 94.48333333333333, 94.46666666666667, 94.48333333333333, 94.48333333333333, 94.46666666666667, 94.48333333333333, 94.45, 94.46666666666667, 94.45, 94.46666666666667, 94.46666666666667, 94.43333333333334, 94.43333333333334, 94.41666666666667, 94.41666666666667, 94.41666666666667, 94.4, 94.4, 94.4, 94.41666666666667, 94.41666666666667, 94.4, 94.38333333333334, 94.36666666666666, 94.36666666666666, 94.35, 94.31666666666666, 94.31666666666666, 94.31666666666666, 94.31666666666666, 94.33333333333333, 94.33333333333333, 94.31666666666666, 94.31666666666666, 94.31666666666666, 94.31666666666666, 94.3, 94.3, 94.3, 94.3, 94.3, 94.3, 94.31666666666666, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.274, Test loss: 2.215, Test accuracy: 39.85 

Round   0, Global train loss: 2.274, Global test loss: 2.221, Global test accuracy: 34.15 

Round   1, Train loss: 2.057, Test loss: 2.051, Test accuracy: 51.85 

Round   1, Global train loss: 2.057, Global test loss: 2.087, Global test accuracy: 36.82 

Round   2, Train loss: 1.852, Test loss: 1.916, Test accuracy: 65.33 

Round   2, Global train loss: 1.852, Global test loss: 2.062, Global test accuracy: 39.12 

Round   3, Train loss: 1.628, Test loss: 1.843, Test accuracy: 70.73 

Round   3, Global train loss: 1.628, Global test loss: 2.031, Global test accuracy: 41.90 

Round   4, Train loss: 1.672, Test loss: 1.747, Test accuracy: 81.28 

Round   4, Global train loss: 1.672, Global test loss: 1.989, Global test accuracy: 48.10 

Round   5, Train loss: 1.667, Test loss: 1.649, Test accuracy: 85.50 

Round   5, Global train loss: 1.667, Global test loss: 1.987, Global test accuracy: 47.83 

Round   6, Train loss: 1.683, Test loss: 1.624, Test accuracy: 86.38 

Round   6, Global train loss: 1.683, Global test loss: 2.006, Global test accuracy: 45.07 

Round   7, Train loss: 1.612, Test loss: 1.622, Test accuracy: 86.43 

Round   7, Global train loss: 1.612, Global test loss: 1.998, Global test accuracy: 45.72 

Round   8, Train loss: 1.640, Test loss: 1.613, Test accuracy: 87.10 

Round   8, Global train loss: 1.640, Global test loss: 1.989, Global test accuracy: 47.03 

Round   9, Train loss: 1.736, Test loss: 1.620, Test accuracy: 86.03 

Round   9, Global train loss: 1.736, Global test loss: 1.990, Global test accuracy: 46.68 

Round  10, Train loss: 1.590, Test loss: 1.615, Test accuracy: 86.63 

Round  10, Global train loss: 1.590, Global test loss: 1.996, Global test accuracy: 45.80 

Round  11, Train loss: 1.720, Test loss: 1.630, Test accuracy: 84.87 

Round  11, Global train loss: 1.720, Global test loss: 1.986, Global test accuracy: 47.05 

Round  12, Train loss: 1.680, Test loss: 1.629, Test accuracy: 84.97 

Round  12, Global train loss: 1.680, Global test loss: 1.975, Global test accuracy: 48.52 

Round  13, Train loss: 1.584, Test loss: 1.626, Test accuracy: 84.23 

Round  13, Global train loss: 1.584, Global test loss: 1.982, Global test accuracy: 47.40 

Round  14, Train loss: 1.584, Test loss: 1.626, Test accuracy: 84.23 

Round  14, Global train loss: 1.584, Global test loss: 1.979, Global test accuracy: 48.18 

Round  15, Train loss: 1.600, Test loss: 1.615, Test accuracy: 85.20 

Round  15, Global train loss: 1.600, Global test loss: 1.995, Global test accuracy: 45.77 

Round  16, Train loss: 1.562, Test loss: 1.601, Test accuracy: 86.67 

Round  16, Global train loss: 1.562, Global test loss: 1.970, Global test accuracy: 49.55 

Round  17, Train loss: 1.638, Test loss: 1.599, Test accuracy: 86.85 

Round  17, Global train loss: 1.638, Global test loss: 1.994, Global test accuracy: 46.00 

Round  18, Train loss: 1.570, Test loss: 1.595, Test accuracy: 87.13 

Round  18, Global train loss: 1.570, Global test loss: 2.023, Global test accuracy: 43.02 

Round  19, Train loss: 1.748, Test loss: 1.644, Test accuracy: 82.10 

Round  19, Global train loss: 1.748, Global test loss: 2.041, Global test accuracy: 41.35 

Round  20, Train loss: 1.625, Test loss: 1.612, Test accuracy: 85.40 

Round  20, Global train loss: 1.625, Global test loss: 1.993, Global test accuracy: 46.45 

Round  21, Train loss: 1.611, Test loss: 1.594, Test accuracy: 87.22 

Round  21, Global train loss: 1.611, Global test loss: 1.973, Global test accuracy: 48.62 

Round  22, Train loss: 1.718, Test loss: 1.591, Test accuracy: 87.62 

Round  22, Global train loss: 1.718, Global test loss: 1.994, Global test accuracy: 45.08 

Round  23, Train loss: 1.558, Test loss: 1.580, Test accuracy: 88.70 

Round  23, Global train loss: 1.558, Global test loss: 1.999, Global test accuracy: 44.95 

Round  24, Train loss: 1.552, Test loss: 1.580, Test accuracy: 88.80 

Round  24, Global train loss: 1.552, Global test loss: 1.987, Global test accuracy: 45.95 

Round  25, Train loss: 1.552, Test loss: 1.593, Test accuracy: 87.38 

Round  25, Global train loss: 1.552, Global test loss: 1.982, Global test accuracy: 47.77 

Round  26, Train loss: 1.718, Test loss: 1.594, Test accuracy: 87.18 

Round  26, Global train loss: 1.718, Global test loss: 1.984, Global test accuracy: 47.15 

Round  27, Train loss: 1.561, Test loss: 1.609, Test accuracy: 85.70 

Round  27, Global train loss: 1.561, Global test loss: 1.967, Global test accuracy: 49.62 

Round  28, Train loss: 1.563, Test loss: 1.598, Test accuracy: 86.82 

Round  28, Global train loss: 1.563, Global test loss: 1.983, Global test accuracy: 47.48 

Round  29, Train loss: 1.661, Test loss: 1.598, Test accuracy: 86.92 

Round  29, Global train loss: 1.661, Global test loss: 1.983, Global test accuracy: 47.38 

Round  30, Train loss: 1.628, Test loss: 1.597, Test accuracy: 86.87 

Round  30, Global train loss: 1.628, Global test loss: 2.013, Global test accuracy: 43.62 

Round  31, Train loss: 1.538, Test loss: 1.597, Test accuracy: 86.85 

Round  31, Global train loss: 1.538, Global test loss: 2.003, Global test accuracy: 44.00 

Round  32, Train loss: 1.592, Test loss: 1.608, Test accuracy: 85.88 

Round  32, Global train loss: 1.592, Global test loss: 2.007, Global test accuracy: 45.15 

Round  33, Train loss: 1.558, Test loss: 1.595, Test accuracy: 87.08 

Round  33, Global train loss: 1.558, Global test loss: 2.020, Global test accuracy: 42.28 

Round  34, Train loss: 1.656, Test loss: 1.596, Test accuracy: 86.90 

Round  34, Global train loss: 1.656, Global test loss: 2.003, Global test accuracy: 44.93 

Round  35, Train loss: 1.651, Test loss: 1.613, Test accuracy: 85.17 

Round  35, Global train loss: 1.651, Global test loss: 2.030, Global test accuracy: 41.37 

Round  36, Train loss: 1.545, Test loss: 1.613, Test accuracy: 85.18 

Round  36, Global train loss: 1.545, Global test loss: 2.001, Global test accuracy: 44.80 

Round  37, Train loss: 1.511, Test loss: 1.612, Test accuracy: 85.25 

Round  37, Global train loss: 1.511, Global test loss: 1.962, Global test accuracy: 49.57 

Round  38, Train loss: 1.564, Test loss: 1.626, Test accuracy: 83.70 

Round  38, Global train loss: 1.564, Global test loss: 1.980, Global test accuracy: 47.22 

Round  39, Train loss: 1.538, Test loss: 1.609, Test accuracy: 85.33 

Round  39, Global train loss: 1.538, Global test loss: 1.946, Global test accuracy: 51.37 

Round  40, Train loss: 1.584, Test loss: 1.611, Test accuracy: 85.30 

Round  40, Global train loss: 1.584, Global test loss: 1.972, Global test accuracy: 47.78 

Round  41, Train loss: 1.598, Test loss: 1.610, Test accuracy: 85.33 

Round  41, Global train loss: 1.598, Global test loss: 1.998, Global test accuracy: 44.82 

Round  42, Train loss: 1.598, Test loss: 1.609, Test accuracy: 85.47 

Round  42, Global train loss: 1.598, Global test loss: 1.987, Global test accuracy: 46.60 

Round  43, Train loss: 1.540, Test loss: 1.609, Test accuracy: 85.47 

Round  43, Global train loss: 1.540, Global test loss: 1.973, Global test accuracy: 48.28 

Round  44, Train loss: 1.534, Test loss: 1.594, Test accuracy: 86.98 

Round  44, Global train loss: 1.534, Global test loss: 1.993, Global test accuracy: 46.08 

Round  45, Train loss: 1.494, Test loss: 1.594, Test accuracy: 86.90 

Round  45, Global train loss: 1.494, Global test loss: 1.984, Global test accuracy: 46.87 

Round  46, Train loss: 1.616, Test loss: 1.612, Test accuracy: 85.03 

Round  46, Global train loss: 1.616, Global test loss: 2.006, Global test accuracy: 43.93 

Round  47, Train loss: 1.542, Test loss: 1.606, Test accuracy: 85.75 

Round  47, Global train loss: 1.542, Global test loss: 1.970, Global test accuracy: 48.78 

Round  48, Train loss: 1.636, Test loss: 1.591, Test accuracy: 87.40 

Round  48, Global train loss: 1.636, Global test loss: 2.000, Global test accuracy: 45.10 

Round  49, Train loss: 1.536, Test loss: 1.592, Test accuracy: 87.28 

Round  49, Global train loss: 1.536, Global test loss: 1.939, Global test accuracy: 52.48 

Round  50, Train loss: 1.544, Test loss: 1.578, Test accuracy: 88.80 

Round  50, Global train loss: 1.544, Global test loss: 1.948, Global test accuracy: 51.05 

Round  51, Train loss: 1.515, Test loss: 1.580, Test accuracy: 88.52 

Round  51, Global train loss: 1.515, Global test loss: 1.946, Global test accuracy: 51.75 

Round  52, Train loss: 1.641, Test loss: 1.597, Test accuracy: 86.83 

Round  52, Global train loss: 1.641, Global test loss: 1.974, Global test accuracy: 48.15 

Round  53, Train loss: 1.562, Test loss: 1.596, Test accuracy: 86.78 

Round  53, Global train loss: 1.562, Global test loss: 1.956, Global test accuracy: 50.15 

Round  54, Train loss: 1.623, Test loss: 1.587, Test accuracy: 87.70 

Round  54, Global train loss: 1.623, Global test loss: 1.970, Global test accuracy: 48.35 

Round  55, Train loss: 1.553, Test loss: 1.599, Test accuracy: 86.53 

Round  55, Global train loss: 1.553, Global test loss: 1.958, Global test accuracy: 49.93 

Round  56, Train loss: 1.540, Test loss: 1.593, Test accuracy: 87.15 

Round  56, Global train loss: 1.540, Global test loss: 1.962, Global test accuracy: 49.57 

Round  57, Train loss: 1.537, Test loss: 1.595, Test accuracy: 86.93 

Round  57, Global train loss: 1.537, Global test loss: 1.956, Global test accuracy: 50.25 

Round  58, Train loss: 1.549, Test loss: 1.593, Test accuracy: 87.10 

Round  58, Global train loss: 1.549, Global test loss: 1.973, Global test accuracy: 48.67 

Round  59, Train loss: 1.633, Test loss: 1.577, Test accuracy: 88.70 

Round  59, Global train loss: 1.633, Global test loss: 1.982, Global test accuracy: 47.58 

Round  60, Train loss: 1.493, Test loss: 1.576, Test accuracy: 88.83 

Round  60, Global train loss: 1.493, Global test loss: 1.987, Global test accuracy: 46.73 

Round  61, Train loss: 1.479, Test loss: 1.576, Test accuracy: 88.95 

Round  61, Global train loss: 1.479, Global test loss: 1.965, Global test accuracy: 49.52 

Round  62, Train loss: 1.548, Test loss: 1.567, Test accuracy: 89.80 

Round  62, Global train loss: 1.548, Global test loss: 1.999, Global test accuracy: 45.10 

Round  63, Train loss: 1.521, Test loss: 1.550, Test accuracy: 91.50 

Round  63, Global train loss: 1.521, Global test loss: 1.974, Global test accuracy: 48.97 

Round  64, Train loss: 1.550, Test loss: 1.537, Test accuracy: 92.73 

Round  64, Global train loss: 1.550, Global test loss: 2.013, Global test accuracy: 43.60 

Round  65, Train loss: 1.571, Test loss: 1.553, Test accuracy: 91.12 

Round  65, Global train loss: 1.571, Global test loss: 1.987, Global test accuracy: 47.07 

Round  66, Train loss: 1.498, Test loss: 1.553, Test accuracy: 91.10 

Round  66, Global train loss: 1.498, Global test loss: 1.947, Global test accuracy: 50.87 

Round  67, Train loss: 1.537, Test loss: 1.568, Test accuracy: 89.62 

Round  67, Global train loss: 1.537, Global test loss: 1.953, Global test accuracy: 50.70 

Round  68, Train loss: 1.650, Test loss: 1.592, Test accuracy: 87.32 

Round  68, Global train loss: 1.650, Global test loss: 1.936, Global test accuracy: 52.43 

Round  69, Train loss: 1.515, Test loss: 1.577, Test accuracy: 88.80 

Round  69, Global train loss: 1.515, Global test loss: 1.953, Global test accuracy: 50.75 

Round  70, Train loss: 1.587, Test loss: 1.593, Test accuracy: 87.07 

Round  70, Global train loss: 1.587, Global test loss: 1.968, Global test accuracy: 49.20 

Round  71, Train loss: 1.589, Test loss: 1.596, Test accuracy: 86.70 

Round  71, Global train loss: 1.589, Global test loss: 1.958, Global test accuracy: 50.40 

Round  72, Train loss: 1.531, Test loss: 1.568, Test accuracy: 89.55 

Round  72, Global train loss: 1.531, Global test loss: 1.985, Global test accuracy: 47.18 

Round  73, Train loss: 1.479, Test loss: 1.551, Test accuracy: 91.30 

Round  73, Global train loss: 1.479, Global test loss: 1.962, Global test accuracy: 49.55 

Round  74, Train loss: 1.534, Test loss: 1.552, Test accuracy: 91.22 

Round  74, Global train loss: 1.534, Global test loss: 2.003, Global test accuracy: 44.47 

Round  75, Train loss: 1.548, Test loss: 1.553, Test accuracy: 91.08 

Round  75, Global train loss: 1.548, Global test loss: 1.954, Global test accuracy: 50.20 

Round  76, Train loss: 1.498, Test loss: 1.555, Test accuracy: 91.02 

Round  76, Global train loss: 1.498, Global test loss: 1.941, Global test accuracy: 52.25 

Round  77, Train loss: 1.477, Test loss: 1.557, Test accuracy: 90.70 

Round  77, Global train loss: 1.477, Global test loss: 1.951, Global test accuracy: 50.58 

Round  78, Train loss: 1.480, Test loss: 1.557, Test accuracy: 90.75 

Round  78, Global train loss: 1.480, Global test loss: 1.957, Global test accuracy: 49.90 

Round  79, Train loss: 1.484, Test loss: 1.557, Test accuracy: 90.77 

Round  79, Global train loss: 1.484, Global test loss: 1.954, Global test accuracy: 50.78 

Round  80, Train loss: 1.548, Test loss: 1.564, Test accuracy: 90.12 

Round  80, Global train loss: 1.548, Global test loss: 1.980, Global test accuracy: 47.48 

Round  81, Train loss: 1.619, Test loss: 1.563, Test accuracy: 90.17 

Round  81, Global train loss: 1.619, Global test loss: 1.997, Global test accuracy: 45.67 

Round  82, Train loss: 1.591, Test loss: 1.562, Test accuracy: 90.27 

Round  82, Global train loss: 1.591, Global test loss: 2.001, Global test accuracy: 45.12 

Round  83, Train loss: 1.489, Test loss: 1.560, Test accuracy: 90.40 

Round  83, Global train loss: 1.489, Global test loss: 1.978, Global test accuracy: 48.05 

Round  84, Train loss: 1.480, Test loss: 1.563, Test accuracy: 90.12 

Round  84, Global train loss: 1.480, Global test loss: 1.969, Global test accuracy: 48.62 

Round  85, Train loss: 1.536, Test loss: 1.562, Test accuracy: 90.07 

Round  85, Global train loss: 1.536, Global test loss: 1.987, Global test accuracy: 46.33 

Round  86, Train loss: 1.487, Test loss: 1.562, Test accuracy: 90.18 

Round  86, Global train loss: 1.487, Global test loss: 1.959, Global test accuracy: 49.73 

Round  87, Train loss: 1.491, Test loss: 1.551, Test accuracy: 91.28 

Round  87, Global train loss: 1.491, Global test loss: 1.951, Global test accuracy: 50.70 

Round  88, Train loss: 1.590, Test loss: 1.565, Test accuracy: 89.88 

Round  88, Global train loss: 1.590, Global test loss: 1.944, Global test accuracy: 51.27 

Round  89, Train loss: 1.554, Test loss: 1.565, Test accuracy: 89.72 

Round  89, Global train loss: 1.554, Global test loss: 1.961, Global test accuracy: 49.33 

Round  90, Train loss: 1.531, Test loss: 1.566, Test accuracy: 89.70 

Round  90, Global train loss: 1.531, Global test loss: 1.955, Global test accuracy: 50.10 

Round  91, Train loss: 1.505, Test loss: 1.567, Test accuracy: 89.50 

Round  91, Global train loss: 1.505, Global test loss: 1.941, Global test accuracy: 51.53 

Round  92, Train loss: 1.606, Test loss: 1.563, Test accuracy: 89.87 

Round  92, Global train loss: 1.606, Global test loss: 1.954, Global test accuracy: 50.17 

Round  93, Train loss: 1.636, Test loss: 1.553, Test accuracy: 91.02 

Round  93, Global train loss: 1.636, Global test loss: 2.004, Global test accuracy: 44.58 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.533, Test loss: 1.553, Test accuracy: 91.03 

Round  94, Global train loss: 1.533, Global test loss: 1.959, Global test accuracy: 49.70 

Round  95, Train loss: 1.583, Test loss: 1.554, Test accuracy: 90.97 

Round  95, Global train loss: 1.583, Global test loss: 1.980, Global test accuracy: 47.87 

Round  96, Train loss: 1.593, Test loss: 1.556, Test accuracy: 90.75 

Round  96, Global train loss: 1.593, Global test loss: 1.969, Global test accuracy: 49.13 

Round  97, Train loss: 1.485, Test loss: 1.553, Test accuracy: 91.07 

Round  97, Global train loss: 1.485, Global test loss: 1.951, Global test accuracy: 50.75 

Round  98, Train loss: 1.512, Test loss: 1.550, Test accuracy: 91.33 

Round  98, Global train loss: 1.512, Global test loss: 1.989, Global test accuracy: 45.93 

Round  99, Train loss: 1.583, Test loss: 1.551, Test accuracy: 91.23 

Round  99, Global train loss: 1.583, Global test loss: 1.951, Global test accuracy: 50.40 

Final Round, Train loss: 1.524, Test loss: 1.566, Test accuracy: 89.58 

Final Round, Global train loss: 1.524, Global test loss: 1.951, Global test accuracy: 50.40 

Average accuracy final 10 rounds: 90.64666666666668 

Average global accuracy final 10 rounds: 49.01666666666667 

456.33891344070435
[0.5395512580871582, 0.9648370742797852, 1.3908236026763916, 1.8182392120361328, 2.243316411972046, 2.6693642139434814, 3.0949103832244873, 3.5195653438568115, 3.945579767227173, 4.3691816329956055, 4.794477224349976, 5.215858697891235, 5.638089179992676, 6.05871319770813, 6.483699321746826, 6.906272649765015, 7.330844402313232, 7.755492687225342, 8.177452087402344, 8.597864151000977, 8.962563037872314, 9.323505640029907, 9.683552026748657, 10.04566216468811, 10.406425476074219, 10.767622470855713, 11.12936282157898, 11.493323564529419, 11.856749057769775, 12.221142053604126, 12.58588457107544, 12.950159788131714, 13.314952850341797, 13.675990581512451, 14.036881685256958, 14.399642705917358, 14.764028787612915, 15.127678155899048, 15.490034341812134, 15.85136342048645, 16.213937520980835, 16.5784809589386, 16.939568281173706, 17.299723625183105, 17.660685777664185, 18.02227258682251, 18.38311767578125, 18.744504690170288, 19.106898546218872, 19.46880602836609, 19.829432487487793, 20.19267702102661, 20.564555168151855, 20.926028966903687, 21.290348052978516, 21.654508352279663, 22.019367694854736, 22.380554914474487, 22.741347312927246, 23.103147983551025, 23.464431762695312, 23.82580018043518, 24.186370611190796, 24.54753875732422, 24.908920288085938, 25.271141052246094, 25.638410806655884, 25.999069690704346, 26.359941244125366, 26.72496485710144, 27.09014058113098, 27.454434394836426, 27.81829285621643, 28.183719873428345, 28.547603368759155, 28.90805745124817, 29.27031445503235, 29.631837606430054, 29.995229482650757, 30.358937978744507, 30.723148822784424, 31.08369278907776, 31.44378137588501, 31.804636478424072, 32.166141748428345, 32.528364419937134, 32.88876271247864, 33.2497341632843, 33.6144654750824, 33.97645664215088, 34.33970355987549, 34.70302605628967, 35.06806135177612, 35.43298935890198, 35.796393156051636, 36.15720582008362, 36.51743268966675, 36.878132820129395, 37.24159240722656, 37.60251188278198, 38.323673725128174]
[39.85, 51.85, 65.33333333333333, 70.73333333333333, 81.28333333333333, 85.5, 86.38333333333334, 86.43333333333334, 87.1, 86.03333333333333, 86.63333333333334, 84.86666666666666, 84.96666666666667, 84.23333333333333, 84.23333333333333, 85.2, 86.66666666666667, 86.85, 87.13333333333334, 82.1, 85.4, 87.21666666666667, 87.61666666666666, 88.7, 88.8, 87.38333333333334, 87.18333333333334, 85.7, 86.81666666666666, 86.91666666666667, 86.86666666666666, 86.85, 85.88333333333334, 87.08333333333333, 86.9, 85.16666666666667, 85.18333333333334, 85.25, 83.7, 85.33333333333333, 85.3, 85.33333333333333, 85.46666666666667, 85.46666666666667, 86.98333333333333, 86.9, 85.03333333333333, 85.75, 87.4, 87.28333333333333, 88.8, 88.51666666666667, 86.83333333333333, 86.78333333333333, 87.7, 86.53333333333333, 87.15, 86.93333333333334, 87.1, 88.7, 88.83333333333333, 88.95, 89.8, 91.5, 92.73333333333333, 91.11666666666666, 91.1, 89.61666666666666, 87.31666666666666, 88.8, 87.06666666666666, 86.7, 89.55, 91.3, 91.21666666666667, 91.08333333333333, 91.01666666666667, 90.7, 90.75, 90.76666666666667, 90.11666666666666, 90.16666666666667, 90.26666666666667, 90.4, 90.11666666666666, 90.06666666666666, 90.18333333333334, 91.28333333333333, 89.88333333333334, 89.71666666666667, 89.7, 89.5, 89.86666666666666, 91.01666666666667, 91.03333333333333, 90.96666666666667, 90.75, 91.06666666666666, 91.33333333333333, 91.23333333333333, 89.58333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.299, Test accuracy: 31.17 

Round   1, Train loss: 2.292, Test loss: 2.284, Test accuracy: 33.37 

Round   2, Train loss: 2.261, Test loss: 2.227, Test accuracy: 32.77 

Round   3, Train loss: 2.144, Test loss: 2.130, Test accuracy: 33.33 

Round   4, Train loss: 2.082, Test loss: 2.102, Test accuracy: 33.37 

Round   5, Train loss: 2.040, Test loss: 2.078, Test accuracy: 38.37 

Round   6, Train loss: 1.967, Test loss: 2.047, Test accuracy: 42.63 

Round   7, Train loss: 1.937, Test loss: 1.991, Test accuracy: 49.27 

Round   8, Train loss: 1.929, Test loss: 1.953, Test accuracy: 54.22 

Round   9, Train loss: 1.863, Test loss: 1.937, Test accuracy: 54.60 

Round  10, Train loss: 1.778, Test loss: 1.894, Test accuracy: 58.62 

Round  11, Train loss: 1.800, Test loss: 1.884, Test accuracy: 59.45 

Round  12, Train loss: 1.731, Test loss: 1.860, Test accuracy: 62.40 

Round  13, Train loss: 1.859, Test loss: 1.849, Test accuracy: 63.60 

Round  14, Train loss: 1.733, Test loss: 1.842, Test accuracy: 63.65 

Round  15, Train loss: 1.812, Test loss: 1.819, Test accuracy: 64.90 

Round  16, Train loss: 1.769, Test loss: 1.808, Test accuracy: 66.40 

Round  17, Train loss: 1.833, Test loss: 1.795, Test accuracy: 68.27 

Round  18, Train loss: 1.741, Test loss: 1.780, Test accuracy: 69.78 

Round  19, Train loss: 1.716, Test loss: 1.779, Test accuracy: 69.72 

Round  20, Train loss: 1.704, Test loss: 1.775, Test accuracy: 69.55 

Round  21, Train loss: 1.660, Test loss: 1.774, Test accuracy: 69.52 

Round  22, Train loss: 1.704, Test loss: 1.762, Test accuracy: 70.88 

Round  23, Train loss: 1.694, Test loss: 1.749, Test accuracy: 72.30 

Round  24, Train loss: 1.671, Test loss: 1.745, Test accuracy: 72.53 

Round  25, Train loss: 1.826, Test loss: 1.745, Test accuracy: 72.85 

Round  26, Train loss: 1.824, Test loss: 1.743, Test accuracy: 72.87 

Round  27, Train loss: 1.658, Test loss: 1.735, Test accuracy: 73.88 

Round  28, Train loss: 1.672, Test loss: 1.732, Test accuracy: 73.98 

Round  29, Train loss: 1.725, Test loss: 1.727, Test accuracy: 74.23 

Round  30, Train loss: 1.657, Test loss: 1.726, Test accuracy: 74.18 

Round  31, Train loss: 1.746, Test loss: 1.721, Test accuracy: 74.88 

Round  32, Train loss: 1.677, Test loss: 1.720, Test accuracy: 74.93 

Round  33, Train loss: 1.673, Test loss: 1.716, Test accuracy: 75.47 

Round  34, Train loss: 1.731, Test loss: 1.718, Test accuracy: 75.02 

Round  35, Train loss: 1.724, Test loss: 1.716, Test accuracy: 75.30 

Round  36, Train loss: 1.712, Test loss: 1.716, Test accuracy: 75.18 

Round  37, Train loss: 1.624, Test loss: 1.712, Test accuracy: 75.72 

Round  38, Train loss: 1.759, Test loss: 1.714, Test accuracy: 75.25 

Round  39, Train loss: 1.657, Test loss: 1.715, Test accuracy: 75.13 

Round  40, Train loss: 1.605, Test loss: 1.715, Test accuracy: 75.15 

Round  41, Train loss: 1.575, Test loss: 1.702, Test accuracy: 76.65 

Round  42, Train loss: 1.722, Test loss: 1.702, Test accuracy: 76.70 

Round  43, Train loss: 1.714, Test loss: 1.702, Test accuracy: 76.55 

Round  44, Train loss: 1.651, Test loss: 1.706, Test accuracy: 76.07 

Round  45, Train loss: 1.673, Test loss: 1.698, Test accuracy: 77.07 

Round  46, Train loss: 1.709, Test loss: 1.700, Test accuracy: 76.68 

Round  47, Train loss: 1.719, Test loss: 1.702, Test accuracy: 76.52 

Round  48, Train loss: 1.671, Test loss: 1.699, Test accuracy: 76.90 

Round  49, Train loss: 1.733, Test loss: 1.696, Test accuracy: 77.10 

Round  50, Train loss: 1.649, Test loss: 1.696, Test accuracy: 76.95 

Round  51, Train loss: 1.563, Test loss: 1.694, Test accuracy: 77.33 

Round  52, Train loss: 1.707, Test loss: 1.694, Test accuracy: 77.42 

Round  53, Train loss: 1.713, Test loss: 1.696, Test accuracy: 76.97 

Round  54, Train loss: 1.724, Test loss: 1.694, Test accuracy: 77.25 

Round  55, Train loss: 1.602, Test loss: 1.694, Test accuracy: 77.17 

Round  56, Train loss: 1.700, Test loss: 1.693, Test accuracy: 77.20 

Round  57, Train loss: 1.615, Test loss: 1.690, Test accuracy: 77.55 

Round  58, Train loss: 1.663, Test loss: 1.689, Test accuracy: 77.57 

Round  59, Train loss: 1.659, Test loss: 1.689, Test accuracy: 77.58 

Round  60, Train loss: 1.597, Test loss: 1.689, Test accuracy: 77.72 

Round  61, Train loss: 1.702, Test loss: 1.689, Test accuracy: 77.47 

Round  62, Train loss: 1.670, Test loss: 1.687, Test accuracy: 77.68 

Round  63, Train loss: 1.647, Test loss: 1.686, Test accuracy: 77.83 

Round  64, Train loss: 1.651, Test loss: 1.686, Test accuracy: 78.02 

Round  65, Train loss: 1.699, Test loss: 1.686, Test accuracy: 77.98 

Round  66, Train loss: 1.703, Test loss: 1.685, Test accuracy: 77.85 

Round  67, Train loss: 1.705, Test loss: 1.685, Test accuracy: 77.85 

Round  68, Train loss: 1.664, Test loss: 1.685, Test accuracy: 77.90 

Round  69, Train loss: 1.703, Test loss: 1.685, Test accuracy: 77.87 

Round  70, Train loss: 1.598, Test loss: 1.684, Test accuracy: 78.02 

Round  71, Train loss: 1.640, Test loss: 1.684, Test accuracy: 78.03 

Round  72, Train loss: 1.645, Test loss: 1.685, Test accuracy: 77.88 

Round  73, Train loss: 1.806, Test loss: 1.685, Test accuracy: 77.93 

Round  74, Train loss: 1.594, Test loss: 1.685, Test accuracy: 77.87 

Round  75, Train loss: 1.588, Test loss: 1.685, Test accuracy: 77.87 

Round  76, Train loss: 1.600, Test loss: 1.684, Test accuracy: 77.93 

Round  77, Train loss: 1.647, Test loss: 1.684, Test accuracy: 77.97 

Round  78, Train loss: 1.647, Test loss: 1.683, Test accuracy: 78.18 

Round  79, Train loss: 1.650, Test loss: 1.682, Test accuracy: 78.22 

Round  80, Train loss: 1.644, Test loss: 1.681, Test accuracy: 78.17 

Round  81, Train loss: 1.645, Test loss: 1.681, Test accuracy: 78.42 

Round  82, Train loss: 1.650, Test loss: 1.680, Test accuracy: 78.35 

Round  83, Train loss: 1.585, Test loss: 1.680, Test accuracy: 78.38 

Round  84, Train loss: 1.599, Test loss: 1.680, Test accuracy: 78.45 

Round  85, Train loss: 1.650, Test loss: 1.679, Test accuracy: 78.55 

Round  86, Train loss: 1.744, Test loss: 1.680, Test accuracy: 78.33 

Round  87, Train loss: 1.599, Test loss: 1.679, Test accuracy: 78.57 

Round  88, Train loss: 1.642, Test loss: 1.679, Test accuracy: 78.45 

Round  89, Train loss: 1.700, Test loss: 1.680, Test accuracy: 78.37 

Round  90, Train loss: 1.652, Test loss: 1.679, Test accuracy: 78.38 

Round  91, Train loss: 1.588, Test loss: 1.680, Test accuracy: 78.37 

Round  92, Train loss: 1.649, Test loss: 1.681, Test accuracy: 78.27 

Round  93, Train loss: 1.642, Test loss: 1.681, Test accuracy: 78.20 

Round  94, Train loss: 1.699, Test loss: 1.680, Test accuracy: 78.33 

Round  95, Train loss: 1.646, Test loss: 1.679, Test accuracy: 78.37 

Round  96, Train loss: 1.596, Test loss: 1.679, Test accuracy: 78.42 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.689, Test loss: 1.679, Test accuracy: 78.50 

Round  98, Train loss: 1.641, Test loss: 1.679, Test accuracy: 78.57 

Round  99, Train loss: 1.636, Test loss: 1.679, Test accuracy: 78.50 

Final Round, Train loss: 1.646, Test loss: 1.678, Test accuracy: 78.48 

Average accuracy final 10 rounds: 78.39 

348.6260230541229
[0.5015842914581299, 0.8826982975006104, 1.264200210571289, 1.6461923122406006, 2.0296409130096436, 2.411123514175415, 2.7926793098449707, 3.1746585369110107, 3.556485891342163, 3.9394729137420654, 4.321695804595947, 4.703872203826904, 5.085407257080078, 5.468048572540283, 5.852091550827026, 6.235579967498779, 6.616536378860474, 6.998983860015869, 7.3806023597717285, 7.76161003112793, 8.143164873123169, 8.524008989334106, 8.905997514724731, 9.287926197052002, 9.67177152633667, 10.05699348449707, 10.439809799194336, 10.824758291244507, 11.21052622795105, 11.595336198806763, 11.98022174835205, 12.3653883934021, 12.752704858779907, 13.139698266983032, 13.524673223495483, 13.907323598861694, 14.287846088409424, 14.672051906585693, 15.057478189468384, 15.44257140159607, 15.823212623596191, 16.20733904838562, 16.59238028526306, 16.977709770202637, 17.362053871154785, 17.748677253723145, 18.132293939590454, 18.516608715057373, 18.896926641464233, 19.27812433242798, 19.660196781158447, 20.04217028617859, 20.42315173149109, 20.80418586730957, 21.185352087020874, 21.567050457000732, 21.949475288391113, 22.334137678146362, 22.719646692276, 23.103036403656006, 23.483322620391846, 23.864328145980835, 24.246727466583252, 24.627784967422485, 25.00923180580139, 25.38977026939392, 25.773715257644653, 26.154883861541748, 26.53566026687622, 26.91566228866577, 27.29636025428772, 27.676673650741577, 28.05869436264038, 28.44042444229126, 28.822163105010986, 29.206019639968872, 29.58656406402588, 29.969419717788696, 30.351619720458984, 30.733636617660522, 31.116748094558716, 31.496803283691406, 31.882038354873657, 32.26793384552002, 32.6535427570343, 33.03863525390625, 33.422738790512085, 33.80271792411804, 34.183833360672, 34.56580877304077, 34.94821810722351, 35.3335223197937, 35.71869730949402, 36.10409355163574, 36.49020171165466, 36.875497817993164, 37.26069784164429, 37.64608693122864, 38.0271315574646, 38.4077250957489, 39.07687020301819]
[31.166666666666668, 33.36666666666667, 32.766666666666666, 33.333333333333336, 33.36666666666667, 38.36666666666667, 42.63333333333333, 49.266666666666666, 54.21666666666667, 54.6, 58.61666666666667, 59.45, 62.4, 63.6, 63.65, 64.9, 66.4, 68.26666666666667, 69.78333333333333, 69.71666666666667, 69.55, 69.51666666666667, 70.88333333333334, 72.3, 72.53333333333333, 72.85, 72.86666666666666, 73.88333333333334, 73.98333333333333, 74.23333333333333, 74.18333333333334, 74.88333333333334, 74.93333333333334, 75.46666666666667, 75.01666666666667, 75.3, 75.18333333333334, 75.71666666666667, 75.25, 75.13333333333334, 75.15, 76.65, 76.7, 76.55, 76.06666666666666, 77.06666666666666, 76.68333333333334, 76.51666666666667, 76.9, 77.1, 76.95, 77.33333333333333, 77.41666666666667, 76.96666666666667, 77.25, 77.16666666666667, 77.2, 77.55, 77.56666666666666, 77.58333333333333, 77.71666666666667, 77.46666666666667, 77.68333333333334, 77.83333333333333, 78.01666666666667, 77.98333333333333, 77.85, 77.85, 77.9, 77.86666666666666, 78.01666666666667, 78.03333333333333, 77.88333333333334, 77.93333333333334, 77.86666666666666, 77.86666666666666, 77.93333333333334, 77.96666666666667, 78.18333333333334, 78.21666666666667, 78.16666666666667, 78.41666666666667, 78.35, 78.38333333333334, 78.45, 78.55, 78.33333333333333, 78.56666666666666, 78.45, 78.36666666666666, 78.38333333333334, 78.36666666666666, 78.26666666666667, 78.2, 78.33333333333333, 78.36666666666666, 78.41666666666667, 78.5, 78.56666666666666, 78.5, 78.48333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.288, Test accuracy: 33.33 

Round   1, Train loss: 2.209, Test loss: 2.135, Test accuracy: 38.37 

Round   2, Train loss: 1.932, Test loss: 2.062, Test accuracy: 41.98 

Round   3, Train loss: 1.763, Test loss: 2.002, Test accuracy: 49.45 

Round   4, Train loss: 1.671, Test loss: 1.969, Test accuracy: 51.25 

Round   5, Train loss: 1.707, Test loss: 1.957, Test accuracy: 50.35 

Round   6, Train loss: 1.731, Test loss: 1.943, Test accuracy: 51.68 

Round   7, Train loss: 1.675, Test loss: 1.942, Test accuracy: 51.42 

Round   8, Train loss: 1.668, Test loss: 1.916, Test accuracy: 55.45 

Round   9, Train loss: 1.528, Test loss: 1.912, Test accuracy: 55.12 

Round  10, Train loss: 1.656, Test loss: 1.913, Test accuracy: 55.68 

Round  11, Train loss: 1.637, Test loss: 1.894, Test accuracy: 57.98 

Round  12, Train loss: 1.642, Test loss: 1.895, Test accuracy: 56.58 

Round  13, Train loss: 1.735, Test loss: 1.881, Test accuracy: 58.90 

Round  14, Train loss: 1.567, Test loss: 1.890, Test accuracy: 57.32 

Round  15, Train loss: 1.573, Test loss: 1.872, Test accuracy: 59.37 

Round  16, Train loss: 1.604, Test loss: 1.875, Test accuracy: 58.10 

Round  17, Train loss: 1.504, Test loss: 1.868, Test accuracy: 59.37 

Round  18, Train loss: 1.676, Test loss: 1.886, Test accuracy: 57.28 

Round  19, Train loss: 1.559, Test loss: 1.869, Test accuracy: 59.22 

Round  20, Train loss: 1.657, Test loss: 1.855, Test accuracy: 60.97 

Round  21, Train loss: 1.541, Test loss: 1.843, Test accuracy: 61.93 

Round  22, Train loss: 1.699, Test loss: 1.844, Test accuracy: 62.17 

Round  23, Train loss: 1.601, Test loss: 1.839, Test accuracy: 62.60 

Round  24, Train loss: 1.558, Test loss: 1.831, Test accuracy: 63.47 

Round  25, Train loss: 1.543, Test loss: 1.823, Test accuracy: 64.65 

Round  26, Train loss: 1.588, Test loss: 1.834, Test accuracy: 62.33 

Round  27, Train loss: 1.649, Test loss: 1.818, Test accuracy: 65.05 

Round  28, Train loss: 1.607, Test loss: 1.819, Test accuracy: 64.92 

Round  29, Train loss: 1.647, Test loss: 1.795, Test accuracy: 67.63 

Round  30, Train loss: 1.537, Test loss: 1.799, Test accuracy: 66.45 

Round  31, Train loss: 1.627, Test loss: 1.790, Test accuracy: 67.60 

Round  32, Train loss: 1.593, Test loss: 1.786, Test accuracy: 68.50 

Round  33, Train loss: 1.606, Test loss: 1.791, Test accuracy: 67.08 

Round  34, Train loss: 1.533, Test loss: 1.786, Test accuracy: 68.05 

Round  35, Train loss: 1.612, Test loss: 1.794, Test accuracy: 66.98 

Round  36, Train loss: 1.587, Test loss: 1.763, Test accuracy: 70.15 

Round  37, Train loss: 1.535, Test loss: 1.773, Test accuracy: 69.32 

Round  38, Train loss: 1.644, Test loss: 1.770, Test accuracy: 69.72 

Round  39, Train loss: 1.497, Test loss: 1.742, Test accuracy: 73.55 

Round  40, Train loss: 1.486, Test loss: 1.740, Test accuracy: 73.15 

Round  41, Train loss: 1.595, Test loss: 1.746, Test accuracy: 72.50 

Round  42, Train loss: 1.483, Test loss: 1.748, Test accuracy: 72.12 

Round  43, Train loss: 1.535, Test loss: 1.733, Test accuracy: 73.63 

Round  44, Train loss: 1.534, Test loss: 1.751, Test accuracy: 71.47 

Round  45, Train loss: 1.586, Test loss: 1.728, Test accuracy: 74.20 

Round  46, Train loss: 1.688, Test loss: 1.730, Test accuracy: 73.78 

Round  47, Train loss: 1.527, Test loss: 1.727, Test accuracy: 73.88 

Round  48, Train loss: 1.529, Test loss: 1.716, Test accuracy: 74.70 

Round  49, Train loss: 1.538, Test loss: 1.705, Test accuracy: 76.10 

Round  50, Train loss: 1.695, Test loss: 1.710, Test accuracy: 75.75 

Round  51, Train loss: 1.531, Test loss: 1.709, Test accuracy: 75.95 

Round  52, Train loss: 1.528, Test loss: 1.705, Test accuracy: 76.38 

Round  53, Train loss: 1.547, Test loss: 1.702, Test accuracy: 76.83 

Round  54, Train loss: 1.475, Test loss: 1.701, Test accuracy: 76.78 

Round  55, Train loss: 1.537, Test loss: 1.698, Test accuracy: 76.88 

Round  56, Train loss: 1.475, Test loss: 1.707, Test accuracy: 75.83 

Round  57, Train loss: 1.535, Test loss: 1.700, Test accuracy: 76.93 

Round  58, Train loss: 1.527, Test loss: 1.688, Test accuracy: 78.02 

Round  59, Train loss: 1.527, Test loss: 1.689, Test accuracy: 77.60 

Round  60, Train loss: 1.526, Test loss: 1.685, Test accuracy: 78.42 

Round  61, Train loss: 1.575, Test loss: 1.690, Test accuracy: 77.67 

Round  62, Train loss: 1.590, Test loss: 1.688, Test accuracy: 77.92 

Round  63, Train loss: 1.582, Test loss: 1.688, Test accuracy: 77.92 

Round  64, Train loss: 1.587, Test loss: 1.673, Test accuracy: 79.55 

Round  65, Train loss: 1.530, Test loss: 1.671, Test accuracy: 79.87 

Round  66, Train loss: 1.634, Test loss: 1.667, Test accuracy: 80.12 

Round  67, Train loss: 1.526, Test loss: 1.667, Test accuracy: 80.23 

Round  68, Train loss: 1.582, Test loss: 1.668, Test accuracy: 80.08 

Round  69, Train loss: 1.478, Test loss: 1.678, Test accuracy: 78.83 

Round  70, Train loss: 1.582, Test loss: 1.661, Test accuracy: 80.75 

Round  71, Train loss: 1.583, Test loss: 1.663, Test accuracy: 80.43 

Round  72, Train loss: 1.526, Test loss: 1.662, Test accuracy: 80.50 

Round  73, Train loss: 1.583, Test loss: 1.655, Test accuracy: 80.93 

Round  74, Train loss: 1.576, Test loss: 1.662, Test accuracy: 80.47 

Round  75, Train loss: 1.636, Test loss: 1.660, Test accuracy: 80.72 

Round  76, Train loss: 1.577, Test loss: 1.655, Test accuracy: 81.25 

Round  77, Train loss: 1.523, Test loss: 1.653, Test accuracy: 81.27 

Round  78, Train loss: 1.690, Test loss: 1.663, Test accuracy: 80.20 

Round  79, Train loss: 1.580, Test loss: 1.661, Test accuracy: 80.55 

Round  80, Train loss: 1.526, Test loss: 1.652, Test accuracy: 81.35 

Round  81, Train loss: 1.580, Test loss: 1.660, Test accuracy: 80.80 

Round  82, Train loss: 1.526, Test loss: 1.655, Test accuracy: 81.20 

Round  83, Train loss: 1.556, Test loss: 1.654, Test accuracy: 81.32 

Round  84, Train loss: 1.578, Test loss: 1.647, Test accuracy: 81.93 

Round  85, Train loss: 1.521, Test loss: 1.654, Test accuracy: 81.07 

Round  86, Train loss: 1.524, Test loss: 1.658, Test accuracy: 80.55 

Round  87, Train loss: 1.528, Test loss: 1.645, Test accuracy: 82.03 

Round  88, Train loss: 1.576, Test loss: 1.641, Test accuracy: 82.58 

Round  89, Train loss: 1.469, Test loss: 1.638, Test accuracy: 82.82 

Round  90, Train loss: 1.525, Test loss: 1.639, Test accuracy: 82.72 

Round  91, Train loss: 1.523, Test loss: 1.639, Test accuracy: 82.57 

Round  92, Train loss: 1.526, Test loss: 1.641, Test accuracy: 82.70 

Round  93, Train loss: 1.559, Test loss: 1.642, Test accuracy: 82.47 

Round  94, Train loss: 1.580, Test loss: 1.638, Test accuracy: 82.97 

Round  95, Train loss: 1.538, Test loss: 1.647, Test accuracy: 81.80 

Round  96, Train loss: 1.578, Test loss: 1.639, Test accuracy: 82.88 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.522, Test loss: 1.637, Test accuracy: 83.03 

Round  98, Train loss: 1.577, Test loss: 1.629, Test accuracy: 83.55 

Round  99, Train loss: 1.589, Test loss: 1.634, Test accuracy: 82.85 

Final Round, Train loss: 1.556, Test loss: 1.605, Test accuracy: 86.45 

Average accuracy final 10 rounds: 82.75333333333333 

335.63165950775146
[0.5076503753662109, 0.9305894374847412, 1.3529777526855469, 1.7784509658813477, 2.139484405517578, 2.5004806518554688, 2.8600409030914307, 3.217315912246704, 3.5730702877044678, 3.9293954372406006, 4.28516411781311, 4.642108201980591, 4.998359680175781, 5.353881359100342, 5.710408449172974, 6.066202163696289, 6.423068284988403, 6.782383680343628, 7.140927791595459, 7.501563549041748, 7.862861156463623, 8.222179174423218, 8.581423997879028, 8.942354679107666, 9.302262306213379, 9.661631345748901, 10.021280527114868, 10.38107943534851, 10.74156904220581, 11.10243034362793, 11.46246862411499, 11.822546243667603, 12.17950439453125, 12.539604902267456, 12.899739980697632, 13.259052276611328, 13.619000911712646, 13.977843046188354, 14.338510036468506, 14.699236392974854, 15.059563398361206, 15.420653104782104, 15.786574125289917, 16.145609855651855, 16.50552225112915, 16.880172729492188, 17.24205493927002, 17.601496696472168, 17.95956039428711, 18.319060564041138, 18.67499279975891, 19.04882788658142, 19.40805673599243, 19.767699718475342, 20.127294301986694, 20.48631191253662, 20.84628391265869, 21.205622673034668, 21.56160306930542, 21.918679237365723, 22.2754168510437, 22.630706310272217, 23.00382924079895, 23.358815670013428, 23.714232683181763, 24.08871626853943, 24.444881200790405, 24.800979375839233, 25.161292552947998, 25.517271518707275, 25.874018669128418, 26.230583906173706, 26.586130619049072, 26.942075490951538, 27.298091888427734, 27.65330410003662, 28.008479356765747, 28.363659620285034, 28.718891620635986, 29.07421612739563, 29.436193227767944, 29.793254852294922, 30.149344444274902, 30.505000114440918, 30.859909296035767, 31.21480917930603, 31.571095943450928, 31.93137550354004, 32.2870409488678, 32.642311811447144, 32.99742126464844, 33.351778507232666, 33.70758366584778, 34.06395769119263, 34.42482113838196, 34.782421588897705, 35.14178013801575, 35.50027918815613, 35.85728478431702, 36.21616315841675, 36.87063956260681]
[33.333333333333336, 38.36666666666667, 41.983333333333334, 49.45, 51.25, 50.35, 51.68333333333333, 51.416666666666664, 55.45, 55.11666666666667, 55.68333333333333, 57.983333333333334, 56.583333333333336, 58.9, 57.31666666666667, 59.36666666666667, 58.1, 59.36666666666667, 57.28333333333333, 59.21666666666667, 60.96666666666667, 61.93333333333333, 62.166666666666664, 62.6, 63.46666666666667, 64.65, 62.333333333333336, 65.05, 64.91666666666667, 67.63333333333334, 66.45, 67.6, 68.5, 67.08333333333333, 68.05, 66.98333333333333, 70.15, 69.31666666666666, 69.71666666666667, 73.55, 73.15, 72.5, 72.11666666666666, 73.63333333333334, 71.46666666666667, 74.2, 73.78333333333333, 73.88333333333334, 74.7, 76.1, 75.75, 75.95, 76.38333333333334, 76.83333333333333, 76.78333333333333, 76.88333333333334, 75.83333333333333, 76.93333333333334, 78.01666666666667, 77.6, 78.41666666666667, 77.66666666666667, 77.91666666666667, 77.91666666666667, 79.55, 79.86666666666666, 80.11666666666666, 80.23333333333333, 80.08333333333333, 78.83333333333333, 80.75, 80.43333333333334, 80.5, 80.93333333333334, 80.46666666666667, 80.71666666666667, 81.25, 81.26666666666667, 80.2, 80.55, 81.35, 80.8, 81.2, 81.31666666666666, 81.93333333333334, 81.06666666666666, 80.55, 82.03333333333333, 82.58333333333333, 82.81666666666666, 82.71666666666667, 82.56666666666666, 82.7, 82.46666666666667, 82.96666666666667, 81.8, 82.88333333333334, 83.03333333333333, 83.55, 82.85, 86.45]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.286, Test loss: 2.272, Test accuracy: 40.07 

Round   1, Train loss: 2.167, Test loss: 2.111, Test accuracy: 46.67 

Round   2, Train loss: 1.916, Test loss: 2.007, Test accuracy: 50.42 

Round   3, Train loss: 1.794, Test loss: 1.902, Test accuracy: 60.27 

Round   4, Train loss: 1.628, Test loss: 1.786, Test accuracy: 71.65 

Round   5, Train loss: 1.572, Test loss: 1.744, Test accuracy: 75.37 

Round   6, Train loss: 1.505, Test loss: 1.721, Test accuracy: 78.13 

Round   7, Train loss: 1.515, Test loss: 1.663, Test accuracy: 81.73 

Round   8, Train loss: 1.518, Test loss: 1.603, Test accuracy: 87.95 

Round   9, Train loss: 1.474, Test loss: 1.608, Test accuracy: 86.93 

Round  10, Train loss: 1.473, Test loss: 1.603, Test accuracy: 87.52 

Round  11, Train loss: 1.568, Test loss: 1.545, Test accuracy: 92.42 

Round  12, Train loss: 1.471, Test loss: 1.542, Test accuracy: 92.72 

Round  13, Train loss: 1.524, Test loss: 1.541, Test accuracy: 92.73 

Round  14, Train loss: 1.470, Test loss: 1.540, Test accuracy: 92.87 

Round  15, Train loss: 1.469, Test loss: 1.539, Test accuracy: 92.85 

Round  16, Train loss: 1.470, Test loss: 1.538, Test accuracy: 92.85 

Round  17, Train loss: 1.466, Test loss: 1.538, Test accuracy: 92.85 

Round  18, Train loss: 1.468, Test loss: 1.538, Test accuracy: 92.87 

Round  19, Train loss: 1.467, Test loss: 1.537, Test accuracy: 92.85 

Round  20, Train loss: 1.466, Test loss: 1.537, Test accuracy: 92.82 

Round  21, Train loss: 1.466, Test loss: 1.537, Test accuracy: 92.78 

Round  22, Train loss: 1.466, Test loss: 1.537, Test accuracy: 92.72 

Round  23, Train loss: 1.465, Test loss: 1.537, Test accuracy: 92.70 

Round  24, Train loss: 1.465, Test loss: 1.537, Test accuracy: 92.72 

Round  25, Train loss: 1.518, Test loss: 1.537, Test accuracy: 92.73 

Round  26, Train loss: 1.517, Test loss: 1.537, Test accuracy: 92.72 

Round  27, Train loss: 1.517, Test loss: 1.537, Test accuracy: 92.75 

Round  28, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.77 

Round  29, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.75 

Round  30, Train loss: 1.465, Test loss: 1.536, Test accuracy: 92.75 

Round  31, Train loss: 1.462, Test loss: 1.536, Test accuracy: 92.75 

Round  32, Train loss: 1.518, Test loss: 1.536, Test accuracy: 92.73 

Round  33, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.72 

Round  34, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.72 

Round  35, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.73 

Round  36, Train loss: 1.466, Test loss: 1.536, Test accuracy: 92.73 

Round  37, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.75 

Round  38, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.75 

Round  39, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.75 

Round  40, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.77 

Round  41, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.75 

Round  42, Train loss: 1.518, Test loss: 1.536, Test accuracy: 92.75 

Round  43, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.77 

Round  44, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.77 

Round  45, Train loss: 1.518, Test loss: 1.536, Test accuracy: 92.77 

Round  46, Train loss: 1.519, Test loss: 1.536, Test accuracy: 92.75 

Round  47, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.75 

Round  48, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.72 

Round  49, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.70 

Round  50, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.72 

Round  51, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.72 

Round  52, Train loss: 1.516, Test loss: 1.536, Test accuracy: 92.70 

Round  53, Train loss: 1.465, Test loss: 1.536, Test accuracy: 92.70 

Round  54, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.70 

Round  55, Train loss: 1.462, Test loss: 1.535, Test accuracy: 92.70 

Round  56, Train loss: 1.463, Test loss: 1.535, Test accuracy: 92.72 

Round  57, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.72 

Round  58, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.72 

Round  59, Train loss: 1.465, Test loss: 1.535, Test accuracy: 92.73 

Round  60, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.67 

Round  61, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.68 

Round  62, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.68 

Round  63, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.68 

Round  64, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.68 

Round  65, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.68 

Round  66, Train loss: 1.462, Test loss: 1.536, Test accuracy: 92.68 

Round  67, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.68 

Round  68, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.68 

Round  69, Train loss: 1.462, Test loss: 1.536, Test accuracy: 92.68 

Round  70, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.67 

Round  71, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.67 

Round  72, Train loss: 1.517, Test loss: 1.536, Test accuracy: 92.68 

Round  73, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.68 

Round  74, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.70 

Round  75, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.65 

Round  76, Train loss: 1.462, Test loss: 1.536, Test accuracy: 92.65 

Round  77, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.65 

Round  78, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.65 

Round  79, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.65 

Round  80, Train loss: 1.462, Test loss: 1.536, Test accuracy: 92.68 

Round  81, Train loss: 1.464, Test loss: 1.536, Test accuracy: 92.68 

Round  82, Train loss: 1.518, Test loss: 1.536, Test accuracy: 92.67 

Round  83, Train loss: 1.463, Test loss: 1.536, Test accuracy: 92.67 

Round  84, Train loss: 1.462, Test loss: 1.536, Test accuracy: 92.67 

Round  85, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.65 

Round  86, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.65 

Round  87, Train loss: 1.463, Test loss: 1.535, Test accuracy: 92.63 

Round  88, Train loss: 1.516, Test loss: 1.535, Test accuracy: 92.63 

Round  89, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.65 

Round  90, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.65 

Round  91, Train loss: 1.462, Test loss: 1.535, Test accuracy: 92.65 

Round  92, Train loss: 1.463, Test loss: 1.535, Test accuracy: 92.63 

Round  93, Train loss: 1.463, Test loss: 1.535, Test accuracy: 92.63 

Round  94, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.65 

Round  95, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.65 

Round  96, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.65 

Round  97, Train loss: 1.463, Test loss: 1.535, Test accuracy: 92.65 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  98, Train loss: 1.464, Test loss: 1.535, Test accuracy: 92.63 

Round  99, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.62 

Final Round, Train loss: 1.479, Test loss: 1.535, Test accuracy: 92.63 

Average accuracy final 10 rounds: 92.64166666666668 

375.8079357147217
[0.5359597206115723, 0.9668407440185547, 1.396562099456787, 1.8295183181762695, 2.262143850326538, 2.694075345993042, 3.124147415161133, 3.5548133850097656, 3.9849441051483154, 4.401538848876953, 4.81617283821106, 5.230779409408569, 5.643125057220459, 6.057911157608032, 6.464100122451782, 6.871938228607178, 7.276791334152222, 7.683144569396973, 8.090013027191162, 8.502619504928589, 8.917236804962158, 9.329092979431152, 9.740750789642334, 10.1531343460083, 10.565533638000488, 10.97891354560852, 11.391926527023315, 11.818340301513672, 12.24766230583191, 12.676175832748413, 13.105477094650269, 13.537465810775757, 13.969263315200806, 14.402129411697388, 14.832318782806396, 15.261942625045776, 15.692028522491455, 16.12450337409973, 16.558156728744507, 16.992091178894043, 17.42513155937195, 17.856900691986084, 18.29545021057129, 18.7282133102417, 19.159398317337036, 19.59181785583496, 20.02521276473999, 20.458251953125, 20.88869023323059, 21.321203231811523, 21.754087448120117, 22.186782598495483, 22.620821952819824, 23.055326223373413, 23.490572929382324, 23.920844078063965, 24.353972673416138, 24.787856101989746, 25.22198224067688, 25.655834674835205, 26.08984112739563, 26.525359630584717, 26.958518505096436, 27.39377474784851, 27.828315496444702, 28.262689352035522, 28.697038888931274, 29.13297986984253, 29.563934803009033, 29.996508598327637, 30.427019834518433, 30.856964111328125, 31.288606643676758, 31.722697257995605, 32.15581130981445, 32.58993077278137, 33.02390813827515, 33.4577374458313, 33.88845157623291, 34.31858801841736, 34.750385761260986, 35.18085432052612, 35.61468982696533, 36.04802966117859, 36.48344874382019, 36.91344428062439, 37.345038414001465, 37.779484033584595, 38.1482150554657, 38.516743898391724, 38.88501787185669, 39.2543888092041, 39.62337899208069, 39.99231195449829, 40.38643503189087, 40.7551543712616, 41.124107360839844, 41.49374008178711, 41.862730264663696, 42.23158860206604, 42.925938844680786]
[40.06666666666667, 46.666666666666664, 50.416666666666664, 60.266666666666666, 71.65, 75.36666666666666, 78.13333333333334, 81.73333333333333, 87.95, 86.93333333333334, 87.51666666666667, 92.41666666666667, 92.71666666666667, 92.73333333333333, 92.86666666666666, 92.85, 92.85, 92.85, 92.86666666666666, 92.85, 92.81666666666666, 92.78333333333333, 92.71666666666667, 92.7, 92.71666666666667, 92.73333333333333, 92.71666666666667, 92.75, 92.76666666666667, 92.75, 92.75, 92.75, 92.73333333333333, 92.71666666666667, 92.71666666666667, 92.73333333333333, 92.73333333333333, 92.75, 92.75, 92.75, 92.76666666666667, 92.75, 92.75, 92.76666666666667, 92.76666666666667, 92.76666666666667, 92.75, 92.75, 92.71666666666667, 92.7, 92.71666666666667, 92.71666666666667, 92.7, 92.7, 92.7, 92.7, 92.71666666666667, 92.71666666666667, 92.71666666666667, 92.73333333333333, 92.66666666666667, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.68333333333334, 92.66666666666667, 92.66666666666667, 92.68333333333334, 92.68333333333334, 92.7, 92.65, 92.65, 92.65, 92.65, 92.65, 92.68333333333334, 92.68333333333334, 92.66666666666667, 92.66666666666667, 92.66666666666667, 92.65, 92.65, 92.63333333333334, 92.63333333333334, 92.65, 92.65, 92.65, 92.63333333333334, 92.63333333333334, 92.65, 92.65, 92.65, 92.65, 92.63333333333334, 92.61666666666666, 92.63333333333334]
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 18, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.279, Test loss: 2.201, Test accuracy: 33.33
Round   1, Train loss: 2.091, Test loss: 2.086, Test accuracy: 34.03
Round   2, Train loss: 1.879, Test loss: 2.052, Test accuracy: 39.77
Round   3, Train loss: 1.833, Test loss: 2.037, Test accuracy: 41.73
Round   4, Train loss: 1.714, Test loss: 2.047, Test accuracy: 39.98
Round   5, Train loss: 1.715, Test loss: 2.014, Test accuracy: 43.37
Round   6, Train loss: 1.639, Test loss: 2.002, Test accuracy: 45.67
Round   7, Train loss: 1.779, Test loss: 2.025, Test accuracy: 42.45
Round   8, Train loss: 1.593, Test loss: 2.013, Test accuracy: 44.43
Round   9, Train loss: 1.612, Test loss: 2.025, Test accuracy: 43.20
Round  10, Train loss: 1.585, Test loss: 2.009, Test accuracy: 45.08
Round  11, Train loss: 1.660, Test loss: 2.005, Test accuracy: 44.70
Round  12, Train loss: 1.554, Test loss: 2.019, Test accuracy: 42.90
Round  13, Train loss: 1.534, Test loss: 1.998, Test accuracy: 46.25
Round  14, Train loss: 1.508, Test loss: 2.043, Test accuracy: 39.82
Round  15, Train loss: 1.537, Test loss: 1.999, Test accuracy: 46.25
Round  16, Train loss: 1.544, Test loss: 1.976, Test accuracy: 48.75
Round  17, Train loss: 1.495, Test loss: 1.984, Test accuracy: 47.38
Round  18, Train loss: 1.517, Test loss: 1.967, Test accuracy: 48.97
Round  19, Train loss: 1.485, Test loss: 1.986, Test accuracy: 47.27
Round  20, Train loss: 1.481, Test loss: 1.984, Test accuracy: 47.52
Round  21, Train loss: 1.478, Test loss: 1.969, Test accuracy: 49.08
Round  22, Train loss: 1.488, Test loss: 1.980, Test accuracy: 47.58
Round  23, Train loss: 1.516, Test loss: 1.997, Test accuracy: 46.13
Round  24, Train loss: 1.485, Test loss: 2.022, Test accuracy: 42.43
Round  25, Train loss: 1.483, Test loss: 1.998, Test accuracy: 45.55
Round  26, Train loss: 1.484, Test loss: 1.973, Test accuracy: 48.57
Round  27, Train loss: 1.482, Test loss: 1.981, Test accuracy: 47.87
Round  28, Train loss: 1.484, Test loss: 1.981, Test accuracy: 47.58
Round  29, Train loss: 1.483, Test loss: 1.991, Test accuracy: 46.22
Round  30, Train loss: 1.484, Test loss: 1.977, Test accuracy: 48.22
Round  31, Train loss: 1.480, Test loss: 1.973, Test accuracy: 48.57
Round  32, Train loss: 1.477, Test loss: 1.990, Test accuracy: 46.87
Round  33, Train loss: 1.480, Test loss: 1.953, Test accuracy: 50.87
Round  34, Train loss: 1.474, Test loss: 1.962, Test accuracy: 49.53
Round  35, Train loss: 1.484, Test loss: 1.966, Test accuracy: 49.13
Round  36, Train loss: 1.476, Test loss: 1.976, Test accuracy: 48.00
Round  37, Train loss: 1.481, Test loss: 1.973, Test accuracy: 48.42
Round  38, Train loss: 1.474, Test loss: 1.954, Test accuracy: 50.67
Round  39, Train loss: 1.478, Test loss: 2.041, Test accuracy: 41.07
Round  40, Train loss: 1.472, Test loss: 2.058, Test accuracy: 38.80
Round  41, Train loss: 1.475, Test loss: 1.991, Test accuracy: 45.87
Round  42, Train loss: 1.472, Test loss: 2.000, Test accuracy: 44.80
Round  43, Train loss: 1.476, Test loss: 1.983, Test accuracy: 47.78
Round  44, Train loss: 1.474, Test loss: 2.021, Test accuracy: 42.85
Round  45, Train loss: 1.477, Test loss: 1.961, Test accuracy: 49.37
Round  46, Train loss: 1.472, Test loss: 1.980, Test accuracy: 47.85
Round  47, Train loss: 1.470, Test loss: 1.956, Test accuracy: 50.28
Round  48, Train loss: 1.470, Test loss: 1.986, Test accuracy: 46.92
Round  49, Train loss: 1.470, Test loss: 1.944, Test accuracy: 51.60
Round  50, Train loss: 1.467, Test loss: 1.955, Test accuracy: 50.52
Round  51, Train loss: 1.473, Test loss: 1.953, Test accuracy: 51.13
Round  52, Train loss: 1.469, Test loss: 1.935, Test accuracy: 52.53
Round  53, Train loss: 1.471, Test loss: 2.005, Test accuracy: 44.78
Round  54, Train loss: 1.470, Test loss: 1.958, Test accuracy: 50.33
Round  55, Train loss: 1.470, Test loss: 1.952, Test accuracy: 50.40
Round  56, Train loss: 1.469, Test loss: 1.969, Test accuracy: 48.92
Round  57, Train loss: 1.469, Test loss: 1.946, Test accuracy: 51.50
Round  58, Train loss: 1.470, Test loss: 1.969, Test accuracy: 48.83
Round  59, Train loss: 1.473, Test loss: 2.014, Test accuracy: 43.87
Round  60, Train loss: 1.469, Test loss: 1.985, Test accuracy: 46.93
Round  61, Train loss: 1.470, Test loss: 1.980, Test accuracy: 48.17
Round  62, Train loss: 1.469, Test loss: 1.996, Test accuracy: 46.07
Round  63, Train loss: 1.469, Test loss: 2.040, Test accuracy: 41.35
Round  64, Train loss: 1.467, Test loss: 1.998, Test accuracy: 45.20
Round  65, Train loss: 1.469, Test loss: 1.975, Test accuracy: 47.53
Round  66, Train loss: 1.468, Test loss: 1.996, Test accuracy: 45.52
Round  67, Train loss: 1.466, Test loss: 1.960, Test accuracy: 50.08
Round  68, Train loss: 1.469, Test loss: 2.017, Test accuracy: 43.18
Round  69, Train loss: 1.466, Test loss: 1.966, Test accuracy: 49.00
Round  70, Train loss: 1.468, Test loss: 1.971, Test accuracy: 48.23
Round  71, Train loss: 1.465, Test loss: 1.971, Test accuracy: 48.47
Round  72, Train loss: 1.468, Test loss: 1.977, Test accuracy: 47.62
Round  73, Train loss: 1.468, Test loss: 1.969, Test accuracy: 48.92
Round  74, Train loss: 1.466, Test loss: 1.958, Test accuracy: 49.67
Round  75, Train loss: 1.469, Test loss: 1.993, Test accuracy: 46.00
Round  76, Train loss: 1.466, Test loss: 1.967, Test accuracy: 48.75
Round  77, Train loss: 1.466, Test loss: 1.961, Test accuracy: 49.47
Round  78, Train loss: 1.465, Test loss: 1.974, Test accuracy: 48.42
Round  79, Train loss: 1.467, Test loss: 1.950, Test accuracy: 50.67
Round  80, Train loss: 1.465, Test loss: 1.963, Test accuracy: 49.60
Round  81, Train loss: 1.468, Test loss: 1.967, Test accuracy: 49.53
Round  82, Train loss: 1.470, Test loss: 1.955, Test accuracy: 50.53
Round  83, Train loss: 1.465, Test loss: 1.965, Test accuracy: 48.63
Round  84, Train loss: 1.467, Test loss: 2.022, Test accuracy: 43.17
Round  85, Train loss: 1.467, Test loss: 2.038, Test accuracy: 41.07
Round  86, Train loss: 1.466, Test loss: 1.991, Test accuracy: 46.00
Round  87, Train loss: 1.465, Test loss: 1.942, Test accuracy: 51.77
Round  88, Train loss: 1.467, Test loss: 1.952, Test accuracy: 51.02
Round  89, Train loss: 1.466, Test loss: 2.003, Test accuracy: 44.73
Round  90, Train loss: 1.465, Test loss: 1.989, Test accuracy: 46.15
Round  91, Train loss: 1.465, Test loss: 1.999, Test accuracy: 45.22
Round  92, Train loss: 1.463, Test loss: 1.982, Test accuracy: 46.82
Round  93, Train loss: 1.465, Test loss: 1.956, Test accuracy: 50.37
Round  94, Train loss: 1.465, Test loss: 1.984, Test accuracy: 46.78
Round  95, Train loss: 1.465, Test loss: 1.998, Test accuracy: 46.00
Round  96, Train loss: 1.464, Test loss: 1.968, Test accuracy: 49.02
Round  97, Train loss: 1.465, Test loss: 1.990, Test accuracy: 45.98
Round  98, Train loss: 1.466, Test loss: 1.966, Test accuracy: 49.05
Round  99, Train loss: 1.467, Test loss: 1.980, Test accuracy: 47.72
Final Round, Train loss: 1.465, Test loss: 1.955, Test accuracy: 50.18
Average accuracy final 10 rounds: 47.31
760.166228055954
[1.2966995239257812, 2.4687106609344482, 3.6394309997558594, 4.8071608543396, 5.9761693477630615, 7.146061658859253, 8.31545376777649, 9.484874725341797, 10.653342485427856, 11.820929050445557, 12.988762140274048, 14.155590772628784, 15.318614721298218, 16.475495100021362, 17.610848426818848, 18.65246891975403, 19.690828323364258, 20.731526851654053, 21.773770093917847, 22.814872980117798, 23.853768348693848, 24.894848108291626, 25.936221599578857, 26.9822678565979, 28.020309686660767, 29.061283111572266, 30.100412845611572, 31.13970637321472, 32.18472194671631, 33.23886752128601, 34.3076753616333, 35.34384536743164, 36.375309467315674, 37.409191370010376, 38.440449714660645, 39.471901178359985, 40.50034832954407, 41.53148579597473, 42.56160569190979, 43.59124231338501, 44.62277173995972, 45.653916120529175, 46.71267485618591, 47.77969264984131, 48.80963349342346, 49.83935618400574, 50.8736138343811, 51.90764832496643, 52.93881130218506, 53.96887493133545, 54.999523401260376, 56.03245973587036, 57.06452822685242, 58.095025300979614, 59.12627601623535, 60.15723156929016, 61.18899416923523, 62.22100639343262, 63.25339937210083, 64.28337693214417, 65.31443881988525, 66.34614539146423, 67.38090872764587, 68.41203022003174, 69.44438552856445, 70.47652244567871, 71.50636267662048, 72.54048562049866, 73.57156562805176, 74.60319709777832, 75.63365912437439, 76.66856002807617, 77.70243382453918, 78.73296594619751, 79.76517391204834, 80.79782176017761, 81.83292174339294, 82.86439800262451, 83.89480829238892, 84.92811465263367, 85.96003270149231, 86.99026298522949, 88.02261924743652, 89.05769729614258, 90.08988523483276, 91.12215662002563, 92.15408253669739, 93.18930149078369, 94.22001194953918, 95.24896764755249, 96.28026103973389, 97.3090238571167, 98.34047222137451, 99.37295341491699, 100.40414214134216, 101.43982410430908, 102.47181439399719, 103.50146436691284, 104.53190183639526, 105.56242632865906, 106.59540581703186]/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[33.333333333333336, 34.03333333333333, 39.766666666666666, 41.733333333333334, 39.983333333333334, 43.36666666666667, 45.666666666666664, 42.45, 44.43333333333333, 43.2, 45.083333333333336, 44.7, 42.9, 46.25, 39.81666666666667, 46.25, 48.75, 47.38333333333333, 48.96666666666667, 47.266666666666666, 47.516666666666666, 49.083333333333336, 47.583333333333336, 46.13333333333333, 42.43333333333333, 45.55, 48.56666666666667, 47.86666666666667, 47.583333333333336, 46.21666666666667, 48.21666666666667, 48.56666666666667, 46.86666666666667, 50.86666666666667, 49.53333333333333, 49.13333333333333, 48.0, 48.416666666666664, 50.666666666666664, 41.06666666666667, 38.8, 45.86666666666667, 44.8, 47.78333333333333, 42.85, 49.36666666666667, 47.85, 50.28333333333333, 46.916666666666664, 51.6, 50.516666666666666, 51.13333333333333, 52.53333333333333, 44.78333333333333, 50.333333333333336, 50.4, 48.916666666666664, 51.5, 48.833333333333336, 43.86666666666667, 46.93333333333333, 48.166666666666664, 46.06666666666667, 41.35, 45.2, 47.53333333333333, 45.516666666666666, 50.083333333333336, 43.18333333333333, 49.0, 48.233333333333334, 48.46666666666667, 47.61666666666667, 48.916666666666664, 49.666666666666664, 46.0, 48.75, 49.46666666666667, 48.416666666666664, 50.666666666666664, 49.6, 49.53333333333333, 50.53333333333333, 48.63333333333333, 43.166666666666664, 41.06666666666667, 46.0, 51.766666666666666, 51.016666666666666, 44.733333333333334, 46.15, 45.21666666666667, 46.81666666666667, 50.36666666666667, 46.78333333333333, 46.0, 49.016666666666666, 45.983333333333334, 49.05, 47.71666666666667, 50.18333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.513, Test loss: 2.170, Test accuracy: 48.82
Round   1, Train loss: 1.183, Test loss: 1.987, Test accuracy: 55.63
Round   2, Train loss: 1.151, Test loss: 1.893, Test accuracy: 63.97
Round   3, Train loss: 1.222, Test loss: 1.835, Test accuracy: 70.00
Round   4, Train loss: 1.281, Test loss: 1.793, Test accuracy: 73.72
Round   5, Train loss: 1.212, Test loss: 1.745, Test accuracy: 78.10
Round   6, Train loss: 1.255, Test loss: 1.723, Test accuracy: 79.67
Round   7, Train loss: 1.213, Test loss: 1.680, Test accuracy: 83.70
Round   8, Train loss: 1.274, Test loss: 1.669, Test accuracy: 84.20
Round   9, Train loss: 1.120, Test loss: 1.648, Test accuracy: 86.37
Round  10, Train loss: 1.151, Test loss: 1.637, Test accuracy: 86.43
Round  11, Train loss: 1.116, Test loss: 1.627, Test accuracy: 86.55
Round  12, Train loss: 1.109, Test loss: 1.619, Test accuracy: 87.07
Round  13, Train loss: 1.185, Test loss: 1.619, Test accuracy: 86.90
Round  14, Train loss: 1.103, Test loss: 1.616, Test accuracy: 86.83
Round  15, Train loss: 1.187, Test loss: 1.614, Test accuracy: 86.63
Round  16, Train loss: 1.144, Test loss: 1.612, Test accuracy: 86.57
Round  17, Train loss: 1.184, Test loss: 1.611, Test accuracy: 86.45
Round  18, Train loss: 1.226, Test loss: 1.604, Test accuracy: 87.27
Round  19, Train loss: 1.144, Test loss: 1.594, Test accuracy: 88.17
Round  20, Train loss: 1.185, Test loss: 1.593, Test accuracy: 88.20
Round  21, Train loss: 1.184, Test loss: 1.593, Test accuracy: 88.15
Round  22, Train loss: 1.189, Test loss: 1.592, Test accuracy: 88.22
Round  23, Train loss: 1.142, Test loss: 1.591, Test accuracy: 88.20
Round  24, Train loss: 1.102, Test loss: 1.591, Test accuracy: 88.28
Round  25, Train loss: 1.144, Test loss: 1.592, Test accuracy: 87.95
Round  26, Train loss: 1.142, Test loss: 1.591, Test accuracy: 87.97
Round  27, Train loss: 1.141, Test loss: 1.591, Test accuracy: 87.83
Round  28, Train loss: 1.142, Test loss: 1.591, Test accuracy: 87.88
Round  29, Train loss: 1.140, Test loss: 1.590, Test accuracy: 87.93
Round  30, Train loss: 1.142, Test loss: 1.589, Test accuracy: 87.92
Round  31, Train loss: 1.184, Test loss: 1.588, Test accuracy: 87.90
Round  32, Train loss: 1.142, Test loss: 1.588, Test accuracy: 87.95
Round  33, Train loss: 1.140, Test loss: 1.589, Test accuracy: 87.93
Round  34, Train loss: 1.143, Test loss: 1.588, Test accuracy: 87.87
Round  35, Train loss: 1.099, Test loss: 1.588, Test accuracy: 87.77
Round  36, Train loss: 1.184, Test loss: 1.588, Test accuracy: 87.82
Round  37, Train loss: 1.181, Test loss: 1.588, Test accuracy: 87.83
Round  38, Train loss: 1.224, Test loss: 1.589, Test accuracy: 87.68
Round  39, Train loss: 1.184, Test loss: 1.590, Test accuracy: 87.65
Round  40, Train loss: 1.175, Test loss: 1.580, Test accuracy: 88.40
Round  41, Train loss: 1.144, Test loss: 1.579, Test accuracy: 88.45
Round  42, Train loss: 1.141, Test loss: 1.579, Test accuracy: 88.47
Round  43, Train loss: 1.102, Test loss: 1.579, Test accuracy: 88.50
Round  44, Train loss: 1.144, Test loss: 1.575, Test accuracy: 89.00
Round  45, Train loss: 1.142, Test loss: 1.576, Test accuracy: 88.93
Round  46, Train loss: 1.143, Test loss: 1.575, Test accuracy: 88.93
Round  47, Train loss: 1.102, Test loss: 1.576, Test accuracy: 88.85
Round  48, Train loss: 1.111, Test loss: 1.565, Test accuracy: 89.97
Round  49, Train loss: 1.141, Test loss: 1.563, Test accuracy: 90.10
Round  50, Train loss: 1.101, Test loss: 1.563, Test accuracy: 90.08
Round  51, Train loss: 1.141, Test loss: 1.563, Test accuracy: 90.13
Round  52, Train loss: 1.139, Test loss: 1.563, Test accuracy: 90.10
Round  53, Train loss: 1.100, Test loss: 1.564, Test accuracy: 90.02
Round  54, Train loss: 1.182, Test loss: 1.563, Test accuracy: 90.08
Round  55, Train loss: 1.142, Test loss: 1.564, Test accuracy: 90.03
Round  56, Train loss: 1.140, Test loss: 1.563, Test accuracy: 89.98
Round  57, Train loss: 1.139, Test loss: 1.563, Test accuracy: 90.12
Round  58, Train loss: 1.141, Test loss: 1.563, Test accuracy: 90.03
Round  59, Train loss: 1.182, Test loss: 1.563, Test accuracy: 90.10
Round  60, Train loss: 1.100, Test loss: 1.561, Test accuracy: 90.40
Round  61, Train loss: 1.100, Test loss: 1.562, Test accuracy: 90.27
Round  62, Train loss: 1.100, Test loss: 1.561, Test accuracy: 90.45
Round  63, Train loss: 1.141, Test loss: 1.561, Test accuracy: 90.27
Round  64, Train loss: 1.100, Test loss: 1.561, Test accuracy: 90.33
Round  65, Train loss: 1.100, Test loss: 1.561, Test accuracy: 90.28
Round  66, Train loss: 1.139, Test loss: 1.561, Test accuracy: 90.23
Round  67, Train loss: 1.098, Test loss: 1.562, Test accuracy: 90.17
Round  68, Train loss: 1.122, Test loss: 1.551, Test accuracy: 91.17
Round  69, Train loss: 1.146, Test loss: 1.549, Test accuracy: 91.38
Round  70, Train loss: 1.142, Test loss: 1.548, Test accuracy: 91.50
Round  71, Train loss: 1.098, Test loss: 1.547, Test accuracy: 91.58
Round  72, Train loss: 1.140, Test loss: 1.548, Test accuracy: 91.53
Round  73, Train loss: 1.098, Test loss: 1.547, Test accuracy: 91.68
Round  74, Train loss: 1.100, Test loss: 1.547, Test accuracy: 91.70
Round  75, Train loss: 1.099, Test loss: 1.547, Test accuracy: 91.58
Round  76, Train loss: 1.099, Test loss: 1.547, Test accuracy: 91.55
Round  77, Train loss: 1.143, Test loss: 1.547, Test accuracy: 91.57
Round  78, Train loss: 1.139, Test loss: 1.547, Test accuracy: 91.58
Round  79, Train loss: 1.101, Test loss: 1.547, Test accuracy: 91.63
Round  80, Train loss: 1.130, Test loss: 1.544, Test accuracy: 91.90
Round  81, Train loss: 1.104, Test loss: 1.534, Test accuracy: 92.82
Round  82, Train loss: 1.100, Test loss: 1.531, Test accuracy: 93.18
Round  83, Train loss: 1.098, Test loss: 1.530, Test accuracy: 93.22
Round  84, Train loss: 1.100, Test loss: 1.530, Test accuracy: 93.35
Round  85, Train loss: 1.099, Test loss: 1.529, Test accuracy: 93.48
Round  86, Train loss: 1.100, Test loss: 1.529, Test accuracy: 93.47
Round  87, Train loss: 1.098, Test loss: 1.529, Test accuracy: 93.47
Round  88, Train loss: 1.100, Test loss: 1.529, Test accuracy: 93.47
Round  89, Train loss: 1.099, Test loss: 1.530, Test accuracy: 93.33
Round  90, Train loss: 1.100, Test loss: 1.530, Test accuracy: 93.28
Round  91, Train loss: 1.099, Test loss: 1.530, Test accuracy: 93.18
Round  92, Train loss: 1.100, Test loss: 1.530, Test accuracy: 93.25
Round  93, Train loss: 1.100, Test loss: 1.530, Test accuracy: 93.37
Round  94, Train loss: 1.099, Test loss: 1.531, Test accuracy: 93.15
Round  95, Train loss: 1.097, Test loss: 1.531, Test accuracy: 93.08
Round  96, Train loss: 1.100, Test loss: 1.532, Test accuracy: 93.05
Round  97, Train loss: 1.101, Test loss: 1.532, Test accuracy: 93.08
Round  98, Train loss: 1.099, Test loss: 1.532, Test accuracy: 92.97
Round  99, Train loss: 1.098, Test loss: 1.531, Test accuracy: 93.07
Final Round, Train loss: 1.099, Test loss: 1.533, Test accuracy: 92.83
Average accuracy final 10 rounds: 93.14833333333335
629.5056250095367
[]
[48.81666666666667, 55.63333333333333, 63.96666666666667, 70.0, 73.71666666666667, 78.1, 79.66666666666667, 83.7, 84.2, 86.36666666666666, 86.43333333333334, 86.55, 87.06666666666666, 86.9, 86.83333333333333, 86.63333333333334, 86.56666666666666, 86.45, 87.26666666666667, 88.16666666666667, 88.2, 88.15, 88.21666666666667, 88.2, 88.28333333333333, 87.95, 87.96666666666667, 87.83333333333333, 87.88333333333334, 87.93333333333334, 87.91666666666667, 87.9, 87.95, 87.93333333333334, 87.86666666666666, 87.76666666666667, 87.81666666666666, 87.83333333333333, 87.68333333333334, 87.65, 88.4, 88.45, 88.46666666666667, 88.5, 89.0, 88.93333333333334, 88.93333333333334, 88.85, 89.96666666666667, 90.1, 90.08333333333333, 90.13333333333334, 90.1, 90.01666666666667, 90.08333333333333, 90.03333333333333, 89.98333333333333, 90.11666666666666, 90.03333333333333, 90.1, 90.4, 90.26666666666667, 90.45, 90.26666666666667, 90.33333333333333, 90.28333333333333, 90.23333333333333, 90.16666666666667, 91.16666666666667, 91.38333333333334, 91.5, 91.58333333333333, 91.53333333333333, 91.68333333333334, 91.7, 91.58333333333333, 91.55, 91.56666666666666, 91.58333333333333, 91.63333333333334, 91.9, 92.81666666666666, 93.18333333333334, 93.21666666666667, 93.35, 93.48333333333333, 93.46666666666667, 93.46666666666667, 93.46666666666667, 93.33333333333333, 93.28333333333333, 93.18333333333334, 93.25, 93.36666666666666, 93.15, 93.08333333333333, 93.05, 93.08333333333333, 92.96666666666667, 93.06666666666666, 92.83333333333333]/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.189, Test loss: 2.169, Test accuracy: 27.04
Round   0: Global train loss: 2.189, Global test loss: 2.302, Global test accuracy: 10.39
Round   1, Train loss: 1.969, Test loss: 2.100, Test accuracy: 34.58
Round   1: Global train loss: 1.969, Global test loss: 2.302, Global test accuracy: 12.57
Round   2, Train loss: 1.906, Test loss: 2.048, Test accuracy: 39.53
Round   2: Global train loss: 1.906, Global test loss: 2.301, Global test accuracy: 13.29
Round   3, Train loss: 1.817, Test loss: 2.035, Test accuracy: 40.36
Round   3: Global train loss: 1.817, Global test loss: 2.301, Global test accuracy: 13.62
Round   4, Train loss: 1.706, Test loss: 1.984, Test accuracy: 46.47
Round   4: Global train loss: 1.706, Global test loss: 2.299, Global test accuracy: 14.54
Round   5, Train loss: 1.806, Test loss: 2.001, Test accuracy: 46.23
Round   5: Global train loss: 1.806, Global test loss: 2.299, Global test accuracy: 14.46
Round   6, Train loss: 1.442, Test loss: 1.997, Test accuracy: 46.85
Round   6: Global train loss: 1.442, Global test loss: 2.298, Global test accuracy: 14.11
Round   7, Train loss: 0.973, Test loss: 1.948, Test accuracy: 51.02
Round   7: Global train loss: 0.973, Global test loss: 2.295, Global test accuracy: 14.96
Round   8, Train loss: 1.222, Test loss: 1.888, Test accuracy: 57.49
Round   8: Global train loss: 1.222, Global test loss: 2.293, Global test accuracy: 14.77
Round   9, Train loss: 1.100, Test loss: 1.835, Test accuracy: 63.08
Round   9: Global train loss: 1.100, Global test loss: 2.290, Global test accuracy: 14.83
Round  10, Train loss: 0.432, Test loss: 1.798, Test accuracy: 66.70
Round  10: Global train loss: 0.432, Global test loss: 2.285, Global test accuracy: 15.02
Round  11, Train loss: 1.028, Test loss: 1.804, Test accuracy: 66.50
Round  11: Global train loss: 1.028, Global test loss: 2.282, Global test accuracy: 15.09
Round  12, Train loss: 1.073, Test loss: 1.811, Test accuracy: 65.65
Round  12: Global train loss: 1.073, Global test loss: 2.282, Global test accuracy: 15.05
Round  13, Train loss: 0.873, Test loss: 1.789, Test accuracy: 67.91
Round  13: Global train loss: 0.873, Global test loss: 2.281, Global test accuracy: 15.60
Round  14, Train loss: 1.039, Test loss: 1.757, Test accuracy: 70.69
Round  14: Global train loss: 1.039, Global test loss: 2.278, Global test accuracy: 16.48
Round  15, Train loss: 0.954, Test loss: 1.780, Test accuracy: 68.25
Round  15: Global train loss: 0.954, Global test loss: 2.277, Global test accuracy: 16.55
Round  16, Train loss: 0.568, Test loss: 1.754, Test accuracy: 70.76
Round  16: Global train loss: 0.568, Global test loss: 2.273, Global test accuracy: 17.23
Round  17, Train loss: 0.358, Test loss: 1.741, Test accuracy: 72.09
Round  17: Global train loss: 0.358, Global test loss: 2.272, Global test accuracy: 17.53
Round  18, Train loss: 0.600, Test loss: 1.766, Test accuracy: 69.56
Round  18: Global train loss: 0.600, Global test loss: 2.272, Global test accuracy: 18.05
Round  19, Train loss: 0.452, Test loss: 1.746, Test accuracy: 71.46
Round  19: Global train loss: 0.452, Global test loss: 2.274, Global test accuracy: 17.67
Round  20, Train loss: -0.194, Test loss: 1.720, Test accuracy: 74.09
Round  20: Global train loss: -0.194, Global test loss: 2.276, Global test accuracy: 16.03
Round  21, Train loss: 0.162, Test loss: 1.718, Test accuracy: 74.27
Round  21: Global train loss: 0.162, Global test loss: 2.277, Global test accuracy: 15.82
Round  22, Train loss: 0.345, Test loss: 1.730, Test accuracy: 73.06
Round  22: Global train loss: 0.345, Global test loss: 2.278, Global test accuracy: 15.74
Round  23, Train loss: 0.130, Test loss: 1.725, Test accuracy: 73.59
Round  23: Global train loss: 0.130, Global test loss: 2.274, Global test accuracy: 16.72
Round  24, Train loss: 0.243, Test loss: 1.746, Test accuracy: 71.38
Round  24: Global train loss: 0.243, Global test loss: 2.271, Global test accuracy: 17.16
Round  25, Train loss: 0.130, Test loss: 1.744, Test accuracy: 71.63
Round  25: Global train loss: 0.130, Global test loss: 2.278, Global test accuracy: 16.01
Round  26, Train loss: 0.186, Test loss: 1.736, Test accuracy: 72.46
Round  26: Global train loss: 0.186, Global test loss: 2.272, Global test accuracy: 17.06
Round  27, Train loss: -0.162, Test loss: 1.713, Test accuracy: 74.75
Round  27: Global train loss: -0.162, Global test loss: 2.267, Global test accuracy: 18.07
Round  28, Train loss: 0.163, Test loss: 1.730, Test accuracy: 73.01
Round  28: Global train loss: 0.163, Global test loss: 2.264, Global test accuracy: 18.55
Round  29, Train loss: -0.154, Test loss: 1.728, Test accuracy: 73.17
Round  29: Global train loss: -0.154, Global test loss: 2.265, Global test accuracy: 18.30
Round  30, Train loss: 0.174, Test loss: 1.683, Test accuracy: 77.77
Round  30: Global train loss: 0.174, Global test loss: 2.264, Global test accuracy: 18.29
Round  31, Train loss: 0.083, Test loss: 1.664, Test accuracy: 79.72
Round  31: Global train loss: 0.083, Global test loss: 2.265, Global test accuracy: 17.98
Round  32, Train loss: -0.681, Test loss: 1.666, Test accuracy: 79.39
Round  32: Global train loss: -0.681, Global test loss: 2.265, Global test accuracy: 18.01
Round  33, Train loss: -0.217, Test loss: 1.704, Test accuracy: 75.66
Round  33: Global train loss: -0.217, Global test loss: 2.262, Global test accuracy: 18.66
Round  34, Train loss: -0.322, Test loss: 1.718, Test accuracy: 74.21
Round  34: Global train loss: -0.322, Global test loss: 2.262, Global test accuracy: 18.70
Round  35, Train loss: -0.686, Test loss: 1.720, Test accuracy: 73.96
Round  35: Global train loss: -0.686, Global test loss: 2.261, Global test accuracy: 18.81
Round  36, Train loss: -0.248, Test loss: 1.696, Test accuracy: 76.37
Round  36: Global train loss: -0.248, Global test loss: 2.261, Global test accuracy: 18.54
Round  37, Train loss: -0.488, Test loss: 1.680, Test accuracy: 78.06
Round  37: Global train loss: -0.488, Global test loss: 2.263, Global test accuracy: 17.91
Round  38, Train loss: -0.647, Test loss: 1.672, Test accuracy: 78.86
Round  38: Global train loss: -0.647, Global test loss: 2.263, Global test accuracy: 18.13
Round  39, Train loss: -0.597, Test loss: 1.658, Test accuracy: 80.23
Round  39: Global train loss: -0.597, Global test loss: 2.262, Global test accuracy: 18.11
Round  40, Train loss: -1.130, Test loss: 1.625, Test accuracy: 83.52
Round  40: Global train loss: -1.130, Global test loss: 2.258, Global test accuracy: 18.85
Round  41, Train loss: -0.058, Test loss: 1.662, Test accuracy: 79.81
Round  41: Global train loss: -0.058, Global test loss: 2.258, Global test accuracy: 18.57
Round  42, Train loss: -0.490, Test loss: 1.659, Test accuracy: 80.15
Round  42: Global train loss: -0.490, Global test loss: 2.254, Global test accuracy: 19.04
Round  43, Train loss: -0.082, Test loss: 1.682, Test accuracy: 77.88
Round  43: Global train loss: -0.082, Global test loss: 2.252, Global test accuracy: 19.47
Round  44, Train loss: -0.535, Test loss: 1.666, Test accuracy: 79.46
Round  44: Global train loss: -0.535, Global test loss: 2.251, Global test accuracy: 19.79
Round  45, Train loss: -0.379, Test loss: 1.660, Test accuracy: 80.13
Round  45: Global train loss: -0.379, Global test loss: 2.251, Global test accuracy: 19.66
Round  46, Train loss: -0.650, Test loss: 1.661, Test accuracy: 79.99
Round  46: Global train loss: -0.650, Global test loss: 2.251, Global test accuracy: 19.63
Round  47, Train loss: -1.058, Test loss: 1.654, Test accuracy: 80.70
Round  47: Global train loss: -1.058, Global test loss: 2.248, Global test accuracy: 19.88
Round  48, Train loss: -0.913, Test loss: 1.641, Test accuracy: 81.95
Round  48: Global train loss: -0.913, Global test loss: 2.251, Global test accuracy: 19.69
Round  49, Train loss: -0.792, Test loss: 1.648, Test accuracy: 81.31
Round  49: Global train loss: -0.792, Global test loss: 2.248, Global test accuracy: 20.04
Round  50, Train loss: -0.286, Test loss: 1.658, Test accuracy: 80.24
Round  50: Global train loss: -0.286, Global test loss: 2.248, Global test accuracy: 20.09
Round  51, Train loss: -0.426, Test loss: 1.660, Test accuracy: 80.08
Round  51: Global train loss: -0.426, Global test loss: 2.251, Global test accuracy: 19.29
Round  52, Train loss: -1.047, Test loss: 1.648, Test accuracy: 81.25
Round  52: Global train loss: -1.047, Global test loss: 2.253, Global test accuracy: 18.93
Round  53, Train loss: -0.360, Test loss: 1.636, Test accuracy: 82.52
Round  53: Global train loss: -0.360, Global test loss: 2.251, Global test accuracy: 19.26
Round  54, Train loss: -0.439, Test loss: 1.618, Test accuracy: 84.28
Round  54: Global train loss: -0.439, Global test loss: 2.252, Global test accuracy: 18.97
Round  55, Train loss: -0.908, Test loss: 1.616, Test accuracy: 84.46
Round  55: Global train loss: -0.908, Global test loss: 2.251, Global test accuracy: 19.29
Round  56, Train loss: -0.627, Test loss: 1.625, Test accuracy: 83.60
Round  56: Global train loss: -0.627, Global test loss: 2.248, Global test accuracy: 19.74
Round  57, Train loss: -0.649, Test loss: 1.634, Test accuracy: 82.63
Round  57: Global train loss: -0.649, Global test loss: 2.250, Global test accuracy: 19.39
Round  58, Train loss: -0.924, Test loss: 1.614, Test accuracy: 84.64
Round  58: Global train loss: -0.924, Global test loss: 2.250, Global test accuracy: 19.26
Round  59, Train loss: -0.922, Test loss: 1.627, Test accuracy: 83.37
Round  59: Global train loss: -0.922, Global test loss: 2.249, Global test accuracy: 19.64
Round  60, Train loss: -0.842, Test loss: 1.624, Test accuracy: 83.66
Round  60: Global train loss: -0.842, Global test loss: 2.249, Global test accuracy: 19.72
Round  61, Train loss: -0.404, Test loss: 1.635, Test accuracy: 82.52
Round  61: Global train loss: -0.404, Global test loss: 2.248, Global test accuracy: 19.69
Round  62, Train loss: -0.913, Test loss: 1.640, Test accuracy: 82.00
Round  62: Global train loss: -0.913, Global test loss: 2.248, Global test accuracy: 19.81
Round  63, Train loss: -0.663, Test loss: 1.644, Test accuracy: 81.58
Round  63: Global train loss: -0.663, Global test loss: 2.248, Global test accuracy: 19.89
Round  64, Train loss: -0.773, Test loss: 1.638, Test accuracy: 82.26
Round  64: Global train loss: -0.773, Global test loss: 2.250, Global test accuracy: 19.14
Round  65, Train loss: -0.825, Test loss: 1.645, Test accuracy: 81.54
Round  65: Global train loss: -0.825, Global test loss: 2.248, Global test accuracy: 19.58
Round  66, Train loss: -0.664, Test loss: 1.622, Test accuracy: 83.86
Round  66: Global train loss: -0.664, Global test loss: 2.247, Global test accuracy: 19.56
Round  67, Train loss: -1.119, Test loss: 1.618, Test accuracy: 84.31
Round  67: Global train loss: -1.119, Global test loss: 2.247, Global test accuracy: 19.64
Round  68, Train loss: -0.849, Test loss: 1.638, Test accuracy: 82.27
Round  68: Global train loss: -0.849, Global test loss: 2.248, Global test accuracy: 19.50
Round  69, Train loss: -0.785, Test loss: 1.645, Test accuracy: 81.53
Round  69: Global train loss: -0.785, Global test loss: 2.247, Global test accuracy: 19.71
Round  70, Train loss: -0.931, Test loss: 1.649, Test accuracy: 81.16
Round  70: Global train loss: -0.931, Global test loss: 2.248, Global test accuracy: 19.67
Round  71, Train loss: -1.137, Test loss: 1.637, Test accuracy: 82.36
Round  71: Global train loss: -1.137, Global test loss: 2.248, Global test accuracy: 19.46
Round  72, Train loss: -0.496, Test loss: 1.627, Test accuracy: 83.31
Round  72: Global train loss: -0.496, Global test loss: 2.247, Global test accuracy: 19.57
Round  73, Train loss: -1.223, Test loss: 1.628, Test accuracy: 83.26
Round  73: Global train loss: -1.223, Global test loss: 2.248, Global test accuracy: 19.55
Round  74, Train loss: -1.062, Test loss: 1.637, Test accuracy: 82.38
Round  74: Global train loss: -1.062, Global test loss: 2.248, Global test accuracy: 19.39
Round  75, Train loss: -1.321, Test loss: 1.620, Test accuracy: 84.14
Round  75: Global train loss: -1.321, Global test loss: 2.247, Global test accuracy: 19.45
Round  76, Train loss: -1.161, Test loss: 1.599, Test accuracy: 86.22
Round  76: Global train loss: -1.161, Global test loss: 2.244, Global test accuracy: 19.91
Round  77, Train loss: -0.428, Test loss: 1.633, Test accuracy: 82.81
Round  77: Global train loss: -0.428, Global test loss: 2.246, Global test accuracy: 19.69
Round  78, Train loss: -0.785, Test loss: 1.627, Test accuracy: 83.35
Round  78: Global train loss: -0.785, Global test loss: 2.246, Global test accuracy: 19.64
Round  79, Train loss: -1.158, Test loss: 1.625, Test accuracy: 83.54
Round  79: Global train loss: -1.158, Global test loss: 2.246, Global test accuracy: 19.39
Round  80, Train loss: -1.133, Test loss: 1.622, Test accuracy: 83.85
Round  80: Global train loss: -1.133, Global test loss: 2.246, Global test accuracy: 19.27
Round  81, Train loss: -1.066, Test loss: 1.618, Test accuracy: 84.22
Round  81: Global train loss: -1.066, Global test loss: 2.245, Global test accuracy: 19.44
Round  82, Train loss: -0.573, Test loss: 1.631, Test accuracy: 82.96
Round  82: Global train loss: -0.573, Global test loss: 2.245, Global test accuracy: 19.71
Round  83, Train loss: -1.409, Test loss: 1.613, Test accuracy: 84.74
Round  83: Global train loss: -1.409, Global test loss: 2.246, Global test accuracy: 19.52
Round  84, Train loss: -1.063, Test loss: 1.604, Test accuracy: 85.70
Round  84: Global train loss: -1.063, Global test loss: 2.245, Global test accuracy: 19.64
Round  85, Train loss: -0.947, Test loss: 1.598, Test accuracy: 86.25
Round  85: Global train loss: -0.947, Global test loss: 2.247, Global test accuracy: 19.39
Round  86, Train loss: -0.549, Test loss: 1.624, Test accuracy: 83.68
Round  86: Global train loss: -0.549, Global test loss: 2.246, Global test accuracy: 19.50
Round  87, Train loss: -0.922, Test loss: 1.634, Test accuracy: 82.64
Round  87: Global train loss: -0.922, Global test loss: 2.246, Global test accuracy: 19.58
Round  88, Train loss: -1.217, Test loss: 1.618, Test accuracy: 84.28
Round  88: Global train loss: -1.217, Global test loss: 2.246, Global test accuracy: 19.69
Round  89, Train loss: -1.083, Test loss: 1.613, Test accuracy: 84.78
Round  89: Global train loss: -1.083, Global test loss: 2.245, Global test accuracy: 19.84
Round  90, Train loss: -0.941, Test loss: 1.628, Test accuracy: 83.25
Round  90: Global train loss: -0.941, Global test loss: 2.247, Global test accuracy: 19.53
Round  91, Train loss: -0.750, Test loss: 1.626, Test accuracy: 83.44
Round  91: Global train loss: -0.750, Global test loss: 2.246, Global test accuracy: 19.68
Round  92, Train loss: -1.120, Test loss: 1.622, Test accuracy: 83.91
Round  92: Global train loss: -1.120, Global test loss: 2.245, Global test accuracy: 19.72
Round  93, Train loss: -0.988, Test loss: 1.628, Test accuracy: 83.19
Round  93: Global train loss: -0.988, Global test loss: 2.244, Global test accuracy: 19.89
Round  94, Train loss: -1.100, Test loss: 1.629, Test accuracy: 83.08
Round  94: Global train loss: -1.100, Global test loss: 2.245, Global test accuracy: 19.89
Round  95, Train loss: -0.965, Test loss: 1.602, Test accuracy: 85.79
Round  95: Global train loss: -0.965, Global test loss: 2.240, Global test accuracy: 20.46
Round  96, Train loss: -0.953, Test loss: 1.607, Test accuracy: 85.33
Round  96: Global train loss: -0.953, Global test loss: 2.240, Global test accuracy: 20.51
Round  97, Train loss: -1.074, Test loss: 1.616, Test accuracy: 84.48
Round  97: Global train loss: -1.074, Global test loss: 2.241, Global test accuracy: 20.45
Round  98, Train loss: -0.864, Test loss: 1.628, Test accuracy: 83.29
Round  98: Global train loss: -0.864, Global test loss: 2.243, Global test accuracy: 20.22/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: -1.211, Test loss: 1.600, Test accuracy: 86.06
Round  99: Global train loss: -1.211, Global test loss: 2.243, Global test accuracy: 20.20
Final Round: Train loss: 1.784, Test loss: 1.748, Test accuracy: 71.41
Final Round: Global train loss: 1.784, Global test loss: 2.242, Global test accuracy: 20.24
Average accuracy final 10 rounds: 84.18033333333334
Average global accuracy final 10 rounds: 20.055333333333333
5806.166157245636
[]
[27.038333333333334, 34.583333333333336, 39.526666666666664, 40.36, 46.47, 46.23166666666667, 46.855, 51.02333333333333, 57.486666666666665, 63.075, 66.70333333333333, 66.5, 65.65333333333334, 67.91333333333333, 70.685, 68.25166666666667, 70.75666666666666, 72.09333333333333, 69.56333333333333, 71.45833333333333, 74.09166666666667, 74.27, 73.055, 73.595, 71.37666666666667, 71.63, 72.46166666666667, 74.755, 73.01, 73.175, 77.77333333333333, 79.71833333333333, 79.39333333333333, 75.66166666666666, 74.20833333333333, 73.95833333333333, 76.36833333333334, 78.06166666666667, 78.86166666666666, 80.22833333333334, 83.52333333333333, 79.805, 80.15166666666667, 77.87666666666667, 79.46333333333334, 80.12833333333333, 79.99166666666666, 80.70333333333333, 81.94833333333334, 81.31333333333333, 80.24333333333334, 80.08166666666666, 81.25333333333333, 82.52333333333333, 84.28166666666667, 84.46333333333334, 83.60166666666667, 82.63, 84.64, 83.36666666666666, 83.65666666666667, 82.51833333333333, 81.995, 81.58333333333333, 82.26, 81.54166666666667, 83.86, 84.30833333333334, 82.26833333333333, 81.525, 81.155, 82.355, 83.31166666666667, 83.26333333333334, 82.37833333333333, 84.13666666666667, 86.225, 82.805, 83.35333333333334, 83.54333333333334, 83.85166666666667, 84.22333333333333, 82.96333333333334, 84.74333333333334, 85.70166666666667, 86.245, 83.67666666666666, 82.63666666666667, 84.27833333333334, 84.785, 83.24666666666667, 83.435, 83.90666666666667, 83.19333333333333, 83.07666666666667, 85.78833333333333, 85.32833333333333, 84.47666666666667, 83.28833333333333, 86.06333333333333, 71.41333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round   0, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.00 

Round   1, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.01 

Round   1, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.01 

Round   2, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.01 

Round   2, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.99 

Round   3, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.01 

Round   3, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98 

Round   4, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.04 

Round   4, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.96 

Round   5, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.04 

Round   5, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.95 

Round   6, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round   6, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round   7, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.04 

Round   7, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98 

Round   8, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.04 

Round   8, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98 

Round   9, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round   9, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.99 

Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round  10, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.99 

Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round  11, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.01 

Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.02 

Round  12, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.01 

Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round  13, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.00 

Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round  14, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.00 

Round  15, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.05 

Round  15, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.00 

Round  16, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.03 

Round  16, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.00 

Round  17, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.03 

Round  17, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.00 

Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.02 

Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.99 

Round  19, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.02 

Round  19, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.01 

Round  20, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.03 

Round  20, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.00 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.02 

Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.00 

Round  22, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round  22, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.02 

Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.01 

Round  23, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.00 

Round  24, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.01 

Round  24, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.00 

Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.01 

Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.00 

Round  26, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.02 

Round  26, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.01 

Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.03 

Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.99 

Round  28, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.05 

Round  28, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.01 

Round  29, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.05 

Round  29, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.01 

Round  30, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.04 

Round  30, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.01 

Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round  32, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.01 

Round  32, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.97 

Round  33, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.01 

Round  33, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.96 

Round  34, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.99 

Round  34, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.93 

Round  35, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  35, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.95 

Round  36, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.99 

Round  36, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.97 

Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round  38, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  38, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round  39, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.98 

Round  39, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  40, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  40, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  41, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.99 

Round  41, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.97 

Round  42, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.02 

Round  42, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  43, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  43, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  44, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  44, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round  45, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.99 

Round  45, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98 

Round  46, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.98 

Round  46, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98 

Round  47, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  47, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  49, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98 

Round  50, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  50, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round  51, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.98 

Round  51, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.96 

Round  52, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.98 

Round  52, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.97 

Round  53, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.98 

Round  53, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.97 

Round  54, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.98 

Round  54, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.96 

Round  55, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.99 

Round  55, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.95 

Round  56, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.97 

Round  56, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.95 

Round  57, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.95 

Round  57, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.96 

Round  58, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.95 

Round  58, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.96 

Round  59, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.96 

Round  59, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.96 

Round  60, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.96 

Round  60, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.95 

Round  61, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.95 

Round  61, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.97 

Round  62, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.97 

Round  62, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.96 

Round  63, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  63, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.95 

Round  64, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.01 

Round  64, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.97 

Round  65, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.00 

Round  65, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.96 

Round  66, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.00 

Round  66, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.94 

Round  67, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  67, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.94 

Round  68, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99 

Round  68, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.95 

Round  69, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.98 

Round  69, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  70, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.96 

Round  70, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  71, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.97 

Round  71, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.96 

Round  72, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  73, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.96 

Round  73, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  74, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.95 

Round  74, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.92 

Round  75, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.95 

Round  75, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  76, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.96 

Round  76, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  77, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.94 

Round  77, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.93 

Round  78, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.96 

Round  78, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  79, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.92 

Round  79, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  80, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.93 

Round  80, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  81, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.93 

Round  81, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  82, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.93 

Round  82, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.91 

Round  83, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.96 

Round  83, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  84, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.95 

Round  84, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.92 

Round  85, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.95 

Round  85, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  86, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.94 

Round  86, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.91 

Round  87, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.94 

Round  87, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  88, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.94 

Round  88, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.93 

Round  89, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.94 

Round  89, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.91 

Round  90, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.94 

Round  90, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.92 

Round  91, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.95 

Round  91, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  92, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.95 

Round  92, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  93, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.94 

Round  93, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  94, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.93 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.93 

Round  95, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.92 

Round  95, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.93 

Round  96, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.92 

Round  96, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.91 

Round  97, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.94 

Round  97, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  98, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.94 

Round  98, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Round  99, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.93 

Round  99, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Final Round, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.97 

Final Round, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92 

Average accuracy final 10 rounds: 10.935666666666668 

Average global accuracy final 10 rounds: 10.922333333333334 

2788.061982870102
[0.9300532341003418, 1.761915683746338, 2.5912511348724365, 3.419407844543457, 4.24282431602478, 5.067185640335083, 5.887357711791992, 6.7046802043914795, 7.52628755569458, 8.337432861328125, 9.154517889022827, 9.974074840545654, 10.794632911682129, 11.61852502822876, 12.445518970489502, 13.264613151550293, 14.086994886398315, 14.909467935562134, 15.729444026947021, 16.557815313339233, 17.375961780548096, 18.20860981941223, 19.030197143554688, 19.852767944335938, 20.676025867462158, 21.498679637908936, 22.321218013763428, 23.141083002090454, 23.949148893356323, 24.760401248931885, 25.57153558731079, 26.38538432121277, 27.203717947006226, 28.01574158668518, 28.829169511795044, 29.645694971084595, 30.462372303009033, 31.278706073760986, 31.980748891830444, 32.68651509284973, 33.3926203250885, 34.10478615760803, 34.81258845329285, 35.52068257331848, 36.23013615608215, 36.93767189979553, 37.64910864830017, 38.3550169467926, 39.06716728210449, 39.77957558631897, 40.48492240905762, 41.19044494628906, 41.898529291152954, 42.60852003097534, 43.32088375091553, 44.032106161117554, 44.74069356918335, 45.45659685134888, 46.16562247276306, 46.87993812561035, 47.58548355102539, 48.29483199119568, 49.00813293457031, 49.718061208724976, 50.427067041397095, 51.13502550125122, 51.847795248031616, 52.558204889297485, 53.266268491744995, 53.977609395980835, 54.68871760368347, 55.40047812461853, 56.105050563812256, 56.815176010131836, 57.525864601135254, 58.23715424537659, 58.94525909423828, 59.65517592430115, 60.366668939590454, 61.07325315475464, 61.78384852409363, 62.494349241256714, 63.20488691329956, 63.91339111328125, 64.62214803695679, 65.32448863983154, 66.03040385246277, 66.73982453346252, 67.4482889175415, 68.15726351737976, 68.86717057228088, 69.57606172561646, 70.28245091438293, 70.98755431175232, 71.69206380844116, 72.39455485343933, 73.09727358818054, 73.80523037910461, 74.5139570236206, 75.22425055503845, 76.64148330688477]
[11.001666666666667, 11.011666666666667, 11.01, 11.01, 11.036666666666667, 11.036666666666667, 11.026666666666667, 11.038333333333334, 11.036666666666667, 11.03, 11.025, 11.03, 11.021666666666667, 11.026666666666667, 11.031666666666666, 11.046666666666667, 11.033333333333333, 11.031666666666666, 11.018333333333333, 11.02, 11.028333333333334, 11.015, 11.025, 11.006666666666666, 11.005, 11.008333333333333, 11.021666666666667, 11.033333333333333, 11.046666666666667, 11.055, 11.043333333333333, 11.011666666666667, 11.006666666666666, 11.006666666666666, 10.99, 10.991666666666667, 10.995, 11.0, 10.996666666666666, 10.981666666666667, 10.993333333333334, 10.993333333333334, 11.018333333333333, 11.001666666666667, 10.988333333333333, 10.988333333333333, 10.978333333333333, 10.996666666666666, 10.988333333333333, 11.003333333333334, 10.988333333333333, 10.985, 10.978333333333333, 10.981666666666667, 10.976666666666667, 10.986666666666666, 10.975, 10.953333333333333, 10.953333333333333, 10.955, 10.961666666666666, 10.953333333333333, 10.973333333333333, 10.996666666666666, 11.008333333333333, 10.998333333333333, 11.001666666666667, 10.991666666666667, 10.995, 10.978333333333333, 10.96, 10.968333333333334, 10.96, 10.965, 10.948333333333334, 10.945, 10.96, 10.941666666666666, 10.96, 10.923333333333334, 10.925, 10.928333333333333, 10.931666666666667, 10.958333333333334, 10.946666666666667, 10.945, 10.938333333333333, 10.943333333333333, 10.935, 10.938333333333333, 10.938333333333333, 10.946666666666667, 10.945, 10.94, 10.93, 10.923333333333334, 10.923333333333334, 10.941666666666666, 10.935, 10.933333333333334, 10.973333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.215, Test loss: 2.081, Test accuracy: 35.35 

Round   0, Global train loss: 2.215, Global test loss: 2.115, Global test accuracy: 32.72 

Round   1, Train loss: 1.801, Test loss: 1.929, Test accuracy: 52.53 

Round   1, Global train loss: 1.801, Global test loss: 2.052, Global test accuracy: 39.52 

Round   2, Train loss: 1.699, Test loss: 1.825, Test accuracy: 65.12 

Round   2, Global train loss: 1.699, Global test loss: 2.057, Global test accuracy: 37.30 

Round   3, Train loss: 1.585, Test loss: 1.746, Test accuracy: 73.63 

Round   3, Global train loss: 1.585, Global test loss: 2.013, Global test accuracy: 46.67 

Round   4, Train loss: 1.650, Test loss: 1.702, Test accuracy: 76.42 

Round   4, Global train loss: 1.650, Global test loss: 2.064, Global test accuracy: 37.49 

Round   5, Train loss: 1.598, Test loss: 1.679, Test accuracy: 78.97 

Round   5, Global train loss: 1.598, Global test loss: 2.091, Global test accuracy: 34.11 

Round   6, Train loss: 1.609, Test loss: 1.615, Test accuracy: 85.49 

Round   6, Global train loss: 1.609, Global test loss: 2.014, Global test accuracy: 45.31 

Round   7, Train loss: 1.542, Test loss: 1.598, Test accuracy: 87.86 

Round   7, Global train loss: 1.542, Global test loss: 1.987, Global test accuracy: 46.91 

Round   8, Train loss: 1.538, Test loss: 1.581, Test accuracy: 88.91 

Round   8, Global train loss: 1.538, Global test loss: 1.996, Global test accuracy: 46.41 

Round   9, Train loss: 1.539, Test loss: 1.577, Test accuracy: 89.01 

Round   9, Global train loss: 1.539, Global test loss: 2.033, Global test accuracy: 41.02 

Round  10, Train loss: 1.633, Test loss: 1.576, Test accuracy: 89.13 

Round  10, Global train loss: 1.633, Global test loss: 2.077, Global test accuracy: 37.18 

Round  11, Train loss: 1.578, Test loss: 1.576, Test accuracy: 89.07 

Round  11, Global train loss: 1.578, Global test loss: 2.040, Global test accuracy: 40.38 

Round  12, Train loss: 1.532, Test loss: 1.576, Test accuracy: 89.11 

Round  12, Global train loss: 1.532, Global test loss: 2.021, Global test accuracy: 43.14 

Round  13, Train loss: 1.533, Test loss: 1.574, Test accuracy: 89.12 

Round  13, Global train loss: 1.533, Global test loss: 2.048, Global test accuracy: 39.66 

Round  14, Train loss: 1.579, Test loss: 1.573, Test accuracy: 89.17 

Round  14, Global train loss: 1.579, Global test loss: 2.026, Global test accuracy: 43.06 

Round  15, Train loss: 1.472, Test loss: 1.573, Test accuracy: 89.23 

Round  15, Global train loss: 1.472, Global test loss: 2.013, Global test accuracy: 43.94 

Round  16, Train loss: 1.579, Test loss: 1.572, Test accuracy: 89.21 

Round  16, Global train loss: 1.579, Global test loss: 2.038, Global test accuracy: 41.78 

Round  17, Train loss: 1.514, Test loss: 1.560, Test accuracy: 90.52 

Round  17, Global train loss: 1.514, Global test loss: 2.016, Global test accuracy: 44.69 

Round  18, Train loss: 1.529, Test loss: 1.560, Test accuracy: 90.61 

Round  18, Global train loss: 1.529, Global test loss: 2.001, Global test accuracy: 45.11 

Round  19, Train loss: 1.471, Test loss: 1.560, Test accuracy: 90.62 

Round  19, Global train loss: 1.471, Global test loss: 2.009, Global test accuracy: 45.42 

Round  20, Train loss: 1.581, Test loss: 1.558, Test accuracy: 90.66 

Round  20, Global train loss: 1.581, Global test loss: 2.005, Global test accuracy: 44.59 

Round  21, Train loss: 1.522, Test loss: 1.557, Test accuracy: 90.67 

Round  21, Global train loss: 1.522, Global test loss: 1.997, Global test accuracy: 45.34 

Round  22, Train loss: 1.523, Test loss: 1.557, Test accuracy: 90.63 

Round  22, Global train loss: 1.523, Global test loss: 2.009, Global test accuracy: 44.33 

Round  23, Train loss: 1.532, Test loss: 1.543, Test accuracy: 92.24 

Round  23, Global train loss: 1.532, Global test loss: 1.989, Global test accuracy: 47.57 

Round  24, Train loss: 1.472, Test loss: 1.542, Test accuracy: 92.24 

Round  24, Global train loss: 1.472, Global test loss: 2.034, Global test accuracy: 42.67 

Round  25, Train loss: 1.581, Test loss: 1.542, Test accuracy: 92.22 

Round  25, Global train loss: 1.581, Global test loss: 2.062, Global test accuracy: 37.64 

Round  26, Train loss: 1.525, Test loss: 1.542, Test accuracy: 92.23 

Round  26, Global train loss: 1.525, Global test loss: 2.041, Global test accuracy: 41.49 

Round  27, Train loss: 1.524, Test loss: 1.542, Test accuracy: 92.25 

Round  27, Global train loss: 1.524, Global test loss: 2.045, Global test accuracy: 39.32 

Round  28, Train loss: 1.522, Test loss: 1.541, Test accuracy: 92.29 

Round  28, Global train loss: 1.522, Global test loss: 2.029, Global test accuracy: 42.88 

Round  29, Train loss: 1.523, Test loss: 1.541, Test accuracy: 92.21 

Round  29, Global train loss: 1.523, Global test loss: 2.030, Global test accuracy: 41.83 

Round  30, Train loss: 1.574, Test loss: 1.541, Test accuracy: 92.26 

Round  30, Global train loss: 1.574, Global test loss: 2.056, Global test accuracy: 39.19 

Round  31, Train loss: 1.573, Test loss: 1.541, Test accuracy: 92.23 

Round  31, Global train loss: 1.573, Global test loss: 2.001, Global test accuracy: 46.27 

Round  32, Train loss: 1.519, Test loss: 1.541, Test accuracy: 92.26 

Round  32, Global train loss: 1.519, Global test loss: 2.001, Global test accuracy: 44.98 

Round  33, Train loss: 1.469, Test loss: 1.541, Test accuracy: 92.27 

Round  33, Global train loss: 1.469, Global test loss: 1.992, Global test accuracy: 46.47 

Round  34, Train loss: 1.521, Test loss: 1.541, Test accuracy: 92.27 

Round  34, Global train loss: 1.521, Global test loss: 1.992, Global test accuracy: 47.03 

Round  35, Train loss: 1.467, Test loss: 1.541, Test accuracy: 92.21 

Round  35, Global train loss: 1.467, Global test loss: 2.033, Global test accuracy: 42.24 

Round  36, Train loss: 1.468, Test loss: 1.541, Test accuracy: 92.23 

Round  36, Global train loss: 1.468, Global test loss: 2.017, Global test accuracy: 43.24 

Round  37, Train loss: 1.521, Test loss: 1.541, Test accuracy: 92.23 

Round  37, Global train loss: 1.521, Global test loss: 2.022, Global test accuracy: 42.36 

Round  38, Train loss: 1.521, Test loss: 1.541, Test accuracy: 92.26 

Round  38, Global train loss: 1.521, Global test loss: 1.988, Global test accuracy: 47.28 

Round  39, Train loss: 1.524, Test loss: 1.541, Test accuracy: 92.26 

Round  39, Global train loss: 1.524, Global test loss: 2.004, Global test accuracy: 44.55 

Round  40, Train loss: 1.467, Test loss: 1.540, Test accuracy: 92.26 

Round  40, Global train loss: 1.467, Global test loss: 1.995, Global test accuracy: 46.33 

Round  41, Train loss: 1.518, Test loss: 1.540, Test accuracy: 92.28 

Round  41, Global train loss: 1.518, Global test loss: 2.039, Global test accuracy: 39.99 

Round  42, Train loss: 1.522, Test loss: 1.540, Test accuracy: 92.29 

Round  42, Global train loss: 1.522, Global test loss: 2.034, Global test accuracy: 42.01 

Round  43, Train loss: 1.521, Test loss: 1.541, Test accuracy: 92.27 

Round  43, Global train loss: 1.521, Global test loss: 2.022, Global test accuracy: 43.83 

Round  44, Train loss: 1.521, Test loss: 1.541, Test accuracy: 92.27 

Round  44, Global train loss: 1.521, Global test loss: 2.047, Global test accuracy: 40.29 

Round  45, Train loss: 1.523, Test loss: 1.541, Test accuracy: 92.27 

Round  45, Global train loss: 1.523, Global test loss: 2.071, Global test accuracy: 37.64 

Round  46, Train loss: 1.523, Test loss: 1.540, Test accuracy: 92.31 

Round  46, Global train loss: 1.523, Global test loss: 2.020, Global test accuracy: 43.66 

Round  47, Train loss: 1.468, Test loss: 1.540, Test accuracy: 92.29 

Round  47, Global train loss: 1.468, Global test loss: 2.010, Global test accuracy: 44.18 

Round  48, Train loss: 1.467, Test loss: 1.540, Test accuracy: 92.28 

Round  48, Global train loss: 1.467, Global test loss: 2.024, Global test accuracy: 43.43 

Round  49, Train loss: 1.469, Test loss: 1.540, Test accuracy: 92.26 

Round  49, Global train loss: 1.469, Global test loss: 1.997, Global test accuracy: 45.39 

Round  50, Train loss: 1.467, Test loss: 1.540, Test accuracy: 92.27 

Round  50, Global train loss: 1.467, Global test loss: 2.029, Global test accuracy: 42.18 

Round  51, Train loss: 1.470, Test loss: 1.540, Test accuracy: 92.29 

Round  51, Global train loss: 1.470, Global test loss: 2.010, Global test accuracy: 44.11 

Round  52, Train loss: 1.520, Test loss: 1.540, Test accuracy: 92.29 

Round  52, Global train loss: 1.520, Global test loss: 2.073, Global test accuracy: 36.99 

Round  53, Train loss: 1.520, Test loss: 1.540, Test accuracy: 92.28 

Round  53, Global train loss: 1.520, Global test loss: 2.002, Global test accuracy: 45.34 

Round  54, Train loss: 1.468, Test loss: 1.540, Test accuracy: 92.31 

Round  54, Global train loss: 1.468, Global test loss: 2.014, Global test accuracy: 44.14 

Round  55, Train loss: 1.467, Test loss: 1.540, Test accuracy: 92.32 

Round  55, Global train loss: 1.467, Global test loss: 2.016, Global test accuracy: 44.36 

Round  56, Train loss: 1.468, Test loss: 1.540, Test accuracy: 92.34 

Round  56, Global train loss: 1.468, Global test loss: 2.059, Global test accuracy: 38.44 

Round  57, Train loss: 1.470, Test loss: 1.540, Test accuracy: 92.34 

Round  57, Global train loss: 1.470, Global test loss: 2.046, Global test accuracy: 40.08 

Round  58, Train loss: 1.466, Test loss: 1.540, Test accuracy: 92.34 

Round  58, Global train loss: 1.466, Global test loss: 2.005, Global test accuracy: 44.90 

Round  59, Train loss: 1.521, Test loss: 1.540, Test accuracy: 92.34 

Round  59, Global train loss: 1.521, Global test loss: 1.996, Global test accuracy: 46.62 

Round  60, Train loss: 1.519, Test loss: 1.540, Test accuracy: 92.34 

Round  60, Global train loss: 1.519, Global test loss: 2.015, Global test accuracy: 43.85 

Round  61, Train loss: 1.573, Test loss: 1.540, Test accuracy: 92.33 

Round  61, Global train loss: 1.573, Global test loss: 2.041, Global test accuracy: 41.62 

Round  62, Train loss: 1.467, Test loss: 1.540, Test accuracy: 92.33 

Round  62, Global train loss: 1.467, Global test loss: 2.012, Global test accuracy: 44.62 

Round  63, Train loss: 1.468, Test loss: 1.540, Test accuracy: 92.34 

Round  63, Global train loss: 1.468, Global test loss: 1.977, Global test accuracy: 47.99 

Round  64, Train loss: 1.467, Test loss: 1.540, Test accuracy: 92.36 

Round  64, Global train loss: 1.467, Global test loss: 2.039, Global test accuracy: 40.53 

Round  65, Train loss: 1.470, Test loss: 1.539, Test accuracy: 92.34 

Round  65, Global train loss: 1.470, Global test loss: 2.009, Global test accuracy: 44.81 

Round  66, Train loss: 1.517, Test loss: 1.540, Test accuracy: 92.33 

Round  66, Global train loss: 1.517, Global test loss: 1.996, Global test accuracy: 46.90 

Round  67, Train loss: 1.521, Test loss: 1.540, Test accuracy: 92.35 

Round  67, Global train loss: 1.521, Global test loss: 2.033, Global test accuracy: 41.52 

Round  68, Train loss: 1.522, Test loss: 1.540, Test accuracy: 92.35 

Round  68, Global train loss: 1.522, Global test loss: 2.015, Global test accuracy: 43.44 

Round  69, Train loss: 1.518, Test loss: 1.540, Test accuracy: 92.35 

Round  69, Global train loss: 1.518, Global test loss: 2.037, Global test accuracy: 41.81 

Round  70, Train loss: 1.573, Test loss: 1.540, Test accuracy: 92.36 

Round  70, Global train loss: 1.573, Global test loss: 2.015, Global test accuracy: 44.57 

Round  71, Train loss: 1.520, Test loss: 1.539, Test accuracy: 92.36 

Round  71, Global train loss: 1.520, Global test loss: 2.035, Global test accuracy: 41.72 

Round  72, Train loss: 1.469, Test loss: 1.539, Test accuracy: 92.36 

Round  72, Global train loss: 1.469, Global test loss: 2.028, Global test accuracy: 42.41 

Round  73, Train loss: 1.518, Test loss: 1.539, Test accuracy: 92.36 

Round  73, Global train loss: 1.518, Global test loss: 2.029, Global test accuracy: 42.68 

Round  74, Train loss: 1.468, Test loss: 1.539, Test accuracy: 92.36 

Round  74, Global train loss: 1.468, Global test loss: 2.038, Global test accuracy: 41.22 

Round  75, Train loss: 1.466, Test loss: 1.539, Test accuracy: 92.36 

Round  75, Global train loss: 1.466, Global test loss: 2.007, Global test accuracy: 44.32 

Round  76, Train loss: 1.466, Test loss: 1.539, Test accuracy: 92.35 

Round  76, Global train loss: 1.466, Global test loss: 1.988, Global test accuracy: 46.49 

Round  77, Train loss: 1.518, Test loss: 1.539, Test accuracy: 92.35 

Round  77, Global train loss: 1.518, Global test loss: 1.999, Global test accuracy: 45.77 

Round  78, Train loss: 1.466, Test loss: 1.539, Test accuracy: 92.35 

Round  78, Global train loss: 1.466, Global test loss: 2.022, Global test accuracy: 43.27 

Round  79, Train loss: 1.465, Test loss: 1.539, Test accuracy: 92.37 

Round  79, Global train loss: 1.465, Global test loss: 1.989, Global test accuracy: 46.91 

Round  80, Train loss: 1.469, Test loss: 1.539, Test accuracy: 92.37 

Round  80, Global train loss: 1.469, Global test loss: 1.999, Global test accuracy: 45.34 

Round  81, Train loss: 1.520, Test loss: 1.539, Test accuracy: 92.38 

Round  81, Global train loss: 1.520, Global test loss: 2.035, Global test accuracy: 42.73 

Round  82, Train loss: 1.467, Test loss: 1.539, Test accuracy: 92.41 

Round  82, Global train loss: 1.467, Global test loss: 2.009, Global test accuracy: 44.69 

Round  83, Train loss: 1.467, Test loss: 1.539, Test accuracy: 92.42 

Round  83, Global train loss: 1.467, Global test loss: 2.015, Global test accuracy: 44.36 

Round  84, Train loss: 1.465, Test loss: 1.539, Test accuracy: 92.43 

Round  84, Global train loss: 1.465, Global test loss: 1.998, Global test accuracy: 45.60 

Round  85, Train loss: 1.517, Test loss: 1.539, Test accuracy: 92.43 

Round  85, Global train loss: 1.517, Global test loss: 1.986, Global test accuracy: 47.29 

Round  86, Train loss: 1.467, Test loss: 1.539, Test accuracy: 92.43 

Round  86, Global train loss: 1.467, Global test loss: 1.978, Global test accuracy: 47.98 

Round  87, Train loss: 1.521, Test loss: 1.539, Test accuracy: 92.42 

Round  87, Global train loss: 1.521, Global test loss: 2.026, Global test accuracy: 42.57 

Round  88, Train loss: 1.517, Test loss: 1.539, Test accuracy: 92.42 

Round  88, Global train loss: 1.517, Global test loss: 2.022, Global test accuracy: 42.62 

Round  89, Train loss: 1.466, Test loss: 1.539, Test accuracy: 92.42 

Round  89, Global train loss: 1.466, Global test loss: 1.989, Global test accuracy: 46.82 

Round  90, Train loss: 1.521, Test loss: 1.539, Test accuracy: 92.42 

Round  90, Global train loss: 1.521, Global test loss: 2.034, Global test accuracy: 42.26 

Round  91, Train loss: 1.468, Test loss: 1.539, Test accuracy: 92.42 

Round  91, Global train loss: 1.468, Global test loss: 1.994, Global test accuracy: 46.21 

Round  92, Train loss: 1.466, Test loss: 1.539, Test accuracy: 92.42 

Round  92, Global train loss: 1.466, Global test loss: 2.044, Global test accuracy: 41.67 

Round  93, Train loss: 1.521, Test loss: 1.538, Test accuracy: 92.42 

Round  93, Global train loss: 1.521, Global test loss: 2.123, Global test accuracy: 31.58 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.466, Test loss: 1.538, Test accuracy: 92.42 

Round  94, Global train loss: 1.466, Global test loss: 2.044, Global test accuracy: 40.21 

Round  95, Train loss: 1.466, Test loss: 1.538, Test accuracy: 92.42 

Round  95, Global train loss: 1.466, Global test loss: 2.046, Global test accuracy: 41.32 

Round  96, Train loss: 1.465, Test loss: 1.538, Test accuracy: 92.42 

Round  96, Global train loss: 1.465, Global test loss: 1.997, Global test accuracy: 46.16 

Round  97, Train loss: 1.467, Test loss: 1.538, Test accuracy: 92.42 

Round  97, Global train loss: 1.467, Global test loss: 2.017, Global test accuracy: 44.42 

Round  98, Train loss: 1.480, Test loss: 1.524, Test accuracy: 93.97 

Round  98, Global train loss: 1.480, Global test loss: 1.977, Global test accuracy: 47.85 

Round  99, Train loss: 1.467, Test loss: 1.524, Test accuracy: 93.95 

Round  99, Global train loss: 1.467, Global test loss: 2.012, Global test accuracy: 44.68 

Final Round, Train loss: 1.482, Test loss: 1.523, Test accuracy: 93.97 

Final Round, Global train loss: 1.482, Global test loss: 2.012, Global test accuracy: 44.68 

Average accuracy final 10 rounds: 92.72944444444444 

Average global accuracy final 10 rounds: 42.636111111111106 

1111.7448425292969
[0.8297455310821533, 1.5570049285888672, 2.2862660884857178, 3.014171838760376, 3.74031662940979, 4.4645771980285645, 5.189706325531006, 5.915440320968628, 6.646543025970459, 7.374328136444092, 8.099864721298218, 8.836287021636963, 9.569287061691284, 10.30541181564331, 11.03061842918396, 11.756391763687134, 12.484055995941162, 13.209663391113281, 13.938112735748291, 14.670774221420288, 15.404613733291626, 16.128047227859497, 16.861109495162964, 17.590789079666138, 18.316570520401, 19.03290843963623, 19.750365734100342, 20.467307090759277, 21.18749213218689, 21.91115164756775, 22.63090968132019, 23.352290630340576, 24.07364058494568, 24.79310393333435, 25.456550121307373, 26.069526195526123, 26.68894338607788, 27.301499366760254, 27.920939207077026, 28.531599044799805, 29.150740385055542, 29.76188015937805, 30.383263111114502, 30.99646830558777, 31.614978313446045, 32.22575378417969, 32.84427762031555, 33.45651817321777, 34.077951192855835, 34.689796447753906, 35.30834698677063, 35.91442084312439, 36.53440237045288, 37.14318776130676, 37.763121604919434, 38.374268531799316, 38.99403738975525, 39.606197118759155, 40.226080656051636, 40.837867736816406, 41.45842719078064, 42.07459545135498, 42.692160844802856, 43.30799841880798, 43.92568278312683, 44.535053968429565, 45.15595269203186, 45.765761375427246, 46.38867163658142, 47.00728178024292, 47.62479257583618, 48.22960424423218, 48.85013675689697, 49.455535888671875, 50.074418783187866, 50.680466175079346, 51.302114486694336, 51.90585708618164, 52.52919316291809, 53.13896107673645, 53.763288497924805, 54.37179684638977, 54.99458026885986, 55.601932764053345, 56.22498393058777, 56.82862424850464, 57.451160192489624, 58.05667209625244, 58.68058657646179, 59.298343658447266, 59.91516375541687, 60.51992630958557, 61.128904581069946, 61.74777054786682, 62.353689432144165, 62.97025966644287, 63.58389115333557, 64.21014547348022, 64.82065391540527, 65.4489517211914, 66.68447542190552]
[35.35, 52.53333333333333, 65.11666666666666, 73.63333333333334, 76.41666666666667, 78.97222222222223, 85.4888888888889, 87.86111111111111, 88.91111111111111, 89.00555555555556, 89.12777777777778, 89.07222222222222, 89.10555555555555, 89.12222222222222, 89.16666666666667, 89.22777777777777, 89.21111111111111, 90.52222222222223, 90.61111111111111, 90.62222222222222, 90.66111111111111, 90.66666666666667, 90.62777777777778, 92.24444444444444, 92.2388888888889, 92.21666666666667, 92.23333333333333, 92.25, 92.28888888888889, 92.21111111111111, 92.2611111111111, 92.23333333333333, 92.25555555555556, 92.27222222222223, 92.26666666666667, 92.21111111111111, 92.23333333333333, 92.23333333333333, 92.2611111111111, 92.25555555555556, 92.2611111111111, 92.28333333333333, 92.28888888888889, 92.27222222222223, 92.27222222222223, 92.27222222222223, 92.31111111111112, 92.28888888888889, 92.28333333333333, 92.2611111111111, 92.26666666666667, 92.29444444444445, 92.28888888888889, 92.28333333333333, 92.30555555555556, 92.32222222222222, 92.33888888888889, 92.34444444444445, 92.33888888888889, 92.33888888888889, 92.33888888888889, 92.33333333333333, 92.33333333333333, 92.34444444444445, 92.35555555555555, 92.34444444444445, 92.33333333333333, 92.35, 92.35, 92.35, 92.35555555555555, 92.36111111111111, 92.36111111111111, 92.36111111111111, 92.35555555555555, 92.36111111111111, 92.35, 92.35, 92.35, 92.36666666666666, 92.37222222222222, 92.37777777777778, 92.41111111111111, 92.41666666666667, 92.42777777777778, 92.42777777777778, 92.42777777777778, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 92.42222222222222, 93.96666666666667, 93.95, 93.96666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.264, Test loss: 2.160, Test accuracy: 34.62 

Round   0, Global train loss: 2.264, Global test loss: 2.185, Global test accuracy: 33.33 

Round   1, Train loss: 1.838, Test loss: 1.934, Test accuracy: 53.50 

Round   1, Global train loss: 1.838, Global test loss: 2.047, Global test accuracy: 41.61 

Round   2, Train loss: 1.689, Test loss: 1.805, Test accuracy: 68.97 

Round   2, Global train loss: 1.689, Global test loss: 1.992, Global test accuracy: 48.77 

Round   3, Train loss: 1.670, Test loss: 1.699, Test accuracy: 79.78 

Round   3, Global train loss: 1.670, Global test loss: 1.989, Global test accuracy: 47.02 

Round   4, Train loss: 1.581, Test loss: 1.624, Test accuracy: 87.03 

Round   4, Global train loss: 1.581, Global test loss: 1.966, Global test accuracy: 49.66 

Round   5, Train loss: 1.600, Test loss: 1.621, Test accuracy: 86.67 

Round   5, Global train loss: 1.600, Global test loss: 1.979, Global test accuracy: 47.85 

Round   6, Train loss: 1.649, Test loss: 1.621, Test accuracy: 86.41 

Round   6, Global train loss: 1.649, Global test loss: 1.981, Global test accuracy: 48.33 

Round   7, Train loss: 1.565, Test loss: 1.601, Test accuracy: 87.96 

Round   7, Global train loss: 1.565, Global test loss: 1.974, Global test accuracy: 48.75 

Round   8, Train loss: 1.511, Test loss: 1.549, Test accuracy: 91.93 

Round   8, Global train loss: 1.511, Global test loss: 1.960, Global test accuracy: 49.81 

Round   9, Train loss: 1.636, Test loss: 1.564, Test accuracy: 90.36 

Round   9, Global train loss: 1.636, Global test loss: 1.969, Global test accuracy: 49.07 

Round  10, Train loss: 1.638, Test loss: 1.580, Test accuracy: 88.67 

Round  10, Global train loss: 1.638, Global test loss: 1.970, Global test accuracy: 48.80 

Round  11, Train loss: 1.675, Test loss: 1.592, Test accuracy: 87.41 

Round  11, Global train loss: 1.675, Global test loss: 1.968, Global test accuracy: 48.64 

Round  12, Train loss: 1.520, Test loss: 1.575, Test accuracy: 89.14 

Round  12, Global train loss: 1.520, Global test loss: 2.001, Global test accuracy: 45.44 

Round  13, Train loss: 1.521, Test loss: 1.574, Test accuracy: 89.23 

Round  13, Global train loss: 1.521, Global test loss: 1.972, Global test accuracy: 48.81 

Round  14, Train loss: 1.581, Test loss: 1.573, Test accuracy: 89.34 

Round  14, Global train loss: 1.581, Global test loss: 1.996, Global test accuracy: 45.73 

Round  15, Train loss: 1.576, Test loss: 1.573, Test accuracy: 89.24 

Round  15, Global train loss: 1.576, Global test loss: 1.968, Global test accuracy: 48.84 

Round  16, Train loss: 1.611, Test loss: 1.572, Test accuracy: 89.33 

Round  16, Global train loss: 1.611, Global test loss: 1.968, Global test accuracy: 49.06 

Round  17, Train loss: 1.587, Test loss: 1.572, Test accuracy: 89.35 

Round  17, Global train loss: 1.587, Global test loss: 1.969, Global test accuracy: 48.67 

Round  18, Train loss: 1.616, Test loss: 1.573, Test accuracy: 89.16 

Round  18, Global train loss: 1.616, Global test loss: 1.989, Global test accuracy: 46.73 

Round  19, Train loss: 1.524, Test loss: 1.559, Test accuracy: 90.57 

Round  19, Global train loss: 1.524, Global test loss: 1.954, Global test accuracy: 50.59 

Round  20, Train loss: 1.506, Test loss: 1.558, Test accuracy: 90.69 

Round  20, Global train loss: 1.506, Global test loss: 1.987, Global test accuracy: 47.08 

Round  21, Train loss: 1.600, Test loss: 1.572, Test accuracy: 89.27 

Round  21, Global train loss: 1.600, Global test loss: 1.950, Global test accuracy: 50.87 

Round  22, Train loss: 1.546, Test loss: 1.573, Test accuracy: 89.16 

Round  22, Global train loss: 1.546, Global test loss: 1.962, Global test accuracy: 49.37 

Round  23, Train loss: 1.588, Test loss: 1.572, Test accuracy: 89.23 

Round  23, Global train loss: 1.588, Global test loss: 1.983, Global test accuracy: 47.62 

Round  24, Train loss: 1.550, Test loss: 1.571, Test accuracy: 89.32 

Round  24, Global train loss: 1.550, Global test loss: 1.960, Global test accuracy: 50.00 

Round  25, Train loss: 1.495, Test loss: 1.571, Test accuracy: 89.34 

Round  25, Global train loss: 1.495, Global test loss: 1.957, Global test accuracy: 49.97 

Round  26, Train loss: 1.657, Test loss: 1.569, Test accuracy: 89.43 

Round  26, Global train loss: 1.657, Global test loss: 1.943, Global test accuracy: 51.64 

Round  27, Train loss: 1.552, Test loss: 1.568, Test accuracy: 89.52 

Round  27, Global train loss: 1.552, Global test loss: 1.949, Global test accuracy: 51.03 

Round  28, Train loss: 1.593, Test loss: 1.569, Test accuracy: 89.39 

Round  28, Global train loss: 1.593, Global test loss: 1.994, Global test accuracy: 45.94 

Round  29, Train loss: 1.600, Test loss: 1.585, Test accuracy: 87.76 

Round  29, Global train loss: 1.600, Global test loss: 1.945, Global test accuracy: 51.33 

Round  30, Train loss: 1.542, Test loss: 1.577, Test accuracy: 88.62 

Round  30, Global train loss: 1.542, Global test loss: 1.966, Global test accuracy: 48.93 

Round  31, Train loss: 1.542, Test loss: 1.591, Test accuracy: 87.20 

Round  31, Global train loss: 1.542, Global test loss: 1.937, Global test accuracy: 52.12 

Round  32, Train loss: 1.623, Test loss: 1.607, Test accuracy: 85.49 

Round  32, Global train loss: 1.623, Global test loss: 1.943, Global test accuracy: 51.57 

Round  33, Train loss: 1.573, Test loss: 1.576, Test accuracy: 88.66 

Round  33, Global train loss: 1.573, Global test loss: 1.945, Global test accuracy: 51.25 

Round  34, Train loss: 1.591, Test loss: 1.560, Test accuracy: 90.24 

Round  34, Global train loss: 1.591, Global test loss: 1.937, Global test accuracy: 52.09 

Round  35, Train loss: 1.488, Test loss: 1.560, Test accuracy: 90.31 

Round  35, Global train loss: 1.488, Global test loss: 1.979, Global test accuracy: 47.60 

Round  36, Train loss: 1.545, Test loss: 1.560, Test accuracy: 90.31 

Round  36, Global train loss: 1.545, Global test loss: 1.973, Global test accuracy: 47.94 

Round  37, Train loss: 1.485, Test loss: 1.559, Test accuracy: 90.38 

Round  37, Global train loss: 1.485, Global test loss: 1.944, Global test accuracy: 51.24 

Round  38, Train loss: 1.700, Test loss: 1.575, Test accuracy: 88.63 

Round  38, Global train loss: 1.700, Global test loss: 1.954, Global test accuracy: 50.21 

Round  39, Train loss: 1.508, Test loss: 1.556, Test accuracy: 90.64 

Round  39, Global train loss: 1.508, Global test loss: 1.967, Global test accuracy: 48.77 

Round  40, Train loss: 1.526, Test loss: 1.558, Test accuracy: 90.53 

Round  40, Global train loss: 1.526, Global test loss: 1.944, Global test accuracy: 51.29 

Round  41, Train loss: 1.540, Test loss: 1.572, Test accuracy: 89.03 

Round  41, Global train loss: 1.540, Global test loss: 1.964, Global test accuracy: 49.59 

Round  42, Train loss: 1.518, Test loss: 1.559, Test accuracy: 90.34 

Round  42, Global train loss: 1.518, Global test loss: 1.956, Global test accuracy: 50.24 

Round  43, Train loss: 1.558, Test loss: 1.554, Test accuracy: 90.84 

Round  43, Global train loss: 1.558, Global test loss: 1.947, Global test accuracy: 50.98 

Round  44, Train loss: 1.561, Test loss: 1.553, Test accuracy: 90.93 

Round  44, Global train loss: 1.561, Global test loss: 1.933, Global test accuracy: 52.29 

Round  45, Train loss: 1.488, Test loss: 1.552, Test accuracy: 91.14 

Round  45, Global train loss: 1.488, Global test loss: 1.961, Global test accuracy: 49.91 

Round  46, Train loss: 1.486, Test loss: 1.552, Test accuracy: 91.12 

Round  46, Global train loss: 1.486, Global test loss: 1.946, Global test accuracy: 51.07 

Round  47, Train loss: 1.608, Test loss: 1.553, Test accuracy: 91.04 

Round  47, Global train loss: 1.608, Global test loss: 1.924, Global test accuracy: 53.68 

Round  48, Train loss: 1.481, Test loss: 1.553, Test accuracy: 90.98 

Round  48, Global train loss: 1.481, Global test loss: 1.950, Global test accuracy: 50.81 

Round  49, Train loss: 1.632, Test loss: 1.570, Test accuracy: 89.25 

Round  49, Global train loss: 1.632, Global test loss: 1.933, Global test accuracy: 52.73 

Round  50, Train loss: 1.547, Test loss: 1.569, Test accuracy: 89.34 

Round  50, Global train loss: 1.547, Global test loss: 1.928, Global test accuracy: 53.09 

Round  51, Train loss: 1.639, Test loss: 1.571, Test accuracy: 89.13 

Round  51, Global train loss: 1.639, Global test loss: 1.948, Global test accuracy: 51.11 

Round  52, Train loss: 1.498, Test loss: 1.571, Test accuracy: 89.10 

Round  52, Global train loss: 1.498, Global test loss: 1.929, Global test accuracy: 52.99 

Round  53, Train loss: 1.566, Test loss: 1.586, Test accuracy: 87.59 

Round  53, Global train loss: 1.566, Global test loss: 1.961, Global test accuracy: 49.75 

Round  54, Train loss: 1.547, Test loss: 1.586, Test accuracy: 87.62 

Round  54, Global train loss: 1.547, Global test loss: 1.927, Global test accuracy: 53.25 

Round  55, Train loss: 1.530, Test loss: 1.586, Test accuracy: 87.59 

Round  55, Global train loss: 1.530, Global test loss: 1.919, Global test accuracy: 54.16 

Round  56, Train loss: 1.591, Test loss: 1.572, Test accuracy: 89.07 

Round  56, Global train loss: 1.591, Global test loss: 1.949, Global test accuracy: 51.04 

Round  57, Train loss: 1.540, Test loss: 1.572, Test accuracy: 89.01 

Round  57, Global train loss: 1.540, Global test loss: 1.967, Global test accuracy: 48.87 

Round  58, Train loss: 1.581, Test loss: 1.572, Test accuracy: 89.09 

Round  58, Global train loss: 1.581, Global test loss: 1.930, Global test accuracy: 52.86 

Round  59, Train loss: 1.583, Test loss: 1.572, Test accuracy: 89.04 

Round  59, Global train loss: 1.583, Global test loss: 1.958, Global test accuracy: 49.96 

Round  60, Train loss: 1.487, Test loss: 1.571, Test accuracy: 89.09 

Round  60, Global train loss: 1.487, Global test loss: 1.940, Global test accuracy: 51.91 

Round  61, Train loss: 1.535, Test loss: 1.556, Test accuracy: 90.69 

Round  61, Global train loss: 1.535, Global test loss: 1.970, Global test accuracy: 48.60 

Round  62, Train loss: 1.592, Test loss: 1.568, Test accuracy: 89.43 

Round  62, Global train loss: 1.592, Global test loss: 1.935, Global test accuracy: 52.14 

Round  63, Train loss: 1.479, Test loss: 1.569, Test accuracy: 89.25 

Round  63, Global train loss: 1.479, Global test loss: 1.943, Global test accuracy: 51.56 

Round  64, Train loss: 1.530, Test loss: 1.554, Test accuracy: 90.73 

Round  64, Global train loss: 1.530, Global test loss: 1.979, Global test accuracy: 47.46 

Round  65, Train loss: 1.504, Test loss: 1.553, Test accuracy: 90.85 

Round  65, Global train loss: 1.504, Global test loss: 1.934, Global test accuracy: 52.14 

Round  66, Train loss: 1.630, Test loss: 1.551, Test accuracy: 91.07 

Round  66, Global train loss: 1.630, Global test loss: 1.967, Global test accuracy: 49.04 

Round  67, Train loss: 1.540, Test loss: 1.551, Test accuracy: 91.15 

Round  67, Global train loss: 1.540, Global test loss: 1.947, Global test accuracy: 51.09 

Round  68, Train loss: 1.636, Test loss: 1.565, Test accuracy: 89.65 

Round  68, Global train loss: 1.636, Global test loss: 1.935, Global test accuracy: 52.39 

Round  69, Train loss: 1.540, Test loss: 1.581, Test accuracy: 88.07 

Round  69, Global train loss: 1.540, Global test loss: 1.946, Global test accuracy: 51.14 

Round  70, Train loss: 1.476, Test loss: 1.581, Test accuracy: 88.02 

Round  70, Global train loss: 1.476, Global test loss: 1.946, Global test accuracy: 51.06 

Round  71, Train loss: 1.639, Test loss: 1.582, Test accuracy: 87.89 

Round  71, Global train loss: 1.639, Global test loss: 1.949, Global test accuracy: 51.17 

Round  72, Train loss: 1.612, Test loss: 1.582, Test accuracy: 87.88 

Round  72, Global train loss: 1.612, Global test loss: 1.933, Global test accuracy: 52.49 

Round  73, Train loss: 1.577, Test loss: 1.582, Test accuracy: 87.91 

Round  73, Global train loss: 1.577, Global test loss: 1.956, Global test accuracy: 50.04 

Round  74, Train loss: 1.556, Test loss: 1.569, Test accuracy: 89.25 

Round  74, Global train loss: 1.556, Global test loss: 1.935, Global test accuracy: 52.22 

Round  75, Train loss: 1.487, Test loss: 1.554, Test accuracy: 90.85 

Round  75, Global train loss: 1.487, Global test loss: 1.952, Global test accuracy: 50.58 

Round  76, Train loss: 1.539, Test loss: 1.553, Test accuracy: 90.89 

Round  76, Global train loss: 1.539, Global test loss: 1.950, Global test accuracy: 50.74 

Round  77, Train loss: 1.601, Test loss: 1.552, Test accuracy: 91.00 

Round  77, Global train loss: 1.601, Global test loss: 1.966, Global test accuracy: 49.12 

Round  78, Train loss: 1.503, Test loss: 1.537, Test accuracy: 92.56 

Round  78, Global train loss: 1.503, Global test loss: 1.974, Global test accuracy: 48.46 

Round  79, Train loss: 1.542, Test loss: 1.537, Test accuracy: 92.61 

Round  79, Global train loss: 1.542, Global test loss: 1.968, Global test accuracy: 48.75 

Round  80, Train loss: 1.672, Test loss: 1.553, Test accuracy: 91.04 

Round  80, Global train loss: 1.672, Global test loss: 1.975, Global test accuracy: 47.97 

Round  81, Train loss: 1.498, Test loss: 1.539, Test accuracy: 92.43 

Round  81, Global train loss: 1.498, Global test loss: 1.960, Global test accuracy: 49.83 

Round  82, Train loss: 1.539, Test loss: 1.539, Test accuracy: 92.36 

Round  82, Global train loss: 1.539, Global test loss: 1.935, Global test accuracy: 52.42 

Round  83, Train loss: 1.488, Test loss: 1.538, Test accuracy: 92.48 

Round  83, Global train loss: 1.488, Global test loss: 1.939, Global test accuracy: 51.81 

Round  84, Train loss: 1.533, Test loss: 1.538, Test accuracy: 92.52 

Round  84, Global train loss: 1.533, Global test loss: 1.944, Global test accuracy: 51.37 

Round  85, Train loss: 1.553, Test loss: 1.552, Test accuracy: 90.99 

Round  85, Global train loss: 1.553, Global test loss: 1.981, Global test accuracy: 47.44 

Round  86, Train loss: 1.559, Test loss: 1.553, Test accuracy: 90.88 

Round  86, Global train loss: 1.559, Global test loss: 1.956, Global test accuracy: 50.26 

Round  87, Train loss: 1.528, Test loss: 1.568, Test accuracy: 89.42 

Round  87, Global train loss: 1.528, Global test loss: 1.936, Global test accuracy: 52.35 

Round  88, Train loss: 1.484, Test loss: 1.568, Test accuracy: 89.38 

Round  88, Global train loss: 1.484, Global test loss: 1.953, Global test accuracy: 50.17 

Round  89, Train loss: 1.476, Test loss: 1.553, Test accuracy: 91.00 

Round  89, Global train loss: 1.476, Global test loss: 1.922, Global test accuracy: 53.57 

Round  90, Train loss: 1.530, Test loss: 1.553, Test accuracy: 90.97 

Round  90, Global train loss: 1.530, Global test loss: 1.923, Global test accuracy: 53.50 

Round  91, Train loss: 1.543, Test loss: 1.553, Test accuracy: 90.99 

Round  91, Global train loss: 1.543, Global test loss: 1.946, Global test accuracy: 51.04 

Round  92, Train loss: 1.491, Test loss: 1.553, Test accuracy: 91.01 

Round  92, Global train loss: 1.491, Global test loss: 1.937, Global test accuracy: 51.82 

Round  93, Train loss: 1.601, Test loss: 1.553, Test accuracy: 91.01 

Round  93, Global train loss: 1.601, Global test loss: 1.950, Global test accuracy: 50.78 
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.505, Test loss: 1.553, Test accuracy: 91.03 

Round  94, Global train loss: 1.505, Global test loss: 1.962, Global test accuracy: 49.57 

Round  95, Train loss: 1.522, Test loss: 1.553, Test accuracy: 90.94 

Round  95, Global train loss: 1.522, Global test loss: 1.953, Global test accuracy: 50.15 

Round  96, Train loss: 1.479, Test loss: 1.553, Test accuracy: 90.92 

Round  96, Global train loss: 1.479, Global test loss: 1.963, Global test accuracy: 49.25 

Round  97, Train loss: 1.585, Test loss: 1.553, Test accuracy: 90.94 

Round  97, Global train loss: 1.585, Global test loss: 1.957, Global test accuracy: 49.91 

Round  98, Train loss: 1.531, Test loss: 1.553, Test accuracy: 90.89 

Round  98, Global train loss: 1.531, Global test loss: 1.966, Global test accuracy: 49.20 

Round  99, Train loss: 1.529, Test loss: 1.553, Test accuracy: 90.92 

Round  99, Global train loss: 1.529, Global test loss: 1.932, Global test accuracy: 52.39 

Final Round, Train loss: 1.520, Test loss: 1.553, Test accuracy: 91.02 

Final Round, Global train loss: 1.520, Global test loss: 1.932, Global test accuracy: 52.39 

Average accuracy final 10 rounds: 90.96166666666664 

Average global accuracy final 10 rounds: 50.76222222222222 

1254.5240099430084
[0.8257339000701904, 1.5493662357330322, 2.2528891563415527, 2.9588756561279297, 3.6556990146636963, 4.362938642501831, 5.061034917831421, 5.766898155212402, 6.469566583633423, 7.167541980743408, 7.9000842571258545, 8.524773359298706, 9.181805610656738, 9.796116828918457, 10.424649715423584, 11.077665328979492, 11.704744577407837, 12.321447134017944, 12.9497652053833, 13.633294105529785, 14.43922209739685, 15.196128129959106, 16.023170471191406, 16.8350830078125, 17.594218492507935, 18.3094539642334, 19.05543088912964, 19.84373378753662, 20.593098878860474, 21.3352689743042, 22.06501841545105, 22.81623649597168, 23.573105812072754, 24.312585830688477, 25.072667360305786, 25.83933687210083, 26.590765237808228, 27.311708450317383, 28.04518461227417, 28.83450746536255, 29.654709100723267, 30.435890913009644, 31.15517544746399, 31.890963792800903, 32.65083932876587, 33.42704248428345, 34.223880767822266, 34.973217248916626, 35.778162717819214, 36.58864402770996, 37.346654653549194, 38.13665556907654, 38.87961483001709, 39.59551239013672, 40.361016035079956, 41.15801167488098, 41.9488582611084, 42.6762797832489, 43.30683970451355, 43.92395830154419, 44.554709911346436, 45.17254137992859, 45.80418920516968, 46.42015743255615, 47.057518005371094, 47.689324378967285, 48.42675280570984, 49.127445936203, 49.842772245407104, 50.55225372314453, 51.27848196029663, 51.98512053489685, 52.694612979888916, 53.41897916793823, 54.134838819503784, 54.858128786087036, 55.56109070777893, 56.27693057060242, 56.979933977127075, 57.681835889816284, 58.38338780403137, 59.092731952667236, 59.797460079193115, 60.51631760597229, 61.2182400226593, 61.90757346153259, 62.6373348236084, 63.3498957157135, 64.06540727615356, 64.78774881362915, 65.49813747406006, 66.1980950832367, 66.90404963493347, 67.61910581588745, 68.32407593727112, 69.02590441703796, 69.70885109901428, 70.43036079406738, 71.15997982025146, 71.87525534629822, 73.31347322463989]
[34.61666666666667, 53.5, 68.96666666666667, 79.78333333333333, 87.03333333333333, 86.67222222222222, 86.40555555555555, 87.96111111111111, 91.92777777777778, 90.35555555555555, 88.67222222222222, 87.40555555555555, 89.14444444444445, 89.23333333333333, 89.33888888888889, 89.24444444444444, 89.32777777777778, 89.35, 89.15555555555555, 90.56666666666666, 90.69444444444444, 89.26666666666667, 89.15555555555555, 89.23333333333333, 89.32222222222222, 89.34444444444445, 89.43333333333334, 89.52222222222223, 89.38888888888889, 87.7611111111111, 88.61666666666666, 87.2, 85.49444444444444, 88.66111111111111, 90.2388888888889, 90.30555555555556, 90.31111111111112, 90.38333333333334, 88.62777777777778, 90.63888888888889, 90.53333333333333, 89.02777777777777, 90.33888888888889, 90.83888888888889, 90.93333333333334, 91.13888888888889, 91.11666666666666, 91.04444444444445, 90.97777777777777, 89.25, 89.33888888888889, 89.13333333333334, 89.1, 87.59444444444445, 87.62222222222222, 87.59444444444445, 89.06666666666666, 89.00555555555556, 89.08888888888889, 89.04444444444445, 89.09444444444445, 90.69444444444444, 89.43333333333334, 89.25, 90.72777777777777, 90.85, 91.06666666666666, 91.15, 89.65, 88.07222222222222, 88.02222222222223, 87.88888888888889, 87.88333333333334, 87.91111111111111, 89.25, 90.85, 90.88888888888889, 91.0, 92.55555555555556, 92.60555555555555, 91.03888888888889, 92.42777777777778, 92.35555555555555, 92.48333333333333, 92.51666666666667, 90.9888888888889, 90.88333333333334, 89.41666666666667, 89.38333333333334, 91.0, 90.96666666666667, 90.9888888888889, 91.0111111111111, 91.0111111111111, 91.02777777777777, 90.93888888888888, 90.92222222222222, 90.93888888888888, 90.89444444444445, 90.91666666666667, 91.01666666666667]
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 679, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 679, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 679, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 18, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 541, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 412, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 285, in train
    local_par_list = torch.cat((local_par_list, param.reshape(-1)), 0)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
/home/ChenSM/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 849, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar100/cifar-100-python.tar.gz
Extracting data/cifar100/cifar-100-python.tar.gz to data/cifar100
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 44, in <module>
    dataset_train, dataset_test, dict_users_train, dict_users_test, concept_matrix = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_ditto.py", line 48, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_apfl.py", line 49, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_scaffold.py", line 48, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_pfedme.py", line 54, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 44, in <module>
    dataset_train, dataset_test, dict_users_train, dict_users_test, concept_matrix = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_ditto.py", line 48, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_apfl.py", line 49, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_scaffold.py", line 48, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_pfedme.py", line 54, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 44, in <module>
    dataset_train, dataset_test, dict_users_train, dict_users_test, concept_matrix = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 56, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 18, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_ditto.py", line 48, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_apfl.py", line 49, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_scaffold.py", line 48, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_pfedme.py", line 54, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 110, in get_data_v2
    dict_users_test, rand_set_all = noniid_v2(dataset_test, args.num_users, args.shard_per_user, args.num_classes,
  File "/home/ChenSM/code/FL_HLS/utils/sampling.py", line 131, in noniid_v2
    idx = np.random.choice(len(idxs_dict[label]), replace=False)
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.231, Test loss: 2.108, Test accuracy: 21.77 

Round   0, Global train loss: 2.231, Global test loss: 2.103, Global test accuracy: 22.02 

Round   1, Train loss: 2.027, Test loss: 1.975, Test accuracy: 27.81 

Round   1, Global train loss: 2.027, Global test loss: 1.906, Global test accuracy: 31.16 

Round   2, Train loss: 1.888, Test loss: 1.868, Test accuracy: 31.55 

Round   2, Global train loss: 1.888, Global test loss: 1.740, Global test accuracy: 36.98 

Round   3, Train loss: 1.782, Test loss: 1.786, Test accuracy: 33.77 

Round   3, Global train loss: 1.782, Global test loss: 1.641, Global test accuracy: 39.49 

Round   4, Train loss: 1.713, Test loss: 1.732, Test accuracy: 36.12 

Round   4, Global train loss: 1.713, Global test loss: 1.597, Global test accuracy: 41.71 

Round   5, Train loss: 1.633, Test loss: 1.721, Test accuracy: 36.21 

Round   5, Global train loss: 1.633, Global test loss: 1.518, Global test accuracy: 44.51 

Round   6, Train loss: 1.580, Test loss: 1.693, Test accuracy: 37.37 

Round   6, Global train loss: 1.580, Global test loss: 1.491, Global test accuracy: 45.20 

Round   7, Train loss: 1.543, Test loss: 1.666, Test accuracy: 38.53 

Round   7, Global train loss: 1.543, Global test loss: 1.433, Global test accuracy: 48.15 

Round   8, Train loss: 1.511, Test loss: 1.642, Test accuracy: 40.14 

Round   8, Global train loss: 1.511, Global test loss: 1.428, Global test accuracy: 48.66 

Round   9, Train loss: 1.481, Test loss: 1.612, Test accuracy: 41.32 

Round   9, Global train loss: 1.481, Global test loss: 1.390, Global test accuracy: 49.91 

Round  10, Train loss: 1.449, Test loss: 1.579, Test accuracy: 42.85 

Round  10, Global train loss: 1.449, Global test loss: 1.346, Global test accuracy: 50.90 

Round  11, Train loss: 1.387, Test loss: 1.558, Test accuracy: 43.87 

Round  11, Global train loss: 1.387, Global test loss: 1.346, Global test accuracy: 51.17 

Round  12, Train loss: 1.358, Test loss: 1.527, Test accuracy: 45.01 

Round  12, Global train loss: 1.358, Global test loss: 1.292, Global test accuracy: 53.90 

Round  13, Train loss: 1.352, Test loss: 1.522, Test accuracy: 45.52 

Round  13, Global train loss: 1.352, Global test loss: 1.285, Global test accuracy: 54.33 

Round  14, Train loss: 1.303, Test loss: 1.499, Test accuracy: 46.61 

Round  14, Global train loss: 1.303, Global test loss: 1.262, Global test accuracy: 54.59 

Round  15, Train loss: 1.272, Test loss: 1.478, Test accuracy: 47.35 

Round  15, Global train loss: 1.272, Global test loss: 1.238, Global test accuracy: 55.66 

Round  16, Train loss: 1.274, Test loss: 1.450, Test accuracy: 48.75 

Round  16, Global train loss: 1.274, Global test loss: 1.220, Global test accuracy: 56.12 

Round  17, Train loss: 1.210, Test loss: 1.433, Test accuracy: 49.39 

Round  17, Global train loss: 1.210, Global test loss: 1.196, Global test accuracy: 57.41 

Round  18, Train loss: 1.190, Test loss: 1.423, Test accuracy: 49.83 

Round  18, Global train loss: 1.190, Global test loss: 1.204, Global test accuracy: 57.61 

Round  19, Train loss: 1.180, Test loss: 1.417, Test accuracy: 50.25 

Round  19, Global train loss: 1.180, Global test loss: 1.189, Global test accuracy: 57.89 

Round  20, Train loss: 1.138, Test loss: 1.407, Test accuracy: 50.88 

Round  20, Global train loss: 1.138, Global test loss: 1.149, Global test accuracy: 59.52 

Round  21, Train loss: 1.096, Test loss: 1.395, Test accuracy: 51.51 

Round  21, Global train loss: 1.096, Global test loss: 1.152, Global test accuracy: 59.24 

Round  22, Train loss: 1.097, Test loss: 1.375, Test accuracy: 52.56 

Round  22, Global train loss: 1.097, Global test loss: 1.140, Global test accuracy: 60.10 

Round  23, Train loss: 1.076, Test loss: 1.372, Test accuracy: 52.83 

Round  23, Global train loss: 1.076, Global test loss: 1.145, Global test accuracy: 59.44 

Round  24, Train loss: 1.019, Test loss: 1.375, Test accuracy: 52.72 

Round  24, Global train loss: 1.019, Global test loss: 1.131, Global test accuracy: 60.11 

Round  25, Train loss: 1.040, Test loss: 1.356, Test accuracy: 53.48 

Round  25, Global train loss: 1.040, Global test loss: 1.102, Global test accuracy: 61.97 

Round  26, Train loss: 0.982, Test loss: 1.365, Test accuracy: 53.54 

Round  26, Global train loss: 0.982, Global test loss: 1.122, Global test accuracy: 60.67 

Round  27, Train loss: 1.017, Test loss: 1.362, Test accuracy: 53.83 

Round  27, Global train loss: 1.017, Global test loss: 1.086, Global test accuracy: 61.88 

Round  28, Train loss: 0.973, Test loss: 1.358, Test accuracy: 53.99 

Round  28, Global train loss: 0.973, Global test loss: 1.088, Global test accuracy: 62.00 

Round  29, Train loss: 0.951, Test loss: 1.349, Test accuracy: 54.64 

Round  29, Global train loss: 0.951, Global test loss: 1.090, Global test accuracy: 62.53 

Round  30, Train loss: 0.952, Test loss: 1.344, Test accuracy: 55.03 

Round  30, Global train loss: 0.952, Global test loss: 1.096, Global test accuracy: 61.30 

Round  31, Train loss: 0.933, Test loss: 1.342, Test accuracy: 55.38 

Round  31, Global train loss: 0.933, Global test loss: 1.067, Global test accuracy: 62.78 

Round  32, Train loss: 0.936, Test loss: 1.335, Test accuracy: 55.85 

Round  32, Global train loss: 0.936, Global test loss: 1.068, Global test accuracy: 63.33 

Round  33, Train loss: 0.921, Test loss: 1.324, Test accuracy: 56.11 

Round  33, Global train loss: 0.921, Global test loss: 1.053, Global test accuracy: 63.60 

Round  34, Train loss: 0.864, Test loss: 1.342, Test accuracy: 56.14 

Round  34, Global train loss: 0.864, Global test loss: 1.057, Global test accuracy: 64.23 

Round  35, Train loss: 0.844, Test loss: 1.339, Test accuracy: 56.62 

Round  35, Global train loss: 0.844, Global test loss: 1.042, Global test accuracy: 64.66 

Round  36, Train loss: 0.876, Test loss: 1.347, Test accuracy: 56.62 

Round  36, Global train loss: 0.876, Global test loss: 1.045, Global test accuracy: 64.47 

Round  37, Train loss: 0.837, Test loss: 1.364, Test accuracy: 56.68 

Round  37, Global train loss: 0.837, Global test loss: 1.051, Global test accuracy: 64.64 

Round  38, Train loss: 0.814, Test loss: 1.363, Test accuracy: 56.91 

Round  38, Global train loss: 0.814, Global test loss: 1.053, Global test accuracy: 64.44 

Round  39, Train loss: 0.800, Test loss: 1.378, Test accuracy: 57.00 

Round  39, Global train loss: 0.800, Global test loss: 1.059, Global test accuracy: 65.09 

Round  40, Train loss: 0.766, Test loss: 1.374, Test accuracy: 57.21 

Round  40, Global train loss: 0.766, Global test loss: 1.060, Global test accuracy: 64.75 

Round  41, Train loss: 0.771, Test loss: 1.385, Test accuracy: 57.17 

Round  41, Global train loss: 0.771, Global test loss: 1.041, Global test accuracy: 65.09 

Round  42, Train loss: 0.743, Test loss: 1.388, Test accuracy: 57.23 

Round  42, Global train loss: 0.743, Global test loss: 1.044, Global test accuracy: 65.04 

Round  43, Train loss: 0.787, Test loss: 1.385, Test accuracy: 57.47 

Round  43, Global train loss: 0.787, Global test loss: 1.035, Global test accuracy: 65.38 

Round  44, Train loss: 0.755, Test loss: 1.383, Test accuracy: 57.51 

Round  44, Global train loss: 0.755, Global test loss: 1.048, Global test accuracy: 65.09 

Round  45, Train loss: 0.738, Test loss: 1.400, Test accuracy: 57.65 

Round  45, Global train loss: 0.738, Global test loss: 1.054, Global test accuracy: 65.43 

Round  46, Train loss: 0.783, Test loss: 1.378, Test accuracy: 58.19 

Round  46, Global train loss: 0.783, Global test loss: 1.034, Global test accuracy: 66.16 

Round  47, Train loss: 0.728, Test loss: 1.374, Test accuracy: 58.44 

Round  47, Global train loss: 0.728, Global test loss: 1.044, Global test accuracy: 66.00 

Round  48, Train loss: 0.675, Test loss: 1.390, Test accuracy: 58.45 

Round  48, Global train loss: 0.675, Global test loss: 1.072, Global test accuracy: 65.80 

Round  49, Train loss: 0.704, Test loss: 1.386, Test accuracy: 58.77 

Round  49, Global train loss: 0.704, Global test loss: 1.061, Global test accuracy: 66.00 

Round  50, Train loss: 0.718, Test loss: 1.378, Test accuracy: 58.92 

Round  50, Global train loss: 0.718, Global test loss: 1.036, Global test accuracy: 65.89 

Round  51, Train loss: 0.691, Test loss: 1.377, Test accuracy: 59.02 

Round  51, Global train loss: 0.691, Global test loss: 1.043, Global test accuracy: 66.56 

Round  52, Train loss: 0.651, Test loss: 1.374, Test accuracy: 59.30 

Round  52, Global train loss: 0.651, Global test loss: 1.044, Global test accuracy: 66.75 

Round  53, Train loss: 0.618, Test loss: 1.362, Test accuracy: 59.62 

Round  53, Global train loss: 0.618, Global test loss: 1.060, Global test accuracy: 66.72 

Round  54, Train loss: 0.684, Test loss: 1.383, Test accuracy: 59.25 

Round  54, Global train loss: 0.684, Global test loss: 1.039, Global test accuracy: 66.87 

Round  55, Train loss: 0.696, Test loss: 1.379, Test accuracy: 59.43 

Round  55, Global train loss: 0.696, Global test loss: 1.037, Global test accuracy: 66.81 

Round  56, Train loss: 0.605, Test loss: 1.386, Test accuracy: 59.42 

Round  56, Global train loss: 0.605, Global test loss: 1.052, Global test accuracy: 66.94 

Round  57, Train loss: 0.631, Test loss: 1.399, Test accuracy: 59.23 

Round  57, Global train loss: 0.631, Global test loss: 1.041, Global test accuracy: 66.98 

Round  58, Train loss: 0.572, Test loss: 1.414, Test accuracy: 59.37 

Round  58, Global train loss: 0.572, Global test loss: 1.070, Global test accuracy: 66.87 

Round  59, Train loss: 0.617, Test loss: 1.421, Test accuracy: 59.59 

Round  59, Global train loss: 0.617, Global test loss: 1.061, Global test accuracy: 66.70 

Round  60, Train loss: 0.585, Test loss: 1.419, Test accuracy: 59.67 

Round  60, Global train loss: 0.585, Global test loss: 1.049, Global test accuracy: 67.34 

Round  61, Train loss: 0.586, Test loss: 1.420, Test accuracy: 59.87 

Round  61, Global train loss: 0.586, Global test loss: 1.076, Global test accuracy: 66.52 

Round  62, Train loss: 0.611, Test loss: 1.411, Test accuracy: 60.07 

Round  62, Global train loss: 0.611, Global test loss: 1.060, Global test accuracy: 66.61 

Round  63, Train loss: 0.631, Test loss: 1.407, Test accuracy: 60.13 

Round  63, Global train loss: 0.631, Global test loss: 1.031, Global test accuracy: 67.19 

Round  64, Train loss: 0.595, Test loss: 1.408, Test accuracy: 60.22 

Round  64, Global train loss: 0.595, Global test loss: 1.064, Global test accuracy: 66.72 

Round  65, Train loss: 0.585, Test loss: 1.416, Test accuracy: 60.14 

Round  65, Global train loss: 0.585, Global test loss: 1.074, Global test accuracy: 66.47 

Round  66, Train loss: 0.570, Test loss: 1.418, Test accuracy: 60.35 

Round  66, Global train loss: 0.570, Global test loss: 1.071, Global test accuracy: 67.50 

Round  67, Train loss: 0.587, Test loss: 1.422, Test accuracy: 60.93 

Round  67, Global train loss: 0.587, Global test loss: 1.077, Global test accuracy: 68.11 

Round  68, Train loss: 0.562, Test loss: 1.418, Test accuracy: 61.01 

Round  68, Global train loss: 0.562, Global test loss: 1.055, Global test accuracy: 67.72 

Round  69, Train loss: 0.562, Test loss: 1.433, Test accuracy: 60.79 

Round  69, Global train loss: 0.562, Global test loss: 1.045, Global test accuracy: 67.51 

Round  70, Train loss: 0.575, Test loss: 1.429, Test accuracy: 60.78 

Round  70, Global train loss: 0.575, Global test loss: 1.041, Global test accuracy: 67.71 

Round  71, Train loss: 0.560, Test loss: 1.438, Test accuracy: 61.04 

Round  71, Global train loss: 0.560, Global test loss: 1.083, Global test accuracy: 67.85 

Round  72, Train loss: 0.542, Test loss: 1.453, Test accuracy: 60.85 

Round  72, Global train loss: 0.542, Global test loss: 1.081, Global test accuracy: 67.74 

Round  73, Train loss: 0.532, Test loss: 1.448, Test accuracy: 61.02 

Round  73, Global train loss: 0.532, Global test loss: 1.047, Global test accuracy: 67.90 

Round  74, Train loss: 0.562, Test loss: 1.445, Test accuracy: 61.05 

Round  74, Global train loss: 0.562, Global test loss: 1.052, Global test accuracy: 68.09 

Round  75, Train loss: 0.529, Test loss: 1.446, Test accuracy: 60.99 

Round  75, Global train loss: 0.529, Global test loss: 1.054, Global test accuracy: 67.98 

Round  76, Train loss: 0.534, Test loss: 1.431, Test accuracy: 61.53 

Round  76, Global train loss: 0.534, Global test loss: 1.061, Global test accuracy: 68.26 

Round  77, Train loss: 0.516, Test loss: 1.436, Test accuracy: 61.70 

Round  77, Global train loss: 0.516, Global test loss: 1.041, Global test accuracy: 68.12 

Round  78, Train loss: 0.494, Test loss: 1.434, Test accuracy: 61.61 

Round  78, Global train loss: 0.494, Global test loss: 1.066, Global test accuracy: 67.85 

Round  79, Train loss: 0.515, Test loss: 1.443, Test accuracy: 61.38 

Round  79, Global train loss: 0.515, Global test loss: 1.073, Global test accuracy: 67.50 

Round  80, Train loss: 0.501, Test loss: 1.447, Test accuracy: 61.59 

Round  80, Global train loss: 0.501, Global test loss: 1.071, Global test accuracy: 68.07 

Round  81, Train loss: 0.481, Test loss: 1.464, Test accuracy: 61.51 

Round  81, Global train loss: 0.481, Global test loss: 1.083, Global test accuracy: 68.04 

Round  82, Train loss: 0.469, Test loss: 1.447, Test accuracy: 61.85 

Round  82, Global train loss: 0.469, Global test loss: 1.097, Global test accuracy: 68.17 

Round  83, Train loss: 0.490, Test loss: 1.452, Test accuracy: 61.72 

Round  83, Global train loss: 0.490, Global test loss: 1.078, Global test accuracy: 67.54 

Round  84, Train loss: 0.498, Test loss: 1.441, Test accuracy: 61.80 

Round  84, Global train loss: 0.498, Global test loss: 1.093, Global test accuracy: 67.98 

Round  85, Train loss: 0.465, Test loss: 1.461, Test accuracy: 61.69 

Round  85, Global train loss: 0.465, Global test loss: 1.103, Global test accuracy: 67.53 

Round  86, Train loss: 0.476, Test loss: 1.452, Test accuracy: 62.11 

Round  86, Global train loss: 0.476, Global test loss: 1.081, Global test accuracy: 68.47 

Round  87, Train loss: 0.513, Test loss: 1.448, Test accuracy: 62.27 

Round  87, Global train loss: 0.513, Global test loss: 1.090, Global test accuracy: 68.07 

Round  88, Train loss: 0.440, Test loss: 1.450, Test accuracy: 62.28 

Round  88, Global train loss: 0.440, Global test loss: 1.104, Global test accuracy: 68.28 

Round  89, Train loss: 0.482, Test loss: 1.451, Test accuracy: 62.32 

Round  89, Global train loss: 0.482, Global test loss: 1.077, Global test accuracy: 68.48 

Round  90, Train loss: 0.466, Test loss: 1.474, Test accuracy: 62.29 

Round  90, Global train loss: 0.466, Global test loss: 1.111, Global test accuracy: 67.86 

Round  91, Train loss: 0.470, Test loss: 1.481, Test accuracy: 62.14 

Round  91, Global train loss: 0.470, Global test loss: 1.103, Global test accuracy: 67.98 

Round  92, Train loss: 0.441, Test loss: 1.475, Test accuracy: 62.34 

Round  92, Global train loss: 0.441, Global test loss: 1.105, Global test accuracy: 68.38 

Round  93, Train loss: 0.503, Test loss: 1.481, Test accuracy: 62.35 

Round  93, Global train loss: 0.503, Global test loss: 1.075, Global test accuracy: 68.53 

Round  94, Train loss: 0.443, Test loss: 1.493, Test accuracy: 62.41 

Round  94, Global train loss: 0.443, Global test loss: 1.120, Global test accuracy: 68.74 

Round  95, Train loss: 0.446, Test loss: 1.499, Test accuracy: 62.46 

Round  95, Global train loss: 0.446, Global test loss: 1.119, Global test accuracy: 68.76 

Round  96, Train loss: 0.451, Test loss: 1.516, Test accuracy: 62.09 

Round  96, Global train loss: 0.451, Global test loss: 1.099, Global test accuracy: 68.49 

Round  97, Train loss: 0.410, Test loss: 1.532, Test accuracy: 62.23 

Round  97, Global train loss: 0.410, Global test loss: 1.157, Global test accuracy: 68.08 

Round  98, Train loss: 0.423, Test loss: 1.514, Test accuracy: 62.44 

Round  98, Global train loss: 0.423, Global test loss: 1.111, Global test accuracy: 68.53 

Round  99, Train loss: 0.437, Test loss: 1.504, Test accuracy: 62.52 

Round  99, Global train loss: 0.437, Global test loss: 1.102, Global test accuracy: 68.08 

Final Round, Train loss: 0.342, Test loss: 1.676, Test accuracy: 62.05 

Final Round, Global train loss: 0.342, Global test loss: 1.102, Global test accuracy: 68.08 

Average accuracy final 10 rounds: 62.3275 

Average global accuracy final 10 rounds: 68.34333333333333 

3767.0523595809937
[1.4010138511657715, 2.591355085372925, 3.7655982971191406, 4.95026159286499, 6.1245551109313965, 7.284342527389526, 8.463492393493652, 9.643137693405151, 10.827686786651611, 12.013633728027344, 13.200522422790527, 14.380924940109253, 15.566022157669067, 16.747313976287842, 17.932716608047485, 19.10492253303528, 20.282387018203735, 21.458606958389282, 22.640721797943115, 23.813604831695557, 24.86007261276245, 25.90047264099121, 26.944312572479248, 27.9750816822052, 29.0297532081604, 30.069818019866943, 31.117759227752686, 32.154688358306885, 33.18787693977356, 34.22242593765259, 35.270957946777344, 36.30604267120361, 37.349310874938965, 38.38766527175903, 39.417765378952026, 40.458415269851685, 41.49450063705444, 42.52731680870056, 43.56221270561218, 44.60315680503845, 45.641138792037964, 46.69422388076782, 47.73508310317993, 48.77790141105652, 49.823079109191895, 50.85788917541504, 51.890071868896484, 52.92816686630249, 53.971078634262085, 55.00824332237244, 56.04454445838928, 57.08038377761841, 58.12038779258728, 59.16097402572632, 60.19022727012634, 61.22611379623413, 62.27079105377197, 63.305105447769165, 64.33358812332153, 65.37099146842957, 66.41774487495422, 67.46411871910095, 68.49739027023315, 69.53701853752136, 70.56918573379517, 71.60653352737427, 72.64431238174438, 73.68188810348511, 74.7109522819519, 75.75311541557312, 76.7872862815857, 77.82048296928406, 78.85625171661377, 79.88990211486816, 80.93527388572693, 81.96407985687256, 83.00167393684387, 84.03990626335144, 85.07775092124939, 86.12113094329834, 87.16625022888184, 88.19953966140747, 89.24685049057007, 90.28348851203918, 91.31680250167847, 92.35198855400085, 93.39218592643738, 94.44076323509216, 95.47895526885986, 96.51884198188782, 97.55412673950195, 98.63200902938843, 99.70867967605591, 100.78702020645142, 101.82220530509949, 102.85327363014221, 103.89254403114319, 104.9359929561615, 105.9684739112854, 107.00938057899475, 109.08643746376038]
[21.768333333333334, 27.81, 31.551666666666666, 33.775, 36.12, 36.211666666666666, 37.37166666666667, 38.53, 40.138333333333335, 41.32333333333333, 42.855, 43.873333333333335, 45.01166666666666, 45.52166666666667, 46.60666666666667, 47.355, 48.751666666666665, 49.38666666666666, 49.833333333333336, 50.251666666666665, 50.88333333333333, 51.505, 52.565, 52.833333333333336, 52.721666666666664, 53.47666666666667, 53.54333333333334, 53.83166666666666, 53.995, 54.63666666666666, 55.03, 55.385, 55.85166666666667, 56.10666666666667, 56.14333333333333, 56.615, 56.61833333333333, 56.678333333333335, 56.915, 56.998333333333335, 57.21333333333333, 57.17166666666667, 57.235, 57.468333333333334, 57.51166666666666, 57.64833333333333, 58.185, 58.43666666666667, 58.45333333333333, 58.77166666666667, 58.92, 59.015, 59.305, 59.61666666666667, 59.248333333333335, 59.42666666666667, 59.42, 59.225, 59.365, 59.595, 59.67333333333333, 59.87, 60.07333333333333, 60.126666666666665, 60.221666666666664, 60.14, 60.35, 60.928333333333335, 61.00666666666667, 60.78666666666667, 60.776666666666664, 61.04, 60.855, 61.02166666666667, 61.05166666666667, 60.986666666666665, 61.53, 61.70333333333333, 61.61333333333334, 61.385, 61.58833333333333, 61.50833333333333, 61.85333333333333, 61.718333333333334, 61.80166666666667, 61.69166666666667, 62.11, 62.27333333333333, 62.28, 62.321666666666665, 62.29333333333334, 62.14, 62.345, 62.35166666666667, 62.41166666666667, 62.458333333333336, 62.085, 62.23, 62.443333333333335, 62.516666666666666, 62.05]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.277, Test loss: 2.212, Test accuracy: 18.27 

Round   1, Train loss: 2.163, Test loss: 2.045, Test accuracy: 25.72 

Round   2, Train loss: 2.028, Test loss: 1.967, Test accuracy: 28.29 

Round   3, Train loss: 1.960, Test loss: 1.878, Test accuracy: 31.07 

Round   4, Train loss: 1.856, Test loss: 1.795, Test accuracy: 34.07 

Round   5, Train loss: 1.804, Test loss: 1.760, Test accuracy: 35.74 

Round   6, Train loss: 1.719, Test loss: 1.693, Test accuracy: 37.25 

Round   7, Train loss: 1.718, Test loss: 1.654, Test accuracy: 39.20 

Round   8, Train loss: 1.674, Test loss: 1.613, Test accuracy: 40.38 

Round   9, Train loss: 1.643, Test loss: 1.595, Test accuracy: 40.42 

Round  10, Train loss: 1.601, Test loss: 1.553, Test accuracy: 42.45 

Round  11, Train loss: 1.580, Test loss: 1.538, Test accuracy: 42.51 

Round  12, Train loss: 1.530, Test loss: 1.531, Test accuracy: 43.08 

Round  13, Train loss: 1.550, Test loss: 1.504, Test accuracy: 44.41 

Round  14, Train loss: 1.490, Test loss: 1.477, Test accuracy: 45.42 

Round  15, Train loss: 1.463, Test loss: 1.470, Test accuracy: 45.91 

Round  16, Train loss: 1.464, Test loss: 1.466, Test accuracy: 46.16 

Round  17, Train loss: 1.418, Test loss: 1.443, Test accuracy: 47.41 

Round  18, Train loss: 1.433, Test loss: 1.439, Test accuracy: 47.55 

Round  19, Train loss: 1.383, Test loss: 1.444, Test accuracy: 47.35 

Round  20, Train loss: 1.394, Test loss: 1.411, Test accuracy: 48.39 

Round  21, Train loss: 1.360, Test loss: 1.397, Test accuracy: 49.07 

Round  22, Train loss: 1.321, Test loss: 1.365, Test accuracy: 50.32 

Round  23, Train loss: 1.310, Test loss: 1.363, Test accuracy: 50.77 

Round  24, Train loss: 1.328, Test loss: 1.343, Test accuracy: 51.47 

Round  25, Train loss: 1.308, Test loss: 1.318, Test accuracy: 52.40 

Round  26, Train loss: 1.279, Test loss: 1.317, Test accuracy: 52.43 

Round  27, Train loss: 1.265, Test loss: 1.306, Test accuracy: 53.07 

Round  28, Train loss: 1.235, Test loss: 1.307, Test accuracy: 52.93 

Round  29, Train loss: 1.206, Test loss: 1.281, Test accuracy: 53.92 

Round  30, Train loss: 1.223, Test loss: 1.274, Test accuracy: 54.48 

Round  31, Train loss: 1.212, Test loss: 1.266, Test accuracy: 54.84 

Round  32, Train loss: 1.192, Test loss: 1.264, Test accuracy: 55.01 

Round  33, Train loss: 1.135, Test loss: 1.246, Test accuracy: 55.07 

Round  34, Train loss: 1.126, Test loss: 1.252, Test accuracy: 55.05 

Round  35, Train loss: 1.124, Test loss: 1.231, Test accuracy: 56.02 

Round  36, Train loss: 1.101, Test loss: 1.232, Test accuracy: 55.82 

Round  37, Train loss: 1.134, Test loss: 1.224, Test accuracy: 56.38 

Round  38, Train loss: 1.067, Test loss: 1.214, Test accuracy: 56.97 

Round  39, Train loss: 1.088, Test loss: 1.214, Test accuracy: 57.10 

Round  40, Train loss: 1.073, Test loss: 1.198, Test accuracy: 57.67 

Round  41, Train loss: 1.053, Test loss: 1.207, Test accuracy: 57.54 

Round  42, Train loss: 1.008, Test loss: 1.198, Test accuracy: 57.70 

Round  43, Train loss: 1.018, Test loss: 1.192, Test accuracy: 58.14 

Round  44, Train loss: 0.998, Test loss: 1.193, Test accuracy: 57.88 

Round  45, Train loss: 1.012, Test loss: 1.192, Test accuracy: 58.70 

Round  46, Train loss: 0.979, Test loss: 1.175, Test accuracy: 58.97 

Round  47, Train loss: 0.995, Test loss: 1.166, Test accuracy: 59.25 

Round  48, Train loss: 0.947, Test loss: 1.177, Test accuracy: 59.22 

Round  49, Train loss: 0.974, Test loss: 1.171, Test accuracy: 59.68 

Round  50, Train loss: 0.936, Test loss: 1.174, Test accuracy: 59.59 

Round  51, Train loss: 0.898, Test loss: 1.180, Test accuracy: 59.77 

Round  52, Train loss: 0.884, Test loss: 1.191, Test accuracy: 59.40 

Round  53, Train loss: 0.929, Test loss: 1.173, Test accuracy: 59.75 

Round  54, Train loss: 0.924, Test loss: 1.159, Test accuracy: 59.84 

Round  55, Train loss: 0.897, Test loss: 1.159, Test accuracy: 60.19 

Round  56, Train loss: 0.903, Test loss: 1.176, Test accuracy: 60.01 

Round  57, Train loss: 0.869, Test loss: 1.161, Test accuracy: 60.37 

Round  58, Train loss: 0.857, Test loss: 1.156, Test accuracy: 60.82 

Round  59, Train loss: 0.841, Test loss: 1.186, Test accuracy: 60.40 

Round  60, Train loss: 0.846, Test loss: 1.187, Test accuracy: 60.25 

Round  61, Train loss: 0.839, Test loss: 1.187, Test accuracy: 60.70 

Round  62, Train loss: 0.894, Test loss: 1.169, Test accuracy: 60.73 

Round  63, Train loss: 0.827, Test loss: 1.180, Test accuracy: 60.72 

Round  64, Train loss: 0.833, Test loss: 1.182, Test accuracy: 60.95 

Round  65, Train loss: 0.810, Test loss: 1.159, Test accuracy: 61.37 

Round  66, Train loss: 0.807, Test loss: 1.153, Test accuracy: 61.87 

Round  67, Train loss: 0.778, Test loss: 1.181, Test accuracy: 61.36 

Round  68, Train loss: 0.763, Test loss: 1.180, Test accuracy: 61.39 

Round  69, Train loss: 0.786, Test loss: 1.168, Test accuracy: 62.03 

Round  70, Train loss: 0.773, Test loss: 1.164, Test accuracy: 62.21 

Round  71, Train loss: 0.768, Test loss: 1.173, Test accuracy: 61.80 

Round  72, Train loss: 0.735, Test loss: 1.180, Test accuracy: 61.81 

Round  73, Train loss: 0.757, Test loss: 1.176, Test accuracy: 61.74 

Round  74, Train loss: 0.760, Test loss: 1.188, Test accuracy: 61.95 

Round  75, Train loss: 0.787, Test loss: 1.179, Test accuracy: 61.87 

Round  76, Train loss: 0.740, Test loss: 1.173, Test accuracy: 62.06 

Round  77, Train loss: 0.674, Test loss: 1.175, Test accuracy: 62.32 

Round  78, Train loss: 0.708, Test loss: 1.169, Test accuracy: 62.75 

Round  79, Train loss: 0.682, Test loss: 1.195, Test accuracy: 62.27 

Round  80, Train loss: 0.701, Test loss: 1.211, Test accuracy: 62.06 

Round  81, Train loss: 0.732, Test loss: 1.230, Test accuracy: 61.96 

Round  82, Train loss: 0.657, Test loss: 1.228, Test accuracy: 62.19 

Round  83, Train loss: 0.695, Test loss: 1.195, Test accuracy: 62.41 

Round  84, Train loss: 0.666, Test loss: 1.197, Test accuracy: 62.55 

Round  85, Train loss: 0.697, Test loss: 1.193, Test accuracy: 62.74 

Round  86, Train loss: 0.652, Test loss: 1.227, Test accuracy: 62.64 

Round  87, Train loss: 0.652, Test loss: 1.201, Test accuracy: 63.05 

Round  88, Train loss: 0.672, Test loss: 1.181, Test accuracy: 63.10 

Round  89, Train loss: 0.644, Test loss: 1.204, Test accuracy: 62.95 

Round  90, Train loss: 0.624, Test loss: 1.230, Test accuracy: 62.66 

Round  91, Train loss: 0.602, Test loss: 1.224, Test accuracy: 62.54 

Round  92, Train loss: 0.682, Test loss: 1.210, Test accuracy: 63.08 

Round  93, Train loss: 0.601, Test loss: 1.277, Test accuracy: 62.12 

Round  94, Train loss: 0.618, Test loss: 1.247, Test accuracy: 63.17 

Round  95, Train loss: 0.605, Test loss: 1.241, Test accuracy: 62.94 

Round  96, Train loss: 0.610, Test loss: 1.238, Test accuracy: 62.59 

Round  97, Train loss: 0.620, Test loss: 1.223, Test accuracy: 62.57 

Round  98, Train loss: 0.572, Test loss: 1.237, Test accuracy: 63.06 

Round  99, Train loss: 0.585, Test loss: 1.233, Test accuracy: 63.15 

Final Round, Train loss: 0.518, Test loss: 1.244, Test accuracy: 63.33 

Average accuracy final 10 rounds: 62.78650000000001 

2165.443638563156
[1.3289318084716797, 2.4575626850128174, 3.56215763092041, 4.674685716629028, 5.7846081256866455, 6.874426603317261, 7.948850870132446, 9.022879838943481, 10.151948690414429, 11.269521474838257, 12.379613637924194, 13.485122680664062, 14.533276319503784, 15.583614349365234, 16.637912034988403, 17.6911358833313, 18.747662782669067, 19.813371419906616, 20.875935792922974, 21.952216386795044, 23.026366710662842, 24.104941368103027, 25.18128728866577, 26.22522282600403, 27.2921621799469, 28.338717222213745, 29.38931918144226, 30.44708776473999, 31.50441312789917, 32.608246088027954, 33.66583776473999, 34.7219295501709, 35.76740884780884, 36.8132209777832, 37.886171102523804, 38.94435119628906, 39.99559497833252, 41.04936504364014, 42.323323488235474, 43.41216707229614, 44.49188446998596, 45.56807804107666, 46.652698040008545, 47.613378047943115, 48.560786485672, 49.50956106185913, 50.46267056465149, 51.417450189590454, 52.36746621131897, 53.31654357910156, 54.26231646537781, 55.21227145195007, 56.16545844078064, 57.382732629776, 58.34255623817444, 59.29236578941345, 60.2439398765564, 61.20296025276184, 62.15924906730652, 63.10819959640503, 64.06570148468018, 65.02285170555115, 65.98114728927612, 66.93236541748047, 67.88912105560303, 68.84854221343994, 69.80487537384033, 70.75673985481262, 71.75020670890808, 72.9364185333252, 74.8776535987854, 76.01361846923828, 77.12829303741455, 78.23539924621582, 79.34414052963257, 80.44659399986267, 81.55301785469055, 82.66047930717468, 83.7635989189148, 84.87378907203674, 85.97906017303467, 87.08468747138977, 88.19393992424011, 89.30188202857971, 90.41050672531128, 91.52535605430603, 92.64655065536499, 93.77247977256775, 94.88817715644836, 96.01230764389038, 97.13211798667908, 98.24981737136841, 99.36288619041443, 100.47830820083618, 101.58333849906921, 102.68640947341919, 103.79348421096802, 104.89980053901672, 106.0070390701294, 107.11445021629333, 109.05807304382324]
[18.265, 25.718333333333334, 28.288333333333334, 31.066666666666666, 34.07333333333333, 35.73833333333334, 37.248333333333335, 39.205, 40.385, 40.42333333333333, 42.446666666666665, 42.50833333333333, 43.075, 44.406666666666666, 45.42, 45.906666666666666, 46.163333333333334, 47.406666666666666, 47.553333333333335, 47.35333333333333, 48.39333333333333, 49.071666666666665, 50.321666666666665, 50.766666666666666, 51.471666666666664, 52.4, 52.431666666666665, 53.07333333333333, 52.92666666666667, 53.916666666666664, 54.48166666666667, 54.83833333333333, 55.01166666666666, 55.068333333333335, 55.04833333333333, 56.016666666666666, 55.821666666666665, 56.375, 56.973333333333336, 57.1, 57.67333333333333, 57.54, 57.7, 58.14333333333333, 57.876666666666665, 58.705, 58.96666666666667, 59.251666666666665, 59.223333333333336, 59.681666666666665, 59.59, 59.765, 59.401666666666664, 59.74666666666667, 59.835, 60.19, 60.00666666666667, 60.373333333333335, 60.818333333333335, 60.403333333333336, 60.248333333333335, 60.696666666666665, 60.735, 60.715, 60.94833333333333, 61.36833333333333, 61.865, 61.36, 61.388333333333335, 62.03, 62.20666666666666, 61.803333333333335, 61.81166666666667, 61.73833333333334, 61.95333333333333, 61.873333333333335, 62.056666666666665, 62.321666666666665, 62.75333333333333, 62.26833333333333, 62.05833333333333, 61.95666666666666, 62.19166666666667, 62.405, 62.553333333333335, 62.745, 62.63666666666666, 63.05, 63.098333333333336, 62.945, 62.663333333333334, 62.54, 63.075, 62.11666666666667, 63.17166666666667, 62.935, 62.58833333333333, 62.57333333333333, 63.056666666666665, 63.145, 63.325]
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 18, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 2.276, Test loss: 2.125, Test accuracy: 23.00
Round   1, Train loss: 2.085, Test loss: 1.937, Test accuracy: 28.59
Round   2, Train loss: 1.956, Test loss: 1.793, Test accuracy: 33.46
Round   3, Train loss: 1.878, Test loss: 1.687, Test accuracy: 37.05
Round   4, Train loss: 1.764, Test loss: 1.615, Test accuracy: 41.10
Round   5, Train loss: 1.692, Test loss: 1.531, Test accuracy: 43.62
Round   6, Train loss: 1.640, Test loss: 1.499, Test accuracy: 44.26
Round   7, Train loss: 1.553, Test loss: 1.445, Test accuracy: 47.73
Round   8, Train loss: 1.512, Test loss: 1.408, Test accuracy: 48.35
Round   9, Train loss: 1.551, Test loss: 1.373, Test accuracy: 51.48
Round  10, Train loss: 1.429, Test loss: 1.352, Test accuracy: 51.76
Round  11, Train loss: 1.443, Test loss: 1.311, Test accuracy: 53.87
Round  12, Train loss: 1.401, Test loss: 1.290, Test accuracy: 54.19
Round  13, Train loss: 1.295, Test loss: 1.280, Test accuracy: 55.02
Round  14, Train loss: 1.315, Test loss: 1.254, Test accuracy: 55.70
Round  15, Train loss: 1.331, Test loss: 1.219, Test accuracy: 57.08
Round  16, Train loss: 1.277, Test loss: 1.203, Test accuracy: 58.21
Round  17, Train loss: 1.218, Test loss: 1.189, Test accuracy: 58.51
Round  18, Train loss: 1.197, Test loss: 1.180, Test accuracy: 58.38
Round  19, Train loss: 1.221, Test loss: 1.155, Test accuracy: 59.48
Round  20, Train loss: 1.147, Test loss: 1.144, Test accuracy: 60.13
Round  21, Train loss: 1.127, Test loss: 1.139, Test accuracy: 60.36
Round  22, Train loss: 1.111, Test loss: 1.124, Test accuracy: 60.49
Round  23, Train loss: 1.050, Test loss: 1.111, Test accuracy: 61.88
Round  24, Train loss: 1.026, Test loss: 1.096, Test accuracy: 62.20
Round  25, Train loss: 1.028, Test loss: 1.103, Test accuracy: 61.79
Round  26, Train loss: 0.992, Test loss: 1.081, Test accuracy: 62.89
Round  27, Train loss: 1.001, Test loss: 1.088, Test accuracy: 62.60
Round  28, Train loss: 0.934, Test loss: 1.078, Test accuracy: 63.51
Round  29, Train loss: 0.966, Test loss: 1.084, Test accuracy: 63.12
Round  30, Train loss: 0.878, Test loss: 1.076, Test accuracy: 63.00
Round  31, Train loss: 0.947, Test loss: 1.058, Test accuracy: 63.68
Round  32, Train loss: 0.852, Test loss: 1.077, Test accuracy: 64.07
Round  33, Train loss: 0.900, Test loss: 1.051, Test accuracy: 64.39
Round  34, Train loss: 0.794, Test loss: 1.059, Test accuracy: 64.29
Round  35, Train loss: 0.840, Test loss: 1.068, Test accuracy: 64.69
Round  36, Train loss: 0.811, Test loss: 1.058, Test accuracy: 65.13
Round  37, Train loss: 0.778, Test loss: 1.080, Test accuracy: 64.48
Round  38, Train loss: 0.780, Test loss: 1.060, Test accuracy: 65.07
Round  39, Train loss: 0.744, Test loss: 1.048, Test accuracy: 65.29
Round  40, Train loss: 0.794, Test loss: 1.048, Test accuracy: 65.44
Round  41, Train loss: 0.734, Test loss: 1.034, Test accuracy: 65.91
Round  42, Train loss: 0.765, Test loss: 1.030, Test accuracy: 66.11
Round  43, Train loss: 0.742, Test loss: 1.038, Test accuracy: 65.27
Round  44, Train loss: 0.714, Test loss: 1.050, Test accuracy: 65.56
Round  45, Train loss: 0.685, Test loss: 1.044, Test accuracy: 65.81
Round  46, Train loss: 0.654, Test loss: 1.055, Test accuracy: 65.78
Round  47, Train loss: 0.640, Test loss: 1.057, Test accuracy: 66.35
Round  48, Train loss: 0.671, Test loss: 1.051, Test accuracy: 66.51
Round  49, Train loss: 0.620, Test loss: 1.057, Test accuracy: 66.38
Round  50, Train loss: 0.617, Test loss: 1.050, Test accuracy: 66.28
Round  51, Train loss: 0.599, Test loss: 1.063, Test accuracy: 66.26
Round  52, Train loss: 0.661, Test loss: 1.025, Test accuracy: 66.24
Round  53, Train loss: 0.594, Test loss: 1.044, Test accuracy: 66.85
Round  54, Train loss: 0.620, Test loss: 1.037, Test accuracy: 66.94
Round  55, Train loss: 0.577, Test loss: 1.041, Test accuracy: 66.82
Round  56, Train loss: 0.613, Test loss: 1.060, Test accuracy: 66.80
Round  57, Train loss: 0.606, Test loss: 1.052, Test accuracy: 66.50
Round  58, Train loss: 0.603, Test loss: 1.042, Test accuracy: 67.12
Round  59, Train loss: 0.522, Test loss: 1.048, Test accuracy: 66.96
Round  60, Train loss: 0.596, Test loss: 1.039, Test accuracy: 67.03
Round  61, Train loss: 0.588, Test loss: 1.057, Test accuracy: 67.16
Round  62, Train loss: 0.540, Test loss: 1.049, Test accuracy: 67.36
Round  63, Train loss: 0.562, Test loss: 1.044, Test accuracy: 67.58
Round  64, Train loss: 0.549, Test loss: 1.053, Test accuracy: 67.35
Round  65, Train loss: 0.495, Test loss: 1.065, Test accuracy: 67.22
Round  66, Train loss: 0.532, Test loss: 1.045, Test accuracy: 67.78
Round  67, Train loss: 0.511, Test loss: 1.057, Test accuracy: 67.48
Round  68, Train loss: 0.559, Test loss: 1.033, Test accuracy: 67.88
Round  69, Train loss: 0.507, Test loss: 1.040, Test accuracy: 67.64
Round  70, Train loss: 0.503, Test loss: 1.040, Test accuracy: 68.05
Round  71, Train loss: 0.479, Test loss: 1.050, Test accuracy: 67.97
Round  72, Train loss: 0.457, Test loss: 1.060, Test accuracy: 67.56
Round  73, Train loss: 0.452, Test loss: 1.068, Test accuracy: 67.85
Round  74, Train loss: 0.482, Test loss: 1.050, Test accuracy: 68.08
Round  75, Train loss: 0.470, Test loss: 1.063, Test accuracy: 68.23
Round  76, Train loss: 0.448, Test loss: 1.053, Test accuracy: 68.30
Round  77, Train loss: 0.431, Test loss: 1.086, Test accuracy: 67.52
Round  78, Train loss: 0.438, Test loss: 1.062, Test accuracy: 67.81
Round  79, Train loss: 0.448, Test loss: 1.053, Test accuracy: 68.77
Round  80, Train loss: 0.473, Test loss: 1.073, Test accuracy: 68.07
Round  81, Train loss: 0.416, Test loss: 1.082, Test accuracy: 67.97
Round  82, Train loss: 0.436, Test loss: 1.071, Test accuracy: 67.94
Round  83, Train loss: 0.413, Test loss: 1.075, Test accuracy: 68.75
Round  84, Train loss: 0.380, Test loss: 1.108, Test accuracy: 68.27
Round  85, Train loss: 0.425, Test loss: 1.067, Test accuracy: 68.56
Round  86, Train loss: 0.421, Test loss: 1.070, Test accuracy: 68.73
Round  87, Train loss: 0.438, Test loss: 1.091, Test accuracy: 68.83
Round  88, Train loss: 0.401, Test loss: 1.083, Test accuracy: 68.80
Round  89, Train loss: 0.380, Test loss: 1.119, Test accuracy: 67.94
Round  90, Train loss: 0.373, Test loss: 1.112, Test accuracy: 69.03
Round  91, Train loss: 0.392, Test loss: 1.109, Test accuracy: 67.83
Round  92, Train loss: 0.381, Test loss: 1.091, Test accuracy: 69.25
Round  93, Train loss: 0.337, Test loss: 1.136, Test accuracy: 68.20
Round  94, Train loss: 0.387, Test loss: 1.108, Test accuracy: 68.89
Round  95, Train loss: 0.361, Test loss: 1.137, Test accuracy: 68.17
Round  96, Train loss: 0.332, Test loss: 1.117, Test accuracy: 69.12
Round  97, Train loss: 0.350, Test loss: 1.138, Test accuracy: 68.81
Round  98, Train loss: 0.365, Test loss: 1.126, Test accuracy: 68.41
Round  99, Train loss: 0.337, Test loss: 1.097, Test accuracy: 69.30
Final Round, Train loss: 0.355, Test loss: 1.064, Test accuracy: 69.70
Average accuracy final 10 rounds: 68.70116666666667
3039.267439365387
[3.181297779083252, 6.171732425689697, 9.036666631698608, 11.832326889038086, 14.78673005104065, 17.733500242233276, 20.53091812133789, 23.471810579299927, 26.37999987602234, 29.045496463775635, 31.72799801826477, 34.379061222076416, 37.03934144973755, 39.620179176330566, 42.18129801750183, 44.74775409698486, 47.313024044036865, 49.88226819038391, 52.45273756980896, 55.01094055175781, 57.624107122421265, 60.19468426704407, 62.75994658470154, 65.33420896530151, 67.91394400596619, 70.49386954307556, 73.10482001304626, 75.6766767501831, 78.23781132698059, 80.80289769172668, 83.36753344535828, 85.93676900863647, 88.56375551223755, 91.13179779052734, 93.77014017105103, 96.34416770935059, 98.99366092681885, 101.63971638679504, 104.2669107913971, 106.8509373664856, 109.47486639022827, 112.1098313331604, 114.74579167366028, 117.3194568157196, 119.88794326782227, 122.46426296234131, 125.03728866577148, 127.60950875282288, 130.22148323059082, 132.7863757610321, 135.34745025634766, 137.91551399230957, 140.49369645118713, 143.07791781425476, 145.65902471542358, 148.23607921600342, 150.81389713287354, 153.3846287727356, 155.98763608932495, 158.5718605518341, 161.14602279663086, 163.71924448013306, 166.3012294769287, 168.87743544578552, 171.4525430202484, 174.02641010284424, 176.60107946395874, 179.18163442611694, 181.77652168273926, 184.36489582061768, 187.2437870502472, 189.81551861763, 192.40869140625, 194.99882745742798, 197.5893256664276, 200.1718716621399, 202.74443817138672, 205.3344428539276, 207.91864848136902, 210.4965741634369, 213.090562582016, 215.66871428489685, 218.2338001728058, 220.80251097679138, 223.38655877113342, 225.96979522705078, 228.5532989501953, 231.1286427974701, 233.68338179588318, 236.25591850280762, 238.84683418273926, 241.4085602760315, 243.98546957969666, 246.56360054016113, 249.12833452224731, 251.7033622264862, 254.28368544578552, 256.8566007614136, 259.4327428340912, 262.0060486793518, 264.59806728363037]
[23.0, 28.585, 33.46, 37.05166666666667, 41.10166666666667, 43.62166666666667, 44.25666666666667, 47.73, 48.35333333333333, 51.485, 51.755, 53.87, 54.193333333333335, 55.02333333333333, 55.70166666666667, 57.075, 58.21, 58.50833333333333, 58.37833333333333, 59.47666666666667, 60.13, 60.358333333333334, 60.495, 61.88, 62.19833333333333, 61.791666666666664, 62.888333333333335, 62.60333333333333, 63.51166666666666, 63.125, 62.998333333333335, 63.678333333333335, 64.07333333333334, 64.395, 64.28666666666666, 64.68666666666667, 65.13333333333334, 64.48, 65.06666666666666, 65.28666666666666, 65.445, 65.91333333333333, 66.11166666666666, 65.27333333333333, 65.56333333333333, 65.81166666666667, 65.78333333333333, 66.35, 66.51166666666667, 66.37666666666667, 66.285, 66.26333333333334, 66.23666666666666, 66.85, 66.94333333333333, 66.81666666666666, 66.80166666666666, 66.49833333333333, 67.11833333333334, 66.95833333333333, 67.035, 67.15666666666667, 67.365, 67.58, 67.35333333333334, 67.21833333333333, 67.78, 67.48166666666667, 67.88333333333334, 67.64, 68.05, 67.96833333333333, 67.56333333333333, 67.85, 68.08166666666666, 68.235, 68.29833333333333, 67.52, 67.805, 68.765, 68.07, 67.975, 67.94333333333333, 68.75, 68.26666666666667, 68.56333333333333, 68.73333333333333, 68.82833333333333, 68.795, 67.94166666666666, 69.035, 67.83333333333333, 69.24666666666667, 68.205, 68.89166666666667, 68.165, 69.12333333333333, 68.805, 68.41166666666666, 69.295, 69.69833333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.58 

Round   0, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.51 

Round   1, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.71 

Round   1, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.65 

Round   2, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.94 

Round   2, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98 

Round   3, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.24 

Round   3, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.33 

Round   4, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.60 

Round   4, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.14 

Round   5, Train loss: 2.299, Test loss: 2.302, Test accuracy: 11.93 

Round   5, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 12.35 

Round   6, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.11 

Round   6, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.52 

Round   7, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.21 

Round   7, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.58 

Round   8, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.56 

Round   8, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.32 

Round   9, Train loss: 2.298, Test loss: 2.301, Test accuracy: 12.77 

Round   9, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 13.30 

Round  10, Train loss: 2.300, Test loss: 2.300, Test accuracy: 12.97 

Round  10, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 13.58 

Round  11, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.33 

Round  11, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 13.91 

Round  12, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.59 

Round  12, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 14.47 

Round  13, Train loss: 2.299, Test loss: 2.300, Test accuracy: 13.58 

Round  13, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 14.71 

Round  14, Train loss: 2.299, Test loss: 2.299, Test accuracy: 13.73 

Round  14, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 14.84 

Round  15, Train loss: 2.298, Test loss: 2.299, Test accuracy: 14.23 

Round  15, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 15.27 

Round  16, Train loss: 2.298, Test loss: 2.298, Test accuracy: 14.54 

Round  16, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 15.31 

Round  17, Train loss: 2.296, Test loss: 2.298, Test accuracy: 14.63 

Round  17, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 15.43 

Round  18, Train loss: 2.298, Test loss: 2.297, Test accuracy: 14.81 

Round  18, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 15.50 

Round  19, Train loss: 2.297, Test loss: 2.297, Test accuracy: 14.97 

Round  19, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 15.78 

Round  20, Train loss: 2.294, Test loss: 2.296, Test accuracy: 15.35 

Round  20, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 16.04 

Round  21, Train loss: 2.295, Test loss: 2.295, Test accuracy: 15.54 

Round  21, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 16.04 

Round  22, Train loss: 2.293, Test loss: 2.295, Test accuracy: 15.61 

Round  22, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 16.28 

Round  23, Train loss: 2.295, Test loss: 2.295, Test accuracy: 15.65 

Round  23, Global train loss: 2.295, Global test loss: 2.293, Global test accuracy: 16.32 

Round  24, Train loss: 2.293, Test loss: 2.294, Test accuracy: 15.79 

Round  24, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 16.23 

Round  25, Train loss: 2.294, Test loss: 2.293, Test accuracy: 15.72 

Round  25, Global train loss: 2.294, Global test loss: 2.292, Global test accuracy: 16.22 

Round  26, Train loss: 2.294, Test loss: 2.292, Test accuracy: 15.82 

Round  26, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 16.04 

Round  27, Train loss: 2.292, Test loss: 2.292, Test accuracy: 15.65 

Round  27, Global train loss: 2.292, Global test loss: 2.290, Global test accuracy: 15.60 

Round  28, Train loss: 2.291, Test loss: 2.291, Test accuracy: 15.64 

Round  28, Global train loss: 2.291, Global test loss: 2.290, Global test accuracy: 15.66 

Round  29, Train loss: 2.291, Test loss: 2.291, Test accuracy: 15.65 

Round  29, Global train loss: 2.291, Global test loss: 2.290, Global test accuracy: 15.82 

Round  30, Train loss: 2.289, Test loss: 2.290, Test accuracy: 15.58 

Round  30, Global train loss: 2.289, Global test loss: 2.289, Global test accuracy: 16.02 

Round  31, Train loss: 2.289, Test loss: 2.290, Test accuracy: 15.69 

Round  31, Global train loss: 2.289, Global test loss: 2.289, Global test accuracy: 16.00 

Round  32, Train loss: 2.290, Test loss: 2.289, Test accuracy: 15.76 

Round  32, Global train loss: 2.290, Global test loss: 2.287, Global test accuracy: 15.92 

Round  33, Train loss: 2.289, Test loss: 2.288, Test accuracy: 15.71 

Round  33, Global train loss: 2.289, Global test loss: 2.287, Global test accuracy: 15.89 

Round  34, Train loss: 2.288, Test loss: 2.288, Test accuracy: 15.69 

Round  34, Global train loss: 2.288, Global test loss: 2.286, Global test accuracy: 15.86 

Round  35, Train loss: 2.288, Test loss: 2.287, Test accuracy: 15.70 

Round  35, Global train loss: 2.288, Global test loss: 2.286, Global test accuracy: 16.03 

Round  36, Train loss: 2.286, Test loss: 2.287, Test accuracy: 15.71 

Round  36, Global train loss: 2.286, Global test loss: 2.285, Global test accuracy: 16.23 

Round  37, Train loss: 2.288, Test loss: 2.286, Test accuracy: 15.83 

Round  37, Global train loss: 2.288, Global test loss: 2.284, Global test accuracy: 15.91 

Round  38, Train loss: 2.284, Test loss: 2.285, Test accuracy: 15.84 

Round  38, Global train loss: 2.284, Global test loss: 2.283, Global test accuracy: 16.15 

Round  39, Train loss: 2.285, Test loss: 2.284, Test accuracy: 15.98 

Round  39, Global train loss: 2.285, Global test loss: 2.282, Global test accuracy: 16.12 

Round  40, Train loss: 2.286, Test loss: 2.283, Test accuracy: 16.03 

Round  40, Global train loss: 2.286, Global test loss: 2.282, Global test accuracy: 16.13 

Round  41, Train loss: 2.284, Test loss: 2.283, Test accuracy: 16.09 

Round  41, Global train loss: 2.284, Global test loss: 2.281, Global test accuracy: 16.37 

Round  42, Train loss: 2.285, Test loss: 2.282, Test accuracy: 16.03 

Round  42, Global train loss: 2.285, Global test loss: 2.280, Global test accuracy: 16.07 

Round  43, Train loss: 2.281, Test loss: 2.281, Test accuracy: 16.14 

Round  43, Global train loss: 2.281, Global test loss: 2.280, Global test accuracy: 16.53 

Round  44, Train loss: 2.283, Test loss: 2.280, Test accuracy: 16.25 

Round  44, Global train loss: 2.283, Global test loss: 2.279, Global test accuracy: 16.61 

Round  45, Train loss: 2.282, Test loss: 2.280, Test accuracy: 16.31 

Round  45, Global train loss: 2.282, Global test loss: 2.278, Global test accuracy: 16.74 

Round  46, Train loss: 2.279, Test loss: 2.279, Test accuracy: 16.31 

Round  46, Global train loss: 2.279, Global test loss: 2.277, Global test accuracy: 16.75 

Round  47, Train loss: 2.279, Test loss: 2.278, Test accuracy: 16.42 

Round  47, Global train loss: 2.279, Global test loss: 2.276, Global test accuracy: 16.57 

Round  48, Train loss: 2.279, Test loss: 2.277, Test accuracy: 16.27 

Round  48, Global train loss: 2.279, Global test loss: 2.275, Global test accuracy: 16.45 

Round  49, Train loss: 2.276, Test loss: 2.276, Test accuracy: 16.18 

Round  49, Global train loss: 2.276, Global test loss: 2.274, Global test accuracy: 16.72 

Round  50, Train loss: 2.277, Test loss: 2.275, Test accuracy: 16.15 

Round  50, Global train loss: 2.277, Global test loss: 2.273, Global test accuracy: 16.76 

Round  51, Train loss: 2.280, Test loss: 2.274, Test accuracy: 16.28 

Round  51, Global train loss: 2.280, Global test loss: 2.272, Global test accuracy: 17.05 

Round  52, Train loss: 2.278, Test loss: 2.273, Test accuracy: 16.28 

Round  52, Global train loss: 2.278, Global test loss: 2.271, Global test accuracy: 16.84 

Round  53, Train loss: 2.274, Test loss: 2.272, Test accuracy: 16.50 

Round  53, Global train loss: 2.274, Global test loss: 2.270, Global test accuracy: 16.77 

Round  54, Train loss: 2.275, Test loss: 2.271, Test accuracy: 16.39 

Round  54, Global train loss: 2.275, Global test loss: 2.269, Global test accuracy: 16.53 

Round  55, Train loss: 2.276, Test loss: 2.270, Test accuracy: 16.32 

Round  55, Global train loss: 2.276, Global test loss: 2.268, Global test accuracy: 16.52 

Round  56, Train loss: 2.275, Test loss: 2.269, Test accuracy: 16.29 

Round  56, Global train loss: 2.275, Global test loss: 2.267, Global test accuracy: 16.54 

Round  57, Train loss: 2.274, Test loss: 2.268, Test accuracy: 16.12 

Round  57, Global train loss: 2.274, Global test loss: 2.266, Global test accuracy: 15.99 

Round  58, Train loss: 2.276, Test loss: 2.268, Test accuracy: 16.07 

Round  58, Global train loss: 2.276, Global test loss: 2.265, Global test accuracy: 15.96 

Round  59, Train loss: 2.270, Test loss: 2.266, Test accuracy: 15.92 

Round  59, Global train loss: 2.270, Global test loss: 2.264, Global test accuracy: 15.77 

Round  60, Train loss: 2.268, Test loss: 2.265, Test accuracy: 15.87 

Round  60, Global train loss: 2.268, Global test loss: 2.263, Global test accuracy: 16.14 

Round  61, Train loss: 2.271, Test loss: 2.264, Test accuracy: 15.94 

Round  61, Global train loss: 2.271, Global test loss: 2.263, Global test accuracy: 16.31 

Round  62, Train loss: 2.267, Test loss: 2.264, Test accuracy: 16.00 

Round  62, Global train loss: 2.267, Global test loss: 2.261, Global test accuracy: 16.38 

Round  63, Train loss: 2.267, Test loss: 2.263, Test accuracy: 16.11 

Round  63, Global train loss: 2.267, Global test loss: 2.259, Global test accuracy: 16.28 

Round  64, Train loss: 2.264, Test loss: 2.261, Test accuracy: 15.80 

Round  64, Global train loss: 2.264, Global test loss: 2.257, Global test accuracy: 15.91 

Round  65, Train loss: 2.265, Test loss: 2.259, Test accuracy: 15.69 

Round  65, Global train loss: 2.265, Global test loss: 2.256, Global test accuracy: 16.47 

Round  66, Train loss: 2.262, Test loss: 2.258, Test accuracy: 15.78 

Round  66, Global train loss: 2.262, Global test loss: 2.255, Global test accuracy: 16.62 

Round  67, Train loss: 2.264, Test loss: 2.256, Test accuracy: 16.09 

Round  67, Global train loss: 2.264, Global test loss: 2.253, Global test accuracy: 16.71 

Round  68, Train loss: 2.265, Test loss: 2.255, Test accuracy: 16.02 

Round  68, Global train loss: 2.265, Global test loss: 2.252, Global test accuracy: 16.35 

Round  69, Train loss: 2.269, Test loss: 2.254, Test accuracy: 15.94 

Round  69, Global train loss: 2.269, Global test loss: 2.251, Global test accuracy: 16.60 

Round  70, Train loss: 2.265, Test loss: 2.254, Test accuracy: 15.99 

Round  70, Global train loss: 2.265, Global test loss: 2.251, Global test accuracy: 16.26 

Round  71, Train loss: 2.261, Test loss: 2.253, Test accuracy: 16.14 

Round  71, Global train loss: 2.261, Global test loss: 2.250, Global test accuracy: 16.59 

Round  72, Train loss: 2.260, Test loss: 2.252, Test accuracy: 16.11 

Round  72, Global train loss: 2.260, Global test loss: 2.249, Global test accuracy: 16.44 

Round  73, Train loss: 2.261, Test loss: 2.251, Test accuracy: 16.36 

Round  73, Global train loss: 2.261, Global test loss: 2.247, Global test accuracy: 16.81 

Round  74, Train loss: 2.264, Test loss: 2.250, Test accuracy: 16.58 

Round  74, Global train loss: 2.264, Global test loss: 2.248, Global test accuracy: 17.45 

Round  75, Train loss: 2.256, Test loss: 2.250, Test accuracy: 16.73 

Round  75, Global train loss: 2.256, Global test loss: 2.247, Global test accuracy: 17.46 

Round  76, Train loss: 2.260, Test loss: 2.248, Test accuracy: 16.82 

Round  76, Global train loss: 2.260, Global test loss: 2.246, Global test accuracy: 17.56 

Round  77, Train loss: 2.262, Test loss: 2.247, Test accuracy: 17.04 

Round  77, Global train loss: 2.262, Global test loss: 2.245, Global test accuracy: 17.83 

Round  78, Train loss: 2.256, Test loss: 2.246, Test accuracy: 17.23 

Round  78, Global train loss: 2.256, Global test loss: 2.244, Global test accuracy: 17.73 

Round  79, Train loss: 2.256, Test loss: 2.245, Test accuracy: 17.16 

Round  79, Global train loss: 2.256, Global test loss: 2.243, Global test accuracy: 17.80 

Round  80, Train loss: 2.255, Test loss: 2.245, Test accuracy: 17.38 

Round  80, Global train loss: 2.255, Global test loss: 2.242, Global test accuracy: 18.18 

Round  81, Train loss: 2.253, Test loss: 2.244, Test accuracy: 17.65 

Round  81, Global train loss: 2.253, Global test loss: 2.240, Global test accuracy: 18.29 

Round  82, Train loss: 2.255, Test loss: 2.242, Test accuracy: 17.77 

Round  82, Global train loss: 2.255, Global test loss: 2.238, Global test accuracy: 18.37 

Round  83, Train loss: 2.256, Test loss: 2.241, Test accuracy: 17.88 

Round  83, Global train loss: 2.256, Global test loss: 2.238, Global test accuracy: 18.67 

Round  84, Train loss: 2.255, Test loss: 2.239, Test accuracy: 17.93 

Round  84, Global train loss: 2.255, Global test loss: 2.236, Global test accuracy: 18.17 

Round  85, Train loss: 2.254, Test loss: 2.238, Test accuracy: 17.87 

Round  85, Global train loss: 2.254, Global test loss: 2.234, Global test accuracy: 17.46 

Round  86, Train loss: 2.253, Test loss: 2.237, Test accuracy: 18.13 

Round  86, Global train loss: 2.253, Global test loss: 2.233, Global test accuracy: 18.05 

Round  87, Train loss: 2.252, Test loss: 2.235, Test accuracy: 18.09 

Round  87, Global train loss: 2.252, Global test loss: 2.232, Global test accuracy: 18.15 

Round  88, Train loss: 2.251, Test loss: 2.234, Test accuracy: 17.74 

Round  88, Global train loss: 2.251, Global test loss: 2.230, Global test accuracy: 17.54 

Round  89, Train loss: 2.264, Test loss: 2.232, Test accuracy: 17.58 

Round  89, Global train loss: 2.264, Global test loss: 2.229, Global test accuracy: 18.01 

Round  90, Train loss: 2.253, Test loss: 2.231, Test accuracy: 17.98 

Round  90, Global train loss: 2.253, Global test loss: 2.228, Global test accuracy: 19.12 

Round  91, Train loss: 2.252, Test loss: 2.230, Test accuracy: 17.99 

Round  91, Global train loss: 2.252, Global test loss: 2.227, Global test accuracy: 18.36 

Round  92, Train loss: 2.250, Test loss: 2.229, Test accuracy: 18.12 

Round  92, Global train loss: 2.250, Global test loss: 2.226, Global test accuracy: 18.82 

Round  93, Train loss: 2.251, Test loss: 2.229, Test accuracy: 18.24 

Round  93, Global train loss: 2.251, Global test loss: 2.225, Global test accuracy: 19.30 

Round  94, Train loss: 2.252, Test loss: 2.228, Test accuracy: 18.75 

Round  94, Global train loss: 2.252, Global test loss: 2.225, Global test accuracy: 19.74 

Round  95, Train loss: 2.245, Test loss: 2.227, Test accuracy: 19.09 

Round  95, Global train loss: 2.245, Global test loss: 2.224, Global test accuracy: 20.40 

Round  96, Train loss: 2.243, Test loss: 2.226, Test accuracy: 19.30 

Round  96, Global train loss: 2.243, Global test loss: 2.223, Global test accuracy: 20.31 

Round  97, Train loss: 2.246, Test loss: 2.225, Test accuracy: 19.35 

Round  97, Global train loss: 2.246, Global test loss: 2.222, Global test accuracy: 20.31 

Round  98, Train loss: 2.247, Test loss: 2.224, Test accuracy: 19.45 

Round  98, Global train loss: 2.247, Global test loss: 2.221, Global test accuracy: 19.96 

Round  99, Train loss: 2.244, Test loss: 2.223, Test accuracy: 19.56 

Round  99, Global train loss: 2.244, Global test loss: 2.220, Global test accuracy: 20.55 

Round 100, Train loss: 2.241, Test loss: 2.222, Test accuracy: 19.44 

Round 100, Global train loss: 2.241, Global test loss: 2.219, Global test accuracy: 20.14 

Round 101, Train loss: 2.239, Test loss: 2.221, Test accuracy: 19.45 

Round 101, Global train loss: 2.239, Global test loss: 2.217, Global test accuracy: 19.99 

Round 102, Train loss: 2.246, Test loss: 2.220, Test accuracy: 19.87 

Round 102, Global train loss: 2.246, Global test loss: 2.217, Global test accuracy: 19.78 

Round 103, Train loss: 2.242, Test loss: 2.219, Test accuracy: 20.06 

Round 103, Global train loss: 2.242, Global test loss: 2.214, Global test accuracy: 20.74 

Round 104, Train loss: 2.239, Test loss: 2.217, Test accuracy: 20.55 

Round 104, Global train loss: 2.239, Global test loss: 2.214, Global test accuracy: 21.28 

Round 105, Train loss: 2.236, Test loss: 2.216, Test accuracy: 20.86 

Round 105, Global train loss: 2.236, Global test loss: 2.212, Global test accuracy: 21.46 

Round 106, Train loss: 2.234, Test loss: 2.214, Test accuracy: 21.21 

Round 106, Global train loss: 2.234, Global test loss: 2.211, Global test accuracy: 21.69 

Round 107, Train loss: 2.231, Test loss: 2.213, Test accuracy: 21.61 

Round 107, Global train loss: 2.231, Global test loss: 2.209, Global test accuracy: 22.47 

Round 108, Train loss: 2.235, Test loss: 2.211, Test accuracy: 21.62 

Round 108, Global train loss: 2.235, Global test loss: 2.209, Global test accuracy: 22.77 

Round 109, Train loss: 2.242, Test loss: 2.210, Test accuracy: 21.47 

Round 109, Global train loss: 2.242, Global test loss: 2.208, Global test accuracy: 22.46 

Round 110, Train loss: 2.230, Test loss: 2.208, Test accuracy: 21.67 

Round 110, Global train loss: 2.230, Global test loss: 2.204, Global test accuracy: 22.34 

Round 111, Train loss: 2.227, Test loss: 2.208, Test accuracy: 21.75 

Round 111, Global train loss: 2.227, Global test loss: 2.203, Global test accuracy: 22.57 

Round 112, Train loss: 2.232, Test loss: 2.207, Test accuracy: 21.76 

Round 112, Global train loss: 2.232, Global test loss: 2.202, Global test accuracy: 23.09 

Round 113, Train loss: 2.235, Test loss: 2.206, Test accuracy: 21.60 

Round 113, Global train loss: 2.235, Global test loss: 2.201, Global test accuracy: 22.88 

Round 114, Train loss: 2.229, Test loss: 2.203, Test accuracy: 21.61 

Round 114, Global train loss: 2.229, Global test loss: 2.199, Global test accuracy: 22.29 

Round 115, Train loss: 2.236, Test loss: 2.202, Test accuracy: 21.82 

Round 115, Global train loss: 2.236, Global test loss: 2.197, Global test accuracy: 22.03 

Round 116, Train loss: 2.230, Test loss: 2.201, Test accuracy: 21.71 

Round 116, Global train loss: 2.230, Global test loss: 2.198, Global test accuracy: 23.18 

Round 117, Train loss: 2.225, Test loss: 2.201, Test accuracy: 22.11 

Round 117, Global train loss: 2.225, Global test loss: 2.198, Global test accuracy: 23.50 

Round 118, Train loss: 2.228, Test loss: 2.199, Test accuracy: 22.35 

Round 118, Global train loss: 2.228, Global test loss: 2.196, Global test accuracy: 23.11 

Round 119, Train loss: 2.229, Test loss: 2.199, Test accuracy: 22.55 

Round 119, Global train loss: 2.229, Global test loss: 2.196, Global test accuracy: 23.18 

Round 120, Train loss: 2.222, Test loss: 2.199, Test accuracy: 22.61 

Round 120, Global train loss: 2.222, Global test loss: 2.196, Global test accuracy: 23.78 

Round 121, Train loss: 2.224, Test loss: 2.197, Test accuracy: 22.71 

Round 121, Global train loss: 2.224, Global test loss: 2.192, Global test accuracy: 23.94 

Round 122, Train loss: 2.223, Test loss: 2.195, Test accuracy: 22.63 

Round 122, Global train loss: 2.223, Global test loss: 2.191, Global test accuracy: 24.07 

Round 123, Train loss: 2.223, Test loss: 2.193, Test accuracy: 23.00 

Round 123, Global train loss: 2.223, Global test loss: 2.189, Global test accuracy: 23.98 

Round 124, Train loss: 2.222, Test loss: 2.193, Test accuracy: 23.00 

Round 124, Global train loss: 2.222, Global test loss: 2.188, Global test accuracy: 23.09 

Round 125, Train loss: 2.227, Test loss: 2.191, Test accuracy: 23.16 

Round 125, Global train loss: 2.227, Global test loss: 2.189, Global test accuracy: 23.75 

Round 126, Train loss: 2.224, Test loss: 2.189, Test accuracy: 23.39 

Round 126, Global train loss: 2.224, Global test loss: 2.186, Global test accuracy: 23.88 

Round 127, Train loss: 2.225, Test loss: 2.188, Test accuracy: 23.24 

Round 127, Global train loss: 2.225, Global test loss: 2.183, Global test accuracy: 23.93 

Round 128, Train loss: 2.221, Test loss: 2.187, Test accuracy: 23.16 

Round 128, Global train loss: 2.221, Global test loss: 2.183, Global test accuracy: 23.34 

Round 129, Train loss: 2.223, Test loss: 2.186, Test accuracy: 23.09 

Round 129, Global train loss: 2.223, Global test loss: 2.183, Global test accuracy: 23.50 

Round 130, Train loss: 2.215, Test loss: 2.186, Test accuracy: 23.38 

Round 130, Global train loss: 2.215, Global test loss: 2.181, Global test accuracy: 24.32 

Round 131, Train loss: 2.224, Test loss: 2.184, Test accuracy: 23.24 

Round 131, Global train loss: 2.224, Global test loss: 2.177, Global test accuracy: 24.13 

Round 132, Train loss: 2.217, Test loss: 2.180, Test accuracy: 23.49 

Round 132, Global train loss: 2.217, Global test loss: 2.175, Global test accuracy: 23.86 

Round 133, Train loss: 2.220, Test loss: 2.180, Test accuracy: 23.75 

Round 133, Global train loss: 2.220, Global test loss: 2.177, Global test accuracy: 25.23 

Round 134, Train loss: 2.217, Test loss: 2.180, Test accuracy: 24.09 

Round 134, Global train loss: 2.217, Global test loss: 2.181, Global test accuracy: 25.22 

Round 135, Train loss: 2.213, Test loss: 2.181, Test accuracy: 24.12 

Round 135, Global train loss: 2.213, Global test loss: 2.179, Global test accuracy: 24.98 

Round 136, Train loss: 2.214, Test loss: 2.180, Test accuracy: 24.05 

Round 136, Global train loss: 2.214, Global test loss: 2.180, Global test accuracy: 24.17 

Round 137, Train loss: 2.211, Test loss: 2.179, Test accuracy: 23.87 

Round 137, Global train loss: 2.211, Global test loss: 2.177, Global test accuracy: 23.75 

Round 138, Train loss: 2.214, Test loss: 2.177, Test accuracy: 23.85 

Round 138, Global train loss: 2.214, Global test loss: 2.175, Global test accuracy: 24.09 

Round 139, Train loss: 2.209, Test loss: 2.176, Test accuracy: 23.94 

Round 139, Global train loss: 2.209, Global test loss: 2.171, Global test accuracy: 24.09 

Round 140, Train loss: 2.212, Test loss: 2.175, Test accuracy: 23.75 

Round 140, Global train loss: 2.212, Global test loss: 2.171, Global test accuracy: 24.12 

Round 141, Train loss: 2.203, Test loss: 2.175, Test accuracy: 23.80 

Round 141, Global train loss: 2.203, Global test loss: 2.170, Global test accuracy: 24.29 

Round 142, Train loss: 2.210, Test loss: 2.175, Test accuracy: 23.73 

Round 142, Global train loss: 2.210, Global test loss: 2.173, Global test accuracy: 24.32 

Round 143, Train loss: 2.213, Test loss: 2.174, Test accuracy: 23.44 

Round 143, Global train loss: 2.213, Global test loss: 2.172, Global test accuracy: 23.88 

Round 144, Train loss: 2.205, Test loss: 2.173, Test accuracy: 23.47 

Round 144, Global train loss: 2.205, Global test loss: 2.170, Global test accuracy: 24.19 

Round 145, Train loss: 2.201, Test loss: 2.173, Test accuracy: 23.63 

Round 145, Global train loss: 2.201, Global test loss: 2.167, Global test accuracy: 24.95 

Round 146, Train loss: 2.205, Test loss: 2.171, Test accuracy: 23.91 

Round 146, Global train loss: 2.205, Global test loss: 2.167, Global test accuracy: 24.73 

Round 147, Train loss: 2.205, Test loss: 2.169, Test accuracy: 24.02 

Round 147, Global train loss: 2.205, Global test loss: 2.165, Global test accuracy: 24.85 

Round 148, Train loss: 2.204, Test loss: 2.166, Test accuracy: 24.06 

Round 148, Global train loss: 2.204, Global test loss: 2.159, Global test accuracy: 25.16 

Round 149, Train loss: 2.209, Test loss: 2.165, Test accuracy: 24.04 

Round 149, Global train loss: 2.209, Global test loss: 2.160, Global test accuracy: 24.66 

Round 150, Train loss: 2.208, Test loss: 2.163, Test accuracy: 24.07 

Round 150, Global train loss: 2.208, Global test loss: 2.159, Global test accuracy: 24.85 

Round 151, Train loss: 2.207, Test loss: 2.161, Test accuracy: 24.05 

Round 151, Global train loss: 2.207, Global test loss: 2.156, Global test accuracy: 25.03 

Round 152, Train loss: 2.208, Test loss: 2.160, Test accuracy: 24.09 

Round 152, Global train loss: 2.208, Global test loss: 2.160, Global test accuracy: 25.23 

Round 153, Train loss: 2.196, Test loss: 2.160, Test accuracy: 24.13 

Round 153, Global train loss: 2.196, Global test loss: 2.158, Global test accuracy: 24.64 

Round 154, Train loss: 2.199, Test loss: 2.159, Test accuracy: 23.75 

Round 154, Global train loss: 2.199, Global test loss: 2.154, Global test accuracy: 24.03 

Round 155, Train loss: 2.203, Test loss: 2.157, Test accuracy: 23.92 

Round 155, Global train loss: 2.203, Global test loss: 2.152, Global test accuracy: 24.09 

Round 156, Train loss: 2.208, Test loss: 2.157, Test accuracy: 23.98 

Round 156, Global train loss: 2.208, Global test loss: 2.154, Global test accuracy: 24.02 

Round 157, Train loss: 2.208, Test loss: 2.155, Test accuracy: 24.05 

Round 157, Global train loss: 2.208, Global test loss: 2.150, Global test accuracy: 24.45 

Round 158, Train loss: 2.203, Test loss: 2.152, Test accuracy: 23.98 

Round 158, Global train loss: 2.203, Global test loss: 2.147, Global test accuracy: 25.00 

Round 159, Train loss: nan, Test loss: nan, Test accuracy: 22.90 

Round 159, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 160, Train loss: nan, Test loss: nan, Test accuracy: 19.01 

Round 160, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 161, Train loss: nan, Test loss: nan, Test accuracy: 16.34 

Round 161, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 162, Train loss: nan, Test loss: nan, Test accuracy: 13.69 

Round 162, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 163, Train loss: nan, Test loss: nan, Test accuracy: 13.69 

Round 163, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 164, Train loss: nan, Test loss: nan, Test accuracy: 12.29 

Round 164, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 165, Train loss: nan, Test loss: nan, Test accuracy: 11.44 

Round 165, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 166, Train loss: nan, Test loss: nan, Test accuracy: 11.44 

Round 166, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 167, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 167, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 168, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 168, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 169, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 169, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 170, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 170, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 171, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 171, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 172, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 172, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 173, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 173, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 174, Train loss: nan, Test loss: nan, Test accuracy: 10.73 

Round 174, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 175, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 175, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 176, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 176, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 177, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 177, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 178, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 178, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 179, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 179, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 180, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 180, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 181, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 181, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 182, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 182, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 183, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 183, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 184, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 184, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 185, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 185, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 186, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 186, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 187, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 187, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 188, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 188, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 189, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 189, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 190, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 190, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Average accuracy final 10 rounds: 10.0 

Average global accuracy final 10 rounds: 10.0 

10950.268898248672
[1.4786860942840576, 2.605346441268921, 3.7116169929504395, 4.8179848194122314, 5.924561023712158, 7.02874755859375, 8.131888151168823, 9.234551191329956, 10.338961362838745, 11.444447755813599, 12.54892349243164, 13.65371036529541, 14.75742244720459, 15.860095977783203, 16.963695764541626, 18.066390991210938, 19.172324895858765, 20.275205373764038, 21.377315044403076, 22.47869300842285, 23.59335160255432, 24.851970434188843, 26.11813235282898, 27.378172636032104, 28.638445377349854, 29.898725748062134, 31.160592317581177, 32.4213502407074, 33.68340253829956, 34.94504737854004, 36.20384216308594, 37.46630859375, 38.732747316360474, 39.993647813797, 41.25718688964844, 42.519760847091675, 43.78690195083618, 45.04848766326904, 46.31443786621094, 47.5706844329834, 48.83401036262512, 50.09205889701843, 51.35149693489075, 52.613980531692505, 53.87776041030884, 55.14086198806763, 56.399763345718384, 57.66142463684082, 58.92580199241638, 60.19121813774109, 61.45318388938904, 62.564826011657715, 63.670233726501465, 64.78696155548096, 65.89549374580383, 67.0127923488617, 68.12018036842346, 69.22595477104187, 70.33404874801636, 71.44399237632751, 72.54788208007812, 73.6500883102417, 74.75315427780151, 75.85880446434021, 76.96708536148071, 78.07691812515259, 79.18553495407104, 80.29228115081787, 81.39326906204224, 82.50748419761658, 83.61387825012207, 84.7215507030487, 85.83036708831787, 86.93879175186157, 88.05379867553711, 89.16078543663025, 90.28090953826904, 91.39193153381348, 92.50153923034668, 93.60146236419678, 94.70305848121643, 95.8147132396698, 96.91985750198364, 98.02496671676636, 99.1267511844635, 100.2288146018982, 101.33633351325989, 102.44823718070984, 103.56670880317688, 104.66792058944702, 105.78586840629578, 106.89612126350403, 108.00498342514038, 109.11490654945374, 110.22295761108398, 111.32512545585632, 112.4313235282898, 113.5500545501709, 114.65849685668945, 115.76861548423767, 116.87816762924194, 117.986492395401, 119.1062581539154, 120.21295881271362, 121.33117914199829, 122.43972396850586, 123.54843473434448, 124.65780425071716, 125.76871800422668, 126.88616871833801, 127.9955415725708, 129.1119351387024, 130.22246313095093, 131.3335781097412, 132.442702293396, 133.550395488739, 134.67078304290771, 135.77905702590942, 136.88104605674744, 137.98824095726013, 139.09850931167603, 140.20882296562195, 141.32051706314087, 142.44066214561462, 143.55033373832703, 144.65762853622437, 145.75867247581482, 146.86202573776245, 147.9658966064453, 149.0676555633545, 150.17843437194824, 151.28180074691772, 152.38331151008606, 153.4860405921936, 154.58948755264282, 155.6910011768341, 156.7928431034088, 157.89694094657898, 158.99707293510437, 160.09906148910522, 161.19894552230835, 162.30121421813965, 163.40178442001343, 164.50453209877014, 165.60825443267822, 166.7114052772522, 167.81375885009766, 168.916978597641, 170.0211226940155, 171.12380385398865, 172.22488927841187, 173.32877492904663, 174.42963933944702, 175.53267192840576, 176.63314414024353, 177.7347333431244, 178.83511352539062, 179.93585848808289, 181.0373044013977, 182.1377124786377, 183.23819279670715, 184.3373465538025, 185.43785429000854, 186.54382348060608, 187.6493604183197, 188.78351426124573, 189.92570424079895, 191.04902982711792, 192.18448567390442, 193.3064579963684, 194.44131112098694, 195.5714886188507, 196.70132660865784, 197.834641456604, 198.96557068824768, 200.09541940689087, 201.22007846832275, 202.35134887695312, 203.47664618492126, 204.60404682159424, 205.70472240447998, 206.80735445022583, 207.90746998786926, 209.0084102153778, 210.12315106391907, 211.2296702861786, 212.34873247146606, 213.44953751564026, 214.55352234840393, 215.65873908996582, 216.7593080997467, 217.86749505996704, 218.97109580039978, 220.07634258270264, 221.18115186691284, 222.28337836265564, 223.3877866268158, 224.4922375679016, 225.59341096878052, 226.69359612464905, 227.80098414421082, 228.91301608085632, 230.02294635772705, 231.1265013217926, 232.23534154891968, 233.34016919136047, 234.44044542312622, 235.82847428321838, 237.08684062957764, 238.20404386520386, 239.30391263961792, 240.4055097103119, 241.50477623939514, 242.62777018547058, 243.726957321167, 244.82785367965698, 245.93057107925415, 247.0448501110077, 248.14367175102234, 249.33923506736755, 250.43550777435303, 251.53161787986755, 252.92935848236084, 254.33989119529724, 255.71142387390137, 257.01854276657104, 258.40867376327515, 259.8248281478882, 261.2397072315216, 262.5910630226135, 263.9862976074219, 265.3281364440918, 266.7274577617645, 268.0053017139435, 269.418331861496, 270.8284921646118, 272.25696778297424, 273.6278409957886, 275.03055238723755, 276.4271125793457, 277.82600450515747, 279.23360109329224, 280.65582966804504, 281.98488187789917, 283.37287759780884, 284.7637252807617, 286.1379120349884, 287.55823040008545, 288.89498114585876, 290.22141885757446, 291.57551646232605, 292.9214677810669, 294.1800501346588, 295.5149359703064, 296.853627204895, 298.0427451133728, 299.248060464859, 300.4452941417694, 301.7732856273651, 303.0594234466553, 304.3384006023407, 305.6510434150696, 306.965784072876, 308.1306619644165, 309.4465403556824, 310.75800681114197, 311.90514969825745, 313.11203813552856, 314.29802560806274, 315.47431778907776, 316.87964272499084, 318.2029986381531, 319.43332624435425, 320.6427638530731, 321.8710947036743, 323.0775411128998, 324.40342593193054, 325.737496137619, 327.0635914802551, 328.4189946651459, 329.767769575119, 331.1063144207001, 332.4530849456787, 333.79394602775574, 335.1396882534027, 336.4817078113556, 337.8335943222046, 339.1837649345398, 340.53893780708313, 341.87062191963196, 343.1867787837982, 344.38250708580017, 345.5696539878845, 346.7760889530182, 348.0090289115906, 349.2002377510071, 350.4029805660248, 351.588826417923, 352.7849450111389, 353.965523481369, 356.2954866886139]
[10.578333333333333, 10.71, 10.941666666666666, 11.241666666666667, 11.603333333333333, 11.93, 12.105, 12.211666666666666, 12.558333333333334, 12.773333333333333, 12.971666666666666, 13.333333333333334, 13.586666666666666, 13.583333333333334, 13.728333333333333, 14.235, 14.538333333333334, 14.633333333333333, 14.806666666666667, 14.966666666666667, 15.351666666666667, 15.536666666666667, 15.61, 15.646666666666667, 15.795, 15.723333333333333, 15.816666666666666, 15.653333333333334, 15.643333333333333, 15.653333333333334, 15.581666666666667, 15.686666666666667, 15.761666666666667, 15.706666666666667, 15.693333333333333, 15.695, 15.705, 15.826666666666666, 15.835, 15.981666666666667, 16.026666666666667, 16.086666666666666, 16.026666666666667, 16.141666666666666, 16.253333333333334, 16.31, 16.30666666666667, 16.418333333333333, 16.265, 16.18166666666667, 16.153333333333332, 16.283333333333335, 16.281666666666666, 16.501666666666665, 16.386666666666667, 16.323333333333334, 16.29, 16.121666666666666, 16.075, 15.918333333333333, 15.87, 15.935, 16.0, 16.113333333333333, 15.803333333333333, 15.688333333333333, 15.775, 16.093333333333334, 16.023333333333333, 15.938333333333333, 15.991666666666667, 16.135, 16.11, 16.361666666666668, 16.581666666666667, 16.73, 16.82, 17.035, 17.233333333333334, 17.161666666666665, 17.376666666666665, 17.651666666666667, 17.775, 17.881666666666668, 17.93, 17.866666666666667, 18.13, 18.085, 17.741666666666667, 17.583333333333332, 17.985, 17.988333333333333, 18.116666666666667, 18.24, 18.753333333333334, 19.09, 19.3, 19.346666666666668, 19.451666666666668, 19.563333333333333, 19.436666666666667, 19.455, 19.868333333333332, 20.05666666666667, 20.553333333333335, 20.856666666666666, 21.206666666666667, 21.608333333333334, 21.616666666666667, 21.47, 21.668333333333333, 21.748333333333335, 21.761666666666667, 21.601666666666667, 21.613333333333333, 21.823333333333334, 21.713333333333335, 22.11, 22.35333333333333, 22.55, 22.605, 22.706666666666667, 22.631666666666668, 22.995, 22.996666666666666, 23.165, 23.388333333333332, 23.236666666666668, 23.163333333333334, 23.086666666666666, 23.375, 23.241666666666667, 23.491666666666667, 23.753333333333334, 24.088333333333335, 24.118333333333332, 24.05, 23.87, 23.846666666666668, 23.938333333333333, 23.745, 23.803333333333335, 23.735, 23.44, 23.47, 23.626666666666665, 23.905, 24.016666666666666, 24.05666666666667, 24.038333333333334, 24.071666666666665, 24.053333333333335, 24.095, 24.131666666666668, 23.751666666666665, 23.918333333333333, 23.976666666666667, 24.05, 23.981666666666666, 22.898333333333333, 19.013333333333332, 16.336666666666666, 13.691666666666666, 13.691666666666666, 12.293333333333333, 11.435, 11.435, 10.733333333333333, 10.733333333333333, 10.733333333333333, 10.733333333333333, 10.733333333333333, 10.733333333333333, 10.733333333333333, 10.733333333333333, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.226, Test loss: 2.091, Test accuracy: 23.52 

Round   0, Global train loss: 2.226, Global test loss: 2.095, Global test accuracy: 23.88 

Round   1, Train loss: 2.002, Test loss: 1.993, Test accuracy: 26.00 

Round   1, Global train loss: 2.002, Global test loss: 1.953, Global test accuracy: 27.24 

Round   2, Train loss: 1.880, Test loss: 1.878, Test accuracy: 30.18 

Round   2, Global train loss: 1.880, Global test loss: 1.797, Global test accuracy: 32.83 

Round   3, Train loss: 1.784, Test loss: 1.832, Test accuracy: 32.13 

Round   3, Global train loss: 1.784, Global test loss: 1.705, Global test accuracy: 37.20 

Round   4, Train loss: 1.692, Test loss: 1.770, Test accuracy: 34.64 

Round   4, Global train loss: 1.692, Global test loss: 1.655, Global test accuracy: 38.55 

Round   5, Train loss: 1.637, Test loss: 1.708, Test accuracy: 37.34 

Round   5, Global train loss: 1.637, Global test loss: 1.594, Global test accuracy: 41.77 

Round   6, Train loss: 1.586, Test loss: 1.672, Test accuracy: 38.90 

Round   6, Global train loss: 1.586, Global test loss: 1.563, Global test accuracy: 42.85 

Round   7, Train loss: 1.574, Test loss: 1.649, Test accuracy: 40.02 

Round   7, Global train loss: 1.574, Global test loss: 1.533, Global test accuracy: 43.30 

Round   8, Train loss: 1.520, Test loss: 1.626, Test accuracy: 40.70 

Round   8, Global train loss: 1.520, Global test loss: 1.507, Global test accuracy: 45.12 

Round   9, Train loss: 1.477, Test loss: 1.600, Test accuracy: 41.69 

Round   9, Global train loss: 1.477, Global test loss: 1.496, Global test accuracy: 45.05 

Round  10, Train loss: 1.442, Test loss: 1.592, Test accuracy: 42.48 

Round  10, Global train loss: 1.442, Global test loss: 1.495, Global test accuracy: 47.61 

Round  11, Train loss: 1.425, Test loss: 1.564, Test accuracy: 43.70 

Round  11, Global train loss: 1.425, Global test loss: 1.415, Global test accuracy: 49.55 

Round  12, Train loss: 1.379, Test loss: 1.539, Test accuracy: 44.76 

Round  12, Global train loss: 1.379, Global test loss: 1.435, Global test accuracy: 49.91 

Round  13, Train loss: 1.377, Test loss: 1.524, Test accuracy: 45.72 

Round  13, Global train loss: 1.377, Global test loss: 1.384, Global test accuracy: 51.53 

Round  14, Train loss: 1.317, Test loss: 1.510, Test accuracy: 46.52 

Round  14, Global train loss: 1.317, Global test loss: 1.372, Global test accuracy: 49.52 

Round  15, Train loss: 1.299, Test loss: 1.499, Test accuracy: 47.19 

Round  15, Global train loss: 1.299, Global test loss: 1.340, Global test accuracy: 50.83 

Round  16, Train loss: 1.283, Test loss: 1.478, Test accuracy: 48.20 

Round  16, Global train loss: 1.283, Global test loss: 1.326, Global test accuracy: 51.16 

Round  17, Train loss: 1.230, Test loss: 1.459, Test accuracy: 48.83 

Round  17, Global train loss: 1.230, Global test loss: 1.325, Global test accuracy: 54.52 

Round  18, Train loss: 1.190, Test loss: 1.461, Test accuracy: 48.87 

Round  18, Global train loss: 1.190, Global test loss: 1.298, Global test accuracy: 53.82 

Round  19, Train loss: 1.201, Test loss: 1.447, Test accuracy: 49.76 

Round  19, Global train loss: 1.201, Global test loss: 1.255, Global test accuracy: 55.70 

Round  20, Train loss: 1.131, Test loss: 1.444, Test accuracy: 50.02 

Round  20, Global train loss: 1.131, Global test loss: 1.280, Global test accuracy: 53.48 

Round  21, Train loss: 1.132, Test loss: 1.439, Test accuracy: 50.26 

Round  21, Global train loss: 1.132, Global test loss: 1.285, Global test accuracy: 56.24 

Round  22, Train loss: 1.120, Test loss: 1.417, Test accuracy: 51.05 

Round  22, Global train loss: 1.120, Global test loss: 1.241, Global test accuracy: 55.95 

Round  23, Train loss: 1.075, Test loss: 1.428, Test accuracy: 50.99 

Round  23, Global train loss: 1.075, Global test loss: 1.251, Global test accuracy: 55.92 

Round  24, Train loss: 1.071, Test loss: 1.426, Test accuracy: 51.54 

Round  24, Global train loss: 1.071, Global test loss: 1.249, Global test accuracy: 57.45 

Round  25, Train loss: 1.054, Test loss: 1.402, Test accuracy: 52.42 

Round  25, Global train loss: 1.054, Global test loss: 1.238, Global test accuracy: 55.47 

Round  26, Train loss: 1.010, Test loss: 1.403, Test accuracy: 52.75 

Round  26, Global train loss: 1.010, Global test loss: 1.291, Global test accuracy: 57.85 

Round  27, Train loss: 0.974, Test loss: 1.398, Test accuracy: 52.86 

Round  27, Global train loss: 0.974, Global test loss: 1.293, Global test accuracy: 57.49 

Round  28, Train loss: 1.006, Test loss: 1.369, Test accuracy: 54.22 

Round  28, Global train loss: 1.006, Global test loss: 1.265, Global test accuracy: 58.16 

Round  29, Train loss: 0.983, Test loss: 1.376, Test accuracy: 54.21 

Round  29, Global train loss: 0.983, Global test loss: 1.210, Global test accuracy: 58.35 

Round  30, Train loss: 0.955, Test loss: 1.376, Test accuracy: 54.48 

Round  30, Global train loss: 0.955, Global test loss: 1.226, Global test accuracy: 57.66 

Round  31, Train loss: 0.919, Test loss: 1.379, Test accuracy: 54.63 

Round  31, Global train loss: 0.919, Global test loss: 1.276, Global test accuracy: 58.88 

Round  32, Train loss: 0.909, Test loss: 1.369, Test accuracy: 55.17 

Round  32, Global train loss: 0.909, Global test loss: 1.260, Global test accuracy: 58.93 

Round  33, Train loss: 0.882, Test loss: 1.385, Test accuracy: 55.05 

Round  33, Global train loss: 0.882, Global test loss: 1.282, Global test accuracy: 59.23 

Round  34, Train loss: 0.921, Test loss: 1.398, Test accuracy: 54.91 

Round  34, Global train loss: 0.921, Global test loss: 1.193, Global test accuracy: 57.09 

Round  35, Train loss: 0.897, Test loss: 1.400, Test accuracy: 55.20 

Round  35, Global train loss: 0.897, Global test loss: 1.195, Global test accuracy: 58.58 

Round  36, Train loss: 0.867, Test loss: 1.395, Test accuracy: 55.40 

Round  36, Global train loss: 0.867, Global test loss: 1.185, Global test accuracy: 59.93 

Round  37, Train loss: 0.794, Test loss: 1.393, Test accuracy: 55.63 

Round  37, Global train loss: 0.794, Global test loss: 1.200, Global test accuracy: 59.68 

Round  38, Train loss: 0.824, Test loss: 1.400, Test accuracy: 55.87 

Round  38, Global train loss: 0.824, Global test loss: 1.275, Global test accuracy: 59.90 

Round  39, Train loss: 0.836, Test loss: 1.394, Test accuracy: 56.22 

Round  39, Global train loss: 0.836, Global test loss: 1.292, Global test accuracy: 55.77 

Round  40, Train loss: 0.864, Test loss: 1.394, Test accuracy: 56.41 

Round  40, Global train loss: 0.864, Global test loss: 1.184, Global test accuracy: 59.87 

Round  41, Train loss: 0.755, Test loss: 1.391, Test accuracy: 56.62 

Round  41, Global train loss: 0.755, Global test loss: 1.235, Global test accuracy: 60.68 

Round  42, Train loss: 0.754, Test loss: 1.399, Test accuracy: 56.81 

Round  42, Global train loss: 0.754, Global test loss: 1.242, Global test accuracy: 57.25 

Round  43, Train loss: 0.797, Test loss: 1.399, Test accuracy: 57.16 

Round  43, Global train loss: 0.797, Global test loss: 1.197, Global test accuracy: 60.08 

Round  44, Train loss: 0.719, Test loss: 1.401, Test accuracy: 57.42 

Round  44, Global train loss: 0.719, Global test loss: 1.206, Global test accuracy: 60.84 

Round  45, Train loss: 0.777, Test loss: 1.392, Test accuracy: 57.59 

Round  45, Global train loss: 0.777, Global test loss: 1.189, Global test accuracy: 59.05 

Round  46, Train loss: 0.693, Test loss: 1.384, Test accuracy: 57.92 

Round  46, Global train loss: 0.693, Global test loss: 1.237, Global test accuracy: 58.08 

Round  47, Train loss: 0.722, Test loss: 1.381, Test accuracy: 58.05 

Round  47, Global train loss: 0.722, Global test loss: 1.247, Global test accuracy: 57.20 

Round  48, Train loss: 0.760, Test loss: 1.375, Test accuracy: 58.17 

Round  48, Global train loss: 0.760, Global test loss: 1.239, Global test accuracy: 60.71 

Round  49, Train loss: 0.710, Test loss: 1.391, Test accuracy: 58.23 

Round  49, Global train loss: 0.710, Global test loss: 1.323, Global test accuracy: 60.69 

Round  50, Train loss: 0.672, Test loss: 1.404, Test accuracy: 58.08 

Round  50, Global train loss: 0.672, Global test loss: 1.241, Global test accuracy: 60.45 

Round  51, Train loss: 0.660, Test loss: 1.410, Test accuracy: 58.34 

Round  51, Global train loss: 0.660, Global test loss: 1.326, Global test accuracy: 60.72 

Round  52, Train loss: 0.791, Test loss: 1.424, Test accuracy: 58.26 

Round  52, Global train loss: 0.791, Global test loss: 1.228, Global test accuracy: 57.61 

Round  53, Train loss: 0.636, Test loss: 1.427, Test accuracy: 58.30 

Round  53, Global train loss: 0.636, Global test loss: 1.245, Global test accuracy: 58.16 

Round  54, Train loss: 0.697, Test loss: 1.434, Test accuracy: 58.34 

Round  54, Global train loss: 0.697, Global test loss: 1.222, Global test accuracy: 58.70 

Round  55, Train loss: 0.637, Test loss: 1.437, Test accuracy: 58.31 

Round  55, Global train loss: 0.637, Global test loss: 1.233, Global test accuracy: 59.76 

Round  56, Train loss: 0.720, Test loss: 1.442, Test accuracy: 58.52 

Round  56, Global train loss: 0.720, Global test loss: 1.253, Global test accuracy: 62.11 

Round  57, Train loss: 0.613, Test loss: 1.430, Test accuracy: 58.51 

Round  57, Global train loss: 0.613, Global test loss: 1.242, Global test accuracy: 60.72 

Round  58, Train loss: 0.580, Test loss: 1.433, Test accuracy: 58.65 

Round  58, Global train loss: 0.580, Global test loss: 1.440, Global test accuracy: 61.59 

Round  59, Train loss: 0.649, Test loss: 1.442, Test accuracy: 58.78 

Round  59, Global train loss: 0.649, Global test loss: 1.405, Global test accuracy: 61.58 

Round  60, Train loss: 0.621, Test loss: 1.444, Test accuracy: 58.83 

Round  60, Global train loss: 0.621, Global test loss: 1.325, Global test accuracy: 61.86 

Round  61, Train loss: 0.663, Test loss: 1.442, Test accuracy: 59.09 

Round  61, Global train loss: 0.663, Global test loss: 1.228, Global test accuracy: 59.37 

Round  62, Train loss: 0.580, Test loss: 1.441, Test accuracy: 59.37 

Round  62, Global train loss: 0.580, Global test loss: 1.290, Global test accuracy: 62.00 

Round  63, Train loss: 0.614, Test loss: 1.437, Test accuracy: 59.56 

Round  63, Global train loss: 0.614, Global test loss: 1.334, Global test accuracy: 61.57 

Round  64, Train loss: 0.554, Test loss: 1.442, Test accuracy: 59.62 

Round  64, Global train loss: 0.554, Global test loss: 1.357, Global test accuracy: 62.00 

Round  65, Train loss: 0.606, Test loss: 1.468, Test accuracy: 59.19 

Round  65, Global train loss: 0.606, Global test loss: 1.277, Global test accuracy: 61.73 

Round  66, Train loss: 0.567, Test loss: 1.480, Test accuracy: 59.23 

Round  66, Global train loss: 0.567, Global test loss: 1.271, Global test accuracy: 60.45 

Round  67, Train loss: 0.542, Test loss: 1.485, Test accuracy: 59.32 

Round  67, Global train loss: 0.542, Global test loss: 1.294, Global test accuracy: 62.14 

Round  68, Train loss: 0.634, Test loss: 1.488, Test accuracy: 59.60 

Round  68, Global train loss: 0.634, Global test loss: 1.221, Global test accuracy: 61.45 

Round  69, Train loss: 0.522, Test loss: 1.487, Test accuracy: 59.74 

Round  69, Global train loss: 0.522, Global test loss: 1.245, Global test accuracy: 61.85 

Round  70, Train loss: 0.561, Test loss: 1.498, Test accuracy: 59.65 

Round  70, Global train loss: 0.561, Global test loss: 1.260, Global test accuracy: 61.65 

Round  71, Train loss: 0.555, Test loss: 1.499, Test accuracy: 59.95 

Round  71, Global train loss: 0.555, Global test loss: 1.439, Global test accuracy: 62.73 

Round  72, Train loss: 0.594, Test loss: 1.493, Test accuracy: 59.84 

Round  72, Global train loss: 0.594, Global test loss: 1.398, Global test accuracy: 57.08 

Round  73, Train loss: 0.564, Test loss: 1.480, Test accuracy: 60.16 

Round  73, Global train loss: 0.564, Global test loss: 1.252, Global test accuracy: 60.49 

Round  74, Train loss: 0.553, Test loss: 1.462, Test accuracy: 60.34 

Round  74, Global train loss: 0.553, Global test loss: 1.414, Global test accuracy: 62.40 

Round  75, Train loss: 0.526, Test loss: 1.463, Test accuracy: 60.59 

Round  75, Global train loss: 0.526, Global test loss: 1.273, Global test accuracy: 61.97 

Round  76, Train loss: 0.512, Test loss: 1.469, Test accuracy: 60.65 

Round  76, Global train loss: 0.512, Global test loss: 1.497, Global test accuracy: 62.26 

Round  77, Train loss: 0.480, Test loss: 1.471, Test accuracy: 60.56 

Round  77, Global train loss: 0.480, Global test loss: 1.420, Global test accuracy: 62.09 

Round  78, Train loss: 0.561, Test loss: 1.475, Test accuracy: 60.69 

Round  78, Global train loss: 0.561, Global test loss: 1.246, Global test accuracy: 62.07 

Round  79, Train loss: 0.530, Test loss: 1.469, Test accuracy: 60.88 

Round  79, Global train loss: 0.530, Global test loss: 1.249, Global test accuracy: 62.16 

Round  80, Train loss: 0.535, Test loss: 1.499, Test accuracy: 60.37 

Round  80, Global train loss: 0.535, Global test loss: 1.252, Global test accuracy: 61.82 

Round  81, Train loss: 0.487, Test loss: 1.494, Test accuracy: 60.44 

Round  81, Global train loss: 0.487, Global test loss: 1.492, Global test accuracy: 57.81 

Round  82, Train loss: 0.494, Test loss: 1.493, Test accuracy: 60.45 

Round  82, Global train loss: 0.494, Global test loss: 1.306, Global test accuracy: 61.66 

Round  83, Train loss: 0.470, Test loss: 1.502, Test accuracy: 60.72 

Round  83, Global train loss: 0.470, Global test loss: 1.331, Global test accuracy: 58.62 

Round  84, Train loss: 0.521, Test loss: 1.521, Test accuracy: 60.64 

Round  84, Global train loss: 0.521, Global test loss: 1.298, Global test accuracy: 59.71 

Round  85, Train loss: 0.499, Test loss: 1.527, Test accuracy: 60.66 

Round  85, Global train loss: 0.499, Global test loss: 1.380, Global test accuracy: 62.91 

Round  86, Train loss: 0.513, Test loss: 1.521, Test accuracy: 60.91 

Round  86, Global train loss: 0.513, Global test loss: 1.279, Global test accuracy: 62.41 

Round  87, Train loss: 0.440, Test loss: 1.549, Test accuracy: 60.68 

Round  87, Global train loss: 0.440, Global test loss: 1.287, Global test accuracy: 62.25 

Round  88, Train loss: 0.527, Test loss: 1.545, Test accuracy: 60.76 

Round  88, Global train loss: 0.527, Global test loss: 1.338, Global test accuracy: 62.81 

Round  89, Train loss: 0.458, Test loss: 1.548, Test accuracy: 60.70 

Round  89, Global train loss: 0.458, Global test loss: 1.315, Global test accuracy: 60.62 

Round  90, Train loss: 0.467, Test loss: 1.549, Test accuracy: 60.69 

Round  90, Global train loss: 0.467, Global test loss: 1.344, Global test accuracy: 60.02 

Round  91, Train loss: 0.516, Test loss: 1.546, Test accuracy: 60.41 

Round  91, Global train loss: 0.516, Global test loss: 1.281, Global test accuracy: 62.31 

Round  92, Train loss: 0.473, Test loss: 1.550, Test accuracy: 60.44 

Round  92, Global train loss: 0.473, Global test loss: 1.318, Global test accuracy: 61.94 

Round  93, Train loss: 0.468, Test loss: 1.553, Test accuracy: 60.42 

Round  93, Global train loss: 0.468, Global test loss: 1.310, Global test accuracy: 62.68 

Round  94, Train loss: 0.480, Test loss: 1.529, Test accuracy: 60.81 

Round  94, Global train loss: 0.480, Global test loss: 1.273, Global test accuracy: 62.92 

Round  95, Train loss: 0.475, Test loss: 1.525, Test accuracy: 61.02 

Round  95, Global train loss: 0.475, Global test loss: 1.274, Global test accuracy: 60.86 

Round  96, Train loss: 0.459, Test loss: 1.532, Test accuracy: 60.98 

Round  96, Global train loss: 0.459, Global test loss: 1.360, Global test accuracy: 59.23 

Round  97, Train loss: 0.457, Test loss: 1.535, Test accuracy: 61.32 

Round  97, Global train loss: 0.457, Global test loss: 1.329, Global test accuracy: 62.01 

Round  98, Train loss: 0.440, Test loss: 1.539, Test accuracy: 61.42 

Round  98, Global train loss: 0.440, Global test loss: 1.327, Global test accuracy: 62.76 

Round  99, Train loss: 0.482, Test loss: 1.544, Test accuracy: 61.52 

Round  99, Global train loss: 0.482, Global test loss: 1.509, Global test accuracy: 63.21 

Final Round, Train loss: 0.347, Test loss: 1.763, Test accuracy: 60.71 

Final Round, Global train loss: 0.347, Global test loss: 1.509, Global test accuracy: 63.21 

Average accuracy final 10 rounds: 60.902499999999996 

Average global accuracy final 10 rounds: 61.794250000000005 

2937.5333919525146
[1.4262800216674805, 2.641301393508911, 3.8673770427703857, 5.08941388130188, 6.307087421417236, 7.512232065200806, 8.713381290435791, 9.91672158241272, 11.122952461242676, 12.323667049407959, 13.537535667419434, 14.600226640701294, 15.66067624092102, 16.726064920425415, 17.800461053848267, 18.865440368652344, 19.926589488983154, 21.0020751953125, 22.05251955986023, 23.130246877670288, 24.196736812591553, 25.413352489471436, 26.62806487083435, 27.838654279708862, 28.894296646118164, 29.96074914932251, 31.036415815353394, 32.096360206604004, 33.18210220336914, 34.24814772605896, 35.28000521659851, 36.32110381126404, 37.35920476913452, 38.39322018623352, 39.4384286403656, 40.46833539009094, 41.50286364555359, 42.589956760406494, 43.623491525650024, 44.65314817428589, 45.697789907455444, 46.757164478302, 47.80676746368408, 48.829795360565186, 50.13300895690918, 51.163918018341064, 52.20383548736572, 53.24294066429138, 54.27787518501282, 55.31340742111206, 56.35178327560425, 57.381471395492554, 58.41628956794739, 59.45530652999878, 60.48986530303955, 61.530630588531494, 62.5675904750824, 63.639694929122925, 64.71994042396545, 65.79155540466309, 66.83215308189392, 67.9126570224762, 68.9860770702362, 70.06972432136536, 71.11334896087646, 72.1484227180481, 73.1872353553772, 74.22511887550354, 75.28794431686401, 76.40040159225464, 77.50624656677246, 78.60157108306885, 79.88491296768188, 80.98726844787598, 82.07997584342957, 83.17709016799927, 84.26954078674316, 85.37515497207642, 86.48784756660461, 87.57010126113892, 88.68168830871582, 89.82383513450623, 90.93614220619202, 92.09358787536621, 93.22925877571106, 94.35552024841309, 95.47885179519653, 96.60803437232971, 97.84549236297607, 99.12395763397217, 100.38865876197815, 101.65399527549744, 102.93351721763611, 104.17312908172607, 105.44403958320618, 106.7363121509552, 107.93035793304443, 109.24252772331238, 110.52689242362976, 111.79989433288574, 114.39537835121155]
[23.525, 25.995, 30.185, 32.135, 34.6425, 37.34, 38.8975, 40.0225, 40.695, 41.6925, 42.48, 43.705, 44.7625, 45.7225, 46.52, 47.19, 48.2, 48.8325, 48.8725, 49.7575, 50.0175, 50.26, 51.0475, 50.9875, 51.5425, 52.42, 52.7525, 52.8575, 54.2225, 54.2075, 54.48, 54.635, 55.175, 55.0525, 54.915, 55.195, 55.4, 55.63, 55.865, 56.22, 56.4125, 56.615, 56.81, 57.1575, 57.42, 57.5875, 57.925, 58.05, 58.1675, 58.225, 58.0825, 58.345, 58.2575, 58.305, 58.345, 58.315, 58.525, 58.505, 58.6525, 58.785, 58.8275, 59.09, 59.37, 59.5625, 59.625, 59.1925, 59.23, 59.3225, 59.6025, 59.7425, 59.6475, 59.945, 59.8425, 60.165, 60.34, 60.585, 60.6475, 60.5625, 60.69, 60.88, 60.3725, 60.4375, 60.4525, 60.7175, 60.6425, 60.6625, 60.9125, 60.68, 60.755, 60.705, 60.6925, 60.4125, 60.4375, 60.4175, 60.8125, 61.02, 60.98, 61.32, 61.4175, 61.515, 60.7075]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.274, Test loss: 2.176, Test accuracy: 19.75 

Round   1, Train loss: 2.113, Test loss: 1.995, Test accuracy: 25.82 

Round   2, Train loss: 1.978, Test loss: 1.912, Test accuracy: 28.15 

Round   3, Train loss: 1.887, Test loss: 1.841, Test accuracy: 31.32 

Round   4, Train loss: 1.822, Test loss: 1.771, Test accuracy: 33.55 

Round   5, Train loss: 1.754, Test loss: 1.740, Test accuracy: 35.90 

Round   6, Train loss: 1.728, Test loss: 1.678, Test accuracy: 38.12 

Round   7, Train loss: 1.674, Test loss: 1.646, Test accuracy: 39.88 

Round   8, Train loss: 1.651, Test loss: 1.610, Test accuracy: 40.81 

Round   9, Train loss: 1.625, Test loss: 1.583, Test accuracy: 42.13 

Round  10, Train loss: 1.600, Test loss: 1.554, Test accuracy: 43.99 

Round  11, Train loss: 1.569, Test loss: 1.539, Test accuracy: 44.03 

Round  12, Train loss: 1.524, Test loss: 1.517, Test accuracy: 44.79 

Round  13, Train loss: 1.485, Test loss: 1.514, Test accuracy: 44.38 

Round  14, Train loss: 1.480, Test loss: 1.540, Test accuracy: 43.38 

Round  15, Train loss: 1.490, Test loss: 1.501, Test accuracy: 45.16 

Round  16, Train loss: 1.473, Test loss: 1.455, Test accuracy: 47.29 

Round  17, Train loss: 1.427, Test loss: 1.425, Test accuracy: 48.48 

Round  18, Train loss: 1.412, Test loss: 1.422, Test accuracy: 48.91 

Round  19, Train loss: 1.408, Test loss: 1.373, Test accuracy: 50.70 

Round  20, Train loss: 1.354, Test loss: 1.365, Test accuracy: 51.07 

Round  21, Train loss: 1.326, Test loss: 1.337, Test accuracy: 52.06 

Round  22, Train loss: 1.339, Test loss: 1.328, Test accuracy: 52.57 

Round  23, Train loss: 1.301, Test loss: 1.310, Test accuracy: 53.07 

Round  24, Train loss: 1.308, Test loss: 1.308, Test accuracy: 53.13 

Round  25, Train loss: 1.257, Test loss: 1.291, Test accuracy: 53.66 

Round  26, Train loss: 1.255, Test loss: 1.281, Test accuracy: 54.24 

Round  27, Train loss: 1.212, Test loss: 1.280, Test accuracy: 54.39 

Round  28, Train loss: 1.222, Test loss: 1.270, Test accuracy: 54.49 

Round  29, Train loss: 1.194, Test loss: 1.256, Test accuracy: 55.26 

Round  30, Train loss: 1.152, Test loss: 1.262, Test accuracy: 55.35 

Round  31, Train loss: 1.201, Test loss: 1.230, Test accuracy: 56.58 

Round  32, Train loss: 1.153, Test loss: 1.250, Test accuracy: 55.56 

Round  33, Train loss: 1.121, Test loss: 1.244, Test accuracy: 55.98 

Round  34, Train loss: 1.139, Test loss: 1.255, Test accuracy: 55.76 

Round  35, Train loss: 1.118, Test loss: 1.212, Test accuracy: 57.25 

Round  36, Train loss: 1.120, Test loss: 1.202, Test accuracy: 57.77 

Round  37, Train loss: 1.065, Test loss: 1.193, Test accuracy: 57.95 

Round  38, Train loss: 1.061, Test loss: 1.195, Test accuracy: 58.05 

Round  39, Train loss: 1.028, Test loss: 1.204, Test accuracy: 57.80 

Round  40, Train loss: 1.039, Test loss: 1.208, Test accuracy: 58.32 

Round  41, Train loss: 1.032, Test loss: 1.193, Test accuracy: 58.27 

Round  42, Train loss: 1.014, Test loss: 1.180, Test accuracy: 59.19 

Round  43, Train loss: 1.000, Test loss: 1.163, Test accuracy: 59.57 

Round  44, Train loss: 0.941, Test loss: 1.172, Test accuracy: 59.63 

Round  45, Train loss: 0.984, Test loss: 1.166, Test accuracy: 59.77 

Round  46, Train loss: 0.979, Test loss: 1.162, Test accuracy: 59.72 

Round  47, Train loss: 1.008, Test loss: 1.148, Test accuracy: 60.68 

Round  48, Train loss: 0.911, Test loss: 1.160, Test accuracy: 60.41 

Round  49, Train loss: 0.923, Test loss: 1.160, Test accuracy: 60.23 

Round  50, Train loss: 0.949, Test loss: 1.146, Test accuracy: 60.83 

Round  51, Train loss: 0.935, Test loss: 1.148, Test accuracy: 61.02 

Round  52, Train loss: 0.864, Test loss: 1.146, Test accuracy: 61.20 

Round  53, Train loss: 0.912, Test loss: 1.160, Test accuracy: 60.88 

Round  54, Train loss: 0.890, Test loss: 1.141, Test accuracy: 61.52 

Round  55, Train loss: 0.857, Test loss: 1.161, Test accuracy: 60.93 

Round  56, Train loss: 0.869, Test loss: 1.166, Test accuracy: 60.96 

Round  57, Train loss: 0.871, Test loss: 1.158, Test accuracy: 60.87 

Round  58, Train loss: 0.862, Test loss: 1.150, Test accuracy: 61.20 

Round  59, Train loss: 0.831, Test loss: 1.148, Test accuracy: 61.50 

Round  60, Train loss: 0.851, Test loss: 1.145, Test accuracy: 61.53 

Round  61, Train loss: 0.890, Test loss: 1.143, Test accuracy: 61.70 

Round  62, Train loss: 0.799, Test loss: 1.154, Test accuracy: 61.62 

Round  63, Train loss: 0.803, Test loss: 1.149, Test accuracy: 61.77 

Round  64, Train loss: 0.823, Test loss: 1.152, Test accuracy: 61.97 

Round  65, Train loss: 0.849, Test loss: 1.130, Test accuracy: 62.38 

Round  66, Train loss: 0.805, Test loss: 1.133, Test accuracy: 62.44 

Round  67, Train loss: 0.756, Test loss: 1.149, Test accuracy: 62.45 

Round  68, Train loss: 0.793, Test loss: 1.162, Test accuracy: 62.14 

Round  69, Train loss: 0.767, Test loss: 1.161, Test accuracy: 62.20 

Round  70, Train loss: 0.744, Test loss: 1.156, Test accuracy: 62.20 

Round  71, Train loss: 0.779, Test loss: 1.164, Test accuracy: 62.48 

Round  72, Train loss: 0.760, Test loss: 1.159, Test accuracy: 62.28 

Round  73, Train loss: 0.738, Test loss: 1.169, Test accuracy: 62.48 

Round  74, Train loss: 0.704, Test loss: 1.162, Test accuracy: 62.59 

Round  75, Train loss: 0.692, Test loss: 1.162, Test accuracy: 62.82 

Round  76, Train loss: 0.720, Test loss: 1.183, Test accuracy: 62.64 

Round  77, Train loss: 0.711, Test loss: 1.178, Test accuracy: 62.71 

Round  78, Train loss: 0.683, Test loss: 1.177, Test accuracy: 62.77 

Round  79, Train loss: 0.711, Test loss: 1.176, Test accuracy: 62.83 

Round  80, Train loss: 0.674, Test loss: 1.192, Test accuracy: 62.66 

Round  81, Train loss: 0.628, Test loss: 1.184, Test accuracy: 62.68 

Round  82, Train loss: 0.705, Test loss: 1.192, Test accuracy: 62.77 

Round  83, Train loss: 0.708, Test loss: 1.180, Test accuracy: 62.70 

Round  84, Train loss: 0.688, Test loss: 1.183, Test accuracy: 63.15 

Round  85, Train loss: 0.673, Test loss: 1.187, Test accuracy: 63.26 

Round  86, Train loss: 0.610, Test loss: 1.189, Test accuracy: 62.74 

Round  87, Train loss: 0.669, Test loss: 1.187, Test accuracy: 62.74 

Round  88, Train loss: 0.678, Test loss: 1.203, Test accuracy: 63.23 

Round  89, Train loss: 0.619, Test loss: 1.194, Test accuracy: 63.43 

Round  90, Train loss: 0.647, Test loss: 1.195, Test accuracy: 63.34 

Round  91, Train loss: 0.635, Test loss: 1.210, Test accuracy: 63.31 

Round  92, Train loss: 0.629, Test loss: 1.205, Test accuracy: 63.03 

Round  93, Train loss: 0.618, Test loss: 1.209, Test accuracy: 63.26 

Round  94, Train loss: 0.611, Test loss: 1.221, Test accuracy: 63.45 

Round  95, Train loss: 0.617, Test loss: 1.213, Test accuracy: 63.40 

Round  96, Train loss: 0.573, Test loss: 1.234, Test accuracy: 63.23 

Round  97, Train loss: 0.581, Test loss: 1.221, Test accuracy: 63.27 

Round  98, Train loss: 0.594, Test loss: 1.241, Test accuracy: 63.45 

Round  99, Train loss: 0.602, Test loss: 1.224, Test accuracy: 63.44 

Final Round, Train loss: 0.508, Test loss: 1.240, Test accuracy: 63.35 

Average accuracy final 10 rounds: 63.31699999999999 

1890.0545814037323
[1.3092401027679443, 2.4024267196655273, 3.496680974960327, 4.580519437789917, 5.641057014465332, 6.6485350131988525, 7.666205167770386, 8.664093017578125, 9.659521341323853, 10.66167140007019, 11.73753046989441, 12.821801662445068, 13.900443077087402, 14.960826396942139, 16.03259801864624, 17.28785014152527, 18.50931429862976, 19.768670320510864, 20.760242223739624, 21.728835344314575, 22.87848711013794, 23.999479055404663, 25.115954399108887, 26.21425461769104, 27.36681628227234, 28.693376779556274, 29.862627744674683, 30.940791130065918, 32.01580548286438, 33.12875962257385, 34.20940661430359, 35.28050756454468, 36.34408688545227, 37.41893029212952, 38.50518989562988, 39.616193771362305, 40.68985033035278, 41.74849319458008, 42.83569955825806, 43.92057132720947, 45.022332429885864, 46.12686228752136, 47.206096172332764, 48.29776883125305, 49.38893461227417, 50.46412634849548, 51.5423321723938, 52.61526846885681, 53.699700117111206, 54.781023025512695, 55.861013889312744, 56.91973567008972, 57.981881618499756, 59.08416986465454, 60.17454814910889, 61.20438289642334, 62.25275540351868, 63.30105781555176, 64.44925355911255, 65.58884286880493, 66.60648918151855, 67.69926404953003, 68.8092155456543, 69.90330839157104, 71.00450348854065, 72.09727811813354, 73.56531190872192, 74.76648378372192, 75.831627368927, 76.88096237182617, 77.94103765487671, 79.01510429382324, 80.08124303817749, 81.15281248092651, 82.2231616973877, 83.2679934501648, 84.33283972740173, 85.41676712036133, 86.49579739570618, 87.57587766647339, 88.66516375541687, 89.76002526283264, 90.84890246391296, 91.92509961128235, 92.98628377914429, 94.05077195167542, 95.1041989326477, 96.16236186027527, 97.2123191356659, 98.26672101020813, 99.35756421089172, 100.42561316490173, 101.48386859893799, 102.54910373687744, 103.59627723693848, 104.6653561592102, 105.76604843139648, 106.80509781837463, 107.87563824653625, 108.94753575325012, 110.96989130973816]
[19.7475, 25.825, 28.15, 31.325, 33.545, 35.8975, 38.125, 39.875, 40.8125, 42.1325, 43.9925, 44.0325, 44.7875, 44.375, 43.3825, 45.1575, 47.2875, 48.4775, 48.9125, 50.695, 51.0725, 52.06, 52.57, 53.0675, 53.135, 53.6625, 54.2375, 54.3875, 54.4875, 55.26, 55.3475, 56.5775, 55.56, 55.9825, 55.755, 57.25, 57.77, 57.9475, 58.05, 57.7975, 58.3225, 58.275, 59.19, 59.5725, 59.6275, 59.77, 59.7175, 60.6775, 60.4075, 60.2275, 60.825, 61.0175, 61.2, 60.885, 61.525, 60.93, 60.96, 60.87, 61.2025, 61.5, 61.5275, 61.6975, 61.625, 61.77, 61.97, 62.38, 62.44, 62.455, 62.14, 62.1975, 62.1975, 62.4825, 62.2825, 62.48, 62.5875, 62.8175, 62.64, 62.7075, 62.77, 62.8325, 62.66, 62.6825, 62.7675, 62.695, 63.145, 63.2575, 62.74, 62.74, 63.23, 63.4325, 63.3375, 63.3075, 63.03, 63.26, 63.45, 63.4, 63.23, 63.2675, 63.4475, 63.44, 63.3525]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307832
307842
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.300, Test loss: 2.237, Test accuracy: 19.36
Round   1, Train loss: 2.192, Test loss: 2.078, Test accuracy: 23.76
Round   2, Train loss: 2.065, Test loss: 1.995, Test accuracy: 26.09
Round   3, Train loss: 1.973, Test loss: 1.907, Test accuracy: 29.99
Round   4, Train loss: 1.887, Test loss: 1.838, Test accuracy: 33.10
Round   5, Train loss: 1.834, Test loss: 1.782, Test accuracy: 35.92
Round   6, Train loss: 1.774, Test loss: 1.725, Test accuracy: 36.82
Round   7, Train loss: 1.740, Test loss: 1.679, Test accuracy: 39.73
Round   8, Train loss: 1.715, Test loss: 1.626, Test accuracy: 41.05
Round   9, Train loss: 1.668, Test loss: 1.602, Test accuracy: 42.37
Round  10, Train loss: 1.627, Test loss: 1.568, Test accuracy: 43.86
Round  11, Train loss: 1.598, Test loss: 1.525, Test accuracy: 44.95
Round  12, Train loss: 1.580, Test loss: 1.495, Test accuracy: 46.03
Round  13, Train loss: 1.539, Test loss: 1.477, Test accuracy: 46.88
Round  14, Train loss: 1.533, Test loss: 1.450, Test accuracy: 47.96
Round  15, Train loss: 1.484, Test loss: 1.428, Test accuracy: 49.10
Round  16, Train loss: 1.496, Test loss: 1.398, Test accuracy: 50.27
Round  17, Train loss: 1.460, Test loss: 1.387, Test accuracy: 50.55
Round  18, Train loss: 1.425, Test loss: 1.368, Test accuracy: 51.37
Round  19, Train loss: 1.398, Test loss: 1.358, Test accuracy: 51.97
Round  20, Train loss: 1.411, Test loss: 1.326, Test accuracy: 52.73
Round  21, Train loss: 1.354, Test loss: 1.324, Test accuracy: 53.25
Round  22, Train loss: 1.351, Test loss: 1.326, Test accuracy: 53.79
Round  23, Train loss: 1.347, Test loss: 1.287, Test accuracy: 54.46
Round  24, Train loss: 1.335, Test loss: 1.278, Test accuracy: 54.58
Round  25, Train loss: 1.267, Test loss: 1.274, Test accuracy: 55.01
Round  26, Train loss: 1.298, Test loss: 1.254, Test accuracy: 56.12
Round  27, Train loss: 1.279, Test loss: 1.236, Test accuracy: 56.84
Round  28, Train loss: 1.284, Test loss: 1.209, Test accuracy: 57.22
Round  29, Train loss: 1.216, Test loss: 1.206, Test accuracy: 57.79
Round  30, Train loss: 1.215, Test loss: 1.193, Test accuracy: 57.80
Round  31, Train loss: 1.199, Test loss: 1.187, Test accuracy: 58.06
Round  32, Train loss: 1.157, Test loss: 1.175, Test accuracy: 58.47
Round  33, Train loss: 1.171, Test loss: 1.175, Test accuracy: 58.23
Round  34, Train loss: 1.131, Test loss: 1.171, Test accuracy: 58.99
Round  35, Train loss: 1.145, Test loss: 1.154, Test accuracy: 59.24
Round  36, Train loss: 1.137, Test loss: 1.141, Test accuracy: 59.98
Round  37, Train loss: 1.115, Test loss: 1.130, Test accuracy: 60.00
Round  38, Train loss: 1.096, Test loss: 1.132, Test accuracy: 60.27
Round  39, Train loss: 1.083, Test loss: 1.117, Test accuracy: 60.52
Round  40, Train loss: 1.110, Test loss: 1.104, Test accuracy: 61.16
Round  41, Train loss: 1.062, Test loss: 1.099, Test accuracy: 61.27
Round  42, Train loss: 1.119, Test loss: 1.087, Test accuracy: 61.43
Round  43, Train loss: 1.059, Test loss: 1.076, Test accuracy: 62.20
Round  44, Train loss: 1.012, Test loss: 1.072, Test accuracy: 62.42
Round  45, Train loss: 1.026, Test loss: 1.069, Test accuracy: 62.34
Round  46, Train loss: 1.039, Test loss: 1.055, Test accuracy: 62.96
Round  47, Train loss: 1.006, Test loss: 1.066, Test accuracy: 62.74
Round  48, Train loss: 1.001, Test loss: 1.055, Test accuracy: 63.27
Round  49, Train loss: 0.957, Test loss: 1.062, Test accuracy: 63.31
Round  50, Train loss: 0.984, Test loss: 1.053, Test accuracy: 63.19
Round  51, Train loss: 0.975, Test loss: 1.041, Test accuracy: 63.35
Round  52, Train loss: 0.959, Test loss: 1.035, Test accuracy: 63.87
Round  53, Train loss: 0.922, Test loss: 1.040, Test accuracy: 64.09
Round  54, Train loss: 0.977, Test loss: 1.025, Test accuracy: 64.34
Round  55, Train loss: 0.948, Test loss: 1.034, Test accuracy: 63.98
Round  56, Train loss: 0.911, Test loss: 1.025, Test accuracy: 64.39
Round  57, Train loss: 0.896, Test loss: 1.021, Test accuracy: 64.60
Round  58, Train loss: 0.889, Test loss: 1.033, Test accuracy: 63.97
Round  59, Train loss: 0.891, Test loss: 1.019, Test accuracy: 64.58
Round  60, Train loss: 0.863, Test loss: 1.016, Test accuracy: 64.55
Round  61, Train loss: 0.884, Test loss: 1.012, Test accuracy: 64.66
Round  62, Train loss: 0.879, Test loss: 1.011, Test accuracy: 64.87
Round  63, Train loss: 0.929, Test loss: 1.007, Test accuracy: 65.14
Round  64, Train loss: 0.842, Test loss: 0.989, Test accuracy: 65.53
Round  65, Train loss: 0.881, Test loss: 0.988, Test accuracy: 65.99
Round  66, Train loss: 0.830, Test loss: 1.005, Test accuracy: 65.41
Round  67, Train loss: 0.834, Test loss: 0.989, Test accuracy: 65.81
Round  68, Train loss: 0.809, Test loss: 0.998, Test accuracy: 65.70
Round  69, Train loss: 0.864, Test loss: 0.980, Test accuracy: 66.28
Round  70, Train loss: 0.804, Test loss: 0.993, Test accuracy: 66.40
Round  71, Train loss: 0.801, Test loss: 0.983, Test accuracy: 66.12
Round  72, Train loss: 0.828, Test loss: 0.995, Test accuracy: 66.04
Round  73, Train loss: 0.803, Test loss: 0.986, Test accuracy: 66.27
Round  74, Train loss: 0.788, Test loss: 0.986, Test accuracy: 66.24
Round  75, Train loss: 0.770, Test loss: 0.970, Test accuracy: 66.71
Round  76, Train loss: 0.805, Test loss: 0.972, Test accuracy: 66.85
Round  77, Train loss: 0.740, Test loss: 0.970, Test accuracy: 66.72
Round  78, Train loss: 0.751, Test loss: 0.964, Test accuracy: 67.05
Round  79, Train loss: 0.764, Test loss: 0.967, Test accuracy: 66.81
Round  80, Train loss: 0.754, Test loss: 0.959, Test accuracy: 67.29
Round  81, Train loss: 0.740, Test loss: 0.975, Test accuracy: 66.64
Round  82, Train loss: 0.708, Test loss: 0.961, Test accuracy: 67.22
Round  83, Train loss: 0.754, Test loss: 0.964, Test accuracy: 66.95
Round  84, Train loss: 0.730, Test loss: 0.962, Test accuracy: 67.20
Round  85, Train loss: 0.727, Test loss: 0.955, Test accuracy: 67.42
Round  86, Train loss: 0.712, Test loss: 0.959, Test accuracy: 67.31
Round  87, Train loss: 0.709, Test loss: 0.965, Test accuracy: 67.21
Round  88, Train loss: 0.706, Test loss: 0.966, Test accuracy: 67.17
Round  89, Train loss: 0.657, Test loss: 0.968, Test accuracy: 67.19
Round  90, Train loss: 0.657, Test loss: 0.964, Test accuracy: 67.15
Round  91, Train loss: 0.734, Test loss: 0.954, Test accuracy: 67.70
Round  92, Train loss: 0.660, Test loss: 0.961, Test accuracy: 67.61
Round  93, Train loss: 0.668, Test loss: 0.960, Test accuracy: 67.25
Round  94, Train loss: 0.668, Test loss: 0.954, Test accuracy: 67.37
Round  95, Train loss: 0.641, Test loss: 0.957, Test accuracy: 67.61
Round  96, Train loss: 0.648, Test loss: 0.970, Test accuracy: 67.13
Round  97, Train loss: 0.680, Test loss: 0.974, Test accuracy: 67.30
Round  98, Train loss: 0.651, Test loss: 0.969, Test accuracy: 67.58
Round  99, Train loss: 0.588, Test loss: 0.964, Test accuracy: 67.48
Final Round, Train loss: 0.562, Test loss: 0.964, Test accuracy: 67.58
Average accuracy final 10 rounds: 67.41799999999999
2135.98525762558
[1.9024722576141357, 3.4364895820617676, 4.994551181793213, 6.47732949256897, 7.955271482467651, 9.496958494186401, 10.988799571990967, 12.49871277809143, 13.987566471099854, 15.476462602615356, 16.98096513748169, 18.50515580177307, 20.057432413101196, 21.60286283493042, 23.132970333099365, 24.653538703918457, 26.17749834060669, 27.723814964294434, 29.213452339172363, 30.684820652008057, 32.178762674331665, 33.68296575546265, 35.20973587036133, 36.73187828063965, 38.25651478767395, 39.7835910320282, 41.29182720184326, 42.808674812316895, 44.32071018218994, 45.82979083061218, 47.366148948669434, 48.89213418960571, 50.4364173412323, 52.00461506843567, 53.50875282287598, 55.018603801727295, 56.55078673362732, 58.08417105674744, 59.60165882110596, 61.13568353652954, 62.55790114402771, 63.9827721118927, 65.40691423416138, 66.7897596359253, 68.2061276435852, 69.62103056907654, 71.01581835746765, 72.46297955513, 73.90725517272949, 75.33215665817261, 76.75452733039856, 78.15182971954346, 79.54879546165466, 80.9806342124939, 82.43343877792358, 83.89595890045166, 85.33518719673157, 86.76890969276428, 88.19836163520813, 89.61777997016907, 91.02716064453125, 92.45317792892456, 93.85840559005737, 95.27653217315674, 96.7122950553894, 98.13996624946594, 99.54898023605347, 100.97239398956299, 102.37674760818481, 103.79319310188293, 105.18588638305664, 106.60704398155212, 108.056893825531, 109.49402260780334, 110.9188723564148, 112.34437346458435, 113.75697898864746, 115.17129850387573, 116.58029079437256, 117.9694652557373, 119.38102293014526, 120.79855823516846, 122.21504139900208, 123.65814423561096, 125.0562174320221, 126.45321106910706, 127.86122107505798, 129.26217675209045, 130.68368697166443, 132.12854433059692, 133.5124011039734, 134.92336773872375, 136.30922746658325, 137.71416449546814, 139.12811279296875, 140.5249423980713, 141.9277949333191, 143.34613800048828, 144.7517466545105, 146.14568328857422, 148.36630201339722]
[19.36, 23.76, 26.085, 29.9925, 33.0975, 35.925, 36.82, 39.7275, 41.0475, 42.3725, 43.8625, 44.95, 46.03, 46.875, 47.96, 49.1, 50.2675, 50.5525, 51.365, 51.9725, 52.735, 53.2475, 53.7925, 54.46, 54.5825, 55.0125, 56.1175, 56.835, 57.2225, 57.79, 57.795, 58.0575, 58.465, 58.23, 58.9875, 59.2425, 59.985, 60.0, 60.275, 60.525, 61.1575, 61.27, 61.43, 62.1975, 62.4225, 62.345, 62.96, 62.745, 63.27, 63.315, 63.19, 63.3525, 63.87, 64.09, 64.3425, 63.975, 64.395, 64.6025, 63.9725, 64.585, 64.545, 64.6625, 64.8675, 65.1375, 65.5325, 65.9875, 65.41, 65.815, 65.705, 66.28, 66.3975, 66.125, 66.0425, 66.2675, 66.2375, 66.7125, 66.8525, 66.7175, 67.05, 66.8075, 67.29, 66.645, 67.215, 66.9525, 67.2, 67.425, 67.3075, 67.2075, 67.17, 67.1875, 67.1525, 67.6975, 67.6075, 67.255, 67.3675, 67.605, 67.13, 67.3025, 67.585, 67.4775, 67.575]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 2.268, Test loss: 2.131, Test accuracy: 22.06
Round   1, Train loss: 2.075, Test loss: 1.945, Test accuracy: 28.30
Round   2, Train loss: 1.955, Test loss: 1.831, Test accuracy: 32.24
Round   3, Train loss: 1.868, Test loss: 1.722, Test accuracy: 35.76
Round   4, Train loss: 1.801, Test loss: 1.685, Test accuracy: 35.85
Round   5, Train loss: 1.714, Test loss: 1.655, Test accuracy: 39.61
Round   6, Train loss: 1.687, Test loss: 1.577, Test accuracy: 40.01
Round   7, Train loss: 1.608, Test loss: 1.557, Test accuracy: 41.97
Round   8, Train loss: 1.563, Test loss: 1.513, Test accuracy: 43.50
Round   9, Train loss: 1.523, Test loss: 1.461, Test accuracy: 44.97
Round  10, Train loss: 1.534, Test loss: 1.462, Test accuracy: 45.33
Round  11, Train loss: 1.487, Test loss: 1.435, Test accuracy: 46.02
Round  12, Train loss: 1.458, Test loss: 1.506, Test accuracy: 47.92
Round  13, Train loss: 1.399, Test loss: 1.398, Test accuracy: 48.23
Round  14, Train loss: 1.344, Test loss: 1.397, Test accuracy: 48.81
Round  15, Train loss: 1.295, Test loss: 1.429, Test accuracy: 48.67
Round  16, Train loss: 1.319, Test loss: 1.341, Test accuracy: 50.54
Round  17, Train loss: 1.251, Test loss: 1.342, Test accuracy: 51.61
Round  18, Train loss: 1.204, Test loss: 1.360, Test accuracy: 51.02
Round  19, Train loss: 1.227, Test loss: 1.292, Test accuracy: 52.34
Round  20, Train loss: 1.184, Test loss: 1.359, Test accuracy: 51.34
Round  21, Train loss: 1.158, Test loss: 1.304, Test accuracy: 52.65
Round  22, Train loss: 1.210, Test loss: 1.269, Test accuracy: 54.14
Round  23, Train loss: 1.092, Test loss: 1.244, Test accuracy: 54.02
Round  24, Train loss: 1.130, Test loss: 1.312, Test accuracy: 54.29
Round  25, Train loss: 1.070, Test loss: 1.291, Test accuracy: 53.76
Round  26, Train loss: 1.099, Test loss: 1.255, Test accuracy: 54.97
Round  27, Train loss: 1.011, Test loss: 1.403, Test accuracy: 53.96
Round  28, Train loss: 1.006, Test loss: 1.247, Test accuracy: 55.75
Round  29, Train loss: 0.950, Test loss: 1.242, Test accuracy: 55.77
Round  30, Train loss: 0.975, Test loss: 1.322, Test accuracy: 55.76
Round  31, Train loss: 0.993, Test loss: 1.246, Test accuracy: 55.50
Round  32, Train loss: 0.946, Test loss: 1.229, Test accuracy: 56.53
Round  33, Train loss: 0.926, Test loss: 1.315, Test accuracy: 57.20
Round  34, Train loss: 0.883, Test loss: 1.284, Test accuracy: 55.97
Round  35, Train loss: 0.875, Test loss: 1.233, Test accuracy: 55.39
Round  36, Train loss: 0.849, Test loss: 1.226, Test accuracy: 56.26
Round  37, Train loss: 0.800, Test loss: 1.253, Test accuracy: 57.38
Round  38, Train loss: 0.790, Test loss: 1.240, Test accuracy: 57.66
Round  39, Train loss: 0.840, Test loss: 1.258, Test accuracy: 57.64
Round  40, Train loss: 0.847, Test loss: 1.315, Test accuracy: 56.90
Round  41, Train loss: 0.804, Test loss: 1.302, Test accuracy: 56.95
Round  42, Train loss: 0.753, Test loss: 1.245, Test accuracy: 57.99
Round  43, Train loss: 0.755, Test loss: 1.291, Test accuracy: 57.44
Round  44, Train loss: 0.766, Test loss: 1.257, Test accuracy: 58.18
Round  45, Train loss: 0.785, Test loss: 1.266, Test accuracy: 58.49
Round  46, Train loss: 0.735, Test loss: 1.297, Test accuracy: 57.29
Round  47, Train loss: 0.718, Test loss: 1.228, Test accuracy: 58.56
Round  48, Train loss: 0.691, Test loss: 1.243, Test accuracy: 57.98
Round  49, Train loss: 0.750, Test loss: 1.206, Test accuracy: 58.13
Round  50, Train loss: 0.696, Test loss: 1.242, Test accuracy: 58.52
Round  51, Train loss: 0.640, Test loss: 1.292, Test accuracy: 58.42
Round  52, Train loss: 0.635, Test loss: 1.250, Test accuracy: 59.22
Round  53, Train loss: 0.632, Test loss: 1.324, Test accuracy: 58.10
Round  54, Train loss: 0.723, Test loss: 1.231, Test accuracy: 59.67
Round  55, Train loss: 0.608, Test loss: 1.255, Test accuracy: 59.45
Round  56, Train loss: 0.609, Test loss: 1.246, Test accuracy: 59.02
Round  57, Train loss: 0.585, Test loss: 1.237, Test accuracy: 59.24
Round  58, Train loss: 0.581, Test loss: 1.328, Test accuracy: 58.46
Round  59, Train loss: 0.646, Test loss: 1.248, Test accuracy: 59.59
Round  60, Train loss: 0.622, Test loss: 1.243, Test accuracy: 59.93
Round  61, Train loss: 0.558, Test loss: 1.311, Test accuracy: 59.34
Round  62, Train loss: 0.577, Test loss: 1.341, Test accuracy: 58.66
Round  63, Train loss: 0.614, Test loss: 1.238, Test accuracy: 60.48
Round  64, Train loss: 0.546, Test loss: 1.297, Test accuracy: 59.79
Round  65, Train loss: 0.569, Test loss: 1.243, Test accuracy: 59.73
Round  66, Train loss: 0.569, Test loss: 1.251, Test accuracy: 60.22
Round  67, Train loss: 0.554, Test loss: 1.240, Test accuracy: 59.56
Round  68, Train loss: 0.538, Test loss: 1.282, Test accuracy: 59.17
Round  69, Train loss: 0.534, Test loss: 1.273, Test accuracy: 59.59
Round  70, Train loss: 0.540, Test loss: 1.318, Test accuracy: 60.23
Round  71, Train loss: 0.550, Test loss: 1.323, Test accuracy: 59.59
Round  72, Train loss: 0.521, Test loss: 1.287, Test accuracy: 59.26
Round  73, Train loss: 0.489, Test loss: 1.369, Test accuracy: 59.09
Round  74, Train loss: 0.526, Test loss: 1.329, Test accuracy: 60.84
Round  75, Train loss: 0.511, Test loss: 1.284, Test accuracy: 59.65
Round  76, Train loss: 0.480, Test loss: 1.285, Test accuracy: 59.88
Round  77, Train loss: 0.470, Test loss: 1.309, Test accuracy: 59.08
Round  78, Train loss: 0.457, Test loss: 1.323, Test accuracy: 59.51
Round  79, Train loss: 0.464, Test loss: 1.360, Test accuracy: 60.05
Round  80, Train loss: 0.433, Test loss: 1.371, Test accuracy: 60.61
Round  81, Train loss: 0.451, Test loss: 1.370, Test accuracy: 60.37
Round  82, Train loss: 0.504, Test loss: 1.327, Test accuracy: 60.37
Round  83, Train loss: 0.492, Test loss: 1.455, Test accuracy: 60.84
Round  84, Train loss: 0.424, Test loss: 1.311, Test accuracy: 60.24
Round  85, Train loss: 0.412, Test loss: 1.449, Test accuracy: 59.00
Round  86, Train loss: 0.450, Test loss: 1.370, Test accuracy: 61.03
Round  87, Train loss: 0.443, Test loss: 1.514, Test accuracy: 60.91
Round  88, Train loss: 0.472, Test loss: 1.286, Test accuracy: 60.37
Round  89, Train loss: 0.431, Test loss: 1.344, Test accuracy: 60.01
Round  90, Train loss: 0.409, Test loss: 1.393, Test accuracy: 60.44
Round  91, Train loss: 0.427, Test loss: 1.502, Test accuracy: 60.77
Round  92, Train loss: 0.392, Test loss: 1.513, Test accuracy: 60.56
Round  93, Train loss: 0.403, Test loss: 1.433, Test accuracy: 59.99
Round  94, Train loss: 0.380, Test loss: 1.414, Test accuracy: 60.14
Round  95, Train loss: 0.436, Test loss: 1.374, Test accuracy: 60.20
Round  96, Train loss: 0.390, Test loss: 1.344, Test accuracy: 59.92
Round  97, Train loss: 0.390, Test loss: 1.425, Test accuracy: 59.14
Round  98, Train loss: 0.405, Test loss: 1.339, Test accuracy: 59.83
Round  99, Train loss: 0.387, Test loss: 1.468, Test accuracy: 59.88
Final Round, Train loss: 0.384, Test loss: 1.310, Test accuracy: 61.16
Average accuracy final 10 rounds: 60.08774999999999
3068.407467365265
[3.4657950401306152, 6.733107566833496, 9.979809522628784, 13.267478704452515, 16.580824851989746, 19.821341037750244, 23.05545210838318, 26.023643970489502, 28.99167013168335, 31.97943902015686, 34.93474245071411, 37.930309534072876, 40.91088366508484, 43.91784882545471, 46.90460467338562, 49.89396572113037, 52.882396936416626, 55.91378474235535, 58.871477365493774, 61.84906244277954, 64.81351804733276, 67.75582885742188, 70.74021124839783, 73.776362657547, 76.75110244750977, 79.7556881904602, 82.78152370452881, 85.75006699562073, 88.68250107765198, 91.6541657447815, 94.64668416976929, 97.62825918197632, 100.61283206939697, 103.59467768669128, 106.57987332344055, 109.5498378276825, 112.54342842102051, 115.53608417510986, 118.53145503997803, 121.54921650886536, 124.52974534034729, 127.51128816604614, 130.51786613464355, 133.47350597381592, 136.45758390426636, 139.41270470619202, 142.3745789527893, 145.38652753829956, 148.4031000137329, 151.37791919708252, 154.3772087097168, 157.38241910934448, 160.34338974952698, 163.32859015464783, 166.35578751564026, 169.35929679870605, 172.33098816871643, 175.30486464500427, 178.27606582641602, 181.27007937431335, 184.24862337112427, 187.21051406860352, 190.17449355125427, 193.13008069992065, 196.15115451812744, 199.13195896148682, 202.1378049850464, 205.18169736862183, 208.1844973564148, 211.14995336532593, 214.14618158340454, 217.12346243858337, 220.12605547904968, 223.08385038375854, 226.03749680519104, 229.02372217178345, 232.03043603897095, 235.03408932685852, 238.00166296958923, 240.9780023097992, 243.99215984344482, 247.00959277153015, 249.98940706253052, 252.95177149772644, 255.9350883960724, 258.92942547798157, 261.9255292415619, 264.8968126773834, 267.89500617980957, 270.88487911224365, 273.92316246032715, 276.9232568740845, 279.9090692996979, 282.91998386383057, 285.95868396759033, 288.9694242477417, 291.97241854667664, 294.97577238082886, 297.961706161499, 300.9486012458801, 303.9775948524475]
[22.06, 28.305, 32.24, 35.7575, 35.855, 39.6125, 40.0075, 41.965, 43.4975, 44.9675, 45.325, 46.02, 47.9175, 48.225, 48.8075, 48.6675, 50.54, 51.6075, 51.015, 52.34, 51.3375, 52.6525, 54.14, 54.025, 54.2875, 53.755, 54.9725, 53.9625, 55.7525, 55.775, 55.76, 55.5025, 56.535, 57.2, 55.965, 55.39, 56.2625, 57.38, 57.66, 57.6425, 56.9, 56.945, 57.99, 57.435, 58.1775, 58.495, 57.2925, 58.5575, 57.9825, 58.13, 58.525, 58.42, 59.2225, 58.1, 59.6675, 59.445, 59.025, 59.245, 58.46, 59.585, 59.9275, 59.335, 58.665, 60.485, 59.79, 59.7275, 60.2175, 59.56, 59.175, 59.5875, 60.2325, 59.585, 59.26, 59.0925, 60.835, 59.645, 59.875, 59.0775, 59.5125, 60.05, 60.6075, 60.3725, 60.3675, 60.845, 60.245, 59.0, 61.035, 60.9075, 60.3725, 60.01, 60.4375, 60.7725, 60.565, 59.9925, 60.14, 60.2025, 59.925, 59.1375, 59.83, 59.875, 61.165]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.306, Test loss: 2.307, Test accuracy: 9.93 

Round   0, Global train loss: 2.306, Global test loss: 2.307, Global test accuracy: 9.91 

Round   1, Train loss: 2.306, Test loss: 2.306, Test accuracy: 9.99 

Round   1, Global train loss: 2.306, Global test loss: 2.306, Global test accuracy: 9.99 

Round   2, Train loss: 2.306, Test loss: 2.306, Test accuracy: 10.03 

Round   2, Global train loss: 2.306, Global test loss: 2.306, Global test accuracy: 10.04 

Round   3, Train loss: 2.305, Test loss: 2.306, Test accuracy: 10.16 

Round   3, Global train loss: 2.305, Global test loss: 2.306, Global test accuracy: 10.19 

Round   4, Train loss: 2.308, Test loss: 2.306, Test accuracy: 10.18 

Round   4, Global train loss: 2.308, Global test loss: 2.305, Global test accuracy: 10.10 

Round   5, Train loss: 2.306, Test loss: 2.306, Test accuracy: 10.31 

Round   5, Global train loss: 2.306, Global test loss: 2.305, Global test accuracy: 10.23 

Round   6, Train loss: 2.303, Test loss: 2.305, Test accuracy: 10.26 

Round   6, Global train loss: 2.303, Global test loss: 2.305, Global test accuracy: 10.10 

Round   7, Train loss: 2.306, Test loss: 2.305, Test accuracy: 10.42 

Round   7, Global train loss: 2.306, Global test loss: 2.305, Global test accuracy: 10.38 

Round   8, Train loss: 2.305, Test loss: 2.305, Test accuracy: 10.58 

Round   8, Global train loss: 2.305, Global test loss: 2.304, Global test accuracy: 10.55 

Round   9, Train loss: 2.306, Test loss: 2.305, Test accuracy: 10.65 

Round   9, Global train loss: 2.306, Global test loss: 2.304, Global test accuracy: 10.81 

Round  10, Train loss: 2.302, Test loss: 2.304, Test accuracy: 10.83 

Round  10, Global train loss: 2.302, Global test loss: 2.304, Global test accuracy: 11.23 

Round  11, Train loss: 2.304, Test loss: 2.304, Test accuracy: 11.10 

Round  11, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 11.28 

Round  12, Train loss: 2.302, Test loss: 2.304, Test accuracy: 11.13 

Round  12, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.86 

Round  13, Train loss: 2.303, Test loss: 2.304, Test accuracy: 10.78 

Round  13, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.85 

Round  14, Train loss: 2.306, Test loss: 2.303, Test accuracy: 10.80 

Round  14, Global train loss: 2.306, Global test loss: 2.303, Global test accuracy: 10.87 

Round  15, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.88 

Round  15, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 11.17 

Round  16, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.96 

Round  16, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 11.35 

Round  17, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.15 

Round  17, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.72 

Round  18, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.38 

Round  18, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.52 

Round  19, Train loss: 2.302, Test loss: 2.303, Test accuracy: 11.47 

Round  19, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.65 

Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.62 

Round  20, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.81 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.68 

Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.50 

Round  22, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.52 

Round  22, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.42 

Round  23, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.32 

Round  23, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.21 

Round  24, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.43 

Round  24, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.53 

Round  25, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.53 

Round  25, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 11.29 

Round  26, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.49 

Round  26, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.45 

Round  27, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.71 

Round  27, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.70 

Round  28, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.76 

Round  28, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 11.57 

Round  29, Train loss: 2.299, Test loss: 2.301, Test accuracy: 11.65 

Round  29, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 11.49 

Round  30, Train loss: 2.301, Test loss: 2.300, Test accuracy: 11.55 

Round  30, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 11.50 

Round  31, Train loss: 2.301, Test loss: 2.300, Test accuracy: 11.62 

Round  31, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 11.65 

Round  32, Train loss: 2.300, Test loss: 2.300, Test accuracy: 11.59 

Round  32, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 11.60 

Round  33, Train loss: 2.300, Test loss: 2.300, Test accuracy: 11.79 

Round  33, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 11.71 

Round  34, Train loss: 2.302, Test loss: 2.300, Test accuracy: 11.87 

Round  34, Global train loss: 2.302, Global test loss: 2.299, Global test accuracy: 11.84 

Round  35, Train loss: 2.302, Test loss: 2.299, Test accuracy: 11.92 

Round  35, Global train loss: 2.302, Global test loss: 2.299, Global test accuracy: 11.97 

Round  36, Train loss: 2.300, Test loss: 2.299, Test accuracy: 11.67 

Round  36, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 11.80 

Round  37, Train loss: 2.300, Test loss: 2.299, Test accuracy: 11.82 

Round  37, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 11.97 

Round  38, Train loss: 2.299, Test loss: 2.299, Test accuracy: 12.05 

Round  38, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 12.52 

Round  39, Train loss: 2.299, Test loss: 2.299, Test accuracy: 12.24 

Round  39, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 13.14 

Round  40, Train loss: 2.300, Test loss: 2.298, Test accuracy: 12.62 

Round  40, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 13.24 

Round  41, Train loss: 2.298, Test loss: 2.298, Test accuracy: 12.55 

Round  41, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 12.57 

Round  42, Train loss: 2.299, Test loss: 2.298, Test accuracy: 12.55 

Round  42, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 12.84 

Round  43, Train loss: 2.299, Test loss: 2.298, Test accuracy: 12.52 

Round  43, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 13.22 

Round  44, Train loss: 2.298, Test loss: 2.298, Test accuracy: 12.82 

Round  44, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 12.98 

Round  45, Train loss: 2.297, Test loss: 2.297, Test accuracy: 12.68 

Round  45, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 12.40 

Round  46, Train loss: 2.298, Test loss: 2.297, Test accuracy: 12.62 

Round  46, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 12.38 

Round  47, Train loss: 2.297, Test loss: 2.297, Test accuracy: 12.72 

Round  47, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 12.05 

Round  48, Train loss: 2.295, Test loss: 2.296, Test accuracy: 12.15 

Round  48, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 11.80 

Round  49, Train loss: 2.298, Test loss: 2.296, Test accuracy: 11.81 

Round  49, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 11.79 

Round  50, Train loss: 2.299, Test loss: 2.296, Test accuracy: 11.69 

Round  50, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 11.68 

Round  51, Train loss: 2.297, Test loss: 2.296, Test accuracy: 11.51 

Round  51, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 12.04 

Round  52, Train loss: 2.297, Test loss: 2.296, Test accuracy: 11.61 

Round  52, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 12.12 

Round  53, Train loss: 2.296, Test loss: 2.295, Test accuracy: 11.79 

Round  53, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 11.49 

Round  54, Train loss: 2.296, Test loss: 2.295, Test accuracy: 11.91 

Round  54, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 11.66 

Round  55, Train loss: 2.297, Test loss: 2.295, Test accuracy: 11.82 

Round  55, Global train loss: 2.297, Global test loss: 2.294, Global test accuracy: 11.48 

Round  56, Train loss: 2.296, Test loss: 2.295, Test accuracy: 11.89 

Round  56, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 11.36 

Round  57, Train loss: 2.294, Test loss: 2.294, Test accuracy: 11.61 

Round  57, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 11.25 

Round  58, Train loss: 2.296, Test loss: 2.294, Test accuracy: 11.52 

Round  58, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 11.05 

Round  59, Train loss: 2.294, Test loss: 2.294, Test accuracy: 11.54 

Round  59, Global train loss: 2.294, Global test loss: 2.293, Global test accuracy: 11.42 

Round  60, Train loss: 2.294, Test loss: 2.293, Test accuracy: 11.67 

Round  60, Global train loss: 2.294, Global test loss: 2.292, Global test accuracy: 11.77 

Round  61, Train loss: 2.295, Test loss: 2.293, Test accuracy: 11.99 

Round  61, Global train loss: 2.295, Global test loss: 2.292, Global test accuracy: 12.12 

Round  62, Train loss: 2.294, Test loss: 2.293, Test accuracy: 12.01 

Round  62, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 12.30 

Round  63, Train loss: 2.294, Test loss: 2.292, Test accuracy: 11.86 

Round  63, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 11.98 

Round  64, Train loss: 2.292, Test loss: 2.292, Test accuracy: 11.90 

Round  64, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 12.11 

Round  65, Train loss: 2.292, Test loss: 2.291, Test accuracy: 11.95 

Round  65, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 11.65 

Round  66, Train loss: 2.291, Test loss: 2.291, Test accuracy: 12.16 

Round  66, Global train loss: 2.291, Global test loss: 2.290, Global test accuracy: 11.95 

Round  67, Train loss: 2.292, Test loss: 2.291, Test accuracy: 12.24 

Round  67, Global train loss: 2.292, Global test loss: 2.290, Global test accuracy: 12.54 

Round  68, Train loss: 2.293, Test loss: 2.290, Test accuracy: 12.29 

Round  68, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 12.29 

Round  69, Train loss: 2.291, Test loss: 2.290, Test accuracy: 12.52 

Round  69, Global train loss: 2.291, Global test loss: 2.289, Global test accuracy: 12.04 

Round  70, Train loss: 2.291, Test loss: 2.290, Test accuracy: 12.50 

Round  70, Global train loss: 2.291, Global test loss: 2.289, Global test accuracy: 12.50 

Round  71, Train loss: 2.291, Test loss: 2.289, Test accuracy: 12.78 

Round  71, Global train loss: 2.291, Global test loss: 2.289, Global test accuracy: 12.67 

Round  72, Train loss: 2.291, Test loss: 2.289, Test accuracy: 12.97 

Round  72, Global train loss: 2.291, Global test loss: 2.288, Global test accuracy: 13.11 

Round  73, Train loss: 2.289, Test loss: 2.289, Test accuracy: 13.07 

Round  73, Global train loss: 2.289, Global test loss: 2.288, Global test accuracy: 13.24 

Round  74, Train loss: 2.292, Test loss: 2.288, Test accuracy: 13.21 

Round  74, Global train loss: 2.292, Global test loss: 2.287, Global test accuracy: 13.17 

Round  75, Train loss: 2.290, Test loss: 2.288, Test accuracy: 13.23 

Round  75, Global train loss: 2.290, Global test loss: 2.287, Global test accuracy: 13.41 

Round  76, Train loss: 2.291, Test loss: 2.288, Test accuracy: 13.35 

Round  76, Global train loss: 2.291, Global test loss: 2.287, Global test accuracy: 13.24 

Round  77, Train loss: 2.289, Test loss: 2.287, Test accuracy: 13.44 

Round  77, Global train loss: 2.289, Global test loss: 2.286, Global test accuracy: 14.01 

Round  78, Train loss: 2.290, Test loss: 2.287, Test accuracy: 13.50 

Round  78, Global train loss: 2.290, Global test loss: 2.286, Global test accuracy: 14.08 

Round  79, Train loss: 2.288, Test loss: 2.286, Test accuracy: 13.79 

Round  79, Global train loss: 2.288, Global test loss: 2.285, Global test accuracy: 13.91 

Round  80, Train loss: 2.288, Test loss: 2.286, Test accuracy: 13.86 

Round  80, Global train loss: 2.288, Global test loss: 2.285, Global test accuracy: 14.18 

Round  81, Train loss: 2.287, Test loss: 2.285, Test accuracy: 13.90 

Round  81, Global train loss: 2.287, Global test loss: 2.284, Global test accuracy: 14.90 

Round  82, Train loss: 2.287, Test loss: 2.284, Test accuracy: 14.38 

Round  82, Global train loss: 2.287, Global test loss: 2.284, Global test accuracy: 14.93 

Round  83, Train loss: 2.287, Test loss: 2.284, Test accuracy: 14.35 

Round  83, Global train loss: 2.287, Global test loss: 2.283, Global test accuracy: 14.91 

Round  84, Train loss: 2.285, Test loss: 2.284, Test accuracy: 14.25 

Round  84, Global train loss: 2.285, Global test loss: 2.283, Global test accuracy: 14.31 

Round  85, Train loss: 2.289, Test loss: 2.283, Test accuracy: 14.27 

Round  85, Global train loss: 2.289, Global test loss: 2.282, Global test accuracy: 14.64 

Round  86, Train loss: 2.286, Test loss: 2.283, Test accuracy: 14.31 

Round  86, Global train loss: 2.286, Global test loss: 2.282, Global test accuracy: 14.40 

Round  87, Train loss: 2.285, Test loss: 2.283, Test accuracy: 14.27 

Round  87, Global train loss: 2.285, Global test loss: 2.281, Global test accuracy: 14.47 

Round  88, Train loss: 2.283, Test loss: 2.282, Test accuracy: 14.28 

Round  88, Global train loss: 2.283, Global test loss: 2.281, Global test accuracy: 13.96 

Round  89, Train loss: 2.283, Test loss: 2.281, Test accuracy: 14.15 

Round  89, Global train loss: 2.283, Global test loss: 2.280, Global test accuracy: 13.79 

Round  90, Train loss: 2.285, Test loss: 2.281, Test accuracy: 14.14 

Round  90, Global train loss: 2.285, Global test loss: 2.280, Global test accuracy: 13.93 

Round  91, Train loss: 2.284, Test loss: 2.280, Test accuracy: 14.20 

Round  91, Global train loss: 2.284, Global test loss: 2.279, Global test accuracy: 14.13 

Round  92, Train loss: 2.283, Test loss: 2.280, Test accuracy: 14.04 

Round  92, Global train loss: 2.283, Global test loss: 2.279, Global test accuracy: 13.64 

Round  93, Train loss: 2.281, Test loss: 2.279, Test accuracy: 14.32 

Round  93, Global train loss: 2.281, Global test loss: 2.277, Global test accuracy: 13.93 

Round  94, Train loss: 2.283, Test loss: 2.278, Test accuracy: 14.51 

Round  94, Global train loss: 2.283, Global test loss: 2.277, Global test accuracy: 15.15 

Round  95, Train loss: 2.281, Test loss: 2.278, Test accuracy: 14.73 

Round  95, Global train loss: 2.281, Global test loss: 2.276, Global test accuracy: 14.09 

Round  96, Train loss: 2.282, Test loss: 2.277, Test accuracy: 14.57 

Round  96, Global train loss: 2.282, Global test loss: 2.275, Global test accuracy: 14.16 

Round  97, Train loss: 2.281, Test loss: 2.276, Test accuracy: 14.52 

Round  97, Global train loss: 2.281, Global test loss: 2.275, Global test accuracy: 13.97 

Round  98, Train loss: 2.281, Test loss: 2.276, Test accuracy: 14.59 

Round  98, Global train loss: 2.281, Global test loss: 2.274, Global test accuracy: 14.37 

Round  99, Train loss: 2.281, Test loss: 2.276, Test accuracy: 14.48 

Round  99, Global train loss: 2.281, Global test loss: 2.274, Global test accuracy: 14.13 

Round 100, Train loss: 2.279, Test loss: 2.274, Test accuracy: 14.40 

Round 100, Global train loss: 2.279, Global test loss: 2.273, Global test accuracy: 14.57 

Round 101, Train loss: 2.278, Test loss: 2.273, Test accuracy: 14.45 

Round 101, Global train loss: 2.278, Global test loss: 2.272, Global test accuracy: 14.92 

Round 102, Train loss: 2.279, Test loss: 2.273, Test accuracy: 14.77 

Round 102, Global train loss: 2.279, Global test loss: 2.271, Global test accuracy: 15.21 

Round 103, Train loss: 2.277, Test loss: 2.272, Test accuracy: 15.04 

Round 103, Global train loss: 2.277, Global test loss: 2.270, Global test accuracy: 15.16 

Round 104, Train loss: 2.276, Test loss: 2.272, Test accuracy: 15.07 

Round 104, Global train loss: 2.276, Global test loss: 2.270, Global test accuracy: 16.31 

Round 105, Train loss: 2.277, Test loss: 2.271, Test accuracy: 15.27 

Round 105, Global train loss: 2.277, Global test loss: 2.269, Global test accuracy: 16.54 

Round 106, Train loss: 2.275, Test loss: 2.270, Test accuracy: 15.85 

Round 106, Global train loss: 2.275, Global test loss: 2.268, Global test accuracy: 17.48 

Round 107, Train loss: 2.274, Test loss: 2.269, Test accuracy: 16.44 

Round 107, Global train loss: 2.274, Global test loss: 2.267, Global test accuracy: 18.30 

Round 108, Train loss: 2.271, Test loss: 2.269, Test accuracy: 16.77 

Round 108, Global train loss: 2.271, Global test loss: 2.266, Global test accuracy: 17.44 

Round 109, Train loss: 2.273, Test loss: 2.268, Test accuracy: 16.92 

Round 109, Global train loss: 2.273, Global test loss: 2.265, Global test accuracy: 17.64 

Round 110, Train loss: 2.274, Test loss: 2.267, Test accuracy: 16.95 

Round 110, Global train loss: 2.274, Global test loss: 2.265, Global test accuracy: 17.48 

Round 111, Train loss: 2.275, Test loss: 2.266, Test accuracy: 16.89 

Round 111, Global train loss: 2.275, Global test loss: 2.264, Global test accuracy: 16.79 

Round 112, Train loss: 2.271, Test loss: 2.265, Test accuracy: 16.98 

Round 112, Global train loss: 2.271, Global test loss: 2.264, Global test accuracy: 16.90 

Round 113, Train loss: 2.271, Test loss: 2.264, Test accuracy: 17.50 

Round 113, Global train loss: 2.271, Global test loss: 2.262, Global test accuracy: 17.75 

Round 114, Train loss: 2.271, Test loss: 2.264, Test accuracy: 17.52 

Round 114, Global train loss: 2.271, Global test loss: 2.261, Global test accuracy: 17.84 

Round 115, Train loss: 2.268, Test loss: 2.262, Test accuracy: 17.66 

Round 115, Global train loss: 2.268, Global test loss: 2.260, Global test accuracy: 17.47 

Round 116, Train loss: 2.271, Test loss: 2.261, Test accuracy: 17.70 

Round 116, Global train loss: 2.271, Global test loss: 2.259, Global test accuracy: 17.60 

Round 117, Train loss: 2.263, Test loss: 2.260, Test accuracy: 17.85 

Round 117, Global train loss: 2.263, Global test loss: 2.257, Global test accuracy: 17.91 

Round 118, Train loss: 2.266, Test loss: 2.259, Test accuracy: 17.66 

Round 118, Global train loss: 2.266, Global test loss: 2.257, Global test accuracy: 17.06 

Round 119, Train loss: 2.268, Test loss: 2.258, Test accuracy: 17.48 

Round 119, Global train loss: 2.268, Global test loss: 2.256, Global test accuracy: 17.23 

Round 120, Train loss: 2.269, Test loss: 2.257, Test accuracy: 17.25 

Round 120, Global train loss: 2.269, Global test loss: 2.255, Global test accuracy: 17.52 

Round 121, Train loss: 2.266, Test loss: 2.256, Test accuracy: 17.04 

Round 121, Global train loss: 2.266, Global test loss: 2.255, Global test accuracy: 17.82 

Round 122, Train loss: 2.266, Test loss: 2.256, Test accuracy: 17.12 

Round 122, Global train loss: 2.266, Global test loss: 2.254, Global test accuracy: 17.82 

Round 123, Train loss: 2.262, Test loss: 2.255, Test accuracy: 17.38 

Round 123, Global train loss: 2.262, Global test loss: 2.253, Global test accuracy: 18.11 

Round 124, Train loss: 2.267, Test loss: 2.254, Test accuracy: 17.67 

Round 124, Global train loss: 2.267, Global test loss: 2.252, Global test accuracy: 18.22 

Round 125, Train loss: 2.259, Test loss: 2.253, Test accuracy: 17.99 

Round 125, Global train loss: 2.259, Global test loss: 2.250, Global test accuracy: 18.34 

Round 126, Train loss: 2.263, Test loss: 2.252, Test accuracy: 18.12 

Round 126, Global train loss: 2.263, Global test loss: 2.249, Global test accuracy: 18.77 

Round 127, Train loss: 2.261, Test loss: 2.251, Test accuracy: 18.23 

Round 127, Global train loss: 2.261, Global test loss: 2.249, Global test accuracy: 19.06 

Round 128, Train loss: 2.262, Test loss: 2.250, Test accuracy: 18.29 

Round 128, Global train loss: 2.262, Global test loss: 2.249, Global test accuracy: 18.88 

Round 129, Train loss: 2.261, Test loss: 2.250, Test accuracy: 18.10 

Round 129, Global train loss: 2.261, Global test loss: 2.247, Global test accuracy: 18.78 

Round 130, Train loss: 2.258, Test loss: 2.249, Test accuracy: 18.02 

Round 130, Global train loss: 2.258, Global test loss: 2.246, Global test accuracy: 18.59 

Round 131, Train loss: 2.258, Test loss: 2.248, Test accuracy: 18.21 

Round 131, Global train loss: 2.258, Global test loss: 2.246, Global test accuracy: 18.75 

Round 132, Train loss: 2.255, Test loss: 2.247, Test accuracy: 18.48 

Round 132, Global train loss: 2.255, Global test loss: 2.244, Global test accuracy: 18.42 

Round 133, Train loss: 2.256, Test loss: 2.246, Test accuracy: 18.42 

Round 133, Global train loss: 2.256, Global test loss: 2.243, Global test accuracy: 18.75 

Round 134, Train loss: 2.253, Test loss: 2.245, Test accuracy: 18.58 

Round 134, Global train loss: 2.253, Global test loss: 2.241, Global test accuracy: 18.89 

Round 135, Train loss: 2.255, Test loss: 2.243, Test accuracy: 18.94 

Round 135, Global train loss: 2.255, Global test loss: 2.239, Global test accuracy: 19.42 

Round 136, Train loss: 2.255, Test loss: 2.241, Test accuracy: 19.08 

Round 136, Global train loss: 2.255, Global test loss: 2.239, Global test accuracy: 19.58 

Round 137, Train loss: 2.256, Test loss: 2.240, Test accuracy: 19.06 

Round 137, Global train loss: 2.256, Global test loss: 2.239, Global test accuracy: 19.41 

Round 138, Train loss: 2.250, Test loss: 2.240, Test accuracy: 19.00 

Round 138, Global train loss: 2.250, Global test loss: 2.237, Global test accuracy: 19.70 

Round 139, Train loss: 2.256, Test loss: 2.239, Test accuracy: 19.08 

Round 139, Global train loss: 2.256, Global test loss: 2.238, Global test accuracy: 19.84 

Round 140, Train loss: 2.253, Test loss: 2.238, Test accuracy: 19.41 

Round 140, Global train loss: 2.253, Global test loss: 2.237, Global test accuracy: 19.90 

Round 141, Train loss: 2.246, Test loss: 2.237, Test accuracy: 19.70 

Round 141, Global train loss: 2.246, Global test loss: 2.235, Global test accuracy: 20.18 

Round 142, Train loss: 2.250, Test loss: 2.236, Test accuracy: 19.86 

Round 142, Global train loss: 2.250, Global test loss: 2.233, Global test accuracy: 20.64 

Round 143, Train loss: 2.252, Test loss: 2.235, Test accuracy: 19.93 

Round 143, Global train loss: 2.252, Global test loss: 2.232, Global test accuracy: 19.97 

Round 144, Train loss: 2.250, Test loss: 2.234, Test accuracy: 19.96 

Round 144, Global train loss: 2.250, Global test loss: 2.231, Global test accuracy: 20.43 

Round 145, Train loss: 2.246, Test loss: 2.233, Test accuracy: 19.84 

Round 145, Global train loss: 2.246, Global test loss: 2.231, Global test accuracy: 20.14 

Round 146, Train loss: 2.251, Test loss: 2.232, Test accuracy: 19.91 

Round 146, Global train loss: 2.251, Global test loss: 2.230, Global test accuracy: 20.31 

Round 147, Train loss: 2.245, Test loss: 2.231, Test accuracy: 19.78 

Round 147, Global train loss: 2.245, Global test loss: 2.229, Global test accuracy: 20.45 

Round 148, Train loss: 2.242, Test loss: 2.231, Test accuracy: 19.94 

Round 148, Global train loss: 2.242, Global test loss: 2.227, Global test accuracy: 20.35 

Round 149, Train loss: 2.245, Test loss: 2.229, Test accuracy: 19.85 

Round 149, Global train loss: 2.245, Global test loss: 2.225, Global test accuracy: 20.50 

Round 150, Train loss: 2.245, Test loss: 2.228, Test accuracy: 19.92 

Round 150, Global train loss: 2.245, Global test loss: 2.224, Global test accuracy: 20.06 

Round 151, Train loss: 2.250, Test loss: 2.227, Test accuracy: 19.78 

Round 151, Global train loss: 2.250, Global test loss: 2.224, Global test accuracy: 19.76 

Round 152, Train loss: 2.246, Test loss: 2.225, Test accuracy: 19.91 

Round 152, Global train loss: 2.246, Global test loss: 2.223, Global test accuracy: 20.19 

Round 153, Train loss: 2.244, Test loss: 2.224, Test accuracy: 20.18 

Round 153, Global train loss: 2.244, Global test loss: 2.221, Global test accuracy: 20.99 

Round 154, Train loss: 2.242, Test loss: 2.223, Test accuracy: 20.34 

Round 154, Global train loss: 2.242, Global test loss: 2.220, Global test accuracy: 20.32 

Round 155, Train loss: 2.241, Test loss: 2.222, Test accuracy: 20.35 

Round 155, Global train loss: 2.241, Global test loss: 2.219, Global test accuracy: 20.54 

Round 156, Train loss: 2.241, Test loss: 2.222, Test accuracy: 20.31 

Round 156, Global train loss: 2.241, Global test loss: 2.218, Global test accuracy: 20.88 

Round 157, Train loss: 2.239, Test loss: 2.221, Test accuracy: 20.38 

Round 157, Global train loss: 2.239, Global test loss: 2.216, Global test accuracy: 20.91 

Round 158, Train loss: 2.237, Test loss: 2.219, Test accuracy: 20.39 

Round 158, Global train loss: 2.237, Global test loss: 2.215, Global test accuracy: 20.65 

Round 159, Train loss: 2.245, Test loss: 2.217, Test accuracy: 20.39 

Round 159, Global train loss: 2.245, Global test loss: 2.213, Global test accuracy: 20.57 

Round 160, Train loss: 2.232, Test loss: 2.216, Test accuracy: 20.12 

Round 160, Global train loss: 2.232, Global test loss: 2.213, Global test accuracy: 20.87 

Round 161, Train loss: 2.236, Test loss: 2.215, Test accuracy: 20.28 

Round 161, Global train loss: 2.236, Global test loss: 2.212, Global test accuracy: 20.96 

Round 162, Train loss: 2.235, Test loss: 2.213, Test accuracy: 20.38 

Round 162, Global train loss: 2.235, Global test loss: 2.212, Global test accuracy: 21.28 

Round 163, Train loss: 2.236, Test loss: 2.212, Test accuracy: 20.54 

Round 163, Global train loss: 2.236, Global test loss: 2.212, Global test accuracy: 20.66 

Round 164, Train loss: 2.236, Test loss: 2.212, Test accuracy: 20.62 

Round 164, Global train loss: 2.236, Global test loss: 2.211, Global test accuracy: 20.42 

Round 165, Train loss: 2.227, Test loss: 2.212, Test accuracy: 20.66 

Round 165, Global train loss: 2.227, Global test loss: 2.211, Global test accuracy: 20.39 

Round 166, Train loss: 2.231, Test loss: 2.211, Test accuracy: 20.77 

Round 166, Global train loss: 2.231, Global test loss: 2.209, Global test accuracy: 20.77 

Round 167, Train loss: 2.232, Test loss: 2.210, Test accuracy: 20.70 

Round 167, Global train loss: 2.232, Global test loss: 2.208, Global test accuracy: 20.93 

Round 168, Train loss: 2.229, Test loss: 2.209, Test accuracy: 20.57 

Round 168, Global train loss: 2.229, Global test loss: 2.206, Global test accuracy: 20.46 

Round 169, Train loss: 2.231, Test loss: 2.207, Test accuracy: 20.36 

Round 169, Global train loss: 2.231, Global test loss: 2.205, Global test accuracy: 20.32 

Round 170, Train loss: 2.230, Test loss: 2.207, Test accuracy: 20.45 

Round 170, Global train loss: 2.230, Global test loss: 2.204, Global test accuracy: 20.42 

Round 171, Train loss: 2.232, Test loss: 2.205, Test accuracy: 20.41 

Round 171, Global train loss: 2.232, Global test loss: 2.203, Global test accuracy: 20.62 

Round 172, Train loss: 2.228, Test loss: 2.205, Test accuracy: 20.48 

Round 172, Global train loss: 2.228, Global test loss: 2.202, Global test accuracy: 20.35 

Round 173, Train loss: 2.227, Test loss: 2.204, Test accuracy: 20.35 

Round 173, Global train loss: 2.227, Global test loss: 2.202, Global test accuracy: 20.03 

Round 174, Train loss: 2.223, Test loss: 2.203, Test accuracy: 20.24 

Round 174, Global train loss: 2.223, Global test loss: 2.200, Global test accuracy: 20.27 

Round 175, Train loss: 2.234, Test loss: 2.202, Test accuracy: 20.32 

Round 175, Global train loss: 2.234, Global test loss: 2.201, Global test accuracy: 20.82 

Round 176, Train loss: 2.226, Test loss: 2.201, Test accuracy: 20.12 

Round 176, Global train loss: 2.226, Global test loss: 2.200, Global test accuracy: 20.49 

Round 177, Train loss: 2.221, Test loss: 2.200, Test accuracy: 20.28 

Round 177, Global train loss: 2.221, Global test loss: 2.199, Global test accuracy: 21.12 

Round 178, Train loss: 2.226, Test loss: 2.200, Test accuracy: 20.38 

Round 178, Global train loss: 2.226, Global test loss: 2.198, Global test accuracy: 21.16 

Round 179, Train loss: 2.218, Test loss: 2.199, Test accuracy: 20.74 

Round 179, Global train loss: 2.218, Global test loss: 2.197, Global test accuracy: 21.29 

Round 180, Train loss: 2.227, Test loss: 2.198, Test accuracy: 20.93 

Round 180, Global train loss: 2.227, Global test loss: 2.195, Global test accuracy: 21.02 

Round 181, Train loss: 2.231, Test loss: 2.197, Test accuracy: 21.05 

Round 181, Global train loss: 2.231, Global test loss: 2.194, Global test accuracy: 21.47 

Round 182, Train loss: 2.225, Test loss: 2.196, Test accuracy: 21.28 

Round 182, Global train loss: 2.225, Global test loss: 2.194, Global test accuracy: 21.35 

Round 183, Train loss: 2.217, Test loss: 2.196, Test accuracy: 21.04 

Round 183, Global train loss: 2.217, Global test loss: 2.193, Global test accuracy: 21.17 

Round 184, Train loss: 2.220, Test loss: 2.194, Test accuracy: 21.25 

Round 184, Global train loss: 2.220, Global test loss: 2.189, Global test accuracy: 21.65 

Round 185, Train loss: 2.219, Test loss: 2.192, Test accuracy: 21.64 

Round 185, Global train loss: 2.219, Global test loss: 2.186, Global test accuracy: 22.68 

Round 186, Train loss: 2.217, Test loss: 2.188, Test accuracy: 21.78 

Round 186, Global train loss: 2.217, Global test loss: 2.183, Global test accuracy: 22.17 

Round 187, Train loss: 2.218, Test loss: 2.187, Test accuracy: 21.54 

Round 187, Global train loss: 2.218, Global test loss: 2.182, Global test accuracy: 22.48 

Round 188, Train loss: 2.221, Test loss: 2.187, Test accuracy: 21.59 

Round 188, Global train loss: 2.221, Global test loss: 2.182, Global test accuracy: 22.27 

Round 189, Train loss: 2.222, Test loss: 2.184, Test accuracy: 21.78 

Round 189, Global train loss: 2.222, Global test loss: 2.181, Global test accuracy: 21.63 

Round 190, Train loss: 2.225, Test loss: 2.185, Test accuracy: 21.54 

Round 190, Global train loss: 2.225, Global test loss: 2.181, Global test accuracy: 21.22 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 21.09 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 17.32 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 14.94 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 14.29 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 13.38 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 12.19 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 12.19 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 10.61 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 10.61 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 10.61 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Average accuracy final 10 rounds: 10.0 

Average global accuracy final 10 rounds: 10.0 

8078.258389234543
[1.630859375, 2.977327585220337, 4.304571628570557, 5.642122030258179, 6.982874393463135, 8.313072681427002, 9.627411603927612, 10.944374561309814, 12.299662828445435, 13.535698652267456, 14.738281965255737, 15.94679856300354, 17.143015146255493, 18.348805904388428, 19.555720567703247, 20.744261741638184, 21.9437313079834, 23.105732917785645, 24.260148286819458, 25.431251049041748, 26.5958092212677, 27.868650913238525, 29.1393723487854, 30.44097590446472, 31.74286723136902, 33.04955840110779, 34.363242864608765, 35.66577863693237, 36.98609185218811, 38.304569482803345, 39.61857771873474, 40.93406534194946, 42.241586208343506, 43.548784255981445, 44.86048364639282, 46.17162537574768, 47.476810932159424, 48.79329252243042, 50.09515309333801, 51.404823780059814, 52.66776466369629, 53.93183994293213, 55.194127321243286, 56.45941209793091, 57.72498297691345, 58.995391845703125, 60.262595891952515, 61.52978038787842, 62.79577684402466, 64.06273651123047, 65.33351540565491, 66.59822297096252, 67.8669056892395, 69.13574075698853, 70.4011960029602, 71.66764569282532, 72.92949938774109, 74.19162797927856, 75.4541449546814, 76.7180118560791, 77.98032331466675, 79.24382972717285, 80.50595712661743, 81.61368441581726, 82.72187495231628, 83.82882571220398, 84.93429017066956, 86.04160523414612, 87.15217924118042, 88.26375269889832, 89.37614059448242, 90.48856711387634, 91.59532737731934, 92.70633029937744, 93.81980776786804, 94.93300724029541, 96.04431891441345, 97.1545979976654, 98.26704406738281, 99.3763689994812, 100.4886646270752, 101.59686398506165, 102.70603322982788, 103.81264758110046, 104.92211532592773, 106.03285336494446, 107.14357662200928, 108.24971604347229, 109.35972166061401, 110.46746706962585, 111.57637214660645, 112.68179273605347, 113.79364824295044, 114.9055564403534, 116.01948308944702, 117.13317608833313, 118.24922370910645, 119.36682772636414, 120.480539560318, 121.59342980384827, 122.70482444763184, 123.81632852554321, 124.92676401138306, 126.03762149810791, 127.14918422698975, 128.2574918270111, 129.36702680587769, 130.47862672805786, 131.5860514640808, 132.69526147842407, 133.80314326286316, 134.91107273101807, 136.02183938026428, 137.1341061592102, 138.24498844146729, 139.3548707962036, 140.46663165092468, 141.58084678649902, 142.69005632400513, 143.8056287765503, 144.92202520370483, 146.0393362045288, 147.15408086776733, 148.2638750076294, 149.37817764282227, 150.48967671394348, 151.60358357429504, 152.7154016494751, 153.82770442962646, 154.93808031082153, 156.0490484237671, 157.1583766937256, 158.26522874832153, 159.37621116638184, 160.48657131195068, 161.593829870224, 162.70541381835938, 163.81500577926636, 164.92363810539246, 166.03112173080444, 167.13662934303284, 168.24278473854065, 169.34774470329285, 170.4549081325531, 171.56214118003845, 172.67087531089783, 173.78500938415527, 174.89845514297485, 176.01425123214722, 177.12786674499512, 178.24069023132324, 179.35428738594055, 180.46812462806702, 181.5825216770172, 182.6932475566864, 183.80316257476807, 184.91275024414062, 186.02386474609375, 187.1269941329956, 188.23641324043274, 189.34242129325867, 190.44841504096985, 191.55953764915466, 192.67509269714355, 193.78542184829712, 194.89685940742493, 196.0068004131317, 197.1149139404297, 198.22215938568115, 199.3299150466919, 200.44418597221375, 201.55213356018066, 202.6634018421173, 203.77308440208435, 204.8836727142334, 205.99468779563904, 207.1063690185547, 208.21634817123413, 209.32601809501648, 210.43920922279358, 211.55075454711914, 212.6642289161682, 213.77716779708862, 214.8895387649536, 216.00085616111755, 217.11361241340637, 218.22483730316162, 219.3374102115631, 220.44709491729736, 221.55901741981506, 222.66630601882935, 223.78028512001038, 224.88553595542908, 225.99779605865479, 227.11416387557983, 228.22596430778503, 229.33858394622803, 230.45089197158813, 231.5667519569397, 232.68115234375, 233.79860091209412, 234.91210961341858, 236.02718210220337, 237.1453239917755, 238.260192155838, 239.37774777412415, 240.49530506134033, 241.60947155952454, 242.7242946624756, 243.83905744552612, 244.95502734184265, 246.0665578842163, 247.1835858821869, 248.29187178611755, 249.40685439109802, 250.5190646648407, 251.63458037376404, 252.75166749954224, 253.86899995803833, 254.98418021202087, 256.10202383995056, 257.2183151245117, 258.3324782848358, 259.448184967041, 260.5665738582611, 261.68231201171875, 262.794869184494, 263.9093165397644, 265.0224025249481, 266.1395800113678, 267.25103425979614, 268.364205121994, 269.47183108329773, 270.58894634246826, 271.6955487728119, 272.8089623451233, 273.9219694137573, 275.03123354911804, 276.1423296928406, 277.2549388408661, 278.36422395706177, 279.4702982902527, 280.57798433303833, 281.6846590042114, 282.789856672287, 283.9002740383148, 285.0084137916565, 286.11541414260864, 287.2209892272949, 288.3290479183197, 289.4382576942444, 290.54664373397827, 291.6515955924988, 292.7609443664551, 293.8702030181885, 294.97794795036316, 296.0934317111969, 297.2029414176941, 298.31569480895996, 299.42129707336426, 300.52526330947876, 301.63334441185, 302.7389042377472, 303.8427550792694, 304.9465699195862, 306.0530467033386, 307.15838623046875, 308.26353693008423, 309.37068033218384, 310.4792559146881, 311.58376121520996, 312.687703371048, 313.79162859916687, 314.89808225631714, 316.005708694458, 317.1123380661011, 318.22002601623535, 319.3269507884979, 320.43329977989197, 321.5399992465973, 322.64742732048035, 323.75458788871765, 324.86173391342163, 325.9683952331543, 327.0739743709564, 328.18327140808105, 329.2881455421448, 330.39754462242126, 331.5049669742584, 332.61068058013916, 333.71966767311096, 334.8213005065918, 335.92494559288025, 337.0291950702667, 338.13028478622437, 339.23704051971436, 340.3417794704437, 341.44730138778687, 342.5532875061035, 343.6593198776245, 345.8651351928711]
[9.925, 9.9925, 10.0325, 10.1575, 10.1775, 10.3125, 10.255, 10.42, 10.5825, 10.6525, 10.8275, 11.0975, 11.13, 10.775, 10.8025, 10.875, 10.9625, 11.155, 11.3825, 11.4725, 11.62, 11.6825, 11.5175, 11.325, 11.425, 11.525, 11.49, 11.715, 11.7575, 11.6525, 11.55, 11.62, 11.59, 11.795, 11.8675, 11.9175, 11.67, 11.82, 12.055, 12.245, 12.62, 12.55, 12.55, 12.515, 12.8225, 12.6775, 12.62, 12.72, 12.155, 11.815, 11.6925, 11.5125, 11.605, 11.795, 11.91, 11.8225, 11.895, 11.605, 11.5175, 11.535, 11.6675, 11.995, 12.005, 11.855, 11.905, 11.945, 12.165, 12.2425, 12.2875, 12.515, 12.5, 12.775, 12.9725, 13.075, 13.205, 13.2275, 13.3475, 13.4375, 13.5025, 13.795, 13.855, 13.9025, 14.38, 14.345, 14.2475, 14.265, 14.3075, 14.265, 14.2825, 14.1475, 14.1425, 14.195, 14.0375, 14.32, 14.5075, 14.735, 14.575, 14.52, 14.59, 14.485, 14.3975, 14.45, 14.7725, 15.045, 15.0675, 15.265, 15.8475, 16.4425, 16.765, 16.9175, 16.9475, 16.895, 16.9825, 17.4975, 17.52, 17.6575, 17.705, 17.85, 17.665, 17.485, 17.2475, 17.0425, 17.12, 17.3825, 17.67, 17.9875, 18.1175, 18.225, 18.2875, 18.0975, 18.02, 18.21, 18.4825, 18.4225, 18.5825, 18.94, 19.0775, 19.0625, 18.9975, 19.0825, 19.405, 19.695, 19.86, 19.9325, 19.965, 19.8425, 19.905, 19.78, 19.9425, 19.8525, 19.9175, 19.7825, 19.91, 20.185, 20.34, 20.3525, 20.3075, 20.3775, 20.395, 20.39, 20.1175, 20.28, 20.375, 20.54, 20.625, 20.665, 20.7675, 20.7025, 20.5725, 20.36, 20.4475, 20.415, 20.485, 20.3475, 20.2425, 20.325, 20.1175, 20.2825, 20.375, 20.7375, 20.9275, 21.055, 21.28, 21.035, 21.245, 21.635, 21.7825, 21.54, 21.595, 21.7775, 21.54, 21.09, 17.315, 14.935, 14.295, 13.385, 12.1875, 12.1875, 10.61, 10.61, 10.61, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.233, Test loss: 2.164, Test accuracy: 22.70 

Round   0, Global train loss: 2.233, Global test loss: 2.182, Global test accuracy: 22.98 

Round   1, Train loss: 2.067, Test loss: 2.052, Test accuracy: 26.25 

Round   1, Global train loss: 2.067, Global test loss: 2.066, Global test accuracy: 26.42 

Round   2, Train loss: 1.954, Test loss: 1.991, Test accuracy: 28.33 

Round   2, Global train loss: 1.954, Global test loss: 2.006, Global test accuracy: 29.73 

Round   3, Train loss: 1.834, Test loss: 1.925, Test accuracy: 29.96 

Round   3, Global train loss: 1.834, Global test loss: 1.929, Global test accuracy: 33.48 

Round   4, Train loss: 1.756, Test loss: 1.872, Test accuracy: 32.22 

Round   4, Global train loss: 1.756, Global test loss: 1.924, Global test accuracy: 35.11 

Round   5, Train loss: 1.696, Test loss: 1.817, Test accuracy: 33.51 

Round   5, Global train loss: 1.696, Global test loss: 1.900, Global test accuracy: 36.18 

Round   6, Train loss: 1.656, Test loss: 1.806, Test accuracy: 34.10 

Round   6, Global train loss: 1.656, Global test loss: 1.860, Global test accuracy: 37.40 

Round   7, Train loss: 1.622, Test loss: 1.757, Test accuracy: 36.23 

Round   7, Global train loss: 1.622, Global test loss: 1.826, Global test accuracy: 38.43 

Round   8, Train loss: 1.613, Test loss: 1.710, Test accuracy: 38.00 

Round   8, Global train loss: 1.613, Global test loss: 1.790, Global test accuracy: 39.55 

Round   9, Train loss: 1.557, Test loss: 1.652, Test accuracy: 39.74 

Round   9, Global train loss: 1.557, Global test loss: 1.757, Global test accuracy: 40.08 

Round  10, Train loss: 1.514, Test loss: 1.641, Test accuracy: 40.30 

Round  10, Global train loss: 1.514, Global test loss: 1.815, Global test accuracy: 40.33 

Round  11, Train loss: 1.498, Test loss: 1.634, Test accuracy: 40.49 

Round  11, Global train loss: 1.498, Global test loss: 1.740, Global test accuracy: 41.40 

Round  12, Train loss: 1.430, Test loss: 1.604, Test accuracy: 42.10 

Round  12, Global train loss: 1.430, Global test loss: 1.738, Global test accuracy: 42.43 

Round  13, Train loss: 1.427, Test loss: 1.597, Test accuracy: 42.55 

Round  13, Global train loss: 1.427, Global test loss: 1.718, Global test accuracy: 43.05 

Round  14, Train loss: 1.405, Test loss: 1.541, Test accuracy: 44.43 

Round  14, Global train loss: 1.405, Global test loss: 1.770, Global test accuracy: 43.40 

Round  15, Train loss: 1.390, Test loss: 1.521, Test accuracy: 45.46 

Round  15, Global train loss: 1.390, Global test loss: 1.680, Global test accuracy: 43.84 

Round  16, Train loss: 1.336, Test loss: 1.497, Test accuracy: 46.39 

Round  16, Global train loss: 1.336, Global test loss: 1.724, Global test accuracy: 43.66 

Round  17, Train loss: 1.333, Test loss: 1.485, Test accuracy: 47.51 

Round  17, Global train loss: 1.333, Global test loss: 1.694, Global test accuracy: 44.59 

Round  18, Train loss: 1.266, Test loss: 1.487, Test accuracy: 47.68 

Round  18, Global train loss: 1.266, Global test loss: 1.714, Global test accuracy: 44.59 

Round  19, Train loss: 1.267, Test loss: 1.480, Test accuracy: 48.15 

Round  19, Global train loss: 1.267, Global test loss: 1.703, Global test accuracy: 45.30 

Round  20, Train loss: 1.230, Test loss: 1.462, Test accuracy: 48.67 

Round  20, Global train loss: 1.230, Global test loss: 1.644, Global test accuracy: 45.42 

Round  21, Train loss: 1.240, Test loss: 1.439, Test accuracy: 49.59 

Round  21, Global train loss: 1.240, Global test loss: 1.670, Global test accuracy: 45.47 

Round  22, Train loss: 1.185, Test loss: 1.441, Test accuracy: 49.63 

Round  22, Global train loss: 1.185, Global test loss: 1.670, Global test accuracy: 46.17 

Round  23, Train loss: 1.166, Test loss: 1.445, Test accuracy: 50.00 

Round  23, Global train loss: 1.166, Global test loss: 1.674, Global test accuracy: 45.90 

Round  24, Train loss: 1.163, Test loss: 1.432, Test accuracy: 50.73 

Round  24, Global train loss: 1.163, Global test loss: 1.660, Global test accuracy: 46.90 

Round  25, Train loss: 1.172, Test loss: 1.429, Test accuracy: 51.09 

Round  25, Global train loss: 1.172, Global test loss: 1.691, Global test accuracy: 46.90 

Round  26, Train loss: 1.102, Test loss: 1.438, Test accuracy: 51.16 

Round  26, Global train loss: 1.102, Global test loss: 1.682, Global test accuracy: 46.92 

Round  27, Train loss: 1.107, Test loss: 1.437, Test accuracy: 51.24 

Round  27, Global train loss: 1.107, Global test loss: 1.613, Global test accuracy: 47.02 

Round  28, Train loss: 1.088, Test loss: 1.422, Test accuracy: 52.02 

Round  28, Global train loss: 1.088, Global test loss: 1.612, Global test accuracy: 47.68 

Round  29, Train loss: 1.053, Test loss: 1.403, Test accuracy: 52.62 

Round  29, Global train loss: 1.053, Global test loss: 1.740, Global test accuracy: 48.13 

Round  30, Train loss: 1.110, Test loss: 1.400, Test accuracy: 53.06 

Round  30, Global train loss: 1.110, Global test loss: 1.700, Global test accuracy: 47.61 

Round  31, Train loss: 1.071, Test loss: 1.402, Test accuracy: 53.41 

Round  31, Global train loss: 1.071, Global test loss: 1.648, Global test accuracy: 48.36 

Round  32, Train loss: 1.036, Test loss: 1.393, Test accuracy: 53.74 

Round  32, Global train loss: 1.036, Global test loss: 1.563, Global test accuracy: 48.38 

Round  33, Train loss: 1.001, Test loss: 1.396, Test accuracy: 53.84 

Round  33, Global train loss: 1.001, Global test loss: 1.641, Global test accuracy: 47.73 

Round  34, Train loss: 1.010, Test loss: 1.409, Test accuracy: 53.70 

Round  34, Global train loss: 1.010, Global test loss: 1.668, Global test accuracy: 47.41 

Round  35, Train loss: 0.964, Test loss: 1.432, Test accuracy: 53.50 

Round  35, Global train loss: 0.964, Global test loss: 1.665, Global test accuracy: 47.75 

Round  36, Train loss: 0.955, Test loss: 1.418, Test accuracy: 53.99 

Round  36, Global train loss: 0.955, Global test loss: 1.620, Global test accuracy: 48.72 

Round  37, Train loss: 0.949, Test loss: 1.410, Test accuracy: 54.38 

Round  37, Global train loss: 0.949, Global test loss: 1.693, Global test accuracy: 48.44 

Round  38, Train loss: 0.913, Test loss: 1.422, Test accuracy: 54.35 

Round  38, Global train loss: 0.913, Global test loss: 1.603, Global test accuracy: 49.03 

Round  39, Train loss: 0.929, Test loss: 1.424, Test accuracy: 54.59 

Round  39, Global train loss: 0.929, Global test loss: 1.650, Global test accuracy: 48.80 

Round  40, Train loss: 0.923, Test loss: 1.437, Test accuracy: 54.91 

Round  40, Global train loss: 0.923, Global test loss: 1.685, Global test accuracy: 49.23 

Round  41, Train loss: 0.838, Test loss: 1.446, Test accuracy: 55.09 

Round  41, Global train loss: 0.838, Global test loss: 1.657, Global test accuracy: 49.47 

Round  42, Train loss: 0.911, Test loss: 1.435, Test accuracy: 55.51 

Round  42, Global train loss: 0.911, Global test loss: 1.637, Global test accuracy: 49.00 

Round  43, Train loss: 0.845, Test loss: 1.418, Test accuracy: 55.88 

Round  43, Global train loss: 0.845, Global test loss: 1.649, Global test accuracy: 50.05 

Round  44, Train loss: 0.824, Test loss: 1.455, Test accuracy: 55.49 

Round  44, Global train loss: 0.824, Global test loss: 1.796, Global test accuracy: 49.13 

Round  45, Train loss: 0.860, Test loss: 1.431, Test accuracy: 56.08 

Round  45, Global train loss: 0.860, Global test loss: 1.640, Global test accuracy: 49.48 

Round  46, Train loss: 0.804, Test loss: 1.438, Test accuracy: 56.08 

Round  46, Global train loss: 0.804, Global test loss: 1.637, Global test accuracy: 49.10 

Round  47, Train loss: 0.799, Test loss: 1.435, Test accuracy: 56.22 

Round  47, Global train loss: 0.799, Global test loss: 1.664, Global test accuracy: 49.41 

Round  48, Train loss: 0.785, Test loss: 1.443, Test accuracy: 56.06 

Round  48, Global train loss: 0.785, Global test loss: 1.669, Global test accuracy: 49.86 

Round  49, Train loss: 0.791, Test loss: 1.447, Test accuracy: 56.16 

Round  49, Global train loss: 0.791, Global test loss: 1.694, Global test accuracy: 49.64 

Round  50, Train loss: 0.772, Test loss: 1.449, Test accuracy: 56.20 

Round  50, Global train loss: 0.772, Global test loss: 1.859, Global test accuracy: 50.34 

Round  51, Train loss: 0.817, Test loss: 1.448, Test accuracy: 56.66 

Round  51, Global train loss: 0.817, Global test loss: 1.684, Global test accuracy: 49.95 

Round  52, Train loss: 0.789, Test loss: 1.429, Test accuracy: 57.12 

Round  52, Global train loss: 0.789, Global test loss: 1.645, Global test accuracy: 50.01 

Round  53, Train loss: 0.743, Test loss: 1.433, Test accuracy: 57.44 

Round  53, Global train loss: 0.743, Global test loss: 1.667, Global test accuracy: 50.24 

Round  54, Train loss: 0.805, Test loss: 1.435, Test accuracy: 57.33 

Round  54, Global train loss: 0.805, Global test loss: 1.630, Global test accuracy: 50.27 

Round  55, Train loss: 0.708, Test loss: 1.433, Test accuracy: 57.57 

Round  55, Global train loss: 0.708, Global test loss: 1.700, Global test accuracy: 49.86 

Round  56, Train loss: 0.728, Test loss: 1.447, Test accuracy: 57.58 

Round  56, Global train loss: 0.728, Global test loss: 1.701, Global test accuracy: 49.53 

Round  57, Train loss: 0.746, Test loss: 1.459, Test accuracy: 57.53 

Round  57, Global train loss: 0.746, Global test loss: 1.796, Global test accuracy: 50.55 

Round  58, Train loss: 0.722, Test loss: 1.448, Test accuracy: 57.83 

Round  58, Global train loss: 0.722, Global test loss: 1.734, Global test accuracy: 49.97 

Round  59, Train loss: 0.720, Test loss: 1.446, Test accuracy: 58.09 

Round  59, Global train loss: 0.720, Global test loss: 1.726, Global test accuracy: 50.37 

Round  60, Train loss: 0.665, Test loss: 1.470, Test accuracy: 57.65 

Round  60, Global train loss: 0.665, Global test loss: 1.844, Global test accuracy: 50.81 

Round  61, Train loss: 0.696, Test loss: 1.485, Test accuracy: 57.89 

Round  61, Global train loss: 0.696, Global test loss: 1.737, Global test accuracy: 50.59 

Round  62, Train loss: 0.681, Test loss: 1.492, Test accuracy: 58.08 

Round  62, Global train loss: 0.681, Global test loss: 1.789, Global test accuracy: 50.02 

Round  63, Train loss: 0.679, Test loss: 1.504, Test accuracy: 57.98 

Round  63, Global train loss: 0.679, Global test loss: 1.858, Global test accuracy: 49.70 

Round  64, Train loss: 0.690, Test loss: 1.479, Test accuracy: 58.35 

Round  64, Global train loss: 0.690, Global test loss: 1.786, Global test accuracy: 50.71 

Round  65, Train loss: 0.627, Test loss: 1.469, Test accuracy: 58.70 

Round  65, Global train loss: 0.627, Global test loss: 1.790, Global test accuracy: 50.69 

Round  66, Train loss: 0.636, Test loss: 1.481, Test accuracy: 58.54 

Round  66, Global train loss: 0.636, Global test loss: 1.756, Global test accuracy: 50.10 

Round  67, Train loss: 0.583, Test loss: 1.497, Test accuracy: 58.45 

Round  67, Global train loss: 0.583, Global test loss: 1.934, Global test accuracy: 50.92 

Round  68, Train loss: 0.622, Test loss: 1.497, Test accuracy: 58.35 

Round  68, Global train loss: 0.622, Global test loss: 1.944, Global test accuracy: 50.43 

Round  69, Train loss: 0.639, Test loss: 1.504, Test accuracy: 58.28 

Round  69, Global train loss: 0.639, Global test loss: 1.791, Global test accuracy: 51.12 

Round  70, Train loss: 0.650, Test loss: 1.491, Test accuracy: 58.53 

Round  70, Global train loss: 0.650, Global test loss: 1.849, Global test accuracy: 50.49 

Round  71, Train loss: 0.567, Test loss: 1.506, Test accuracy: 58.39 

Round  71, Global train loss: 0.567, Global test loss: 1.899, Global test accuracy: 50.69 

Round  72, Train loss: 0.630, Test loss: 1.518, Test accuracy: 58.49 

Round  72, Global train loss: 0.630, Global test loss: 1.744, Global test accuracy: 50.81 

Round  73, Train loss: 0.577, Test loss: 1.526, Test accuracy: 58.64 

Round  73, Global train loss: 0.577, Global test loss: 1.819, Global test accuracy: 50.54 

Round  74, Train loss: 0.641, Test loss: 1.562, Test accuracy: 58.32 

Round  74, Global train loss: 0.641, Global test loss: 1.900, Global test accuracy: 51.10 

Round  75, Train loss: 0.685, Test loss: 1.546, Test accuracy: 58.69 

Round  75, Global train loss: 0.685, Global test loss: 1.883, Global test accuracy: 51.10 

Round  76, Train loss: 0.605, Test loss: 1.547, Test accuracy: 58.61 

Round  76, Global train loss: 0.605, Global test loss: 1.801, Global test accuracy: 50.88 

Round  77, Train loss: 0.600, Test loss: 1.558, Test accuracy: 58.54 

Round  77, Global train loss: 0.600, Global test loss: 1.916, Global test accuracy: 50.78 

Round  78, Train loss: 0.639, Test loss: 1.570, Test accuracy: 58.43 

Round  78, Global train loss: 0.639, Global test loss: 1.806, Global test accuracy: 50.53 

Round  79, Train loss: 0.602, Test loss: 1.570, Test accuracy: 58.70 

Round  79, Global train loss: 0.602, Global test loss: 1.910, Global test accuracy: 50.94 

Round  80, Train loss: 0.603, Test loss: 1.563, Test accuracy: 59.08 

Round  80, Global train loss: 0.603, Global test loss: 1.875, Global test accuracy: 50.91 

Round  81, Train loss: 0.611, Test loss: 1.559, Test accuracy: 59.21 

Round  81, Global train loss: 0.611, Global test loss: 1.861, Global test accuracy: 51.03 

Round  82, Train loss: 0.582, Test loss: 1.538, Test accuracy: 59.57 

Round  82, Global train loss: 0.582, Global test loss: 1.877, Global test accuracy: 51.68 

Round  83, Train loss: 0.578, Test loss: 1.539, Test accuracy: 59.77 

Round  83, Global train loss: 0.578, Global test loss: 1.784, Global test accuracy: 51.42 

Round  84, Train loss: 0.577, Test loss: 1.545, Test accuracy: 59.57 

Round  84, Global train loss: 0.577, Global test loss: 1.864, Global test accuracy: 50.84 

Round  85, Train loss: 0.562, Test loss: 1.550, Test accuracy: 59.75 

Round  85, Global train loss: 0.562, Global test loss: 1.897, Global test accuracy: 51.29 

Round  86, Train loss: 0.569, Test loss: 1.556, Test accuracy: 59.78 

Round  86, Global train loss: 0.569, Global test loss: 1.950, Global test accuracy: 50.54 

Round  87, Train loss: 0.540, Test loss: 1.556, Test accuracy: 59.89 

Round  87, Global train loss: 0.540, Global test loss: 1.934, Global test accuracy: 51.34 

Round  88, Train loss: 0.592, Test loss: 1.575, Test accuracy: 59.69 

Round  88, Global train loss: 0.592, Global test loss: 1.838, Global test accuracy: 51.04 

Round  89, Train loss: 0.537, Test loss: 1.584, Test accuracy: 59.82 

Round  89, Global train loss: 0.537, Global test loss: 1.837, Global test accuracy: 51.43 

Round  90, Train loss: 0.515, Test loss: 1.582, Test accuracy: 59.85 

Round  90, Global train loss: 0.515, Global test loss: 1.888, Global test accuracy: 51.38 

Round  91, Train loss: 0.555, Test loss: 1.591, Test accuracy: 59.94 

Round  91, Global train loss: 0.555, Global test loss: 1.819, Global test accuracy: 50.96 

Round  92, Train loss: 0.541, Test loss: 1.580, Test accuracy: 60.13 

Round  92, Global train loss: 0.541, Global test loss: 1.966, Global test accuracy: 51.72 

Round  93, Train loss: 0.561, Test loss: 1.598, Test accuracy: 59.92 

Round  93, Global train loss: 0.561, Global test loss: 1.841, Global test accuracy: 50.91 

Round  94, Train loss: 0.509, Test loss: 1.597, Test accuracy: 59.85 

Round  94, Global train loss: 0.509, Global test loss: 2.075, Global test accuracy: 51.22 

Round  95, Train loss: 0.548, Test loss: 1.606, Test accuracy: 59.63 

Round  95, Global train loss: 0.548, Global test loss: 1.796, Global test accuracy: 50.99 

Round  96, Train loss: 0.518, Test loss: 1.610, Test accuracy: 59.80 

Round  96, Global train loss: 0.518, Global test loss: 1.899, Global test accuracy: 51.03 

Round  97, Train loss: 0.533, Test loss: 1.599, Test accuracy: 59.95 

Round  97, Global train loss: 0.533, Global test loss: 1.845, Global test accuracy: 51.11 

Round  98, Train loss: 0.509, Test loss: 1.594, Test accuracy: 59.82 

Round  98, Global train loss: 0.509, Global test loss: 1.921, Global test accuracy: 51.38 

Round  99, Train loss: 0.480, Test loss: 1.588, Test accuracy: 60.14 

Round  99, Global train loss: 0.480, Global test loss: 2.074, Global test accuracy: 51.48 

Final Round, Train loss: 0.396, Test loss: 1.779, Test accuracy: 59.72 

Final Round, Global train loss: 0.396, Global test loss: 2.074, Global test accuracy: 51.48 

Average accuracy final 10 rounds: 59.90375 

Average global accuracy final 10 rounds: 51.21825 

2686.8764939308167
[1.3868060111999512, 2.562180280685425, 3.7505390644073486, 4.915131092071533, 6.076842308044434, 7.248243570327759, 8.408397436141968, 9.568053245544434, 10.735430240631104, 11.90587067604065, 13.080509424209595, 14.241061449050903, 15.406361103057861, 16.584139585494995, 17.745861530303955, 18.90742325782776, 20.063408136367798, 21.2346830368042, 22.40706205368042, 23.60630512237549, 24.77591633796692, 25.947682857513428, 26.9832661151886, 28.01658821105957, 29.051257610321045, 30.087300062179565, 31.277133226394653, 32.442882776260376, 33.552494049072266, 34.732728719711304, 35.89576959609985, 37.059977769851685, 38.22350096702576, 39.39003300666809, 40.58052897453308, 41.762545108795166, 42.949790477752686, 44.135624408721924, 45.30869221687317, 46.48690724372864, 47.673293113708496, 48.86001467704773, 50.058677196502686, 51.239821672439575, 52.427852153778076, 53.6111114025116, 54.796839475631714, 55.979822635650635, 57.157707929611206, 58.33795094490051, 59.51538705825806, 60.688655614852905, 61.868218421936035, 63.04313063621521, 64.22527050971985, 65.40257453918457, 66.57761096954346, 67.75444602966309, 68.93335008621216, 70.11197996139526, 71.289391040802, 72.46917200088501, 73.64392471313477, 74.82436466217041, 75.99985694885254, 77.18526220321655, 78.34884810447693, 79.50737476348877, 80.69250154495239, 81.87124443054199, 83.05216526985168, 84.22680115699768, 85.41068625450134, 86.58277153968811, 87.76445174217224, 88.94040083885193, 90.1159610748291, 91.29365062713623, 92.4635910987854, 93.6458899974823, 94.8181037902832, 95.99866676330566, 97.1699492931366, 98.3574869632721, 99.52978444099426, 100.70447897911072, 101.70713257789612, 102.70257258415222, 103.69677591323853, 104.69302034378052, 105.69168949127197, 106.68441271781921, 107.68081855773926, 108.68736529350281, 109.69892740249634, 110.70285367965698, 111.71239590644836, 112.72105383872986, 113.73097658157349, 114.73401284217834, 116.77790141105652]
[22.7, 26.255, 28.3275, 29.9575, 32.2175, 33.51, 34.1025, 36.235, 38.0, 39.745, 40.3, 40.495, 42.1, 42.5475, 44.4275, 45.4625, 46.3925, 47.505, 47.6775, 48.15, 48.675, 49.59, 49.635, 50.0, 50.725, 51.095, 51.1625, 51.24, 52.015, 52.62, 53.0575, 53.4075, 53.7425, 53.8425, 53.7, 53.5025, 53.9925, 54.375, 54.355, 54.595, 54.9125, 55.085, 55.5075, 55.8775, 55.495, 56.075, 56.075, 56.22, 56.0575, 56.1575, 56.1975, 56.66, 57.12, 57.4375, 57.3325, 57.5725, 57.575, 57.5275, 57.83, 58.095, 57.645, 57.89, 58.08, 57.9825, 58.35, 58.6975, 58.54, 58.445, 58.3525, 58.2775, 58.5325, 58.39, 58.4925, 58.64, 58.3225, 58.685, 58.6125, 58.54, 58.43, 58.6975, 59.075, 59.21, 59.57, 59.7725, 59.57, 59.7525, 59.7775, 59.8875, 59.6925, 59.8225, 59.8475, 59.94, 60.13, 59.9225, 59.8475, 59.6325, 59.805, 59.9525, 59.82, 60.14, 59.7175]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.487, Test loss: 2.041, Test accuracy: 26.18 

Round   1, Train loss: 0.947, Test loss: 1.654, Test accuracy: 43.23 

Round   2, Train loss: 0.849, Test loss: 1.401, Test accuracy: 48.51 

Round   3, Train loss: 0.794, Test loss: 1.124, Test accuracy: 55.17 

Round   4, Train loss: 0.778, Test loss: 0.936, Test accuracy: 59.85 

Round   5, Train loss: 0.831, Test loss: 0.818, Test accuracy: 62.60 

Round   6, Train loss: 0.655, Test loss: 0.771, Test accuracy: 66.12 

Round   7, Train loss: 0.658, Test loss: 0.683, Test accuracy: 68.66 

Round   8, Train loss: 0.625, Test loss: 0.657, Test accuracy: 69.96 

Round   9, Train loss: 0.616, Test loss: 0.640, Test accuracy: 70.99 

Round  10, Train loss: 0.627, Test loss: 0.616, Test accuracy: 72.09 

Round  11, Train loss: 0.612, Test loss: 0.596, Test accuracy: 73.89 

Round  12, Train loss: 0.604, Test loss: 0.581, Test accuracy: 74.69 

Round  13, Train loss: 0.550, Test loss: 0.573, Test accuracy: 75.59 

Round  14, Train loss: 0.546, Test loss: 0.573, Test accuracy: 75.36 

Round  15, Train loss: 0.577, Test loss: 0.540, Test accuracy: 76.80 

Round  16, Train loss: 0.556, Test loss: 0.528, Test accuracy: 77.32 

Round  17, Train loss: 0.520, Test loss: 0.531, Test accuracy: 77.88 

Round  18, Train loss: 0.446, Test loss: 0.513, Test accuracy: 78.39 

Round  19, Train loss: 0.531, Test loss: 0.529, Test accuracy: 77.61 

Round  20, Train loss: 0.484, Test loss: 0.512, Test accuracy: 77.80 

Round  21, Train loss: 0.499, Test loss: 0.500, Test accuracy: 78.63 

Round  22, Train loss: 0.444, Test loss: 0.491, Test accuracy: 79.58 

Round  23, Train loss: 0.493, Test loss: 0.493, Test accuracy: 79.19 

Round  24, Train loss: 0.462, Test loss: 0.483, Test accuracy: 79.83 

Round  25, Train loss: 0.490, Test loss: 0.489, Test accuracy: 79.22 

Round  26, Train loss: 0.472, Test loss: 0.475, Test accuracy: 80.36 

Round  27, Train loss: 0.424, Test loss: 0.474, Test accuracy: 80.08 

Round  28, Train loss: 0.412, Test loss: 0.477, Test accuracy: 80.30 

Round  29, Train loss: 0.426, Test loss: 0.467, Test accuracy: 80.48 

Round  30, Train loss: 0.529, Test loss: 0.458, Test accuracy: 80.53 

Round  31, Train loss: 0.419, Test loss: 0.460, Test accuracy: 80.41 

Round  32, Train loss: 0.375, Test loss: 0.447, Test accuracy: 80.79 

Round  33, Train loss: 0.434, Test loss: 0.447, Test accuracy: 80.92 

Round  34, Train loss: 0.400, Test loss: 0.442, Test accuracy: 81.09 

Round  35, Train loss: 0.410, Test loss: 0.437, Test accuracy: 81.46 

Round  36, Train loss: 0.373, Test loss: 0.438, Test accuracy: 81.52 

Round  37, Train loss: 0.366, Test loss: 0.441, Test accuracy: 81.49 

Round  38, Train loss: 0.451, Test loss: 0.435, Test accuracy: 81.90 

Round  39, Train loss: 0.462, Test loss: 0.433, Test accuracy: 81.71 

Round  40, Train loss: 0.389, Test loss: 0.428, Test accuracy: 82.26 

Round  41, Train loss: 0.366, Test loss: 0.429, Test accuracy: 81.91 

Round  42, Train loss: 0.369, Test loss: 0.422, Test accuracy: 82.47 

Round  43, Train loss: 0.330, Test loss: 0.425, Test accuracy: 82.11 

Round  44, Train loss: 0.369, Test loss: 0.411, Test accuracy: 82.81 

Round  45, Train loss: 0.470, Test loss: 0.408, Test accuracy: 83.01 

Round  46, Train loss: 0.316, Test loss: 0.407, Test accuracy: 83.13 

Round  47, Train loss: 0.334, Test loss: 0.414, Test accuracy: 83.11 

Round  48, Train loss: 0.319, Test loss: 0.409, Test accuracy: 83.38 

Round  49, Train loss: 0.435, Test loss: 0.406, Test accuracy: 83.37 

Round  50, Train loss: 0.363, Test loss: 0.409, Test accuracy: 83.17 

Round  51, Train loss: 0.309, Test loss: 0.401, Test accuracy: 83.50 

Round  52, Train loss: 0.287, Test loss: 0.397, Test accuracy: 83.51 

Round  53, Train loss: 0.316, Test loss: 0.403, Test accuracy: 83.38 

Round  54, Train loss: 0.372, Test loss: 0.403, Test accuracy: 83.33 

Round  55, Train loss: 0.396, Test loss: 0.403, Test accuracy: 83.08 

Round  56, Train loss: 0.367, Test loss: 0.398, Test accuracy: 83.62 

Round  57, Train loss: 0.329, Test loss: 0.404, Test accuracy: 83.36 

Round  58, Train loss: 0.315, Test loss: 0.401, Test accuracy: 83.42 

Round  59, Train loss: 0.371, Test loss: 0.405, Test accuracy: 83.36 

Round  60, Train loss: 0.320, Test loss: 0.406, Test accuracy: 83.55 

Round  61, Train loss: 0.408, Test loss: 0.408, Test accuracy: 83.25 

Round  62, Train loss: 0.326, Test loss: 0.403, Test accuracy: 83.53 

Round  63, Train loss: 0.350, Test loss: 0.399, Test accuracy: 83.56 

Round  64, Train loss: 0.362, Test loss: 0.411, Test accuracy: 83.08 

Round  65, Train loss: 0.322, Test loss: 0.403, Test accuracy: 83.43 

Round  66, Train loss: 0.325, Test loss: 0.390, Test accuracy: 84.22 

Round  67, Train loss: 0.326, Test loss: 0.392, Test accuracy: 84.03 

Round  68, Train loss: 0.352, Test loss: 0.387, Test accuracy: 84.19 

Round  69, Train loss: 0.305, Test loss: 0.391, Test accuracy: 84.03 

Round  70, Train loss: 0.280, Test loss: 0.388, Test accuracy: 84.11 

Round  71, Train loss: 0.367, Test loss: 0.398, Test accuracy: 84.07 

Round  72, Train loss: 0.275, Test loss: 0.381, Test accuracy: 84.42 

Round  73, Train loss: 0.278, Test loss: 0.383, Test accuracy: 84.88 

Round  74, Train loss: 0.343, Test loss: 0.380, Test accuracy: 84.66 

Round  75, Train loss: 0.297, Test loss: 0.391, Test accuracy: 84.03 

Round  76, Train loss: 0.278, Test loss: 0.389, Test accuracy: 84.35 

Round  77, Train loss: 0.271, Test loss: 0.384, Test accuracy: 84.71 

Round  78, Train loss: 0.285, Test loss: 0.383, Test accuracy: 84.78 

Round  79, Train loss: 0.274, Test loss: 0.376, Test accuracy: 85.03 

Round  80, Train loss: 0.277, Test loss: 0.384, Test accuracy: 84.77 

Round  81, Train loss: 0.253, Test loss: 0.377, Test accuracy: 84.84 

Round  82, Train loss: 0.301, Test loss: 0.376, Test accuracy: 84.93 

Round  83, Train loss: 0.288, Test loss: 0.377, Test accuracy: 84.93 

Round  84, Train loss: 0.230, Test loss: 0.384, Test accuracy: 85.08 

Round  85, Train loss: 0.258, Test loss: 0.380, Test accuracy: 85.22 

Round  86, Train loss: 0.247, Test loss: 0.376, Test accuracy: 85.17 

Round  87, Train loss: 0.272, Test loss: 0.377, Test accuracy: 85.08 

Round  88, Train loss: 0.230, Test loss: 0.386, Test accuracy: 84.83 

Round  89, Train loss: 0.235, Test loss: 0.386, Test accuracy: 84.88 

Round  90, Train loss: 0.295, Test loss: 0.382, Test accuracy: 84.59 

Round  91, Train loss: 0.226, Test loss: 0.376, Test accuracy: 85.21 

Round  92, Train loss: 0.291, Test loss: 0.386, Test accuracy: 85.06 

Round  93, Train loss: 0.265, Test loss: 0.382, Test accuracy: 85.36 

Round  94, Train loss: 0.207, Test loss: 0.385, Test accuracy: 85.14 

Round  95, Train loss: 0.273, Test loss: 0.383, Test accuracy: 85.06 

Round  96, Train loss: 0.243, Test loss: 0.381, Test accuracy: 85.17 

Round  97, Train loss: 0.211, Test loss: 0.386, Test accuracy: 85.23 

Round  98, Train loss: 0.283, Test loss: 0.387, Test accuracy: 85.28 

Round  99, Train loss: 0.235, Test loss: 0.385, Test accuracy: 85.53 

Final Round, Train loss: 0.208, Test loss: 0.381, Test accuracy: 85.41 

Average accuracy final 10 rounds: 85.1625 

961.0184938907623
[1.4200356006622314, 2.4800095558166504, 3.541705369949341, 4.605197906494141, 5.653068780899048, 6.707156658172607, 7.754563570022583, 8.796928405761719, 9.844979763031006, 10.896888971328735, 11.945740699768066, 12.992922306060791, 14.045911312103271, 15.099173784255981, 16.158673763275146, 17.209274291992188, 18.261537075042725, 19.310250282287598, 20.363049745559692, 21.42271900177002, 22.480645656585693, 23.533029556274414, 24.58623433113098, 25.633981943130493, 26.725135803222656, 27.778130054473877, 28.836748600006104, 29.895474910736084, 30.94556188583374, 31.998032093048096, 33.053619384765625, 34.102582931518555, 35.1563618183136, 36.206241846084595, 37.25815749168396, 38.308714866638184, 39.36027765274048, 40.41241216659546, 41.46924662590027, 42.51588749885559, 43.56733798980713, 44.62821626663208, 45.68464684486389, 46.744550943374634, 47.797481298446655, 48.84713339805603, 49.9081072807312, 50.958868741989136, 52.01549553871155, 53.07712364196777, 54.13199067115784, 55.18669533729553, 56.24117112159729, 57.29950833320618, 58.35581350326538, 59.404428482055664, 60.4508695602417, 61.51222801208496, 62.56661653518677, 63.616660356521606, 64.66473817825317, 65.72168111801147, 66.77779507637024, 67.83314418792725, 68.88635611534119, 69.93797183036804, 70.98367667198181, 72.03154826164246, 73.08634686470032, 74.14381122589111, 75.20092177391052, 76.25509881973267, 77.30724477767944, 78.36077237129211, 79.41922354698181, 80.47135806083679, 81.5255708694458, 82.57883667945862, 83.63225960731506, 84.68633818626404, 85.73122525215149, 86.78632116317749, 87.83816623687744, 88.89208436012268, 89.94840216636658, 90.99301171302795, 92.04122972488403, 93.10059642791748, 94.15649724006653, 95.20985674858093, 96.25866985321045, 97.30957651138306, 98.36855363845825, 99.42277717590332, 100.47821140289307, 101.52958583831787, 102.58357572555542, 103.63207268714905, 104.68340587615967, 105.7394187450409, 107.62453365325928]
[26.175, 43.225, 48.50833333333333, 55.166666666666664, 59.85, 62.6, 66.125, 68.65833333333333, 69.95833333333333, 70.99166666666666, 72.09166666666667, 73.89166666666667, 74.69166666666666, 75.59166666666667, 75.35833333333333, 76.8, 77.31666666666666, 77.88333333333334, 78.39166666666667, 77.60833333333333, 77.8, 78.63333333333334, 79.58333333333333, 79.19166666666666, 79.825, 79.21666666666667, 80.35833333333333, 80.08333333333333, 80.3, 80.48333333333333, 80.53333333333333, 80.40833333333333, 80.79166666666667, 80.925, 81.09166666666667, 81.45833333333333, 81.51666666666667, 81.49166666666666, 81.9, 81.70833333333333, 82.25833333333334, 81.90833333333333, 82.46666666666667, 82.10833333333333, 82.80833333333334, 83.00833333333334, 83.13333333333334, 83.10833333333333, 83.375, 83.36666666666666, 83.16666666666667, 83.5, 83.50833333333334, 83.375, 83.325, 83.075, 83.61666666666666, 83.35833333333333, 83.425, 83.35833333333333, 83.55, 83.25, 83.53333333333333, 83.55833333333334, 83.075, 83.43333333333334, 84.225, 84.025, 84.19166666666666, 84.025, 84.10833333333333, 84.06666666666666, 84.425, 84.88333333333334, 84.65833333333333, 84.025, 84.35, 84.70833333333333, 84.78333333333333, 85.025, 84.76666666666667, 84.84166666666667, 84.93333333333334, 84.93333333333334, 85.075, 85.21666666666667, 85.16666666666667, 85.075, 84.83333333333333, 84.88333333333334, 84.59166666666667, 85.20833333333333, 85.05833333333334, 85.35833333333333, 85.14166666666667, 85.05833333333334, 85.16666666666667, 85.23333333333333, 85.28333333333333, 85.525, 85.40833333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307832
307842
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.554, Test loss: 2.127, Test accuracy: 28.24
Round   1, Train loss: 1.005, Test loss: 1.633, Test accuracy: 42.48
Round   2, Train loss: 0.932, Test loss: 1.524, Test accuracy: 47.55
Round   3, Train loss: 0.835, Test loss: 1.274, Test accuracy: 50.68
Round   4, Train loss: 0.790, Test loss: 1.069, Test accuracy: 57.08
Round   5, Train loss: 0.727, Test loss: 0.890, Test accuracy: 60.72
Round   6, Train loss: 0.782, Test loss: 0.918, Test accuracy: 64.20
Round   7, Train loss: 0.710, Test loss: 0.757, Test accuracy: 68.17
Round   8, Train loss: 0.659, Test loss: 0.754, Test accuracy: 68.42
Round   9, Train loss: 0.693, Test loss: 0.643, Test accuracy: 74.08
Round  10, Train loss: 0.601, Test loss: 0.619, Test accuracy: 75.26
Round  11, Train loss: 0.589, Test loss: 0.613, Test accuracy: 75.41
Round  12, Train loss: 0.593, Test loss: 0.583, Test accuracy: 76.02
Round  13, Train loss: 0.576, Test loss: 0.575, Test accuracy: 76.67
Round  14, Train loss: 0.547, Test loss: 0.573, Test accuracy: 77.70
Round  15, Train loss: 0.616, Test loss: 0.562, Test accuracy: 76.77
Round  16, Train loss: 0.585, Test loss: 0.554, Test accuracy: 77.33
Round  17, Train loss: 0.540, Test loss: 0.530, Test accuracy: 78.41
Round  18, Train loss: 0.538, Test loss: 0.519, Test accuracy: 78.36
Round  19, Train loss: 0.540, Test loss: 0.514, Test accuracy: 79.33
Round  20, Train loss: 0.573, Test loss: 0.513, Test accuracy: 79.47
Round  21, Train loss: 0.539, Test loss: 0.504, Test accuracy: 79.74
Round  22, Train loss: 0.515, Test loss: 0.505, Test accuracy: 79.77
Round  23, Train loss: 0.475, Test loss: 0.500, Test accuracy: 80.08
Round  24, Train loss: 0.537, Test loss: 0.486, Test accuracy: 80.11
Round  25, Train loss: 0.518, Test loss: 0.482, Test accuracy: 80.17
Round  26, Train loss: 0.515, Test loss: 0.477, Test accuracy: 80.39
Round  27, Train loss: 0.466, Test loss: 0.477, Test accuracy: 80.84
Round  28, Train loss: 0.435, Test loss: 0.468, Test accuracy: 81.15
Round  29, Train loss: 0.498, Test loss: 0.467, Test accuracy: 81.24
Round  30, Train loss: 0.527, Test loss: 0.455, Test accuracy: 81.72
Round  31, Train loss: 0.416, Test loss: 0.461, Test accuracy: 81.49
Round  32, Train loss: 0.518, Test loss: 0.455, Test accuracy: 81.83
Round  33, Train loss: 0.442, Test loss: 0.447, Test accuracy: 82.07
Round  34, Train loss: 0.453, Test loss: 0.445, Test accuracy: 82.06
Round  35, Train loss: 0.422, Test loss: 0.436, Test accuracy: 82.50
Round  36, Train loss: 0.496, Test loss: 0.434, Test accuracy: 82.18
Round  37, Train loss: 0.384, Test loss: 0.432, Test accuracy: 82.47
Round  38, Train loss: 0.473, Test loss: 0.420, Test accuracy: 82.67
Round  39, Train loss: 0.479, Test loss: 0.432, Test accuracy: 82.38
Round  40, Train loss: 0.438, Test loss: 0.421, Test accuracy: 83.16
Round  41, Train loss: 0.366, Test loss: 0.420, Test accuracy: 83.42
Round  42, Train loss: 0.382, Test loss: 0.415, Test accuracy: 83.75
Round  43, Train loss: 0.362, Test loss: 0.410, Test accuracy: 83.28
Round  44, Train loss: 0.387, Test loss: 0.416, Test accuracy: 83.26
Round  45, Train loss: 0.367, Test loss: 0.412, Test accuracy: 83.54
Round  46, Train loss: 0.384, Test loss: 0.407, Test accuracy: 83.62
Round  47, Train loss: 0.384, Test loss: 0.410, Test accuracy: 83.36
Round  48, Train loss: 0.411, Test loss: 0.404, Test accuracy: 83.78
Round  49, Train loss: 0.311, Test loss: 0.405, Test accuracy: 83.87
Round  50, Train loss: 0.405, Test loss: 0.403, Test accuracy: 83.85
Round  51, Train loss: 0.372, Test loss: 0.394, Test accuracy: 84.02
Round  52, Train loss: 0.310, Test loss: 0.391, Test accuracy: 84.03
Round  53, Train loss: 0.297, Test loss: 0.389, Test accuracy: 83.99
Round  54, Train loss: 0.454, Test loss: 0.388, Test accuracy: 84.82
Round  55, Train loss: 0.407, Test loss: 0.379, Test accuracy: 84.68
Round  56, Train loss: 0.355, Test loss: 0.383, Test accuracy: 84.72
Round  57, Train loss: 0.398, Test loss: 0.377, Test accuracy: 84.67
Round  58, Train loss: 0.361, Test loss: 0.379, Test accuracy: 84.73
Round  59, Train loss: 0.392, Test loss: 0.375, Test accuracy: 85.12
Round  60, Train loss: 0.319, Test loss: 0.379, Test accuracy: 84.77
Round  61, Train loss: 0.326, Test loss: 0.370, Test accuracy: 84.95
Round  62, Train loss: 0.303, Test loss: 0.373, Test accuracy: 84.72
Round  63, Train loss: 0.425, Test loss: 0.378, Test accuracy: 84.72
Round  64, Train loss: 0.349, Test loss: 0.372, Test accuracy: 85.15
Round  65, Train loss: 0.270, Test loss: 0.364, Test accuracy: 85.59
Round  66, Train loss: 0.316, Test loss: 0.371, Test accuracy: 85.08
Round  67, Train loss: 0.320, Test loss: 0.368, Test accuracy: 85.26
Round  68, Train loss: 0.329, Test loss: 0.372, Test accuracy: 84.92
Round  69, Train loss: 0.335, Test loss: 0.368, Test accuracy: 85.41
Round  70, Train loss: 0.260, Test loss: 0.370, Test accuracy: 85.22
Round  71, Train loss: 0.370, Test loss: 0.371, Test accuracy: 85.08
Round  72, Train loss: 0.346, Test loss: 0.372, Test accuracy: 85.33
Round  73, Train loss: 0.283, Test loss: 0.371, Test accuracy: 85.07
Round  74, Train loss: 0.290, Test loss: 0.368, Test accuracy: 85.12
Round  75, Train loss: 0.364, Test loss: 0.367, Test accuracy: 85.39
Round  76, Train loss: 0.342, Test loss: 0.363, Test accuracy: 85.47
Round  77, Train loss: 0.281, Test loss: 0.358, Test accuracy: 85.56
Round  78, Train loss: 0.253, Test loss: 0.356, Test accuracy: 85.55
Round  79, Train loss: 0.253, Test loss: 0.357, Test accuracy: 85.67
Round  80, Train loss: 0.285, Test loss: 0.355, Test accuracy: 85.88
Round  81, Train loss: 0.250, Test loss: 0.355, Test accuracy: 85.95
Round  82, Train loss: 0.263, Test loss: 0.364, Test accuracy: 85.52
Round  83, Train loss: 0.279, Test loss: 0.349, Test accuracy: 86.42
Round  84, Train loss: 0.254, Test loss: 0.352, Test accuracy: 86.08
Round  85, Train loss: 0.229, Test loss: 0.357, Test accuracy: 85.62
Round  86, Train loss: 0.290, Test loss: 0.359, Test accuracy: 85.81
Round  87, Train loss: 0.287, Test loss: 0.358, Test accuracy: 85.88
Round  88, Train loss: 0.276, Test loss: 0.359, Test accuracy: 85.78
Round  89, Train loss: 0.318, Test loss: 0.361, Test accuracy: 85.53
Round  90, Train loss: 0.291, Test loss: 0.360, Test accuracy: 85.59
Round  91, Train loss: 0.249, Test loss: 0.361, Test accuracy: 85.47
Round  92, Train loss: 0.269, Test loss: 0.353, Test accuracy: 86.07
Round  93, Train loss: 0.216, Test loss: 0.350, Test accuracy: 86.17
Round  94, Train loss: 0.288, Test loss: 0.354, Test accuracy: 85.86
Round  95, Train loss: 0.311, Test loss: 0.359, Test accuracy: 85.78
Round  96, Train loss: 0.299, Test loss: 0.355, Test accuracy: 86.08
Round  97, Train loss: 0.259, Test loss: 0.350, Test accuracy: 86.15
Round  98, Train loss: 0.269, Test loss: 0.357, Test accuracy: 85.89
Round  99, Train loss: 0.222, Test loss: 0.355, Test accuracy: 85.83
Final Round, Train loss: 0.201, Test loss: 0.356, Test accuracy: 86.00
Average accuracy final 10 rounds: 85.8875
1037.4338080883026
[1.7133479118347168, 3.0249650478363037, 4.3174402713775635, 5.61152982711792, 6.85769510269165, 8.099599838256836, 9.352471351623535, 10.543176889419556, 11.734596967697144, 12.923945903778076, 14.104265451431274, 15.291413068771362, 16.459436893463135, 17.627535581588745, 19.020490407943726, 20.214930295944214, 21.39573574066162, 22.571213006973267, 23.745253086090088, 24.92935085296631, 26.104662895202637, 27.287206411361694, 28.462864637374878, 29.64384412765503, 30.824495553970337, 32.006104707717896, 33.183886766433716, 34.35757398605347, 35.529420137405396, 36.707988262176514, 37.88516926765442, 39.05926561355591, 40.23697566986084, 41.41872978210449, 42.59585189819336, 43.768649101257324, 44.942559480667114, 46.12029266357422, 47.30995416641235, 48.484973430633545, 49.66130304336548, 50.83931851387024, 52.02606821060181, 53.20289731025696, 54.39417052268982, 55.573025941848755, 56.759034156799316, 57.939796686172485, 59.11705231666565, 60.293665170669556, 61.473053216934204, 62.68162536621094, 63.86202788352966, 65.03765296936035, 66.20648527145386, 67.38163685798645, 68.55973410606384, 69.743901014328, 70.93164920806885, 72.12670516967773, 73.30697822570801, 74.49182415008545, 75.67777466773987, 76.84927248954773, 78.0371835231781, 79.22330927848816, 80.40091300010681, 81.57371091842651, 82.77166867256165, 83.96052932739258, 85.14745855331421, 86.32805252075195, 87.52300500869751, 88.70868253707886, 89.89225244522095, 91.07120037078857, 92.23990488052368, 93.42302179336548, 94.6078896522522, 95.79788327217102, 96.97231221199036, 98.14980745315552, 99.32619905471802, 100.51667618751526, 101.70731592178345, 102.88147211074829, 104.04770922660828, 105.22400164604187, 106.40549039840698, 107.58894658088684, 108.77625465393066, 109.96745538711548, 111.1544828414917, 112.34988641738892, 113.52947211265564, 114.71239757537842, 115.90462231636047, 117.08087825775146, 118.26292610168457, 119.43747115135193, 121.3488917350769]
[28.241666666666667, 42.475, 47.55, 50.68333333333333, 57.083333333333336, 60.71666666666667, 64.2, 68.16666666666667, 68.425, 74.08333333333333, 75.25833333333334, 75.40833333333333, 76.01666666666667, 76.675, 77.7, 76.76666666666667, 77.325, 78.40833333333333, 78.35833333333333, 79.325, 79.46666666666667, 79.74166666666666, 79.76666666666667, 80.08333333333333, 80.10833333333333, 80.175, 80.39166666666667, 80.84166666666667, 81.15, 81.24166666666666, 81.71666666666667, 81.49166666666666, 81.825, 82.06666666666666, 82.05833333333334, 82.5, 82.18333333333334, 82.475, 82.66666666666667, 82.375, 83.15833333333333, 83.425, 83.75, 83.28333333333333, 83.25833333333334, 83.54166666666667, 83.625, 83.35833333333333, 83.775, 83.86666666666666, 83.85, 84.01666666666667, 84.03333333333333, 83.99166666666666, 84.81666666666666, 84.68333333333334, 84.725, 84.675, 84.73333333333333, 85.11666666666666, 84.76666666666667, 84.95, 84.71666666666667, 84.725, 85.15, 85.59166666666667, 85.08333333333333, 85.25833333333334, 84.91666666666667, 85.40833333333333, 85.21666666666667, 85.075, 85.325, 85.06666666666666, 85.125, 85.39166666666667, 85.475, 85.55833333333334, 85.55, 85.66666666666667, 85.875, 85.95, 85.51666666666667, 86.41666666666667, 86.075, 85.61666666666666, 85.80833333333334, 85.875, 85.78333333333333, 85.53333333333333, 85.59166666666667, 85.46666666666667, 86.06666666666666, 86.16666666666667, 85.85833333333333, 85.78333333333333, 86.075, 86.15, 85.89166666666667, 85.825, 86.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.157, Test loss: 2.154, Test accuracy: 24.57
Round   1, Train loss: 0.929, Test loss: 2.147, Test accuracy: 25.97
Round   2, Train loss: 0.781, Test loss: 2.154, Test accuracy: 31.38
Round   3, Train loss: 0.820, Test loss: 1.987, Test accuracy: 33.62
Round   4, Train loss: 0.770, Test loss: 1.926, Test accuracy: 37.50
Round   5, Train loss: 0.795, Test loss: 1.938, Test accuracy: 35.31
Round   6, Train loss: 0.721, Test loss: 1.827, Test accuracy: 39.73
Round   7, Train loss: 0.653, Test loss: 1.761, Test accuracy: 39.18
Round   8, Train loss: 0.691, Test loss: 2.180, Test accuracy: 34.34
Round   9, Train loss: 0.627, Test loss: 1.913, Test accuracy: 37.26
Round  10, Train loss: 0.629, Test loss: 1.781, Test accuracy: 42.84
Round  11, Train loss: 0.622, Test loss: 1.917, Test accuracy: 39.69
Round  12, Train loss: 0.566, Test loss: 2.240, Test accuracy: 32.20
Round  13, Train loss: 0.520, Test loss: 2.344, Test accuracy: 36.17
Round  14, Train loss: 0.690, Test loss: 1.750, Test accuracy: 42.32
Round  15, Train loss: 0.520, Test loss: 1.680, Test accuracy: 46.33
Round  16, Train loss: 0.560, Test loss: 1.880, Test accuracy: 42.55
Round  17, Train loss: 0.525, Test loss: 1.571, Test accuracy: 47.67
Round  18, Train loss: 0.553, Test loss: 1.752, Test accuracy: 44.52
Round  19, Train loss: 0.514, Test loss: 1.659, Test accuracy: 44.00
Round  20, Train loss: 0.478, Test loss: 1.613, Test accuracy: 47.30
Round  21, Train loss: 0.493, Test loss: 1.722, Test accuracy: 46.03
Round  22, Train loss: 0.515, Test loss: 1.721, Test accuracy: 45.88
Round  23, Train loss: 0.445, Test loss: 1.723, Test accuracy: 47.73
Round  24, Train loss: 0.455, Test loss: 1.706, Test accuracy: 47.23
Round  25, Train loss: 0.421, Test loss: 1.561, Test accuracy: 51.31
Round  26, Train loss: 0.441, Test loss: 1.859, Test accuracy: 45.77
Round  27, Train loss: 0.415, Test loss: 1.946, Test accuracy: 46.63
Round  28, Train loss: 0.513, Test loss: 1.931, Test accuracy: 41.11
Round  29, Train loss: 0.418, Test loss: 1.583, Test accuracy: 49.26
Round  30, Train loss: 0.409, Test loss: 1.714, Test accuracy: 47.98
Round  31, Train loss: 0.424, Test loss: 1.421, Test accuracy: 53.38
Round  32, Train loss: 0.376, Test loss: 1.698, Test accuracy: 48.39
Round  33, Train loss: 0.401, Test loss: 1.517, Test accuracy: 52.65
Round  34, Train loss: 0.352, Test loss: 1.595, Test accuracy: 51.58
Round  35, Train loss: 0.397, Test loss: 1.441, Test accuracy: 53.02
Round  36, Train loss: 0.411, Test loss: 1.704, Test accuracy: 48.21
Round  37, Train loss: 0.391, Test loss: 1.561, Test accuracy: 51.59
Round  38, Train loss: 0.369, Test loss: 1.596, Test accuracy: 50.48
Round  39, Train loss: 0.420, Test loss: 1.497, Test accuracy: 53.47
Round  40, Train loss: 0.336, Test loss: 1.722, Test accuracy: 50.19
Round  41, Train loss: 0.406, Test loss: 1.633, Test accuracy: 49.27
Round  42, Train loss: 0.415, Test loss: 1.568, Test accuracy: 51.90
Round  43, Train loss: 0.335, Test loss: 1.544, Test accuracy: 52.02
Round  44, Train loss: 0.373, Test loss: 1.601, Test accuracy: 50.27
Round  45, Train loss: 0.340, Test loss: 1.856, Test accuracy: 42.39
Round  46, Train loss: 0.369, Test loss: 1.573, Test accuracy: 52.08
Round  47, Train loss: 0.410, Test loss: 1.471, Test accuracy: 52.15
Round  48, Train loss: 0.364, Test loss: 1.565, Test accuracy: 51.93
Round  49, Train loss: 0.339, Test loss: 1.704, Test accuracy: 48.88
Round  50, Train loss: 0.344, Test loss: 1.625, Test accuracy: 51.41
Round  51, Train loss: 0.266, Test loss: 1.656, Test accuracy: 53.17
Round  52, Train loss: 0.304, Test loss: 1.684, Test accuracy: 52.26
Round  53, Train loss: 0.328, Test loss: 1.695, Test accuracy: 49.55
Round  54, Train loss: 0.330, Test loss: 1.517, Test accuracy: 54.61
Round  55, Train loss: 0.287, Test loss: 1.568, Test accuracy: 55.08
Round  56, Train loss: 0.334, Test loss: 1.575, Test accuracy: 49.92
Round  57, Train loss: 0.352, Test loss: 1.928, Test accuracy: 48.19
Round  58, Train loss: 0.341, Test loss: 1.491, Test accuracy: 53.83
Round  59, Train loss: 0.300, Test loss: 1.425, Test accuracy: 56.33
Round  60, Train loss: 0.251, Test loss: 1.610, Test accuracy: 52.02
Round  61, Train loss: 0.291, Test loss: 1.611, Test accuracy: 53.27
Round  62, Train loss: 0.253, Test loss: 1.656, Test accuracy: 52.88
Round  63, Train loss: 0.245, Test loss: 1.736, Test accuracy: 53.54
Round  64, Train loss: 0.292, Test loss: 1.826, Test accuracy: 54.47
Round  65, Train loss: 0.323, Test loss: 1.378, Test accuracy: 54.76
Round  66, Train loss: 0.304, Test loss: 1.550, Test accuracy: 52.62
Round  67, Train loss: 0.282, Test loss: 1.780, Test accuracy: 47.04
Round  68, Train loss: 0.230, Test loss: 1.598, Test accuracy: 52.11
Round  69, Train loss: 0.205, Test loss: 1.577, Test accuracy: 53.28
Round  70, Train loss: 0.236, Test loss: 1.937, Test accuracy: 47.50
Round  71, Train loss: 0.257, Test loss: 1.737, Test accuracy: 52.42
Round  72, Train loss: 0.236, Test loss: 1.553, Test accuracy: 53.44
Round  73, Train loss: 0.207, Test loss: 1.619, Test accuracy: 53.34
Round  74, Train loss: 0.188, Test loss: 1.859, Test accuracy: 51.07
Round  75, Train loss: 0.213, Test loss: 1.784, Test accuracy: 51.21
Round  76, Train loss: 0.228, Test loss: 2.124, Test accuracy: 49.05
Round  77, Train loss: 0.276, Test loss: 1.725, Test accuracy: 52.98
Round  78, Train loss: 0.228, Test loss: 1.528, Test accuracy: 57.12
Round  79, Train loss: 0.303, Test loss: 1.584, Test accuracy: 52.28
Round  80, Train loss: 0.241, Test loss: 1.756, Test accuracy: 52.61
Round  81, Train loss: 0.227, Test loss: 1.809, Test accuracy: 52.45
Round  82, Train loss: 0.209, Test loss: 1.611, Test accuracy: 53.42
Round  83, Train loss: 0.212, Test loss: 1.617, Test accuracy: 54.21
Round  84, Train loss: 0.202, Test loss: 2.157, Test accuracy: 45.65
Round  85, Train loss: 0.165, Test loss: 1.711, Test accuracy: 52.42
Round  86, Train loss: 0.248, Test loss: 1.827, Test accuracy: 48.42
Round  87, Train loss: 0.167, Test loss: 1.692, Test accuracy: 53.37
Round  88, Train loss: 0.151, Test loss: 1.666, Test accuracy: 55.02
Round  89, Train loss: 0.173, Test loss: 2.202, Test accuracy: 46.78
Round  90, Train loss: 0.222, Test loss: 1.646, Test accuracy: 55.69
Round  91, Train loss: 0.216, Test loss: 1.574, Test accuracy: 55.38
Round  92, Train loss: 0.209, Test loss: 1.819, Test accuracy: 49.96
Round  93, Train loss: 0.220, Test loss: 2.156, Test accuracy: 45.57
Round  94, Train loss: 0.224, Test loss: 1.829, Test accuracy: 50.01
Round  95, Train loss: 0.149, Test loss: 1.745, Test accuracy: 55.38
Round  96, Train loss: 0.211, Test loss: 1.860, Test accuracy: 52.17
Round  97, Train loss: 0.158, Test loss: 1.797, Test accuracy: 53.87
Round  98, Train loss: 0.197, Test loss: 1.585, Test accuracy: 55.63
Round  99, Train loss: 0.205, Test loss: 1.806, Test accuracy: 50.68
Final Round, Train loss: 0.170, Test loss: 1.424, Test accuracy: 58.70
Average accuracy final 10 rounds: 52.4325
1911.5291776657104
[3.17614483833313, 6.144439935684204, 9.0516836643219, 11.965090990066528, 14.875200033187866, 17.77505922317505, 20.679203748703003, 23.625906705856323, 26.581650495529175, 29.47909665107727, 32.38664245605469, 35.3057963848114, 38.245314836502075, 41.15877342224121, 44.095067262649536, 47.06480574607849, 49.98296761512756, 52.56659555435181, 55.137277364730835, 57.71043634414673, 60.29144263267517, 62.88635444641113, 65.46974301338196, 68.04697966575623, 70.61960649490356, 73.20698523521423, 75.80084371566772, 78.39012956619263, 80.97551655769348, 83.54837036132812, 86.12176299095154, 88.69918894767761, 91.29322123527527, 93.87555027008057, 96.44760131835938, 99.01721215248108, 101.597323179245, 104.17478704452515, 106.74626541137695, 109.32230067253113, 111.9030773639679, 114.49253249168396, 117.08286666870117, 119.66751146316528, 122.24174499511719, 124.81896710395813, 127.40123224258423, 129.99246430397034, 132.57639598846436, 135.15501737594604, 137.73221969604492, 140.30226516723633, 142.8904688358307, 145.47703051567078, 148.06333231925964, 150.6476013660431, 153.23412656784058, 155.7895359992981, 158.34049487113953, 160.8922998905182, 163.44497990608215, 165.99492120742798, 168.54902911186218, 171.10492539405823, 173.6688690185547, 176.23769688606262, 178.7846987247467, 181.33326077461243, 183.9017677307129, 186.4823865890503, 189.06087255477905, 191.6395936012268, 194.20771861076355, 196.77442908287048, 199.34534335136414, 201.9188051223755, 204.50543427467346, 207.09943389892578, 209.68079280853271, 212.25343537330627, 214.84446835517883, 217.4292299747467, 220.0216143131256, 222.60410070419312, 225.1700439453125, 227.76948046684265, 230.3276331424713, 232.89539170265198, 235.4715542793274, 238.03150868415833, 240.59219431877136, 243.16314888000488, 245.7549524307251, 248.31914901733398, 250.90034699440002, 253.46694540977478, 256.0687265396118, 258.6459197998047, 261.22576999664307, 263.8101441860199, 266.41864562034607]
[24.575, 25.966666666666665, 31.375, 33.625, 37.5, 35.30833333333333, 39.725, 39.18333333333333, 34.34166666666667, 37.25833333333333, 42.84166666666667, 39.69166666666667, 32.2, 36.175, 42.31666666666667, 46.325, 42.55, 47.666666666666664, 44.516666666666666, 44.0, 47.3, 46.03333333333333, 45.88333333333333, 47.733333333333334, 47.225, 51.30833333333333, 45.766666666666666, 46.63333333333333, 41.108333333333334, 49.25833333333333, 47.975, 53.375, 48.391666666666666, 52.65, 51.575, 53.016666666666666, 48.208333333333336, 51.59166666666667, 50.475, 53.46666666666667, 50.19166666666667, 49.266666666666666, 51.9, 52.025, 50.266666666666666, 42.391666666666666, 52.075, 52.15, 51.93333333333333, 48.88333333333333, 51.40833333333333, 53.175, 52.25833333333333, 49.55, 54.608333333333334, 55.075, 49.916666666666664, 48.19166666666667, 53.825, 56.325, 52.016666666666666, 53.266666666666666, 52.875, 53.541666666666664, 54.46666666666667, 54.75833333333333, 52.61666666666667, 47.041666666666664, 52.108333333333334, 53.28333333333333, 47.5, 52.416666666666664, 53.44166666666667, 53.34166666666667, 51.06666666666667, 51.208333333333336, 49.05, 52.983333333333334, 57.11666666666667, 52.28333333333333, 52.608333333333334, 52.45, 53.425, 54.208333333333336, 45.65, 52.416666666666664, 48.425, 53.36666666666667, 55.016666666666666, 46.78333333333333, 55.69166666666667, 55.375, 49.958333333333336, 45.56666666666667, 50.00833333333333, 55.375, 52.166666666666664, 53.86666666666667, 55.63333333333333, 50.68333333333333, 58.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.273, Test loss: 2.303, Test accuracy: 13.08 

Round   0, Global train loss: 2.273, Global test loss: 2.306, Global test accuracy: 12.89 

Round   1, Train loss: 2.260, Test loss: 2.301, Test accuracy: 12.69 

Round   1, Global train loss: 2.260, Global test loss: 2.304, Global test accuracy: 12.80 

Round   2, Train loss: 2.235, Test loss: 2.297, Test accuracy: 12.61 

Round   2, Global train loss: 2.235, Global test loss: 2.303, Global test accuracy: 11.37 

Round   3, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.24 

Round   3, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 9.43 

Round   4, Train loss: 2.312, Test loss: 2.303, Test accuracy: 7.22 

Round   4, Global train loss: 2.312, Global test loss: 2.300, Global test accuracy: 6.31 

Round   5, Train loss: 2.307, Test loss: 2.306, Test accuracy: 6.99 

Round   5, Global train loss: 2.307, Global test loss: 2.298, Global test accuracy: 5.34 

Round   6, Train loss: nan, Test loss: nan, Test accuracy: 6.19 

Round   6, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round   7, Train loss: nan, Test loss: nan, Test accuracy: 5.89 

Round   7, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round   8, Train loss: nan, Test loss: nan, Test accuracy: 2.36 

Round   8, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round   9, Train loss: nan, Test loss: nan, Test accuracy: 1.90 

Round   9, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  10, Train loss: nan, Test loss: nan, Test accuracy: 1.90 

Round  10, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  11, Train loss: nan, Test loss: nan, Test accuracy: 3.57 

Round  11, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  12, Train loss: nan, Test loss: nan, Test accuracy: 3.57 

Round  12, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  13, Train loss: nan, Test loss: nan, Test accuracy: 3.57 

Round  13, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  14, Train loss: nan, Test loss: nan, Test accuracy: 3.56 

Round  14, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  15, Train loss: nan, Test loss: nan, Test accuracy: 3.56 

Round  15, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  16, Train loss: nan, Test loss: nan, Test accuracy: 3.56 

Round  16, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  17, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  17, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  18, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  18, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  19, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  19, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  20, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  20, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  21, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  21, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  22, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  22, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  23, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  23, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  24, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  24, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  25, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  25, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  26, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  26, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  27, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  27, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  28, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  28, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  29, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  29, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  30, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  30, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  31, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  31, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  32, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  32, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  33, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  33, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  34, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  34, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  35, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  35, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  36, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  36, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  37, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  37, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  38, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  38, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  39, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  39, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  40, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  40, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  41, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  41, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  42, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  42, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  43, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  43, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  44, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  44, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  45, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  45, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  46, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  46, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  47, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  47, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  48, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  48, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  49, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  49, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  50, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  50, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  51, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  51, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  52, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  52, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  53, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  53, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  54, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  54, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  55, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  55, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  56, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  56, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  57, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  57, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  58, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  58, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  59, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  59, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  60, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  60, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  61, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  61, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  62, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  62, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  63, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  63, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  64, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  64, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  65, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  65, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  66, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  66, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  67, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  67, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  68, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  68, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  69, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  69, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  70, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  70, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  71, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  71, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  72, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  72, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  73, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  73, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  74, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  74, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  75, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  75, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  76, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  76, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  77, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  77, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  78, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  78, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  79, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  79, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  80, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  80, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  81, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  81, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  82, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  82, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  83, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  83, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  84, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  84, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  85, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  85, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  86, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  86, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  87, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  87, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  88, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  88, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  89, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  89, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  90, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  90, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  91, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  91, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  92, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  92, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  93, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  93, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  94, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  94, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  95, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  95, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  96, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  96, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  97, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  97, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  98, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  98, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round  99, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round  99, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 100, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 100, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 101, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 101, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 102, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 102, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 103, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 103, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 104, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 104, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 105, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 105, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 106, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 106, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 107, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 107, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 108, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 108, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 109, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 109, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 110, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 110, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 111, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 111, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 112, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 112, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 113, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 113, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 114, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 114, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 115, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 115, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 116, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 116, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 117, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 117, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 118, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 118, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 119, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 119, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 120, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 120, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 121, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 121, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 122, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 122, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 123, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 123, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 124, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 124, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 125, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 125, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 126, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 126, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 127, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 127, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 128, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 128, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 129, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 129, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 130, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 130, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 131, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 131, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 132, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 132, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 133, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 133, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 134, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 134, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 135, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 135, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 136, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 136, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 137, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 137, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 138, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 138, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 139, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 139, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 140, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 140, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 141, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 141, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 142, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 142, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 143, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 143, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 144, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 144, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 145, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 145, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 146, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 146, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 147, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 147, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 148, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 148, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 149, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 149, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 150, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 150, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 151, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 151, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 152, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 152, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 153, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 153, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 154, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 154, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 155, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 155, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 156, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 156, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 157, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 157, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 158, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 158, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 159, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 159, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 160, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 160, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 161, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 161, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 162, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 162, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 163, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 163, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 164, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 164, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 165, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 165, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 166, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 166, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 167, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 167, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 168, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 168, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 169, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 169, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 170, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 170, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 171, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 171, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 172, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 172, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 173, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 173, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 174, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 174, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 175, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 175, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 176, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 176, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 177, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 177, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 178, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 178, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 179, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 179, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 180, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 180, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 181, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 181, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 182, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 182, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 183, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 183, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 184, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 184, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 185, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 185, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 186, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 186, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 187, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 187, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 188, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 188, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 189, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 189, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 190, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 190, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 3.33 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 3.33 

Average accuracy final 10 rounds: 3.3333333333333344 

Average global accuracy final 10 rounds: 3.3333333333333344 

3959.8447642326355
[1.4944381713867188, 2.771502733230591, 4.043136835098267, 5.313908338546753, 6.584728956222534, 7.853299140930176, 9.120100259780884, 10.384680271148682, 11.650012016296387, 12.91349196434021, 14.176306962966919, 15.436570882797241, 16.69987726211548, 17.961451292037964, 19.21949338912964, 20.47990584373474, 21.737972497940063, 23.000795125961304, 24.257497310638428, 25.518424034118652, 26.781689643859863, 28.04349637031555, 29.304090976715088, 30.565804481506348, 31.831082105636597, 33.0939826965332, 34.357949018478394, 35.61886119842529, 36.88339829444885, 38.14356517791748, 39.40489959716797, 40.67307925224304, 41.934526205062866, 43.20123481750488, 44.46381688117981, 45.729278326034546, 46.994255781173706, 48.25375509262085, 49.51508975028992, 50.774603843688965, 52.03640961647034, 53.29824662208557, 54.55827975273132, 55.81999588012695, 57.07858204841614, 58.34092831611633, 59.60354256629944, 60.865824460983276, 62.121713638305664, 63.3810133934021, 64.64090871810913, 65.90194988250732, 67.16292691230774, 68.42251563072205, 69.68287539482117, 70.94119334220886, 72.20255398750305, 73.46572995185852, 74.73090076446533, 75.99662566184998, 77.25686478614807, 78.53890252113342, 79.8298671245575, 81.09090566635132, 82.3494074344635, 83.63203406333923, 84.89815521240234, 86.15667605400085, 87.41863942146301, 88.67799854278564, 89.94266152381897, 91.22614431381226, 92.49142336845398, 93.76010870933533, 95.0253677368164, 96.29057693481445, 97.55156111717224, 98.81522488594055, 100.0733208656311, 101.33438754081726, 102.59644818305969, 103.85813188552856, 105.12102627754211, 106.37918376922607, 107.65771126747131, 108.91937494277954, 110.18233966827393, 111.44294548034668, 112.709308385849, 113.9709701538086, 115.23516941070557, 116.49952673912048, 117.76158094406128, 119.02642607688904, 120.29159688949585, 121.55510759353638, 122.82358026504517, 124.08461928367615, 125.3435378074646, 126.61494779586792, 127.89346361160278, 129.17216968536377, 130.441162109375, 131.7079312801361, 132.97267818450928, 134.2416274547577, 135.51707792282104, 136.78577661514282, 138.0587408542633, 139.33048391342163, 140.60454988479614, 141.87582755088806, 143.15242266654968, 144.42217540740967, 145.69934177398682, 146.97352123260498, 148.25099539756775, 149.5290768146515, 150.80488348007202, 152.07852411270142, 153.35321640968323, 154.61949014663696, 155.89128589630127, 157.15719413757324, 158.4317066669464, 159.70194292068481, 160.97263288497925, 162.24662113189697, 163.51964020729065, 164.79427671432495, 166.06824040412903, 167.34417986869812, 168.61810088157654, 169.8922894001007, 171.1685221195221, 172.44240307807922, 173.71840596199036, 174.9898898601532, 176.2576253414154, 177.52511501312256, 178.79944133758545, 180.07460832595825, 181.3491530418396, 182.62336540222168, 183.8994243144989, 185.180766582489, 186.45403027534485, 187.58120441436768, 188.70239162445068, 189.82807064056396, 190.9495542049408, 192.07888793945312, 193.20709681510925, 194.33277797698975, 195.45679879188538, 196.57471895217896, 197.69979524612427, 198.81957173347473, 199.9408895969391, 201.05333971977234, 202.17531871795654, 203.29846453666687, 204.42359328269958, 205.54827523231506, 206.67562437057495, 207.79898619651794, 208.9262912273407, 210.05338549613953, 211.17944407463074, 212.29977130889893, 213.42627692222595, 214.54958963394165, 215.6733422279358, 216.79130244255066, 217.9119827747345, 219.0385513305664, 220.15872931480408, 221.28302526474, 222.40307211875916, 223.53062915802002, 224.6553499698639, 225.78293991088867, 226.90335965156555, 228.03233361244202, 229.15531659126282, 230.27838921546936, 231.40090680122375, 232.52598237991333, 233.65153312683105, 234.7779884338379, 235.90425610542297, 237.02618670463562, 238.15313243865967, 239.2831871509552, 240.41258549690247, 241.5353000164032, 242.66092562675476, 243.78945541381836, 244.91241788864136, 246.0330810546875, 247.15884852409363, 248.28635358810425, 249.41266512870789, 250.54087948799133, 251.66291117668152, 252.78828811645508, 253.91037511825562, 255.03746604919434, 256.16463828086853, 257.2879204750061, 258.414190530777, 259.5390532016754, 260.6634991168976, 261.78925466537476, 262.9140946865082, 264.040296792984, 265.165629863739, 266.28964161872864, 267.41526055336, 268.5384154319763, 269.65929341316223, 270.7817289829254, 271.9094178676605, 273.03680968284607, 274.15837931632996, 275.2860915660858, 276.4092800617218, 277.5378384590149, 278.6664843559265, 279.79102420806885, 281.06287455558777, 282.33484411239624, 283.60944652557373, 284.8882625102997, 286.16212701797485, 287.43364429473877, 288.65441608428955, 289.87147521972656, 291.15457367897034, 292.387175321579, 293.62825441360474, 294.8553891181946, 296.08717465400696, 297.34534096717834, 298.60717010498047, 299.86671924591064, 301.13823652267456, 302.41695737838745, 303.70552015304565, 304.9700982570648, 306.2401146888733, 307.5016920566559, 308.7621374130249, 310.02015829086304, 311.28231501579285, 312.547993183136, 313.8128499984741, 315.08618998527527, 316.3526072502136, 317.6175272464752, 318.8885564804077, 320.1551728248596, 321.41742181777954, 322.6426911354065, 323.75233817100525, 324.8645555973053, 325.97403216362, 327.08526968955994, 328.19667530059814, 329.31135272979736, 330.4227511882782, 331.5358233451843, 332.6498329639435, 333.7620084285736, 334.87133526802063, 335.98343896865845, 337.0959391593933, 338.2046899795532, 339.3183295726776, 340.43151021003723, 341.54591488838196, 342.6571056842804, 343.767409324646, 344.88031578063965, 345.99284410476685, 347.10441875457764, 348.21662998199463, 349.3283612728119, 350.4377875328064, 351.5484025478363, 352.6593039035797, 353.7689871788025, 354.87954020500183, 355.98999547958374, 357.10148334503174, 358.2170624732971, 359.3251986503601, 360.4361171722412, 361.54804134368896, 362.6619031429291, 364.880437374115]
[13.083333333333334, 12.691666666666666, 12.608333333333333, 10.241666666666667, 7.216666666666667, 6.991666666666666, 6.191666666666666, 5.891666666666667, 2.3583333333333334, 1.9, 1.9, 3.566666666666667, 3.566666666666667, 3.566666666666667, 3.558333333333333, 3.558333333333333, 3.558333333333333, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.227, Test loss: 2.183, Test accuracy: 20.11 

Round   0, Global train loss: 2.227, Global test loss: 2.203, Global test accuracy: 20.31 

Round   1, Train loss: 2.064, Test loss: 2.104, Test accuracy: 23.68 

Round   1, Global train loss: 2.064, Global test loss: 2.136, Global test accuracy: 24.36 

Round   2, Train loss: 1.968, Test loss: 2.059, Test accuracy: 26.00 

Round   2, Global train loss: 1.968, Global test loss: 2.096, Global test accuracy: 27.18 

Round   3, Train loss: 1.870, Test loss: 1.958, Test accuracy: 28.47 

Round   3, Global train loss: 1.870, Global test loss: 2.075, Global test accuracy: 28.62 

Round   4, Train loss: 1.806, Test loss: 1.871, Test accuracy: 30.45 

Round   4, Global train loss: 1.806, Global test loss: 1.991, Global test accuracy: 30.51 

Round   5, Train loss: 1.740, Test loss: 1.831, Test accuracy: 32.51 

Round   5, Global train loss: 1.740, Global test loss: 2.015, Global test accuracy: 31.35 

Round   6, Train loss: 1.692, Test loss: 1.787, Test accuracy: 33.99 

Round   6, Global train loss: 1.692, Global test loss: 1.988, Global test accuracy: 31.97 

Round   7, Train loss: 1.639, Test loss: 1.727, Test accuracy: 36.12 

Round   7, Global train loss: 1.639, Global test loss: 1.965, Global test accuracy: 33.33 

Round   8, Train loss: 1.595, Test loss: 1.705, Test accuracy: 37.32 

Round   8, Global train loss: 1.595, Global test loss: 1.951, Global test accuracy: 34.10 

Round   9, Train loss: 1.575, Test loss: 1.677, Test accuracy: 38.59 

Round   9, Global train loss: 1.575, Global test loss: 1.935, Global test accuracy: 35.11 

Round  10, Train loss: 1.527, Test loss: 1.646, Test accuracy: 39.82 

Round  10, Global train loss: 1.527, Global test loss: 1.927, Global test accuracy: 35.21 

Round  11, Train loss: 1.498, Test loss: 1.633, Test accuracy: 40.92 

Round  11, Global train loss: 1.498, Global test loss: 1.959, Global test accuracy: 35.33 

Round  12, Train loss: 1.478, Test loss: 1.608, Test accuracy: 41.85 

Round  12, Global train loss: 1.478, Global test loss: 1.893, Global test accuracy: 36.35 

Round  13, Train loss: 1.444, Test loss: 1.573, Test accuracy: 43.09 

Round  13, Global train loss: 1.444, Global test loss: 1.921, Global test accuracy: 36.43 

Round  14, Train loss: 1.414, Test loss: 1.560, Test accuracy: 43.98 

Round  14, Global train loss: 1.414, Global test loss: 1.918, Global test accuracy: 37.91 

Round  15, Train loss: 1.386, Test loss: 1.544, Test accuracy: 44.24 

Round  15, Global train loss: 1.386, Global test loss: 1.861, Global test accuracy: 38.26 

Round  16, Train loss: 1.369, Test loss: 1.528, Test accuracy: 45.17 

Round  16, Global train loss: 1.369, Global test loss: 1.936, Global test accuracy: 38.11 

Round  17, Train loss: 1.323, Test loss: 1.519, Test accuracy: 45.80 

Round  17, Global train loss: 1.323, Global test loss: 1.920, Global test accuracy: 38.75 

Round  18, Train loss: 1.339, Test loss: 1.529, Test accuracy: 45.91 

Round  18, Global train loss: 1.339, Global test loss: 1.873, Global test accuracy: 37.66 

Round  19, Train loss: 1.341, Test loss: 1.498, Test accuracy: 47.34 

Round  19, Global train loss: 1.341, Global test loss: 1.840, Global test accuracy: 39.19 

Round  20, Train loss: 1.259, Test loss: 1.491, Test accuracy: 47.70 

Round  20, Global train loss: 1.259, Global test loss: 1.866, Global test accuracy: 38.76 

Round  21, Train loss: 1.267, Test loss: 1.492, Test accuracy: 48.03 

Round  21, Global train loss: 1.267, Global test loss: 1.841, Global test accuracy: 39.17 

Round  22, Train loss: 1.219, Test loss: 1.510, Test accuracy: 47.96 

Round  22, Global train loss: 1.219, Global test loss: 1.897, Global test accuracy: 38.97 

Round  23, Train loss: 1.252, Test loss: 1.496, Test accuracy: 48.37 

Round  23, Global train loss: 1.252, Global test loss: 1.878, Global test accuracy: 39.38 

Round  24, Train loss: 1.229, Test loss: 1.478, Test accuracy: 48.78 

Round  24, Global train loss: 1.229, Global test loss: 1.872, Global test accuracy: 39.60 

Round  25, Train loss: 1.165, Test loss: 1.473, Test accuracy: 49.09 

Round  25, Global train loss: 1.165, Global test loss: 1.960, Global test accuracy: 40.92 

Round  26, Train loss: 1.196, Test loss: 1.478, Test accuracy: 49.43 

Round  26, Global train loss: 1.196, Global test loss: 1.860, Global test accuracy: 40.25 

Round  27, Train loss: 1.144, Test loss: 1.455, Test accuracy: 50.43 

Round  27, Global train loss: 1.144, Global test loss: 1.865, Global test accuracy: 40.55 

Round  28, Train loss: 1.117, Test loss: 1.486, Test accuracy: 49.95 

Round  28, Global train loss: 1.117, Global test loss: 1.837, Global test accuracy: 40.70 

Round  29, Train loss: 1.135, Test loss: 1.487, Test accuracy: 49.95 

Round  29, Global train loss: 1.135, Global test loss: 1.868, Global test accuracy: 41.48 

Round  30, Train loss: 1.060, Test loss: 1.512, Test accuracy: 49.70 

Round  30, Global train loss: 1.060, Global test loss: 1.912, Global test accuracy: 40.56 

Round  31, Train loss: 1.086, Test loss: 1.498, Test accuracy: 50.49 

Round  31, Global train loss: 1.086, Global test loss: 1.856, Global test accuracy: 41.04 

Round  32, Train loss: 1.066, Test loss: 1.483, Test accuracy: 51.27 

Round  32, Global train loss: 1.066, Global test loss: 1.871, Global test accuracy: 40.80 

Round  33, Train loss: 1.065, Test loss: 1.477, Test accuracy: 51.45 

Round  33, Global train loss: 1.065, Global test loss: 1.853, Global test accuracy: 40.69 

Round  34, Train loss: 1.061, Test loss: 1.468, Test accuracy: 52.24 

Round  34, Global train loss: 1.061, Global test loss: 1.869, Global test accuracy: 41.35 

Round  35, Train loss: 0.994, Test loss: 1.473, Test accuracy: 52.31 

Round  35, Global train loss: 0.994, Global test loss: 1.886, Global test accuracy: 41.35 

Round  36, Train loss: 1.012, Test loss: 1.495, Test accuracy: 51.95 

Round  36, Global train loss: 1.012, Global test loss: 1.907, Global test accuracy: 41.19 

Round  37, Train loss: 0.963, Test loss: 1.470, Test accuracy: 52.52 

Round  37, Global train loss: 0.963, Global test loss: 1.951, Global test accuracy: 41.92 

Round  38, Train loss: 0.998, Test loss: 1.466, Test accuracy: 52.73 

Round  38, Global train loss: 0.998, Global test loss: 1.876, Global test accuracy: 41.12 

Round  39, Train loss: 0.972, Test loss: 1.483, Test accuracy: 52.44 

Round  39, Global train loss: 0.972, Global test loss: 1.986, Global test accuracy: 40.89 

Round  40, Train loss: 0.934, Test loss: 1.490, Test accuracy: 52.74 

Round  40, Global train loss: 0.934, Global test loss: 1.931, Global test accuracy: 42.07 

Round  41, Train loss: 0.934, Test loss: 1.484, Test accuracy: 53.41 

Round  41, Global train loss: 0.934, Global test loss: 2.082, Global test accuracy: 42.73 

Round  42, Train loss: 0.949, Test loss: 1.478, Test accuracy: 53.95 

Round  42, Global train loss: 0.949, Global test loss: 1.978, Global test accuracy: 41.96 

Round  43, Train loss: 0.902, Test loss: 1.461, Test accuracy: 54.38 

Round  43, Global train loss: 0.902, Global test loss: 1.891, Global test accuracy: 42.15 

Round  44, Train loss: 0.829, Test loss: 1.486, Test accuracy: 54.08 

Round  44, Global train loss: 0.829, Global test loss: 1.988, Global test accuracy: 41.88 

Round  45, Train loss: 0.879, Test loss: 1.483, Test accuracy: 54.08 

Round  45, Global train loss: 0.879, Global test loss: 1.916, Global test accuracy: 42.98 

Round  46, Train loss: 0.893, Test loss: 1.500, Test accuracy: 53.91 

Round  46, Global train loss: 0.893, Global test loss: 1.917, Global test accuracy: 42.04 

Round  47, Train loss: 0.886, Test loss: 1.502, Test accuracy: 54.11 

Round  47, Global train loss: 0.886, Global test loss: 1.994, Global test accuracy: 42.01 

Round  48, Train loss: 0.795, Test loss: 1.505, Test accuracy: 54.26 

Round  48, Global train loss: 0.795, Global test loss: 2.064, Global test accuracy: 42.66 

Round  49, Train loss: 0.877, Test loss: 1.538, Test accuracy: 53.89 

Round  49, Global train loss: 0.877, Global test loss: 1.926, Global test accuracy: 42.23 

Round  50, Train loss: 0.882, Test loss: 1.565, Test accuracy: 53.78 

Round  50, Global train loss: 0.882, Global test loss: 1.968, Global test accuracy: 41.13 

Round  51, Train loss: 0.841, Test loss: 1.571, Test accuracy: 53.77 

Round  51, Global train loss: 0.841, Global test loss: 1.970, Global test accuracy: 41.40 

Round  52, Train loss: 0.860, Test loss: 1.551, Test accuracy: 53.97 

Round  52, Global train loss: 0.860, Global test loss: 1.884, Global test accuracy: 42.28 

Round  53, Train loss: 0.796, Test loss: 1.538, Test accuracy: 54.43 

Round  53, Global train loss: 0.796, Global test loss: 1.970, Global test accuracy: 42.44 

Round  54, Train loss: 0.751, Test loss: 1.540, Test accuracy: 54.74 

Round  54, Global train loss: 0.751, Global test loss: 2.041, Global test accuracy: 42.36 

Round  55, Train loss: 0.770, Test loss: 1.542, Test accuracy: 54.79 

Round  55, Global train loss: 0.770, Global test loss: 2.008, Global test accuracy: 42.49 

Round  56, Train loss: 0.798, Test loss: 1.554, Test accuracy: 55.08 

Round  56, Global train loss: 0.798, Global test loss: 2.045, Global test accuracy: 42.74 

Round  57, Train loss: 0.814, Test loss: 1.543, Test accuracy: 55.62 

Round  57, Global train loss: 0.814, Global test loss: 2.073, Global test accuracy: 42.01 

Round  58, Train loss: 0.742, Test loss: 1.544, Test accuracy: 55.58 

Round  58, Global train loss: 0.742, Global test loss: 2.027, Global test accuracy: 42.73 

Round  59, Train loss: 0.771, Test loss: 1.556, Test accuracy: 55.69 

Round  59, Global train loss: 0.771, Global test loss: 2.142, Global test accuracy: 42.45 

Round  60, Train loss: 0.779, Test loss: 1.559, Test accuracy: 55.79 

Round  60, Global train loss: 0.779, Global test loss: 2.074, Global test accuracy: 42.93 

Round  61, Train loss: 0.732, Test loss: 1.565, Test accuracy: 55.64 

Round  61, Global train loss: 0.732, Global test loss: 2.276, Global test accuracy: 43.36 

Round  62, Train loss: 0.747, Test loss: 1.557, Test accuracy: 55.97 

Round  62, Global train loss: 0.747, Global test loss: 2.167, Global test accuracy: 43.08 

Round  63, Train loss: 0.764, Test loss: 1.558, Test accuracy: 55.92 

Round  63, Global train loss: 0.764, Global test loss: 2.067, Global test accuracy: 41.89 

Round  64, Train loss: 0.681, Test loss: 1.584, Test accuracy: 55.70 

Round  64, Global train loss: 0.681, Global test loss: 2.147, Global test accuracy: 42.95 

Round  65, Train loss: 0.716, Test loss: 1.567, Test accuracy: 55.96 

Round  65, Global train loss: 0.716, Global test loss: 2.113, Global test accuracy: 43.52 

Round  66, Train loss: 0.764, Test loss: 1.599, Test accuracy: 55.96 

Round  66, Global train loss: 0.764, Global test loss: 2.066, Global test accuracy: 42.94 

Round  67, Train loss: 0.756, Test loss: 1.585, Test accuracy: 56.14 

Round  67, Global train loss: 0.756, Global test loss: 2.067, Global test accuracy: 42.36 

Round  68, Train loss: 0.672, Test loss: 1.579, Test accuracy: 56.03 

Round  68, Global train loss: 0.672, Global test loss: 2.144, Global test accuracy: 43.35 

Round  69, Train loss: 0.736, Test loss: 1.602, Test accuracy: 55.73 

Round  69, Global train loss: 0.736, Global test loss: 2.071, Global test accuracy: 42.57 

Round  70, Train loss: 0.670, Test loss: 1.610, Test accuracy: 56.01 

Round  70, Global train loss: 0.670, Global test loss: 2.104, Global test accuracy: 43.16 

Round  71, Train loss: 0.683, Test loss: 1.610, Test accuracy: 55.86 

Round  71, Global train loss: 0.683, Global test loss: 2.054, Global test accuracy: 43.24 

Round  72, Train loss: 0.676, Test loss: 1.623, Test accuracy: 55.70 

Round  72, Global train loss: 0.676, Global test loss: 2.100, Global test accuracy: 42.41 

Round  73, Train loss: 0.698, Test loss: 1.630, Test accuracy: 55.85 

Round  73, Global train loss: 0.698, Global test loss: 2.101, Global test accuracy: 42.16 

Round  74, Train loss: 0.701, Test loss: 1.628, Test accuracy: 55.97 

Round  74, Global train loss: 0.701, Global test loss: 2.091, Global test accuracy: 42.54 

Round  75, Train loss: 0.703, Test loss: 1.636, Test accuracy: 55.78 

Round  75, Global train loss: 0.703, Global test loss: 2.006, Global test accuracy: 42.45 

Round  76, Train loss: 0.611, Test loss: 1.624, Test accuracy: 56.09 

Round  76, Global train loss: 0.611, Global test loss: 2.265, Global test accuracy: 43.12 

Round  77, Train loss: 0.641, Test loss: 1.605, Test accuracy: 56.40 

Round  77, Global train loss: 0.641, Global test loss: 2.114, Global test accuracy: 42.25 

Round  78, Train loss: 0.679, Test loss: 1.611, Test accuracy: 56.64 

Round  78, Global train loss: 0.679, Global test loss: 2.113, Global test accuracy: 42.65 

Round  79, Train loss: 0.613, Test loss: 1.651, Test accuracy: 56.27 

Round  79, Global train loss: 0.613, Global test loss: 2.313, Global test accuracy: 43.02 

Round  80, Train loss: 0.693, Test loss: 1.650, Test accuracy: 56.34 

Round  80, Global train loss: 0.693, Global test loss: 2.138, Global test accuracy: 43.05 

Round  81, Train loss: 0.593, Test loss: 1.664, Test accuracy: 55.91 

Round  81, Global train loss: 0.593, Global test loss: 2.273, Global test accuracy: 42.72 

Round  82, Train loss: 0.644, Test loss: 1.639, Test accuracy: 56.41 

Round  82, Global train loss: 0.644, Global test loss: 2.284, Global test accuracy: 43.49 

Round  83, Train loss: 0.567, Test loss: 1.659, Test accuracy: 56.26 

Round  83, Global train loss: 0.567, Global test loss: 2.260, Global test accuracy: 43.29 

Round  84, Train loss: 0.620, Test loss: 1.675, Test accuracy: 56.01 

Round  84, Global train loss: 0.620, Global test loss: 2.300, Global test accuracy: 42.12 

Round  85, Train loss: 0.646, Test loss: 1.658, Test accuracy: 56.56 

Round  85, Global train loss: 0.646, Global test loss: 2.214, Global test accuracy: 42.35 

Round  86, Train loss: 0.605, Test loss: 1.671, Test accuracy: 56.58 

Round  86, Global train loss: 0.605, Global test loss: 2.296, Global test accuracy: 43.48 

Round  87, Train loss: 0.589, Test loss: 1.683, Test accuracy: 56.69 

Round  87, Global train loss: 0.589, Global test loss: 2.302, Global test accuracy: 42.34 

Round  88, Train loss: 0.614, Test loss: 1.683, Test accuracy: 56.84 

Round  88, Global train loss: 0.614, Global test loss: 2.218, Global test accuracy: 42.26 

Round  89, Train loss: 0.570, Test loss: 1.696, Test accuracy: 56.70 

Round  89, Global train loss: 0.570, Global test loss: 2.253, Global test accuracy: 42.48 

Round  90, Train loss: 0.602, Test loss: 1.674, Test accuracy: 57.29 

Round  90, Global train loss: 0.602, Global test loss: 2.156, Global test accuracy: 43.17 

Round  91, Train loss: 0.560, Test loss: 1.663, Test accuracy: 57.27 

Round  91, Global train loss: 0.560, Global test loss: 2.338, Global test accuracy: 42.93 

Round  92, Train loss: 0.622, Test loss: 1.670, Test accuracy: 57.11 

Round  92, Global train loss: 0.622, Global test loss: 2.275, Global test accuracy: 42.02 

Round  93, Train loss: 0.545, Test loss: 1.673, Test accuracy: 56.91 

Round  93, Global train loss: 0.545, Global test loss: 2.480, Global test accuracy: 43.12 

Round  94, Train loss: 0.568, Test loss: 1.662, Test accuracy: 57.23 

Round  94, Global train loss: 0.568, Global test loss: 2.469, Global test accuracy: 42.77 

Round  95, Train loss: 0.585, Test loss: 1.681, Test accuracy: 57.03 

Round  95, Global train loss: 0.585, Global test loss: 2.305, Global test accuracy: 41.90 

Round  96, Train loss: 0.517, Test loss: 1.667, Test accuracy: 57.06 

Round  96, Global train loss: 0.517, Global test loss: 2.261, Global test accuracy: 42.17 

Round  97, Train loss: 0.569, Test loss: 1.684, Test accuracy: 57.19 

Round  97, Global train loss: 0.569, Global test loss: 2.359, Global test accuracy: 42.97 

Round  98, Train loss: 0.606, Test loss: 1.687, Test accuracy: 57.15 

Round  98, Global train loss: 0.606, Global test loss: 2.303, Global test accuracy: 42.22 

Round  99, Train loss: 0.562, Test loss: 1.699, Test accuracy: 57.23 

Round  99, Global train loss: 0.562, Global test loss: 2.220, Global test accuracy: 42.66 

Final Round, Train loss: 0.438, Test loss: 1.919, Test accuracy: 56.94 

Final Round, Global train loss: 0.438, Global test loss: 2.220, Global test accuracy: 42.66 

Average accuracy final 10 rounds: 57.14625000000001 

Average global accuracy final 10 rounds: 42.59324999999999 

2589.7529418468475
[1.4056363105773926, 2.5114481449127197, 3.508190631866455, 4.508052825927734, 5.508493900299072, 6.510578632354736, 7.508588075637817, 8.514979600906372, 9.517591953277588, 10.521937131881714, 11.51925015449524, 12.523168563842773, 13.516848087310791, 14.517078399658203, 15.512389898300171, 16.516427278518677, 17.523423671722412, 18.525134563446045, 19.517358541488647, 20.519691944122314, 21.512770891189575, 22.518242120742798, 23.518317699432373, 24.51844596862793, 25.517698287963867, 26.515470504760742, 27.506221294403076, 28.502708196640015, 29.506918907165527, 30.506747245788574, 31.503079175949097, 32.49821496009827, 33.49276828765869, 34.496636152267456, 35.49111819267273, 36.490330934524536, 37.4854838848114, 38.48692178726196, 39.48169994354248, 40.4825873374939, 41.476412296295166, 42.47282886505127, 43.467292070388794, 44.46924090385437, 45.46434164047241, 46.46894717216492, 47.46504282951355, 48.46642470359802, 49.46248936653137, 50.46634292602539, 51.460577726364136, 52.45265293121338, 53.4466712474823, 54.445807695388794, 55.44193649291992, 56.44158935546875, 57.436458587646484, 58.43448543548584, 59.430275201797485, 60.43077778816223, 61.43354296684265, 62.42830157279968, 63.431175231933594, 64.43081569671631, 65.43839502334595, 66.43546962738037, 67.4449315071106, 68.44452834129333, 69.44744801521301, 70.44253659248352, 71.44342517852783, 72.44396424293518, 73.44717073440552, 74.44646143913269, 75.44612646102905, 76.44596433639526, 77.44539737701416, 78.44559073448181, 79.59965538978577, 80.75755739212036, 81.90593409538269, 83.06037521362305, 84.21555948257446, 85.36921381950378, 86.52668857574463, 87.68050861358643, 88.84243488311768, 89.98906087875366, 91.13376331329346, 92.29133868217468, 93.44799542427063, 94.59591269493103, 95.74855160713196, 96.91135716438293, 98.06530904769897, 99.06883406639099, 100.07150912284851, 101.07800245285034, 102.08634877204895, 103.09028339385986, 105.09148335456848]
[20.1125, 23.6775, 25.995, 28.4675, 30.4525, 32.5075, 33.9925, 36.12, 37.32, 38.585, 39.8175, 40.9225, 41.8475, 43.095, 43.9775, 44.2375, 45.175, 45.805, 45.91, 47.3425, 47.7025, 48.0275, 47.9575, 48.37, 48.7775, 49.0925, 49.4275, 50.43, 49.945, 49.955, 49.7, 50.49, 51.265, 51.4475, 52.2375, 52.3125, 51.9525, 52.525, 52.73, 52.4375, 52.7375, 53.4125, 53.95, 54.3775, 54.0825, 54.0775, 53.905, 54.11, 54.2625, 53.8925, 53.785, 53.7725, 53.97, 54.43, 54.745, 54.7875, 55.075, 55.62, 55.58, 55.685, 55.79, 55.6375, 55.965, 55.9225, 55.695, 55.9625, 55.9625, 56.1425, 56.035, 55.73, 56.0125, 55.86, 55.705, 55.855, 55.9675, 55.7775, 56.095, 56.4025, 56.6425, 56.27, 56.34, 55.915, 56.4125, 56.255, 56.01, 56.5575, 56.5775, 56.6925, 56.835, 56.695, 57.2875, 57.2675, 57.1075, 56.905, 57.2325, 57.035, 57.0575, 57.1875, 57.1475, 57.235, 56.94]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.513, Test loss: 2.191, Test accuracy: 18.95 

Round   1, Train loss: 1.044, Test loss: 1.926, Test accuracy: 28.91 

Round   2, Train loss: 0.945, Test loss: 1.849, Test accuracy: 35.28 

Round   3, Train loss: 0.906, Test loss: 1.713, Test accuracy: 40.34 

Round   4, Train loss: 0.857, Test loss: 1.415, Test accuracy: 45.02 

Round   5, Train loss: 0.854, Test loss: 0.984, Test accuracy: 58.91 

Round   6, Train loss: 0.722, Test loss: 1.101, Test accuracy: 58.83 

Round   7, Train loss: 0.782, Test loss: 1.024, Test accuracy: 59.15 

Round   8, Train loss: 0.784, Test loss: 0.986, Test accuracy: 62.95 

Round   9, Train loss: 0.695, Test loss: 0.929, Test accuracy: 59.38 

Round  10, Train loss: 0.684, Test loss: 1.010, Test accuracy: 62.42 

Round  11, Train loss: 0.733, Test loss: 0.845, Test accuracy: 64.95 

Round  12, Train loss: 0.681, Test loss: 0.681, Test accuracy: 69.72 

Round  13, Train loss: 0.757, Test loss: 0.670, Test accuracy: 71.00 

Round  14, Train loss: 0.701, Test loss: 0.669, Test accuracy: 70.63 

Round  15, Train loss: 0.645, Test loss: 0.648, Test accuracy: 71.88 

Round  16, Train loss: 0.595, Test loss: 0.651, Test accuracy: 71.16 

Round  17, Train loss: 0.692, Test loss: 0.637, Test accuracy: 72.20 

Round  18, Train loss: 0.636, Test loss: 0.639, Test accuracy: 71.72 

Round  19, Train loss: 0.722, Test loss: 0.632, Test accuracy: 72.07 

Round  20, Train loss: 0.616, Test loss: 0.627, Test accuracy: 72.38 

Round  21, Train loss: 0.638, Test loss: 0.617, Test accuracy: 72.71 

Round  22, Train loss: 0.655, Test loss: 0.616, Test accuracy: 73.25 

Round  23, Train loss: 0.633, Test loss: 0.596, Test accuracy: 74.44 

Round  24, Train loss: 0.542, Test loss: 0.597, Test accuracy: 74.38 

Round  25, Train loss: 0.670, Test loss: 0.589, Test accuracy: 74.78 

Round  26, Train loss: 0.609, Test loss: 0.588, Test accuracy: 74.98 

Round  27, Train loss: 0.569, Test loss: 0.562, Test accuracy: 76.47 

Round  28, Train loss: 0.554, Test loss: 0.554, Test accuracy: 76.48 

Round  29, Train loss: 0.635, Test loss: 0.556, Test accuracy: 76.57 

Round  30, Train loss: 0.511, Test loss: 0.550, Test accuracy: 76.84 

Round  31, Train loss: 0.551, Test loss: 0.547, Test accuracy: 77.17 

Round  32, Train loss: 0.620, Test loss: 0.533, Test accuracy: 77.88 

Round  33, Train loss: 0.441, Test loss: 0.535, Test accuracy: 78.02 

Round  34, Train loss: 0.501, Test loss: 0.535, Test accuracy: 77.82 

Round  35, Train loss: 0.479, Test loss: 0.527, Test accuracy: 78.28 

Round  36, Train loss: 0.483, Test loss: 0.532, Test accuracy: 77.92 

Round  37, Train loss: 0.443, Test loss: 0.522, Test accuracy: 78.12 

Round  38, Train loss: 0.432, Test loss: 0.516, Test accuracy: 78.83 

Round  39, Train loss: 0.477, Test loss: 0.513, Test accuracy: 79.08 

Round  40, Train loss: 0.459, Test loss: 0.506, Test accuracy: 78.85 

Round  41, Train loss: 0.463, Test loss: 0.500, Test accuracy: 79.37 

Round  42, Train loss: 0.475, Test loss: 0.496, Test accuracy: 79.43 

Round  43, Train loss: 0.463, Test loss: 0.494, Test accuracy: 79.62 

Round  44, Train loss: 0.435, Test loss: 0.486, Test accuracy: 79.92 

Round  45, Train loss: 0.492, Test loss: 0.484, Test accuracy: 80.01 

Round  46, Train loss: 0.516, Test loss: 0.486, Test accuracy: 80.00 

Round  47, Train loss: 0.403, Test loss: 0.478, Test accuracy: 80.58 

Round  48, Train loss: 0.563, Test loss: 0.477, Test accuracy: 80.44 

Round  49, Train loss: 0.374, Test loss: 0.481, Test accuracy: 80.47 

Round  50, Train loss: 0.453, Test loss: 0.481, Test accuracy: 80.20 

Round  51, Train loss: 0.448, Test loss: 0.476, Test accuracy: 80.28 

Round  52, Train loss: 0.428, Test loss: 0.472, Test accuracy: 80.88 

Round  53, Train loss: 0.421, Test loss: 0.471, Test accuracy: 80.77 

Round  54, Train loss: 0.452, Test loss: 0.467, Test accuracy: 80.82 

Round  55, Train loss: 0.324, Test loss: 0.464, Test accuracy: 80.97 

Round  56, Train loss: 0.398, Test loss: 0.469, Test accuracy: 80.82 

Round  57, Train loss: 0.372, Test loss: 0.467, Test accuracy: 80.56 

Round  58, Train loss: 0.399, Test loss: 0.463, Test accuracy: 80.78 

Round  59, Train loss: 0.380, Test loss: 0.465, Test accuracy: 80.92 

Round  60, Train loss: 0.410, Test loss: 0.456, Test accuracy: 81.45 

Round  61, Train loss: 0.359, Test loss: 0.468, Test accuracy: 81.04 

Round  62, Train loss: 0.402, Test loss: 0.465, Test accuracy: 81.26 

Round  63, Train loss: 0.376, Test loss: 0.472, Test accuracy: 80.98 

Round  64, Train loss: 0.294, Test loss: 0.456, Test accuracy: 81.22 

Round  65, Train loss: 0.379, Test loss: 0.456, Test accuracy: 81.46 

Round  66, Train loss: 0.347, Test loss: 0.459, Test accuracy: 81.49 

Round  67, Train loss: 0.361, Test loss: 0.457, Test accuracy: 81.60 

Round  68, Train loss: 0.373, Test loss: 0.454, Test accuracy: 81.32 

Round  69, Train loss: 0.402, Test loss: 0.451, Test accuracy: 81.71 

Round  70, Train loss: 0.368, Test loss: 0.451, Test accuracy: 81.69 

Round  71, Train loss: 0.424, Test loss: 0.451, Test accuracy: 81.73 

Round  72, Train loss: 0.358, Test loss: 0.460, Test accuracy: 81.35 

Round  73, Train loss: 0.412, Test loss: 0.450, Test accuracy: 82.07 

Round  74, Train loss: 0.364, Test loss: 0.455, Test accuracy: 81.46 

Round  75, Train loss: 0.337, Test loss: 0.451, Test accuracy: 81.66 

Round  76, Train loss: 0.338, Test loss: 0.452, Test accuracy: 81.88 

Round  77, Train loss: 0.309, Test loss: 0.446, Test accuracy: 82.32 

Round  78, Train loss: 0.364, Test loss: 0.445, Test accuracy: 82.58 

Round  79, Train loss: 0.329, Test loss: 0.447, Test accuracy: 82.36 

Round  80, Train loss: 0.299, Test loss: 0.455, Test accuracy: 82.16 

Round  81, Train loss: 0.310, Test loss: 0.448, Test accuracy: 82.55 

Round  82, Train loss: 0.246, Test loss: 0.453, Test accuracy: 82.31 

Round  83, Train loss: 0.315, Test loss: 0.446, Test accuracy: 82.38 

Round  84, Train loss: 0.291, Test loss: 0.446, Test accuracy: 82.32 

Round  85, Train loss: 0.355, Test loss: 0.444, Test accuracy: 82.51 

Round  86, Train loss: 0.322, Test loss: 0.454, Test accuracy: 81.99 

Round  87, Train loss: 0.312, Test loss: 0.445, Test accuracy: 82.36 

Round  88, Train loss: 0.338, Test loss: 0.437, Test accuracy: 82.73 

Round  89, Train loss: 0.259, Test loss: 0.445, Test accuracy: 82.95 

Round  90, Train loss: 0.239, Test loss: 0.441, Test accuracy: 83.12 

Round  91, Train loss: 0.360, Test loss: 0.439, Test accuracy: 82.76 

Round  92, Train loss: 0.327, Test loss: 0.442, Test accuracy: 82.74 

Round  93, Train loss: 0.337, Test loss: 0.443, Test accuracy: 82.58 

Round  94, Train loss: 0.253, Test loss: 0.445, Test accuracy: 83.17 

Round  95, Train loss: 0.290, Test loss: 0.433, Test accuracy: 83.32 

Round  96, Train loss: 0.283, Test loss: 0.436, Test accuracy: 83.27 

Round  97, Train loss: 0.267, Test loss: 0.447, Test accuracy: 82.72 

Round  98, Train loss: 0.294, Test loss: 0.443, Test accuracy: 83.08 

Round  99, Train loss: 0.293, Test loss: 0.457, Test accuracy: 82.53 

Final Round, Train loss: 0.249, Test loss: 0.453, Test accuracy: 82.87 

Average accuracy final 10 rounds: 82.92833333333333 

923.1691346168518
[1.2594935894012451, 2.294055938720703, 3.3309028148651123, 4.360585689544678, 5.394463539123535, 6.426874399185181, 7.463225603103638, 8.490654945373535, 9.524153232574463, 10.554927825927734, 11.590500593185425, 12.622284173965454, 13.645799398422241, 14.671181917190552, 15.718880653381348, 16.75408363342285, 17.78344464302063, 18.81579899787903, 19.84320831298828, 20.88603687286377, 21.918235778808594, 22.93681502342224, 23.968611478805542, 24.989970922470093, 26.01303768157959, 27.034685850143433, 28.057441473007202, 29.081018447875977, 30.11798930168152, 31.14097237586975, 32.16353797912598, 33.18612861633301, 34.209513664245605, 35.23377585411072, 36.25420784950256, 37.27624773979187, 38.301055908203125, 39.3267502784729, 40.35391974449158, 41.38054418563843, 42.40443801879883, 43.459524154663086, 44.519734382629395, 45.584757804870605, 46.64380931854248, 47.710265159606934, 48.77523851394653, 49.84005832672119, 50.90218949317932, 51.85599064826965, 52.8078351020813, 53.76305317878723, 54.71849775314331, 55.671555280685425, 56.62470316886902, 57.577698707580566, 58.53096580505371, 59.485207080841064, 60.43757724761963, 61.39067888259888, 62.343385457992554, 63.29465365409851, 64.24904251098633, 65.20170140266418, 66.152916431427, 67.10579657554626, 68.05950808525085, 69.01279330253601, 69.96494150161743, 70.91626572608948, 71.86853575706482, 72.82050561904907, 73.77319765090942, 74.7278401851654, 75.68269872665405, 76.63788104057312, 77.59081745147705, 78.54468870162964, 79.49918580055237, 80.45070457458496, 81.40646195411682, 82.36273455619812, 83.31758999824524, 84.27295660972595, 85.22722291946411, 86.18377566337585, 87.13892269134521, 88.0939450263977, 89.04796481132507, 90.00366377830505, 90.95759344100952, 91.91209745407104, 92.86881995201111, 93.82795524597168, 94.79262852668762, 95.74492931365967, 96.69559216499329, 97.64457106590271, 98.5974657535553, 99.55154037475586, 101.33796763420105]
[18.95, 28.908333333333335, 35.28333333333333, 40.34166666666667, 45.025, 58.90833333333333, 58.825, 59.15, 62.95, 59.38333333333333, 62.425, 64.95, 69.725, 71.0, 70.63333333333334, 71.875, 71.15833333333333, 72.2, 71.725, 72.06666666666666, 72.375, 72.70833333333333, 73.25, 74.44166666666666, 74.38333333333334, 74.78333333333333, 74.98333333333333, 76.46666666666667, 76.48333333333333, 76.56666666666666, 76.84166666666667, 77.175, 77.88333333333334, 78.01666666666667, 77.81666666666666, 78.28333333333333, 77.925, 78.11666666666666, 78.825, 79.08333333333333, 78.85, 79.36666666666666, 79.43333333333334, 79.61666666666666, 79.925, 80.00833333333334, 80.0, 80.575, 80.44166666666666, 80.46666666666667, 80.2, 80.28333333333333, 80.88333333333334, 80.76666666666667, 80.81666666666666, 80.96666666666667, 80.81666666666666, 80.55833333333334, 80.775, 80.925, 81.45, 81.04166666666667, 81.25833333333334, 80.98333333333333, 81.21666666666667, 81.45833333333333, 81.49166666666666, 81.6, 81.31666666666666, 81.70833333333333, 81.69166666666666, 81.73333333333333, 81.35, 82.06666666666666, 81.45833333333333, 81.65833333333333, 81.88333333333334, 82.31666666666666, 82.58333333333333, 82.35833333333333, 82.15833333333333, 82.55, 82.30833333333334, 82.375, 82.31666666666666, 82.50833333333334, 81.99166666666666, 82.35833333333333, 82.73333333333333, 82.95, 83.125, 82.75833333333334, 82.74166666666666, 82.575, 83.175, 83.31666666666666, 83.26666666666667, 82.71666666666667, 83.08333333333333, 82.525, 82.86666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307832
307842
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.581, Test loss: 2.189, Test accuracy: 20.07
Round   1, Train loss: 1.093, Test loss: 1.727, Test accuracy: 28.29
Round   2, Train loss: 1.001, Test loss: 1.532, Test accuracy: 39.65
Round   3, Train loss: 0.981, Test loss: 1.265, Test accuracy: 50.22
Round   4, Train loss: 0.912, Test loss: 1.174, Test accuracy: 52.09
Round   5, Train loss: 0.816, Test loss: 1.022, Test accuracy: 59.26
Round   6, Train loss: 0.794, Test loss: 0.903, Test accuracy: 63.10
Round   7, Train loss: 0.783, Test loss: 0.879, Test accuracy: 62.82
Round   8, Train loss: 0.784, Test loss: 0.748, Test accuracy: 68.00
Round   9, Train loss: 0.754, Test loss: 0.720, Test accuracy: 69.86
Round  10, Train loss: 0.649, Test loss: 0.695, Test accuracy: 71.22
Round  11, Train loss: 0.793, Test loss: 0.680, Test accuracy: 71.14
Round  12, Train loss: 0.680, Test loss: 0.678, Test accuracy: 72.49
Round  13, Train loss: 0.666, Test loss: 0.656, Test accuracy: 73.47
Round  14, Train loss: 0.617, Test loss: 0.643, Test accuracy: 73.48
Round  15, Train loss: 0.593, Test loss: 0.630, Test accuracy: 74.28
Round  16, Train loss: 0.674, Test loss: 0.646, Test accuracy: 73.51
Round  17, Train loss: 0.513, Test loss: 0.611, Test accuracy: 74.26
Round  18, Train loss: 0.708, Test loss: 0.624, Test accuracy: 74.92
Round  19, Train loss: 0.597, Test loss: 0.622, Test accuracy: 74.61
Round  20, Train loss: 0.603, Test loss: 0.598, Test accuracy: 75.71
Round  21, Train loss: 0.607, Test loss: 0.588, Test accuracy: 76.14
Round  22, Train loss: 0.560, Test loss: 0.573, Test accuracy: 75.83
Round  23, Train loss: 0.544, Test loss: 0.571, Test accuracy: 76.63
Round  24, Train loss: 0.573, Test loss: 0.564, Test accuracy: 76.94
Round  25, Train loss: 0.546, Test loss: 0.568, Test accuracy: 76.70
Round  26, Train loss: 0.510, Test loss: 0.563, Test accuracy: 76.39
Round  27, Train loss: 0.539, Test loss: 0.548, Test accuracy: 77.67
Round  28, Train loss: 0.537, Test loss: 0.553, Test accuracy: 77.29
Round  29, Train loss: 0.502, Test loss: 0.542, Test accuracy: 77.58
Round  30, Train loss: 0.510, Test loss: 0.523, Test accuracy: 78.36
Round  31, Train loss: 0.596, Test loss: 0.515, Test accuracy: 78.99
Round  32, Train loss: 0.480, Test loss: 0.514, Test accuracy: 79.12
Round  33, Train loss: 0.528, Test loss: 0.500, Test accuracy: 79.35
Round  34, Train loss: 0.589, Test loss: 0.507, Test accuracy: 79.41
Round  35, Train loss: 0.637, Test loss: 0.502, Test accuracy: 79.42
Round  36, Train loss: 0.452, Test loss: 0.494, Test accuracy: 79.55
Round  37, Train loss: 0.459, Test loss: 0.497, Test accuracy: 79.44
Round  38, Train loss: 0.500, Test loss: 0.491, Test accuracy: 80.07
Round  39, Train loss: 0.517, Test loss: 0.490, Test accuracy: 79.84
Round  40, Train loss: 0.470, Test loss: 0.489, Test accuracy: 80.09
Round  41, Train loss: 0.452, Test loss: 0.493, Test accuracy: 79.83
Round  42, Train loss: 0.414, Test loss: 0.496, Test accuracy: 79.70
Round  43, Train loss: 0.385, Test loss: 0.479, Test accuracy: 80.49
Round  44, Train loss: 0.461, Test loss: 0.475, Test accuracy: 80.46
Round  45, Train loss: 0.474, Test loss: 0.473, Test accuracy: 80.34
Round  46, Train loss: 0.412, Test loss: 0.471, Test accuracy: 80.42
Round  47, Train loss: 0.479, Test loss: 0.479, Test accuracy: 80.70
Round  48, Train loss: 0.458, Test loss: 0.471, Test accuracy: 80.80
Round  49, Train loss: 0.493, Test loss: 0.469, Test accuracy: 80.86
Round  50, Train loss: 0.406, Test loss: 0.467, Test accuracy: 81.04
Round  51, Train loss: 0.490, Test loss: 0.458, Test accuracy: 81.28
Round  52, Train loss: 0.459, Test loss: 0.460, Test accuracy: 81.26
Round  53, Train loss: 0.338, Test loss: 0.457, Test accuracy: 81.67
Round  54, Train loss: 0.393, Test loss: 0.458, Test accuracy: 81.25
Round  55, Train loss: 0.416, Test loss: 0.456, Test accuracy: 81.29
Round  56, Train loss: 0.418, Test loss: 0.451, Test accuracy: 81.92
Round  57, Train loss: 0.453, Test loss: 0.448, Test accuracy: 81.99
Round  58, Train loss: 0.438, Test loss: 0.449, Test accuracy: 81.60
Round  59, Train loss: 0.345, Test loss: 0.456, Test accuracy: 81.28
Round  60, Train loss: 0.428, Test loss: 0.446, Test accuracy: 82.11
Round  61, Train loss: 0.408, Test loss: 0.440, Test accuracy: 82.47
Round  62, Train loss: 0.327, Test loss: 0.441, Test accuracy: 82.16
Round  63, Train loss: 0.379, Test loss: 0.436, Test accuracy: 82.78
Round  64, Train loss: 0.400, Test loss: 0.432, Test accuracy: 82.50
Round  65, Train loss: 0.407, Test loss: 0.431, Test accuracy: 82.55
Round  66, Train loss: 0.351, Test loss: 0.439, Test accuracy: 82.26
Round  67, Train loss: 0.369, Test loss: 0.431, Test accuracy: 82.73
Round  68, Train loss: 0.346, Test loss: 0.433, Test accuracy: 82.58
Round  69, Train loss: 0.366, Test loss: 0.437, Test accuracy: 82.53
Round  70, Train loss: 0.342, Test loss: 0.437, Test accuracy: 82.15
Round  71, Train loss: 0.370, Test loss: 0.434, Test accuracy: 82.46
Round  72, Train loss: 0.378, Test loss: 0.441, Test accuracy: 82.51
Round  73, Train loss: 0.332, Test loss: 0.432, Test accuracy: 82.94
Round  74, Train loss: 0.359, Test loss: 0.429, Test accuracy: 82.84
Round  75, Train loss: 0.303, Test loss: 0.430, Test accuracy: 82.87
Round  76, Train loss: 0.379, Test loss: 0.430, Test accuracy: 82.87
Round  77, Train loss: 0.309, Test loss: 0.427, Test accuracy: 82.92
Round  78, Train loss: 0.332, Test loss: 0.422, Test accuracy: 83.17
Round  79, Train loss: 0.274, Test loss: 0.430, Test accuracy: 82.96
Round  80, Train loss: 0.339, Test loss: 0.427, Test accuracy: 82.87
Round  81, Train loss: 0.297, Test loss: 0.428, Test accuracy: 83.14
Round  82, Train loss: 0.402, Test loss: 0.427, Test accuracy: 82.95
Round  83, Train loss: 0.389, Test loss: 0.428, Test accuracy: 82.97
Round  84, Train loss: 0.327, Test loss: 0.424, Test accuracy: 82.80
Round  85, Train loss: 0.339, Test loss: 0.425, Test accuracy: 82.99
Round  86, Train loss: 0.355, Test loss: 0.427, Test accuracy: 83.08
Round  87, Train loss: 0.303, Test loss: 0.423, Test accuracy: 83.03
Round  88, Train loss: 0.262, Test loss: 0.425, Test accuracy: 83.12
Round  89, Train loss: 0.259, Test loss: 0.424, Test accuracy: 83.01
Round  90, Train loss: 0.308, Test loss: 0.427, Test accuracy: 83.40
Round  91, Train loss: 0.305, Test loss: 0.422, Test accuracy: 83.49
Round  92, Train loss: 0.339, Test loss: 0.424, Test accuracy: 83.26
Round  93, Train loss: 0.328, Test loss: 0.431, Test accuracy: 83.22
Round  94, Train loss: 0.341, Test loss: 0.424, Test accuracy: 83.45
Round  95, Train loss: 0.290, Test loss: 0.412, Test accuracy: 83.86
Round  96, Train loss: 0.317, Test loss: 0.421, Test accuracy: 83.51
Round  97, Train loss: 0.309, Test loss: 0.420, Test accuracy: 83.65
Round  98, Train loss: 0.269, Test loss: 0.424, Test accuracy: 83.33
Round  99, Train loss: 0.295, Test loss: 0.426, Test accuracy: 83.52
Final Round, Train loss: 0.239, Test loss: 0.425, Test accuracy: 83.50
Average accuracy final 10 rounds: 83.46916666666667
1157.9480786323547
[1.705477237701416, 3.0145599842071533, 4.317127704620361, 5.62860369682312, 6.9265735149383545, 8.232681512832642, 9.53896450996399, 10.84509801864624, 12.152204513549805, 13.449135303497314, 14.7478346824646, 16.050101280212402, 17.348573207855225, 18.648288249969482, 19.948044300079346, 21.24522829055786, 22.541399717330933, 23.8376681804657, 25.133180379867554, 26.435524225234985, 27.74131202697754, 29.045193910598755, 30.362188816070557, 31.660288095474243, 32.96757650375366, 34.27751684188843, 35.58339333534241, 36.89228677749634, 38.19158864021301, 39.5118932723999, 40.815956115722656, 42.12249755859375, 43.41936469078064, 44.81483817100525, 46.17301940917969, 47.5975558757782, 49.008503437042236, 50.41422772407532, 51.81857681274414, 53.22369074821472, 54.62857007980347, 56.04159736633301, 57.44260358810425, 58.86111235618591, 60.26930332183838, 61.67885780334473, 63.09094429016113, 64.49680709838867, 65.90727639198303, 67.31505727767944, 68.7237286567688, 70.1417031288147, 71.55262589454651, 72.9670934677124, 74.37807083129883, 75.78988409042358, 77.20075273513794, 78.61083054542542, 80.02120113372803, 81.42962217330933, 82.83903980255127, 84.2531967163086, 85.66381454467773, 87.0697066783905, 88.47419238090515, 89.88056230545044, 91.28901934623718, 92.69810700416565, 94.10554361343384, 95.5211775302887, 96.9332263469696, 98.34614968299866, 99.75369811058044, 101.15891647338867, 102.56332087516785, 103.97377943992615, 105.38547086715698, 106.79701256752014, 108.2102267742157, 109.62408709526062, 111.03349757194519, 112.44464826583862, 113.85052728652954, 115.24488472938538, 116.64783310890198, 118.04765439033508, 119.46414947509766, 120.87834620475769, 122.28941440582275, 123.70228147506714, 125.10830640792847, 126.51413655281067, 127.9214391708374, 129.328369140625, 130.74401092529297, 132.16426539421082, 133.5750765800476, 134.9875829219818, 136.39938020706177, 137.81419730186462, 139.90407419204712]
[20.075, 28.291666666666668, 39.65, 50.21666666666667, 52.09166666666667, 59.25833333333333, 63.1, 62.81666666666667, 68.0, 69.85833333333333, 71.225, 71.14166666666667, 72.49166666666666, 73.475, 73.48333333333333, 74.275, 73.50833333333334, 74.25833333333334, 74.91666666666667, 74.60833333333333, 75.70833333333333, 76.14166666666667, 75.83333333333333, 76.63333333333334, 76.94166666666666, 76.7, 76.39166666666667, 77.66666666666667, 77.29166666666667, 77.58333333333333, 78.35833333333333, 78.99166666666666, 79.11666666666666, 79.35, 79.40833333333333, 79.41666666666667, 79.55, 79.44166666666666, 80.06666666666666, 79.84166666666667, 80.09166666666667, 79.825, 79.7, 80.49166666666666, 80.45833333333333, 80.34166666666667, 80.425, 80.7, 80.8, 80.85833333333333, 81.04166666666667, 81.28333333333333, 81.25833333333334, 81.675, 81.25, 81.29166666666667, 81.91666666666667, 81.99166666666666, 81.6, 81.28333333333333, 82.10833333333333, 82.475, 82.15833333333333, 82.78333333333333, 82.5, 82.55, 82.25833333333334, 82.73333333333333, 82.575, 82.53333333333333, 82.15, 82.45833333333333, 82.50833333333334, 82.94166666666666, 82.84166666666667, 82.86666666666666, 82.86666666666666, 82.91666666666667, 83.16666666666667, 82.95833333333333, 82.86666666666666, 83.14166666666667, 82.95, 82.96666666666667, 82.8, 82.99166666666666, 83.075, 83.03333333333333, 83.11666666666666, 83.00833333333334, 83.4, 83.49166666666666, 83.25833333333334, 83.225, 83.45, 83.85833333333333, 83.50833333333334, 83.65, 83.33333333333333, 83.51666666666667, 83.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.170, Test loss: 2.537, Test accuracy: 10.89
Round   1, Train loss: 1.001, Test loss: 2.404, Test accuracy: 13.40
Round   2, Train loss: 0.921, Test loss: 2.304, Test accuracy: 19.73
Round   3, Train loss: 0.884, Test loss: 2.254, Test accuracy: 25.38
Round   4, Train loss: 0.824, Test loss: 2.172, Test accuracy: 21.44
Round   5, Train loss: 0.789, Test loss: 2.227, Test accuracy: 21.69
Round   6, Train loss: 0.729, Test loss: 2.135, Test accuracy: 26.41
Round   7, Train loss: 0.734, Test loss: 2.088, Test accuracy: 24.94
Round   8, Train loss: 0.802, Test loss: 2.177, Test accuracy: 26.93
Round   9, Train loss: 0.754, Test loss: 2.091, Test accuracy: 27.12
Round  10, Train loss: 0.743, Test loss: 2.079, Test accuracy: 26.45
Round  11, Train loss: 0.686, Test loss: 2.130, Test accuracy: 27.48
Round  12, Train loss: 0.672, Test loss: 2.087, Test accuracy: 31.23
Round  13, Train loss: 0.691, Test loss: 2.137, Test accuracy: 26.04
Round  14, Train loss: 0.607, Test loss: 2.130, Test accuracy: 26.53
Round  15, Train loss: 0.585, Test loss: 2.340, Test accuracy: 31.93
Round  16, Train loss: 0.548, Test loss: 2.000, Test accuracy: 31.06
Round  17, Train loss: 0.635, Test loss: 2.043, Test accuracy: 25.95
Round  18, Train loss: 0.657, Test loss: 2.055, Test accuracy: 27.22
Round  19, Train loss: 0.642, Test loss: 2.033, Test accuracy: 30.78
Round  20, Train loss: 0.655, Test loss: 2.151, Test accuracy: 27.93
Round  21, Train loss: 0.662, Test loss: 2.298, Test accuracy: 27.24
Round  22, Train loss: 0.501, Test loss: 1.919, Test accuracy: 34.88
Round  23, Train loss: 0.556, Test loss: 2.040, Test accuracy: 33.44
Round  24, Train loss: 0.501, Test loss: 1.930, Test accuracy: 34.94
Round  25, Train loss: 0.540, Test loss: 2.156, Test accuracy: 31.61
Round  26, Train loss: 0.561, Test loss: 2.156, Test accuracy: 32.92
Round  27, Train loss: 0.567, Test loss: 1.979, Test accuracy: 28.42
Round  28, Train loss: 0.538, Test loss: 2.178, Test accuracy: 27.97
Round  29, Train loss: 0.460, Test loss: 2.234, Test accuracy: 29.49
Round  30, Train loss: 0.435, Test loss: 2.457, Test accuracy: 30.73
Round  31, Train loss: 0.587, Test loss: 1.869, Test accuracy: 34.02
Round  32, Train loss: 0.507, Test loss: 2.579, Test accuracy: 33.46
Round  33, Train loss: 0.536, Test loss: 2.036, Test accuracy: 34.48
Round  34, Train loss: 0.515, Test loss: 2.546, Test accuracy: 32.47
Round  35, Train loss: 0.479, Test loss: 2.012, Test accuracy: 31.62
Round  36, Train loss: 0.432, Test loss: 2.064, Test accuracy: 31.96
Round  37, Train loss: 0.428, Test loss: 2.730, Test accuracy: 28.48
Round  38, Train loss: 0.518, Test loss: 2.001, Test accuracy: 31.44
Round  39, Train loss: 0.522, Test loss: 1.930, Test accuracy: 32.33
Round  40, Train loss: 0.438, Test loss: 2.274, Test accuracy: 28.39
Round  41, Train loss: 0.489, Test loss: 2.344, Test accuracy: 30.25
Round  42, Train loss: 0.449, Test loss: 2.395, Test accuracy: 30.82
Round  43, Train loss: 0.373, Test loss: 2.530, Test accuracy: 32.54
Round  44, Train loss: 0.391, Test loss: 2.276, Test accuracy: 33.44
Round  45, Train loss: 0.389, Test loss: 2.221, Test accuracy: 35.42
Round  46, Train loss: 0.347, Test loss: 2.122, Test accuracy: 37.88
Round  47, Train loss: 0.448, Test loss: 1.966, Test accuracy: 35.80
Round  48, Train loss: 0.375, Test loss: 2.310, Test accuracy: 32.66
Round  49, Train loss: 0.381, Test loss: 2.307, Test accuracy: 33.84
Round  50, Train loss: 0.358, Test loss: 2.121, Test accuracy: 38.27
Round  51, Train loss: 0.329, Test loss: 2.466, Test accuracy: 33.78
Round  52, Train loss: 0.436, Test loss: 1.858, Test accuracy: 35.42
Round  53, Train loss: 0.371, Test loss: 2.188, Test accuracy: 34.39
Round  54, Train loss: 0.393, Test loss: 2.069, Test accuracy: 34.55
Round  55, Train loss: 0.343, Test loss: 2.189, Test accuracy: 34.22
Round  56, Train loss: 0.396, Test loss: 2.066, Test accuracy: 34.98
Round  57, Train loss: 0.371, Test loss: 2.132, Test accuracy: 34.49
Round  58, Train loss: 0.359, Test loss: 2.204, Test accuracy: 35.99
Round  59, Train loss: 0.272, Test loss: 2.560, Test accuracy: 35.31
Round  60, Train loss: 0.333, Test loss: 2.190, Test accuracy: 35.74
Round  61, Train loss: 0.337, Test loss: 2.378, Test accuracy: 31.22
Round  62, Train loss: 0.309, Test loss: 2.025, Test accuracy: 34.83
Round  63, Train loss: 0.334, Test loss: 2.036, Test accuracy: 36.01
Round  64, Train loss: 0.346, Test loss: 1.914, Test accuracy: 38.23
Round  65, Train loss: 0.356, Test loss: 2.458, Test accuracy: 32.57
Round  66, Train loss: 0.327, Test loss: 2.704, Test accuracy: 32.04
Round  67, Train loss: 0.347, Test loss: 2.403, Test accuracy: 34.88
Round  68, Train loss: 0.323, Test loss: 2.167, Test accuracy: 37.17
Round  69, Train loss: 0.322, Test loss: 2.616, Test accuracy: 30.44
Round  70, Train loss: 0.325, Test loss: 2.239, Test accuracy: 34.49
Round  71, Train loss: 0.287, Test loss: 2.357, Test accuracy: 35.10
Round  72, Train loss: 0.227, Test loss: 2.870, Test accuracy: 37.12
Round  73, Train loss: 0.267, Test loss: 2.217, Test accuracy: 37.89
Round  74, Train loss: 0.313, Test loss: 2.490, Test accuracy: 35.79
Round  75, Train loss: 0.388, Test loss: 2.208, Test accuracy: 35.01
Round  76, Train loss: 0.292, Test loss: 2.161, Test accuracy: 37.70
Round  77, Train loss: 0.241, Test loss: 2.135, Test accuracy: 37.78
Round  78, Train loss: 0.329, Test loss: 2.397, Test accuracy: 35.42
Round  79, Train loss: 0.273, Test loss: 2.462, Test accuracy: 36.73
Round  80, Train loss: 0.283, Test loss: 2.484, Test accuracy: 34.14
Round  81, Train loss: 0.239, Test loss: 2.316, Test accuracy: 37.65
Round  82, Train loss: 0.230, Test loss: 2.370, Test accuracy: 37.31
Round  83, Train loss: 0.214, Test loss: 2.414, Test accuracy: 36.02
Round  84, Train loss: 0.272, Test loss: 2.386, Test accuracy: 37.69
Round  85, Train loss: 0.243, Test loss: 2.700, Test accuracy: 34.31
Round  86, Train loss: 0.264, Test loss: 2.426, Test accuracy: 31.93
Round  87, Train loss: 0.285, Test loss: 2.534, Test accuracy: 34.99
Round  88, Train loss: 0.216, Test loss: 2.406, Test accuracy: 32.26
Round  89, Train loss: 0.252, Test loss: 2.872, Test accuracy: 30.48
Round  90, Train loss: 0.190, Test loss: 2.423, Test accuracy: 36.80
Round  91, Train loss: 0.213, Test loss: 3.073, Test accuracy: 34.98
Round  92, Train loss: 0.256, Test loss: 3.236, Test accuracy: 29.52
Round  93, Train loss: 0.236, Test loss: 2.240, Test accuracy: 38.46
Round  94, Train loss: 0.256, Test loss: 2.420, Test accuracy: 36.58
Round  95, Train loss: 0.291, Test loss: 2.142, Test accuracy: 35.23
Round  96, Train loss: 0.215, Test loss: 2.378, Test accuracy: 36.41
Round  97, Train loss: 0.185, Test loss: 2.556, Test accuracy: 37.28
Round  98, Train loss: 0.235, Test loss: 2.221, Test accuracy: 36.58
Round  99, Train loss: 0.195, Test loss: 2.772, Test accuracy: 35.52
Final Round, Train loss: 0.213, Test loss: 2.051, Test accuracy: 38.98
Average accuracy final 10 rounds: 35.73583333333333
1964.509919166565
[3.1774444580078125, 6.081580638885498, 8.992592096328735, 11.897983074188232, 14.802720308303833, 17.708308458328247, 20.61453342437744, 23.531115770339966, 26.43891453742981, 29.366217851638794, 32.24902367591858, 35.13479804992676, 38.040985107421875, 40.933443784713745, 43.835883378982544, 46.75335192680359, 49.67962956428528, 52.57632327079773, 55.4696261882782, 58.36028337478638, 61.24746775627136, 64.13009691238403, 67.03544616699219, 69.9432520866394, 72.84706783294678, 75.74688792228699, 78.64801549911499, 81.52046823501587, 84.41709852218628, 87.30898571014404, 90.18562507629395, 93.06896162033081, 95.95511198043823, 98.8431043624878, 101.71783661842346, 104.58987498283386, 107.47149157524109, 110.07803416252136, 112.70411276817322, 115.31014609336853, 117.924809217453, 120.53252124786377, 123.14086937904358, 125.75343346595764, 128.3530216217041, 130.9602198600769, 133.56321167945862, 136.16784572601318, 138.7733917236328, 141.38285422325134, 143.9995150566101, 146.61800336837769, 149.23650431632996, 151.8557858467102, 154.47126007080078, 157.08901715278625, 159.70458698272705, 162.32139253616333, 164.93797039985657, 167.5522084236145, 170.1648666858673, 172.78864240646362, 175.404522895813, 178.01577973365784, 180.62882208824158, 183.2189064025879, 185.84101176261902, 188.46456718444824, 191.09285593032837, 193.69821524620056, 196.3103802204132, 198.91225457191467, 201.51017212867737, 204.12393450737, 206.72355318069458, 209.32956457138062, 211.93429589271545, 214.54285335540771, 217.14753460884094, 219.75779008865356, 222.38247537612915, 224.99414491653442, 227.6240725517273, 230.22808504104614, 232.83173942565918, 235.42735266685486, 238.03282570838928, 240.65132236480713, 243.25666046142578, 245.8647198677063, 248.46841597557068, 251.07401251792908, 253.68775820732117, 256.30578994750977, 258.9220767021179, 261.5432014465332, 264.1652865409851, 266.7827615737915, 269.3955478668213, 272.00853419303894, 274.6282308101654]
[10.891666666666667, 13.4, 19.733333333333334, 25.375, 21.441666666666666, 21.691666666666666, 26.408333333333335, 24.941666666666666, 26.925, 27.116666666666667, 26.45, 27.475, 31.225, 26.041666666666668, 26.533333333333335, 31.933333333333334, 31.058333333333334, 25.95, 27.216666666666665, 30.783333333333335, 27.925, 27.241666666666667, 34.88333333333333, 33.44166666666667, 34.94166666666667, 31.608333333333334, 32.925, 28.416666666666668, 27.966666666666665, 29.491666666666667, 30.733333333333334, 34.025, 33.458333333333336, 34.483333333333334, 32.46666666666667, 31.616666666666667, 31.958333333333332, 28.475, 31.441666666666666, 32.325, 28.391666666666666, 30.25, 30.816666666666666, 32.541666666666664, 33.44166666666667, 35.425, 37.88333333333333, 35.8, 32.65833333333333, 33.84166666666667, 38.266666666666666, 33.78333333333333, 35.425, 34.391666666666666, 34.55, 34.21666666666667, 34.983333333333334, 34.49166666666667, 35.99166666666667, 35.30833333333333, 35.74166666666667, 31.216666666666665, 34.833333333333336, 36.00833333333333, 38.225, 32.56666666666667, 32.041666666666664, 34.88333333333333, 37.175, 30.441666666666666, 34.49166666666667, 35.1, 37.125, 37.891666666666666, 35.791666666666664, 35.00833333333333, 37.7, 37.78333333333333, 35.416666666666664, 36.725, 34.141666666666666, 37.65, 37.30833333333333, 36.025, 37.69166666666667, 34.30833333333333, 31.925, 34.99166666666667, 32.25833333333333, 30.475, 36.8, 34.975, 29.525, 38.458333333333336, 36.583333333333336, 35.233333333333334, 36.40833333333333, 37.28333333333333, 36.575, 35.516666666666666, 38.975]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.267, Test loss: 2.294, Test accuracy: 14.86 

Round   0, Global train loss: 2.267, Global test loss: 2.297, Global test accuracy: 13.72 

Round   1, Train loss: 2.238, Test loss: 2.290, Test accuracy: 16.62 

Round   1, Global train loss: 2.238, Global test loss: 2.297, Global test accuracy: 13.71 

Round   2, Train loss: 2.250, Test loss: 2.289, Test accuracy: 18.07 

Round   2, Global train loss: 2.250, Global test loss: 2.296, Global test accuracy: 13.82 

Round   3, Train loss: 2.254, Test loss: 2.287, Test accuracy: 18.68 

Round   3, Global train loss: 2.254, Global test loss: 2.296, Global test accuracy: 13.67 

Round   4, Train loss: 2.229, Test loss: 2.286, Test accuracy: 18.39 

Round   4, Global train loss: 2.229, Global test loss: 2.296, Global test accuracy: 13.71 

Round   5, Train loss: 2.227, Test loss: 2.287, Test accuracy: 17.78 

Round   5, Global train loss: 2.227, Global test loss: 2.296, Global test accuracy: 13.58 

Round   6, Train loss: 2.234, Test loss: 2.287, Test accuracy: 16.71 

Round   6, Global train loss: 2.234, Global test loss: 2.296, Global test accuracy: 13.46 

Round   7, Train loss: 2.249, Test loss: 2.284, Test accuracy: 15.27 

Round   7, Global train loss: 2.249, Global test loss: 2.298, Global test accuracy: 13.23 

Round   8, Train loss: 2.215, Test loss: 2.285, Test accuracy: 14.47 

Round   8, Global train loss: 2.215, Global test loss: 2.301, Global test accuracy: 11.06 

Round   9, Train loss: nan, Test loss: nan, Test accuracy: 13.57 

Round   9, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  10, Train loss: nan, Test loss: nan, Test accuracy: 13.57 

Round  10, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  11, Train loss: nan, Test loss: nan, Test accuracy: 15.07 

Round  11, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  12, Train loss: nan, Test loss: nan, Test accuracy: 15.85 

Round  12, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  13, Train loss: nan, Test loss: nan, Test accuracy: 14.88 

Round  13, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  14, Train loss: nan, Test loss: nan, Test accuracy: 13.76 

Round  14, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  15, Train loss: nan, Test loss: nan, Test accuracy: 14.97 

Round  15, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  16, Train loss: nan, Test loss: nan, Test accuracy: 14.41 

Round  16, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  17, Train loss: nan, Test loss: nan, Test accuracy: 14.41 

Round  17, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  18, Train loss: nan, Test loss: nan, Test accuracy: 14.41 

Round  18, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  19, Train loss: nan, Test loss: nan, Test accuracy: 14.41 

Round  19, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  20, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  20, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  21, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  21, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  22, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  22, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  23, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  23, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  24, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  24, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  25, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  25, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  26, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  26, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  27, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  27, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  28, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  28, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  29, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  29, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  30, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  30, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  31, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  31, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  32, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  32, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  33, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  33, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  34, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  34, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  35, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  35, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  36, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  36, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  37, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  37, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  38, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  38, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  39, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  39, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  40, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  40, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  41, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  41, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  42, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  42, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  43, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  43, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  44, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  44, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  45, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  45, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  46, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  46, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  47, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  47, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  48, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  48, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  49, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  49, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  50, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  50, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  51, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  51, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  52, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  52, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  53, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  53, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  54, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  54, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  55, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  55, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  56, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  56, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  57, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  57, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  58, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  58, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  59, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  59, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  60, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  60, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  61, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  61, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  62, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  62, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  63, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  63, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  64, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  64, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  65, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  65, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  66, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  66, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  67, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  67, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  68, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  68, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  69, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  69, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  70, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  70, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  71, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  71, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  72, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  72, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  73, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  73, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  74, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  74, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  75, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  75, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  76, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  76, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  77, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  77, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  78, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  78, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  79, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  79, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  80, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  80, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  81, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  81, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  82, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  82, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  83, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  83, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  84, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  84, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  85, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  85, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  86, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  86, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  87, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  87, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  88, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  88, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  89, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  89, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  90, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  90, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  91, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  91, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  92, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  92, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  93, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  93, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  94, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  94, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  95, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  95, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  96, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  96, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  97, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  97, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  98, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  98, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round  99, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round  99, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 100, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 100, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 101, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 101, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 102, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 102, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 103, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 103, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 104, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 104, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 105, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 105, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 106, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 106, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 107, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 107, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 108, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 108, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 109, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 109, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 110, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 110, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 111, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 111, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 112, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 112, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 113, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 113, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 114, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 114, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 115, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 115, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 116, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 116, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 117, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 117, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 118, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 118, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 119, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 119, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 120, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 120, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 121, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 121, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 122, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 122, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 123, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 123, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 124, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 124, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 125, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 125, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 126, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 126, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 127, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 127, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 128, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 128, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 129, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 129, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 130, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 130, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 131, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 131, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 132, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 132, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 133, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 133, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 134, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 134, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 135, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 135, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 136, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 136, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 137, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 137, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 138, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 138, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 139, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 139, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 140, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 140, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 141, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 141, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 142, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 142, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 143, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 143, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 144, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 144, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 145, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 145, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 146, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 146, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 147, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 147, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 148, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 148, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 149, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 149, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 150, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 150, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 151, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 151, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 152, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 152, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 153, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 153, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 154, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 154, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 155, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 155, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 156, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 156, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 157, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 157, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 158, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 158, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 159, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 159, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 160, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 160, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 161, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 161, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 162, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 162, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 163, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 163, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 164, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 164, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 165, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 165, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 166, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 166, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 167, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 167, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 168, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 168, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 169, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 169, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 170, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 170, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 171, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 171, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 172, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 172, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 173, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 173, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 174, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 174, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 175, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 175, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 176, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 176, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 177, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 177, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 178, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 178, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 179, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 179, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 180, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 180, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 181, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 181, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 182, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 182, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 183, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 183, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 184, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 184, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 185, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 185, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 186, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 186, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 187, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 187, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 188, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 188, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 189, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 189, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 190, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 190, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 13.33 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 13.33 

Average accuracy final 10 rounds: 13.333333333333337 

Average global accuracy final 10 rounds: 13.333333333333337 

3936.8062422275543
[1.476386547088623, 2.732004404067993, 3.9840662479400635, 5.246387720108032, 6.50384521484375, 7.770944595336914, 9.033199310302734, 10.295193433761597, 11.55059003829956, 12.813768148422241, 14.07010793685913, 15.328137636184692, 16.58400559425354, 17.844196319580078, 19.104716777801514, 20.363723278045654, 21.62656044960022, 22.886736631393433, 24.13930583000183, 25.40003728866577, 26.661567449569702, 27.917736291885376, 29.179325342178345, 30.444231271743774, 31.708271980285645, 32.96473240852356, 34.224185943603516, 35.48036742210388, 36.74265170097351, 38.006781816482544, 39.26808190345764, 40.52216839790344, 41.78281235694885, 43.04216480255127, 44.294371604919434, 45.55141258239746, 46.813058853149414, 48.07527136802673, 49.3292932510376, 50.58429217338562, 51.832093715667725, 53.074827432632446, 54.31872582435608, 55.56417894363403, 56.81446862220764, 58.0596444606781, 59.15020704269409, 60.25161290168762, 61.34301972389221, 62.43140363693237, 63.525397300720215, 64.61917352676392, 65.71281623840332, 66.80861759185791, 67.91401433944702, 69.02018690109253, 70.1198525428772, 71.21900534629822, 72.317622423172, 73.42230725288391, 74.52828001976013, 75.62266850471497, 76.72242474555969, 77.8321328163147, 78.94478726387024, 80.0461061000824, 81.14415144920349, 82.24582171440125, 83.35661053657532, 84.44898414611816, 85.54834842681885, 86.65453028678894, 87.75567293167114, 88.8550500869751, 89.95266318321228, 91.05716514587402, 92.15459513664246, 93.25385689735413, 94.34764695167542, 95.44472408294678, 96.545969247818, 97.65413522720337, 98.7597017288208, 99.86575436592102, 100.9658534526825, 102.0640172958374, 103.1583878993988, 104.25968050956726, 105.3667299747467, 106.46852087974548, 107.5750503540039, 108.68102931976318, 109.78600287437439, 110.88852977752686, 111.99578261375427, 113.10108399391174, 114.20909690856934, 115.30784916877747, 116.40840530395508, 117.51523041725159, 118.62060499191284, 119.72163319587708, 120.8242998123169, 121.91952872276306, 123.01582098007202, 124.11701393127441, 125.216383934021, 126.32015013694763, 127.41848015785217, 128.5203719139099, 129.61732292175293, 130.72307133674622, 131.8229751586914, 132.92093324661255, 134.0169961452484, 135.11517000198364, 136.24132323265076, 137.33713579177856, 138.44478726387024, 139.5533480644226, 140.66080617904663, 141.77067589759827, 142.88631653785706, 143.99484539031982, 145.10167026519775, 146.20107626914978, 147.29903960227966, 148.40663862228394, 149.5107078552246, 150.60783004760742, 151.7087390422821, 152.80822348594666, 153.9012758731842, 155.0012457370758, 156.10368180274963, 157.21880269050598, 158.33638954162598, 159.44482564926147, 160.55748915672302, 161.67427730560303, 162.7921302318573, 163.8993866443634, 165.0017580986023, 166.11224484443665, 167.2152214050293, 168.31671357154846, 169.55324459075928, 170.92777752876282, 172.28809571266174, 173.65371870994568, 175.00896859169006, 176.35584950447083, 177.71493768692017, 179.07546830177307, 180.43173456192017, 181.7876901626587, 183.14601850509644, 184.51044130325317, 185.87282586097717, 187.23263120651245, 188.59188842773438, 189.95512652397156, 191.31126356124878, 192.67715191841125, 194.03408908843994, 195.39500403404236, 196.75566983222961, 198.10827445983887, 199.4711310863495, 200.82978463172913, 202.19077277183533, 203.55253744125366, 204.90779447555542, 206.2685182094574, 207.6245174407959, 208.97970414161682, 210.3248429298401, 211.68814396858215, 213.0438196659088, 214.3910801410675, 215.75206446647644, 217.11308479309082, 218.46745252609253, 219.82564449310303, 221.17621779441833, 222.54371690750122, 223.90485000610352, 225.26731657981873, 226.63117337226868, 227.99266386032104, 229.34710597991943, 230.70709490776062, 232.06855487823486, 233.4226405620575, 234.78161144256592, 236.12458968162537, 237.38366389274597, 238.63867664337158, 239.9054651260376, 241.18803930282593, 242.4697880744934, 243.8305332660675, 245.1952874660492, 246.4586272239685, 247.73015522956848, 248.99765348434448, 250.26111841201782, 251.5211534500122, 252.7890510559082, 254.04954624176025, 255.31175541877747, 256.5707232952118, 257.8326871395111, 259.089834690094, 260.3550217151642, 261.6166470050812, 262.8765435218811, 264.1341586112976, 265.394583940506, 266.65870118141174, 267.92575573921204, 269.1906313896179, 270.45938324928284, 271.7287929058075, 272.98403334617615, 274.23850774765015, 275.4902939796448, 276.760249376297, 278.0406126976013, 279.3129687309265, 280.58914947509766, 281.8621642589569, 283.14272713661194, 284.41512537002563, 285.6901216506958, 286.95071840286255, 288.21016240119934, 289.4795491695404, 290.74374198913574, 292.0131359100342, 293.27331161499023, 294.53316259384155, 295.80565547943115, 297.07502245903015, 298.3415365219116, 299.61182618141174, 300.722692489624, 301.83311557769775, 302.93895387649536, 304.0447859764099, 305.1468188762665, 306.25053811073303, 307.35419487953186, 308.46019196510315, 309.5674967765808, 310.67732644081116, 311.78407168388367, 312.88816237449646, 313.9927144050598, 315.09481048583984, 316.19349789619446, 317.2968919277191, 318.3995535373688, 319.50390005111694, 320.6152048110962, 321.7192232608795, 322.82248306274414, 323.926043510437, 325.0321681499481, 326.1411190032959, 327.2515254020691, 328.3583333492279, 329.4651629924774, 330.57759070396423, 331.68201184272766, 332.7849304676056, 333.8879072666168, 334.9877395629883, 336.09122133255005, 337.19661498069763, 338.30772972106934, 339.4122290611267, 340.5177254676819, 341.6318006515503, 342.7391424179077, 343.84677600860596, 344.95098423957825, 346.05493235588074, 347.1545238494873, 348.2650377750397, 349.37020993232727, 350.4766082763672, 351.5841200351715, 352.6927373409271, 353.79998254776, 354.90454745292664, 356.0145435333252, 357.1236777305603, 358.2332983016968, 359.34264516830444, 361.55819487571716]
[14.858333333333333, 16.625, 18.075, 18.675, 18.391666666666666, 17.783333333333335, 16.708333333333332, 15.266666666666667, 14.475, 13.575, 13.575, 15.066666666666666, 15.85, 14.875, 13.758333333333333, 14.966666666666667, 14.408333333333333, 14.408333333333333, 14.408333333333333, 14.408333333333333, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334, 13.333333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.224, Test loss: 2.206, Test accuracy: 17.78 

Round   0, Global train loss: 2.224, Global test loss: 2.242, Global test accuracy: 16.64 

Round   1, Train loss: 2.049, Test loss: 2.119, Test accuracy: 21.97 

Round   1, Global train loss: 2.049, Global test loss: 2.195, Global test accuracy: 19.12 

Round   2, Train loss: 1.948, Test loss: 2.045, Test accuracy: 25.10 

Round   2, Global train loss: 1.948, Global test loss: 2.195, Global test accuracy: 21.15 

Round   3, Train loss: 1.882, Test loss: 1.978, Test accuracy: 27.75 

Round   3, Global train loss: 1.882, Global test loss: 2.175, Global test accuracy: 21.63 

Round   4, Train loss: 1.844, Test loss: 1.926, Test accuracy: 29.33 

Round   4, Global train loss: 1.844, Global test loss: 2.202, Global test accuracy: 22.41 

Round   5, Train loss: 1.791, Test loss: 1.841, Test accuracy: 32.10 

Round   5, Global train loss: 1.791, Global test loss: 2.165, Global test accuracy: 24.03 

Round   6, Train loss: 1.751, Test loss: 1.829, Test accuracy: 33.06 

Round   6, Global train loss: 1.751, Global test loss: 2.207, Global test accuracy: 24.00 

Round   7, Train loss: 1.727, Test loss: 1.770, Test accuracy: 34.97 

Round   7, Global train loss: 1.727, Global test loss: 2.165, Global test accuracy: 23.79 

Round   8, Train loss: 1.684, Test loss: 1.752, Test accuracy: 35.47 

Round   8, Global train loss: 1.684, Global test loss: 2.209, Global test accuracy: 23.24 

Round   9, Train loss: 1.635, Test loss: 1.730, Test accuracy: 36.88 

Round   9, Global train loss: 1.635, Global test loss: 2.199, Global test accuracy: 24.51 

Round  10, Train loss: 1.621, Test loss: 1.676, Test accuracy: 38.57 

Round  10, Global train loss: 1.621, Global test loss: 2.152, Global test accuracy: 23.31 

Round  11, Train loss: 1.564, Test loss: 1.666, Test accuracy: 39.11 

Round  11, Global train loss: 1.564, Global test loss: 2.211, Global test accuracy: 25.05 

Round  12, Train loss: 1.539, Test loss: 1.672, Test accuracy: 39.30 

Round  12, Global train loss: 1.539, Global test loss: 2.194, Global test accuracy: 24.85 

Round  13, Train loss: 1.515, Test loss: 1.672, Test accuracy: 39.48 

Round  13, Global train loss: 1.515, Global test loss: 2.218, Global test accuracy: 24.27 

Round  14, Train loss: 1.473, Test loss: 1.660, Test accuracy: 40.30 

Round  14, Global train loss: 1.473, Global test loss: 2.166, Global test accuracy: 26.21 

Round  15, Train loss: 1.471, Test loss: 1.642, Test accuracy: 41.03 

Round  15, Global train loss: 1.471, Global test loss: 2.198, Global test accuracy: 24.98 

Round  16, Train loss: 1.444, Test loss: 1.643, Test accuracy: 41.55 

Round  16, Global train loss: 1.444, Global test loss: 2.143, Global test accuracy: 25.66 

Round  17, Train loss: 1.456, Test loss: 1.620, Test accuracy: 42.44 

Round  17, Global train loss: 1.456, Global test loss: 2.120, Global test accuracy: 25.35 

Round  18, Train loss: 1.410, Test loss: 1.592, Test accuracy: 43.99 

Round  18, Global train loss: 1.410, Global test loss: 2.203, Global test accuracy: 27.70 

Round  19, Train loss: 1.411, Test loss: 1.567, Test accuracy: 44.97 

Round  19, Global train loss: 1.411, Global test loss: 2.203, Global test accuracy: 27.14 

Round  20, Train loss: 1.375, Test loss: 1.560, Test accuracy: 45.11 

Round  20, Global train loss: 1.375, Global test loss: 2.146, Global test accuracy: 27.25 

Round  21, Train loss: 1.322, Test loss: 1.555, Test accuracy: 45.30 

Round  21, Global train loss: 1.322, Global test loss: 2.247, Global test accuracy: 27.55 

Round  22, Train loss: 1.271, Test loss: 1.548, Test accuracy: 45.97 

Round  22, Global train loss: 1.271, Global test loss: 2.385, Global test accuracy: 27.16 

Round  23, Train loss: 1.273, Test loss: 1.546, Test accuracy: 46.32 

Round  23, Global train loss: 1.273, Global test loss: 2.253, Global test accuracy: 27.06 

Round  24, Train loss: 1.261, Test loss: 1.535, Test accuracy: 46.87 

Round  24, Global train loss: 1.261, Global test loss: 2.176, Global test accuracy: 27.39 

Round  25, Train loss: 1.317, Test loss: 1.527, Test accuracy: 47.37 

Round  25, Global train loss: 1.317, Global test loss: 2.184, Global test accuracy: 29.13 

Round  26, Train loss: 1.200, Test loss: 1.523, Test accuracy: 47.64 

Round  26, Global train loss: 1.200, Global test loss: 2.347, Global test accuracy: 28.62 

Round  27, Train loss: 1.248, Test loss: 1.522, Test accuracy: 48.05 

Round  27, Global train loss: 1.248, Global test loss: 2.218, Global test accuracy: 28.46 

Round  28, Train loss: 1.183, Test loss: 1.514, Test accuracy: 48.32 

Round  28, Global train loss: 1.183, Global test loss: 2.219, Global test accuracy: 27.33 

Round  29, Train loss: 1.230, Test loss: 1.513, Test accuracy: 48.54 

Round  29, Global train loss: 1.230, Global test loss: 2.266, Global test accuracy: 27.00 

Round  30, Train loss: 1.179, Test loss: 1.514, Test accuracy: 49.05 

Round  30, Global train loss: 1.179, Global test loss: 2.401, Global test accuracy: 28.39 

Round  31, Train loss: 1.115, Test loss: 1.526, Test accuracy: 49.07 

Round  31, Global train loss: 1.115, Global test loss: 2.260, Global test accuracy: 28.32 

Round  32, Train loss: 1.066, Test loss: 1.530, Test accuracy: 49.19 

Round  32, Global train loss: 1.066, Global test loss: 2.244, Global test accuracy: 27.68 

Round  33, Train loss: 1.191, Test loss: 1.514, Test accuracy: 49.85 

Round  33, Global train loss: 1.191, Global test loss: 2.303, Global test accuracy: 28.07 

Round  34, Train loss: 1.140, Test loss: 1.528, Test accuracy: 49.91 

Round  34, Global train loss: 1.140, Global test loss: 2.255, Global test accuracy: 28.34 

Round  35, Train loss: 1.127, Test loss: 1.516, Test accuracy: 50.56 

Round  35, Global train loss: 1.127, Global test loss: 2.192, Global test accuracy: 27.92 

Round  36, Train loss: 1.068, Test loss: 1.513, Test accuracy: 50.90 

Round  36, Global train loss: 1.068, Global test loss: 2.311, Global test accuracy: 28.39 

Round  37, Train loss: 1.084, Test loss: 1.503, Test accuracy: 51.55 

Round  37, Global train loss: 1.084, Global test loss: 2.213, Global test accuracy: 28.73 

Round  38, Train loss: 1.046, Test loss: 1.518, Test accuracy: 51.70 

Round  38, Global train loss: 1.046, Global test loss: 2.398, Global test accuracy: 28.00 

Round  39, Train loss: 1.021, Test loss: 1.511, Test accuracy: 52.05 

Round  39, Global train loss: 1.021, Global test loss: 2.321, Global test accuracy: 28.71 

Round  40, Train loss: 1.013, Test loss: 1.516, Test accuracy: 52.37 

Round  40, Global train loss: 1.013, Global test loss: 2.309, Global test accuracy: 28.84 

Round  41, Train loss: 0.976, Test loss: 1.514, Test accuracy: 52.62 

Round  41, Global train loss: 0.976, Global test loss: 2.478, Global test accuracy: 29.40 

Round  42, Train loss: 1.006, Test loss: 1.527, Test accuracy: 52.49 

Round  42, Global train loss: 1.006, Global test loss: 2.375, Global test accuracy: 30.06 

Round  43, Train loss: 1.028, Test loss: 1.519, Test accuracy: 52.93 

Round  43, Global train loss: 1.028, Global test loss: 2.349, Global test accuracy: 29.25 

Round  44, Train loss: 0.972, Test loss: 1.529, Test accuracy: 52.84 

Round  44, Global train loss: 0.972, Global test loss: 2.337, Global test accuracy: 27.81 

Round  45, Train loss: 0.947, Test loss: 1.551, Test accuracy: 52.80 

Round  45, Global train loss: 0.947, Global test loss: 2.460, Global test accuracy: 28.26 

Round  46, Train loss: 0.998, Test loss: 1.545, Test accuracy: 53.09 

Round  46, Global train loss: 0.998, Global test loss: 2.326, Global test accuracy: 28.76 

Round  47, Train loss: 0.940, Test loss: 1.534, Test accuracy: 53.19 

Round  47, Global train loss: 0.940, Global test loss: 2.309, Global test accuracy: 28.95 

Round  48, Train loss: 0.882, Test loss: 1.531, Test accuracy: 53.29 

Round  48, Global train loss: 0.882, Global test loss: 2.448, Global test accuracy: 28.03 

Round  49, Train loss: 0.941, Test loss: 1.546, Test accuracy: 53.52 

Round  49, Global train loss: 0.941, Global test loss: 2.430, Global test accuracy: 29.93 

Round  50, Train loss: 0.909, Test loss: 1.535, Test accuracy: 53.86 

Round  50, Global train loss: 0.909, Global test loss: 2.433, Global test accuracy: 28.99 

Round  51, Train loss: 0.914, Test loss: 1.553, Test accuracy: 53.62 

Round  51, Global train loss: 0.914, Global test loss: 2.383, Global test accuracy: 29.36 

Round  52, Train loss: 0.872, Test loss: 1.578, Test accuracy: 53.25 

Round  52, Global train loss: 0.872, Global test loss: 2.448, Global test accuracy: 28.06 

Round  53, Train loss: 0.837, Test loss: 1.595, Test accuracy: 53.15 

Round  53, Global train loss: 0.837, Global test loss: 2.462, Global test accuracy: 29.18 

Round  54, Train loss: 0.853, Test loss: 1.597, Test accuracy: 53.19 

Round  54, Global train loss: 0.853, Global test loss: 2.398, Global test accuracy: 28.55 

Round  55, Train loss: 0.889, Test loss: 1.591, Test accuracy: 53.14 

Round  55, Global train loss: 0.889, Global test loss: 2.412, Global test accuracy: 29.39 

Round  56, Train loss: 0.829, Test loss: 1.586, Test accuracy: 53.37 

Round  56, Global train loss: 0.829, Global test loss: 2.492, Global test accuracy: 28.59 

Round  57, Train loss: 0.886, Test loss: 1.585, Test accuracy: 53.59 

Round  57, Global train loss: 0.886, Global test loss: 2.441, Global test accuracy: 27.84 

Round  58, Train loss: 0.825, Test loss: 1.593, Test accuracy: 53.52 

Round  58, Global train loss: 0.825, Global test loss: 2.599, Global test accuracy: 28.30 

Round  59, Train loss: 0.822, Test loss: 1.626, Test accuracy: 53.27 

Round  59, Global train loss: 0.822, Global test loss: 2.536, Global test accuracy: 28.71 

Round  60, Train loss: 0.805, Test loss: 1.598, Test accuracy: 53.66 

Round  60, Global train loss: 0.805, Global test loss: 2.466, Global test accuracy: 28.30 

Round  61, Train loss: 0.846, Test loss: 1.612, Test accuracy: 53.88 

Round  61, Global train loss: 0.846, Global test loss: 2.566, Global test accuracy: 27.85 

Round  62, Train loss: 0.836, Test loss: 1.643, Test accuracy: 53.59 

Round  62, Global train loss: 0.836, Global test loss: 2.450, Global test accuracy: 28.57 

Round  63, Train loss: 0.769, Test loss: 1.661, Test accuracy: 53.40 

Round  63, Global train loss: 0.769, Global test loss: 2.473, Global test accuracy: 28.18 

Round  64, Train loss: 0.792, Test loss: 1.647, Test accuracy: 53.80 

Round  64, Global train loss: 0.792, Global test loss: 2.641, Global test accuracy: 27.34 

Round  65, Train loss: 0.784, Test loss: 1.644, Test accuracy: 54.05 

Round  65, Global train loss: 0.784, Global test loss: 2.549, Global test accuracy: 29.35 

Round  66, Train loss: 0.785, Test loss: 1.646, Test accuracy: 54.16 

Round  66, Global train loss: 0.785, Global test loss: 2.517, Global test accuracy: 27.71 

Round  67, Train loss: 0.775, Test loss: 1.658, Test accuracy: 54.11 

Round  67, Global train loss: 0.775, Global test loss: 2.684, Global test accuracy: 30.25 

Round  68, Train loss: 0.714, Test loss: 1.674, Test accuracy: 54.07 

Round  68, Global train loss: 0.714, Global test loss: 2.611, Global test accuracy: 28.38 

Round  69, Train loss: 0.787, Test loss: 1.691, Test accuracy: 54.21 

Round  69, Global train loss: 0.787, Global test loss: 2.767, Global test accuracy: 28.73 

Round  70, Train loss: 0.789, Test loss: 1.680, Test accuracy: 54.34 

Round  70, Global train loss: 0.789, Global test loss: 2.510, Global test accuracy: 28.68 

Round  71, Train loss: 0.773, Test loss: 1.660, Test accuracy: 54.47 

Round  71, Global train loss: 0.773, Global test loss: 2.484, Global test accuracy: 28.59 

Round  72, Train loss: 0.738, Test loss: 1.661, Test accuracy: 54.34 

Round  72, Global train loss: 0.738, Global test loss: 2.556, Global test accuracy: 29.28 

Round  73, Train loss: 0.737, Test loss: 1.657, Test accuracy: 54.73 

Round  73, Global train loss: 0.737, Global test loss: 2.637, Global test accuracy: 28.92 

Round  74, Train loss: 0.749, Test loss: 1.668, Test accuracy: 54.80 

Round  74, Global train loss: 0.749, Global test loss: 2.748, Global test accuracy: 28.92 

Round  75, Train loss: 0.703, Test loss: 1.679, Test accuracy: 54.88 

Round  75, Global train loss: 0.703, Global test loss: 2.660, Global test accuracy: 29.64 

Round  76, Train loss: 0.677, Test loss: 1.673, Test accuracy: 55.05 

Round  76, Global train loss: 0.677, Global test loss: 2.736, Global test accuracy: 28.43 

Round  77, Train loss: 0.681, Test loss: 1.696, Test accuracy: 54.83 

Round  77, Global train loss: 0.681, Global test loss: 2.768, Global test accuracy: 27.98 

Round  78, Train loss: 0.708, Test loss: 1.689, Test accuracy: 55.11 

Round  78, Global train loss: 0.708, Global test loss: 2.681, Global test accuracy: 28.50 

Round  79, Train loss: 0.627, Test loss: 1.695, Test accuracy: 55.11 

Round  79, Global train loss: 0.627, Global test loss: 2.807, Global test accuracy: 28.34 

Round  80, Train loss: 0.672, Test loss: 1.686, Test accuracy: 55.41 

Round  80, Global train loss: 0.672, Global test loss: 2.604, Global test accuracy: 28.07 

Round  81, Train loss: 0.693, Test loss: 1.688, Test accuracy: 55.33 

Round  81, Global train loss: 0.693, Global test loss: 2.837, Global test accuracy: 28.38 

Round  82, Train loss: 0.659, Test loss: 1.724, Test accuracy: 55.08 

Round  82, Global train loss: 0.659, Global test loss: 2.928, Global test accuracy: 29.04 

Round  83, Train loss: 0.642, Test loss: 1.732, Test accuracy: 55.02 

Round  83, Global train loss: 0.642, Global test loss: 2.673, Global test accuracy: 28.17 

Round  84, Train loss: 0.618, Test loss: 1.741, Test accuracy: 55.26 

Round  84, Global train loss: 0.618, Global test loss: 2.891, Global test accuracy: 29.00 

Round  85, Train loss: 0.626, Test loss: 1.748, Test accuracy: 55.17 

Round  85, Global train loss: 0.626, Global test loss: 2.987, Global test accuracy: 29.43 

Round  86, Train loss: 0.680, Test loss: 1.745, Test accuracy: 55.14 

Round  86, Global train loss: 0.680, Global test loss: 3.063, Global test accuracy: 30.29 

Round  87, Train loss: 0.645, Test loss: 1.747, Test accuracy: 55.06 

Round  87, Global train loss: 0.645, Global test loss: 2.906, Global test accuracy: 29.57 

Round  88, Train loss: 0.671, Test loss: 1.747, Test accuracy: 55.28 

Round  88, Global train loss: 0.671, Global test loss: 2.690, Global test accuracy: 28.91 

Round  89, Train loss: 0.644, Test loss: 1.764, Test accuracy: 55.39 

Round  89, Global train loss: 0.644, Global test loss: 2.821, Global test accuracy: 28.45 

Round  90, Train loss: 0.654, Test loss: 1.772, Test accuracy: 55.50 

Round  90, Global train loss: 0.654, Global test loss: 2.902, Global test accuracy: 28.39 

Round  91, Train loss: 0.612, Test loss: 1.760, Test accuracy: 55.69 

Round  91, Global train loss: 0.612, Global test loss: 2.792, Global test accuracy: 28.75 

Round  92, Train loss: 0.606, Test loss: 1.752, Test accuracy: 55.78 

Round  92, Global train loss: 0.606, Global test loss: 3.101, Global test accuracy: 29.53 

Round  93, Train loss: 0.667, Test loss: 1.752, Test accuracy: 55.79 

Round  93, Global train loss: 0.667, Global test loss: 3.051, Global test accuracy: 29.37 

Round  94, Train loss: 0.624, Test loss: 1.762, Test accuracy: 55.59 

Round  94, Global train loss: 0.624, Global test loss: 2.700, Global test accuracy: 28.59 

Round  95, Train loss: 0.575, Test loss: 1.793, Test accuracy: 55.31 

Round  95, Global train loss: 0.575, Global test loss: 2.952, Global test accuracy: 28.87 

Round  96, Train loss: 0.712, Test loss: 1.789, Test accuracy: 55.35 

Round  96, Global train loss: 0.712, Global test loss: 2.671, Global test accuracy: 28.45 

Round  97, Train loss: 0.563, Test loss: 1.807, Test accuracy: 55.50 

Round  97, Global train loss: 0.563, Global test loss: 2.925, Global test accuracy: 28.70 

Round  98, Train loss: 0.642, Test loss: 1.834, Test accuracy: 55.24 

Round  98, Global train loss: 0.642, Global test loss: 2.932, Global test accuracy: 29.29 

Round  99, Train loss: 0.577, Test loss: 1.824, Test accuracy: 55.66 

Round  99, Global train loss: 0.577, Global test loss: 2.842, Global test accuracy: 28.62 

Final Round, Train loss: 0.466, Test loss: 2.097, Test accuracy: 54.64 

Final Round, Global train loss: 0.466, Global test loss: 2.842, Global test accuracy: 28.62 

Average accuracy final 10 rounds: 55.5405 

Average global accuracy final 10 rounds: 28.85575 

2715.63400888443
[1.5595569610595703, 2.8078737258911133, 4.068435192108154, 5.324036359786987, 6.583525896072388, 7.8337249755859375, 9.096094369888306, 10.357502698898315, 11.604941606521606, 12.859201908111572, 14.110885858535767, 15.364105224609375, 16.617727994918823, 17.8631808757782, 19.090506553649902, 20.328678607940674, 21.56491208076477, 22.806901216506958, 24.057286024093628, 25.307344436645508, 26.559354305267334, 27.805413722991943, 29.055197715759277, 30.30429720878601, 31.55631732940674, 32.80824136734009, 34.06678247451782, 35.317256927490234, 36.565911054611206, 37.82145380973816, 39.075467586517334, 40.33384871482849, 41.58025908470154, 42.82436394691467, 44.06708741188049, 45.32037043571472, 46.57271695137024, 47.82157874107361, 49.06726336479187, 50.31858205795288, 51.57303190231323, 52.82251691818237, 54.07484531402588, 55.32958436012268, 56.581846475601196, 57.83788061141968, 59.088645696640015, 60.339327335357666, 61.59298348426819, 62.841137647628784, 64.08999156951904, 65.33867835998535, 66.58671379089355, 67.83697319030762, 69.08794641494751, 70.34217715263367, 71.59835600852966, 72.84467911720276, 74.08945775032043, 75.34498715400696, 76.60204005241394, 77.85582947731018, 79.10883522033691, 80.35508489608765, 81.60731816291809, 82.70594000816345, 83.9153790473938, 85.15031385421753, 86.38923597335815, 87.64149212837219, 88.88540768623352, 90.1326789855957, 91.38271975517273, 92.64292311668396, 93.89556789398193, 95.14715909957886, 96.4031867980957, 97.65335869789124, 98.90112400054932, 100.15356278419495, 101.39679193496704, 102.63751888275146, 103.88776159286499, 105.14503598213196, 106.39953541755676, 107.49243593215942, 108.58115339279175, 109.6746392250061, 110.94074535369873, 112.18595814704895, 113.43492603302002, 114.67739605903625, 115.91960597038269, 117.166344165802, 118.41155123710632, 119.6556351184845, 120.9029152393341, 122.14842700958252, 123.38463568687439, 124.62858510017395, 127.11939001083374]
[17.7825, 21.9725, 25.1025, 27.75, 29.3325, 32.1, 33.0625, 34.97, 35.4725, 36.88, 38.5725, 39.1125, 39.3025, 39.485, 40.2975, 41.035, 41.555, 42.4375, 43.9875, 44.9725, 45.11, 45.2975, 45.9725, 46.3225, 46.865, 47.37, 47.6425, 48.0525, 48.3225, 48.54, 49.0475, 49.0725, 49.185, 49.855, 49.91, 50.5575, 50.9025, 51.545, 51.705, 52.055, 52.3725, 52.6225, 52.4925, 52.9275, 52.835, 52.8, 53.0925, 53.185, 53.2925, 53.5225, 53.8625, 53.6225, 53.2475, 53.15, 53.185, 53.14, 53.3675, 53.59, 53.5225, 53.2675, 53.6625, 53.88, 53.585, 53.395, 53.8025, 54.0475, 54.155, 54.11, 54.07, 54.21, 54.345, 54.4725, 54.3425, 54.7325, 54.7975, 54.8825, 55.05, 54.825, 55.1075, 55.1125, 55.415, 55.33, 55.0825, 55.025, 55.2575, 55.1675, 55.1425, 55.06, 55.2775, 55.39, 55.5, 55.69, 55.7825, 55.7875, 55.585, 55.3125, 55.35, 55.5025, 55.24, 55.655, 54.6425]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.279, Test loss: 2.266, Test accuracy: 13.91 

Round   1, Train loss: 2.183, Test loss: 2.198, Test accuracy: 18.40 

Round   2, Train loss: 2.059, Test loss: 2.160, Test accuracy: 19.82 

Round   3, Train loss: 1.997, Test loss: 2.113, Test accuracy: 20.73 

Round   4, Train loss: 1.926, Test loss: 2.031, Test accuracy: 23.51 

Round   5, Train loss: 1.860, Test loss: 1.971, Test accuracy: 26.12 

Round   6, Train loss: 1.831, Test loss: 1.875, Test accuracy: 28.64 

Round   7, Train loss: 1.778, Test loss: 1.856, Test accuracy: 29.84 

Round   8, Train loss: 1.758, Test loss: 1.813, Test accuracy: 31.56 

Round   9, Train loss: 1.724, Test loss: 1.768, Test accuracy: 33.20 

Round  10, Train loss: 1.699, Test loss: 1.722, Test accuracy: 35.09 

Round  11, Train loss: 1.641, Test loss: 1.688, Test accuracy: 36.86 

Round  12, Train loss: 1.644, Test loss: 1.643, Test accuracy: 38.59 

Round  13, Train loss: 1.622, Test loss: 1.618, Test accuracy: 40.02 

Round  14, Train loss: 1.585, Test loss: 1.593, Test accuracy: 41.04 

Round  15, Train loss: 1.541, Test loss: 1.577, Test accuracy: 41.34 

Round  16, Train loss: 1.556, Test loss: 1.533, Test accuracy: 43.02 

Round  17, Train loss: 1.519, Test loss: 1.516, Test accuracy: 43.91 

Round  18, Train loss: 1.477, Test loss: 1.508, Test accuracy: 44.21 

Round  19, Train loss: 1.430, Test loss: 1.490, Test accuracy: 45.32 

Round  20, Train loss: 1.458, Test loss: 1.466, Test accuracy: 46.09 

Round  21, Train loss: 1.412, Test loss: 1.459, Test accuracy: 46.95 

Round  22, Train loss: 1.398, Test loss: 1.442, Test accuracy: 47.47 

Round  23, Train loss: 1.392, Test loss: 1.421, Test accuracy: 48.21 

Round  24, Train loss: 1.366, Test loss: 1.427, Test accuracy: 48.02 

Round  25, Train loss: 1.345, Test loss: 1.423, Test accuracy: 48.37 

Round  26, Train loss: 1.359, Test loss: 1.390, Test accuracy: 49.31 

Round  27, Train loss: 1.330, Test loss: 1.387, Test accuracy: 49.72 

Round  28, Train loss: 1.285, Test loss: 1.383, Test accuracy: 49.68 

Round  29, Train loss: 1.289, Test loss: 1.378, Test accuracy: 50.15 

Round  30, Train loss: 1.258, Test loss: 1.367, Test accuracy: 50.71 

Round  31, Train loss: 1.267, Test loss: 1.337, Test accuracy: 51.69 

Round  32, Train loss: 1.291, Test loss: 1.331, Test accuracy: 52.22 

Round  33, Train loss: 1.245, Test loss: 1.317, Test accuracy: 52.56 

Round  34, Train loss: 1.219, Test loss: 1.297, Test accuracy: 53.55 

Round  35, Train loss: 1.201, Test loss: 1.288, Test accuracy: 53.74 

Round  36, Train loss: 1.183, Test loss: 1.270, Test accuracy: 54.34 

Round  37, Train loss: 1.145, Test loss: 1.287, Test accuracy: 53.55 

Round  38, Train loss: 1.168, Test loss: 1.257, Test accuracy: 54.94 

Round  39, Train loss: 1.148, Test loss: 1.259, Test accuracy: 54.88 

Round  40, Train loss: 1.132, Test loss: 1.258, Test accuracy: 55.23 

Round  41, Train loss: 1.104, Test loss: 1.239, Test accuracy: 55.98 

Round  42, Train loss: 1.117, Test loss: 1.230, Test accuracy: 56.22 

Round  43, Train loss: 1.083, Test loss: 1.231, Test accuracy: 56.40 

Round  44, Train loss: 1.093, Test loss: 1.240, Test accuracy: 56.02 

Round  45, Train loss: 1.098, Test loss: 1.223, Test accuracy: 56.73 

Round  46, Train loss: 1.065, Test loss: 1.224, Test accuracy: 56.65 

Round  47, Train loss: 1.039, Test loss: 1.219, Test accuracy: 57.04 

Round  48, Train loss: 1.023, Test loss: 1.216, Test accuracy: 57.26 

Round  49, Train loss: 1.003, Test loss: 1.216, Test accuracy: 57.28 

Round  50, Train loss: 1.055, Test loss: 1.210, Test accuracy: 57.56 

Round  51, Train loss: 0.997, Test loss: 1.205, Test accuracy: 57.57 

Round  52, Train loss: 1.032, Test loss: 1.216, Test accuracy: 57.80 

Round  53, Train loss: 1.021, Test loss: 1.184, Test accuracy: 58.48 

Round  54, Train loss: 0.967, Test loss: 1.192, Test accuracy: 58.37 

Round  55, Train loss: 0.986, Test loss: 1.179, Test accuracy: 59.40 

Round  56, Train loss: 0.931, Test loss: 1.200, Test accuracy: 58.67 

Round  57, Train loss: 0.969, Test loss: 1.191, Test accuracy: 58.72 

Round  58, Train loss: 0.932, Test loss: 1.190, Test accuracy: 58.72 

Round  59, Train loss: 0.906, Test loss: 1.189, Test accuracy: 59.36 

Round  60, Train loss: 0.919, Test loss: 1.183, Test accuracy: 59.34 

Round  61, Train loss: 0.927, Test loss: 1.193, Test accuracy: 59.61 

Round  62, Train loss: 0.889, Test loss: 1.192, Test accuracy: 59.49 

Round  63, Train loss: 0.858, Test loss: 1.208, Test accuracy: 59.52 

Round  64, Train loss: 0.900, Test loss: 1.196, Test accuracy: 59.63 

Round  65, Train loss: 0.847, Test loss: 1.213, Test accuracy: 59.01 

Round  66, Train loss: 0.846, Test loss: 1.188, Test accuracy: 59.23 

Round  67, Train loss: 0.875, Test loss: 1.177, Test accuracy: 59.86 

Round  68, Train loss: 0.838, Test loss: 1.163, Test accuracy: 60.43 

Round  69, Train loss: 0.811, Test loss: 1.173, Test accuracy: 60.44 

Round  70, Train loss: 0.845, Test loss: 1.213, Test accuracy: 59.90 

Round  71, Train loss: 0.847, Test loss: 1.184, Test accuracy: 60.23 

Round  72, Train loss: 0.807, Test loss: 1.181, Test accuracy: 60.55 

Round  73, Train loss: 0.791, Test loss: 1.181, Test accuracy: 60.69 

Round  74, Train loss: 0.786, Test loss: 1.178, Test accuracy: 60.65 

Round  75, Train loss: 0.795, Test loss: 1.195, Test accuracy: 60.95 

Round  76, Train loss: 0.803, Test loss: 1.202, Test accuracy: 60.40 

Round  77, Train loss: 0.793, Test loss: 1.189, Test accuracy: 61.03 

Round  78, Train loss: 0.757, Test loss: 1.176, Test accuracy: 61.35 

Round  79, Train loss: 0.758, Test loss: 1.175, Test accuracy: 61.56 

Round  80, Train loss: 0.750, Test loss: 1.204, Test accuracy: 61.25 

Round  81, Train loss: 0.715, Test loss: 1.241, Test accuracy: 60.47 

Round  82, Train loss: 0.742, Test loss: 1.196, Test accuracy: 61.27 

Round  83, Train loss: 0.751, Test loss: 1.189, Test accuracy: 61.51 

Round  84, Train loss: 0.751, Test loss: 1.203, Test accuracy: 60.94 

Round  85, Train loss: 0.726, Test loss: 1.207, Test accuracy: 61.02 

Round  86, Train loss: 0.710, Test loss: 1.195, Test accuracy: 61.30 

Round  87, Train loss: 0.658, Test loss: 1.213, Test accuracy: 60.83 

Round  88, Train loss: 0.673, Test loss: 1.221, Test accuracy: 60.69 

Round  89, Train loss: 0.684, Test loss: 1.229, Test accuracy: 61.23 

Round  90, Train loss: 0.701, Test loss: 1.232, Test accuracy: 61.48 

Round  91, Train loss: 0.666, Test loss: 1.211, Test accuracy: 61.74 

Round  92, Train loss: 0.676, Test loss: 1.223, Test accuracy: 61.82 

Round  93, Train loss: 0.651, Test loss: 1.200, Test accuracy: 62.50 

Round  94, Train loss: 0.690, Test loss: 1.208, Test accuracy: 62.27 

Round  95, Train loss: 0.670, Test loss: 1.197, Test accuracy: 62.13 

Round  96, Train loss: 0.619, Test loss: 1.244, Test accuracy: 61.72 

Round  97, Train loss: 0.649, Test loss: 1.217, Test accuracy: 62.40 

Round  98, Train loss: 0.667, Test loss: 1.228, Test accuracy: 62.38 

Round  99, Train loss: 0.649, Test loss: 1.243, Test accuracy: 62.19 

Final Round, Train loss: 0.558, Test loss: 1.241, Test accuracy: 62.40 

Average accuracy final 10 rounds: 62.063250000000004 

1644.11439037323
[1.317284107208252, 2.376323699951172, 3.4357969760894775, 4.498664855957031, 5.56494402885437, 6.623887300491333, 7.6859800815582275, 8.751787185668945, 9.813556671142578, 10.875673770904541, 11.938774824142456, 13.004832029342651, 14.077484369277954, 15.134800434112549, 16.197017431259155, 17.261810779571533, 18.316860914230347, 19.37471890449524, 20.441046953201294, 21.49484920501709, 22.546066522598267, 23.600508451461792, 24.659690856933594, 25.716139316558838, 26.771016597747803, 27.824519634246826, 28.88525629043579, 29.944576263427734, 30.997756719589233, 32.05257034301758, 33.11440658569336, 34.17473316192627, 35.229408502578735, 36.283729791641235, 37.343505859375, 38.414599657058716, 39.47506904602051, 40.52742409706116, 41.589709758758545, 42.65137076377869, 43.70702838897705, 44.76283574104309, 45.829899311065674, 46.896636962890625, 47.94840741157532, 49.0061411857605, 50.06410884857178, 51.11932420730591, 52.17232656478882, 53.231510162353516, 54.28829383850098, 55.34078335762024, 56.39162588119507, 57.446386098861694, 58.50318217277527, 59.55435633659363, 60.60471272468567, 61.66168189048767, 62.71734428405762, 63.768590211868286, 64.81623935699463, 65.87114977836609, 66.92443943023682, 67.9726574420929, 69.02587699890137, 70.08210897445679, 71.1447262763977, 72.19673013687134, 73.2463231086731, 74.32218050956726, 75.37661981582642, 76.42428851127625, 77.47051095962524, 78.52600240707397, 79.5761456489563, 80.62514400482178, 81.67868161201477, 82.73342323303223, 83.78235387802124, 84.82086515426636, 85.86498880386353, 86.91515302658081, 87.96249675750732, 89.00860023498535, 90.0615713596344, 91.10435342788696, 92.14740562438965, 93.1959867477417, 94.24361205101013, 95.28763914108276, 96.33388018608093, 97.38332033157349, 98.42710280418396, 99.47031736373901, 100.52128577232361, 101.56766748428345, 102.60930633544922, 103.65734529495239, 104.7045488357544, 105.75197672843933, 107.63107514381409]
[13.9075, 18.4, 19.82, 20.7275, 23.5125, 26.1175, 28.645, 29.84, 31.5575, 33.205, 35.0925, 36.86, 38.5925, 40.025, 41.04, 41.3425, 43.015, 43.91, 44.2125, 45.3225, 46.0875, 46.95, 47.4725, 48.21, 48.02, 48.365, 49.3075, 49.72, 49.6775, 50.1475, 50.71, 51.6875, 52.2225, 52.5575, 53.555, 53.745, 54.34, 53.5525, 54.9375, 54.8775, 55.2325, 55.9775, 56.215, 56.4025, 56.0175, 56.735, 56.65, 57.04, 57.2625, 57.2775, 57.5575, 57.57, 57.795, 58.4775, 58.365, 59.4, 58.6675, 58.7175, 58.72, 59.36, 59.34, 59.6075, 59.4875, 59.52, 59.635, 59.0075, 59.235, 59.8625, 60.43, 60.4425, 59.9025, 60.2275, 60.55, 60.69, 60.645, 60.955, 60.4, 61.035, 61.3475, 61.565, 61.2525, 60.4725, 61.265, 61.5125, 60.9375, 61.0175, 61.295, 60.8275, 60.685, 61.2275, 61.48, 61.745, 61.82, 62.5, 62.275, 62.13, 61.715, 62.4, 62.375, 62.1925, 62.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307832
307842
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 293, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2181, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 50591 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 504, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 57119 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 825, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51347 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.197, Test loss: 2.021, Test accuracy: 27.10 

Round   0, Global train loss: 1.197, Global test loss: 2.336, Global test accuracy: 17.35 

Round   1, Train loss: 1.025, Test loss: 1.711, Test accuracy: 36.77 

Round   1, Global train loss: 1.025, Global test loss: 2.274, Global test accuracy: 24.57 

Round   2, Train loss: 0.972, Test loss: 1.184, Test accuracy: 54.30 

Round   2, Global train loss: 0.972, Global test loss: 2.226, Global test accuracy: 23.08 

Round   3, Train loss: 0.830, Test loss: 1.163, Test accuracy: 54.22 

Round   3, Global train loss: 0.830, Global test loss: 2.086, Global test accuracy: 30.45 

Round   4, Train loss: 0.755, Test loss: 1.083, Test accuracy: 57.33 

Round   4, Global train loss: 0.755, Global test loss: 2.127, Global test accuracy: 30.17 

Round   5, Train loss: 0.703, Test loss: 0.963, Test accuracy: 63.22 

Round   5, Global train loss: 0.703, Global test loss: 2.390, Global test accuracy: 29.78 

Round   6, Train loss: 0.761, Test loss: 0.824, Test accuracy: 66.73 

Round   6, Global train loss: 0.761, Global test loss: 1.822, Global test accuracy: 36.97 

Round   7, Train loss: 0.686, Test loss: 0.781, Test accuracy: 68.37 

Round   7, Global train loss: 0.686, Global test loss: 1.795, Global test accuracy: 36.67 

Round   8, Train loss: 0.640, Test loss: 0.776, Test accuracy: 68.80 

Round   8, Global train loss: 0.640, Global test loss: 1.926, Global test accuracy: 34.85 

Round   9, Train loss: 0.646, Test loss: 0.737, Test accuracy: 70.57 

Round   9, Global train loss: 0.646, Global test loss: 1.976, Global test accuracy: 39.48 

Round  10, Train loss: 0.661, Test loss: 0.766, Test accuracy: 69.22 

Round  10, Global train loss: 0.661, Global test loss: 2.177, Global test accuracy: 32.72 

Round  11, Train loss: 0.598, Test loss: 0.696, Test accuracy: 71.38 

Round  11, Global train loss: 0.598, Global test loss: 1.877, Global test accuracy: 36.83 

Round  12, Train loss: 0.623, Test loss: 0.640, Test accuracy: 74.03 

Round  12, Global train loss: 0.623, Global test loss: 1.626, Global test accuracy: 43.33 

Round  13, Train loss: 0.551, Test loss: 0.594, Test accuracy: 75.65 

Round  13, Global train loss: 0.551, Global test loss: 1.807, Global test accuracy: 42.68 

Round  14, Train loss: 0.606, Test loss: 0.582, Test accuracy: 76.35 

Round  14, Global train loss: 0.606, Global test loss: 1.613, Global test accuracy: 46.35 

Round  15, Train loss: 0.533, Test loss: 0.578, Test accuracy: 76.63 

Round  15, Global train loss: 0.533, Global test loss: 1.662, Global test accuracy: 44.13 

Round  16, Train loss: 0.608, Test loss: 0.570, Test accuracy: 76.72 

Round  16, Global train loss: 0.608, Global test loss: 1.909, Global test accuracy: 41.20 

Round  17, Train loss: 0.567, Test loss: 0.554, Test accuracy: 77.40 

Round  17, Global train loss: 0.567, Global test loss: 1.687, Global test accuracy: 44.40 

Round  18, Train loss: 0.540, Test loss: 0.537, Test accuracy: 78.65 

Round  18, Global train loss: 0.540, Global test loss: 1.968, Global test accuracy: 42.73 

Round  19, Train loss: 0.499, Test loss: 0.542, Test accuracy: 78.67 

Round  19, Global train loss: 0.499, Global test loss: 1.693, Global test accuracy: 43.90 

Round  20, Train loss: 0.549, Test loss: 0.549, Test accuracy: 78.35 

Round  20, Global train loss: 0.549, Global test loss: 1.811, Global test accuracy: 40.72 

Round  21, Train loss: 0.517, Test loss: 0.547, Test accuracy: 78.13 

Round  21, Global train loss: 0.517, Global test loss: 1.821, Global test accuracy: 44.70 

Round  22, Train loss: 0.515, Test loss: 0.527, Test accuracy: 79.05 

Round  22, Global train loss: 0.515, Global test loss: 1.541, Global test accuracy: 41.28 

Round  23, Train loss: 0.543, Test loss: 0.532, Test accuracy: 79.13 

Round  23, Global train loss: 0.543, Global test loss: 1.738, Global test accuracy: 43.77 

Round  24, Train loss: 0.586, Test loss: 0.530, Test accuracy: 79.40 

Round  24, Global train loss: 0.586, Global test loss: 1.654, Global test accuracy: 44.45 

Round  25, Train loss: 0.527, Test loss: 0.523, Test accuracy: 79.67 

Round  25, Global train loss: 0.527, Global test loss: 1.658, Global test accuracy: 45.33 

Round  26, Train loss: 0.534, Test loss: 0.529, Test accuracy: 79.70 

Round  26, Global train loss: 0.534, Global test loss: 1.455, Global test accuracy: 47.53 

Round  27, Train loss: 0.453, Test loss: 0.511, Test accuracy: 80.30 

Round  27, Global train loss: 0.453, Global test loss: 1.587, Global test accuracy: 48.37 

Round  28, Train loss: 0.479, Test loss: 0.506, Test accuracy: 80.37 

Round  28, Global train loss: 0.479, Global test loss: 1.657, Global test accuracy: 48.37 

Round  29, Train loss: 0.479, Test loss: 0.516, Test accuracy: 80.55 

Round  29, Global train loss: 0.479, Global test loss: 1.871, Global test accuracy: 41.38 

Round  30, Train loss: 0.532, Test loss: 0.516, Test accuracy: 80.60 

Round  30, Global train loss: 0.532, Global test loss: 1.561, Global test accuracy: 43.85 

Round  31, Train loss: 0.485, Test loss: 0.512, Test accuracy: 81.00 

Round  31, Global train loss: 0.485, Global test loss: 1.474, Global test accuracy: 48.45 

Round  32, Train loss: 0.441, Test loss: 0.501, Test accuracy: 81.03 

Round  32, Global train loss: 0.441, Global test loss: 1.558, Global test accuracy: 47.97 

Round  33, Train loss: 0.438, Test loss: 0.524, Test accuracy: 80.52 

Round  33, Global train loss: 0.438, Global test loss: 1.504, Global test accuracy: 50.95 

Round  34, Train loss: 0.472, Test loss: 0.511, Test accuracy: 80.90 

Round  34, Global train loss: 0.472, Global test loss: 1.285, Global test accuracy: 51.87 

Round  35, Train loss: 0.382, Test loss: 0.492, Test accuracy: 81.63 

Round  35, Global train loss: 0.382, Global test loss: 1.350, Global test accuracy: 51.55 

Round  36, Train loss: 0.459, Test loss: 0.514, Test accuracy: 81.22 

Round  36, Global train loss: 0.459, Global test loss: 1.876, Global test accuracy: 45.82 

Round  37, Train loss: 0.436, Test loss: 0.503, Test accuracy: 81.58 

Round  37, Global train loss: 0.436, Global test loss: 1.262, Global test accuracy: 56.20 

Round  38, Train loss: 0.357, Test loss: 0.499, Test accuracy: 81.73 

Round  38, Global train loss: 0.357, Global test loss: 1.632, Global test accuracy: 45.08 

Round  39, Train loss: 0.378, Test loss: 0.492, Test accuracy: 81.65 

Round  39, Global train loss: 0.378, Global test loss: 1.287, Global test accuracy: 55.47 

Round  40, Train loss: 0.365, Test loss: 0.505, Test accuracy: 81.60 

Round  40, Global train loss: 0.365, Global test loss: 1.277, Global test accuracy: 55.40 

Round  41, Train loss: 0.410, Test loss: 0.506, Test accuracy: 81.53 

Round  41, Global train loss: 0.410, Global test loss: 1.445, Global test accuracy: 48.25 

Round  42, Train loss: 0.352, Test loss: 0.493, Test accuracy: 82.07 

Round  42, Global train loss: 0.352, Global test loss: 1.579, Global test accuracy: 49.38 

Round  43, Train loss: 0.395, Test loss: 0.495, Test accuracy: 82.23 

Round  43, Global train loss: 0.395, Global test loss: 1.686, Global test accuracy: 49.27 

Round  44, Train loss: 0.311, Test loss: 0.491, Test accuracy: 82.50 

Round  44, Global train loss: 0.311, Global test loss: 1.469, Global test accuracy: 51.73 

Round  45, Train loss: 0.358, Test loss: 0.473, Test accuracy: 82.83 

Round  45, Global train loss: 0.358, Global test loss: 1.393, Global test accuracy: 52.55 

Round  46, Train loss: 0.403, Test loss: 0.511, Test accuracy: 81.63 

Round  46, Global train loss: 0.403, Global test loss: 1.243, Global test accuracy: 56.28 

Round  47, Train loss: 0.401, Test loss: 0.534, Test accuracy: 81.60 

Round  47, Global train loss: 0.401, Global test loss: 1.376, Global test accuracy: 53.48 

Round  48, Train loss: 0.304, Test loss: 0.528, Test accuracy: 81.70 

Round  48, Global train loss: 0.304, Global test loss: 1.849, Global test accuracy: 49.60 

Round  49, Train loss: 0.358, Test loss: 0.512, Test accuracy: 81.97 

Round  49, Global train loss: 0.358, Global test loss: 1.172, Global test accuracy: 58.40 

Round  50, Train loss: 0.327, Test loss: 0.499, Test accuracy: 82.48 

Round  50, Global train loss: 0.327, Global test loss: 1.238, Global test accuracy: 57.47 

Round  51, Train loss: 0.302, Test loss: 0.484, Test accuracy: 83.13 

Round  51, Global train loss: 0.302, Global test loss: 1.990, Global test accuracy: 44.65 

Round  52, Train loss: 0.365, Test loss: 0.519, Test accuracy: 82.55 

Round  52, Global train loss: 0.365, Global test loss: 1.912, Global test accuracy: 45.28 

Round  53, Train loss: 0.370, Test loss: 0.544, Test accuracy: 81.92 

Round  53, Global train loss: 0.370, Global test loss: 1.201, Global test accuracy: 57.20 

Round  54, Train loss: 0.287, Test loss: 0.528, Test accuracy: 82.48 

Round  54, Global train loss: 0.287, Global test loss: 1.230, Global test accuracy: 58.32 

Round  55, Train loss: 0.359, Test loss: 0.526, Test accuracy: 82.43 

Round  55, Global train loss: 0.359, Global test loss: 1.172, Global test accuracy: 60.28 

Round  56, Train loss: 0.261, Test loss: 0.511, Test accuracy: 82.52 

Round  56, Global train loss: 0.261, Global test loss: 1.483, Global test accuracy: 54.32 

Round  57, Train loss: 0.355, Test loss: 0.507, Test accuracy: 83.23 

Round  57, Global train loss: 0.355, Global test loss: 1.571, Global test accuracy: 52.52 

Round  58, Train loss: 0.285, Test loss: 0.504, Test accuracy: 83.42 

Round  58, Global train loss: 0.285, Global test loss: 1.388, Global test accuracy: 55.25 

Round  59, Train loss: 0.274, Test loss: 0.467, Test accuracy: 84.00 

Round  59, Global train loss: 0.274, Global test loss: 1.192, Global test accuracy: 59.52 

Round  60, Train loss: 0.238, Test loss: 0.461, Test accuracy: 84.07 

Round  60, Global train loss: 0.238, Global test loss: 1.894, Global test accuracy: 49.33 

Round  61, Train loss: 0.354, Test loss: 0.468, Test accuracy: 83.70 

Round  61, Global train loss: 0.354, Global test loss: 1.155, Global test accuracy: 61.55 

Round  62, Train loss: 0.287, Test loss: 0.477, Test accuracy: 83.60 

Round  62, Global train loss: 0.287, Global test loss: 1.511, Global test accuracy: 55.18 

Round  63, Train loss: 0.242, Test loss: 0.474, Test accuracy: 83.92 

Round  63, Global train loss: 0.242, Global test loss: 1.204, Global test accuracy: 60.30 

Round  64, Train loss: 0.346, Test loss: 0.476, Test accuracy: 83.58 

Round  64, Global train loss: 0.346, Global test loss: 1.330, Global test accuracy: 58.37 

Round  65, Train loss: 0.336, Test loss: 0.481, Test accuracy: 83.40 

Round  65, Global train loss: 0.336, Global test loss: 1.181, Global test accuracy: 60.20 

Round  66, Train loss: 0.249, Test loss: 0.503, Test accuracy: 82.93 

Round  66, Global train loss: 0.249, Global test loss: 1.244, Global test accuracy: 59.33 

Round  67, Train loss: 0.298, Test loss: 0.510, Test accuracy: 83.05 

Round  67, Global train loss: 0.298, Global test loss: 1.297, Global test accuracy: 56.05 

Round  68, Train loss: 0.318, Test loss: 0.488, Test accuracy: 84.00 

Round  68, Global train loss: 0.318, Global test loss: 1.596, Global test accuracy: 53.97 

Round  69, Train loss: 0.229, Test loss: 0.497, Test accuracy: 83.95 

Round  69, Global train loss: 0.229, Global test loss: 1.260, Global test accuracy: 59.55 

Round  70, Train loss: 0.233, Test loss: 0.509, Test accuracy: 83.83 

Round  70, Global train loss: 0.233, Global test loss: 1.211, Global test accuracy: 61.28 

Round  71, Train loss: 0.283, Test loss: 0.530, Test accuracy: 83.52 

Round  71, Global train loss: 0.283, Global test loss: 1.276, Global test accuracy: 60.17 

Round  72, Train loss: 0.230, Test loss: 0.523, Test accuracy: 83.75 

Round  72, Global train loss: 0.230, Global test loss: 1.236, Global test accuracy: 59.97 

Round  73, Train loss: 0.282, Test loss: 0.516, Test accuracy: 83.73 

Round  73, Global train loss: 0.282, Global test loss: 1.385, Global test accuracy: 55.47 

Round  74, Train loss: 0.253, Test loss: 0.504, Test accuracy: 83.90 

Round  74, Global train loss: 0.253, Global test loss: 1.461, Global test accuracy: 57.08 

Round  75, Train loss: 0.206, Test loss: 0.493, Test accuracy: 83.88 

Round  75, Global train loss: 0.206, Global test loss: 1.745, Global test accuracy: 51.03 

Round  76, Train loss: 0.223, Test loss: 0.482, Test accuracy: 84.33 

Round  76, Global train loss: 0.223, Global test loss: 1.194, Global test accuracy: 61.08 

Round  77, Train loss: 0.188, Test loss: 0.502, Test accuracy: 84.05 

Round  77, Global train loss: 0.188, Global test loss: 1.421, Global test accuracy: 57.92 

Round  78, Train loss: 0.273, Test loss: 0.509, Test accuracy: 83.82 

Round  78, Global train loss: 0.273, Global test loss: 1.427, Global test accuracy: 56.00 

Round  79, Train loss: 0.221, Test loss: 0.511, Test accuracy: 83.72 

Round  79, Global train loss: 0.221, Global test loss: 1.508, Global test accuracy: 55.95 

Round  80, Train loss: 0.205, Test loss: 0.519, Test accuracy: 83.82 

Round  80, Global train loss: 0.205, Global test loss: 1.301, Global test accuracy: 60.25 

Round  81, Train loss: 0.299, Test loss: 0.517, Test accuracy: 84.00 

Round  81, Global train loss: 0.299, Global test loss: 1.219, Global test accuracy: 59.70 

Round  82, Train loss: 0.231, Test loss: 0.525, Test accuracy: 83.82 

Round  82, Global train loss: 0.231, Global test loss: 1.743, Global test accuracy: 52.97 

Round  83, Train loss: 0.195, Test loss: 0.507, Test accuracy: 84.37 

Round  83, Global train loss: 0.195, Global test loss: 1.162, Global test accuracy: 62.07 

Round  84, Train loss: 0.224, Test loss: 0.516, Test accuracy: 84.28 

Round  84, Global train loss: 0.224, Global test loss: 1.249, Global test accuracy: 60.08 

Round  85, Train loss: 0.196, Test loss: 0.498, Test accuracy: 84.70 

Round  85, Global train loss: 0.196, Global test loss: 1.851, Global test accuracy: 50.98 

Round  86, Train loss: 0.227, Test loss: 0.489, Test accuracy: 84.85 

Round  86, Global train loss: 0.227, Global test loss: 1.212, Global test accuracy: 60.35 

Round  87, Train loss: 0.206, Test loss: 0.493, Test accuracy: 84.53 

Round  87, Global train loss: 0.206, Global test loss: 1.210, Global test accuracy: 62.42 

Round  88, Train loss: 0.253, Test loss: 0.482, Test accuracy: 84.92 

Round  88, Global train loss: 0.253, Global test loss: 1.156, Global test accuracy: 61.47 

Round  89, Train loss: 0.198, Test loss: 0.475, Test accuracy: 84.98 

Round  89, Global train loss: 0.198, Global test loss: 1.559, Global test accuracy: 54.43 

Round  90, Train loss: 0.161, Test loss: 0.467, Test accuracy: 84.93 

Round  90, Global train loss: 0.161, Global test loss: 1.393, Global test accuracy: 59.73 

Round  91, Train loss: 0.234, Test loss: 0.487, Test accuracy: 84.87 

Round  91, Global train loss: 0.234, Global test loss: 1.200, Global test accuracy: 61.48 

Round  92, Train loss: 0.177, Test loss: 0.500, Test accuracy: 85.03 

Round  92, Global train loss: 0.177, Global test loss: 1.312, Global test accuracy: 60.63 

Round  93, Train loss: 0.187, Test loss: 0.485, Test accuracy: 85.32 

Round  93, Global train loss: 0.187, Global test loss: 1.539, Global test accuracy: 56.25 

Round  94, Train loss: 0.272, Test loss: 0.492, Test accuracy: 84.92 

Round  94, Global train loss: 0.272, Global test loss: 1.742, Global test accuracy: 54.53 

Round  95, Train loss: 0.159, Test loss: 0.503, Test accuracy: 84.90 

Round  95, Global train loss: 0.159, Global test loss: 1.560, Global test accuracy: 59.13 

Round  96, Train loss: 0.160, Test loss: 0.509, Test accuracy: 85.17 

Round  96, Global train loss: 0.160, Global test loss: 1.315, Global test accuracy: 60.87 

Round  97, Train loss: 0.205, Test loss: 0.510, Test accuracy: 85.03 

Round  97, Global train loss: 0.205, Global test loss: 1.545, Global test accuracy: 58.25 

Round  98, Train loss: 0.192, Test loss: 0.513, Test accuracy: 84.88 

Round  98, Global train loss: 0.192, Global test loss: 1.526, Global test accuracy: 58.53 

Round  99, Train loss: 0.186, Test loss: 0.494, Test accuracy: 84.87 

Round  99, Global train loss: 0.186, Global test loss: 1.505, Global test accuracy: 58.23 

Final Round, Train loss: 0.156, Test loss: 0.545, Test accuracy: 84.93 

Final Round, Global train loss: 0.156, Global test loss: 1.505, Global test accuracy: 58.23 

Average accuracy final 10 rounds: 84.99166666666666 

Average global accuracy final 10 rounds: 58.76499999999999 

751.9518887996674
[0.9289991855621338, 1.6377723217010498, 2.348233222961426, 3.061379909515381, 3.771148204803467, 4.478842258453369, 5.207491636276245, 5.936104774475098, 6.645326852798462, 7.351801872253418, 8.063002586364746, 8.740291833877563, 9.4152991771698, 10.092270135879517, 10.807144165039062, 11.519769668579102, 12.235870838165283, 12.949498414993286, 13.663175344467163, 14.381168365478516, 15.098495721817017, 15.81433367729187, 16.527447938919067, 17.238051414489746, 17.950761318206787, 18.666626453399658, 19.38346004486084, 20.09367537498474, 20.809582710266113, 21.526298999786377, 22.239086866378784, 22.951854944229126, 23.6685152053833, 24.38445019721985, 25.100257396697998, 25.81666374206543, 26.529395580291748, 27.237117767333984, 27.951123237609863, 28.66891312599182, 29.38601016998291, 30.096701860427856, 30.80575942993164, 31.517070055007935, 32.23780632019043, 32.955371379852295, 33.67294979095459, 34.39046335220337, 35.10115885734558, 35.81742453575134, 36.53341841697693, 37.25173544883728, 37.96503829956055, 38.67853760719299, 39.38965344429016, 40.10663199424744, 40.8235445022583, 41.5423321723938, 42.25836658477783, 42.97358465194702, 43.6867561340332, 44.40460729598999, 45.12326955795288, 45.8421311378479, 46.55837297439575, 47.27329349517822, 47.98509216308594, 48.70505714416504, 49.42461919784546, 50.14147877693176, 50.860472202301025, 51.57379937171936, 52.29538941383362, 53.016345739364624, 53.73539352416992, 54.44562816619873, 55.1565957069397, 55.87074685096741, 56.58848857879639, 57.304686307907104, 58.02293539047241, 58.740561723709106, 59.45581245422363, 60.168680906295776, 60.88202381134033, 61.595301389694214, 62.30863642692566, 63.02615737915039, 63.74675798416138, 64.46611762046814, 65.18039917945862, 65.8983166217804, 66.61577486991882, 67.33316612243652, 68.0447473526001, 68.76032662391663, 69.47529935836792, 70.18958115577698, 70.90760540962219, 71.62410187721252, 73.05271029472351]
[27.1, 36.766666666666666, 54.3, 54.21666666666667, 57.333333333333336, 63.21666666666667, 66.73333333333333, 68.36666666666666, 68.8, 70.56666666666666, 69.21666666666667, 71.38333333333334, 74.03333333333333, 75.65, 76.35, 76.63333333333334, 76.71666666666667, 77.4, 78.65, 78.66666666666667, 78.35, 78.13333333333334, 79.05, 79.13333333333334, 79.4, 79.66666666666667, 79.7, 80.3, 80.36666666666666, 80.55, 80.6, 81.0, 81.03333333333333, 80.51666666666667, 80.9, 81.63333333333334, 81.21666666666667, 81.58333333333333, 81.73333333333333, 81.65, 81.6, 81.53333333333333, 82.06666666666666, 82.23333333333333, 82.5, 82.83333333333333, 81.63333333333334, 81.6, 81.7, 81.96666666666667, 82.48333333333333, 83.13333333333334, 82.55, 81.91666666666667, 82.48333333333333, 82.43333333333334, 82.51666666666667, 83.23333333333333, 83.41666666666667, 84.0, 84.06666666666666, 83.7, 83.6, 83.91666666666667, 83.58333333333333, 83.4, 82.93333333333334, 83.05, 84.0, 83.95, 83.83333333333333, 83.51666666666667, 83.75, 83.73333333333333, 83.9, 83.88333333333334, 84.33333333333333, 84.05, 83.81666666666666, 83.71666666666667, 83.81666666666666, 84.0, 83.81666666666666, 84.36666666666666, 84.28333333333333, 84.7, 84.85, 84.53333333333333, 84.91666666666667, 84.98333333333333, 84.93333333333334, 84.86666666666666, 85.03333333333333, 85.31666666666666, 84.91666666666667, 84.9, 85.16666666666667, 85.03333333333333, 84.88333333333334, 84.86666666666666, 84.93333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.633, Test loss: 2.248, Test accuracy: 14.98 

Round   1, Train loss: 1.013, Test loss: 2.197, Test accuracy: 32.18 

Round   2, Train loss: 0.897, Test loss: 1.830, Test accuracy: 40.97 

Round   3, Train loss: 0.972, Test loss: 1.263, Test accuracy: 49.92 

Round   4, Train loss: 0.856, Test loss: 1.014, Test accuracy: 54.72 

Round   5, Train loss: 0.773, Test loss: 0.948, Test accuracy: 57.52 

Round   6, Train loss: 0.722, Test loss: 0.831, Test accuracy: 64.48 

Round   7, Train loss: 0.688, Test loss: 0.834, Test accuracy: 62.93 

Round   8, Train loss: 0.736, Test loss: 0.703, Test accuracy: 68.08 

Round   9, Train loss: 0.739, Test loss: 0.644, Test accuracy: 71.92 

Round  10, Train loss: 0.623, Test loss: 0.632, Test accuracy: 72.78 

Round  11, Train loss: 0.644, Test loss: 0.630, Test accuracy: 72.63 

Round  12, Train loss: 0.625, Test loss: 0.606, Test accuracy: 73.75 

Round  13, Train loss: 0.722, Test loss: 0.614, Test accuracy: 73.33 

Round  14, Train loss: 0.636, Test loss: 0.608, Test accuracy: 73.78 

Round  15, Train loss: 0.610, Test loss: 0.600, Test accuracy: 74.47 

Round  16, Train loss: 0.552, Test loss: 0.578, Test accuracy: 75.20 

Round  17, Train loss: 0.604, Test loss: 0.561, Test accuracy: 76.42 

Round  18, Train loss: 0.566, Test loss: 0.548, Test accuracy: 76.92 

Round  19, Train loss: 0.528, Test loss: 0.553, Test accuracy: 76.43 

Round  20, Train loss: 0.650, Test loss: 0.541, Test accuracy: 76.87 

Round  21, Train loss: 0.523, Test loss: 0.528, Test accuracy: 77.07 

Round  22, Train loss: 0.536, Test loss: 0.533, Test accuracy: 77.42 

Round  23, Train loss: 0.539, Test loss: 0.523, Test accuracy: 78.08 

Round  24, Train loss: 0.547, Test loss: 0.499, Test accuracy: 79.68 

Round  25, Train loss: 0.495, Test loss: 0.497, Test accuracy: 79.18 

Round  26, Train loss: 0.548, Test loss: 0.493, Test accuracy: 79.48 

Round  27, Train loss: 0.437, Test loss: 0.477, Test accuracy: 80.23 

Round  28, Train loss: 0.523, Test loss: 0.470, Test accuracy: 80.47 

Round  29, Train loss: 0.445, Test loss: 0.465, Test accuracy: 80.28 

Round  30, Train loss: 0.494, Test loss: 0.477, Test accuracy: 80.13 

Round  31, Train loss: 0.522, Test loss: 0.480, Test accuracy: 79.83 

Round  32, Train loss: 0.518, Test loss: 0.489, Test accuracy: 80.02 

Round  33, Train loss: 0.444, Test loss: 0.509, Test accuracy: 79.30 

Round  34, Train loss: 0.502, Test loss: 0.486, Test accuracy: 79.62 

Round  35, Train loss: 0.487, Test loss: 0.451, Test accuracy: 81.73 

Round  36, Train loss: 0.496, Test loss: 0.448, Test accuracy: 81.90 

Round  37, Train loss: 0.442, Test loss: 0.436, Test accuracy: 81.98 

Round  38, Train loss: 0.469, Test loss: 0.422, Test accuracy: 82.62 

Round  39, Train loss: 0.403, Test loss: 0.417, Test accuracy: 83.00 

Round  40, Train loss: 0.398, Test loss: 0.423, Test accuracy: 82.65 

Round  41, Train loss: 0.399, Test loss: 0.424, Test accuracy: 82.47 

Round  42, Train loss: 0.427, Test loss: 0.411, Test accuracy: 83.38 

Round  43, Train loss: 0.357, Test loss: 0.414, Test accuracy: 83.27 

Round  44, Train loss: 0.383, Test loss: 0.415, Test accuracy: 83.23 

Round  45, Train loss: 0.404, Test loss: 0.415, Test accuracy: 83.37 

Round  46, Train loss: 0.337, Test loss: 0.408, Test accuracy: 83.67 

Round  47, Train loss: 0.359, Test loss: 0.407, Test accuracy: 83.78 

Round  48, Train loss: 0.370, Test loss: 0.397, Test accuracy: 83.95 

Round  49, Train loss: 0.345, Test loss: 0.399, Test accuracy: 84.35 

Round  50, Train loss: 0.365, Test loss: 0.408, Test accuracy: 83.82 

Round  51, Train loss: 0.421, Test loss: 0.403, Test accuracy: 83.90 

Round  52, Train loss: 0.405, Test loss: 0.399, Test accuracy: 84.20 

Round  53, Train loss: 0.342, Test loss: 0.397, Test accuracy: 84.02 

Round  54, Train loss: 0.382, Test loss: 0.387, Test accuracy: 84.62 

Round  55, Train loss: 0.349, Test loss: 0.386, Test accuracy: 84.57 

Round  56, Train loss: 0.360, Test loss: 0.385, Test accuracy: 84.50 

Round  57, Train loss: 0.382, Test loss: 0.387, Test accuracy: 84.38 

Round  58, Train loss: 0.404, Test loss: 0.407, Test accuracy: 83.73 

Round  59, Train loss: 0.327, Test loss: 0.395, Test accuracy: 84.12 

Round  60, Train loss: 0.344, Test loss: 0.397, Test accuracy: 84.53 

Round  61, Train loss: 0.346, Test loss: 0.392, Test accuracy: 84.28 

Round  62, Train loss: 0.330, Test loss: 0.405, Test accuracy: 83.58 

Round  63, Train loss: 0.277, Test loss: 0.412, Test accuracy: 83.78 

Round  64, Train loss: 0.348, Test loss: 0.399, Test accuracy: 84.52 

Round  65, Train loss: 0.297, Test loss: 0.394, Test accuracy: 84.48 

Round  66, Train loss: 0.326, Test loss: 0.385, Test accuracy: 84.72 

Round  67, Train loss: 0.307, Test loss: 0.381, Test accuracy: 85.45 

Round  68, Train loss: 0.290, Test loss: 0.377, Test accuracy: 85.38 

Round  69, Train loss: 0.260, Test loss: 0.378, Test accuracy: 85.22 

Round  70, Train loss: 0.360, Test loss: 0.388, Test accuracy: 84.83 

Round  71, Train loss: 0.298, Test loss: 0.383, Test accuracy: 84.77 

Round  72, Train loss: 0.280, Test loss: 0.385, Test accuracy: 84.68 

Round  73, Train loss: 0.337, Test loss: 0.382, Test accuracy: 85.07 

Round  74, Train loss: 0.251, Test loss: 0.375, Test accuracy: 84.93 

Round  75, Train loss: 0.293, Test loss: 0.385, Test accuracy: 84.95 

Round  76, Train loss: 0.255, Test loss: 0.378, Test accuracy: 85.32 

Round  77, Train loss: 0.275, Test loss: 0.392, Test accuracy: 85.15 

Round  78, Train loss: 0.305, Test loss: 0.379, Test accuracy: 85.40 

Round  79, Train loss: 0.275, Test loss: 0.388, Test accuracy: 85.25 

Round  80, Train loss: 0.250, Test loss: 0.390, Test accuracy: 85.12 

Round  81, Train loss: 0.283, Test loss: 0.373, Test accuracy: 85.65 

Round  82, Train loss: 0.274, Test loss: 0.377, Test accuracy: 85.63 

Round  83, Train loss: 0.232, Test loss: 0.390, Test accuracy: 85.58 

Round  84, Train loss: 0.227, Test loss: 0.384, Test accuracy: 85.60 

Round  85, Train loss: 0.233, Test loss: 0.396, Test accuracy: 85.23 

Round  86, Train loss: 0.218, Test loss: 0.400, Test accuracy: 84.65 

Round  87, Train loss: 0.299, Test loss: 0.390, Test accuracy: 85.23 

Round  88, Train loss: 0.261, Test loss: 0.376, Test accuracy: 85.73 

Round  89, Train loss: 0.242, Test loss: 0.382, Test accuracy: 85.65 

Round  90, Train loss: 0.252, Test loss: 0.388, Test accuracy: 85.55 

Round  91, Train loss: 0.296, Test loss: 0.384, Test accuracy: 85.58 

Round  92, Train loss: 0.295, Test loss: 0.398, Test accuracy: 85.45 

Round  93, Train loss: 0.227, Test loss: 0.385, Test accuracy: 85.87 

Round  94, Train loss: 0.294, Test loss: 0.388, Test accuracy: 85.32 

Round  95, Train loss: 0.301, Test loss: 0.395, Test accuracy: 85.52 

Round  96, Train loss: 0.295, Test loss: 0.402, Test accuracy: 85.13 

Round  97, Train loss: 0.214, Test loss: 0.385, Test accuracy: 85.48 

Round  98, Train loss: 0.230, Test loss: 0.386, Test accuracy: 85.52 

Round  99, Train loss: 0.263, Test loss: 0.388, Test accuracy: 85.60 

Final Round, Train loss: 0.201, Test loss: 0.393, Test accuracy: 85.72 

Average accuracy final 10 rounds: 85.50166666666667 

541.7900528907776
[0.8913416862487793, 1.5267412662506104, 2.159374237060547, 2.7950711250305176, 3.430722236633301, 4.070738077163696, 4.705410480499268, 5.339801073074341, 5.9769322872161865, 6.611317873001099, 7.247943639755249, 7.886080980300903, 8.52283763885498, 9.154896974563599, 9.792136669158936, 10.425986051559448, 11.06416916847229, 11.69813585281372, 12.335912466049194, 12.967838287353516, 13.607106924057007, 14.241587162017822, 14.880199670791626, 15.520096778869629, 16.160574674606323, 16.801082134246826, 17.438827514648438, 18.076565265655518, 18.7168071269989, 19.356194496154785, 19.966588973999023, 20.585841417312622, 21.20924973487854, 21.840295791625977, 22.469249486923218, 23.0999276638031, 23.728087663650513, 24.356696367263794, 24.983815908432007, 25.614810466766357, 26.246233701705933, 26.87510061264038, 27.50468921661377, 28.135261058807373, 28.76471757888794, 29.398175477981567, 30.027307510375977, 30.654675483703613, 31.284006595611572, 31.914909601211548, 32.547609090805054, 33.17971920967102, 33.811002016067505, 34.442347049713135, 35.080198526382446, 35.7192165851593, 36.354111194610596, 36.991539001464844, 37.63040018081665, 38.2631733417511, 38.89354586601257, 39.524442195892334, 40.15468645095825, 40.78642201423645, 41.423755168914795, 42.06033778190613, 42.6953387260437, 43.33326292037964, 43.96784019470215, 44.59945845603943, 45.23398995399475, 45.86328101158142, 46.495466232299805, 47.13016057014465, 47.75957489013672, 48.394062995910645, 49.02500319480896, 49.65408992767334, 50.285287857055664, 50.91802430152893, 51.55088424682617, 52.186257123947144, 52.81891989707947, 53.44946646690369, 54.08294224739075, 54.71858787536621, 55.349931478500366, 55.98205327987671, 56.61474800109863, 57.196163177490234, 57.771592140197754, 58.34964632987976, 58.924566984176636, 59.49858236312866, 60.071940422058105, 60.64521813392639, 61.21692371368408, 61.787935733795166, 62.35626578330994, 62.9258828163147, 63.99257278442383]
[14.983333333333333, 32.18333333333333, 40.96666666666667, 49.916666666666664, 54.71666666666667, 57.516666666666666, 64.48333333333333, 62.93333333333333, 68.08333333333333, 71.91666666666667, 72.78333333333333, 72.63333333333334, 73.75, 73.33333333333333, 73.78333333333333, 74.46666666666667, 75.2, 76.41666666666667, 76.91666666666667, 76.43333333333334, 76.86666666666666, 77.06666666666666, 77.41666666666667, 78.08333333333333, 79.68333333333334, 79.18333333333334, 79.48333333333333, 80.23333333333333, 80.46666666666667, 80.28333333333333, 80.13333333333334, 79.83333333333333, 80.01666666666667, 79.3, 79.61666666666666, 81.73333333333333, 81.9, 81.98333333333333, 82.61666666666666, 83.0, 82.65, 82.46666666666667, 83.38333333333334, 83.26666666666667, 83.23333333333333, 83.36666666666666, 83.66666666666667, 83.78333333333333, 83.95, 84.35, 83.81666666666666, 83.9, 84.2, 84.01666666666667, 84.61666666666666, 84.56666666666666, 84.5, 84.38333333333334, 83.73333333333333, 84.11666666666666, 84.53333333333333, 84.28333333333333, 83.58333333333333, 83.78333333333333, 84.51666666666667, 84.48333333333333, 84.71666666666667, 85.45, 85.38333333333334, 85.21666666666667, 84.83333333333333, 84.76666666666667, 84.68333333333334, 85.06666666666666, 84.93333333333334, 84.95, 85.31666666666666, 85.15, 85.4, 85.25, 85.11666666666666, 85.65, 85.63333333333334, 85.58333333333333, 85.6, 85.23333333333333, 84.65, 85.23333333333333, 85.73333333333333, 85.65, 85.55, 85.58333333333333, 85.45, 85.86666666666666, 85.31666666666666, 85.51666666666667, 85.13333333333334, 85.48333333333333, 85.51666666666667, 85.6, 85.71666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307832
307842
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.725, Test loss: 2.147, Test accuracy: 19.97
Round   1, Train loss: 1.094, Test loss: 1.765, Test accuracy: 35.77
Round   2, Train loss: 0.992, Test loss: 1.342, Test accuracy: 47.20
Round   3, Train loss: 0.903, Test loss: 1.158, Test accuracy: 53.45
Round   4, Train loss: 0.870, Test loss: 1.086, Test accuracy: 59.37
Round   5, Train loss: 0.781, Test loss: 0.926, Test accuracy: 62.97
Round   6, Train loss: 0.803, Test loss: 0.893, Test accuracy: 66.02
Round   7, Train loss: 0.691, Test loss: 0.833, Test accuracy: 67.48
Round   8, Train loss: 0.715, Test loss: 0.764, Test accuracy: 69.82
Round   9, Train loss: 0.692, Test loss: 0.774, Test accuracy: 70.90
Round  10, Train loss: 0.647, Test loss: 0.758, Test accuracy: 71.07
Round  11, Train loss: 0.644, Test loss: 0.645, Test accuracy: 75.15
Round  12, Train loss: 0.640, Test loss: 0.623, Test accuracy: 77.02
Round  13, Train loss: 0.630, Test loss: 0.596, Test accuracy: 76.77
Round  14, Train loss: 0.583, Test loss: 0.615, Test accuracy: 76.57
Round  15, Train loss: 0.642, Test loss: 0.575, Test accuracy: 77.43
Round  16, Train loss: 0.603, Test loss: 0.577, Test accuracy: 77.38
Round  17, Train loss: 0.559, Test loss: 0.563, Test accuracy: 78.07
Round  18, Train loss: 0.555, Test loss: 0.549, Test accuracy: 78.80
Round  19, Train loss: 0.547, Test loss: 0.544, Test accuracy: 78.88
Round  20, Train loss: 0.535, Test loss: 0.535, Test accuracy: 78.97
Round  21, Train loss: 0.555, Test loss: 0.536, Test accuracy: 79.28
Round  22, Train loss: 0.640, Test loss: 0.529, Test accuracy: 79.15
Round  23, Train loss: 0.600, Test loss: 0.512, Test accuracy: 80.08
Round  24, Train loss: 0.513, Test loss: 0.501, Test accuracy: 79.77
Round  25, Train loss: 0.589, Test loss: 0.491, Test accuracy: 81.12
Round  26, Train loss: 0.481, Test loss: 0.494, Test accuracy: 80.73
Round  27, Train loss: 0.453, Test loss: 0.474, Test accuracy: 81.33
Round  28, Train loss: 0.486, Test loss: 0.477, Test accuracy: 81.38
Round  29, Train loss: 0.497, Test loss: 0.486, Test accuracy: 81.42
Round  30, Train loss: 0.486, Test loss: 0.469, Test accuracy: 81.38
Round  31, Train loss: 0.479, Test loss: 0.466, Test accuracy: 81.85
Round  32, Train loss: 0.487, Test loss: 0.456, Test accuracy: 82.13
Round  33, Train loss: 0.506, Test loss: 0.445, Test accuracy: 82.52
Round  34, Train loss: 0.458, Test loss: 0.430, Test accuracy: 82.85
Round  35, Train loss: 0.433, Test loss: 0.437, Test accuracy: 82.82
Round  36, Train loss: 0.479, Test loss: 0.430, Test accuracy: 82.60
Round  37, Train loss: 0.500, Test loss: 0.435, Test accuracy: 82.82
Round  38, Train loss: 0.410, Test loss: 0.424, Test accuracy: 83.12
Round  39, Train loss: 0.495, Test loss: 0.418, Test accuracy: 83.65
Round  40, Train loss: 0.500, Test loss: 0.419, Test accuracy: 83.47
Round  41, Train loss: 0.430, Test loss: 0.417, Test accuracy: 83.62
Round  42, Train loss: 0.476, Test loss: 0.412, Test accuracy: 83.72
Round  43, Train loss: 0.392, Test loss: 0.404, Test accuracy: 84.30
Round  44, Train loss: 0.382, Test loss: 0.418, Test accuracy: 83.15
Round  45, Train loss: 0.386, Test loss: 0.400, Test accuracy: 84.22
Round  46, Train loss: 0.435, Test loss: 0.406, Test accuracy: 84.33
Round  47, Train loss: 0.360, Test loss: 0.397, Test accuracy: 84.23
Round  48, Train loss: 0.359, Test loss: 0.401, Test accuracy: 83.98
Round  49, Train loss: 0.376, Test loss: 0.393, Test accuracy: 84.37
Round  50, Train loss: 0.355, Test loss: 0.394, Test accuracy: 84.73
Round  51, Train loss: 0.330, Test loss: 0.389, Test accuracy: 84.68
Round  52, Train loss: 0.331, Test loss: 0.382, Test accuracy: 85.12
Round  53, Train loss: 0.398, Test loss: 0.393, Test accuracy: 84.78
Round  54, Train loss: 0.355, Test loss: 0.386, Test accuracy: 85.10
Round  55, Train loss: 0.354, Test loss: 0.376, Test accuracy: 85.70
Round  56, Train loss: 0.400, Test loss: 0.378, Test accuracy: 85.47
Round  57, Train loss: 0.322, Test loss: 0.374, Test accuracy: 85.33
Round  58, Train loss: 0.293, Test loss: 0.381, Test accuracy: 85.02
Round  59, Train loss: 0.382, Test loss: 0.378, Test accuracy: 85.27
Round  60, Train loss: 0.326, Test loss: 0.382, Test accuracy: 85.08
Round  61, Train loss: 0.398, Test loss: 0.367, Test accuracy: 85.58
Round  62, Train loss: 0.383, Test loss: 0.367, Test accuracy: 85.23
Round  63, Train loss: 0.347, Test loss: 0.369, Test accuracy: 85.37
Round  64, Train loss: 0.322, Test loss: 0.363, Test accuracy: 85.93
Round  65, Train loss: 0.368, Test loss: 0.369, Test accuracy: 85.68
Round  66, Train loss: 0.264, Test loss: 0.363, Test accuracy: 85.32
Round  67, Train loss: 0.335, Test loss: 0.364, Test accuracy: 85.58
Round  68, Train loss: 0.355, Test loss: 0.356, Test accuracy: 86.08
Round  69, Train loss: 0.275, Test loss: 0.360, Test accuracy: 85.93
Round  70, Train loss: 0.366, Test loss: 0.358, Test accuracy: 86.08
Round  71, Train loss: 0.272, Test loss: 0.360, Test accuracy: 85.98
Round  72, Train loss: 0.287, Test loss: 0.353, Test accuracy: 86.03
Round  73, Train loss: 0.294, Test loss: 0.348, Test accuracy: 86.27
Round  74, Train loss: 0.284, Test loss: 0.352, Test accuracy: 85.88
Round  75, Train loss: 0.286, Test loss: 0.346, Test accuracy: 86.13
Round  76, Train loss: 0.313, Test loss: 0.348, Test accuracy: 86.10
Round  77, Train loss: 0.275, Test loss: 0.349, Test accuracy: 86.38
Round  78, Train loss: 0.327, Test loss: 0.351, Test accuracy: 85.98
Round  79, Train loss: 0.264, Test loss: 0.346, Test accuracy: 86.50
Round  80, Train loss: 0.239, Test loss: 0.349, Test accuracy: 86.33
Round  81, Train loss: 0.258, Test loss: 0.341, Test accuracy: 86.30
Round  82, Train loss: 0.312, Test loss: 0.347, Test accuracy: 86.20
Round  83, Train loss: 0.279, Test loss: 0.346, Test accuracy: 86.33
Round  84, Train loss: 0.300, Test loss: 0.349, Test accuracy: 85.57
Round  85, Train loss: 0.276, Test loss: 0.358, Test accuracy: 85.50
Round  86, Train loss: 0.267, Test loss: 0.344, Test accuracy: 86.77
Round  87, Train loss: 0.274, Test loss: 0.349, Test accuracy: 86.33
Round  88, Train loss: 0.245, Test loss: 0.355, Test accuracy: 86.20
Round  89, Train loss: 0.272, Test loss: 0.345, Test accuracy: 86.07
Round  90, Train loss: 0.245, Test loss: 0.341, Test accuracy: 86.33
Round  91, Train loss: 0.322, Test loss: 0.351, Test accuracy: 86.05
Round  92, Train loss: 0.207, Test loss: 0.347, Test accuracy: 86.02
Round  93, Train loss: 0.282, Test loss: 0.352, Test accuracy: 85.85
Round  94, Train loss: 0.243, Test loss: 0.347, Test accuracy: 86.20
Round  95, Train loss: 0.251, Test loss: 0.344, Test accuracy: 86.67
Round  96, Train loss: 0.308, Test loss: 0.359, Test accuracy: 85.67
Round  97, Train loss: 0.246, Test loss: 0.349, Test accuracy: 86.25
Round  98, Train loss: 0.266, Test loss: 0.348, Test accuracy: 86.02
Round  99, Train loss: 0.225, Test loss: 0.339, Test accuracy: 86.85
Final Round, Train loss: 0.201, Test loss: 0.338, Test accuracy: 87.00
Average accuracy final 10 rounds: 86.19
645.7295136451721
[1.0334854125976562, 1.8288044929504395, 2.6459052562713623, 3.4280893802642822, 4.208888292312622, 4.990655899047852, 5.7791266441345215, 6.5613813400268555, 7.344209671020508, 8.130076885223389, 8.919093370437622, 9.701391696929932, 10.4825439453125, 11.264595985412598, 12.050726890563965, 12.82550835609436, 13.600262880325317, 14.381412267684937, 15.172507762908936, 15.957777976989746, 16.74147129058838, 17.5192289352417, 18.315295219421387, 19.1092426776886, 19.88856816291809, 20.67153811454773, 21.46622586250305, 22.263541221618652, 23.04377293586731, 23.8275043964386, 24.608358144760132, 25.399986505508423, 26.181336641311646, 26.96064519882202, 27.745395183563232, 28.53427004814148, 29.327025651931763, 30.107036590576172, 30.892330646514893, 31.688007831573486, 32.48775053024292, 33.28068137168884, 34.07342338562012, 34.865811824798584, 35.66652297973633, 36.45854187011719, 37.25511169433594, 38.04423761367798, 38.844353675842285, 39.64240121841431, 40.43158221244812, 41.22736191749573, 42.01828575134277, 42.814446210861206, 43.607091426849365, 44.40155386924744, 45.19338798522949, 45.99080228805542, 46.788424253463745, 47.578012228012085, 48.37053179740906, 49.16250419616699, 49.950485706329346, 50.73226857185364, 51.51648688316345, 52.299275398254395, 53.089908838272095, 53.8760142326355, 54.65833878517151, 55.43665933609009, 56.23303270339966, 57.02605724334717, 57.81671857833862, 58.609137535095215, 59.40814661979675, 60.20732069015503, 60.999361991882324, 61.794565200805664, 62.58632445335388, 63.38387179374695, 64.18193626403809, 64.9779405593872, 65.76785063743591, 66.5639750957489, 67.36057043075562, 68.15084433555603, 68.93920302391052, 69.72921419143677, 70.52564072608948, 71.32216572761536, 72.11293601989746, 72.9039089679718, 73.69265937805176, 74.48099994659424, 75.26732158660889, 76.04936480522156, 76.83088493347168, 77.6210949420929, 78.40581440925598, 79.19081449508667, 80.40606808662415]
[19.966666666666665, 35.766666666666666, 47.2, 53.45, 59.36666666666667, 62.96666666666667, 66.01666666666667, 67.48333333333333, 69.81666666666666, 70.9, 71.06666666666666, 75.15, 77.01666666666667, 76.76666666666667, 76.56666666666666, 77.43333333333334, 77.38333333333334, 78.06666666666666, 78.8, 78.88333333333334, 78.96666666666667, 79.28333333333333, 79.15, 80.08333333333333, 79.76666666666667, 81.11666666666666, 80.73333333333333, 81.33333333333333, 81.38333333333334, 81.41666666666667, 81.38333333333334, 81.85, 82.13333333333334, 82.51666666666667, 82.85, 82.81666666666666, 82.6, 82.81666666666666, 83.11666666666666, 83.65, 83.46666666666667, 83.61666666666666, 83.71666666666667, 84.3, 83.15, 84.21666666666667, 84.33333333333333, 84.23333333333333, 83.98333333333333, 84.36666666666666, 84.73333333333333, 84.68333333333334, 85.11666666666666, 84.78333333333333, 85.1, 85.7, 85.46666666666667, 85.33333333333333, 85.01666666666667, 85.26666666666667, 85.08333333333333, 85.58333333333333, 85.23333333333333, 85.36666666666666, 85.93333333333334, 85.68333333333334, 85.31666666666666, 85.58333333333333, 86.08333333333333, 85.93333333333334, 86.08333333333333, 85.98333333333333, 86.03333333333333, 86.26666666666667, 85.88333333333334, 86.13333333333334, 86.1, 86.38333333333334, 85.98333333333333, 86.5, 86.33333333333333, 86.3, 86.2, 86.33333333333333, 85.56666666666666, 85.5, 86.76666666666667, 86.33333333333333, 86.2, 86.06666666666666, 86.33333333333333, 86.05, 86.01666666666667, 85.85, 86.2, 86.66666666666667, 85.66666666666667, 86.25, 86.01666666666667, 86.85, 87.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.267, Test loss: 2.259, Test accuracy: 16.10
Round   1, Train loss: 1.076, Test loss: 2.093, Test accuracy: 22.12
Round   2, Train loss: 0.959, Test loss: 2.001, Test accuracy: 30.67
Round   3, Train loss: 0.914, Test loss: 1.937, Test accuracy: 34.70
Round   4, Train loss: 0.789, Test loss: 1.947, Test accuracy: 33.23
Round   5, Train loss: 0.793, Test loss: 1.850, Test accuracy: 34.07
Round   6, Train loss: 0.749, Test loss: 1.973, Test accuracy: 29.77
Round   7, Train loss: 0.726, Test loss: 1.713, Test accuracy: 39.90
Round   8, Train loss: 0.661, Test loss: 1.706, Test accuracy: 42.95
Round   9, Train loss: 0.742, Test loss: 1.900, Test accuracy: 38.98
Round  10, Train loss: 0.633, Test loss: 1.624, Test accuracy: 42.82
Round  11, Train loss: 0.653, Test loss: 1.680, Test accuracy: 43.03
Round  12, Train loss: 0.582, Test loss: 1.579, Test accuracy: 47.83
Round  13, Train loss: 0.712, Test loss: 1.584, Test accuracy: 44.35
Round  14, Train loss: 0.595, Test loss: 1.719, Test accuracy: 44.17
Round  15, Train loss: 0.601, Test loss: 1.646, Test accuracy: 44.72
Round  16, Train loss: 0.542, Test loss: 1.625, Test accuracy: 44.57
Round  17, Train loss: 0.617, Test loss: 1.814, Test accuracy: 40.92
Round  18, Train loss: 0.547, Test loss: 1.655, Test accuracy: 42.03
Round  19, Train loss: 0.518, Test loss: 1.592, Test accuracy: 44.95
Round  20, Train loss: 0.481, Test loss: 1.881, Test accuracy: 43.40
Round  21, Train loss: 0.458, Test loss: 1.498, Test accuracy: 47.37
Round  22, Train loss: 0.558, Test loss: 1.384, Test accuracy: 50.80
Round  23, Train loss: 0.458, Test loss: 1.582, Test accuracy: 45.05
Round  24, Train loss: 0.489, Test loss: 1.531, Test accuracy: 47.90
Round  25, Train loss: 0.481, Test loss: 1.697, Test accuracy: 45.78
Round  26, Train loss: 0.433, Test loss: 1.744, Test accuracy: 43.67
Round  27, Train loss: 0.501, Test loss: 1.335, Test accuracy: 51.27
Round  28, Train loss: 0.424, Test loss: 1.677, Test accuracy: 45.48
Round  29, Train loss: 0.447, Test loss: 1.398, Test accuracy: 50.52
Round  30, Train loss: 0.447, Test loss: 1.662, Test accuracy: 45.72
Round  31, Train loss: 0.472, Test loss: 1.334, Test accuracy: 54.33
Round  32, Train loss: 0.477, Test loss: 1.418, Test accuracy: 51.13
Round  33, Train loss: 0.394, Test loss: 1.774, Test accuracy: 42.63
Round  34, Train loss: 0.414, Test loss: 1.484, Test accuracy: 49.70
Round  35, Train loss: 0.417, Test loss: 1.367, Test accuracy: 53.78
Round  36, Train loss: 0.411, Test loss: 1.416, Test accuracy: 50.88
Round  37, Train loss: 0.405, Test loss: 1.458, Test accuracy: 51.65
Round  38, Train loss: 0.393, Test loss: 1.299, Test accuracy: 55.00
Round  39, Train loss: 0.331, Test loss: 1.437, Test accuracy: 52.97
Round  40, Train loss: 0.357, Test loss: 1.239, Test accuracy: 55.30
Round  41, Train loss: 0.391, Test loss: 1.326, Test accuracy: 53.13
Round  42, Train loss: 0.342, Test loss: 1.290, Test accuracy: 54.60
Round  43, Train loss: 0.300, Test loss: 1.775, Test accuracy: 50.60
Round  44, Train loss: 0.347, Test loss: 1.557, Test accuracy: 48.68
Round  45, Train loss: 0.298, Test loss: 1.422, Test accuracy: 51.37
Round  46, Train loss: 0.322, Test loss: 1.307, Test accuracy: 54.72
Round  47, Train loss: 0.275, Test loss: 1.301, Test accuracy: 54.93
Round  48, Train loss: 0.250, Test loss: 1.394, Test accuracy: 54.08
Round  49, Train loss: 0.348, Test loss: 1.162, Test accuracy: 58.47
Round  50, Train loss: 0.350, Test loss: 1.217, Test accuracy: 57.23
Round  51, Train loss: 0.268, Test loss: 1.802, Test accuracy: 47.63
Round  52, Train loss: 0.317, Test loss: 1.159, Test accuracy: 59.72
Round  53, Train loss: 0.254, Test loss: 1.259, Test accuracy: 57.52
Round  54, Train loss: 0.250, Test loss: 1.397, Test accuracy: 55.93
Round  55, Train loss: 0.256, Test loss: 1.484, Test accuracy: 52.88
Round  56, Train loss: 0.235, Test loss: 1.814, Test accuracy: 48.22
Round  57, Train loss: 0.262, Test loss: 1.374, Test accuracy: 54.00
Round  58, Train loss: 0.318, Test loss: 1.267, Test accuracy: 58.28
Round  59, Train loss: 0.310, Test loss: 1.703, Test accuracy: 51.43
Round  60, Train loss: 0.277, Test loss: 1.495, Test accuracy: 55.78
Round  61, Train loss: 0.227, Test loss: 1.498, Test accuracy: 53.70
Round  62, Train loss: 0.279, Test loss: 1.175, Test accuracy: 59.92
Round  63, Train loss: 0.282, Test loss: 1.365, Test accuracy: 56.13
Round  64, Train loss: 0.249, Test loss: 1.310, Test accuracy: 57.93
Round  65, Train loss: 0.271, Test loss: 1.251, Test accuracy: 57.98
Round  66, Train loss: 0.218, Test loss: 1.397, Test accuracy: 56.72
Round  67, Train loss: 0.219, Test loss: 1.290, Test accuracy: 58.12
Round  68, Train loss: 0.202, Test loss: 1.377, Test accuracy: 56.42
Round  69, Train loss: 0.219, Test loss: 1.365, Test accuracy: 56.42
Round  70, Train loss: 0.252, Test loss: 1.394, Test accuracy: 55.97
Round  71, Train loss: 0.229, Test loss: 1.365, Test accuracy: 55.90
Round  72, Train loss: 0.200, Test loss: 1.595, Test accuracy: 52.63
Round  73, Train loss: 0.190, Test loss: 1.657, Test accuracy: 51.80
Round  74, Train loss: 0.186, Test loss: 1.582, Test accuracy: 51.33
Round  75, Train loss: 0.219, Test loss: 1.537, Test accuracy: 51.48
Round  76, Train loss: 0.180, Test loss: 1.222, Test accuracy: 60.42
Round  77, Train loss: 0.187, Test loss: 1.661, Test accuracy: 52.10
Round  78, Train loss: 0.240, Test loss: 1.559, Test accuracy: 53.20
Round  79, Train loss: 0.199, Test loss: 1.638, Test accuracy: 51.12
Round  80, Train loss: 0.193, Test loss: 1.635, Test accuracy: 54.78
Round  81, Train loss: 0.215, Test loss: 1.241, Test accuracy: 59.40
Round  82, Train loss: 0.161, Test loss: 1.578, Test accuracy: 53.57
Round  83, Train loss: 0.133, Test loss: 1.450, Test accuracy: 56.97
Round  84, Train loss: 0.219, Test loss: 1.181, Test accuracy: 59.62
Round  85, Train loss: 0.160, Test loss: 1.150, Test accuracy: 62.38
Round  86, Train loss: 0.230, Test loss: 1.186, Test accuracy: 60.47
Round  87, Train loss: 0.191, Test loss: 1.583, Test accuracy: 52.03
Round  88, Train loss: 0.230, Test loss: 1.801, Test accuracy: 50.88
Round  89, Train loss: 0.176, Test loss: 1.243, Test accuracy: 59.62
Round  90, Train loss: 0.117, Test loss: 1.605, Test accuracy: 56.20
Round  91, Train loss: 0.155, Test loss: 1.515, Test accuracy: 57.55
Round  92, Train loss: 0.176, Test loss: 1.402, Test accuracy: 57.93
Round  93, Train loss: 0.142, Test loss: 1.444, Test accuracy: 56.35
Round  94, Train loss: 0.139, Test loss: 1.327, Test accuracy: 59.92
Round  95, Train loss: 0.152, Test loss: 1.808, Test accuracy: 52.32
Round  96, Train loss: 0.183, Test loss: 1.185, Test accuracy: 61.33
Round  97, Train loss: 0.142, Test loss: 1.409, Test accuracy: 58.45
Round  98, Train loss: 0.137, Test loss: 1.202, Test accuracy: 62.25
Round  99, Train loss: 0.155, Test loss: 1.278, Test accuracy: 60.35
Final Round, Train loss: 0.140, Test loss: 1.120, Test accuracy: 64.20
Average accuracy final 10 rounds: 58.265
1168.742788553238
[1.9953515529632568, 3.75947904586792, 5.530083894729614, 7.304780006408691, 9.068286180496216, 10.840184211730957, 12.607131242752075, 14.377290725708008, 16.13618755340576, 17.901376247406006, 19.66403603553772, 21.424588441848755, 23.19856882095337, 24.96640396118164, 26.73622751235962, 28.5068519115448, 30.272414684295654, 32.03688907623291, 33.806822299957275, 35.58366584777832, 37.34373164176941, 39.111417055130005, 40.874006032943726, 42.644946575164795, 44.409788846969604, 46.17934560775757, 47.950560092926025, 49.712557554244995, 51.4797625541687, 53.2426540851593, 55.01265358924866, 56.77281355857849, 58.53621196746826, 60.307597160339355, 62.06987738609314, 63.83694815635681, 65.60842490196228, 67.38160514831543, 69.11985111236572, 70.88161778450012, 72.63579273223877, 74.400155544281, 76.16787242889404, 77.92597389221191, 79.50200176239014, 81.07142519950867, 82.64247035980225, 84.21375226974487, 85.78999590873718, 87.36494517326355, 88.93577933311462, 90.50535130500793, 92.07310152053833, 93.63958930969238, 95.21188592910767, 96.78495216369629, 98.35564112663269, 99.9237208366394, 101.49199604988098, 103.06207728385925, 104.6311571598053, 106.20834565162659, 107.7851915359497, 109.3573682308197, 110.93397569656372, 112.50707912445068, 114.07859826087952, 115.64428448677063, 117.21817541122437, 118.78676533699036, 120.35458159446716, 121.92460751533508, 123.4927167892456, 125.06509017944336, 126.63522481918335, 128.2113881111145, 129.78793215751648, 131.3561418056488, 132.92981433868408, 134.50137519836426, 136.07942414283752, 137.65558505058289, 139.22741031646729, 140.80015420913696, 142.37076807022095, 143.9491159915924, 145.51964569091797, 147.0928876399994, 148.66627717018127, 150.23899865150452, 151.81799793243408, 153.3905258178711, 154.9624741077423, 156.53959846496582, 158.11003518104553, 159.6806628704071, 161.25121665000916, 162.82421469688416, 164.39715695381165, 165.9682502746582, 167.54361748695374]
[16.1, 22.116666666666667, 30.666666666666668, 34.7, 33.233333333333334, 34.06666666666667, 29.766666666666666, 39.9, 42.95, 38.983333333333334, 42.81666666666667, 43.03333333333333, 47.833333333333336, 44.35, 44.166666666666664, 44.71666666666667, 44.56666666666667, 40.916666666666664, 42.03333333333333, 44.95, 43.4, 47.36666666666667, 50.8, 45.05, 47.9, 45.78333333333333, 43.666666666666664, 51.266666666666666, 45.483333333333334, 50.516666666666666, 45.71666666666667, 54.333333333333336, 51.13333333333333, 42.63333333333333, 49.7, 53.78333333333333, 50.88333333333333, 51.65, 55.0, 52.96666666666667, 55.3, 53.13333333333333, 54.6, 50.6, 48.68333333333333, 51.36666666666667, 54.71666666666667, 54.93333333333333, 54.083333333333336, 58.46666666666667, 57.233333333333334, 47.63333333333333, 59.71666666666667, 57.516666666666666, 55.93333333333333, 52.88333333333333, 48.21666666666667, 54.0, 58.28333333333333, 51.43333333333333, 55.78333333333333, 53.7, 59.916666666666664, 56.13333333333333, 57.93333333333333, 57.983333333333334, 56.71666666666667, 58.11666666666667, 56.416666666666664, 56.416666666666664, 55.96666666666667, 55.9, 52.63333333333333, 51.8, 51.333333333333336, 51.483333333333334, 60.416666666666664, 52.1, 53.2, 51.11666666666667, 54.78333333333333, 59.4, 53.56666666666667, 56.96666666666667, 59.61666666666667, 62.38333333333333, 60.46666666666667, 52.03333333333333, 50.88333333333333, 59.61666666666667, 56.2, 57.55, 57.93333333333333, 56.35, 59.916666666666664, 52.31666666666667, 61.333333333333336, 58.45, 62.25, 60.35, 64.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.321, Test accuracy: 9.63 

Round   0, Global train loss: 2.290, Global test loss: 2.323, Global test accuracy: 9.42 

Round   1, Train loss: 2.278, Test loss: 2.319, Test accuracy: 11.22 

Round   1, Global train loss: 2.278, Global test loss: 2.321, Global test accuracy: 11.63 

Round   2, Train loss: 2.256, Test loss: 2.315, Test accuracy: 11.23 

Round   2, Global train loss: 2.256, Global test loss: 2.319, Global test accuracy: 11.67 

Round   3, Train loss: 2.316, Test loss: 2.319, Test accuracy: 11.20 

Round   3, Global train loss: 2.316, Global test loss: 2.317, Global test accuracy: 11.67 

Round   4, Train loss: nan, Test loss: nan, Test accuracy: 12.87 

Round   4, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round   5, Train loss: nan, Test loss: nan, Test accuracy: 14.53 

Round   5, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round   6, Train loss: nan, Test loss: nan, Test accuracy: 9.67 

Round   6, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round   7, Train loss: nan, Test loss: nan, Test accuracy: 9.67 

Round   7, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round   8, Train loss: nan, Test loss: nan, Test accuracy: 11.33 

Round   8, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round   9, Train loss: nan, Test loss: nan, Test accuracy: 11.33 

Round   9, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  10, Train loss: nan, Test loss: nan, Test accuracy: 8.33 

Round  10, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  11, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  11, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  12, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  12, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  13, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  13, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  14, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  14, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  15, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  15, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  16, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  16, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  17, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  17, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  18, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  18, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  19, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  19, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  20, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  20, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  21, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  21, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  22, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  22, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  23, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  23, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  24, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  24, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  25, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  25, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  26, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  26, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  27, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  27, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  28, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  28, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  29, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  29, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  30, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  30, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  31, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  31, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  32, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  32, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  33, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  33, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  34, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  34, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  35, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  35, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  36, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  36, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  37, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  37, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  38, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  38, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  39, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  39, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  40, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  40, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  41, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  41, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  42, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  42, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  43, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  43, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  44, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  44, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  45, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  45, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  46, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  46, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  47, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  47, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  48, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  48, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  49, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  49, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  50, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  50, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  51, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  51, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  52, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  52, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  53, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  53, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  54, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  54, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  55, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  55, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  56, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  56, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  57, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  57, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  58, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  58, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  59, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  59, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  60, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  60, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  61, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  61, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  62, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  62, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  63, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  63, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  64, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  64, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  65, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  65, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  66, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  66, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  67, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  67, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  68, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  68, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  69, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  69, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  70, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  70, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  71, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  71, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  72, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  72, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  73, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  73, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  74, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  74, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  75, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  75, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  76, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  76, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  77, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  77, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  78, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  78, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  79, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  79, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  80, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  80, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  81, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  81, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  82, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  82, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  83, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  83, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  84, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  84, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  85, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  85, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  86, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  86, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  87, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  87, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  88, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  88, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  89, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  89, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  90, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  90, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  91, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  91, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  92, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  92, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  93, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  93, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  94, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  94, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  95, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  95, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  96, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  96, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  97, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  97, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  98, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  98, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  99, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round  99, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 100, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 100, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 101, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 101, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 102, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 102, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 103, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 103, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 104, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 104, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 105, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 105, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 106, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 106, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 107, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 107, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 108, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 108, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 109, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 109, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 110, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 110, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 111, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 111, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 112, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 112, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 113, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 113, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 114, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 114, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 115, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 115, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 116, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 116, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 117, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 117, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 118, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 118, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 119, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 119, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 120, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 120, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 121, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 121, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 122, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 122, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 123, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 123, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 124, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 124, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 125, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 125, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 126, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 126, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 127, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 127, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 128, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 128, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 129, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 129, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 130, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 130, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 131, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 131, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 132, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 132, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 133, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 133, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 134, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 134, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 135, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 135, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 136, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 136, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 137, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 137, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 138, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 138, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 139, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 139, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 140, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 140, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 141, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 141, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 142, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 142, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 143, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 143, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 144, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 144, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 145, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 145, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 146, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 146, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 147, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 147, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 148, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 148, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 149, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 149, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 150, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 150, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 151, Train loss: nan, Test loss: nan, Test accuracy: 10.00 
