nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.178, Test loss: 1.989, Test accuracy: 29.02
Round   0, Global train loss: 1.178, Global test loss: 2.298, Global test accuracy: 22.40
Round   1, Train loss: 0.932, Test loss: 1.493, Test accuracy: 42.62
Round   1, Global train loss: 0.932, Global test loss: 2.136, Global test accuracy: 26.60
Round   2, Train loss: 0.880, Test loss: 1.348, Test accuracy: 50.22
Round   2, Global train loss: 0.880, Global test loss: 2.277, Global test accuracy: 26.23
Round   3, Train loss: 0.869, Test loss: 1.022, Test accuracy: 57.85
Round   3, Global train loss: 0.869, Global test loss: 2.085, Global test accuracy: 27.17
Round   4, Train loss: 0.696, Test loss: 0.913, Test accuracy: 61.12
Round   4, Global train loss: 0.696, Global test loss: 2.015, Global test accuracy: 27.65
Round   5, Train loss: 0.685, Test loss: 0.836, Test accuracy: 62.82
Round   5, Global train loss: 0.685, Global test loss: 2.005, Global test accuracy: 25.37
Round   6, Train loss: 0.669, Test loss: 0.785, Test accuracy: 65.40
Round   6, Global train loss: 0.669, Global test loss: 2.394, Global test accuracy: 20.17
Round   7, Train loss: 0.645, Test loss: 0.786, Test accuracy: 66.03
Round   7, Global train loss: 0.645, Global test loss: 2.243, Global test accuracy: 23.60
Round   8, Train loss: 0.597, Test loss: 0.795, Test accuracy: 66.28
Round   8, Global train loss: 0.597, Global test loss: 2.170, Global test accuracy: 31.23
Round   9, Train loss: 0.720, Test loss: 0.811, Test accuracy: 66.40
Round   9, Global train loss: 0.720, Global test loss: 2.421, Global test accuracy: 20.13
Round  10, Train loss: 0.586, Test loss: 0.818, Test accuracy: 66.98
Round  10, Global train loss: 0.586, Global test loss: 2.476, Global test accuracy: 22.00
Round  11, Train loss: 0.601, Test loss: 0.684, Test accuracy: 70.33
Round  11, Global train loss: 0.601, Global test loss: 2.109, Global test accuracy: 25.73
Round  12, Train loss: 0.595, Test loss: 0.665, Test accuracy: 71.22
Round  12, Global train loss: 0.595, Global test loss: 2.071, Global test accuracy: 25.27
Round  13, Train loss: 0.603, Test loss: 0.666, Test accuracy: 71.63
Round  13, Global train loss: 0.603, Global test loss: 2.076, Global test accuracy: 29.38
Round  14, Train loss: 0.509, Test loss: 0.662, Test accuracy: 71.95
Round  14, Global train loss: 0.509, Global test loss: 2.190, Global test accuracy: 29.48
Round  15, Train loss: 0.529, Test loss: 0.658, Test accuracy: 72.63
Round  15, Global train loss: 0.529, Global test loss: 2.218, Global test accuracy: 26.33
Round  16, Train loss: 0.617, Test loss: 0.671, Test accuracy: 72.93
Round  16, Global train loss: 0.617, Global test loss: 2.030, Global test accuracy: 27.03
Round  17, Train loss: 0.606, Test loss: 0.669, Test accuracy: 73.33
Round  17, Global train loss: 0.606, Global test loss: 2.086, Global test accuracy: 29.37
Round  18, Train loss: 0.557, Test loss: 0.653, Test accuracy: 74.02
Round  18, Global train loss: 0.557, Global test loss: 2.215, Global test accuracy: 23.25
Round  19, Train loss: 0.548, Test loss: 0.643, Test accuracy: 74.15
Round  19, Global train loss: 0.548, Global test loss: 2.365, Global test accuracy: 25.98
Round  20, Train loss: 0.530, Test loss: 0.646, Test accuracy: 74.48
Round  20, Global train loss: 0.530, Global test loss: 2.122, Global test accuracy: 19.33
Round  21, Train loss: 0.532, Test loss: 0.640, Test accuracy: 74.53
Round  21, Global train loss: 0.532, Global test loss: 2.244, Global test accuracy: 24.10
Round  22, Train loss: 0.398, Test loss: 0.622, Test accuracy: 75.13
Round  22, Global train loss: 0.398, Global test loss: 2.132, Global test accuracy: 27.20
Round  23, Train loss: 0.422, Test loss: 0.630, Test accuracy: 74.98
Round  23, Global train loss: 0.422, Global test loss: 2.021, Global test accuracy: 32.57
Round  24, Train loss: 0.438, Test loss: 0.645, Test accuracy: 74.40
Round  24, Global train loss: 0.438, Global test loss: 2.250, Global test accuracy: 26.82
Round  25, Train loss: 0.424, Test loss: 0.656, Test accuracy: 74.62
Round  25, Global train loss: 0.424, Global test loss: 2.080, Global test accuracy: 29.70
Round  26, Train loss: 0.341, Test loss: 0.675, Test accuracy: 74.45
Round  26, Global train loss: 0.341, Global test loss: 2.362, Global test accuracy: 22.40
Round  27, Train loss: 0.341, Test loss: 0.662, Test accuracy: 75.00
Round  27, Global train loss: 0.341, Global test loss: 1.999, Global test accuracy: 32.53
Round  28, Train loss: 0.410, Test loss: 0.650, Test accuracy: 75.55
Round  28, Global train loss: 0.410, Global test loss: 2.180, Global test accuracy: 19.88
Round  29, Train loss: 0.413, Test loss: 0.640, Test accuracy: 75.97
Round  29, Global train loss: 0.413, Global test loss: 2.252, Global test accuracy: 24.93
Round  30, Train loss: 0.281, Test loss: 0.644, Test accuracy: 76.12
Round  30, Global train loss: 0.281, Global test loss: 2.204, Global test accuracy: 23.72
Round  31, Train loss: 0.402, Test loss: 0.641, Test accuracy: 76.00
Round  31, Global train loss: 0.402, Global test loss: 1.982, Global test accuracy: 31.83
Round  32, Train loss: 0.383, Test loss: 0.646, Test accuracy: 76.00
Round  32, Global train loss: 0.383, Global test loss: 2.026, Global test accuracy: 33.03
Round  33, Train loss: 0.369, Test loss: 0.662, Test accuracy: 75.57
Round  33, Global train loss: 0.369, Global test loss: 2.275, Global test accuracy: 24.42
Round  34, Train loss: 0.323, Test loss: 0.668, Test accuracy: 75.40
Round  34, Global train loss: 0.323, Global test loss: 1.985, Global test accuracy: 32.33
Round  35, Train loss: 0.235, Test loss: 0.676, Test accuracy: 74.98
Round  35, Global train loss: 0.235, Global test loss: 2.057, Global test accuracy: 25.23
Round  36, Train loss: 0.246, Test loss: 0.710, Test accuracy: 74.68
Round  36, Global train loss: 0.246, Global test loss: 2.293, Global test accuracy: 25.32
Round  37, Train loss: 0.234, Test loss: 0.709, Test accuracy: 75.07
Round  37, Global train loss: 0.234, Global test loss: 2.334, Global test accuracy: 22.35
Round  38, Train loss: 0.260, Test loss: 0.717, Test accuracy: 74.78
Round  38, Global train loss: 0.260, Global test loss: 2.095, Global test accuracy: 27.50
Round  39, Train loss: 0.260, Test loss: 0.721, Test accuracy: 75.03
Round  39, Global train loss: 0.260, Global test loss: 2.108, Global test accuracy: 22.82
Round  40, Train loss: 0.235, Test loss: 0.733, Test accuracy: 75.53
Round  40, Global train loss: 0.235, Global test loss: 2.262, Global test accuracy: 29.72
Round  41, Train loss: 0.254, Test loss: 0.723, Test accuracy: 75.47
Round  41, Global train loss: 0.254, Global test loss: 2.145, Global test accuracy: 27.12
Round  42, Train loss: 0.210, Test loss: 0.727, Test accuracy: 75.90
Round  42, Global train loss: 0.210, Global test loss: 2.066, Global test accuracy: 30.90
Round  43, Train loss: 0.267, Test loss: 0.732, Test accuracy: 76.68
Round  43, Global train loss: 0.267, Global test loss: 2.104, Global test accuracy: 27.70
Round  44, Train loss: 0.221, Test loss: 0.733, Test accuracy: 77.32
Round  44, Global train loss: 0.221, Global test loss: 2.300, Global test accuracy: 29.33
Round  45, Train loss: 0.259, Test loss: 0.745, Test accuracy: 77.27
Round  45, Global train loss: 0.259, Global test loss: 2.084, Global test accuracy: 25.77
Round  46, Train loss: 0.196, Test loss: 0.759, Test accuracy: 76.88
Round  46, Global train loss: 0.196, Global test loss: 2.164, Global test accuracy: 29.95
Round  47, Train loss: 0.211, Test loss: 0.766, Test accuracy: 77.08
Round  47, Global train loss: 0.211, Global test loss: 2.009, Global test accuracy: 36.13
Round  48, Train loss: 0.216, Test loss: 0.763, Test accuracy: 77.77
Round  48, Global train loss: 0.216, Global test loss: 2.438, Global test accuracy: 29.48
Round  49, Train loss: 0.253, Test loss: 0.767, Test accuracy: 77.50
Round  49, Global train loss: 0.253, Global test loss: 2.313, Global test accuracy: 24.08
Round  50, Train loss: 0.268, Test loss: 0.786, Test accuracy: 77.35
Round  50, Global train loss: 0.268, Global test loss: 2.243, Global test accuracy: 29.65
Round  51, Train loss: 0.138, Test loss: 0.799, Test accuracy: 77.33
Round  51, Global train loss: 0.138, Global test loss: 2.029, Global test accuracy: 27.75
Round  52, Train loss: 0.226, Test loss: 0.821, Test accuracy: 76.80
Round  52, Global train loss: 0.226, Global test loss: 2.070, Global test accuracy: 27.58
Round  53, Train loss: 0.224, Test loss: 0.820, Test accuracy: 76.98
Round  53, Global train loss: 0.224, Global test loss: 2.052, Global test accuracy: 27.82
Round  54, Train loss: 0.124, Test loss: 0.812, Test accuracy: 77.30
Round  54, Global train loss: 0.124, Global test loss: 1.972, Global test accuracy: 33.22
Round  55, Train loss: 0.259, Test loss: 0.831, Test accuracy: 77.23
Round  55, Global train loss: 0.259, Global test loss: 2.064, Global test accuracy: 28.80
Round  56, Train loss: 0.202, Test loss: 0.837, Test accuracy: 76.72
Round  56, Global train loss: 0.202, Global test loss: 2.178, Global test accuracy: 28.17
Round  57, Train loss: 0.150, Test loss: 0.843, Test accuracy: 76.52
Round  57, Global train loss: 0.150, Global test loss: 2.102, Global test accuracy: 30.32
Round  58, Train loss: 0.150, Test loss: 0.837, Test accuracy: 76.92
Round  58, Global train loss: 0.150, Global test loss: 2.088, Global test accuracy: 36.57
Round  59, Train loss: 0.175, Test loss: 0.851, Test accuracy: 76.98
Round  59, Global train loss: 0.175, Global test loss: 2.099, Global test accuracy: 23.30
Round  60, Train loss: 0.196, Test loss: 0.843, Test accuracy: 77.82
Round  60, Global train loss: 0.196, Global test loss: 2.102, Global test accuracy: 25.97
Round  61, Train loss: 0.116, Test loss: 0.840, Test accuracy: 77.62
Round  61, Global train loss: 0.116, Global test loss: 2.141, Global test accuracy: 29.67
Round  62, Train loss: 0.191, Test loss: 0.880, Test accuracy: 77.17
Round  62, Global train loss: 0.191, Global test loss: 2.074, Global test accuracy: 22.80
Round  63, Train loss: 0.135, Test loss: 0.901, Test accuracy: 76.57
Round  63, Global train loss: 0.135, Global test loss: 2.179, Global test accuracy: 28.38
Round  64, Train loss: 0.127, Test loss: 0.905, Test accuracy: 76.40
Round  64, Global train loss: 0.127, Global test loss: 2.113, Global test accuracy: 29.75
Round  65, Train loss: 0.194, Test loss: 0.897, Test accuracy: 77.07
Round  65, Global train loss: 0.194, Global test loss: 2.123, Global test accuracy: 25.12
Round  66, Train loss: 0.187, Test loss: 0.902, Test accuracy: 77.03
Round  66, Global train loss: 0.187, Global test loss: 2.165, Global test accuracy: 29.48
Round  67, Train loss: 0.152, Test loss: 0.875, Test accuracy: 77.13
Round  67, Global train loss: 0.152, Global test loss: 2.218, Global test accuracy: 28.87
Round  68, Train loss: 0.142, Test loss: 0.876, Test accuracy: 77.17
Round  68, Global train loss: 0.142, Global test loss: 2.094, Global test accuracy: 25.63
Round  69, Train loss: 0.148, Test loss: 0.926, Test accuracy: 76.93
Round  69, Global train loss: 0.148, Global test loss: 1.862, Global test accuracy: 35.62
Round  70, Train loss: 0.145, Test loss: 0.970, Test accuracy: 76.65
Round  70, Global train loss: 0.145, Global test loss: 2.130, Global test accuracy: 23.17
Round  71, Train loss: 0.086, Test loss: 0.997, Test accuracy: 76.62
Round  71, Global train loss: 0.086, Global test loss: 2.382, Global test accuracy: 18.47
Round  72, Train loss: 0.130, Test loss: 1.025, Test accuracy: 76.37
Round  72, Global train loss: 0.130, Global test loss: 2.237, Global test accuracy: 21.57
Round  73, Train loss: 0.096, Test loss: 1.042, Test accuracy: 76.37
Round  73, Global train loss: 0.096, Global test loss: 2.261, Global test accuracy: 26.88
Round  74, Train loss: 0.094, Test loss: 1.031, Test accuracy: 76.58
Round  74, Global train loss: 0.094, Global test loss: 2.191, Global test accuracy: 27.62
Round  75, Train loss: 0.114, Test loss: 1.003, Test accuracy: 77.13
Round  75, Global train loss: 0.114, Global test loss: 2.663, Global test accuracy: 26.22
Round  76, Train loss: 0.164, Test loss: 0.957, Test accuracy: 77.52
Round  76, Global train loss: 0.164, Global test loss: 1.953, Global test accuracy: 31.32
Round  77, Train loss: 0.109, Test loss: 1.012, Test accuracy: 77.23
Round  77, Global train loss: 0.109, Global test loss: 2.121, Global test accuracy: 31.88
Round  78, Train loss: 0.104, Test loss: 1.010, Test accuracy: 77.33
Round  78, Global train loss: 0.104, Global test loss: 2.356, Global test accuracy: 29.08
Round  79, Train loss: 0.124, Test loss: 0.969, Test accuracy: 78.22
Round  79, Global train loss: 0.124, Global test loss: 1.979, Global test accuracy: 29.37
Round  80, Train loss: 0.094, Test loss: 0.984, Test accuracy: 78.33
Round  80, Global train loss: 0.094, Global test loss: 2.785, Global test accuracy: 25.87
Round  81, Train loss: 0.081, Test loss: 1.040, Test accuracy: 77.32
Round  81, Global train loss: 0.081, Global test loss: 2.221, Global test accuracy: 26.68
Round  82, Train loss: 0.089, Test loss: 1.041, Test accuracy: 77.05
Round  82, Global train loss: 0.089, Global test loss: 2.133, Global test accuracy: 32.03
Round  83, Train loss: 0.111, Test loss: 1.050, Test accuracy: 77.23
Round  83, Global train loss: 0.111, Global test loss: 2.139, Global test accuracy: 23.67
Round  84, Train loss: 0.053, Test loss: 1.050, Test accuracy: 77.80
Round  84, Global train loss: 0.053, Global test loss: 2.234, Global test accuracy: 22.95
Round  85, Train loss: 0.103, Test loss: 1.069, Test accuracy: 77.73
Round  85, Global train loss: 0.103, Global test loss: 2.022, Global test accuracy: 25.62
Round  86, Train loss: 0.055, Test loss: 1.094, Test accuracy: 77.58
Round  86, Global train loss: 0.055, Global test loss: 2.121, Global test accuracy: 31.33
Round  87, Train loss: 0.082, Test loss: 1.095, Test accuracy: 77.27
Round  87, Global train loss: 0.082, Global test loss: 2.369, Global test accuracy: 21.87
Round  88, Train loss: 0.068, Test loss: 1.119, Test accuracy: 76.98
Round  88, Global train loss: 0.068, Global test loss: 2.056, Global test accuracy: 28.60
Round  89, Train loss: 0.064, Test loss: 1.084, Test accuracy: 78.05
Round  89, Global train loss: 0.064, Global test loss: 2.126, Global test accuracy: 32.88
Round  90, Train loss: 0.080, Test loss: 1.175, Test accuracy: 77.33
Round  90, Global train loss: 0.080, Global test loss: 1.907, Global test accuracy: 39.08
Round  91, Train loss: 0.055, Test loss: 1.193, Test accuracy: 76.97
Round  91, Global train loss: 0.055, Global test loss: 2.226, Global test accuracy: 27.45
Round  92, Train loss: 0.080, Test loss: 1.212, Test accuracy: 76.42
Round  92, Global train loss: 0.080, Global test loss: 2.387, Global test accuracy: 24.85
Round  93, Train loss: 0.041, Test loss: 1.235, Test accuracy: 76.83
Round  93, Global train loss: 0.041, Global test loss: 2.003, Global test accuracy: 30.23
Round  94, Train loss: 0.087, Test loss: 1.131, Test accuracy: 77.65
Round  94, Global train loss: 0.087, Global test loss: 2.112, Global test accuracy: 20.40
Round  95, Train loss: 0.070, Test loss: 1.159, Test accuracy: 77.27
Round  95, Global train loss: 0.070, Global test loss: 2.021, Global test accuracy: 32.85
Round  96, Train loss: 0.068, Test loss: 1.152, Test accuracy: 77.00
Round  96, Global train loss: 0.068, Global test loss: 2.478, Global test accuracy: 26.15
Round  97, Train loss: 0.063, Test loss: 1.119, Test accuracy: 77.37
Round  97, Global train loss: 0.063, Global test loss: 2.583, Global test accuracy: 26.48
Round  98, Train loss: 0.068, Test loss: 1.126, Test accuracy: 77.30
Round  98, Global train loss: 0.068, Global test loss: 1.915, Global test accuracy: 32.80
Round  99, Train loss: 0.066, Test loss: 1.130, Test accuracy: 77.53
Round  99, Global train loss: 0.066, Global test loss: 2.108, Global test accuracy: 33.08
Final Round, Train loss: 0.063, Test loss: 1.169, Test accuracy: 77.88
Final Round, Global train loss: 0.063, Global test loss: 2.108, Global test accuracy: 33.08
Average accuracy final 10 rounds: 77.16666666666666 

Average global accuracy final 10 rounds: 29.338333333333335 

951.8742218017578
[0.9209208488464355, 1.841841697692871, 2.501560926437378, 3.1612801551818848, 3.821737766265869, 4.4821953773498535, 5.143723964691162, 5.805252552032471, 6.461387872695923, 7.117523193359375, 7.778177738189697, 8.43883228302002, 9.097195148468018, 9.755558013916016, 10.41290283203125, 11.070247650146484, 11.741131067276001, 12.412014484405518, 13.081819534301758, 13.751624584197998, 14.426245212554932, 15.100865840911865, 15.775420188903809, 16.449974536895752, 17.11811089515686, 17.78624725341797, 18.456128120422363, 19.126008987426758, 19.807700872421265, 20.48939275741577, 21.1706862449646, 21.851979732513428, 22.524258136749268, 23.196536540985107, 23.866575479507446, 24.536614418029785, 25.2167866230011, 25.896958827972412, 26.565397262573242, 27.233835697174072, 27.898659706115723, 28.563483715057373, 29.233784914016724, 29.904086112976074, 30.572221279144287, 31.2403564453125, 31.901409149169922, 32.562461853027344, 33.23127722740173, 33.90009260177612, 34.5834014415741, 35.26671028137207, 35.94983243942261, 36.632954597473145, 37.30734634399414, 37.98173809051514, 38.649336099624634, 39.31693410873413, 39.98668885231018, 40.65644359588623, 41.37277793884277, 42.089112281799316, 42.75392937660217, 43.41874647140503, 44.09789180755615, 44.777037143707275, 45.44936919212341, 46.12170124053955, 46.785685777664185, 47.44967031478882, 48.1342408657074, 48.81881141662598, 49.495341062545776, 50.171870708465576, 50.844740867614746, 51.517611026763916, 52.19741368293762, 52.87721633911133, 53.550602436065674, 54.22398853302002, 54.88910531997681, 55.554222106933594, 56.2288613319397, 56.9035005569458, 57.58168625831604, 58.25987195968628, 58.930792570114136, 59.60171318054199, 60.296993255615234, 60.99227333068848, 61.66206097602844, 62.33184862136841, 63.00475072860718, 63.67765283584595, 64.35190272331238, 65.02615261077881, 65.6938157081604, 66.36147880554199, 67.03061485290527, 67.69975090026855, 68.36882185935974, 69.03789281845093, 69.71570086479187, 70.39350891113281, 71.06571769714355, 71.7379264831543, 72.42168545722961, 73.10544443130493, 73.76738572120667, 74.4293270111084, 75.10010266304016, 75.77087831497192, 76.44262075424194, 77.11436319351196, 77.78170680999756, 78.44905042648315, 79.12025046348572, 79.79145050048828, 80.45914053916931, 81.12683057785034, 81.79301881790161, 82.45920705795288, 83.13134098052979, 83.80347490310669, 84.4829568862915, 85.16243886947632, 85.83133959770203, 86.50024032592773, 87.19196105003357, 87.8836817741394, 88.55684304237366, 89.23000431060791, 89.90684080123901, 90.58367729187012, 91.2594530582428, 91.93522882461548, 92.60512447357178, 93.27502012252808, 93.94540739059448, 94.61579465866089, 95.28644251823425, 95.95709037780762, 96.64419651031494, 97.33130264282227, 98.00564765930176, 98.67999267578125, 99.35420942306519, 100.02842617034912, 100.706063747406, 101.38370132446289, 102.08312702178955, 102.78255271911621, 103.45400285720825, 104.1254529953003, 104.7968201637268, 105.46818733215332, 106.14508175849915, 106.82197618484497, 107.49175834655762, 108.16154050827026, 108.83839726448059, 109.51525402069092, 110.1820170879364, 110.84878015518188, 111.51916790008545, 112.18955564498901, 112.86048197746277, 113.53140830993652, 114.20936179161072, 114.88731527328491, 115.5691750049591, 116.2510347366333, 116.91968655586243, 117.58833837509155, 118.25699377059937, 118.92564916610718, 119.59440302848816, 120.26315689086914, 120.93129324913025, 121.59942960739136, 122.26594185829163, 122.9324541091919, 123.60196876525879, 124.27148342132568, 124.9349434375763, 125.5984034538269, 126.26516270637512, 126.93192195892334, 127.60129642486572, 128.2706708908081, 128.94547748565674, 129.62028408050537, 130.29197144508362, 130.96365880966187, 131.63884091377258, 132.3140230178833, 132.97541522979736, 133.63680744171143, 134.3136386871338, 134.99046993255615, 136.33514595031738, 137.6798219680786]
[29.016666666666666, 29.016666666666666, 42.61666666666667, 42.61666666666667, 50.21666666666667, 50.21666666666667, 57.85, 57.85, 61.11666666666667, 61.11666666666667, 62.81666666666667, 62.81666666666667, 65.4, 65.4, 66.03333333333333, 66.03333333333333, 66.28333333333333, 66.28333333333333, 66.4, 66.4, 66.98333333333333, 66.98333333333333, 70.33333333333333, 70.33333333333333, 71.21666666666667, 71.21666666666667, 71.63333333333334, 71.63333333333334, 71.95, 71.95, 72.63333333333334, 72.63333333333334, 72.93333333333334, 72.93333333333334, 73.33333333333333, 73.33333333333333, 74.01666666666667, 74.01666666666667, 74.15, 74.15, 74.48333333333333, 74.48333333333333, 74.53333333333333, 74.53333333333333, 75.13333333333334, 75.13333333333334, 74.98333333333333, 74.98333333333333, 74.4, 74.4, 74.61666666666666, 74.61666666666666, 74.45, 74.45, 75.0, 75.0, 75.55, 75.55, 75.96666666666667, 75.96666666666667, 76.11666666666666, 76.11666666666666, 76.0, 76.0, 76.0, 76.0, 75.56666666666666, 75.56666666666666, 75.4, 75.4, 74.98333333333333, 74.98333333333333, 74.68333333333334, 74.68333333333334, 75.06666666666666, 75.06666666666666, 74.78333333333333, 74.78333333333333, 75.03333333333333, 75.03333333333333, 75.53333333333333, 75.53333333333333, 75.46666666666667, 75.46666666666667, 75.9, 75.9, 76.68333333333334, 76.68333333333334, 77.31666666666666, 77.31666666666666, 77.26666666666667, 77.26666666666667, 76.88333333333334, 76.88333333333334, 77.08333333333333, 77.08333333333333, 77.76666666666667, 77.76666666666667, 77.5, 77.5, 77.35, 77.35, 77.33333333333333, 77.33333333333333, 76.8, 76.8, 76.98333333333333, 76.98333333333333, 77.3, 77.3, 77.23333333333333, 77.23333333333333, 76.71666666666667, 76.71666666666667, 76.51666666666667, 76.51666666666667, 76.91666666666667, 76.91666666666667, 76.98333333333333, 76.98333333333333, 77.81666666666666, 77.81666666666666, 77.61666666666666, 77.61666666666666, 77.16666666666667, 77.16666666666667, 76.56666666666666, 76.56666666666666, 76.4, 76.4, 77.06666666666666, 77.06666666666666, 77.03333333333333, 77.03333333333333, 77.13333333333334, 77.13333333333334, 77.16666666666667, 77.16666666666667, 76.93333333333334, 76.93333333333334, 76.65, 76.65, 76.61666666666666, 76.61666666666666, 76.36666666666666, 76.36666666666666, 76.36666666666666, 76.36666666666666, 76.58333333333333, 76.58333333333333, 77.13333333333334, 77.13333333333334, 77.51666666666667, 77.51666666666667, 77.23333333333333, 77.23333333333333, 77.33333333333333, 77.33333333333333, 78.21666666666667, 78.21666666666667, 78.33333333333333, 78.33333333333333, 77.31666666666666, 77.31666666666666, 77.05, 77.05, 77.23333333333333, 77.23333333333333, 77.8, 77.8, 77.73333333333333, 77.73333333333333, 77.58333333333333, 77.58333333333333, 77.26666666666667, 77.26666666666667, 76.98333333333333, 76.98333333333333, 78.05, 78.05, 77.33333333333333, 77.33333333333333, 76.96666666666667, 76.96666666666667, 76.41666666666667, 76.41666666666667, 76.83333333333333, 76.83333333333333, 77.65, 77.65, 77.26666666666667, 77.26666666666667, 77.0, 77.0, 77.36666666666666, 77.36666666666666, 77.3, 77.3, 77.53333333333333, 77.53333333333333, 77.88333333333334, 77.88333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.171, Test loss: 1.887, Test accuracy: 31.05
Round   0, Global train loss: 1.171, Global test loss: 2.208, Global test accuracy: 24.23
Round   1, Train loss: 0.962, Test loss: 1.700, Test accuracy: 38.40
Round   1, Global train loss: 0.962, Global test loss: 2.364, Global test accuracy: 24.77
Round   2, Train loss: 0.914, Test loss: 1.134, Test accuracy: 52.42
Round   2, Global train loss: 0.914, Global test loss: 2.015, Global test accuracy: 25.43
Round   3, Train loss: 0.874, Test loss: 1.125, Test accuracy: 53.25
Round   3, Global train loss: 0.874, Global test loss: 2.026, Global test accuracy: 27.13
Round   4, Train loss: 0.788, Test loss: 1.089, Test accuracy: 57.32
Round   4, Global train loss: 0.788, Global test loss: 2.171, Global test accuracy: 27.52
Round   5, Train loss: 0.783, Test loss: 1.071, Test accuracy: 55.67
Round   5, Global train loss: 0.783, Global test loss: 2.065, Global test accuracy: 28.55
Round   6, Train loss: 0.803, Test loss: 0.856, Test accuracy: 65.98
Round   6, Global train loss: 0.803, Global test loss: 2.047, Global test accuracy: 28.37
Round   7, Train loss: 0.712, Test loss: 0.761, Test accuracy: 67.20
Round   7, Global train loss: 0.712, Global test loss: 1.898, Global test accuracy: 35.37
Round   8, Train loss: 0.651, Test loss: 0.744, Test accuracy: 68.25
Round   8, Global train loss: 0.651, Global test loss: 1.699, Global test accuracy: 39.17
Round   9, Train loss: 0.776, Test loss: 0.680, Test accuracy: 71.63
Round   9, Global train loss: 0.776, Global test loss: 1.754, Global test accuracy: 34.23
Round  10, Train loss: 0.729, Test loss: 0.681, Test accuracy: 71.73
Round  10, Global train loss: 0.729, Global test loss: 2.132, Global test accuracy: 33.82
Round  11, Train loss: 0.676, Test loss: 0.681, Test accuracy: 71.63
Round  11, Global train loss: 0.676, Global test loss: 1.909, Global test accuracy: 31.28
Round  12, Train loss: 0.730, Test loss: 0.643, Test accuracy: 72.98
Round  12, Global train loss: 0.730, Global test loss: 1.838, Global test accuracy: 39.70
Round  13, Train loss: 0.680, Test loss: 0.623, Test accuracy: 73.80
Round  13, Global train loss: 0.680, Global test loss: 1.888, Global test accuracy: 38.32
Round  14, Train loss: 0.708, Test loss: 0.613, Test accuracy: 74.90
Round  14, Global train loss: 0.708, Global test loss: 1.834, Global test accuracy: 39.82
Round  15, Train loss: 0.650, Test loss: 0.621, Test accuracy: 74.43
Round  15, Global train loss: 0.650, Global test loss: 1.692, Global test accuracy: 37.77
Round  16, Train loss: 0.616, Test loss: 0.624, Test accuracy: 74.45
Round  16, Global train loss: 0.616, Global test loss: 1.850, Global test accuracy: 35.30
Round  17, Train loss: 0.643, Test loss: 0.637, Test accuracy: 73.83
Round  17, Global train loss: 0.643, Global test loss: 1.702, Global test accuracy: 37.73
Round  18, Train loss: 0.562, Test loss: 0.624, Test accuracy: 74.63
Round  18, Global train loss: 0.562, Global test loss: 1.753, Global test accuracy: 41.07
Round  19, Train loss: 0.612, Test loss: 0.614, Test accuracy: 75.17
Round  19, Global train loss: 0.612, Global test loss: 1.695, Global test accuracy: 39.02
Round  20, Train loss: 0.623, Test loss: 0.605, Test accuracy: 75.57
Round  20, Global train loss: 0.623, Global test loss: 1.592, Global test accuracy: 43.28
Round  21, Train loss: 0.556, Test loss: 0.595, Test accuracy: 75.50
Round  21, Global train loss: 0.556, Global test loss: 1.628, Global test accuracy: 45.53
Round  22, Train loss: 0.627, Test loss: 0.596, Test accuracy: 75.43
Round  22, Global train loss: 0.627, Global test loss: 1.586, Global test accuracy: 44.27
Round  23, Train loss: 0.570, Test loss: 0.606, Test accuracy: 75.18
Round  23, Global train loss: 0.570, Global test loss: 1.473, Global test accuracy: 48.77
Round  24, Train loss: 0.575, Test loss: 0.592, Test accuracy: 76.10
Round  24, Global train loss: 0.575, Global test loss: 1.765, Global test accuracy: 41.98
Round  25, Train loss: 0.580, Test loss: 0.601, Test accuracy: 76.38
Round  25, Global train loss: 0.580, Global test loss: 1.449, Global test accuracy: 48.42
Round  26, Train loss: 0.574, Test loss: 0.611, Test accuracy: 76.15
Round  26, Global train loss: 0.574, Global test loss: 1.564, Global test accuracy: 43.28
Round  27, Train loss: 0.574, Test loss: 0.614, Test accuracy: 75.92
Round  27, Global train loss: 0.574, Global test loss: 1.743, Global test accuracy: 44.77
Round  28, Train loss: 0.548, Test loss: 0.607, Test accuracy: 76.30
Round  28, Global train loss: 0.548, Global test loss: 1.933, Global test accuracy: 35.08
Round  29, Train loss: 0.532, Test loss: 0.572, Test accuracy: 77.50
Round  29, Global train loss: 0.532, Global test loss: 1.602, Global test accuracy: 44.45
Round  30, Train loss: 0.551, Test loss: 0.570, Test accuracy: 77.48
Round  30, Global train loss: 0.551, Global test loss: 1.535, Global test accuracy: 45.42
Round  31, Train loss: 0.489, Test loss: 0.551, Test accuracy: 78.32
Round  31, Global train loss: 0.489, Global test loss: 1.563, Global test accuracy: 46.67
Round  32, Train loss: 0.493, Test loss: 0.552, Test accuracy: 78.68
Round  32, Global train loss: 0.493, Global test loss: 1.578, Global test accuracy: 47.63
Round  33, Train loss: 0.478, Test loss: 0.554, Test accuracy: 78.67
Round  33, Global train loss: 0.478, Global test loss: 1.498, Global test accuracy: 48.58
Round  34, Train loss: 0.531, Test loss: 0.552, Test accuracy: 78.70
Round  34, Global train loss: 0.531, Global test loss: 1.594, Global test accuracy: 48.78
Round  35, Train loss: 0.493, Test loss: 0.544, Test accuracy: 79.05
Round  35, Global train loss: 0.493, Global test loss: 1.792, Global test accuracy: 42.78
Round  36, Train loss: 0.428, Test loss: 0.534, Test accuracy: 79.22
Round  36, Global train loss: 0.428, Global test loss: 1.445, Global test accuracy: 51.22
Round  37, Train loss: 0.462, Test loss: 0.575, Test accuracy: 78.68
Round  37, Global train loss: 0.462, Global test loss: 1.678, Global test accuracy: 44.37
Round  38, Train loss: 0.488, Test loss: 0.575, Test accuracy: 78.43
Round  38, Global train loss: 0.488, Global test loss: 1.610, Global test accuracy: 45.32
Round  39, Train loss: 0.448, Test loss: 0.523, Test accuracy: 79.57
Round  39, Global train loss: 0.448, Global test loss: 1.382, Global test accuracy: 50.45
Round  40, Train loss: 0.480, Test loss: 0.531, Test accuracy: 79.62
Round  40, Global train loss: 0.480, Global test loss: 1.530, Global test accuracy: 48.95
Round  41, Train loss: 0.440, Test loss: 0.525, Test accuracy: 79.97
Round  41, Global train loss: 0.440, Global test loss: 1.567, Global test accuracy: 47.18
Round  42, Train loss: 0.399, Test loss: 0.532, Test accuracy: 79.77
Round  42, Global train loss: 0.399, Global test loss: 1.399, Global test accuracy: 52.47
Round  43, Train loss: 0.465, Test loss: 0.528, Test accuracy: 79.80
Round  43, Global train loss: 0.465, Global test loss: 1.595, Global test accuracy: 47.52
Round  44, Train loss: 0.449, Test loss: 0.525, Test accuracy: 79.63
Round  44, Global train loss: 0.449, Global test loss: 1.469, Global test accuracy: 48.93
Round  45, Train loss: 0.368, Test loss: 0.517, Test accuracy: 80.15
Round  45, Global train loss: 0.368, Global test loss: 1.478, Global test accuracy: 49.88
Round  46, Train loss: 0.428, Test loss: 0.520, Test accuracy: 79.77
Round  46, Global train loss: 0.428, Global test loss: 1.571, Global test accuracy: 48.50
Round  47, Train loss: 0.426, Test loss: 0.514, Test accuracy: 80.35
Round  47, Global train loss: 0.426, Global test loss: 1.400, Global test accuracy: 51.27
Round  48, Train loss: 0.448, Test loss: 0.537, Test accuracy: 79.93
Round  48, Global train loss: 0.448, Global test loss: 1.478, Global test accuracy: 50.08
Round  49, Train loss: 0.433, Test loss: 0.533, Test accuracy: 80.25
Round  49, Global train loss: 0.433, Global test loss: 1.534, Global test accuracy: 48.03
Round  50, Train loss: 0.347, Test loss: 0.543, Test accuracy: 80.10
Round  50, Global train loss: 0.347, Global test loss: 1.338, Global test accuracy: 54.73
Round  51, Train loss: 0.418, Test loss: 0.537, Test accuracy: 80.20
Round  51, Global train loss: 0.418, Global test loss: 1.466, Global test accuracy: 50.63
Round  52, Train loss: 0.350, Test loss: 0.531, Test accuracy: 80.43
Round  52, Global train loss: 0.350, Global test loss: 1.414, Global test accuracy: 52.18
Round  53, Train loss: 0.349, Test loss: 0.536, Test accuracy: 80.40
Round  53, Global train loss: 0.349, Global test loss: 1.580, Global test accuracy: 48.20
Round  54, Train loss: 0.331, Test loss: 0.548, Test accuracy: 80.17
Round  54, Global train loss: 0.331, Global test loss: 1.556, Global test accuracy: 53.60
Round  55, Train loss: 0.325, Test loss: 0.545, Test accuracy: 80.33
Round  55, Global train loss: 0.325, Global test loss: 1.299, Global test accuracy: 56.70
Round  56, Train loss: 0.333, Test loss: 0.518, Test accuracy: 81.25
Round  56, Global train loss: 0.333, Global test loss: 1.557, Global test accuracy: 49.68
Round  57, Train loss: 0.326, Test loss: 0.531, Test accuracy: 80.72
Round  57, Global train loss: 0.326, Global test loss: 1.441, Global test accuracy: 53.43
Round  58, Train loss: 0.349, Test loss: 0.558, Test accuracy: 80.22
Round  58, Global train loss: 0.349, Global test loss: 1.682, Global test accuracy: 50.28
Round  59, Train loss: 0.337, Test loss: 0.539, Test accuracy: 80.28
Round  59, Global train loss: 0.337, Global test loss: 1.532, Global test accuracy: 51.38
Round  60, Train loss: 0.301, Test loss: 0.535, Test accuracy: 80.67
Round  60, Global train loss: 0.301, Global test loss: 1.915, Global test accuracy: 46.20
Round  61, Train loss: 0.377, Test loss: 0.540, Test accuracy: 80.97
Round  61, Global train loss: 0.377, Global test loss: 1.382, Global test accuracy: 52.90
Round  62, Train loss: 0.383, Test loss: 0.532, Test accuracy: 81.62
Round  62, Global train loss: 0.383, Global test loss: 1.382, Global test accuracy: 54.13
Round  63, Train loss: 0.323, Test loss: 0.536, Test accuracy: 81.52
Round  63, Global train loss: 0.323, Global test loss: 1.373, Global test accuracy: 57.57
Round  64, Train loss: 0.284, Test loss: 0.535, Test accuracy: 81.68
Round  64, Global train loss: 0.284, Global test loss: 1.403, Global test accuracy: 55.80
Round  65, Train loss: 0.291, Test loss: 0.548, Test accuracy: 81.37
Round  65, Global train loss: 0.291, Global test loss: 1.455, Global test accuracy: 55.17
Round  66, Train loss: 0.278, Test loss: 0.539, Test accuracy: 81.25
Round  66, Global train loss: 0.278, Global test loss: 1.474, Global test accuracy: 55.53
Round  67, Train loss: 0.290, Test loss: 0.559, Test accuracy: 81.07
Round  67, Global train loss: 0.290, Global test loss: 1.264, Global test accuracy: 58.60
Round  68, Train loss: 0.366, Test loss: 0.568, Test accuracy: 81.08
Round  68, Global train loss: 0.366, Global test loss: 1.536, Global test accuracy: 51.30
Round  69, Train loss: 0.331, Test loss: 0.545, Test accuracy: 81.70
Round  69, Global train loss: 0.331, Global test loss: 1.347, Global test accuracy: 57.13
Round  70, Train loss: 0.323, Test loss: 0.530, Test accuracy: 82.15
Round  70, Global train loss: 0.323, Global test loss: 1.448, Global test accuracy: 52.60
Round  71, Train loss: 0.269, Test loss: 0.547, Test accuracy: 81.77
Round  71, Global train loss: 0.269, Global test loss: 1.351, Global test accuracy: 56.33
Round  72, Train loss: 0.317, Test loss: 0.544, Test accuracy: 82.32
Round  72, Global train loss: 0.317, Global test loss: 1.456, Global test accuracy: 54.52
Round  73, Train loss: 0.272, Test loss: 0.547, Test accuracy: 81.85
Round  73, Global train loss: 0.272, Global test loss: 1.382, Global test accuracy: 56.38
Round  74, Train loss: 0.313, Test loss: 0.541, Test accuracy: 82.05
Round  74, Global train loss: 0.313, Global test loss: 1.481, Global test accuracy: 53.20
Round  75, Train loss: 0.350, Test loss: 0.533, Test accuracy: 81.87
Round  75, Global train loss: 0.350, Global test loss: 1.418, Global test accuracy: 52.90
Round  76, Train loss: 0.268, Test loss: 0.576, Test accuracy: 81.32
Round  76, Global train loss: 0.268, Global test loss: 1.578, Global test accuracy: 51.97
Round  77, Train loss: 0.302, Test loss: 0.576, Test accuracy: 81.28
Round  77, Global train loss: 0.302, Global test loss: 1.373, Global test accuracy: 56.73
Round  78, Train loss: 0.305, Test loss: 0.570, Test accuracy: 81.15
Round  78, Global train loss: 0.305, Global test loss: 1.510, Global test accuracy: 53.57
Round  79, Train loss: 0.291, Test loss: 0.549, Test accuracy: 81.70
Round  79, Global train loss: 0.291, Global test loss: 1.361, Global test accuracy: 54.97
Round  80, Train loss: 0.255, Test loss: 0.553, Test accuracy: 81.92
Round  80, Global train loss: 0.255, Global test loss: 1.459, Global test accuracy: 54.38
Round  81, Train loss: 0.297, Test loss: 0.543, Test accuracy: 82.25
Round  81, Global train loss: 0.297, Global test loss: 1.593, Global test accuracy: 50.15
Round  82, Train loss: 0.294, Test loss: 0.569, Test accuracy: 81.68
Round  82, Global train loss: 0.294, Global test loss: 1.316, Global test accuracy: 54.83
Round  83, Train loss: 0.318, Test loss: 0.566, Test accuracy: 82.00
Round  83, Global train loss: 0.318, Global test loss: 1.239, Global test accuracy: 57.53
Round  84, Train loss: 0.260, Test loss: 0.561, Test accuracy: 81.93
Round  84, Global train loss: 0.260, Global test loss: 1.341, Global test accuracy: 56.07
Round  85, Train loss: 0.277, Test loss: 0.573, Test accuracy: 81.97
Round  85, Global train loss: 0.277, Global test loss: 1.463, Global test accuracy: 53.98
Round  86, Train loss: 0.293, Test loss: 0.575, Test accuracy: 81.62
Round  86, Global train loss: 0.293, Global test loss: 1.407, Global test accuracy: 55.12
Round  87, Train loss: 0.216, Test loss: 0.579, Test accuracy: 81.67
Round  87, Global train loss: 0.216, Global test loss: 1.335, Global test accuracy: 59.37
Round  88, Train loss: 0.213, Test loss: 0.597, Test accuracy: 81.53
Round  88, Global train loss: 0.213, Global test loss: 1.457, Global test accuracy: 55.93
Round  89, Train loss: 0.226, Test loss: 0.588, Test accuracy: 81.72
Round  89, Global train loss: 0.226, Global test loss: 1.462, Global test accuracy: 55.25
Round  90, Train loss: 0.246, Test loss: 0.584, Test accuracy: 81.75
Round  90, Global train loss: 0.246, Global test loss: 1.598, Global test accuracy: 55.90
Round  91, Train loss: 0.253, Test loss: 0.591, Test accuracy: 81.52
Round  91, Global train loss: 0.253, Global test loss: 1.644, Global test accuracy: 54.12
Round  92, Train loss: 0.242, Test loss: 0.601, Test accuracy: 81.35
Round  92, Global train loss: 0.242, Global test loss: 1.484, Global test accuracy: 55.22
Round  93, Train loss: 0.248, Test loss: 0.580, Test accuracy: 81.95
Round  93, Global train loss: 0.248, Global test loss: 1.618, Global test accuracy: 52.85
Round  94, Train loss: 0.242, Test loss: 0.563, Test accuracy: 82.12
Round  94, Global train loss: 0.242, Global test loss: 1.445, Global test accuracy: 55.50
Round  95, Train loss: 0.252, Test loss: 0.553, Test accuracy: 82.52
Round  95, Global train loss: 0.252, Global test loss: 1.438, Global test accuracy: 55.87
Round  96, Train loss: 0.223, Test loss: 0.558, Test accuracy: 82.97
Round  96, Global train loss: 0.223, Global test loss: 1.509, Global test accuracy: 55.23
Round  97, Train loss: 0.239, Test loss: 0.584, Test accuracy: 82.42
Round  97, Global train loss: 0.239, Global test loss: 1.302, Global test accuracy: 58.52
Round  98, Train loss: 0.239, Test loss: 0.580, Test accuracy: 82.75
Round  98, Global train loss: 0.239, Global test loss: 1.571, Global test accuracy: 53.25
Round  99, Train loss: 0.223, Test loss: 0.578, Test accuracy: 82.85
Round  99, Global train loss: 0.223, Global test loss: 1.400, Global test accuracy: 58.15
Final Round, Train loss: 0.183, Test loss: 0.618, Test accuracy: 82.80
Final Round, Global train loss: 0.183, Global test loss: 1.400, Global test accuracy: 58.15
Average accuracy final 10 rounds: 82.21833333333333 

Average global accuracy final 10 rounds: 55.46 

947.0331764221191
[0.9582018852233887, 1.9164037704467773, 2.655416488647461, 3.3944292068481445, 4.099677801132202, 4.80492639541626, 5.558473110198975, 6.3120198249816895, 7.00096869468689, 7.68991756439209, 8.349701166152954, 9.009484767913818, 9.678853988647461, 10.348223209381104, 11.009860277175903, 11.671497344970703, 12.3290536403656, 12.986609935760498, 13.657036304473877, 14.327462673187256, 14.987154722213745, 15.646846771240234, 16.319148302078247, 16.99144983291626, 17.66080617904663, 18.330162525177002, 18.994053602218628, 19.657944679260254, 20.317763090133667, 20.97758150100708, 21.637364149093628, 22.297146797180176, 22.959840297698975, 23.622533798217773, 24.284746646881104, 24.946959495544434, 25.614242792129517, 26.2815260887146, 26.939812183380127, 27.598098278045654, 28.256153345108032, 28.91420841217041, 29.57696294784546, 30.239717483520508, 30.90281391143799, 31.56591033935547, 32.22912621498108, 32.89234209060669, 33.552334785461426, 34.21232748031616, 34.872299671173096, 35.53227186203003, 36.195799350738525, 36.85932683944702, 37.518335819244385, 38.17734479904175, 38.843172550201416, 39.509000301361084, 40.16784071922302, 40.82668113708496, 41.491897106170654, 42.15711307525635, 42.81652903556824, 43.47594499588013, 44.13553762435913, 44.795130252838135, 45.47685480117798, 46.15857934951782, 46.82500886917114, 47.49143838882446, 48.1608202457428, 48.83020210266113, 49.50363779067993, 50.17707347869873, 50.84578466415405, 51.514495849609375, 52.181923389434814, 52.849350929260254, 53.51202750205994, 54.17470407485962, 54.84968042373657, 55.524656772613525, 56.20027303695679, 56.87588930130005, 57.541786432266235, 58.20768356323242, 58.87949466705322, 59.55130577087402, 60.21982288360596, 60.88833999633789, 61.55139350891113, 62.214447021484375, 62.88449263572693, 63.55453824996948, 64.22188353538513, 64.88922882080078, 65.54843735694885, 66.20764589309692, 66.88225483894348, 67.55686378479004, 68.2225570678711, 68.88825035095215, 69.5592679977417, 70.23028564453125, 70.89121150970459, 71.55213737487793, 72.21718955039978, 72.88224172592163, 73.55368638038635, 74.22513103485107, 74.8833167552948, 75.54150247573853, 76.20509457588196, 76.86868667602539, 77.54234862327576, 78.21601057052612, 78.88032913208008, 79.54464769363403, 80.21340847015381, 80.88216924667358, 81.5547981262207, 82.22742700576782, 82.89712858200073, 83.56683015823364, 84.23488664627075, 84.90294313430786, 85.57233476638794, 86.24172639846802, 86.90326714515686, 87.5648078918457, 88.2280764579773, 88.89134502410889, 89.55381727218628, 90.21628952026367, 90.87620091438293, 91.5361123085022, 92.20225834846497, 92.86840438842773, 93.52572822570801, 94.18305206298828, 94.85717272758484, 95.5312933921814, 96.24062895774841, 96.94996452331543, 97.61758732795715, 98.28521013259888, 98.9462559223175, 99.60730171203613, 100.2942841053009, 100.98126649856567, 101.64678287506104, 102.3122992515564, 102.98548483848572, 103.65867042541504, 104.3255136013031, 104.99235677719116, 105.67349791526794, 106.35463905334473, 107.01894521713257, 107.68325138092041, 108.34574294090271, 109.00823450088501, 109.67839002609253, 110.34854555130005, 111.01208901405334, 111.67563247680664, 112.34740686416626, 113.01918125152588, 113.68369197845459, 114.3482027053833, 115.01035380363464, 115.67250490188599, 116.33301115036011, 116.99351739883423, 117.66098523139954, 118.32845306396484, 118.99736833572388, 119.66628360748291, 120.33516216278076, 121.00404071807861, 121.67071986198425, 122.33739900588989, 123.00627851486206, 123.67515802383423, 124.34198594093323, 125.00881385803223, 125.70080900192261, 126.39280414581299, 127.05649495124817, 127.72018575668335, 128.4098379611969, 129.09949016571045, 129.78144097328186, 130.46339178085327, 131.14972519874573, 131.83605861663818, 132.52627038955688, 133.2164821624756, 133.9069082736969, 134.5973343849182, 136.02000212669373, 137.44266986846924]
[31.05, 31.05, 38.4, 38.4, 52.416666666666664, 52.416666666666664, 53.25, 53.25, 57.31666666666667, 57.31666666666667, 55.666666666666664, 55.666666666666664, 65.98333333333333, 65.98333333333333, 67.2, 67.2, 68.25, 68.25, 71.63333333333334, 71.63333333333334, 71.73333333333333, 71.73333333333333, 71.63333333333334, 71.63333333333334, 72.98333333333333, 72.98333333333333, 73.8, 73.8, 74.9, 74.9, 74.43333333333334, 74.43333333333334, 74.45, 74.45, 73.83333333333333, 73.83333333333333, 74.63333333333334, 74.63333333333334, 75.16666666666667, 75.16666666666667, 75.56666666666666, 75.56666666666666, 75.5, 75.5, 75.43333333333334, 75.43333333333334, 75.18333333333334, 75.18333333333334, 76.1, 76.1, 76.38333333333334, 76.38333333333334, 76.15, 76.15, 75.91666666666667, 75.91666666666667, 76.3, 76.3, 77.5, 77.5, 77.48333333333333, 77.48333333333333, 78.31666666666666, 78.31666666666666, 78.68333333333334, 78.68333333333334, 78.66666666666667, 78.66666666666667, 78.7, 78.7, 79.05, 79.05, 79.21666666666667, 79.21666666666667, 78.68333333333334, 78.68333333333334, 78.43333333333334, 78.43333333333334, 79.56666666666666, 79.56666666666666, 79.61666666666666, 79.61666666666666, 79.96666666666667, 79.96666666666667, 79.76666666666667, 79.76666666666667, 79.8, 79.8, 79.63333333333334, 79.63333333333334, 80.15, 80.15, 79.76666666666667, 79.76666666666667, 80.35, 80.35, 79.93333333333334, 79.93333333333334, 80.25, 80.25, 80.1, 80.1, 80.2, 80.2, 80.43333333333334, 80.43333333333334, 80.4, 80.4, 80.16666666666667, 80.16666666666667, 80.33333333333333, 80.33333333333333, 81.25, 81.25, 80.71666666666667, 80.71666666666667, 80.21666666666667, 80.21666666666667, 80.28333333333333, 80.28333333333333, 80.66666666666667, 80.66666666666667, 80.96666666666667, 80.96666666666667, 81.61666666666666, 81.61666666666666, 81.51666666666667, 81.51666666666667, 81.68333333333334, 81.68333333333334, 81.36666666666666, 81.36666666666666, 81.25, 81.25, 81.06666666666666, 81.06666666666666, 81.08333333333333, 81.08333333333333, 81.7, 81.7, 82.15, 82.15, 81.76666666666667, 81.76666666666667, 82.31666666666666, 82.31666666666666, 81.85, 81.85, 82.05, 82.05, 81.86666666666666, 81.86666666666666, 81.31666666666666, 81.31666666666666, 81.28333333333333, 81.28333333333333, 81.15, 81.15, 81.7, 81.7, 81.91666666666667, 81.91666666666667, 82.25, 82.25, 81.68333333333334, 81.68333333333334, 82.0, 82.0, 81.93333333333334, 81.93333333333334, 81.96666666666667, 81.96666666666667, 81.61666666666666, 81.61666666666666, 81.66666666666667, 81.66666666666667, 81.53333333333333, 81.53333333333333, 81.71666666666667, 81.71666666666667, 81.75, 81.75, 81.51666666666667, 81.51666666666667, 81.35, 81.35, 81.95, 81.95, 82.11666666666666, 82.11666666666666, 82.51666666666667, 82.51666666666667, 82.96666666666667, 82.96666666666667, 82.41666666666667, 82.41666666666667, 82.75, 82.75, 82.85, 82.85, 82.8, 82.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.161, Test loss: 1.890, Test accuracy: 28.05
Round   0, Global train loss: 1.161, Global test loss: 2.223, Global test accuracy: 18.48
Round   1, Train loss: 1.002, Test loss: 1.859, Test accuracy: 37.03
Round   1, Global train loss: 1.002, Global test loss: 2.527, Global test accuracy: 24.62
Round   2, Train loss: 0.936, Test loss: 1.848, Test accuracy: 38.18
Round   2, Global train loss: 0.936, Global test loss: 2.638, Global test accuracy: 22.43
Round   3, Train loss: 0.863, Test loss: 1.235, Test accuracy: 50.15
Round   3, Global train loss: 0.863, Global test loss: 2.141, Global test accuracy: 30.00
Round   4, Train loss: 0.868, Test loss: 1.105, Test accuracy: 52.93
Round   4, Global train loss: 0.868, Global test loss: 1.996, Global test accuracy: 26.48
Round   5, Train loss: 0.778, Test loss: 0.913, Test accuracy: 61.13
Round   5, Global train loss: 0.778, Global test loss: 2.266, Global test accuracy: 26.27
Round   6, Train loss: 0.738, Test loss: 0.757, Test accuracy: 66.55
Round   6, Global train loss: 0.738, Global test loss: 2.022, Global test accuracy: 33.60
Round   7, Train loss: 0.740, Test loss: 0.718, Test accuracy: 68.75
Round   7, Global train loss: 0.740, Global test loss: 2.161, Global test accuracy: 33.37
Round   8, Train loss: 0.704, Test loss: 0.707, Test accuracy: 69.55
Round   8, Global train loss: 0.704, Global test loss: 1.930, Global test accuracy: 35.17
Round   9, Train loss: 0.728, Test loss: 0.719, Test accuracy: 68.92
Round   9, Global train loss: 0.728, Global test loss: 2.187, Global test accuracy: 29.43
Round  10, Train loss: 0.667, Test loss: 0.714, Test accuracy: 68.95
Round  10, Global train loss: 0.667, Global test loss: 1.804, Global test accuracy: 38.18
Round  11, Train loss: 0.696, Test loss: 0.717, Test accuracy: 69.72
Round  11, Global train loss: 0.696, Global test loss: 1.726, Global test accuracy: 40.40
Round  12, Train loss: 0.645, Test loss: 0.693, Test accuracy: 71.02
Round  12, Global train loss: 0.645, Global test loss: 1.950, Global test accuracy: 36.08
Round  13, Train loss: 0.657, Test loss: 0.645, Test accuracy: 73.60
Round  13, Global train loss: 0.657, Global test loss: 1.635, Global test accuracy: 43.63
Round  14, Train loss: 0.615, Test loss: 0.662, Test accuracy: 72.63
Round  14, Global train loss: 0.615, Global test loss: 1.659, Global test accuracy: 43.28
Round  15, Train loss: 0.642, Test loss: 0.657, Test accuracy: 72.75
Round  15, Global train loss: 0.642, Global test loss: 1.782, Global test accuracy: 39.05
Round  16, Train loss: 0.629, Test loss: 0.642, Test accuracy: 73.50
Round  16, Global train loss: 0.629, Global test loss: 1.607, Global test accuracy: 45.18
Round  17, Train loss: 0.567, Test loss: 0.637, Test accuracy: 73.62
Round  17, Global train loss: 0.567, Global test loss: 1.950, Global test accuracy: 34.68
Round  18, Train loss: 0.670, Test loss: 0.631, Test accuracy: 73.95
Round  18, Global train loss: 0.670, Global test loss: 1.797, Global test accuracy: 39.58
Round  19, Train loss: 0.643, Test loss: 0.610, Test accuracy: 74.98
Round  19, Global train loss: 0.643, Global test loss: 1.541, Global test accuracy: 45.82
Round  20, Train loss: 0.555, Test loss: 0.592, Test accuracy: 75.80
Round  20, Global train loss: 0.555, Global test loss: 1.663, Global test accuracy: 45.00
Round  21, Train loss: 0.541, Test loss: 0.583, Test accuracy: 76.32
Round  21, Global train loss: 0.541, Global test loss: 1.564, Global test accuracy: 44.98
Round  22, Train loss: 0.528, Test loss: 0.589, Test accuracy: 76.20
Round  22, Global train loss: 0.528, Global test loss: 1.931, Global test accuracy: 38.72
Round  23, Train loss: 0.542, Test loss: 0.586, Test accuracy: 76.18
Round  23, Global train loss: 0.542, Global test loss: 1.498, Global test accuracy: 48.12
Round  24, Train loss: 0.585, Test loss: 0.605, Test accuracy: 75.40
Round  24, Global train loss: 0.585, Global test loss: 1.585, Global test accuracy: 42.67
Round  25, Train loss: 0.539, Test loss: 0.598, Test accuracy: 75.35
Round  25, Global train loss: 0.539, Global test loss: 2.019, Global test accuracy: 37.63
Round  26, Train loss: 0.604, Test loss: 0.598, Test accuracy: 75.88
Round  26, Global train loss: 0.604, Global test loss: 1.613, Global test accuracy: 41.97
Round  27, Train loss: 0.532, Test loss: 0.614, Test accuracy: 75.45
Round  27, Global train loss: 0.532, Global test loss: 1.665, Global test accuracy: 45.55
Round  28, Train loss: 0.537, Test loss: 0.583, Test accuracy: 76.33
Round  28, Global train loss: 0.537, Global test loss: 1.967, Global test accuracy: 38.10
Round  29, Train loss: 0.498, Test loss: 0.566, Test accuracy: 77.05
Round  29, Global train loss: 0.498, Global test loss: 1.606, Global test accuracy: 49.85
Round  30, Train loss: 0.588, Test loss: 0.552, Test accuracy: 77.35
Round  30, Global train loss: 0.588, Global test loss: 1.812, Global test accuracy: 41.27
Round  31, Train loss: 0.494, Test loss: 0.545, Test accuracy: 77.33
Round  31, Global train loss: 0.494, Global test loss: 1.549, Global test accuracy: 46.12
Round  32, Train loss: 0.503, Test loss: 0.541, Test accuracy: 77.67
Round  32, Global train loss: 0.503, Global test loss: 1.447, Global test accuracy: 48.38
Round  33, Train loss: 0.512, Test loss: 0.544, Test accuracy: 78.12
Round  33, Global train loss: 0.512, Global test loss: 1.563, Global test accuracy: 45.92
Round  34, Train loss: 0.445, Test loss: 0.552, Test accuracy: 78.13
Round  34, Global train loss: 0.445, Global test loss: 1.525, Global test accuracy: 47.57
Round  35, Train loss: 0.518, Test loss: 0.571, Test accuracy: 78.00
Round  35, Global train loss: 0.518, Global test loss: 1.660, Global test accuracy: 45.08
Round  36, Train loss: 0.525, Test loss: 0.577, Test accuracy: 77.25
Round  36, Global train loss: 0.525, Global test loss: 1.767, Global test accuracy: 42.92
Round  37, Train loss: 0.458, Test loss: 0.586, Test accuracy: 77.17
Round  37, Global train loss: 0.458, Global test loss: 1.768, Global test accuracy: 41.58
Round  38, Train loss: 0.564, Test loss: 0.580, Test accuracy: 77.68
Round  38, Global train loss: 0.564, Global test loss: 1.355, Global test accuracy: 51.53
Round  39, Train loss: 0.441, Test loss: 0.542, Test accuracy: 78.90
Round  39, Global train loss: 0.441, Global test loss: 1.473, Global test accuracy: 49.05
Round  40, Train loss: 0.450, Test loss: 0.555, Test accuracy: 78.47
Round  40, Global train loss: 0.450, Global test loss: 1.619, Global test accuracy: 45.17
Round  41, Train loss: 0.398, Test loss: 0.545, Test accuracy: 78.83
Round  41, Global train loss: 0.398, Global test loss: 1.580, Global test accuracy: 50.87
Round  42, Train loss: 0.503, Test loss: 0.537, Test accuracy: 78.72
Round  42, Global train loss: 0.503, Global test loss: 1.371, Global test accuracy: 50.97
Round  43, Train loss: 0.495, Test loss: 0.547, Test accuracy: 78.65
Round  43, Global train loss: 0.495, Global test loss: 1.361, Global test accuracy: 51.73
Round  44, Train loss: 0.446, Test loss: 0.557, Test accuracy: 78.53
Round  44, Global train loss: 0.446, Global test loss: 1.591, Global test accuracy: 45.63
Round  45, Train loss: 0.488, Test loss: 0.561, Test accuracy: 78.62
Round  45, Global train loss: 0.488, Global test loss: 1.408, Global test accuracy: 51.45
Round  46, Train loss: 0.425, Test loss: 0.553, Test accuracy: 79.23
Round  46, Global train loss: 0.425, Global test loss: 1.475, Global test accuracy: 50.32
Round  47, Train loss: 0.364, Test loss: 0.565, Test accuracy: 78.83
Round  47, Global train loss: 0.364, Global test loss: 1.378, Global test accuracy: 54.82
Round  48, Train loss: 0.451, Test loss: 0.556, Test accuracy: 79.23
Round  48, Global train loss: 0.451, Global test loss: 1.314, Global test accuracy: 55.27
Round  49, Train loss: 0.381, Test loss: 0.544, Test accuracy: 79.45
Round  49, Global train loss: 0.381, Global test loss: 1.522, Global test accuracy: 50.87
Round  50, Train loss: 0.421, Test loss: 0.560, Test accuracy: 79.22
Round  50, Global train loss: 0.421, Global test loss: 1.254, Global test accuracy: 56.50
Round  51, Train loss: 0.405, Test loss: 0.561, Test accuracy: 79.15
Round  51, Global train loss: 0.405, Global test loss: 1.441, Global test accuracy: 50.30
Round  52, Train loss: 0.444, Test loss: 0.549, Test accuracy: 80.10
Round  52, Global train loss: 0.444, Global test loss: 1.482, Global test accuracy: 50.60
Round  53, Train loss: 0.332, Test loss: 0.538, Test accuracy: 80.28
Round  53, Global train loss: 0.332, Global test loss: 1.319, Global test accuracy: 56.70
Round  54, Train loss: 0.422, Test loss: 0.535, Test accuracy: 79.80
Round  54, Global train loss: 0.422, Global test loss: 1.375, Global test accuracy: 54.65
Round  55, Train loss: 0.426, Test loss: 0.536, Test accuracy: 79.90
Round  55, Global train loss: 0.426, Global test loss: 1.311, Global test accuracy: 55.72
Round  56, Train loss: 0.379, Test loss: 0.530, Test accuracy: 80.53
Round  56, Global train loss: 0.379, Global test loss: 1.341, Global test accuracy: 52.92
Round  57, Train loss: 0.418, Test loss: 0.539, Test accuracy: 80.03
Round  57, Global train loss: 0.418, Global test loss: 1.457, Global test accuracy: 50.43
Round  58, Train loss: 0.410, Test loss: 0.521, Test accuracy: 80.53
Round  58, Global train loss: 0.410, Global test loss: 1.246, Global test accuracy: 55.90
Round  59, Train loss: 0.385, Test loss: 0.518, Test accuracy: 80.87
Round  59, Global train loss: 0.385, Global test loss: 1.618, Global test accuracy: 48.50
Round  60, Train loss: 0.354, Test loss: 0.536, Test accuracy: 80.53
Round  60, Global train loss: 0.354, Global test loss: 1.390, Global test accuracy: 55.58
Round  61, Train loss: 0.309, Test loss: 0.556, Test accuracy: 79.60
Round  61, Global train loss: 0.309, Global test loss: 1.668, Global test accuracy: 51.30
Round  62, Train loss: 0.283, Test loss: 0.578, Test accuracy: 79.27
Round  62, Global train loss: 0.283, Global test loss: 1.446, Global test accuracy: 54.75
Round  63, Train loss: 0.364, Test loss: 0.587, Test accuracy: 79.47
Round  63, Global train loss: 0.364, Global test loss: 1.611, Global test accuracy: 50.87
Round  64, Train loss: 0.277, Test loss: 0.578, Test accuracy: 79.57
Round  64, Global train loss: 0.277, Global test loss: 1.437, Global test accuracy: 54.20
Round  65, Train loss: 0.337, Test loss: 0.562, Test accuracy: 79.98
Round  65, Global train loss: 0.337, Global test loss: 1.456, Global test accuracy: 51.95
Round  66, Train loss: 0.403, Test loss: 0.544, Test accuracy: 80.50
Round  66, Global train loss: 0.403, Global test loss: 1.538, Global test accuracy: 51.93
Round  67, Train loss: 0.306, Test loss: 0.538, Test accuracy: 80.48
Round  67, Global train loss: 0.306, Global test loss: 1.363, Global test accuracy: 56.50
Round  68, Train loss: 0.302, Test loss: 0.537, Test accuracy: 80.85
Round  68, Global train loss: 0.302, Global test loss: 1.363, Global test accuracy: 56.03
Round  69, Train loss: 0.267, Test loss: 0.546, Test accuracy: 80.90
Round  69, Global train loss: 0.267, Global test loss: 1.533, Global test accuracy: 54.75
Round  70, Train loss: 0.370, Test loss: 0.550, Test accuracy: 80.52
Round  70, Global train loss: 0.370, Global test loss: 1.547, Global test accuracy: 52.20
Round  71, Train loss: 0.305, Test loss: 0.545, Test accuracy: 80.73
Round  71, Global train loss: 0.305, Global test loss: 1.309, Global test accuracy: 57.75
Round  72, Train loss: 0.241, Test loss: 0.560, Test accuracy: 80.60
Round  72, Global train loss: 0.241, Global test loss: 1.599, Global test accuracy: 52.58
Round  73, Train loss: 0.288, Test loss: 0.554, Test accuracy: 80.90
Round  73, Global train loss: 0.288, Global test loss: 1.559, Global test accuracy: 52.12
Round  74, Train loss: 0.341, Test loss: 0.557, Test accuracy: 80.50
Round  74, Global train loss: 0.341, Global test loss: 1.551, Global test accuracy: 52.07
Round  75, Train loss: 0.368, Test loss: 0.545, Test accuracy: 80.55
Round  75, Global train loss: 0.368, Global test loss: 1.367, Global test accuracy: 54.32
Round  76, Train loss: 0.266, Test loss: 0.531, Test accuracy: 81.12
Round  76, Global train loss: 0.266, Global test loss: 1.357, Global test accuracy: 54.67
Round  77, Train loss: 0.321, Test loss: 0.528, Test accuracy: 81.50
Round  77, Global train loss: 0.321, Global test loss: 1.532, Global test accuracy: 52.40
Round  78, Train loss: 0.326, Test loss: 0.546, Test accuracy: 81.18
Round  78, Global train loss: 0.326, Global test loss: 1.675, Global test accuracy: 50.27
Round  79, Train loss: 0.297, Test loss: 0.544, Test accuracy: 81.58
Round  79, Global train loss: 0.297, Global test loss: 1.455, Global test accuracy: 54.50
Round  80, Train loss: 0.274, Test loss: 0.547, Test accuracy: 81.48
Round  80, Global train loss: 0.274, Global test loss: 1.383, Global test accuracy: 56.40
Round  81, Train loss: 0.306, Test loss: 0.553, Test accuracy: 81.23
Round  81, Global train loss: 0.306, Global test loss: 1.389, Global test accuracy: 54.57
Round  82, Train loss: 0.269, Test loss: 0.549, Test accuracy: 80.82
Round  82, Global train loss: 0.269, Global test loss: 1.529, Global test accuracy: 53.92
Round  83, Train loss: 0.271, Test loss: 0.545, Test accuracy: 81.45
Round  83, Global train loss: 0.271, Global test loss: 1.532, Global test accuracy: 54.83
Round  84, Train loss: 0.299, Test loss: 0.552, Test accuracy: 81.30
Round  84, Global train loss: 0.299, Global test loss: 1.632, Global test accuracy: 51.27
Round  85, Train loss: 0.336, Test loss: 0.550, Test accuracy: 81.00
Round  85, Global train loss: 0.336, Global test loss: 1.325, Global test accuracy: 56.42
Round  86, Train loss: 0.277, Test loss: 0.558, Test accuracy: 81.12
Round  86, Global train loss: 0.277, Global test loss: 1.405, Global test accuracy: 54.08
Round  87, Train loss: 0.277, Test loss: 0.548, Test accuracy: 81.37
Round  87, Global train loss: 0.277, Global test loss: 1.894, Global test accuracy: 48.78
Round  88, Train loss: 0.259, Test loss: 0.562, Test accuracy: 81.28
Round  88, Global train loss: 0.259, Global test loss: 1.693, Global test accuracy: 51.82
Round  89, Train loss: 0.286, Test loss: 0.561, Test accuracy: 81.35
Round  89, Global train loss: 0.286, Global test loss: 1.366, Global test accuracy: 57.25
Round  90, Train loss: 0.238, Test loss: 0.548, Test accuracy: 81.88
Round  90, Global train loss: 0.238, Global test loss: 1.329, Global test accuracy: 57.37
Round  91, Train loss: 0.223, Test loss: 0.573, Test accuracy: 81.60
Round  91, Global train loss: 0.223, Global test loss: 1.629, Global test accuracy: 54.28
Round  92, Train loss: 0.267, Test loss: 0.555, Test accuracy: 82.28
Round  92, Global train loss: 0.267, Global test loss: 1.310, Global test accuracy: 57.68
Round  93, Train loss: 0.274, Test loss: 0.563, Test accuracy: 82.27
Round  93, Global train loss: 0.274, Global test loss: 1.344, Global test accuracy: 57.50
Round  94, Train loss: 0.221, Test loss: 0.568, Test accuracy: 81.98
Round  94, Global train loss: 0.221, Global test loss: 1.314, Global test accuracy: 58.92
Round  95, Train loss: 0.311, Test loss: 0.577, Test accuracy: 81.83
Round  95, Global train loss: 0.311, Global test loss: 1.289, Global test accuracy: 57.93/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.293, Test loss: 0.584, Test accuracy: 81.63
Round  96, Global train loss: 0.293, Global test loss: 1.522, Global test accuracy: 53.78
Round  97, Train loss: 0.218, Test loss: 0.568, Test accuracy: 81.83
Round  97, Global train loss: 0.218, Global test loss: 1.512, Global test accuracy: 53.75
Round  98, Train loss: 0.264, Test loss: 0.588, Test accuracy: 80.90
Round  98, Global train loss: 0.264, Global test loss: 1.632, Global test accuracy: 51.02
Round  99, Train loss: 0.272, Test loss: 0.598, Test accuracy: 81.00
Round  99, Global train loss: 0.272, Global test loss: 1.440, Global test accuracy: 54.72
Final Round, Train loss: 0.205, Test loss: 0.629, Test accuracy: 81.80
Final Round, Global train loss: 0.205, Global test loss: 1.440, Global test accuracy: 54.72
Average accuracy final 10 rounds: 81.72166666666666 

Average global accuracy final 10 rounds: 55.694999999999986 

1073.5092270374298
[1.0045521259307861, 2.0091042518615723, 2.7398762702941895, 3.4706482887268066, 4.2098307609558105, 4.9490132331848145, 5.673205137252808, 6.397397041320801, 7.120258092880249, 7.843119144439697, 8.593283891677856, 9.343448638916016, 10.07036018371582, 10.797271728515625, 11.52133321762085, 12.245394706726074, 12.966134309768677, 13.68687391281128, 14.413155794143677, 15.139437675476074, 15.885258674621582, 16.63107967376709, 17.367952823638916, 18.104825973510742, 18.828071355819702, 19.551316738128662, 20.281294584274292, 21.011272430419922, 21.74877905845642, 22.48628568649292, 23.21409559249878, 23.94190549850464, 24.67470645904541, 25.40750741958618, 26.14523482322693, 26.882962226867676, 27.605236530303955, 28.327510833740234, 29.056936740875244, 29.786362648010254, 30.524885416030884, 31.263408184051514, 31.985370874404907, 32.7073335647583, 33.44426465034485, 34.1811957359314, 34.90407419204712, 35.62695264816284, 36.3523805141449, 37.07780838012695, 37.810038805007935, 38.542269229888916, 39.28365421295166, 40.025039196014404, 40.76809477806091, 41.51115036010742, 42.24367642402649, 42.97620248794556, 43.698036670684814, 44.41987085342407, 45.14950203895569, 45.879133224487305, 46.60059833526611, 47.32206344604492, 48.05470108985901, 48.787338733673096, 49.53268527984619, 50.27803182601929, 51.042760372161865, 51.80748891830444, 52.581263303756714, 53.355037689208984, 54.14974641799927, 54.94445514678955, 55.71035385131836, 56.47625255584717, 57.21094822883606, 57.94564390182495, 58.69388437271118, 59.44212484359741, 60.20400381088257, 60.965882778167725, 61.734198570251465, 62.502514362335205, 63.282907009124756, 64.0632996559143, 64.85845136642456, 65.65360307693481, 66.39862632751465, 67.14364957809448, 67.88966584205627, 68.63568210601807, 69.40822863578796, 70.18077516555786, 70.94279503822327, 71.70481491088867, 72.47001504898071, 73.23521518707275, 74.02913093566895, 74.82304668426514, 75.61985731124878, 76.41666793823242, 77.16554927825928, 77.91443061828613, 78.72417640686035, 79.53392219543457, 80.39908027648926, 81.26423835754395, 82.06555581092834, 82.86687326431274, 83.66036033630371, 84.45384740829468, 85.24044418334961, 86.02704095840454, 86.77435207366943, 87.52166318893433, 88.27361917495728, 89.02557516098022, 89.83218789100647, 90.63880062103271, 91.4274377822876, 92.21607494354248, 93.01556706428528, 93.81505918502808, 94.66014790534973, 95.50523662567139, 96.32953929901123, 97.15384197235107, 97.96405506134033, 98.77426815032959, 99.62000966072083, 100.46575117111206, 101.30893230438232, 102.15211343765259, 102.99020075798035, 103.8282880783081, 104.68577837944031, 105.54326868057251, 106.41706156730652, 107.29085445404053, 108.12682223320007, 108.96279001235962, 109.80685496330261, 110.6509199142456, 111.49537134170532, 112.33982276916504, 113.18935942649841, 114.03889608383179, 114.846848487854, 115.65480089187622, 116.498788356781, 117.34277582168579, 118.15989112854004, 118.97700643539429, 119.79796290397644, 120.6189193725586, 121.445303440094, 122.2716875076294, 123.046395778656, 123.82110404968262, 124.62980532646179, 125.43850660324097, 126.26316118240356, 127.08781576156616, 127.92095136642456, 128.75408697128296, 129.58153820037842, 130.40898942947388, 131.18612432479858, 131.9632592201233, 132.74742913246155, 133.5315990447998, 134.3097174167633, 135.0878357887268, 135.89317917823792, 136.69852256774902, 137.56633353233337, 138.43414449691772, 139.31116199493408, 140.18817949295044, 141.003675699234, 141.81917190551758, 142.63081216812134, 143.4424524307251, 144.21140241622925, 144.9803524017334, 145.8092555999756, 146.63815879821777, 147.45750761032104, 148.27685642242432, 149.03954601287842, 149.80223560333252, 150.61201572418213, 151.42179584503174, 152.24538803100586, 153.06898021697998, 153.8861129283905, 154.70324563980103, 155.54713368415833, 156.39102172851562, 158.04382610321045, 159.69663047790527]
[28.05, 28.05, 37.03333333333333, 37.03333333333333, 38.18333333333333, 38.18333333333333, 50.15, 50.15, 52.93333333333333, 52.93333333333333, 61.13333333333333, 61.13333333333333, 66.55, 66.55, 68.75, 68.75, 69.55, 69.55, 68.91666666666667, 68.91666666666667, 68.95, 68.95, 69.71666666666667, 69.71666666666667, 71.01666666666667, 71.01666666666667, 73.6, 73.6, 72.63333333333334, 72.63333333333334, 72.75, 72.75, 73.5, 73.5, 73.61666666666666, 73.61666666666666, 73.95, 73.95, 74.98333333333333, 74.98333333333333, 75.8, 75.8, 76.31666666666666, 76.31666666666666, 76.2, 76.2, 76.18333333333334, 76.18333333333334, 75.4, 75.4, 75.35, 75.35, 75.88333333333334, 75.88333333333334, 75.45, 75.45, 76.33333333333333, 76.33333333333333, 77.05, 77.05, 77.35, 77.35, 77.33333333333333, 77.33333333333333, 77.66666666666667, 77.66666666666667, 78.11666666666666, 78.11666666666666, 78.13333333333334, 78.13333333333334, 78.0, 78.0, 77.25, 77.25, 77.16666666666667, 77.16666666666667, 77.68333333333334, 77.68333333333334, 78.9, 78.9, 78.46666666666667, 78.46666666666667, 78.83333333333333, 78.83333333333333, 78.71666666666667, 78.71666666666667, 78.65, 78.65, 78.53333333333333, 78.53333333333333, 78.61666666666666, 78.61666666666666, 79.23333333333333, 79.23333333333333, 78.83333333333333, 78.83333333333333, 79.23333333333333, 79.23333333333333, 79.45, 79.45, 79.21666666666667, 79.21666666666667, 79.15, 79.15, 80.1, 80.1, 80.28333333333333, 80.28333333333333, 79.8, 79.8, 79.9, 79.9, 80.53333333333333, 80.53333333333333, 80.03333333333333, 80.03333333333333, 80.53333333333333, 80.53333333333333, 80.86666666666666, 80.86666666666666, 80.53333333333333, 80.53333333333333, 79.6, 79.6, 79.26666666666667, 79.26666666666667, 79.46666666666667, 79.46666666666667, 79.56666666666666, 79.56666666666666, 79.98333333333333, 79.98333333333333, 80.5, 80.5, 80.48333333333333, 80.48333333333333, 80.85, 80.85, 80.9, 80.9, 80.51666666666667, 80.51666666666667, 80.73333333333333, 80.73333333333333, 80.6, 80.6, 80.9, 80.9, 80.5, 80.5, 80.55, 80.55, 81.11666666666666, 81.11666666666666, 81.5, 81.5, 81.18333333333334, 81.18333333333334, 81.58333333333333, 81.58333333333333, 81.48333333333333, 81.48333333333333, 81.23333333333333, 81.23333333333333, 80.81666666666666, 80.81666666666666, 81.45, 81.45, 81.3, 81.3, 81.0, 81.0, 81.11666666666666, 81.11666666666666, 81.36666666666666, 81.36666666666666, 81.28333333333333, 81.28333333333333, 81.35, 81.35, 81.88333333333334, 81.88333333333334, 81.6, 81.6, 82.28333333333333, 82.28333333333333, 82.26666666666667, 82.26666666666667, 81.98333333333333, 81.98333333333333, 81.83333333333333, 81.83333333333333, 81.63333333333334, 81.63333333333334, 81.83333333333333, 81.83333333333333, 80.9, 80.9, 81.0, 81.0, 81.8, 81.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.676, Test loss: 2.115, Test accuracy: 25.18
Round   1, Train loss: 1.094, Test loss: 1.998, Test accuracy: 35.65
Round   2, Train loss: 0.922, Test loss: 1.479, Test accuracy: 47.77
Round   3, Train loss: 0.860, Test loss: 1.365, Test accuracy: 55.05
Round   4, Train loss: 0.783, Test loss: 1.186, Test accuracy: 56.80
Round   5, Train loss: 0.751, Test loss: 1.246, Test accuracy: 58.23
Round   6, Train loss: 0.758, Test loss: 1.004, Test accuracy: 63.32
Round   7, Train loss: 0.853, Test loss: 0.771, Test accuracy: 67.28
Round   8, Train loss: 0.704, Test loss: 0.690, Test accuracy: 70.75
Round   9, Train loss: 0.705, Test loss: 0.679, Test accuracy: 71.22
Round  10, Train loss: 0.656, Test loss: 0.667, Test accuracy: 71.52
Round  11, Train loss: 0.744, Test loss: 0.647, Test accuracy: 72.00
Round  12, Train loss: 0.709, Test loss: 0.655, Test accuracy: 71.15
Round  13, Train loss: 0.641, Test loss: 0.629, Test accuracy: 72.73
Round  14, Train loss: 0.654, Test loss: 0.603, Test accuracy: 74.45
Round  15, Train loss: 0.646, Test loss: 0.604, Test accuracy: 74.80
Round  16, Train loss: 0.630, Test loss: 0.604, Test accuracy: 75.23
Round  17, Train loss: 0.587, Test loss: 0.591, Test accuracy: 74.95
Round  18, Train loss: 0.605, Test loss: 0.592, Test accuracy: 75.72
Round  19, Train loss: 0.690, Test loss: 0.585, Test accuracy: 75.92
Round  20, Train loss: 0.552, Test loss: 0.581, Test accuracy: 74.88
Round  21, Train loss: 0.508, Test loss: 0.571, Test accuracy: 75.45
Round  22, Train loss: 0.613, Test loss: 0.570, Test accuracy: 75.62
Round  23, Train loss: 0.544, Test loss: 0.561, Test accuracy: 75.55
Round  24, Train loss: 0.542, Test loss: 0.569, Test accuracy: 75.78
Round  25, Train loss: 0.511, Test loss: 0.555, Test accuracy: 76.17
Round  26, Train loss: 0.487, Test loss: 0.542, Test accuracy: 77.13
Round  27, Train loss: 0.527, Test loss: 0.532, Test accuracy: 77.03
Round  28, Train loss: 0.587, Test loss: 0.539, Test accuracy: 77.12
Round  29, Train loss: 0.467, Test loss: 0.521, Test accuracy: 78.10
Round  30, Train loss: 0.467, Test loss: 0.508, Test accuracy: 78.27
Round  31, Train loss: 0.486, Test loss: 0.509, Test accuracy: 78.32
Round  32, Train loss: 0.561, Test loss: 0.520, Test accuracy: 77.55
Round  33, Train loss: 0.508, Test loss: 0.509, Test accuracy: 78.75
Round  34, Train loss: 0.506, Test loss: 0.500, Test accuracy: 79.05
Round  35, Train loss: 0.568, Test loss: 0.501, Test accuracy: 79.03
Round  36, Train loss: 0.501, Test loss: 0.499, Test accuracy: 79.37
Round  37, Train loss: 0.500, Test loss: 0.491, Test accuracy: 79.90
Round  38, Train loss: 0.452, Test loss: 0.488, Test accuracy: 79.80
Round  39, Train loss: 0.469, Test loss: 0.503, Test accuracy: 78.98
Round  40, Train loss: 0.440, Test loss: 0.493, Test accuracy: 79.58
Round  41, Train loss: 0.438, Test loss: 0.483, Test accuracy: 79.97
Round  42, Train loss: 0.394, Test loss: 0.480, Test accuracy: 80.05
Round  43, Train loss: 0.431, Test loss: 0.480, Test accuracy: 80.18
Round  44, Train loss: 0.462, Test loss: 0.474, Test accuracy: 80.68
Round  45, Train loss: 0.454, Test loss: 0.476, Test accuracy: 80.98
Round  46, Train loss: 0.427, Test loss: 0.477, Test accuracy: 80.40
Round  47, Train loss: 0.470, Test loss: 0.472, Test accuracy: 81.00
Round  48, Train loss: 0.445, Test loss: 0.473, Test accuracy: 80.42
Round  49, Train loss: 0.431, Test loss: 0.476, Test accuracy: 80.57
Round  50, Train loss: 0.353, Test loss: 0.477, Test accuracy: 80.50
Round  51, Train loss: 0.401, Test loss: 0.470, Test accuracy: 81.27
Round  52, Train loss: 0.380, Test loss: 0.470, Test accuracy: 80.68
Round  53, Train loss: 0.419, Test loss: 0.464, Test accuracy: 81.40
Round  54, Train loss: 0.401, Test loss: 0.460, Test accuracy: 81.32
Round  55, Train loss: 0.499, Test loss: 0.462, Test accuracy: 81.13
Round  56, Train loss: 0.344, Test loss: 0.468, Test accuracy: 80.95
Round  57, Train loss: 0.371, Test loss: 0.450, Test accuracy: 81.78
Round  58, Train loss: 0.425, Test loss: 0.451, Test accuracy: 81.98
Round  59, Train loss: 0.361, Test loss: 0.450, Test accuracy: 82.02
Round  60, Train loss: 0.515, Test loss: 0.443, Test accuracy: 82.22
Round  61, Train loss: 0.354, Test loss: 0.437, Test accuracy: 82.27
Round  62, Train loss: 0.320, Test loss: 0.442, Test accuracy: 81.87
Round  63, Train loss: 0.427, Test loss: 0.436, Test accuracy: 82.05
Round  64, Train loss: 0.400, Test loss: 0.430, Test accuracy: 82.80
Round  65, Train loss: 0.380, Test loss: 0.435, Test accuracy: 82.25
Round  66, Train loss: 0.321, Test loss: 0.435, Test accuracy: 82.17
Round  67, Train loss: 0.375, Test loss: 0.427, Test accuracy: 83.15
Round  68, Train loss: 0.342, Test loss: 0.431, Test accuracy: 82.80
Round  69, Train loss: 0.320, Test loss: 0.432, Test accuracy: 82.78
Round  70, Train loss: 0.347, Test loss: 0.430, Test accuracy: 82.67
Round  71, Train loss: 0.321, Test loss: 0.432, Test accuracy: 82.75
Round  72, Train loss: 0.413, Test loss: 0.426, Test accuracy: 83.08
Round  73, Train loss: 0.320, Test loss: 0.424, Test accuracy: 82.93
Round  74, Train loss: 0.407, Test loss: 0.424, Test accuracy: 83.23
Round  75, Train loss: 0.325, Test loss: 0.419, Test accuracy: 83.20
Round  76, Train loss: 0.405, Test loss: 0.418, Test accuracy: 83.53
Round  77, Train loss: 0.351, Test loss: 0.418, Test accuracy: 83.48
Round  78, Train loss: 0.349, Test loss: 0.433, Test accuracy: 82.80
Round  79, Train loss: 0.279, Test loss: 0.425, Test accuracy: 83.12
Round  80, Train loss: 0.264, Test loss: 0.419, Test accuracy: 83.65
Round  81, Train loss: 0.309, Test loss: 0.423, Test accuracy: 83.37
Round  82, Train loss: 0.299, Test loss: 0.420, Test accuracy: 83.28
Round  83, Train loss: 0.291, Test loss: 0.418, Test accuracy: 83.65
Round  84, Train loss: 0.309, Test loss: 0.422, Test accuracy: 83.68
Round  85, Train loss: 0.270, Test loss: 0.425, Test accuracy: 83.33
Round  86, Train loss: 0.298, Test loss: 0.417, Test accuracy: 83.92
Round  87, Train loss: 0.280, Test loss: 0.416, Test accuracy: 83.58
Round  88, Train loss: 0.284, Test loss: 0.417, Test accuracy: 83.57
Round  89, Train loss: 0.307, Test loss: 0.413, Test accuracy: 83.48
Round  90, Train loss: 0.310, Test loss: 0.414, Test accuracy: 83.57
Round  91, Train loss: 0.287, Test loss: 0.414, Test accuracy: 83.80
Round  92, Train loss: 0.326, Test loss: 0.413, Test accuracy: 83.58
Round  93, Train loss: 0.398, Test loss: 0.410, Test accuracy: 84.02
Round  94, Train loss: 0.291, Test loss: 0.413, Test accuracy: 83.68
Round  95, Train loss: 0.292, Test loss: 0.412, Test accuracy: 84.02
Round  96, Train loss: 0.295, Test loss: 0.413, Test accuracy: 83.87
Round  97, Train loss: 0.229, Test loss: 0.413, Test accuracy: 83.82
Round  98, Train loss: 0.236, Test loss: 0.413, Test accuracy: 83.92
Round  99, Train loss: 0.268, Test loss: 0.407, Test accuracy: 84.03
Final Round, Train loss: 0.243, Test loss: 0.407, Test accuracy: 84.27
Average accuracy final 10 rounds: 83.83
783.6415708065033
[1.332280158996582, 2.3494582176208496, 3.334467649459839, 4.276329517364502, 5.259710311889648, 6.19642972946167, 7.108271837234497, 8.05490231513977, 9.004534244537354, 9.99301552772522, 10.927774429321289, 11.865921974182129, 12.770316123962402, 13.719532251358032, 14.717787504196167, 15.74113917350769, 16.748475551605225, 17.71904683113098, 18.72803807258606, 19.60092329978943, 20.480119705200195, 21.352195501327515, 22.236085653305054, 23.2159583568573, 24.220224857330322, 25.261016368865967, 26.236449003219604, 27.1732816696167, 28.10499095916748, 29.010384798049927, 29.94376564025879, 30.93488383293152, 31.87665319442749, 32.86353826522827, 33.82222771644592, 34.72502064704895, 35.62911343574524, 36.61204934120178, 37.58190608024597, 38.577640771865845, 39.559306621551514, 40.498679399490356, 41.44494366645813, 42.337559938430786, 43.2176730632782, 44.109376192092896, 45.006213903427124, 46.08671259880066, 47.07102346420288, 48.10781407356262, 49.26988887786865, 50.25725555419922, 51.17151165008545, 52.04931139945984, 52.93378520011902, 53.889113426208496, 54.83187556266785, 55.801125288009644, 56.82380247116089, 57.753570795059204, 58.68245601654053, 59.61177682876587, 60.584951639175415, 61.55599927902222, 62.50388050079346, 63.454822301864624, 64.40708374977112, 65.29075050354004, 66.17626690864563, 67.0594596862793, 68.0239577293396, 69.08033490180969, 70.11769461631775, 71.14913630485535, 72.19274973869324, 73.11817836761475, 73.988445520401, 74.86366367340088, 75.7443995475769, 76.69967484474182, 77.65651631355286, 78.62742257118225, 79.65415143966675, 80.56345129013062, 81.58883905410767, 82.56041693687439, 83.52149939537048, 84.49041199684143, 85.50179743766785, 86.52820158004761, 87.46265697479248, 88.36458158493042, 89.35587882995605, 90.30013227462769, 91.21983122825623, 92.24737572669983, 93.23766875267029, 94.26527214050293, 95.27108454704285, 96.15057039260864, 97.59542989730835]
[25.183333333333334, 35.65, 47.766666666666666, 55.05, 56.8, 58.233333333333334, 63.31666666666667, 67.28333333333333, 70.75, 71.21666666666667, 71.51666666666667, 72.0, 71.15, 72.73333333333333, 74.45, 74.8, 75.23333333333333, 74.95, 75.71666666666667, 75.91666666666667, 74.88333333333334, 75.45, 75.61666666666666, 75.55, 75.78333333333333, 76.16666666666667, 77.13333333333334, 77.03333333333333, 77.11666666666666, 78.1, 78.26666666666667, 78.31666666666666, 77.55, 78.75, 79.05, 79.03333333333333, 79.36666666666666, 79.9, 79.8, 78.98333333333333, 79.58333333333333, 79.96666666666667, 80.05, 80.18333333333334, 80.68333333333334, 80.98333333333333, 80.4, 81.0, 80.41666666666667, 80.56666666666666, 80.5, 81.26666666666667, 80.68333333333334, 81.4, 81.31666666666666, 81.13333333333334, 80.95, 81.78333333333333, 81.98333333333333, 82.01666666666667, 82.21666666666667, 82.26666666666667, 81.86666666666666, 82.05, 82.8, 82.25, 82.16666666666667, 83.15, 82.8, 82.78333333333333, 82.66666666666667, 82.75, 83.08333333333333, 82.93333333333334, 83.23333333333333, 83.2, 83.53333333333333, 83.48333333333333, 82.8, 83.11666666666666, 83.65, 83.36666666666666, 83.28333333333333, 83.65, 83.68333333333334, 83.33333333333333, 83.91666666666667, 83.58333333333333, 83.56666666666666, 83.48333333333333, 83.56666666666666, 83.8, 83.58333333333333, 84.01666666666667, 83.68333333333334, 84.01666666666667, 83.86666666666666, 83.81666666666666, 83.91666666666667, 84.03333333333333, 84.26666666666667]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  10.0000
Round 1 global test acc  17.8600
Round 2 global test acc  17.6000
Round 3 global test acc  19.7900
Round 4 global test acc  20.5000
Round 5 global test acc  25.4900
Round 6 global test acc  22.2900
Round 7 global test acc  26.6100
Round 8 global test acc  29.2000
Round 9 global test acc  27.4100
Round 10 global test acc  26.2200
Round 11 global test acc  30.0200
Round 12 global test acc  22.1800
Round 13 global test acc  22.7900
Round 14 global test acc  30.1100
Round 15 global test acc  25.0100
Round 16 global test acc  24.4800
Round 17 global test acc  26.8700
Round 18 global test acc  20.9600
Round 19 global test acc  23.8400
Round 20 global test acc  24.8200
Round 21 global test acc  28.0100
Round 22 global test acc  28.6100
Round 23 global test acc  29.2700
Round 24 global test acc  30.2400
Round 25 global test acc  21.7600
Round 26 global test acc  30.4900
Round 27 global test acc  28.5200
Round 28 global test acc  29.6200
Round 29 global test acc  22.5200
Round 30 global test acc  26.7700
Round 31 global test acc  30.7200
Round 32 global test acc  29.0000
Round 33 global test acc  29.9300
Round 34 global test acc  22.5200
Round 35 global test acc  26.0100
Round 36 global test acc  32.5400
Round 37 global test acc  34.3800
Round 38 global test acc  36.2800
Round 39 global test acc  23.7600
Round 40 global test acc  27.9300
Round 41 global test acc  31.5600
Round 42 global test acc  29.2200
Round 43 global test acc  35.2800
Round 44 global test acc  29.8100
Round 45 global test acc  30.7400
Round 46 global test acc  31.8900
Round 47 global test acc  23.7900
Round 48 global test acc  33.3300
Round 49 global test acc  24.0300
Round 50 global test acc  24.8000
Round 51 global test acc  30.6700
Round 52 global test acc  28.5000
Round 53 global test acc  37.0200
Round 54 global test acc  33.4700
Round 55 global test acc  25.9500
Round 56 global test acc  25.2900
Round 57 global test acc  32.1200
Round 58 global test acc  26.7300
Round 59 global test acc  26.9800
Round 60 global test acc  32.5000
Round 61 global test acc  36.0400
Round 62 global test acc  32.4300
Round 63 global test acc  24.5200
Round 64 global test acc  24.3900
Round 65 global test acc  37.0300
Round 66 global test acc  32.7500
Round 67 global test acc  33.6700
Round 68 global test acc  35.7600
Round 69 global test acc  29.7100
Round 70 global test acc  30.8400
Round 71 global test acc  33.0100
Round 72 global test acc  36.8300
Round 73 global test acc  33.2800
Round 74 global test acc  20.7400
Round 75 global test acc  35.0700
Round 76 global test acc  31.6100
Round 77 global test acc  29.1800
Round 78 global test acc  29.5000
Round 79 global test acc  35.5500
Round 80 global test acc  32.8000
Round 81 global test acc  33.0900
Round 82 global test acc  30.2800
Round 83 global test acc  29.7600
Round 84 global test acc  28.3300
Round 85 global test acc  27.8600
Round 86 global test acc  27.6500
Round 87 global test acc  26.0200
Round 88 global test acc  24.1600
Round 89 global test acc  23.3300
Round 90 global test acc  23.1300
Round 91 global test acc  22.7400
Round 92 global test acc  22.9600
Round 93 global test acc  22.9800
Round 94 global test acc  23.0100
Round 95 global test acc  22.8900
Round 96 global test acc  22.2300
Round 97 global test acc  22.8900
Round 98 global test acc  22.7600
Round 99 global test acc  22.8700
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.649, Test loss: 2.035, Test accuracy: 25.88
Round   1, Train loss: 1.090, Test loss: 1.690, Test accuracy: 37.87
Round   2, Train loss: 0.984, Test loss: 1.335, Test accuracy: 46.40
Round   3, Train loss: 0.919, Test loss: 1.211, Test accuracy: 49.38
Round   4, Train loss: 0.820, Test loss: 1.220, Test accuracy: 52.88
Round   5, Train loss: 0.849, Test loss: 0.924, Test accuracy: 60.57
Round   6, Train loss: 0.781, Test loss: 0.887, Test accuracy: 61.75
Round   7, Train loss: 0.710, Test loss: 0.812, Test accuracy: 65.93
Round   8, Train loss: 0.727, Test loss: 0.753, Test accuracy: 68.35
Round   9, Train loss: 0.694, Test loss: 0.754, Test accuracy: 69.58
Round  10, Train loss: 0.717, Test loss: 0.743, Test accuracy: 68.35
Round  11, Train loss: 0.677, Test loss: 0.645, Test accuracy: 72.83
Round  12, Train loss: 0.689, Test loss: 0.627, Test accuracy: 73.38
Round  13, Train loss: 0.614, Test loss: 0.609, Test accuracy: 74.23
Round  14, Train loss: 0.577, Test loss: 0.603, Test accuracy: 74.68
Round  15, Train loss: 0.579, Test loss: 0.597, Test accuracy: 75.52
Round  16, Train loss: 0.650, Test loss: 0.594, Test accuracy: 75.07
Round  17, Train loss: 0.668, Test loss: 0.592, Test accuracy: 75.50
Round  18, Train loss: 0.609, Test loss: 0.589, Test accuracy: 75.68
Round  19, Train loss: 0.645, Test loss: 0.585, Test accuracy: 75.33
Round  20, Train loss: 0.599, Test loss: 0.586, Test accuracy: 75.15
Round  21, Train loss: 0.550, Test loss: 0.584, Test accuracy: 74.98
Round  22, Train loss: 0.621, Test loss: 0.588, Test accuracy: 74.48
Round  23, Train loss: 0.568, Test loss: 0.565, Test accuracy: 75.38
Round  24, Train loss: 0.614, Test loss: 0.563, Test accuracy: 76.00
Round  25, Train loss: 0.559, Test loss: 0.550, Test accuracy: 75.95
Round  26, Train loss: 0.529, Test loss: 0.555, Test accuracy: 76.03
Round  27, Train loss: 0.561, Test loss: 0.541, Test accuracy: 76.95
Round  28, Train loss: 0.505, Test loss: 0.538, Test accuracy: 76.72
Round  29, Train loss: 0.532, Test loss: 0.532, Test accuracy: 77.53
Round  30, Train loss: 0.469, Test loss: 0.525, Test accuracy: 77.60
Round  31, Train loss: 0.443, Test loss: 0.530, Test accuracy: 77.03
Round  32, Train loss: 0.605, Test loss: 0.530, Test accuracy: 77.45
Round  33, Train loss: 0.489, Test loss: 0.521, Test accuracy: 77.82
Round  34, Train loss: 0.548, Test loss: 0.516, Test accuracy: 78.35
Round  35, Train loss: 0.519, Test loss: 0.504, Test accuracy: 78.75
Round  36, Train loss: 0.480, Test loss: 0.507, Test accuracy: 78.30
Round  37, Train loss: 0.497, Test loss: 0.504, Test accuracy: 79.18
Round  38, Train loss: 0.528, Test loss: 0.496, Test accuracy: 79.35
Round  39, Train loss: 0.471, Test loss: 0.493, Test accuracy: 79.17
Round  40, Train loss: 0.534, Test loss: 0.501, Test accuracy: 78.48
Round  41, Train loss: 0.479, Test loss: 0.498, Test accuracy: 78.75
Round  42, Train loss: 0.526, Test loss: 0.500, Test accuracy: 78.90
Round  43, Train loss: 0.491, Test loss: 0.496, Test accuracy: 79.42
Round  44, Train loss: 0.448, Test loss: 0.488, Test accuracy: 79.48
Round  45, Train loss: 0.507, Test loss: 0.496, Test accuracy: 79.25
Round  46, Train loss: 0.433, Test loss: 0.471, Test accuracy: 80.30
Round  47, Train loss: 0.436, Test loss: 0.478, Test accuracy: 80.07
Round  48, Train loss: 0.412, Test loss: 0.474, Test accuracy: 80.45
Round  49, Train loss: 0.387, Test loss: 0.472, Test accuracy: 80.25
Round  50, Train loss: 0.471, Test loss: 0.475, Test accuracy: 80.13
Round  51, Train loss: 0.417, Test loss: 0.481, Test accuracy: 79.92
Round  52, Train loss: 0.501, Test loss: 0.471, Test accuracy: 80.58
Round  53, Train loss: 0.488, Test loss: 0.466, Test accuracy: 80.85
Round  54, Train loss: 0.458, Test loss: 0.481, Test accuracy: 80.20
Round  55, Train loss: 0.433, Test loss: 0.471, Test accuracy: 80.67
Round  56, Train loss: 0.384, Test loss: 0.462, Test accuracy: 81.37
Round  57, Train loss: 0.463, Test loss: 0.465, Test accuracy: 80.62
Round  58, Train loss: 0.346, Test loss: 0.464, Test accuracy: 81.10
Round  59, Train loss: 0.494, Test loss: 0.462, Test accuracy: 81.18
Round  60, Train loss: 0.355, Test loss: 0.458, Test accuracy: 81.52
Round  61, Train loss: 0.384, Test loss: 0.459, Test accuracy: 81.07
Round  62, Train loss: 0.382, Test loss: 0.451, Test accuracy: 81.70
Round  63, Train loss: 0.398, Test loss: 0.448, Test accuracy: 82.17
Round  64, Train loss: 0.382, Test loss: 0.454, Test accuracy: 81.77
Round  65, Train loss: 0.418, Test loss: 0.454, Test accuracy: 81.57
Round  66, Train loss: 0.320, Test loss: 0.454, Test accuracy: 81.62
Round  67, Train loss: 0.380, Test loss: 0.462, Test accuracy: 81.57
Round  68, Train loss: 0.353, Test loss: 0.451, Test accuracy: 81.80
Round  69, Train loss: 0.318, Test loss: 0.451, Test accuracy: 81.75
Round  70, Train loss: 0.420, Test loss: 0.462, Test accuracy: 81.68
Round  71, Train loss: 0.333, Test loss: 0.479, Test accuracy: 80.97
Round  72, Train loss: 0.427, Test loss: 0.448, Test accuracy: 81.92
Round  73, Train loss: 0.391, Test loss: 0.439, Test accuracy: 81.97
Round  74, Train loss: 0.329, Test loss: 0.444, Test accuracy: 82.13
Round  75, Train loss: 0.351, Test loss: 0.446, Test accuracy: 82.10
Round  76, Train loss: 0.323, Test loss: 0.445, Test accuracy: 82.13
Round  77, Train loss: 0.333, Test loss: 0.445, Test accuracy: 82.35
Round  78, Train loss: 0.350, Test loss: 0.435, Test accuracy: 82.65
Round  79, Train loss: 0.310, Test loss: 0.433, Test accuracy: 82.62
Round  80, Train loss: 0.303, Test loss: 0.431, Test accuracy: 82.65
Round  81, Train loss: 0.336, Test loss: 0.440, Test accuracy: 82.28
Round  82, Train loss: 0.349, Test loss: 0.435, Test accuracy: 82.62
Round  83, Train loss: 0.354, Test loss: 0.429, Test accuracy: 82.63
Round  84, Train loss: 0.383, Test loss: 0.436, Test accuracy: 82.65
Round  85, Train loss: 0.309, Test loss: 0.442, Test accuracy: 82.10
Round  86, Train loss: 0.298, Test loss: 0.427, Test accuracy: 82.93
Round  87, Train loss: 0.276, Test loss: 0.426, Test accuracy: 82.83
Round  88, Train loss: 0.295, Test loss: 0.430, Test accuracy: 82.77
Round  89, Train loss: 0.320, Test loss: 0.432, Test accuracy: 82.07
Round  90, Train loss: 0.276, Test loss: 0.433, Test accuracy: 82.43
Round  91, Train loss: 0.331, Test loss: 0.428, Test accuracy: 82.73
Round  92, Train loss: 0.311, Test loss: 0.435, Test accuracy: 82.57
Round  93, Train loss: 0.302, Test loss: 0.424, Test accuracy: 82.97
Round  94, Train loss: 0.308, Test loss: 0.430, Test accuracy: 82.68
Round  95, Train loss: 0.308, Test loss: 0.426, Test accuracy: 82.88
Round  96, Train loss: 0.307, Test loss: 0.426, Test accuracy: 83.07
Round  97, Train loss: 0.342, Test loss: 0.429, Test accuracy: 82.97
Round  98, Train loss: 0.238, Test loss: 0.428, Test accuracy: 83.20
Round  99, Train loss: 0.295, Test loss: 0.424, Test accuracy: 83.17
Final Round, Train loss: 0.244, Test loss: 0.426, Test accuracy: 83.43
Average accuracy final 10 rounds: 82.86666666666667
780.0233175754547
[1.300788164138794, 2.4651377201080322, 3.5607995986938477, 4.52777886390686, 5.460642099380493, 6.429641008377075, 7.35741400718689, 8.282326221466064, 9.203938245773315, 10.163306951522827, 11.247402429580688, 12.155198812484741, 13.053593873977661, 14.026211023330688, 14.964627504348755, 15.947742700576782, 16.877898693084717, 17.81478524208069, 18.736674785614014, 19.61599326133728, 20.509805917739868, 21.421892166137695, 22.337151288986206, 23.34601330757141, 24.40044355392456, 25.485062837600708, 26.477519035339355, 27.377612829208374, 28.279811143875122, 29.201196908950806, 30.128708362579346, 31.19684624671936, 32.35898756980896, 33.419193506240845, 34.55125141143799, 35.57866382598877, 36.50751781463623, 37.45289206504822, 38.36066699028015, 39.284995555877686, 40.23381423950195, 41.206130504608154, 42.1568603515625, 43.03667235374451, 43.92552089691162, 44.851001024246216, 45.82984900474548, 46.87753987312317, 47.85805058479309, 48.84288692474365, 49.77326011657715, 50.65478515625, 51.52179503440857, 52.40585684776306, 53.27079892158508, 54.257994174957275, 55.288594007492065, 56.29530739784241, 57.322818994522095, 58.23343062400818, 59.15248250961304, 60.06042289733887, 60.95078444480896, 61.86801290512085, 62.798699617385864, 63.792847633361816, 64.74819946289062, 65.65506029129028, 66.59042882919312, 67.53320097923279, 68.48730087280273, 69.47818279266357, 70.4448344707489, 71.41826629638672, 72.37969326972961, 73.25191378593445, 74.15288209915161, 75.03777623176575, 75.92138528823853, 76.92090463638306, 77.98110270500183, 78.94918608665466, 80.02044868469238, 80.98313498497009, 81.89976716041565, 82.76783895492554, 83.64134693145752, 84.59058213233948, 85.52156925201416, 86.46166491508484, 87.4066002368927, 88.30170464515686, 89.24750328063965, 90.19625902175903, 91.12641096115112, 92.21171116828918, 93.1847231388092, 94.11184453964233, 95.0780382156372, 95.98325681686401, 97.46196341514587]
[25.883333333333333, 37.86666666666667, 46.4, 49.38333333333333, 52.88333333333333, 60.56666666666667, 61.75, 65.93333333333334, 68.35, 69.58333333333333, 68.35, 72.83333333333333, 73.38333333333334, 74.23333333333333, 74.68333333333334, 75.51666666666667, 75.06666666666666, 75.5, 75.68333333333334, 75.33333333333333, 75.15, 74.98333333333333, 74.48333333333333, 75.38333333333334, 76.0, 75.95, 76.03333333333333, 76.95, 76.71666666666667, 77.53333333333333, 77.6, 77.03333333333333, 77.45, 77.81666666666666, 78.35, 78.75, 78.3, 79.18333333333334, 79.35, 79.16666666666667, 78.48333333333333, 78.75, 78.9, 79.41666666666667, 79.48333333333333, 79.25, 80.3, 80.06666666666666, 80.45, 80.25, 80.13333333333334, 79.91666666666667, 80.58333333333333, 80.85, 80.2, 80.66666666666667, 81.36666666666666, 80.61666666666666, 81.1, 81.18333333333334, 81.51666666666667, 81.06666666666666, 81.7, 82.16666666666667, 81.76666666666667, 81.56666666666666, 81.61666666666666, 81.56666666666666, 81.8, 81.75, 81.68333333333334, 80.96666666666667, 81.91666666666667, 81.96666666666667, 82.13333333333334, 82.1, 82.13333333333334, 82.35, 82.65, 82.61666666666666, 82.65, 82.28333333333333, 82.61666666666666, 82.63333333333334, 82.65, 82.1, 82.93333333333334, 82.83333333333333, 82.76666666666667, 82.06666666666666, 82.43333333333334, 82.73333333333333, 82.56666666666666, 82.96666666666667, 82.68333333333334, 82.88333333333334, 83.06666666666666, 82.96666666666667, 83.2, 83.16666666666667, 83.43333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.687, Test loss: 2.274, Test accuracy: 20.28
Round   1, Train loss: 1.048, Test loss: 1.644, Test accuracy: 34.52
Round   2, Train loss: 0.899, Test loss: 1.551, Test accuracy: 43.15
Round   3, Train loss: 0.889, Test loss: 1.283, Test accuracy: 48.33
Round   4, Train loss: 0.795, Test loss: 1.323, Test accuracy: 51.35
Round   5, Train loss: 0.785, Test loss: 1.149, Test accuracy: 55.77
Round   6, Train loss: 0.773, Test loss: 0.910, Test accuracy: 63.32
Round   7, Train loss: 0.661, Test loss: 1.071, Test accuracy: 62.43
Round   8, Train loss: 0.736, Test loss: 0.933, Test accuracy: 65.38
Round   9, Train loss: 0.763, Test loss: 0.672, Test accuracy: 72.12
Round  10, Train loss: 0.652, Test loss: 0.646, Test accuracy: 72.53
Round  11, Train loss: 0.646, Test loss: 0.649, Test accuracy: 71.75
Round  12, Train loss: 0.688, Test loss: 0.621, Test accuracy: 73.73
Round  13, Train loss: 0.617, Test loss: 0.611, Test accuracy: 73.98
Round  14, Train loss: 0.580, Test loss: 0.595, Test accuracy: 74.92
Round  15, Train loss: 0.545, Test loss: 0.600, Test accuracy: 74.60
Round  16, Train loss: 0.696, Test loss: 0.588, Test accuracy: 73.82
Round  17, Train loss: 0.587, Test loss: 0.578, Test accuracy: 74.63
Round  18, Train loss: 0.598, Test loss: 0.571, Test accuracy: 75.72
Round  19, Train loss: 0.611, Test loss: 0.568, Test accuracy: 75.88
Round  20, Train loss: 0.582, Test loss: 0.568, Test accuracy: 75.78
Round  21, Train loss: 0.567, Test loss: 0.557, Test accuracy: 76.05
Round  22, Train loss: 0.643, Test loss: 0.563, Test accuracy: 75.63
Round  23, Train loss: 0.551, Test loss: 0.548, Test accuracy: 76.35
Round  24, Train loss: 0.470, Test loss: 0.541, Test accuracy: 76.70
Round  25, Train loss: 0.576, Test loss: 0.537, Test accuracy: 76.87
Round  26, Train loss: 0.558, Test loss: 0.534, Test accuracy: 76.97
Round  27, Train loss: 0.560, Test loss: 0.531, Test accuracy: 77.48
Round  28, Train loss: 0.550, Test loss: 0.522, Test accuracy: 78.08
Round  29, Train loss: 0.489, Test loss: 0.526, Test accuracy: 77.78
Round  30, Train loss: 0.474, Test loss: 0.518, Test accuracy: 78.05
Round  31, Train loss: 0.549, Test loss: 0.512, Test accuracy: 78.18
Round  32, Train loss: 0.441, Test loss: 0.519, Test accuracy: 77.95
Round  33, Train loss: 0.613, Test loss: 0.514, Test accuracy: 78.17
Round  34, Train loss: 0.480, Test loss: 0.516, Test accuracy: 77.60
Round  35, Train loss: 0.477, Test loss: 0.505, Test accuracy: 78.20
Round  36, Train loss: 0.486, Test loss: 0.493, Test accuracy: 78.98
Round  37, Train loss: 0.468, Test loss: 0.497, Test accuracy: 79.17
Round  38, Train loss: 0.514, Test loss: 0.503, Test accuracy: 78.85
Round  39, Train loss: 0.469, Test loss: 0.495, Test accuracy: 79.40
Round  40, Train loss: 0.439, Test loss: 0.496, Test accuracy: 79.25
Round  41, Train loss: 0.517, Test loss: 0.487, Test accuracy: 80.08
Round  42, Train loss: 0.457, Test loss: 0.491, Test accuracy: 80.27
Round  43, Train loss: 0.418, Test loss: 0.480, Test accuracy: 80.83
Round  44, Train loss: 0.425, Test loss: 0.471, Test accuracy: 80.73
Round  45, Train loss: 0.445, Test loss: 0.473, Test accuracy: 80.58
Round  46, Train loss: 0.437, Test loss: 0.467, Test accuracy: 81.32
Round  47, Train loss: 0.465, Test loss: 0.465, Test accuracy: 81.18
Round  48, Train loss: 0.392, Test loss: 0.473, Test accuracy: 80.65
Round  49, Train loss: 0.467, Test loss: 0.472, Test accuracy: 80.72
Round  50, Train loss: 0.393, Test loss: 0.461, Test accuracy: 81.45
Round  51, Train loss: 0.391, Test loss: 0.462, Test accuracy: 80.67
Round  52, Train loss: 0.379, Test loss: 0.457, Test accuracy: 81.28
Round  53, Train loss: 0.483, Test loss: 0.456, Test accuracy: 81.22
Round  54, Train loss: 0.436, Test loss: 0.465, Test accuracy: 80.77
Round  55, Train loss: 0.451, Test loss: 0.450, Test accuracy: 81.85
Round  56, Train loss: 0.464, Test loss: 0.449, Test accuracy: 81.78
Round  57, Train loss: 0.426, Test loss: 0.459, Test accuracy: 81.23
Round  58, Train loss: 0.398, Test loss: 0.453, Test accuracy: 82.00
Round  59, Train loss: 0.406, Test loss: 0.453, Test accuracy: 81.57
Round  60, Train loss: 0.424, Test loss: 0.448, Test accuracy: 81.47
Round  61, Train loss: 0.372, Test loss: 0.445, Test accuracy: 82.02
Round  62, Train loss: 0.364, Test loss: 0.444, Test accuracy: 82.13
Round  63, Train loss: 0.317, Test loss: 0.444, Test accuracy: 81.97
Round  64, Train loss: 0.328, Test loss: 0.437, Test accuracy: 82.15
Round  65, Train loss: 0.371, Test loss: 0.441, Test accuracy: 82.17
Round  66, Train loss: 0.366, Test loss: 0.439, Test accuracy: 82.27
Round  67, Train loss: 0.384, Test loss: 0.442, Test accuracy: 82.13
Round  68, Train loss: 0.293, Test loss: 0.435, Test accuracy: 82.42
Round  69, Train loss: 0.338, Test loss: 0.436, Test accuracy: 82.52
Round  70, Train loss: 0.331, Test loss: 0.443, Test accuracy: 82.23
Round  71, Train loss: 0.369, Test loss: 0.438, Test accuracy: 82.08
Round  72, Train loss: 0.412, Test loss: 0.443, Test accuracy: 81.77
Round  73, Train loss: 0.411, Test loss: 0.436, Test accuracy: 82.22
Round  74, Train loss: 0.324, Test loss: 0.442, Test accuracy: 81.97
Round  75, Train loss: 0.322, Test loss: 0.431, Test accuracy: 82.65
Round  76, Train loss: 0.280, Test loss: 0.428, Test accuracy: 82.80
Round  77, Train loss: 0.315, Test loss: 0.424, Test accuracy: 82.87
Round  78, Train loss: 0.260, Test loss: 0.435, Test accuracy: 82.67
Round  79, Train loss: 0.348, Test loss: 0.423, Test accuracy: 83.07
Round  80, Train loss: 0.417, Test loss: 0.417, Test accuracy: 83.20
Round  81, Train loss: 0.336, Test loss: 0.427, Test accuracy: 83.17
Round  82, Train loss: 0.319, Test loss: 0.437, Test accuracy: 82.67
Round  83, Train loss: 0.381, Test loss: 0.436, Test accuracy: 82.65
Round  84, Train loss: 0.289, Test loss: 0.429, Test accuracy: 83.07
Round  85, Train loss: 0.312, Test loss: 0.425, Test accuracy: 82.82
Round  86, Train loss: 0.334, Test loss: 0.423, Test accuracy: 83.08
Round  87, Train loss: 0.266, Test loss: 0.431, Test accuracy: 82.62
Round  88, Train loss: 0.303, Test loss: 0.431, Test accuracy: 82.98
Round  89, Train loss: 0.298, Test loss: 0.437, Test accuracy: 82.85
Round  90, Train loss: 0.289, Test loss: 0.427, Test accuracy: 83.03
Round  91, Train loss: 0.257, Test loss: 0.424, Test accuracy: 83.27
Round  92, Train loss: 0.300, Test loss: 0.426, Test accuracy: 83.28
Round  93, Train loss: 0.270, Test loss: 0.424, Test accuracy: 83.50
Round  94, Train loss: 0.255, Test loss: 0.420, Test accuracy: 83.48
Round  95, Train loss: 0.314, Test loss: 0.421, Test accuracy: 83.63
Round  96, Train loss: 0.309, Test loss: 0.429, Test accuracy: 83.13
Round  97, Train loss: 0.238, Test loss: 0.424, Test accuracy: 83.52
Round  98, Train loss: 0.360, Test loss: 0.433, Test accuracy: 82.93
Round  99, Train loss: 0.243, Test loss: 0.425, Test accuracy: 83.07
Final Round, Train loss: 0.239, Test loss: 0.427, Test accuracy: 83.45
Average accuracy final 10 rounds: 83.28500000000001
1451.4264225959778
[1.2893550395965576, 2.297577381134033, 3.2921712398529053, 4.256079912185669, 5.1805784702301025, 6.092287540435791, 7.035178899765015, 8.016704559326172, 8.969711303710938, 10.047600746154785, 10.9682776927948, 11.931177854537964, 12.949951410293579, 13.9205961227417, 14.931360721588135, 15.978999853134155, 17.010324239730835, 18.109452962875366, 19.098565816879272, 20.096813201904297, 21.024599075317383, 23.82839059829712, 26.588149070739746, 29.19529104232788, 31.35372829437256, 34.06213092803955, 36.830302476882935, 39.20733070373535, 41.70789337158203, 44.40595054626465, 46.923431396484375, 49.24772095680237, 51.93760585784912, 54.72639489173889, 56.86892294883728, 59.054903507232666, 61.67082095146179, 64.45463538169861, 67.0380072593689, 69.4931845664978, 72.10589933395386, 74.74554824829102, 77.25981855392456, 79.79546213150024, 82.78883528709412, 85.13723707199097, 87.21200656890869, 90.04956293106079, 92.82163095474243, 95.31521701812744, 97.44636130332947, 100.00315809249878, 102.43493890762329, 104.91889977455139, 107.72271847724915, 110.51421737670898, 112.89645195007324, 115.04713368415833, 117.78950643539429, 120.71235752105713, 123.20311999320984, 125.38943243026733, 128.10439443588257, 130.92109847068787, 133.36536765098572, 136.11204266548157, 138.58305621147156, 141.14915132522583, 143.64378261566162, 146.37151551246643, 149.03871393203735, 151.41571617126465, 153.45954489707947, 155.8697898387909, 158.62741613388062, 161.05719256401062, 163.54195594787598, 165.99290680885315, 168.4146707057953, 170.65740156173706, 173.18710803985596, 175.97780394554138, 178.1397190093994, 180.28068733215332, 182.74394822120667, 185.5513153076172, 187.84724593162537, 190.3221950531006, 192.80614471435547, 195.22787380218506, 197.5773663520813, 199.9824287891388, 202.8710060119629, 205.4291021823883, 207.5645248889923, 209.95727276802063, 212.665944814682, 215.27052092552185, 217.63457536697388, 220.15358090400696, 221.56914138793945]
[20.283333333333335, 34.516666666666666, 43.15, 48.333333333333336, 51.35, 55.766666666666666, 63.31666666666667, 62.43333333333333, 65.38333333333334, 72.11666666666666, 72.53333333333333, 71.75, 73.73333333333333, 73.98333333333333, 74.91666666666667, 74.6, 73.81666666666666, 74.63333333333334, 75.71666666666667, 75.88333333333334, 75.78333333333333, 76.05, 75.63333333333334, 76.35, 76.7, 76.86666666666666, 76.96666666666667, 77.48333333333333, 78.08333333333333, 77.78333333333333, 78.05, 78.18333333333334, 77.95, 78.16666666666667, 77.6, 78.2, 78.98333333333333, 79.16666666666667, 78.85, 79.4, 79.25, 80.08333333333333, 80.26666666666667, 80.83333333333333, 80.73333333333333, 80.58333333333333, 81.31666666666666, 81.18333333333334, 80.65, 80.71666666666667, 81.45, 80.66666666666667, 81.28333333333333, 81.21666666666667, 80.76666666666667, 81.85, 81.78333333333333, 81.23333333333333, 82.0, 81.56666666666666, 81.46666666666667, 82.01666666666667, 82.13333333333334, 81.96666666666667, 82.15, 82.16666666666667, 82.26666666666667, 82.13333333333334, 82.41666666666667, 82.51666666666667, 82.23333333333333, 82.08333333333333, 81.76666666666667, 82.21666666666667, 81.96666666666667, 82.65, 82.8, 82.86666666666666, 82.66666666666667, 83.06666666666666, 83.2, 83.16666666666667, 82.66666666666667, 82.65, 83.06666666666666, 82.81666666666666, 83.08333333333333, 82.61666666666666, 82.98333333333333, 82.85, 83.03333333333333, 83.26666666666667, 83.28333333333333, 83.5, 83.48333333333333, 83.63333333333334, 83.13333333333334, 83.51666666666667, 82.93333333333334, 83.06666666666666, 83.45]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 12, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.228, Test loss: 2.075, Test accuracy: 17.22
Round   0, Global train loss: 1.228, Global test loss: 2.395, Global test accuracy: 10.00
Round   1, Train loss: 1.058, Test loss: 1.483, Test accuracy: 38.87
Round   1, Global train loss: 1.058, Global test loss: 2.111, Global test accuracy: 24.43
Round   2, Train loss: 0.881, Test loss: 1.373, Test accuracy: 43.77
Round   2, Global train loss: 0.881, Global test loss: 2.119, Global test accuracy: 25.87
Round   3, Train loss: 0.917, Test loss: 1.102, Test accuracy: 52.85
Round   3, Global train loss: 0.917, Global test loss: 2.149, Global test accuracy: 21.68
Round   4, Train loss: 0.930, Test loss: 0.967, Test accuracy: 57.67
Round   4, Global train loss: 0.930, Global test loss: 2.082, Global test accuracy: 27.75
Round   5, Train loss: 0.781, Test loss: 0.947, Test accuracy: 59.27
Round   5, Global train loss: 0.781, Global test loss: 2.096, Global test accuracy: 30.55
Round   6, Train loss: 0.765, Test loss: 1.065, Test accuracy: 57.87
Round   6, Global train loss: 0.765, Global test loss: 2.668, Global test accuracy: 20.33
Round   7, Train loss: 0.781, Test loss: 0.900, Test accuracy: 60.60
Round   7, Global train loss: 0.781, Global test loss: 2.139, Global test accuracy: 23.65
Round   8, Train loss: 0.729, Test loss: 0.881, Test accuracy: 61.70
Round   8, Global train loss: 0.729, Global test loss: 2.066, Global test accuracy: 25.67
Round   9, Train loss: 0.773, Test loss: 0.774, Test accuracy: 64.65
Round   9, Global train loss: 0.773, Global test loss: 2.092, Global test accuracy: 23.50
Round  10, Train loss: 0.789, Test loss: 0.745, Test accuracy: 66.08
Round  10, Global train loss: 0.789, Global test loss: 2.216, Global test accuracy: 20.00
Round  11, Train loss: 0.666, Test loss: 0.736, Test accuracy: 67.25
Round  11, Global train loss: 0.666, Global test loss: 2.181, Global test accuracy: 25.68
Round  12, Train loss: 0.733, Test loss: 0.731, Test accuracy: 67.98
Round  12, Global train loss: 0.733, Global test loss: 2.126, Global test accuracy: 25.17
Round  13, Train loss: 0.701, Test loss: 0.713, Test accuracy: 68.87
Round  13, Global train loss: 0.701, Global test loss: 2.209, Global test accuracy: 20.55
Round  14, Train loss: 0.669, Test loss: 0.713, Test accuracy: 69.23
Round  14, Global train loss: 0.669, Global test loss: 2.212, Global test accuracy: 20.27
Round  15, Train loss: 0.653, Test loss: 0.710, Test accuracy: 69.90
Round  15, Global train loss: 0.653, Global test loss: 2.101, Global test accuracy: 26.63
Round  16, Train loss: 0.578, Test loss: 0.700, Test accuracy: 70.32
Round  16, Global train loss: 0.578, Global test loss: 1.997, Global test accuracy: 31.37
Round  17, Train loss: 0.545, Test loss: 0.691, Test accuracy: 70.97
Round  17, Global train loss: 0.545, Global test loss: 2.270, Global test accuracy: 20.67
Round  18, Train loss: 0.664, Test loss: 0.699, Test accuracy: 70.37
Round  18, Global train loss: 0.664, Global test loss: 2.020, Global test accuracy: 28.12
Round  19, Train loss: 0.623, Test loss: 0.691, Test accuracy: 71.00
Round  19, Global train loss: 0.623, Global test loss: 2.070, Global test accuracy: 27.67
Round  20, Train loss: 0.573, Test loss: 0.676, Test accuracy: 71.82
Round  20, Global train loss: 0.573, Global test loss: 2.267, Global test accuracy: 23.87
Round  21, Train loss: 0.548, Test loss: 0.676, Test accuracy: 71.90
Round  21, Global train loss: 0.548, Global test loss: 2.094, Global test accuracy: 21.47
Round  22, Train loss: 0.618, Test loss: 0.669, Test accuracy: 72.55
Round  22, Global train loss: 0.618, Global test loss: 2.160, Global test accuracy: 25.80
Round  23, Train loss: 0.497, Test loss: 0.669, Test accuracy: 73.07
Round  23, Global train loss: 0.497, Global test loss: 1.945, Global test accuracy: 30.22
Round  24, Train loss: 0.515, Test loss: 0.677, Test accuracy: 73.12
Round  24, Global train loss: 0.515, Global test loss: 2.108, Global test accuracy: 26.00
Round  25, Train loss: 0.502, Test loss: 0.699, Test accuracy: 72.42
Round  25, Global train loss: 0.502, Global test loss: 2.124, Global test accuracy: 25.58
Round  26, Train loss: 0.474, Test loss: 0.710, Test accuracy: 71.73
Round  26, Global train loss: 0.474, Global test loss: 2.043, Global test accuracy: 27.12
Round  27, Train loss: 0.516, Test loss: 0.693, Test accuracy: 73.20
Round  27, Global train loss: 0.516, Global test loss: 1.959, Global test accuracy: 33.45
Round  28, Train loss: 0.559, Test loss: 0.696, Test accuracy: 73.10
Round  28, Global train loss: 0.559, Global test loss: 2.309, Global test accuracy: 21.75
Round  29, Train loss: 0.424, Test loss: 0.700, Test accuracy: 73.00
Round  29, Global train loss: 0.424, Global test loss: 2.166, Global test accuracy: 26.20
Round  30, Train loss: 0.458, Test loss: 0.702, Test accuracy: 73.02
Round  30, Global train loss: 0.458, Global test loss: 2.144, Global test accuracy: 24.37
Round  31, Train loss: 0.498, Test loss: 0.715, Test accuracy: 73.00
Round  31, Global train loss: 0.498, Global test loss: 2.208, Global test accuracy: 28.63
Round  32, Train loss: 0.432, Test loss: 0.730, Test accuracy: 72.75
Round  32, Global train loss: 0.432, Global test loss: 2.081, Global test accuracy: 28.15
Round  33, Train loss: 0.328, Test loss: 0.729, Test accuracy: 73.82
Round  33, Global train loss: 0.328, Global test loss: 2.091, Global test accuracy: 22.37
Round  34, Train loss: 0.440, Test loss: 0.742, Test accuracy: 73.90
Round  34, Global train loss: 0.440, Global test loss: 2.070, Global test accuracy: 30.10
Round  35, Train loss: 0.397, Test loss: 0.754, Test accuracy: 73.50
Round  35, Global train loss: 0.397, Global test loss: 2.193, Global test accuracy: 27.98
Round  36, Train loss: 0.372, Test loss: 0.732, Test accuracy: 73.72
Round  36, Global train loss: 0.372, Global test loss: 2.537, Global test accuracy: 21.42
Round  37, Train loss: 0.423, Test loss: 0.716, Test accuracy: 73.98
Round  37, Global train loss: 0.423, Global test loss: 2.187, Global test accuracy: 24.82
Round  38, Train loss: 0.381, Test loss: 0.726, Test accuracy: 74.43
Round  38, Global train loss: 0.381, Global test loss: 2.058, Global test accuracy: 25.50
Round  39, Train loss: 0.334, Test loss: 0.703, Test accuracy: 74.80
Round  39, Global train loss: 0.334, Global test loss: 2.225, Global test accuracy: 25.05
Round  40, Train loss: 0.342, Test loss: 0.730, Test accuracy: 74.50
Round  40, Global train loss: 0.342, Global test loss: 1.963, Global test accuracy: 34.92
Round  41, Train loss: 0.335, Test loss: 0.718, Test accuracy: 75.08
Round  41, Global train loss: 0.335, Global test loss: 1.973, Global test accuracy: 29.83
Round  42, Train loss: 0.265, Test loss: 0.735, Test accuracy: 75.07
Round  42, Global train loss: 0.265, Global test loss: 1.865, Global test accuracy: 34.90
Round  43, Train loss: 0.323, Test loss: 0.751, Test accuracy: 75.10
Round  43, Global train loss: 0.323, Global test loss: 2.145, Global test accuracy: 25.33
Round  44, Train loss: 0.269, Test loss: 0.752, Test accuracy: 74.97
Round  44, Global train loss: 0.269, Global test loss: 1.979, Global test accuracy: 30.00
Round  45, Train loss: 0.359, Test loss: 0.766, Test accuracy: 75.05
Round  45, Global train loss: 0.359, Global test loss: 2.047, Global test accuracy: 33.82
Round  46, Train loss: 0.428, Test loss: 0.778, Test accuracy: 74.78
Round  46, Global train loss: 0.428, Global test loss: 2.160, Global test accuracy: 20.98
Round  47, Train loss: 0.350, Test loss: 0.778, Test accuracy: 74.97
Round  47, Global train loss: 0.350, Global test loss: 2.028, Global test accuracy: 26.23
Round  48, Train loss: 0.250, Test loss: 0.812, Test accuracy: 74.00
Round  48, Global train loss: 0.250, Global test loss: 1.997, Global test accuracy: 28.77
Round  49, Train loss: 0.236, Test loss: 0.822, Test accuracy: 73.95
Round  49, Global train loss: 0.236, Global test loss: 2.063, Global test accuracy: 27.55
Round  50, Train loss: 0.257, Test loss: 0.809, Test accuracy: 74.53
Round  50, Global train loss: 0.257, Global test loss: 2.256, Global test accuracy: 24.52
Round  51, Train loss: 0.216, Test loss: 0.812, Test accuracy: 74.40
Round  51, Global train loss: 0.216, Global test loss: 2.000, Global test accuracy: 31.67
Round  52, Train loss: 0.329, Test loss: 0.809, Test accuracy: 75.15
Round  52, Global train loss: 0.329, Global test loss: 2.005, Global test accuracy: 30.30
Round  53, Train loss: 0.256, Test loss: 0.842, Test accuracy: 74.77
Round  53, Global train loss: 0.256, Global test loss: 2.113, Global test accuracy: 20.38
Round  54, Train loss: 0.224, Test loss: 0.838, Test accuracy: 75.10
Round  54, Global train loss: 0.224, Global test loss: 2.088, Global test accuracy: 24.52
Round  55, Train loss: 0.191, Test loss: 0.839, Test accuracy: 74.97
Round  55, Global train loss: 0.191, Global test loss: 2.163, Global test accuracy: 24.73
Round  56, Train loss: 0.255, Test loss: 0.844, Test accuracy: 74.75
Round  56, Global train loss: 0.255, Global test loss: 2.022, Global test accuracy: 30.18
Round  57, Train loss: 0.286, Test loss: 0.854, Test accuracy: 74.38
Round  57, Global train loss: 0.286, Global test loss: 2.150, Global test accuracy: 24.20
Round  58, Train loss: 0.211, Test loss: 0.868, Test accuracy: 74.63
Round  58, Global train loss: 0.211, Global test loss: 2.559, Global test accuracy: 25.82
Round  59, Train loss: 0.169, Test loss: 0.886, Test accuracy: 74.52
Round  59, Global train loss: 0.169, Global test loss: 1.976, Global test accuracy: 31.22
Round  60, Train loss: 0.169, Test loss: 0.871, Test accuracy: 74.73
Round  60, Global train loss: 0.169, Global test loss: 2.137, Global test accuracy: 22.98
Round  61, Train loss: 0.183, Test loss: 0.900, Test accuracy: 74.72
Round  61, Global train loss: 0.183, Global test loss: 2.082, Global test accuracy: 25.35
Round  62, Train loss: 0.237, Test loss: 0.896, Test accuracy: 74.97
Round  62, Global train loss: 0.237, Global test loss: 2.453, Global test accuracy: 17.88
Round  63, Train loss: 0.134, Test loss: 0.921, Test accuracy: 74.80
Round  63, Global train loss: 0.134, Global test loss: 2.312, Global test accuracy: 29.37
Round  64, Train loss: 0.143, Test loss: 0.963, Test accuracy: 74.35
Round  64, Global train loss: 0.143, Global test loss: 2.175, Global test accuracy: 23.42
Round  65, Train loss: 0.143, Test loss: 0.968, Test accuracy: 74.88
Round  65, Global train loss: 0.143, Global test loss: 2.506, Global test accuracy: 22.58
Round  66, Train loss: 0.135, Test loss: 0.977, Test accuracy: 75.13
Round  66, Global train loss: 0.135, Global test loss: 2.921, Global test accuracy: 24.08
Round  67, Train loss: 0.158, Test loss: 0.996, Test accuracy: 75.00
Round  67, Global train loss: 0.158, Global test loss: 2.108, Global test accuracy: 27.30
Round  68, Train loss: 0.204, Test loss: 1.017, Test accuracy: 74.90
Round  68, Global train loss: 0.204, Global test loss: 2.084, Global test accuracy: 32.45
Round  69, Train loss: 0.170, Test loss: 0.986, Test accuracy: 75.53
Round  69, Global train loss: 0.170, Global test loss: 2.344, Global test accuracy: 23.33
Round  70, Train loss: 0.209, Test loss: 1.001, Test accuracy: 75.20
Round  70, Global train loss: 0.209, Global test loss: 2.294, Global test accuracy: 23.35
Round  71, Train loss: 0.139, Test loss: 0.994, Test accuracy: 75.22
Round  71, Global train loss: 0.139, Global test loss: 2.105, Global test accuracy: 29.22
Round  72, Train loss: 0.174, Test loss: 0.982, Test accuracy: 75.07
Round  72, Global train loss: 0.174, Global test loss: 2.063, Global test accuracy: 22.93
Round  73, Train loss: 0.168, Test loss: 0.997, Test accuracy: 75.53
Round  73, Global train loss: 0.168, Global test loss: 2.603, Global test accuracy: 16.75
Round  74, Train loss: 0.173, Test loss: 1.025, Test accuracy: 75.20
Round  74, Global train loss: 0.173, Global test loss: 2.053, Global test accuracy: 33.58
Round  75, Train loss: 0.150, Test loss: 1.017, Test accuracy: 75.28
Round  75, Global train loss: 0.150, Global test loss: 2.041, Global test accuracy: 27.80
Round  76, Train loss: 0.186, Test loss: 1.023, Test accuracy: 74.93
Round  76, Global train loss: 0.186, Global test loss: 2.307, Global test accuracy: 17.70
Round  77, Train loss: 0.107, Test loss: 1.036, Test accuracy: 75.05
Round  77, Global train loss: 0.107, Global test loss: 1.889, Global test accuracy: 31.78
Round  78, Train loss: 0.123, Test loss: 1.046, Test accuracy: 75.03
Round  78, Global train loss: 0.123, Global test loss: 2.080, Global test accuracy: 27.28
Round  79, Train loss: 0.110, Test loss: 1.058, Test accuracy: 75.78
Round  79, Global train loss: 0.110, Global test loss: 2.056, Global test accuracy: 25.07
Round  80, Train loss: 0.145, Test loss: 1.084, Test accuracy: 75.78
Round  80, Global train loss: 0.145, Global test loss: 2.358, Global test accuracy: 17.87
Round  81, Train loss: 0.093, Test loss: 1.080, Test accuracy: 75.67
Round  81, Global train loss: 0.093, Global test loss: 1.975, Global test accuracy: 34.20
Round  82, Train loss: 0.078, Test loss: 1.110, Test accuracy: 75.47
Round  82, Global train loss: 0.078, Global test loss: 2.302, Global test accuracy: 28.53
Round  83, Train loss: 0.077, Test loss: 1.111, Test accuracy: 75.57
Round  83, Global train loss: 0.077, Global test loss: 2.072, Global test accuracy: 31.90
Round  84, Train loss: 0.121, Test loss: 1.130, Test accuracy: 76.05
Round  84, Global train loss: 0.121, Global test loss: 2.133, Global test accuracy: 23.15
Round  85, Train loss: 0.092, Test loss: 1.146, Test accuracy: 75.92
Round  85, Global train loss: 0.092, Global test loss: 3.086, Global test accuracy: 25.52
Round  86, Train loss: 0.103, Test loss: 1.191, Test accuracy: 75.57
Round  86, Global train loss: 0.103, Global test loss: 2.007, Global test accuracy: 26.72
Round  87, Train loss: 0.136, Test loss: 1.198, Test accuracy: 75.10
Round  87, Global train loss: 0.136, Global test loss: 2.134, Global test accuracy: 21.23
Round  88, Train loss: 0.110, Test loss: 1.228, Test accuracy: 75.27
Round  88, Global train loss: 0.110, Global test loss: 2.124, Global test accuracy: 30.80
Round  89, Train loss: 0.123, Test loss: 1.239, Test accuracy: 75.05
Round  89, Global train loss: 0.123, Global test loss: 2.163, Global test accuracy: 22.23
Round  90, Train loss: 0.108, Test loss: 1.206, Test accuracy: 75.18
Round  90, Global train loss: 0.108, Global test loss: 2.363, Global test accuracy: 21.02
Round  91, Train loss: 0.114, Test loss: 1.210, Test accuracy: 75.32
Round  91, Global train loss: 0.114, Global test loss: 2.186, Global test accuracy: 13.43
Round  92, Train loss: 0.086, Test loss: 1.213, Test accuracy: 75.38
Round  92, Global train loss: 0.086, Global test loss: 2.734, Global test accuracy: 21.55
Round  93, Train loss: 0.100, Test loss: 1.224, Test accuracy: 75.18
Round  93, Global train loss: 0.100, Global test loss: 2.296, Global test accuracy: 22.52
Round  94, Train loss: 0.113, Test loss: 1.225, Test accuracy: 75.10
Round  94, Global train loss: 0.113, Global test loss: 2.039, Global test accuracy: 30.22
Round  95, Train loss: 0.101, Test loss: 1.187, Test accuracy: 75.88
Round  95, Global train loss: 0.101, Global test loss: 2.211, Global test accuracy: 14.03
Round  96, Train loss: 0.092, Test loss: 1.148, Test accuracy: 76.38
Round  96, Global train loss: 0.092, Global test loss: 2.096, Global test accuracy: 28.83
Round  97, Train loss: 0.085, Test loss: 1.191, Test accuracy: 75.77
Round  97, Global train loss: 0.085, Global test loss: 2.046, Global test accuracy: 28.90
Round  98, Train loss: 0.076, Test loss: 1.197, Test accuracy: 76.10
Round  98, Global train loss: 0.076, Global test loss: 2.374, Global test accuracy: 27.18
Round  99, Train loss: 0.093, Test loss: 1.164, Test accuracy: 76.27
Round  99, Global train loss: 0.093, Global test loss: 2.155, Global test accuracy: 22.57
Final Round, Train loss: 0.070, Test loss: 1.315, Test accuracy: 75.27
Final Round, Global train loss: 0.070, Global test loss: 2.155, Global test accuracy: 22.57
Average accuracy final 10 rounds: 75.65666666666667 

Average global accuracy final 10 rounds: 23.025000000000002 

1072.8522124290466
[1.0229806900024414, 2.045961380004883, 2.831752300262451, 3.6175432205200195, 4.38077712059021, 5.1440110206604, 5.891692638397217, 6.639374256134033, 7.357647180557251, 8.075920104980469, 8.815448999404907, 9.554977893829346, 10.2721426486969, 10.989307403564453, 11.766849994659424, 12.544392585754395, 13.386148929595947, 14.2279052734375, 15.007714033126831, 15.787522792816162, 16.503979921340942, 17.220437049865723, 17.95963740348816, 18.698837757110596, 19.452473402023315, 20.206109046936035, 20.945961952209473, 21.68581485748291, 22.4290771484375, 23.17233943939209, 23.91272258758545, 24.65310573577881, 25.402623414993286, 26.152141094207764, 26.90254497528076, 27.65294885635376, 28.400908946990967, 29.148869037628174, 29.894314289093018, 30.63975954055786, 31.41312575340271, 32.18649196624756, 32.93835639953613, 33.69022083282471, 34.4157829284668, 35.14134502410889, 35.95642805099487, 36.77151107788086, 37.547088623046875, 38.32266616821289, 39.092326164245605, 39.86198616027832, 40.61881160736084, 41.37563705444336, 42.12345886230469, 42.871280670166016, 43.61660146713257, 44.36192226409912, 45.09443020820618, 45.82693815231323, 46.5781991481781, 47.32946014404297, 48.090866565704346, 48.85227298736572, 49.5760817527771, 50.29989051818848, 51.03533625602722, 51.77078199386597, 52.507134675979614, 53.24348735809326, 53.99350881576538, 54.7435302734375, 55.48129630088806, 56.21906232833862, 56.937336921691895, 57.655611515045166, 58.379711627960205, 59.103811740875244, 59.84132432937622, 60.5788369178772, 61.36424899101257, 62.14966106414795, 62.930479764938354, 63.71129846572876, 64.47897481918335, 65.24665117263794, 65.9590835571289, 66.67151594161987, 67.38334083557129, 68.0951657295227, 68.81146812438965, 69.52777051925659, 70.27403473854065, 71.0202989578247, 71.771155834198, 72.52201271057129, 73.34007978439331, 74.15814685821533, 74.91935396194458, 75.68056106567383, 76.4177258014679, 77.15489053726196, 77.89810085296631, 78.64131116867065, 79.39321374893188, 80.14511632919312, 80.90215682983398, 81.65919733047485, 82.36035466194153, 83.0615119934082, 83.7688717842102, 84.4762315750122, 85.24065566062927, 86.00507974624634, 86.78139662742615, 87.55771350860596, 88.33401250839233, 89.11031150817871, 89.8958568572998, 90.6814022064209, 91.40815901756287, 92.13491582870483, 92.90762829780579, 93.68034076690674, 94.4011447429657, 95.12194871902466, 95.88687443733215, 96.65180015563965, 97.44183993339539, 98.23187971115112, 99.02886462211609, 99.82584953308105, 100.59433317184448, 101.36281681060791, 102.12387180328369, 102.88492679595947, 103.67091917991638, 104.45691156387329, 105.21681952476501, 105.97672748565674, 106.75091338157654, 107.52509927749634, 108.26678133010864, 109.00846338272095, 109.75470995903015, 110.50095653533936, 111.26338934898376, 112.02582216262817, 112.80785250663757, 113.58988285064697, 114.36120653152466, 115.13253021240234, 115.89066624641418, 116.64880228042603, 117.34661841392517, 118.04443454742432, 118.75321221351624, 119.46198987960815, 120.22670483589172, 120.9914197921753, 121.78606081008911, 122.58070182800293, 123.3780152797699, 124.17532873153687, 124.919593334198, 125.66385793685913, 126.40218114852905, 127.14050436019897, 127.83663368225098, 128.53276300430298, 129.2732446193695, 130.01372623443604, 130.7795479297638, 131.54536962509155, 132.31395721435547, 133.08254480361938, 133.81016182899475, 134.53777885437012, 135.26841259002686, 135.9990463256836, 136.7534601688385, 137.5078740119934, 138.2594187259674, 139.0109634399414, 139.78545427322388, 140.55994510650635, 141.26862406730652, 141.9773030281067, 142.70417881011963, 143.43105459213257, 144.1336886882782, 144.83632278442383, 145.61607360839844, 146.39582443237305, 147.1770212650299, 147.95821809768677, 148.73737859725952, 149.51653909683228, 150.26158261299133, 151.0066261291504, 152.4738655090332, 153.94110488891602]
[17.216666666666665, 17.216666666666665, 38.86666666666667, 38.86666666666667, 43.766666666666666, 43.766666666666666, 52.85, 52.85, 57.666666666666664, 57.666666666666664, 59.266666666666666, 59.266666666666666, 57.86666666666667, 57.86666666666667, 60.6, 60.6, 61.7, 61.7, 64.65, 64.65, 66.08333333333333, 66.08333333333333, 67.25, 67.25, 67.98333333333333, 67.98333333333333, 68.86666666666666, 68.86666666666666, 69.23333333333333, 69.23333333333333, 69.9, 69.9, 70.31666666666666, 70.31666666666666, 70.96666666666667, 70.96666666666667, 70.36666666666666, 70.36666666666666, 71.0, 71.0, 71.81666666666666, 71.81666666666666, 71.9, 71.9, 72.55, 72.55, 73.06666666666666, 73.06666666666666, 73.11666666666666, 73.11666666666666, 72.41666666666667, 72.41666666666667, 71.73333333333333, 71.73333333333333, 73.2, 73.2, 73.1, 73.1, 73.0, 73.0, 73.01666666666667, 73.01666666666667, 73.0, 73.0, 72.75, 72.75, 73.81666666666666, 73.81666666666666, 73.9, 73.9, 73.5, 73.5, 73.71666666666667, 73.71666666666667, 73.98333333333333, 73.98333333333333, 74.43333333333334, 74.43333333333334, 74.8, 74.8, 74.5, 74.5, 75.08333333333333, 75.08333333333333, 75.06666666666666, 75.06666666666666, 75.1, 75.1, 74.96666666666667, 74.96666666666667, 75.05, 75.05, 74.78333333333333, 74.78333333333333, 74.96666666666667, 74.96666666666667, 74.0, 74.0, 73.95, 73.95, 74.53333333333333, 74.53333333333333, 74.4, 74.4, 75.15, 75.15, 74.76666666666667, 74.76666666666667, 75.1, 75.1, 74.96666666666667, 74.96666666666667, 74.75, 74.75, 74.38333333333334, 74.38333333333334, 74.63333333333334, 74.63333333333334, 74.51666666666667, 74.51666666666667, 74.73333333333333, 74.73333333333333, 74.71666666666667, 74.71666666666667, 74.96666666666667, 74.96666666666667, 74.8, 74.8, 74.35, 74.35, 74.88333333333334, 74.88333333333334, 75.13333333333334, 75.13333333333334, 75.0, 75.0, 74.9, 74.9, 75.53333333333333, 75.53333333333333, 75.2, 75.2, 75.21666666666667, 75.21666666666667, 75.06666666666666, 75.06666666666666, 75.53333333333333, 75.53333333333333, 75.2, 75.2, 75.28333333333333, 75.28333333333333, 74.93333333333334, 74.93333333333334, 75.05, 75.05, 75.03333333333333, 75.03333333333333, 75.78333333333333, 75.78333333333333, 75.78333333333333, 75.78333333333333, 75.66666666666667, 75.66666666666667, 75.46666666666667, 75.46666666666667, 75.56666666666666, 75.56666666666666, 76.05, 76.05, 75.91666666666667, 75.91666666666667, 75.56666666666666, 75.56666666666666, 75.1, 75.1, 75.26666666666667, 75.26666666666667, 75.05, 75.05, 75.18333333333334, 75.18333333333334, 75.31666666666666, 75.31666666666666, 75.38333333333334, 75.38333333333334, 75.18333333333334, 75.18333333333334, 75.1, 75.1, 75.88333333333334, 75.88333333333334, 76.38333333333334, 76.38333333333334, 75.76666666666667, 75.76666666666667, 76.1, 76.1, 76.26666666666667, 76.26666666666667, 75.26666666666667, 75.26666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.218, Test loss: 2.095, Test accuracy: 20.92
Round   0, Global train loss: 1.218, Global test loss: 2.426, Global test accuracy: 13.42
Round   1, Train loss: 1.034, Test loss: 1.487, Test accuracy: 41.22
Round   1, Global train loss: 1.034, Global test loss: 2.113, Global test accuracy: 24.05
Round   2, Train loss: 0.923, Test loss: 1.396, Test accuracy: 44.85
Round   2, Global train loss: 0.923, Global test loss: 2.100, Global test accuracy: 25.80
Round   3, Train loss: 0.888, Test loss: 1.111, Test accuracy: 54.55
Round   3, Global train loss: 0.888, Global test loss: 2.064, Global test accuracy: 27.52
Round   4, Train loss: 0.875, Test loss: 0.941, Test accuracy: 60.45
Round   4, Global train loss: 0.875, Global test loss: 1.924, Global test accuracy: 33.10
Round   5, Train loss: 0.770, Test loss: 0.953, Test accuracy: 61.43
Round   5, Global train loss: 0.770, Global test loss: 1.972, Global test accuracy: 34.02
Round   6, Train loss: 0.722, Test loss: 1.052, Test accuracy: 59.60
Round   6, Global train loss: 0.722, Global test loss: 2.615, Global test accuracy: 23.73
Round   7, Train loss: 0.803, Test loss: 0.836, Test accuracy: 63.93
Round   7, Global train loss: 0.803, Global test loss: 1.967, Global test accuracy: 29.38
Round   8, Train loss: 0.738, Test loss: 0.838, Test accuracy: 64.28
Round   8, Global train loss: 0.738, Global test loss: 1.848, Global test accuracy: 29.35
Round   9, Train loss: 0.765, Test loss: 0.721, Test accuracy: 68.40
Round   9, Global train loss: 0.765, Global test loss: 1.751, Global test accuracy: 34.48
Round  10, Train loss: 0.755, Test loss: 0.713, Test accuracy: 69.68
Round  10, Global train loss: 0.755, Global test loss: 2.094, Global test accuracy: 27.72
Round  11, Train loss: 0.663, Test loss: 0.689, Test accuracy: 70.60
Round  11, Global train loss: 0.663, Global test loss: 1.896, Global test accuracy: 35.70
Round  12, Train loss: 0.713, Test loss: 0.661, Test accuracy: 71.73
Round  12, Global train loss: 0.713, Global test loss: 1.780, Global test accuracy: 35.77
Round  13, Train loss: 0.721, Test loss: 0.655, Test accuracy: 72.38
Round  13, Global train loss: 0.721, Global test loss: 1.744, Global test accuracy: 36.08
Round  14, Train loss: 0.693, Test loss: 0.637, Test accuracy: 73.85
Round  14, Global train loss: 0.693, Global test loss: 1.857, Global test accuracy: 34.82
Round  15, Train loss: 0.702, Test loss: 0.641, Test accuracy: 74.10
Round  15, Global train loss: 0.702, Global test loss: 1.692, Global test accuracy: 36.73
Round  16, Train loss: 0.652, Test loss: 0.642, Test accuracy: 74.00
Round  16, Global train loss: 0.652, Global test loss: 1.614, Global test accuracy: 39.82
Round  17, Train loss: 0.629, Test loss: 0.650, Test accuracy: 73.90
Round  17, Global train loss: 0.629, Global test loss: 2.026, Global test accuracy: 34.42
Round  18, Train loss: 0.689, Test loss: 0.663, Test accuracy: 72.67
Round  18, Global train loss: 0.689, Global test loss: 1.571, Global test accuracy: 40.43
Round  19, Train loss: 0.643, Test loss: 0.650, Test accuracy: 73.10
Round  19, Global train loss: 0.643, Global test loss: 1.609, Global test accuracy: 42.07
Round  20, Train loss: 0.598, Test loss: 0.663, Test accuracy: 72.53
Round  20, Global train loss: 0.598, Global test loss: 1.710, Global test accuracy: 43.90
Round  21, Train loss: 0.624, Test loss: 0.651, Test accuracy: 73.15
Round  21, Global train loss: 0.624, Global test loss: 1.666, Global test accuracy: 39.62
Round  22, Train loss: 0.617, Test loss: 0.668, Test accuracy: 72.82
Round  22, Global train loss: 0.617, Global test loss: 1.662, Global test accuracy: 39.55
Round  23, Train loss: 0.602, Test loss: 0.652, Test accuracy: 74.08
Round  23, Global train loss: 0.602, Global test loss: 1.459, Global test accuracy: 47.77
Round  24, Train loss: 0.553, Test loss: 0.653, Test accuracy: 74.10
Round  24, Global train loss: 0.553, Global test loss: 1.509, Global test accuracy: 47.37
Round  25, Train loss: 0.562, Test loss: 0.592, Test accuracy: 76.10
Round  25, Global train loss: 0.562, Global test loss: 1.607, Global test accuracy: 43.78
Round  26, Train loss: 0.559, Test loss: 0.605, Test accuracy: 75.58
Round  26, Global train loss: 0.559, Global test loss: 1.449, Global test accuracy: 47.13
Round  27, Train loss: 0.584, Test loss: 0.593, Test accuracy: 75.80
Round  27, Global train loss: 0.584, Global test loss: 1.473, Global test accuracy: 46.92
Round  28, Train loss: 0.618, Test loss: 0.593, Test accuracy: 76.08
Round  28, Global train loss: 0.618, Global test loss: 1.969, Global test accuracy: 34.78
Round  29, Train loss: 0.514, Test loss: 0.600, Test accuracy: 76.03
Round  29, Global train loss: 0.514, Global test loss: 1.582, Global test accuracy: 46.07
Round  30, Train loss: 0.523, Test loss: 0.606, Test accuracy: 75.48
Round  30, Global train loss: 0.523, Global test loss: 1.435, Global test accuracy: 48.47
Round  31, Train loss: 0.568, Test loss: 0.614, Test accuracy: 75.62
Round  31, Global train loss: 0.568, Global test loss: 1.516, Global test accuracy: 46.47
Round  32, Train loss: 0.490, Test loss: 0.610, Test accuracy: 75.50
Round  32, Global train loss: 0.490, Global test loss: 1.498, Global test accuracy: 46.25
Round  33, Train loss: 0.468, Test loss: 0.613, Test accuracy: 75.13
Round  33, Global train loss: 0.468, Global test loss: 1.517, Global test accuracy: 45.87
Round  34, Train loss: 0.481, Test loss: 0.575, Test accuracy: 76.95
Round  34, Global train loss: 0.481, Global test loss: 1.465, Global test accuracy: 47.83
Round  35, Train loss: 0.466, Test loss: 0.575, Test accuracy: 77.25
Round  35, Global train loss: 0.466, Global test loss: 1.683, Global test accuracy: 42.47
Round  36, Train loss: 0.427, Test loss: 0.580, Test accuracy: 77.08
Round  36, Global train loss: 0.427, Global test loss: 1.869, Global test accuracy: 40.08
Round  37, Train loss: 0.494, Test loss: 0.570, Test accuracy: 77.55
Round  37, Global train loss: 0.494, Global test loss: 1.616, Global test accuracy: 45.10
Round  38, Train loss: 0.433, Test loss: 0.570, Test accuracy: 77.60
Round  38, Global train loss: 0.433, Global test loss: 1.374, Global test accuracy: 52.30
Round  39, Train loss: 0.448, Test loss: 0.588, Test accuracy: 77.38
Round  39, Global train loss: 0.448, Global test loss: 1.611, Global test accuracy: 45.67
Round  40, Train loss: 0.490, Test loss: 0.588, Test accuracy: 77.32
Round  40, Global train loss: 0.490, Global test loss: 1.287, Global test accuracy: 55.70
Round  41, Train loss: 0.498, Test loss: 0.617, Test accuracy: 76.95
Round  41, Global train loss: 0.498, Global test loss: 1.337, Global test accuracy: 53.38
Round  42, Train loss: 0.452, Test loss: 0.602, Test accuracy: 77.53
Round  42, Global train loss: 0.452, Global test loss: 1.410, Global test accuracy: 50.43
Round  43, Train loss: 0.420, Test loss: 0.593, Test accuracy: 77.47
Round  43, Global train loss: 0.420, Global test loss: 1.508, Global test accuracy: 48.22
Round  44, Train loss: 0.440, Test loss: 0.602, Test accuracy: 77.40
Round  44, Global train loss: 0.440, Global test loss: 1.355, Global test accuracy: 53.33
Round  45, Train loss: 0.452, Test loss: 0.581, Test accuracy: 78.30
Round  45, Global train loss: 0.452, Global test loss: 1.327, Global test accuracy: 54.90
Round  46, Train loss: 0.479, Test loss: 0.570, Test accuracy: 78.88
Round  46, Global train loss: 0.479, Global test loss: 1.525, Global test accuracy: 47.45
Round  47, Train loss: 0.420, Test loss: 0.586, Test accuracy: 78.45
Round  47, Global train loss: 0.420, Global test loss: 1.461, Global test accuracy: 50.70
Round  48, Train loss: 0.391, Test loss: 0.580, Test accuracy: 79.00
Round  48, Global train loss: 0.391, Global test loss: 1.400, Global test accuracy: 51.87
Round  49, Train loss: 0.451, Test loss: 0.615, Test accuracy: 77.87
Round  49, Global train loss: 0.451, Global test loss: 1.366, Global test accuracy: 51.95
Round  50, Train loss: 0.407, Test loss: 0.598, Test accuracy: 78.37
Round  50, Global train loss: 0.407, Global test loss: 1.523, Global test accuracy: 48.92
Round  51, Train loss: 0.403, Test loss: 0.571, Test accuracy: 79.23
Round  51, Global train loss: 0.403, Global test loss: 1.300, Global test accuracy: 56.62
Round  52, Train loss: 0.442, Test loss: 0.554, Test accuracy: 79.68
Round  52, Global train loss: 0.442, Global test loss: 1.454, Global test accuracy: 50.93
Round  53, Train loss: 0.400, Test loss: 0.558, Test accuracy: 79.35
Round  53, Global train loss: 0.400, Global test loss: 1.356, Global test accuracy: 54.88
Round  54, Train loss: 0.354, Test loss: 0.570, Test accuracy: 79.00
Round  54, Global train loss: 0.354, Global test loss: 1.396, Global test accuracy: 54.27
Round  55, Train loss: 0.338, Test loss: 0.563, Test accuracy: 79.43
Round  55, Global train loss: 0.338, Global test loss: 1.632, Global test accuracy: 48.82
Round  56, Train loss: 0.356, Test loss: 0.550, Test accuracy: 79.97
Round  56, Global train loss: 0.356, Global test loss: 1.443, Global test accuracy: 53.43
Round  57, Train loss: 0.411, Test loss: 0.555, Test accuracy: 80.17
Round  57, Global train loss: 0.411, Global test loss: 1.512, Global test accuracy: 51.80
Round  58, Train loss: 0.347, Test loss: 0.553, Test accuracy: 80.63
Round  58, Global train loss: 0.347, Global test loss: 1.783, Global test accuracy: 46.72
Round  59, Train loss: 0.357, Test loss: 0.556, Test accuracy: 80.80
Round  59, Global train loss: 0.357, Global test loss: 1.365, Global test accuracy: 54.62
Round  60, Train loss: 0.319, Test loss: 0.565, Test accuracy: 80.35
Round  60, Global train loss: 0.319, Global test loss: 1.366, Global test accuracy: 54.20
Round  61, Train loss: 0.339, Test loss: 0.559, Test accuracy: 80.35
Round  61, Global train loss: 0.339, Global test loss: 1.379, Global test accuracy: 54.27
Round  62, Train loss: 0.434, Test loss: 0.566, Test accuracy: 79.80
Round  62, Global train loss: 0.434, Global test loss: 1.600, Global test accuracy: 48.93
Round  63, Train loss: 0.312, Test loss: 0.573, Test accuracy: 79.78
Round  63, Global train loss: 0.312, Global test loss: 1.697, Global test accuracy: 50.63
Round  64, Train loss: 0.331, Test loss: 0.580, Test accuracy: 79.75
Round  64, Global train loss: 0.331, Global test loss: 1.374, Global test accuracy: 55.32
Round  65, Train loss: 0.298, Test loss: 0.572, Test accuracy: 79.95
Round  65, Global train loss: 0.298, Global test loss: 1.328, Global test accuracy: 55.07
Round  66, Train loss: 0.296, Test loss: 0.553, Test accuracy: 80.43
Round  66, Global train loss: 0.296, Global test loss: 1.694, Global test accuracy: 47.77
Round  67, Train loss: 0.376, Test loss: 0.544, Test accuracy: 80.95
Round  67, Global train loss: 0.376, Global test loss: 1.320, Global test accuracy: 55.58
Round  68, Train loss: 0.323, Test loss: 0.555, Test accuracy: 80.40
Round  68, Global train loss: 0.323, Global test loss: 1.467, Global test accuracy: 54.75
Round  69, Train loss: 0.282, Test loss: 0.561, Test accuracy: 80.92
Round  69, Global train loss: 0.282, Global test loss: 1.397, Global test accuracy: 54.50
Round  70, Train loss: 0.333, Test loss: 0.571, Test accuracy: 80.68
Round  70, Global train loss: 0.333, Global test loss: 1.403, Global test accuracy: 53.68
Round  71, Train loss: 0.312, Test loss: 0.550, Test accuracy: 81.08
Round  71, Global train loss: 0.312, Global test loss: 1.516, Global test accuracy: 53.78
Round  72, Train loss: 0.329, Test loss: 0.566, Test accuracy: 80.70
Round  72, Global train loss: 0.329, Global test loss: 1.311, Global test accuracy: 55.47
Round  73, Train loss: 0.352, Test loss: 0.578, Test accuracy: 80.43
Round  73, Global train loss: 0.352, Global test loss: 1.740, Global test accuracy: 49.03
Round  74, Train loss: 0.324, Test loss: 0.576, Test accuracy: 80.52
Round  74, Global train loss: 0.324, Global test loss: 1.316, Global test accuracy: 56.63
Round  75, Train loss: 0.296, Test loss: 0.587, Test accuracy: 80.45
Round  75, Global train loss: 0.296, Global test loss: 1.372, Global test accuracy: 56.45
Round  76, Train loss: 0.358, Test loss: 0.601, Test accuracy: 80.15
Round  76, Global train loss: 0.358, Global test loss: 1.740, Global test accuracy: 48.88
Round  77, Train loss: 0.305, Test loss: 0.606, Test accuracy: 80.00
Round  77, Global train loss: 0.305, Global test loss: 1.383, Global test accuracy: 55.30
Round  78, Train loss: 0.261, Test loss: 0.596, Test accuracy: 80.30
Round  78, Global train loss: 0.261, Global test loss: 1.431, Global test accuracy: 55.98
Round  79, Train loss: 0.276, Test loss: 0.623, Test accuracy: 79.83
Round  79, Global train loss: 0.276, Global test loss: 1.435, Global test accuracy: 55.45
Round  80, Train loss: 0.313, Test loss: 0.596, Test accuracy: 80.33
Round  80, Global train loss: 0.313, Global test loss: 1.893, Global test accuracy: 47.27
Round  81, Train loss: 0.265, Test loss: 0.617, Test accuracy: 79.88
Round  81, Global train loss: 0.265, Global test loss: 1.323, Global test accuracy: 57.75
Round  82, Train loss: 0.270, Test loss: 0.603, Test accuracy: 80.25
Round  82, Global train loss: 0.270, Global test loss: 1.492, Global test accuracy: 54.63
Round  83, Train loss: 0.286, Test loss: 0.587, Test accuracy: 80.82
Round  83, Global train loss: 0.286, Global test loss: 1.354, Global test accuracy: 56.27
Round  84, Train loss: 0.299, Test loss: 0.588, Test accuracy: 80.92
Round  84, Global train loss: 0.299, Global test loss: 1.639, Global test accuracy: 49.73
Round  85, Train loss: 0.266, Test loss: 0.590, Test accuracy: 80.78
Round  85, Global train loss: 0.266, Global test loss: 1.633, Global test accuracy: 50.38
Round  86, Train loss: 0.285, Test loss: 0.572, Test accuracy: 81.27
Round  86, Global train loss: 0.285, Global test loss: 1.315, Global test accuracy: 56.68
Round  87, Train loss: 0.295, Test loss: 0.570, Test accuracy: 81.62
Round  87, Global train loss: 0.295, Global test loss: 1.415, Global test accuracy: 55.47
Round  88, Train loss: 0.276, Test loss: 0.592, Test accuracy: 81.02
Round  88, Global train loss: 0.276, Global test loss: 1.435, Global test accuracy: 54.63
Round  89, Train loss: 0.280, Test loss: 0.614, Test accuracy: 80.62
Round  89, Global train loss: 0.280, Global test loss: 1.546, Global test accuracy: 53.05
Round  90, Train loss: 0.247, Test loss: 0.625, Test accuracy: 80.58
Round  90, Global train loss: 0.247, Global test loss: 1.551, Global test accuracy: 51.60
Round  91, Train loss: 0.293, Test loss: 0.604, Test accuracy: 81.60
Round  91, Global train loss: 0.293, Global test loss: 1.316, Global test accuracy: 57.53
Round  92, Train loss: 0.251, Test loss: 0.608, Test accuracy: 81.45
Round  92, Global train loss: 0.251, Global test loss: 2.024, Global test accuracy: 45.15
Round  93, Train loss: 0.260, Test loss: 0.625, Test accuracy: 81.07
Round  93, Global train loss: 0.260, Global test loss: 1.738, Global test accuracy: 51.62
Round  94, Train loss: 0.279, Test loss: 0.614, Test accuracy: 80.83
Round  94, Global train loss: 0.279, Global test loss: 1.320, Global test accuracy: 57.47
Round  95, Train loss: 0.255, Test loss: 0.627, Test accuracy: 80.60
Round  95, Global train loss: 0.255, Global test loss: 1.823, Global test accuracy: 49.52
Round  96, Train loss: 0.278, Test loss: 0.635, Test accuracy: 80.25
Round  96, Global train loss: 0.278, Global test loss: 1.401, Global test accuracy: 56.52
Round  97, Train loss: 0.239, Test loss: 0.639, Test accuracy: 80.57
Round  97, Global train loss: 0.239, Global test loss: 1.503, Global test accuracy: 53.83
Round  98, Train loss: 0.242, Test loss: 0.620, Test accuracy: 80.97
Round  98, Global train loss: 0.242, Global test loss: 1.827, Global test accuracy: 50.38
Round  99, Train loss: 0.241, Test loss: 0.643, Test accuracy: 80.90
Round  99, Global train loss: 0.241, Global test loss: 1.515, Global test accuracy: 54.67
Final Round, Train loss: 0.190, Test loss: 0.649, Test accuracy: 81.92
Final Round, Global train loss: 0.190, Global test loss: 1.515, Global test accuracy: 54.67
Average accuracy final 10 rounds: 80.88166666666666 

Average global accuracy final 10 rounds: 52.82833333333333 

1167.8036530017853
[1.0815281867980957, 2.1630563735961914, 2.913267135620117, 3.663477897644043, 4.477478504180908, 5.291479110717773, 6.091060400009155, 6.890641689300537, 7.66217303276062, 8.433704376220703, 9.176977634429932, 9.92025089263916, 10.72337532043457, 11.52649974822998, 12.29832148551941, 13.070143222808838, 13.826074838638306, 14.582006454467773, 15.417893171310425, 16.253779888153076, 17.090379238128662, 17.926978588104248, 18.72487235069275, 19.52276611328125, 20.25308632850647, 20.98340654373169, 21.675644874572754, 22.36788320541382, 23.088736295700073, 23.809589385986328, 24.567167282104492, 25.324745178222656, 26.06638741493225, 26.808029651641846, 27.5927996635437, 28.377569675445557, 29.135882139205933, 29.89419460296631, 30.661227226257324, 31.42825984954834, 32.20871543884277, 32.98917102813721, 33.76287031173706, 34.536569595336914, 35.27088499069214, 36.00520038604736, 36.70520734786987, 37.40521430969238, 38.11468172073364, 38.8241491317749, 39.52389311790466, 40.223637104034424, 40.98753619194031, 41.75143527984619, 42.53566336631775, 43.31989145278931, 44.106297731399536, 44.892704010009766, 45.62709140777588, 46.36147880554199, 47.090545654296875, 47.81961250305176, 48.522444009780884, 49.22527551651001, 50.00427985191345, 50.783284187316895, 51.5735239982605, 52.3637638092041, 53.15161967277527, 53.939475536346436, 54.73847508430481, 55.537474632263184, 56.32760047912598, 57.11772632598877, 57.89071226119995, 58.66369819641113, 59.41622567176819, 60.168753147125244, 60.92066717147827, 61.6725811958313, 62.37068438529968, 63.068787574768066, 63.856950998306274, 64.64511442184448, 65.40606880187988, 66.16702318191528, 66.99084877967834, 67.8146743774414, 68.56313467025757, 69.31159496307373, 70.09929776191711, 70.8870005607605, 71.61937522888184, 72.35174989700317, 73.08422327041626, 73.81669664382935, 74.52338600158691, 75.23007535934448, 75.9628415107727, 76.69560766220093, 77.4480528831482, 78.20049810409546, 78.96493935585022, 79.72938060760498, 80.4628837108612, 81.19638681411743, 81.9305944442749, 82.66480207443237, 83.43146467208862, 84.19812726974487, 84.94158744812012, 85.68504762649536, 86.42284774780273, 87.16064786911011, 87.85879254341125, 88.5569372177124, 89.29032802581787, 90.02371883392334, 90.76149702072144, 91.49927520751953, 92.27842545509338, 93.05757570266724, 93.83277940750122, 94.6079831123352, 95.39272475242615, 96.17746639251709, 96.92523884773254, 97.673011302948, 98.45202326774597, 99.23103523254395, 100.02496838569641, 100.81890153884888, 101.66031289100647, 102.50172424316406, 103.33217477798462, 104.16262531280518, 104.99014091491699, 105.81765651702881, 106.63072061538696, 107.44378471374512, 108.24686622619629, 109.04994773864746, 109.85556960105896, 110.66119146347046, 111.44129681587219, 112.22140216827393, 113.01414847373962, 113.80689477920532, 114.51519560813904, 115.22349643707275, 116.00202488899231, 116.78055334091187, 117.56202793121338, 118.34350252151489, 119.16455793380737, 119.98561334609985, 120.80316162109375, 121.62070989608765, 122.47078037261963, 123.32085084915161, 124.15474033355713, 124.98862981796265, 125.79799318313599, 126.60735654830933, 127.3910744190216, 128.1747922897339, 129.02859807014465, 129.88240385055542, 130.70785474777222, 131.533305644989, 132.32318568229675, 133.1130657196045, 133.8997836112976, 134.68650150299072, 135.47015762329102, 136.2538137435913, 137.0376741886139, 137.82153463363647, 138.6169822216034, 139.4124298095703, 140.19274973869324, 140.97306966781616, 141.7862241268158, 142.59937858581543, 143.38069009780884, 144.16200160980225, 145.00335454940796, 145.84470748901367, 146.7401909828186, 147.63567447662354, 148.54540157318115, 149.45512866973877, 150.33731055259705, 151.21949243545532, 152.04787135124207, 152.8762502670288, 153.61162424087524, 154.34699821472168, 155.11361002922058, 155.88022184371948, 157.5015697479248, 159.12291765213013]
[20.916666666666668, 20.916666666666668, 41.21666666666667, 41.21666666666667, 44.85, 44.85, 54.55, 54.55, 60.45, 60.45, 61.43333333333333, 61.43333333333333, 59.6, 59.6, 63.93333333333333, 63.93333333333333, 64.28333333333333, 64.28333333333333, 68.4, 68.4, 69.68333333333334, 69.68333333333334, 70.6, 70.6, 71.73333333333333, 71.73333333333333, 72.38333333333334, 72.38333333333334, 73.85, 73.85, 74.1, 74.1, 74.0, 74.0, 73.9, 73.9, 72.66666666666667, 72.66666666666667, 73.1, 73.1, 72.53333333333333, 72.53333333333333, 73.15, 73.15, 72.81666666666666, 72.81666666666666, 74.08333333333333, 74.08333333333333, 74.1, 74.1, 76.1, 76.1, 75.58333333333333, 75.58333333333333, 75.8, 75.8, 76.08333333333333, 76.08333333333333, 76.03333333333333, 76.03333333333333, 75.48333333333333, 75.48333333333333, 75.61666666666666, 75.61666666666666, 75.5, 75.5, 75.13333333333334, 75.13333333333334, 76.95, 76.95, 77.25, 77.25, 77.08333333333333, 77.08333333333333, 77.55, 77.55, 77.6, 77.6, 77.38333333333334, 77.38333333333334, 77.31666666666666, 77.31666666666666, 76.95, 76.95, 77.53333333333333, 77.53333333333333, 77.46666666666667, 77.46666666666667, 77.4, 77.4, 78.3, 78.3, 78.88333333333334, 78.88333333333334, 78.45, 78.45, 79.0, 79.0, 77.86666666666666, 77.86666666666666, 78.36666666666666, 78.36666666666666, 79.23333333333333, 79.23333333333333, 79.68333333333334, 79.68333333333334, 79.35, 79.35, 79.0, 79.0, 79.43333333333334, 79.43333333333334, 79.96666666666667, 79.96666666666667, 80.16666666666667, 80.16666666666667, 80.63333333333334, 80.63333333333334, 80.8, 80.8, 80.35, 80.35, 80.35, 80.35, 79.8, 79.8, 79.78333333333333, 79.78333333333333, 79.75, 79.75, 79.95, 79.95, 80.43333333333334, 80.43333333333334, 80.95, 80.95, 80.4, 80.4, 80.91666666666667, 80.91666666666667, 80.68333333333334, 80.68333333333334, 81.08333333333333, 81.08333333333333, 80.7, 80.7, 80.43333333333334, 80.43333333333334, 80.51666666666667, 80.51666666666667, 80.45, 80.45, 80.15, 80.15, 80.0, 80.0, 80.3, 80.3, 79.83333333333333, 79.83333333333333, 80.33333333333333, 80.33333333333333, 79.88333333333334, 79.88333333333334, 80.25, 80.25, 80.81666666666666, 80.81666666666666, 80.91666666666667, 80.91666666666667, 80.78333333333333, 80.78333333333333, 81.26666666666667, 81.26666666666667, 81.61666666666666, 81.61666666666666, 81.01666666666667, 81.01666666666667, 80.61666666666666, 80.61666666666666, 80.58333333333333, 80.58333333333333, 81.6, 81.6, 81.45, 81.45, 81.06666666666666, 81.06666666666666, 80.83333333333333, 80.83333333333333, 80.6, 80.6, 80.25, 80.25, 80.56666666666666, 80.56666666666666, 80.96666666666667, 80.96666666666667, 80.9, 80.9, 81.91666666666667, 81.91666666666667]
usage: main_fedrep.py [-h] [--epochs EPOCHS] [--num_users NUM_USERS]
                      [--shard_per_user SHARD_PER_USER] [--frac FRAC]
                      [--local_ep LOCAL_EP] [--local_bs LOCAL_BS] [--bs BS]
                      [--lr LR] [--momentum MOMENTUM] [--split SPLIT]
                      [--grad_norm] [--lr_decay LR_DECAY]
                      [--local_updates LOCAL_UPDATES] [--m_tr M_TR]
                      [--m_ft M_FT] [--model MODEL] [--kernel_num KERNEL_NUM]
                      [--kernel_sizes KERNEL_SIZES] [--norm NORM]
                      [--num_filters NUM_FILTERS] [--max_pool MAX_POOL]
                      [--num_layers_keep NUM_LAYERS_KEEP] [--alg ALG]
                      [--local_rep_ep LOCAL_REP_EP] [--lr_g LR_G] [--mu MU]
                      [--gmf GMF] [--alpha_apfl ALPHA_APFL]
                      [--alpha_l2gd ALPHA_L2GD] [--lambda_l2gd LAMBDA_L2GD]
                      [--lr_in LR_IN] [--bs_frac_in BS_FRAC_IN]
                      [--lam_ditto LAM_DITTO] [--dataset DATASET] [--iid]
                      [--num_classes NUM_CLASSES]
                      [--num_channels NUM_CHANNELS] [--gpu GPU] [--seed SEED]
                      [--test_freq TEST_FREQ] [--load_fed LOAD_FED]
                      [--results_save RESULTS_SAVE] [--save_every SAVE_EVERY]
                      [--pac_param PAC_PARAM]
                      [--is_concept_shift IS_CONCEPT_SHIFT]
                      [--concept_shift_rate CONCEPT_SHIFT_RATE]
                      [--local_only LOCAL_ONLY]
                      [--limit_local_output LIMIT_LOCAL_OUTPUT]
                      [--nums_per_class NUMS_PER_CLASS]
                      [--is_reset_dataset IS_RESET_DATASET]
                      [--is_reset_model IS_RESET_MODEL]
                      [--personal_learning_rate PERSONAL_LEARNING_RATE]
                      [--lamda LAMDA] [--learning_rate LEARNING_RATE]
                      [--print_all PRINT_ALL]
                      [--data_store_file DATA_STORE_FILE]
                      [--level_n_system LEVEL_N_SYSTEM]
                      [--level_n_lowerb LEVEL_N_LOWERB]
                      [--filter_alg FILTER_ALG] [--frac2 FRAC2]
                      [--rounds2 ROUNDS2] [--T_pl T_PL]
                      [--lambda_cen LAMBDA_CEN] [--lambda_e LAMBDA_E]
                      [--num_gradual NUM_GRADUAL] [--forget_rate FORGET_RATE]
                      [--schedule SCHEDULE [SCHEDULE ...]]
                      [--weight_decay WEIGHT_DECAY]
                      [--feature_dim FEATURE_DIM]
main_fedrep.py: error: argument --level_n_system: invalid float value: '0.2--level_n_lowerb'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.744, Test loss: 2.203, Test accuracy: 16.22
Round   1, Train loss: 1.145, Test loss: 1.712, Test accuracy: 33.95
Round   2, Train loss: 0.958, Test loss: 1.589, Test accuracy: 42.33
Round   3, Train loss: 0.923, Test loss: 1.276, Test accuracy: 49.40
Round   4, Train loss: 0.907, Test loss: 1.025, Test accuracy: 56.58
Round   5, Train loss: 0.790, Test loss: 1.036, Test accuracy: 57.37
Round   6, Train loss: 0.742, Test loss: 1.153, Test accuracy: 56.75
Round   7, Train loss: 0.801, Test loss: 0.881, Test accuracy: 62.50
Round   8, Train loss: 0.749, Test loss: 0.852, Test accuracy: 64.03
Round   9, Train loss: 0.727, Test loss: 0.712, Test accuracy: 68.50
Round  10, Train loss: 0.720, Test loss: 0.698, Test accuracy: 69.25
Round  11, Train loss: 0.660, Test loss: 0.686, Test accuracy: 69.40
Round  12, Train loss: 0.722, Test loss: 0.672, Test accuracy: 70.72
Round  13, Train loss: 0.721, Test loss: 0.648, Test accuracy: 72.55
Round  14, Train loss: 0.700, Test loss: 0.638, Test accuracy: 73.65
Round  15, Train loss: 0.653, Test loss: 0.624, Test accuracy: 74.05
Round  16, Train loss: 0.619, Test loss: 0.620, Test accuracy: 74.42
Round  17, Train loss: 0.637, Test loss: 0.616, Test accuracy: 74.98
Round  18, Train loss: 0.644, Test loss: 0.610, Test accuracy: 74.72
Round  19, Train loss: 0.619, Test loss: 0.599, Test accuracy: 74.85
Round  20, Train loss: 0.600, Test loss: 0.585, Test accuracy: 74.92
Round  21, Train loss: 0.609, Test loss: 0.585, Test accuracy: 75.47
Round  22, Train loss: 0.603, Test loss: 0.574, Test accuracy: 75.62
Round  23, Train loss: 0.604, Test loss: 0.565, Test accuracy: 76.12
Round  24, Train loss: 0.553, Test loss: 0.566, Test accuracy: 75.63
Round  25, Train loss: 0.582, Test loss: 0.554, Test accuracy: 76.53
Round  26, Train loss: 0.582, Test loss: 0.545, Test accuracy: 76.65
Round  27, Train loss: 0.566, Test loss: 0.542, Test accuracy: 76.72
Round  28, Train loss: 0.635, Test loss: 0.542, Test accuracy: 76.77
Round  29, Train loss: 0.539, Test loss: 0.536, Test accuracy: 77.87
Round  30, Train loss: 0.515, Test loss: 0.534, Test accuracy: 77.63
Round  31, Train loss: 0.604, Test loss: 0.530, Test accuracy: 77.88
Round  32, Train loss: 0.509, Test loss: 0.521, Test accuracy: 78.12
Round  33, Train loss: 0.465, Test loss: 0.513, Test accuracy: 78.33
Round  34, Train loss: 0.500, Test loss: 0.517, Test accuracy: 77.80
Round  35, Train loss: 0.474, Test loss: 0.503, Test accuracy: 78.42
Round  36, Train loss: 0.476, Test loss: 0.507, Test accuracy: 78.60
Round  37, Train loss: 0.549, Test loss: 0.498, Test accuracy: 79.62
Round  38, Train loss: 0.461, Test loss: 0.496, Test accuracy: 79.15
Round  39, Train loss: 0.452, Test loss: 0.505, Test accuracy: 78.63
Round  40, Train loss: 0.504, Test loss: 0.492, Test accuracy: 79.10
Round  41, Train loss: 0.484, Test loss: 0.490, Test accuracy: 78.92
Round  42, Train loss: 0.461, Test loss: 0.488, Test accuracy: 79.38
Round  43, Train loss: 0.440, Test loss: 0.490, Test accuracy: 79.18
Round  44, Train loss: 0.447, Test loss: 0.495, Test accuracy: 79.18
Round  45, Train loss: 0.483, Test loss: 0.483, Test accuracy: 79.92
Round  46, Train loss: 0.530, Test loss: 0.480, Test accuracy: 80.40
Round  47, Train loss: 0.478, Test loss: 0.470, Test accuracy: 80.50
Round  48, Train loss: 0.420, Test loss: 0.465, Test accuracy: 80.37
Round  49, Train loss: 0.459, Test loss: 0.471, Test accuracy: 81.05
Round  50, Train loss: 0.427, Test loss: 0.473, Test accuracy: 80.70
Round  51, Train loss: 0.427, Test loss: 0.466, Test accuracy: 80.67
Round  52, Train loss: 0.455, Test loss: 0.463, Test accuracy: 81.15
Round  53, Train loss: 0.464, Test loss: 0.457, Test accuracy: 81.18
Round  54, Train loss: 0.374, Test loss: 0.462, Test accuracy: 80.72
Round  55, Train loss: 0.374, Test loss: 0.458, Test accuracy: 81.13
Round  56, Train loss: 0.411, Test loss: 0.457, Test accuracy: 81.27
Round  57, Train loss: 0.455, Test loss: 0.451, Test accuracy: 81.37
Round  58, Train loss: 0.367, Test loss: 0.462, Test accuracy: 80.92
Round  59, Train loss: 0.368, Test loss: 0.454, Test accuracy: 81.50
Round  60, Train loss: 0.355, Test loss: 0.459, Test accuracy: 81.25
Round  61, Train loss: 0.376, Test loss: 0.452, Test accuracy: 81.30
Round  62, Train loss: 0.484, Test loss: 0.451, Test accuracy: 81.20
Round  63, Train loss: 0.333, Test loss: 0.458, Test accuracy: 80.62
Round  64, Train loss: 0.343, Test loss: 0.447, Test accuracy: 81.53
Round  65, Train loss: 0.337, Test loss: 0.447, Test accuracy: 81.55
Round  66, Train loss: 0.330, Test loss: 0.452, Test accuracy: 81.42
Round  67, Train loss: 0.386, Test loss: 0.445, Test accuracy: 81.30
Round  68, Train loss: 0.376, Test loss: 0.443, Test accuracy: 81.63
Round  69, Train loss: 0.312, Test loss: 0.450, Test accuracy: 81.42
Round  70, Train loss: 0.368, Test loss: 0.441, Test accuracy: 81.73
Round  71, Train loss: 0.339, Test loss: 0.442, Test accuracy: 81.97
Round  72, Train loss: 0.328, Test loss: 0.443, Test accuracy: 82.10
Round  73, Train loss: 0.412, Test loss: 0.437, Test accuracy: 81.93
Round  74, Train loss: 0.361, Test loss: 0.437, Test accuracy: 82.13
Round  75, Train loss: 0.327, Test loss: 0.444, Test accuracy: 81.78
Round  76, Train loss: 0.433, Test loss: 0.435, Test accuracy: 82.15
Round  77, Train loss: 0.313, Test loss: 0.442, Test accuracy: 82.32
Round  78, Train loss: 0.295, Test loss: 0.442, Test accuracy: 82.20
Round  79, Train loss: 0.308, Test loss: 0.431, Test accuracy: 82.88
Round  80, Train loss: 0.372, Test loss: 0.435, Test accuracy: 82.42
Round  81, Train loss: 0.300, Test loss: 0.432, Test accuracy: 82.43
Round  82, Train loss: 0.292, Test loss: 0.435, Test accuracy: 82.55
Round  83, Train loss: 0.312, Test loss: 0.434, Test accuracy: 82.30
Round  84, Train loss: 0.345, Test loss: 0.445, Test accuracy: 81.77
Round  85, Train loss: 0.318, Test loss: 0.433, Test accuracy: 82.17
Round  86, Train loss: 0.319, Test loss: 0.434, Test accuracy: 82.05
Round  87, Train loss: 0.349, Test loss: 0.426, Test accuracy: 82.40
Round  88, Train loss: 0.324, Test loss: 0.426, Test accuracy: 82.48
Round  89, Train loss: 0.331, Test loss: 0.428, Test accuracy: 82.63
Round  90, Train loss: 0.294, Test loss: 0.427, Test accuracy: 82.95
Round  91, Train loss: 0.346, Test loss: 0.423, Test accuracy: 82.43
Round  92, Train loss: 0.298, Test loss: 0.424, Test accuracy: 82.32
Round  93, Train loss: 0.298, Test loss: 0.432, Test accuracy: 82.58
Round  94, Train loss: 0.305, Test loss: 0.429, Test accuracy: 82.65
Round  95, Train loss: 0.298, Test loss: 0.425, Test accuracy: 82.88
Round  96, Train loss: 0.325, Test loss: 0.425, Test accuracy: 82.88
Round  97, Train loss: 0.314, Test loss: 0.426, Test accuracy: 82.82
Round  98, Train loss: 0.304, Test loss: 0.424, Test accuracy: 82.78
Round  99, Train loss: 0.294, Test loss: 0.435, Test accuracy: 82.85
Final Round, Train loss: 0.237, Test loss: 0.429, Test accuracy: 83.20
Average accuracy final 10 rounds: 82.715
818.0801868438721
[1.6136198043823242, 2.773730754852295, 3.9426443576812744, 5.163464307785034, 6.420186281204224, 7.41768217086792, 8.342471361160278, 9.241870641708374, 10.141725301742554, 11.11524248123169, 12.040438652038574, 13.035202503204346, 14.064092636108398, 15.041035652160645, 16.053829669952393, 16.935877084732056, 17.83173108100891, 18.73444104194641, 19.61852264404297, 20.611769914627075, 21.578185558319092, 22.605513095855713, 23.592793703079224, 24.5072124004364, 25.451279878616333, 26.369999647140503, 27.30959987640381, 28.294713735580444, 29.27034831047058, 30.22219467163086, 31.164392471313477, 32.06285047531128, 32.99786329269409, 33.978357791900635, 34.92806553840637, 36.00767230987549, 36.98621654510498, 38.01844120025635, 39.000401973724365, 39.90829634666443, 40.83321475982666, 41.79495882987976, 42.70044445991516, 43.65955686569214, 44.66004705429077, 45.71416211128235, 46.78850722312927, 47.73442316055298, 48.67220115661621, 49.58558225631714, 50.54208254814148, 51.51552700996399, 52.46535515785217, 53.42971873283386, 54.323500633239746, 55.26869773864746, 56.24469828605652, 57.205979108810425, 58.244619607925415, 59.282305002212524, 60.29618573188782, 61.274807929992676, 62.16777849197388, 63.08525109291077, 64.04877996444702, 64.9939124584198, 65.99463987350464, 67.07914113998413, 68.20921492576599, 69.32797360420227, 70.33131718635559, 71.40139079093933, 72.45761704444885, 73.42468547821045, 74.52967810630798, 75.58882093429565, 76.69506525993347, 77.7926115989685, 78.7610764503479, 79.6814513206482, 80.66146087646484, 81.57594323158264, 82.65128803253174, 83.68595695495605, 84.66984510421753, 85.63740754127502, 86.59153985977173, 87.5497658252716, 88.46238899230957, 89.45929336547852, 90.59181618690491, 91.72638416290283, 92.8058409690857, 93.97044563293457, 94.96891641616821, 96.01576328277588, 96.97428727149963, 97.85228514671326, 98.95742511749268, 100.02087354660034, 101.58584976196289]
[16.216666666666665, 33.95, 42.333333333333336, 49.4, 56.583333333333336, 57.36666666666667, 56.75, 62.5, 64.03333333333333, 68.5, 69.25, 69.4, 70.71666666666667, 72.55, 73.65, 74.05, 74.41666666666667, 74.98333333333333, 74.71666666666667, 74.85, 74.91666666666667, 75.46666666666667, 75.61666666666666, 76.11666666666666, 75.63333333333334, 76.53333333333333, 76.65, 76.71666666666667, 76.76666666666667, 77.86666666666666, 77.63333333333334, 77.88333333333334, 78.11666666666666, 78.33333333333333, 77.8, 78.41666666666667, 78.6, 79.61666666666666, 79.15, 78.63333333333334, 79.1, 78.91666666666667, 79.38333333333334, 79.18333333333334, 79.18333333333334, 79.91666666666667, 80.4, 80.5, 80.36666666666666, 81.05, 80.7, 80.66666666666667, 81.15, 81.18333333333334, 80.71666666666667, 81.13333333333334, 81.26666666666667, 81.36666666666666, 80.91666666666667, 81.5, 81.25, 81.3, 81.2, 80.61666666666666, 81.53333333333333, 81.55, 81.41666666666667, 81.3, 81.63333333333334, 81.41666666666667, 81.73333333333333, 81.96666666666667, 82.1, 81.93333333333334, 82.13333333333334, 81.78333333333333, 82.15, 82.31666666666666, 82.2, 82.88333333333334, 82.41666666666667, 82.43333333333334, 82.55, 82.3, 81.76666666666667, 82.16666666666667, 82.05, 82.4, 82.48333333333333, 82.63333333333334, 82.95, 82.43333333333334, 82.31666666666666, 82.58333333333333, 82.65, 82.88333333333334, 82.88333333333334, 82.81666666666666, 82.78333333333333, 82.85, 83.2]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  12.8500
Round 1 global test acc  20.3700
Round 2 global test acc  15.1000
Round 3 global test acc  12.8000
Round 4 global test acc  19.1900
Round 5 global test acc  24.0300
Round 6 global test acc  23.1600
Round 7 global test acc  28.7600
Round 8 global test acc  28.8600
Round 9 global test acc  22.4500
Round 10 global test acc  30.5600
Round 11 global test acc  25.8400
Round 12 global test acc  29.9600
Round 13 global test acc  17.4900
Round 14 global test acc  27.5900
Round 15 global test acc  22.3900
Round 16 global test acc  28.1100
Round 17 global test acc  31.5800
Round 18 global test acc  24.9200
Round 19 global test acc  27.3100
Round 20 global test acc  22.6400
Round 21 global test acc  19.2700
Round 22 global test acc  23.1800
Round 23 global test acc  31.0600
Round 24 global test acc  35.2400
Round 25 global test acc  32.8200
Round 26 global test acc  27.2500
Round 27 global test acc  26.4900
Round 28 global test acc  32.9200
Round 29 global test acc  30.6200
Round 30 global test acc  25.4600
Round 31 global test acc  32.3400
Round 32 global test acc  28.9000
Round 33 global test acc  31.1000
Round 34 global test acc  27.1600
Round 35 global test acc  29.3000
Round 36 global test acc  24.5500
Round 37 global test acc  35.3800
Round 38 global test acc  36.2400
Round 39 global test acc  30.2000
Round 40 global test acc  30.7600
Round 41 global test acc  27.9500
Round 42 global test acc  22.4800
Round 43 global test acc  35.8200
Round 44 global test acc  28.5300
Round 45 global test acc  33.5900
Round 46 global test acc  26.9200
Round 47 global test acc  38.0600
Round 48 global test acc  34.6500
Round 49 global test acc  35.6900
Round 50 global test acc  28.9000
Round 51 global test acc  36.3500
Round 52 global test acc  25.7600
Round 53 global test acc  29.5900
Round 54 global test acc  31.8800
Round 55 global test acc  29.5900
Round 56 global test acc  27.6300
Round 57 global test acc  30.6600
Round 58 global test acc  27.2200
Round 59 global test acc  39.7300
Round 60 global test acc  24.7500
Round 61 global test acc  28.0100
Round 62 global test acc  35.0700
Round 63 global test acc  26.9400
Round 64 global test acc  36.9700
Round 65 global test acc  30.3000
Round 66 global test acc  33.6900
Round 67 global test acc  30.1600
Round 68 global test acc  23.1500
Round 69 global test acc  39.0800
Round 70 global test acc  29.7600
Round 71 global test acc  28.2600
Round 72 global test acc  31.2000
Round 73 global test acc  33.4700
Round 74 global test acc  25.2900
Round 75 global test acc  30.9600
Round 76 global test acc  37.8200
Round 77 global test acc  40.0600
Round 78 global test acc  40.8700
Round 79 global test acc  33.6700
Round 80 global test acc  29.0800
Round 81 global test acc  27.8900
Round 82 global test acc  24.5800
Round 83 global test acc  24.9600
Round 84 global test acc  22.1300
Round 85 global test acc  21.6100
Round 86 global test acc  22.2300
Round 87 global test acc  24.8500
Round 88 global test acc  22.7900
Round 89 global test acc  21.2900
Round 90 global test acc  20.6700
Round 91 global test acc  20.6200
Round 92 global test acc  19.7600
Round 93 global test acc  19.3400
Round 94 global test acc  16.0100
Round 95 global test acc  15.7400
Round 96 global test acc  13.0200
Round 97 global test acc  12.0900
Round 98 global test acc  11.9200
Round 99 global test acc  12.0600
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.676, Test loss: 2.298, Test accuracy: 15.00
Round   1, Train loss: 1.098, Test loss: 1.670, Test accuracy: 38.07
Round   2, Train loss: 0.928, Test loss: 1.554, Test accuracy: 41.98
Round   3, Train loss: 0.901, Test loss: 1.251, Test accuracy: 49.93
Round   4, Train loss: 0.877, Test loss: 0.982, Test accuracy: 57.53
Round   5, Train loss: 0.758, Test loss: 1.009, Test accuracy: 57.32
Round   6, Train loss: 0.710, Test loss: 1.159, Test accuracy: 56.12
Round   7, Train loss: 0.792, Test loss: 0.875, Test accuracy: 62.08
Round   8, Train loss: 0.743, Test loss: 0.854, Test accuracy: 63.47
Round   9, Train loss: 0.729, Test loss: 0.714, Test accuracy: 68.30
Round  10, Train loss: 0.718, Test loss: 0.708, Test accuracy: 67.52
Round  11, Train loss: 0.653, Test loss: 0.691, Test accuracy: 68.40
Round  12, Train loss: 0.720, Test loss: 0.676, Test accuracy: 69.35
Round  13, Train loss: 0.723, Test loss: 0.655, Test accuracy: 70.53
Round  14, Train loss: 0.710, Test loss: 0.638, Test accuracy: 72.18
Round  15, Train loss: 0.652, Test loss: 0.627, Test accuracy: 73.83
Round  16, Train loss: 0.622, Test loss: 0.610, Test accuracy: 74.07
Round  17, Train loss: 0.631, Test loss: 0.609, Test accuracy: 73.78
Round  18, Train loss: 0.645, Test loss: 0.614, Test accuracy: 73.32
Round  19, Train loss: 0.621, Test loss: 0.601, Test accuracy: 73.83
Round  20, Train loss: 0.591, Test loss: 0.604, Test accuracy: 73.87
Round  21, Train loss: 0.608, Test loss: 0.590, Test accuracy: 74.18
Round  22, Train loss: 0.596, Test loss: 0.584, Test accuracy: 74.58
Round  23, Train loss: 0.601, Test loss: 0.579, Test accuracy: 75.40
Round  24, Train loss: 0.550, Test loss: 0.571, Test accuracy: 75.67
Round  25, Train loss: 0.564, Test loss: 0.548, Test accuracy: 76.75
Round  26, Train loss: 0.574, Test loss: 0.566, Test accuracy: 76.22
Round  27, Train loss: 0.556, Test loss: 0.544, Test accuracy: 76.63
Round  28, Train loss: 0.631, Test loss: 0.541, Test accuracy: 76.80
Round  29, Train loss: 0.537, Test loss: 0.543, Test accuracy: 76.83
Round  30, Train loss: 0.509, Test loss: 0.535, Test accuracy: 77.42
Round  31, Train loss: 0.601, Test loss: 0.533, Test accuracy: 77.57
Round  32, Train loss: 0.511, Test loss: 0.520, Test accuracy: 78.27
Round  33, Train loss: 0.455, Test loss: 0.521, Test accuracy: 78.47
Round  34, Train loss: 0.494, Test loss: 0.516, Test accuracy: 78.70
Round  35, Train loss: 0.462, Test loss: 0.511, Test accuracy: 79.00
Round  36, Train loss: 0.467, Test loss: 0.511, Test accuracy: 78.65
Round  37, Train loss: 0.542, Test loss: 0.497, Test accuracy: 79.92
Round  38, Train loss: 0.453, Test loss: 0.499, Test accuracy: 79.65
Round  39, Train loss: 0.437, Test loss: 0.504, Test accuracy: 79.58
Round  40, Train loss: 0.496, Test loss: 0.503, Test accuracy: 79.60
Round  41, Train loss: 0.480, Test loss: 0.496, Test accuracy: 79.10
Round  42, Train loss: 0.460, Test loss: 0.495, Test accuracy: 79.70
Round  43, Train loss: 0.427, Test loss: 0.490, Test accuracy: 79.80
Round  44, Train loss: 0.439, Test loss: 0.489, Test accuracy: 80.33
Round  45, Train loss: 0.477, Test loss: 0.482, Test accuracy: 80.50
Round  46, Train loss: 0.518, Test loss: 0.476, Test accuracy: 80.27
Round  47, Train loss: 0.464, Test loss: 0.476, Test accuracy: 80.52
Round  48, Train loss: 0.420, Test loss: 0.467, Test accuracy: 81.40
Round  49, Train loss: 0.455, Test loss: 0.464, Test accuracy: 81.22
Round  50, Train loss: 0.424, Test loss: 0.468, Test accuracy: 80.87
Round  51, Train loss: 0.426, Test loss: 0.472, Test accuracy: 81.03
Round  52, Train loss: 0.453, Test loss: 0.462, Test accuracy: 81.53
Round  53, Train loss: 0.453, Test loss: 0.461, Test accuracy: 81.68
Round  54, Train loss: 0.374, Test loss: 0.469, Test accuracy: 81.42
Round  55, Train loss: 0.374, Test loss: 0.474, Test accuracy: 80.80
Round  56, Train loss: 0.405, Test loss: 0.462, Test accuracy: 81.22
Round  57, Train loss: 0.458, Test loss: 0.463, Test accuracy: 81.27
Round  58, Train loss: 0.370, Test loss: 0.463, Test accuracy: 81.00
Round  59, Train loss: 0.364, Test loss: 0.456, Test accuracy: 81.32
Round  60, Train loss: 0.346, Test loss: 0.451, Test accuracy: 81.88
Round  61, Train loss: 0.363, Test loss: 0.445, Test accuracy: 82.38
Round  62, Train loss: 0.479, Test loss: 0.445, Test accuracy: 82.25
Round  63, Train loss: 0.324, Test loss: 0.448, Test accuracy: 81.40
Round  64, Train loss: 0.342, Test loss: 0.438, Test accuracy: 82.07
Round  65, Train loss: 0.332, Test loss: 0.435, Test accuracy: 82.37
Round  66, Train loss: 0.312, Test loss: 0.440, Test accuracy: 81.95
Round  67, Train loss: 0.377, Test loss: 0.437, Test accuracy: 81.83
Round  68, Train loss: 0.379, Test loss: 0.439, Test accuracy: 81.75
Round  69, Train loss: 0.306, Test loss: 0.444, Test accuracy: 81.48
Round  70, Train loss: 0.362, Test loss: 0.440, Test accuracy: 81.90
Round  71, Train loss: 0.334, Test loss: 0.432, Test accuracy: 82.62
Round  72, Train loss: 0.326, Test loss: 0.436, Test accuracy: 81.77
Round  73, Train loss: 0.406, Test loss: 0.441, Test accuracy: 81.88
Round  74, Train loss: 0.371, Test loss: 0.433, Test accuracy: 82.00
Round  75, Train loss: 0.318, Test loss: 0.442, Test accuracy: 81.98
Round  76, Train loss: 0.425, Test loss: 0.429, Test accuracy: 82.37
Round  77, Train loss: 0.307, Test loss: 0.428, Test accuracy: 82.82
Round  78, Train loss: 0.295, Test loss: 0.434, Test accuracy: 82.80
Round  79, Train loss: 0.309, Test loss: 0.424, Test accuracy: 82.87
Round  80, Train loss: 0.372, Test loss: 0.434, Test accuracy: 82.25
Round  81, Train loss: 0.300, Test loss: 0.423, Test accuracy: 82.40
Round  82, Train loss: 0.286, Test loss: 0.427, Test accuracy: 82.80
Round  83, Train loss: 0.303, Test loss: 0.428, Test accuracy: 82.93
Round  84, Train loss: 0.335, Test loss: 0.425, Test accuracy: 82.87
Round  85, Train loss: 0.309, Test loss: 0.424, Test accuracy: 83.13
Round  86, Train loss: 0.313, Test loss: 0.422, Test accuracy: 82.83
Round  87, Train loss: 0.343, Test loss: 0.420, Test accuracy: 82.55
Round  88, Train loss: 0.316, Test loss: 0.422, Test accuracy: 82.78
Round  89, Train loss: 0.323, Test loss: 0.425, Test accuracy: 82.60
Round  90, Train loss: 0.284, Test loss: 0.434, Test accuracy: 82.68
Round  91, Train loss: 0.337, Test loss: 0.423, Test accuracy: 82.95
Round  92, Train loss: 0.285, Test loss: 0.420, Test accuracy: 83.02
Round  93, Train loss: 0.298, Test loss: 0.429, Test accuracy: 83.35
Round  94, Train loss: 0.284, Test loss: 0.422, Test accuracy: 83.30
Round  95, Train loss: 0.293, Test loss: 0.424, Test accuracy: 83.08
Round  96, Train loss: 0.322, Test loss: 0.422, Test accuracy: 82.95
Round  97, Train loss: 0.309, Test loss: 0.421, Test accuracy: 82.92
Round  98, Train loss: 0.298, Test loss: 0.422, Test accuracy: 82.92
Round  99, Train loss: 0.297, Test loss: 0.428, Test accuracy: 83.13
Final Round, Train loss: 0.230, Test loss: 0.426, Test accuracy: 83.35
Average accuracy final 10 rounds: 83.03
790.5020041465759
[1.2363545894622803, 2.1741232872009277, 3.1755900382995605, 4.112999439239502, 5.1638336181640625, 6.217764616012573, 7.157297134399414, 8.10882830619812, 9.100696802139282, 10.080604791641235, 11.041107892990112, 12.007526159286499, 12.972655296325684, 13.929953575134277, 14.823753595352173, 15.756605863571167, 16.708787441253662, 17.64351177215576, 18.63528084754944, 19.686583042144775, 20.747214317321777, 21.75633192062378, 22.643332719802856, 23.569363355636597, 24.47445559501648, 25.449280977249146, 26.435157537460327, 27.48779582977295, 28.571754455566406, 29.497861623764038, 30.45156168937683, 31.398828983306885, 32.327512979507446, 33.275256872177124, 34.272172927856445, 35.29574489593506, 36.23223900794983, 37.13112688064575, 38.09931421279907, 39.06055974960327, 39.98978304862976, 41.00580906867981, 42.091530084609985, 43.08307385444641, 44.025837421417236, 44.90930795669556, 45.79279017448425, 46.71094799041748, 47.59371733665466, 48.54618835449219, 49.597007274627686, 50.59231424331665, 51.61846566200256, 52.60308766365051, 53.56338715553284, 54.47609758377075, 55.374266147613525, 56.3932101726532, 57.34295701980591, 58.33969736099243, 59.32509517669678, 60.312199115753174, 61.27278709411621, 62.23843502998352, 63.253491163253784, 64.31648969650269, 65.31726455688477, 66.27998065948486, 67.25946283340454, 68.1548719406128, 69.04285860061646, 69.96849060058594, 70.86327600479126, 71.87609267234802, 72.90056538581848, 73.92708015441895, 74.94530296325684, 75.87043142318726, 76.81416511535645, 77.69113969802856, 78.60668897628784, 79.58392071723938, 80.53394556045532, 81.52658224105835, 82.52308654785156, 83.45422196388245, 84.41164207458496, 85.39477968215942, 86.3943259716034, 87.38465428352356, 88.35316395759583, 89.33728361129761, 90.27100253105164, 91.1605293750763, 92.06731414794922, 93.01929879188538, 93.99974846839905, 94.97404408454895, 95.99413442611694, 97.02314186096191, 98.44313454627991]
[15.0, 38.06666666666667, 41.983333333333334, 49.93333333333333, 57.53333333333333, 57.31666666666667, 56.11666666666667, 62.083333333333336, 63.46666666666667, 68.3, 67.51666666666667, 68.4, 69.35, 70.53333333333333, 72.18333333333334, 73.83333333333333, 74.06666666666666, 73.78333333333333, 73.31666666666666, 73.83333333333333, 73.86666666666666, 74.18333333333334, 74.58333333333333, 75.4, 75.66666666666667, 76.75, 76.21666666666667, 76.63333333333334, 76.8, 76.83333333333333, 77.41666666666667, 77.56666666666666, 78.26666666666667, 78.46666666666667, 78.7, 79.0, 78.65, 79.91666666666667, 79.65, 79.58333333333333, 79.6, 79.1, 79.7, 79.8, 80.33333333333333, 80.5, 80.26666666666667, 80.51666666666667, 81.4, 81.21666666666667, 80.86666666666666, 81.03333333333333, 81.53333333333333, 81.68333333333334, 81.41666666666667, 80.8, 81.21666666666667, 81.26666666666667, 81.0, 81.31666666666666, 81.88333333333334, 82.38333333333334, 82.25, 81.4, 82.06666666666666, 82.36666666666666, 81.95, 81.83333333333333, 81.75, 81.48333333333333, 81.9, 82.61666666666666, 81.76666666666667, 81.88333333333334, 82.0, 81.98333333333333, 82.36666666666666, 82.81666666666666, 82.8, 82.86666666666666, 82.25, 82.4, 82.8, 82.93333333333334, 82.86666666666666, 83.13333333333334, 82.83333333333333, 82.55, 82.78333333333333, 82.6, 82.68333333333334, 82.95, 83.01666666666667, 83.35, 83.3, 83.08333333333333, 82.95, 82.91666666666667, 82.91666666666667, 83.13333333333334, 83.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.648, Test loss: 2.274, Test accuracy: 16.42
Round   1, Train loss: 1.113, Test loss: 1.641, Test accuracy: 36.78
Round   2, Train loss: 0.937, Test loss: 1.559, Test accuracy: 43.73
Round   3, Train loss: 0.909, Test loss: 1.253, Test accuracy: 50.58
Round   4, Train loss: 0.885, Test loss: 0.994, Test accuracy: 58.10
Round   5, Train loss: 0.772, Test loss: 1.028, Test accuracy: 57.93
Round   6, Train loss: 0.721, Test loss: 1.123, Test accuracy: 59.05
Round   7, Train loss: 0.788, Test loss: 0.880, Test accuracy: 63.08
Round   8, Train loss: 0.738, Test loss: 0.846, Test accuracy: 64.80
Round   9, Train loss: 0.724, Test loss: 0.702, Test accuracy: 69.03
Round  10, Train loss: 0.717, Test loss: 0.682, Test accuracy: 70.00
Round  11, Train loss: 0.657, Test loss: 0.676, Test accuracy: 69.57
Round  12, Train loss: 0.711, Test loss: 0.660, Test accuracy: 70.47
Round  13, Train loss: 0.716, Test loss: 0.650, Test accuracy: 71.10
Round  14, Train loss: 0.708, Test loss: 0.636, Test accuracy: 72.92
Round  15, Train loss: 0.643, Test loss: 0.616, Test accuracy: 73.57
Round  16, Train loss: 0.622, Test loss: 0.609, Test accuracy: 73.80
Round  17, Train loss: 0.623, Test loss: 0.608, Test accuracy: 74.22
Round  18, Train loss: 0.656, Test loss: 0.611, Test accuracy: 73.83
Round  19, Train loss: 0.615, Test loss: 0.602, Test accuracy: 73.85
Round  20, Train loss: 0.604, Test loss: 0.581, Test accuracy: 75.27
Round  21, Train loss: 0.605, Test loss: 0.577, Test accuracy: 75.38
Round  22, Train loss: 0.598, Test loss: 0.567, Test accuracy: 76.05
Round  23, Train loss: 0.591, Test loss: 0.565, Test accuracy: 76.22
Round  24, Train loss: 0.556, Test loss: 0.559, Test accuracy: 76.38
Round  25, Train loss: 0.575, Test loss: 0.545, Test accuracy: 77.68
Round  26, Train loss: 0.566, Test loss: 0.543, Test accuracy: 77.78
Round  27, Train loss: 0.552, Test loss: 0.531, Test accuracy: 77.82
Round  28, Train loss: 0.629, Test loss: 0.532, Test accuracy: 77.77
Round  29, Train loss: 0.542, Test loss: 0.526, Test accuracy: 78.15
Round  30, Train loss: 0.512, Test loss: 0.521, Test accuracy: 78.18
Round  31, Train loss: 0.599, Test loss: 0.512, Test accuracy: 78.60
Round  32, Train loss: 0.498, Test loss: 0.508, Test accuracy: 78.55
Round  33, Train loss: 0.466, Test loss: 0.507, Test accuracy: 79.08
Round  34, Train loss: 0.496, Test loss: 0.502, Test accuracy: 78.90
Round  35, Train loss: 0.466, Test loss: 0.502, Test accuracy: 78.85
Round  36, Train loss: 0.469, Test loss: 0.498, Test accuracy: 79.27
Round  37, Train loss: 0.538, Test loss: 0.489, Test accuracy: 79.63
Round  38, Train loss: 0.452, Test loss: 0.490, Test accuracy: 79.55
Round  39, Train loss: 0.445, Test loss: 0.501, Test accuracy: 79.70
Round  40, Train loss: 0.498, Test loss: 0.493, Test accuracy: 79.92
Round  41, Train loss: 0.486, Test loss: 0.479, Test accuracy: 80.65
Round  42, Train loss: 0.442, Test loss: 0.480, Test accuracy: 79.83
Round  43, Train loss: 0.420, Test loss: 0.482, Test accuracy: 79.93
Round  44, Train loss: 0.445, Test loss: 0.481, Test accuracy: 80.13
Round  45, Train loss: 0.476, Test loss: 0.469, Test accuracy: 80.28
Round  46, Train loss: 0.521, Test loss: 0.457, Test accuracy: 81.00
Round  47, Train loss: 0.451, Test loss: 0.462, Test accuracy: 80.68
Round  48, Train loss: 0.414, Test loss: 0.475, Test accuracy: 80.58
Round  49, Train loss: 0.463, Test loss: 0.465, Test accuracy: 81.13
Round  50, Train loss: 0.426, Test loss: 0.462, Test accuracy: 81.20
Round  51, Train loss: 0.426, Test loss: 0.460, Test accuracy: 81.02
Round  52, Train loss: 0.446, Test loss: 0.451, Test accuracy: 81.57
Round  53, Train loss: 0.443, Test loss: 0.458, Test accuracy: 80.90
Round  54, Train loss: 0.368, Test loss: 0.455, Test accuracy: 81.43
Round  55, Train loss: 0.375, Test loss: 0.447, Test accuracy: 81.92
Round  56, Train loss: 0.401, Test loss: 0.449, Test accuracy: 81.48
Round  57, Train loss: 0.447, Test loss: 0.442, Test accuracy: 82.17
Round  58, Train loss: 0.353, Test loss: 0.440, Test accuracy: 82.03
Round  59, Train loss: 0.355, Test loss: 0.441, Test accuracy: 81.85
Round  60, Train loss: 0.348, Test loss: 0.440, Test accuracy: 82.00
Round  61, Train loss: 0.375, Test loss: 0.435, Test accuracy: 82.37
Round  62, Train loss: 0.471, Test loss: 0.435, Test accuracy: 82.38
Round  63, Train loss: 0.327, Test loss: 0.447, Test accuracy: 82.02
Round  64, Train loss: 0.336, Test loss: 0.434, Test accuracy: 82.37
Round  65, Train loss: 0.336, Test loss: 0.429, Test accuracy: 82.78
Round  66, Train loss: 0.314, Test loss: 0.436, Test accuracy: 82.67
Round  67, Train loss: 0.378, Test loss: 0.428, Test accuracy: 82.62
Round  68, Train loss: 0.368, Test loss: 0.429, Test accuracy: 82.52
Round  69, Train loss: 0.304, Test loss: 0.431, Test accuracy: 82.47
Round  70, Train loss: 0.361, Test loss: 0.423, Test accuracy: 83.23
Round  71, Train loss: 0.330, Test loss: 0.429, Test accuracy: 83.05
Round  72, Train loss: 0.326, Test loss: 0.425, Test accuracy: 83.07
Round  73, Train loss: 0.409, Test loss: 0.416, Test accuracy: 83.23
Round  74, Train loss: 0.364, Test loss: 0.420, Test accuracy: 83.28
Round  75, Train loss: 0.321, Test loss: 0.435, Test accuracy: 82.43
Round  76, Train loss: 0.418, Test loss: 0.422, Test accuracy: 83.13
Round  77, Train loss: 0.302, Test loss: 0.422, Test accuracy: 83.08
Round  78, Train loss: 0.298, Test loss: 0.440, Test accuracy: 82.40
Round  79, Train loss: 0.312, Test loss: 0.420, Test accuracy: 83.35
Round  80, Train loss: 0.372, Test loss: 0.418, Test accuracy: 83.05
Round  81, Train loss: 0.293, Test loss: 0.416, Test accuracy: 83.02
Round  82, Train loss: 0.287, Test loss: 0.430, Test accuracy: 83.00
Round  83, Train loss: 0.302, Test loss: 0.428, Test accuracy: 82.78
Round  84, Train loss: 0.331, Test loss: 0.427, Test accuracy: 82.82
Round  85, Train loss: 0.313, Test loss: 0.420, Test accuracy: 83.23
Round  86, Train loss: 0.314, Test loss: 0.416, Test accuracy: 83.47
Round  87, Train loss: 0.343, Test loss: 0.414, Test accuracy: 83.77
Round  88, Train loss: 0.320, Test loss: 0.409, Test accuracy: 84.12
Round  89, Train loss: 0.319, Test loss: 0.412, Test accuracy: 83.48
Round  90, Train loss: 0.289, Test loss: 0.416, Test accuracy: 83.17
Round  91, Train loss: 0.350, Test loss: 0.421, Test accuracy: 83.45
Round  92, Train loss: 0.272, Test loss: 0.411, Test accuracy: 83.87
Round  93, Train loss: 0.298, Test loss: 0.416, Test accuracy: 83.85
Round  94, Train loss: 0.293, Test loss: 0.419, Test accuracy: 83.62
Round  95, Train loss: 0.300, Test loss: 0.414, Test accuracy: 83.92
Round  96, Train loss: 0.321, Test loss: 0.415, Test accuracy: 83.97
Round  97, Train loss: 0.299, Test loss: 0.418, Test accuracy: 83.42
Round  98, Train loss: 0.310, Test loss: 0.412, Test accuracy: 83.63
Round  99, Train loss: 0.293, Test loss: 0.416, Test accuracy: 83.65
Final Round, Train loss: 0.231, Test loss: 0.415, Test accuracy: 83.95
Average accuracy final 10 rounds: 83.65333333333332
1546.3793268203735
[1.3029720783233643, 2.2542359828948975, 3.2850115299224854, 4.233565330505371, 5.154975175857544, 6.114704132080078, 7.090965270996094, 8.065353870391846, 9.047850370407104, 10.018177509307861, 10.979807138442993, 11.83967399597168, 12.756316423416138, 13.705280780792236, 14.680926322937012, 15.675982475280762, 16.693753480911255, 17.678044319152832, 18.692166090011597, 19.570643663406372, 20.476330995559692, 22.682830572128296, 25.313884019851685, 28.086787700653076, 31.04263949394226, 33.51136040687561, 36.2414231300354, 38.77826142311096, 41.25505089759827, 44.49339270591736, 47.36816167831421, 49.678959369659424, 52.113027811050415, 55.09387993812561, 58.00733399391174, 60.64923048019409, 63.201839447021484, 65.90577125549316, 68.40060877799988, 70.97048759460449, 73.95669937133789, 76.6855239868164, 79.05861163139343, 81.79616808891296, 84.98329901695251, 87.62806677818298, 90.00638270378113, 92.76572346687317, 95.581458568573, 98.23116278648376, 101.22285318374634, 103.98455119132996, 106.44833755493164, 108.97809791564941, 111.99422526359558, 114.89403986930847, 117.49211621284485, 119.83856654167175, 122.61219787597656, 125.52053594589233, 128.2506880760193, 131.05800461769104, 133.7668251991272, 136.38900470733643, 139.11430382728577, 142.10936284065247, 145.22715735435486, 147.50410437583923, 150.20491242408752, 152.90129375457764, 155.86543655395508, 158.53055906295776, 161.3115234375, 164.16294741630554, 166.71698117256165, 169.47601079940796, 172.32298040390015, 175.58559823036194, 178.0443205833435, 180.87086749076843, 184.08252882957458, 186.968514919281, 189.89123964309692, 192.83859014511108, 195.58003067970276, 198.38607215881348, 201.7354576587677, 204.80507493019104, 207.26481556892395, 209.7544527053833, 213.04322624206543, 216.1555335521698, 218.98886442184448, 222.01155018806458, 224.68768167495728, 227.43288159370422, 230.18751287460327, 233.2016580104828, 235.98877954483032, 238.448410987854, 239.96636819839478]
[16.416666666666668, 36.78333333333333, 43.733333333333334, 50.583333333333336, 58.1, 57.93333333333333, 59.05, 63.083333333333336, 64.8, 69.03333333333333, 70.0, 69.56666666666666, 70.46666666666667, 71.1, 72.91666666666667, 73.56666666666666, 73.8, 74.21666666666667, 73.83333333333333, 73.85, 75.26666666666667, 75.38333333333334, 76.05, 76.21666666666667, 76.38333333333334, 77.68333333333334, 77.78333333333333, 77.81666666666666, 77.76666666666667, 78.15, 78.18333333333334, 78.6, 78.55, 79.08333333333333, 78.9, 78.85, 79.26666666666667, 79.63333333333334, 79.55, 79.7, 79.91666666666667, 80.65, 79.83333333333333, 79.93333333333334, 80.13333333333334, 80.28333333333333, 81.0, 80.68333333333334, 80.58333333333333, 81.13333333333334, 81.2, 81.01666666666667, 81.56666666666666, 80.9, 81.43333333333334, 81.91666666666667, 81.48333333333333, 82.16666666666667, 82.03333333333333, 81.85, 82.0, 82.36666666666666, 82.38333333333334, 82.01666666666667, 82.36666666666666, 82.78333333333333, 82.66666666666667, 82.61666666666666, 82.51666666666667, 82.46666666666667, 83.23333333333333, 83.05, 83.06666666666666, 83.23333333333333, 83.28333333333333, 82.43333333333334, 83.13333333333334, 83.08333333333333, 82.4, 83.35, 83.05, 83.01666666666667, 83.0, 82.78333333333333, 82.81666666666666, 83.23333333333333, 83.46666666666667, 83.76666666666667, 84.11666666666666, 83.48333333333333, 83.16666666666667, 83.45, 83.86666666666666, 83.85, 83.61666666666666, 83.91666666666667, 83.96666666666667, 83.41666666666667, 83.63333333333334, 83.65, 83.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.241, Test loss: 2.110, Test accuracy: 22.32
Round   0, Global train loss: 1.241, Global test loss: 2.399, Global test accuracy: 13.33
Round   1, Train loss: 1.108, Test loss: 1.613, Test accuracy: 37.37
Round   1, Global train loss: 1.108, Global test loss: 2.178, Global test accuracy: 20.92
Round   2, Train loss: 0.992, Test loss: 1.516, Test accuracy: 40.32
Round   2, Global train loss: 0.992, Global test loss: 2.340, Global test accuracy: 17.77
Round   3, Train loss: 0.997, Test loss: 1.287, Test accuracy: 46.13
Round   3, Global train loss: 0.997, Global test loss: 2.239, Global test accuracy: 20.62
Round   4, Train loss: 0.881, Test loss: 1.099, Test accuracy: 54.43
Round   4, Global train loss: 0.881, Global test loss: 2.065, Global test accuracy: 25.87
Round   5, Train loss: 0.796, Test loss: 1.080, Test accuracy: 55.55
Round   5, Global train loss: 0.796, Global test loss: 2.214, Global test accuracy: 26.67
Round   6, Train loss: 0.782, Test loss: 0.998, Test accuracy: 58.10
Round   6, Global train loss: 0.782, Global test loss: 2.079, Global test accuracy: 28.90
Round   7, Train loss: 0.696, Test loss: 0.941, Test accuracy: 60.55
Round   7, Global train loss: 0.696, Global test loss: 2.075, Global test accuracy: 28.35
Round   8, Train loss: 0.754, Test loss: 0.914, Test accuracy: 60.82
Round   8, Global train loss: 0.754, Global test loss: 1.968, Global test accuracy: 28.12
Round   9, Train loss: 0.809, Test loss: 0.882, Test accuracy: 62.00
Round   9, Global train loss: 0.809, Global test loss: 2.100, Global test accuracy: 24.12
Round  10, Train loss: 0.906, Test loss: 0.855, Test accuracy: 64.08
Round  10, Global train loss: 0.906, Global test loss: 2.088, Global test accuracy: 27.53
Round  11, Train loss: 0.706, Test loss: 0.826, Test accuracy: 66.57
Round  11, Global train loss: 0.706, Global test loss: 2.156, Global test accuracy: 26.85
Round  12, Train loss: 0.745, Test loss: 0.864, Test accuracy: 64.18
Round  12, Global train loss: 0.745, Global test loss: 2.057, Global test accuracy: 27.78
Round  13, Train loss: 0.795, Test loss: 0.860, Test accuracy: 65.75
Round  13, Global train loss: 0.795, Global test loss: 2.409, Global test accuracy: 22.50
Round  14, Train loss: 0.643, Test loss: 0.836, Test accuracy: 66.82
Round  14, Global train loss: 0.643, Global test loss: 2.289, Global test accuracy: 26.83
Round  15, Train loss: 0.813, Test loss: 0.839, Test accuracy: 65.28
Round  15, Global train loss: 0.813, Global test loss: 2.088, Global test accuracy: 25.47
Round  16, Train loss: 0.772, Test loss: 0.826, Test accuracy: 67.27
Round  16, Global train loss: 0.772, Global test loss: 1.985, Global test accuracy: 33.68
Round  17, Train loss: 0.548, Test loss: 0.867, Test accuracy: 66.35
Round  17, Global train loss: 0.548, Global test loss: 1.983, Global test accuracy: 30.20
Round  18, Train loss: 0.630, Test loss: 0.871, Test accuracy: 67.15
Round  18, Global train loss: 0.630, Global test loss: 2.127, Global test accuracy: 23.55
Round  19, Train loss: 0.666, Test loss: 0.779, Test accuracy: 69.15
Round  19, Global train loss: 0.666, Global test loss: 2.162, Global test accuracy: 23.90
Round  20, Train loss: 0.533, Test loss: 0.782, Test accuracy: 69.27
Round  20, Global train loss: 0.533, Global test loss: 1.912, Global test accuracy: 33.38
Round  21, Train loss: 0.668, Test loss: 0.768, Test accuracy: 70.05
Round  21, Global train loss: 0.668, Global test loss: 2.181, Global test accuracy: 28.48
Round  22, Train loss: 0.536, Test loss: 0.755, Test accuracy: 71.20
Round  22, Global train loss: 0.536, Global test loss: 2.068, Global test accuracy: 28.12
Round  23, Train loss: 0.740, Test loss: 0.749, Test accuracy: 71.48
Round  23, Global train loss: 0.740, Global test loss: 2.021, Global test accuracy: 29.85
Round  24, Train loss: 0.597, Test loss: 0.759, Test accuracy: 71.27
Round  24, Global train loss: 0.597, Global test loss: 1.910, Global test accuracy: 30.78
Round  25, Train loss: 0.426, Test loss: 0.777, Test accuracy: 71.20
Round  25, Global train loss: 0.426, Global test loss: 2.003, Global test accuracy: 32.55
Round  26, Train loss: 0.523, Test loss: 0.784, Test accuracy: 71.38
Round  26, Global train loss: 0.523, Global test loss: 2.049, Global test accuracy: 27.15
Round  27, Train loss: 0.476, Test loss: 0.767, Test accuracy: 71.53
Round  27, Global train loss: 0.476, Global test loss: 1.943, Global test accuracy: 35.27
Round  28, Train loss: 0.589, Test loss: 0.780, Test accuracy: 70.25
Round  28, Global train loss: 0.589, Global test loss: 2.210, Global test accuracy: 20.83
Round  29, Train loss: 0.579, Test loss: 0.787, Test accuracy: 70.73
Round  29, Global train loss: 0.579, Global test loss: 2.083, Global test accuracy: 30.48
Round  30, Train loss: 0.476, Test loss: 0.799, Test accuracy: 70.68
Round  30, Global train loss: 0.476, Global test loss: 2.118, Global test accuracy: 30.75
Round  31, Train loss: 0.439, Test loss: 0.802, Test accuracy: 70.67
Round  31, Global train loss: 0.439, Global test loss: 2.052, Global test accuracy: 30.52
Round  32, Train loss: 0.476, Test loss: 0.795, Test accuracy: 70.88
Round  32, Global train loss: 0.476, Global test loss: 2.267, Global test accuracy: 26.45
Round  33, Train loss: 0.361, Test loss: 0.817, Test accuracy: 70.52
Round  33, Global train loss: 0.361, Global test loss: 2.036, Global test accuracy: 25.23
Round  34, Train loss: 0.496, Test loss: 0.826, Test accuracy: 70.43
Round  34, Global train loss: 0.496, Global test loss: 2.079, Global test accuracy: 28.08
Round  35, Train loss: 0.325, Test loss: 0.822, Test accuracy: 70.35
Round  35, Global train loss: 0.325, Global test loss: 1.839, Global test accuracy: 38.70
Round  36, Train loss: 0.311, Test loss: 0.853, Test accuracy: 69.88
Round  36, Global train loss: 0.311, Global test loss: 1.920, Global test accuracy: 34.27
Round  37, Train loss: 0.390, Test loss: 0.846, Test accuracy: 70.52
Round  37, Global train loss: 0.390, Global test loss: 1.896, Global test accuracy: 32.27
Round  38, Train loss: 0.513, Test loss: 0.816, Test accuracy: 71.05
Round  38, Global train loss: 0.513, Global test loss: 2.159, Global test accuracy: 22.03
Round  39, Train loss: 0.409, Test loss: 0.819, Test accuracy: 71.27
Round  39, Global train loss: 0.409, Global test loss: 2.255, Global test accuracy: 26.48
Round  40, Train loss: 0.356, Test loss: 0.822, Test accuracy: 71.08
Round  40, Global train loss: 0.356, Global test loss: 1.935, Global test accuracy: 32.45
Round  41, Train loss: 0.437, Test loss: 0.821, Test accuracy: 71.10
Round  41, Global train loss: 0.437, Global test loss: 1.979, Global test accuracy: 31.03
Round  42, Train loss: 0.483, Test loss: 0.815, Test accuracy: 72.08
Round  42, Global train loss: 0.483, Global test loss: 1.996, Global test accuracy: 31.98
Round  43, Train loss: 0.332, Test loss: 0.839, Test accuracy: 71.93
Round  43, Global train loss: 0.332, Global test loss: 2.108, Global test accuracy: 29.78
Round  44, Train loss: 0.237, Test loss: 0.855, Test accuracy: 71.63
Round  44, Global train loss: 0.237, Global test loss: 1.982, Global test accuracy: 23.65
Round  45, Train loss: 0.411, Test loss: 0.873, Test accuracy: 70.83
Round  45, Global train loss: 0.411, Global test loss: 2.219, Global test accuracy: 22.65
Round  46, Train loss: 0.615, Test loss: 0.861, Test accuracy: 71.48
Round  46, Global train loss: 0.615, Global test loss: 2.096, Global test accuracy: 27.45
Round  47, Train loss: 0.324, Test loss: 0.868, Test accuracy: 70.90
Round  47, Global train loss: 0.324, Global test loss: 1.993, Global test accuracy: 32.68
Round  48, Train loss: 0.235, Test loss: 0.876, Test accuracy: 71.27
Round  48, Global train loss: 0.235, Global test loss: 2.025, Global test accuracy: 25.50
Round  49, Train loss: 0.342, Test loss: 0.864, Test accuracy: 71.40
Round  49, Global train loss: 0.342, Global test loss: 2.067, Global test accuracy: 34.85
Round  50, Train loss: 0.493, Test loss: 0.876, Test accuracy: 71.93
Round  50, Global train loss: 0.493, Global test loss: 2.006, Global test accuracy: 29.85
Round  51, Train loss: 0.426, Test loss: 0.887, Test accuracy: 71.48
Round  51, Global train loss: 0.426, Global test loss: 2.273, Global test accuracy: 21.83
Round  52, Train loss: 0.364, Test loss: 0.899, Test accuracy: 71.40
Round  52, Global train loss: 0.364, Global test loss: 2.026, Global test accuracy: 29.57
Round  53, Train loss: 0.239, Test loss: 0.911, Test accuracy: 71.70
Round  53, Global train loss: 0.239, Global test loss: 1.883, Global test accuracy: 34.02
Round  54, Train loss: 0.250, Test loss: 0.907, Test accuracy: 71.35
Round  54, Global train loss: 0.250, Global test loss: 1.930, Global test accuracy: 27.05
Round  55, Train loss: 0.489, Test loss: 0.931, Test accuracy: 70.78
Round  55, Global train loss: 0.489, Global test loss: 1.947, Global test accuracy: 30.77
Round  56, Train loss: 0.276, Test loss: 0.951, Test accuracy: 70.93
Round  56, Global train loss: 0.276, Global test loss: 2.006, Global test accuracy: 31.13
Round  57, Train loss: 0.349, Test loss: 0.971, Test accuracy: 70.72
Round  57, Global train loss: 0.349, Global test loss: 2.019, Global test accuracy: 31.67
Round  58, Train loss: 0.278, Test loss: 0.953, Test accuracy: 70.88
Round  58, Global train loss: 0.278, Global test loss: 1.964, Global test accuracy: 33.63
Round  59, Train loss: 0.216, Test loss: 0.964, Test accuracy: 70.35
Round  59, Global train loss: 0.216, Global test loss: 2.008, Global test accuracy: 34.22
Round  60, Train loss: 0.231, Test loss: 0.978, Test accuracy: 70.65
Round  60, Global train loss: 0.231, Global test loss: 1.949, Global test accuracy: 24.95
Round  61, Train loss: 0.286, Test loss: 1.004, Test accuracy: 69.95
Round  61, Global train loss: 0.286, Global test loss: 2.090, Global test accuracy: 31.50
Round  62, Train loss: 0.294, Test loss: 0.985, Test accuracy: 71.05
Round  62, Global train loss: 0.294, Global test loss: 1.944, Global test accuracy: 33.88
Round  63, Train loss: 0.304, Test loss: 0.978, Test accuracy: 71.23
Round  63, Global train loss: 0.304, Global test loss: 2.086, Global test accuracy: 30.27
Round  64, Train loss: 0.207, Test loss: 1.079, Test accuracy: 69.90
Round  64, Global train loss: 0.207, Global test loss: 1.953, Global test accuracy: 34.28
Round  65, Train loss: 0.254, Test loss: 1.068, Test accuracy: 69.88
Round  65, Global train loss: 0.254, Global test loss: 2.082, Global test accuracy: 30.90
Round  66, Train loss: 0.339, Test loss: 1.082, Test accuracy: 69.82
Round  66, Global train loss: 0.339, Global test loss: 1.965, Global test accuracy: 31.13
Round  67, Train loss: 0.226, Test loss: 1.049, Test accuracy: 70.70
Round  67, Global train loss: 0.226, Global test loss: 1.976, Global test accuracy: 28.15
Round  68, Train loss: 0.249, Test loss: 1.067, Test accuracy: 70.22
Round  68, Global train loss: 0.249, Global test loss: 2.250, Global test accuracy: 24.82
Round  69, Train loss: 0.241, Test loss: 1.103, Test accuracy: 69.37
Round  69, Global train loss: 0.241, Global test loss: 1.958, Global test accuracy: 31.70
Round  70, Train loss: 0.364, Test loss: 1.083, Test accuracy: 69.75
Round  70, Global train loss: 0.364, Global test loss: 1.976, Global test accuracy: 33.12
Round  71, Train loss: 0.164, Test loss: 1.106, Test accuracy: 69.95
Round  71, Global train loss: 0.164, Global test loss: 2.185, Global test accuracy: 32.13
Round  72, Train loss: 0.245, Test loss: 1.130, Test accuracy: 70.07
Round  72, Global train loss: 0.245, Global test loss: 1.948, Global test accuracy: 30.58
Round  73, Train loss: 0.228, Test loss: 1.136, Test accuracy: 69.80
Round  73, Global train loss: 0.228, Global test loss: 2.120, Global test accuracy: 33.62
Round  74, Train loss: 0.219, Test loss: 1.102, Test accuracy: 70.45
Round  74, Global train loss: 0.219, Global test loss: 2.130, Global test accuracy: 30.27
Round  75, Train loss: 0.163, Test loss: 1.121, Test accuracy: 70.38
Round  75, Global train loss: 0.163, Global test loss: 1.952, Global test accuracy: 31.03
Round  76, Train loss: 0.286, Test loss: 1.117, Test accuracy: 70.67
Round  76, Global train loss: 0.286, Global test loss: 2.079, Global test accuracy: 28.88
Round  77, Train loss: 0.233, Test loss: 1.159, Test accuracy: 70.33
Round  77, Global train loss: 0.233, Global test loss: 2.047, Global test accuracy: 31.82
Round  78, Train loss: 0.246, Test loss: 1.175, Test accuracy: 70.68
Round  78, Global train loss: 0.246, Global test loss: 1.980, Global test accuracy: 33.37
Round  79, Train loss: 0.281, Test loss: 1.223, Test accuracy: 70.17
Round  79, Global train loss: 0.281, Global test loss: 2.026, Global test accuracy: 31.83
Round  80, Train loss: 0.237, Test loss: 1.196, Test accuracy: 70.77
Round  80, Global train loss: 0.237, Global test loss: 2.052, Global test accuracy: 25.90
Round  81, Train loss: 0.166, Test loss: 1.201, Test accuracy: 70.30
Round  81, Global train loss: 0.166, Global test loss: 2.047, Global test accuracy: 30.12
Round  82, Train loss: 0.165, Test loss: 1.228, Test accuracy: 70.18
Round  82, Global train loss: 0.165, Global test loss: 1.803, Global test accuracy: 32.25
Round  83, Train loss: 0.067, Test loss: 1.233, Test accuracy: 70.37
Round  83, Global train loss: 0.067, Global test loss: 1.975, Global test accuracy: 31.00
Round  84, Train loss: 0.126, Test loss: 1.213, Test accuracy: 70.10
Round  84, Global train loss: 0.126, Global test loss: 2.069, Global test accuracy: 30.43
Round  85, Train loss: 0.235, Test loss: 1.200, Test accuracy: 70.83
Round  85, Global train loss: 0.235, Global test loss: 2.076, Global test accuracy: 26.45
Round  86, Train loss: 0.090, Test loss: 1.237, Test accuracy: 70.48
Round  86, Global train loss: 0.090, Global test loss: 2.066, Global test accuracy: 33.95
Round  87, Train loss: 0.144, Test loss: 1.251, Test accuracy: 70.87
Round  87, Global train loss: 0.144, Global test loss: 2.139, Global test accuracy: 20.17
Round  88, Train loss: 0.197, Test loss: 1.280, Test accuracy: 70.50
Round  88, Global train loss: 0.197, Global test loss: 2.056, Global test accuracy: 30.55
Round  89, Train loss: 0.095, Test loss: 1.278, Test accuracy: 70.20
Round  89, Global train loss: 0.095, Global test loss: 1.990, Global test accuracy: 27.75
Round  90, Train loss: 0.195, Test loss: 1.304, Test accuracy: 70.03
Round  90, Global train loss: 0.195, Global test loss: 1.977, Global test accuracy: 32.42
Round  91, Train loss: 0.207, Test loss: 1.306, Test accuracy: 69.48
Round  91, Global train loss: 0.207, Global test loss: 2.194, Global test accuracy: 25.82
Round  92, Train loss: 0.096, Test loss: 1.319, Test accuracy: 69.83
Round  92, Global train loss: 0.096, Global test loss: 1.932, Global test accuracy: 31.58
Round  93, Train loss: 0.188, Test loss: 1.297, Test accuracy: 70.33
Round  93, Global train loss: 0.188, Global test loss: 1.935, Global test accuracy: 32.93
Round  94, Train loss: 0.139, Test loss: 1.340, Test accuracy: 70.28
Round  94, Global train loss: 0.139, Global test loss: 2.028, Global test accuracy: 30.15
Round  95, Train loss: 0.112, Test loss: 1.345, Test accuracy: 70.47
Round  95, Global train loss: 0.112, Global test loss: 1.947, Global test accuracy: 32.45
Round  96, Train loss: 0.077, Test loss: 1.425, Test accuracy: 69.58
Round  96, Global train loss: 0.077, Global test loss: 2.679, Global test accuracy: 22.85
Round  97, Train loss: 0.079, Test loss: 1.412, Test accuracy: 69.62
Round  97, Global train loss: 0.079, Global test loss: 2.307, Global test accuracy: 31.63
Round  98, Train loss: 0.168, Test loss: 1.426, Test accuracy: 70.52
Round  98, Global train loss: 0.168, Global test loss: 2.058, Global test accuracy: 29.33
Round  99, Train loss: 0.054, Test loss: 1.407, Test accuracy: 70.42
Round  99, Global train loss: 0.054, Global test loss: 1.988, Global test accuracy: 30.87
Final Round, Train loss: 0.113, Test loss: 1.490, Test accuracy: 71.10
Final Round, Global train loss: 0.113, Global test loss: 1.988, Global test accuracy: 30.87
Average accuracy final 10 rounds: 70.05666666666667 

Average global accuracy final 10 rounds: 30.003333333333334 

1130.325231552124
[1.1313300132751465, 2.262660026550293, 3.0172979831695557, 3.7719359397888184, 4.528623104095459, 5.2853102684021, 6.067995548248291, 6.850680828094482, 7.613263130187988, 8.375845432281494, 9.151776313781738, 9.927707195281982, 10.69174575805664, 11.455784320831299, 12.234954118728638, 13.014123916625977, 13.78786563873291, 14.561607360839844, 15.363831520080566, 16.16605567932129, 16.93440008163452, 17.702744483947754, 18.49656629562378, 19.290388107299805, 20.016761541366577, 20.74313497543335, 21.517306327819824, 22.2914776802063, 23.103358507156372, 23.915239334106445, 24.753711700439453, 25.59218406677246, 26.370805740356445, 27.14942741394043, 27.935752153396606, 28.722076892852783, 29.461808919906616, 30.20154094696045, 30.954079627990723, 31.706618309020996, 32.528860330581665, 33.351102352142334, 34.15627098083496, 34.96143960952759, 35.78435826301575, 36.607276916503906, 37.378368616104126, 38.149460315704346, 38.914952993392944, 39.68044567108154, 40.44296073913574, 41.20547580718994, 41.980716943740845, 42.75595808029175, 43.525068283081055, 44.29417848587036, 45.06422996520996, 45.83428144454956, 46.56766700744629, 47.30105257034302, 48.06954622268677, 48.83803987503052, 49.628519773483276, 50.418999671936035, 51.211681604385376, 52.00436353683472, 52.774606704711914, 53.54484987258911, 54.27114748954773, 54.99744510650635, 55.75318455696106, 56.50892400741577, 57.24902558326721, 57.98912715911865, 58.791558504104614, 59.593989849090576, 60.396992683410645, 61.19999551773071, 61.953306913375854, 62.706618309020996, 63.47602367401123, 64.24542903900146, 65.01884961128235, 65.79227018356323, 66.5215835571289, 67.25089693069458, 68.04440093040466, 68.83790493011475, 69.60059714317322, 70.36328935623169, 71.14414644241333, 71.92500352859497, 72.69768333435059, 73.4703631401062, 74.25985646247864, 75.04934978485107, 75.81549119949341, 76.58163261413574, 77.37761735916138, 78.17360210418701, 78.96585631370544, 79.75811052322388, 80.46879148483276, 81.17947244644165, 81.89897537231445, 82.61847829818726, 83.37333226203918, 84.12818622589111, 84.88289833068848, 85.63761043548584, 86.45271158218384, 87.26781272888184, 88.06100034713745, 88.85418796539307, 89.59353494644165, 90.33288192749023, 91.0955138206482, 91.85814571380615, 92.60284852981567, 93.3475513458252, 94.10722947120667, 94.86690759658813, 95.64698219299316, 96.4270567893982, 97.18331718444824, 97.93957757949829, 98.71239829063416, 99.48521900177002, 100.2472710609436, 101.00932312011719, 101.80143737792969, 102.59355163574219, 103.37279891967773, 104.15204620361328, 104.92272806167603, 105.69340991973877, 106.42224502563477, 107.15108013153076, 107.88396906852722, 108.61685800552368, 109.35767912864685, 110.09850025177002, 110.89419674873352, 111.68989324569702, 112.48756408691406, 113.2852349281311, 114.09933733940125, 114.91343975067139, 115.66541409492493, 116.41738843917847, 117.1538302898407, 117.89027214050293, 118.66952347755432, 119.44877481460571, 120.2100145816803, 120.97125434875488, 121.725017786026, 122.47878122329712, 123.26675391197205, 124.05472660064697, 124.8136076927185, 125.57248878479004, 126.40203332901001, 127.23157787322998, 128.0739061832428, 128.91623449325562, 129.69017696380615, 130.4641194343567, 131.24644255638123, 132.02876567840576, 132.7619435787201, 133.49512147903442, 134.27858304977417, 135.06204462051392, 135.87030506134033, 136.67856550216675, 137.48957586288452, 138.3005862236023, 139.12410140037537, 139.94761657714844, 140.73037552833557, 141.5131344795227, 142.2517602443695, 142.9903860092163, 143.7252905368805, 144.46019506454468, 145.22885942459106, 145.99752378463745, 146.78877592086792, 147.5800280570984, 148.37765383720398, 149.17527961730957, 149.94474339485168, 150.7142071723938, 151.48401546478271, 152.25382375717163, 153.00987195968628, 153.76592016220093, 154.5287413597107, 155.29156255722046, 156.8140251636505, 158.33648777008057]
[22.316666666666666, 22.316666666666666, 37.36666666666667, 37.36666666666667, 40.31666666666667, 40.31666666666667, 46.13333333333333, 46.13333333333333, 54.43333333333333, 54.43333333333333, 55.55, 55.55, 58.1, 58.1, 60.55, 60.55, 60.81666666666667, 60.81666666666667, 62.0, 62.0, 64.08333333333333, 64.08333333333333, 66.56666666666666, 66.56666666666666, 64.18333333333334, 64.18333333333334, 65.75, 65.75, 66.81666666666666, 66.81666666666666, 65.28333333333333, 65.28333333333333, 67.26666666666667, 67.26666666666667, 66.35, 66.35, 67.15, 67.15, 69.15, 69.15, 69.26666666666667, 69.26666666666667, 70.05, 70.05, 71.2, 71.2, 71.48333333333333, 71.48333333333333, 71.26666666666667, 71.26666666666667, 71.2, 71.2, 71.38333333333334, 71.38333333333334, 71.53333333333333, 71.53333333333333, 70.25, 70.25, 70.73333333333333, 70.73333333333333, 70.68333333333334, 70.68333333333334, 70.66666666666667, 70.66666666666667, 70.88333333333334, 70.88333333333334, 70.51666666666667, 70.51666666666667, 70.43333333333334, 70.43333333333334, 70.35, 70.35, 69.88333333333334, 69.88333333333334, 70.51666666666667, 70.51666666666667, 71.05, 71.05, 71.26666666666667, 71.26666666666667, 71.08333333333333, 71.08333333333333, 71.1, 71.1, 72.08333333333333, 72.08333333333333, 71.93333333333334, 71.93333333333334, 71.63333333333334, 71.63333333333334, 70.83333333333333, 70.83333333333333, 71.48333333333333, 71.48333333333333, 70.9, 70.9, 71.26666666666667, 71.26666666666667, 71.4, 71.4, 71.93333333333334, 71.93333333333334, 71.48333333333333, 71.48333333333333, 71.4, 71.4, 71.7, 71.7, 71.35, 71.35, 70.78333333333333, 70.78333333333333, 70.93333333333334, 70.93333333333334, 70.71666666666667, 70.71666666666667, 70.88333333333334, 70.88333333333334, 70.35, 70.35, 70.65, 70.65, 69.95, 69.95, 71.05, 71.05, 71.23333333333333, 71.23333333333333, 69.9, 69.9, 69.88333333333334, 69.88333333333334, 69.81666666666666, 69.81666666666666, 70.7, 70.7, 70.21666666666667, 70.21666666666667, 69.36666666666666, 69.36666666666666, 69.75, 69.75, 69.95, 69.95, 70.06666666666666, 70.06666666666666, 69.8, 69.8, 70.45, 70.45, 70.38333333333334, 70.38333333333334, 70.66666666666667, 70.66666666666667, 70.33333333333333, 70.33333333333333, 70.68333333333334, 70.68333333333334, 70.16666666666667, 70.16666666666667, 70.76666666666667, 70.76666666666667, 70.3, 70.3, 70.18333333333334, 70.18333333333334, 70.36666666666666, 70.36666666666666, 70.1, 70.1, 70.83333333333333, 70.83333333333333, 70.48333333333333, 70.48333333333333, 70.86666666666666, 70.86666666666666, 70.5, 70.5, 70.2, 70.2, 70.03333333333333, 70.03333333333333, 69.48333333333333, 69.48333333333333, 69.83333333333333, 69.83333333333333, 70.33333333333333, 70.33333333333333, 70.28333333333333, 70.28333333333333, 70.46666666666667, 70.46666666666667, 69.58333333333333, 69.58333333333333, 69.61666666666666, 69.61666666666666, 70.51666666666667, 70.51666666666667, 70.41666666666667, 70.41666666666667, 71.1, 71.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.177, Test loss: 1.951, Test accuracy: 26.08
Round   0, Global train loss: 1.177, Global test loss: 2.268, Global test accuracy: 17.25
Round   1, Train loss: 0.994, Test loss: 1.523, Test accuracy: 41.03
Round   1, Global train loss: 0.994, Global test loss: 2.116, Global test accuracy: 25.95
Round   2, Train loss: 0.877, Test loss: 1.398, Test accuracy: 44.02
Round   2, Global train loss: 0.877, Global test loss: 2.205, Global test accuracy: 21.70
Round   3, Train loss: 0.941, Test loss: 1.152, Test accuracy: 52.67
Round   3, Global train loss: 0.941, Global test loss: 2.025, Global test accuracy: 30.35
Round   4, Train loss: 0.878, Test loss: 0.986, Test accuracy: 58.23
Round   4, Global train loss: 0.878, Global test loss: 1.929, Global test accuracy: 30.33
Round   5, Train loss: 0.818, Test loss: 1.019, Test accuracy: 58.98
Round   5, Global train loss: 0.818, Global test loss: 2.149, Global test accuracy: 30.02
Round   6, Train loss: 0.789, Test loss: 0.909, Test accuracy: 63.13
Round   6, Global train loss: 0.789, Global test loss: 1.810, Global test accuracy: 40.20
Round   7, Train loss: 0.704, Test loss: 0.853, Test accuracy: 65.07
Round   7, Global train loss: 0.704, Global test loss: 1.765, Global test accuracy: 37.08
Round   8, Train loss: 0.751, Test loss: 0.826, Test accuracy: 65.72
Round   8, Global train loss: 0.751, Global test loss: 1.695, Global test accuracy: 37.12
Round   9, Train loss: 0.759, Test loss: 0.794, Test accuracy: 66.83
Round   9, Global train loss: 0.759, Global test loss: 1.858, Global test accuracy: 33.27
Round  10, Train loss: 0.705, Test loss: 0.764, Test accuracy: 68.15
Round  10, Global train loss: 0.705, Global test loss: 1.740, Global test accuracy: 40.50
Round  11, Train loss: 0.684, Test loss: 0.706, Test accuracy: 70.88
Round  11, Global train loss: 0.684, Global test loss: 1.984, Global test accuracy: 30.55
Round  12, Train loss: 0.734, Test loss: 0.748, Test accuracy: 69.45
Round  12, Global train loss: 0.734, Global test loss: 1.693, Global test accuracy: 41.23
Round  13, Train loss: 0.611, Test loss: 0.760, Test accuracy: 69.45
Round  13, Global train loss: 0.611, Global test loss: 2.100, Global test accuracy: 30.48
Round  14, Train loss: 0.650, Test loss: 0.744, Test accuracy: 70.67
Round  14, Global train loss: 0.650, Global test loss: 1.934, Global test accuracy: 38.00
Round  15, Train loss: 0.685, Test loss: 0.719, Test accuracy: 70.00
Round  15, Global train loss: 0.685, Global test loss: 1.549, Global test accuracy: 40.92
Round  16, Train loss: 0.642, Test loss: 0.726, Test accuracy: 70.95
Round  16, Global train loss: 0.642, Global test loss: 1.664, Global test accuracy: 38.80
Round  17, Train loss: 0.563, Test loss: 0.732, Test accuracy: 71.08
Round  17, Global train loss: 0.563, Global test loss: 1.662, Global test accuracy: 43.97
Round  18, Train loss: 0.640, Test loss: 0.748, Test accuracy: 71.98
Round  18, Global train loss: 0.640, Global test loss: 1.890, Global test accuracy: 40.83
Round  19, Train loss: 0.645, Test loss: 0.662, Test accuracy: 74.23
Round  19, Global train loss: 0.645, Global test loss: 1.660, Global test accuracy: 39.60
Round  20, Train loss: 0.671, Test loss: 0.637, Test accuracy: 74.98
Round  20, Global train loss: 0.671, Global test loss: 1.532, Global test accuracy: 44.05
Round  21, Train loss: 0.669, Test loss: 0.636, Test accuracy: 74.92
Round  21, Global train loss: 0.669, Global test loss: 1.715, Global test accuracy: 41.42
Round  22, Train loss: 0.641, Test loss: 0.625, Test accuracy: 75.27
Round  22, Global train loss: 0.641, Global test loss: 1.541, Global test accuracy: 43.73
Round  23, Train loss: 0.674, Test loss: 0.628, Test accuracy: 75.02
Round  23, Global train loss: 0.674, Global test loss: 1.615, Global test accuracy: 43.93
Round  24, Train loss: 0.717, Test loss: 0.620, Test accuracy: 75.03
Round  24, Global train loss: 0.717, Global test loss: 1.552, Global test accuracy: 42.63
Round  25, Train loss: 0.529, Test loss: 0.629, Test accuracy: 74.92
Round  25, Global train loss: 0.529, Global test loss: 1.472, Global test accuracy: 48.98
Round  26, Train loss: 0.516, Test loss: 0.620, Test accuracy: 74.88
Round  26, Global train loss: 0.516, Global test loss: 1.661, Global test accuracy: 38.80
Round  27, Train loss: 0.524, Test loss: 0.626, Test accuracy: 74.82
Round  27, Global train loss: 0.524, Global test loss: 1.410, Global test accuracy: 48.65
Round  28, Train loss: 0.544, Test loss: 0.622, Test accuracy: 75.65
Round  28, Global train loss: 0.544, Global test loss: 1.537, Global test accuracy: 44.15
Round  29, Train loss: 0.603, Test loss: 0.628, Test accuracy: 75.25
Round  29, Global train loss: 0.603, Global test loss: 1.538, Global test accuracy: 47.35
Round  30, Train loss: 0.490, Test loss: 0.623, Test accuracy: 75.53
Round  30, Global train loss: 0.490, Global test loss: 1.663, Global test accuracy: 46.30
Round  31, Train loss: 0.536, Test loss: 0.630, Test accuracy: 75.88
Round  31, Global train loss: 0.536, Global test loss: 1.557, Global test accuracy: 45.63
Round  32, Train loss: 0.496, Test loss: 0.597, Test accuracy: 77.15
Round  32, Global train loss: 0.496, Global test loss: 1.564, Global test accuracy: 45.55
Round  33, Train loss: 0.508, Test loss: 0.613, Test accuracy: 76.85
Round  33, Global train loss: 0.508, Global test loss: 1.540, Global test accuracy: 44.20
Round  34, Train loss: 0.445, Test loss: 0.584, Test accuracy: 77.52
Round  34, Global train loss: 0.445, Global test loss: 1.482, Global test accuracy: 49.90
Round  35, Train loss: 0.506, Test loss: 0.603, Test accuracy: 76.50
Round  35, Global train loss: 0.506, Global test loss: 1.391, Global test accuracy: 51.42
Round  36, Train loss: 0.484, Test loss: 0.588, Test accuracy: 77.03
Round  36, Global train loss: 0.484, Global test loss: 1.453, Global test accuracy: 51.28
Round  37, Train loss: 0.429, Test loss: 0.581, Test accuracy: 77.60
Round  37, Global train loss: 0.429, Global test loss: 1.384, Global test accuracy: 51.93
Round  38, Train loss: 0.517, Test loss: 0.568, Test accuracy: 78.03
Round  38, Global train loss: 0.517, Global test loss: 1.409, Global test accuracy: 48.90
Round  39, Train loss: 0.525, Test loss: 0.568, Test accuracy: 77.90
Round  39, Global train loss: 0.525, Global test loss: 1.715, Global test accuracy: 42.25
Round  40, Train loss: 0.475, Test loss: 0.577, Test accuracy: 77.68
Round  40, Global train loss: 0.475, Global test loss: 1.409, Global test accuracy: 50.52
Round  41, Train loss: 0.394, Test loss: 0.591, Test accuracy: 77.50
Round  41, Global train loss: 0.394, Global test loss: 1.322, Global test accuracy: 52.30
Round  42, Train loss: 0.468, Test loss: 0.593, Test accuracy: 77.55
Round  42, Global train loss: 0.468, Global test loss: 1.332, Global test accuracy: 52.72
Round  43, Train loss: 0.456, Test loss: 0.573, Test accuracy: 78.13
Round  43, Global train loss: 0.456, Global test loss: 1.360, Global test accuracy: 52.40
Round  44, Train loss: 0.434, Test loss: 0.578, Test accuracy: 77.97
Round  44, Global train loss: 0.434, Global test loss: 1.427, Global test accuracy: 48.42
Round  45, Train loss: 0.365, Test loss: 0.575, Test accuracy: 78.18
Round  45, Global train loss: 0.365, Global test loss: 1.616, Global test accuracy: 44.67
Round  46, Train loss: 0.415, Test loss: 0.593, Test accuracy: 77.62
Round  46, Global train loss: 0.415, Global test loss: 1.393, Global test accuracy: 51.35
Round  47, Train loss: 0.440, Test loss: 0.592, Test accuracy: 77.83
Round  47, Global train loss: 0.440, Global test loss: 1.466, Global test accuracy: 51.25
Round  48, Train loss: 0.404, Test loss: 0.570, Test accuracy: 78.35
Round  48, Global train loss: 0.404, Global test loss: 1.454, Global test accuracy: 51.37
Round  49, Train loss: 0.406, Test loss: 0.585, Test accuracy: 78.13
Round  49, Global train loss: 0.406, Global test loss: 1.643, Global test accuracy: 50.02
Round  50, Train loss: 0.374, Test loss: 0.575, Test accuracy: 78.40
Round  50, Global train loss: 0.374, Global test loss: 1.214, Global test accuracy: 56.85
Round  51, Train loss: 0.403, Test loss: 0.570, Test accuracy: 78.78
Round  51, Global train loss: 0.403, Global test loss: 1.345, Global test accuracy: 53.28
Round  52, Train loss: 0.425, Test loss: 0.593, Test accuracy: 78.50
Round  52, Global train loss: 0.425, Global test loss: 1.508, Global test accuracy: 49.52
Round  53, Train loss: 0.381, Test loss: 0.591, Test accuracy: 78.63
Round  53, Global train loss: 0.381, Global test loss: 1.276, Global test accuracy: 56.07
Round  54, Train loss: 0.348, Test loss: 0.566, Test accuracy: 79.22
Round  54, Global train loss: 0.348, Global test loss: 1.355, Global test accuracy: 52.57
Round  55, Train loss: 0.447, Test loss: 0.593, Test accuracy: 78.92
Round  55, Global train loss: 0.447, Global test loss: 1.295, Global test accuracy: 54.22
Round  56, Train loss: 0.443, Test loss: 0.584, Test accuracy: 78.98
Round  56, Global train loss: 0.443, Global test loss: 1.341, Global test accuracy: 53.23
Round  57, Train loss: 0.444, Test loss: 0.587, Test accuracy: 79.00
Round  57, Global train loss: 0.444, Global test loss: 1.320, Global test accuracy: 55.10
Round  58, Train loss: 0.370, Test loss: 0.599, Test accuracy: 79.05
Round  58, Global train loss: 0.370, Global test loss: 1.355, Global test accuracy: 54.25
Round  59, Train loss: 0.341, Test loss: 0.600, Test accuracy: 78.78
Round  59, Global train loss: 0.341, Global test loss: 1.451, Global test accuracy: 52.40
Round  60, Train loss: 0.326, Test loss: 0.612, Test accuracy: 78.52
Round  60, Global train loss: 0.326, Global test loss: 1.260, Global test accuracy: 57.23
Round  61, Train loss: 0.382, Test loss: 0.628, Test accuracy: 78.17
Round  61, Global train loss: 0.382, Global test loss: 1.487, Global test accuracy: 52.60
Round  62, Train loss: 0.444, Test loss: 0.612, Test accuracy: 78.08
Round  62, Global train loss: 0.444, Global test loss: 1.304, Global test accuracy: 55.35
Round  63, Train loss: 0.436, Test loss: 0.599, Test accuracy: 78.58
Round  63, Global train loss: 0.436, Global test loss: 1.519, Global test accuracy: 51.22
Round  64, Train loss: 0.292, Test loss: 0.590, Test accuracy: 79.00
Round  64, Global train loss: 0.292, Global test loss: 1.513, Global test accuracy: 53.55
Round  65, Train loss: 0.311, Test loss: 0.613, Test accuracy: 78.37
Round  65, Global train loss: 0.311, Global test loss: 1.423, Global test accuracy: 53.48
Round  66, Train loss: 0.378, Test loss: 0.582, Test accuracy: 79.75
Round  66, Global train loss: 0.378, Global test loss: 1.339, Global test accuracy: 55.72
Round  67, Train loss: 0.349, Test loss: 0.584, Test accuracy: 79.77
Round  67, Global train loss: 0.349, Global test loss: 1.315, Global test accuracy: 55.40
Round  68, Train loss: 0.263, Test loss: 0.576, Test accuracy: 80.18
Round  68, Global train loss: 0.263, Global test loss: 1.752, Global test accuracy: 49.68
Round  69, Train loss: 0.342, Test loss: 0.572, Test accuracy: 80.30
Round  69, Global train loss: 0.342, Global test loss: 1.309, Global test accuracy: 56.13
Round  70, Train loss: 0.331, Test loss: 0.578, Test accuracy: 79.75
Round  70, Global train loss: 0.331, Global test loss: 1.232, Global test accuracy: 58.75
Round  71, Train loss: 0.343, Test loss: 0.589, Test accuracy: 79.30
Round  71, Global train loss: 0.343, Global test loss: 1.509, Global test accuracy: 51.90
Round  72, Train loss: 0.242, Test loss: 0.588, Test accuracy: 79.50
Round  72, Global train loss: 0.242, Global test loss: 1.282, Global test accuracy: 58.13
Round  73, Train loss: 0.384, Test loss: 0.587, Test accuracy: 79.65
Round  73, Global train loss: 0.384, Global test loss: 1.745, Global test accuracy: 48.13
Round  74, Train loss: 0.324, Test loss: 0.589, Test accuracy: 79.48
Round  74, Global train loss: 0.324, Global test loss: 1.662, Global test accuracy: 49.73
Round  75, Train loss: 0.253, Test loss: 0.615, Test accuracy: 79.73
Round  75, Global train loss: 0.253, Global test loss: 1.461, Global test accuracy: 55.20
Round  76, Train loss: 0.359, Test loss: 0.620, Test accuracy: 80.12
Round  76, Global train loss: 0.359, Global test loss: 1.291, Global test accuracy: 57.37
Round  77, Train loss: 0.343, Test loss: 0.626, Test accuracy: 79.82
Round  77, Global train loss: 0.343, Global test loss: 1.540, Global test accuracy: 54.38
Round  78, Train loss: 0.288, Test loss: 0.627, Test accuracy: 80.27
Round  78, Global train loss: 0.288, Global test loss: 1.316, Global test accuracy: 57.42
Round  79, Train loss: 0.263, Test loss: 0.652, Test accuracy: 79.78
Round  79, Global train loss: 0.263, Global test loss: 1.306, Global test accuracy: 58.43
Round  80, Train loss: 0.273, Test loss: 0.641, Test accuracy: 79.83
Round  80, Global train loss: 0.273, Global test loss: 1.521, Global test accuracy: 52.73
Round  81, Train loss: 0.341, Test loss: 0.639, Test accuracy: 79.73
Round  81, Global train loss: 0.341, Global test loss: 1.376, Global test accuracy: 54.83
Round  82, Train loss: 0.332, Test loss: 0.632, Test accuracy: 79.63
Round  82, Global train loss: 0.332, Global test loss: 1.297, Global test accuracy: 56.78
Round  83, Train loss: 0.325, Test loss: 0.663, Test accuracy: 78.65
Round  83, Global train loss: 0.325, Global test loss: 1.399, Global test accuracy: 54.03
Round  84, Train loss: 0.293, Test loss: 0.629, Test accuracy: 80.05
Round  84, Global train loss: 0.293, Global test loss: 1.499, Global test accuracy: 53.00
Round  85, Train loss: 0.301, Test loss: 0.631, Test accuracy: 79.73
Round  85, Global train loss: 0.301, Global test loss: 1.380, Global test accuracy: 55.00
Round  86, Train loss: 0.269, Test loss: 0.632, Test accuracy: 79.62
Round  86, Global train loss: 0.269, Global test loss: 1.603, Global test accuracy: 54.22
Round  87, Train loss: 0.325, Test loss: 0.623, Test accuracy: 80.35
Round  87, Global train loss: 0.325, Global test loss: 1.318, Global test accuracy: 57.63
Round  88, Train loss: 0.244, Test loss: 0.623, Test accuracy: 79.97
Round  88, Global train loss: 0.244, Global test loss: 1.321, Global test accuracy: 58.17
Round  89, Train loss: 0.305, Test loss: 0.621, Test accuracy: 79.98
Round  89, Global train loss: 0.305, Global test loss: 1.374, Global test accuracy: 56.13
Round  90, Train loss: 0.247, Test loss: 0.597, Test accuracy: 80.88
Round  90, Global train loss: 0.247, Global test loss: 1.454, Global test accuracy: 57.45
Round  91, Train loss: 0.265, Test loss: 0.618, Test accuracy: 80.82
Round  91, Global train loss: 0.265, Global test loss: 1.617, Global test accuracy: 51.67
Round  92, Train loss: 0.249, Test loss: 0.622, Test accuracy: 80.90
Round  92, Global train loss: 0.249, Global test loss: 1.494, Global test accuracy: 55.65
Round  93, Train loss: 0.316, Test loss: 0.630, Test accuracy: 80.97
Round  93, Global train loss: 0.316, Global test loss: 1.338, Global test accuracy: 57.30
Round  94, Train loss: 0.273, Test loss: 0.659, Test accuracy: 79.95
Round  94, Global train loss: 0.273, Global test loss: 1.573, Global test accuracy: 53.62
Round  95, Train loss: 0.325, Test loss: 0.669, Test accuracy: 79.65
Round  95, Global train loss: 0.325, Global test loss: 1.501, Global test accuracy: 55.57
Round  96, Train loss: 0.304, Test loss: 0.664, Test accuracy: 79.58
Round  96, Global train loss: 0.304, Global test loss: 1.672, Global test accuracy: 52.68
Round  97, Train loss: 0.245, Test loss: 0.663, Test accuracy: 79.70
Round  97, Global train loss: 0.245, Global test loss: 1.783, Global test accuracy: 50.68
Round  98, Train loss: 0.259, Test loss: 0.660, Test accuracy: 80.12
Round  98, Global train loss: 0.259, Global test loss: 1.623, Global test accuracy: 52.02
Round  99, Train loss: 0.262, Test loss: 0.626, Test accuracy: 80.63
Round  99, Global train loss: 0.262, Global test loss: 1.366, Global test accuracy: 57.22
Final Round, Train loss: 0.187, Test loss: 0.685, Test accuracy: 81.53
Final Round, Global train loss: 0.187, Global test loss: 1.366, Global test accuracy: 57.22
Average accuracy final 10 rounds: 80.32000000000001 

Average global accuracy final 10 rounds: 54.385 

1163.9160010814667
[1.0625369548797607, 2.1250739097595215, 2.916266679763794, 3.7074594497680664, 4.495502233505249, 5.283545017242432, 6.02130913734436, 6.759073257446289, 7.5132646560668945, 8.2674560546875, 9.019875288009644, 9.772294521331787, 10.546301364898682, 11.320308208465576, 12.098976373672485, 12.877644538879395, 13.70060396194458, 14.523563385009766, 15.266304731369019, 16.00904607772827, 16.77107572555542, 17.53310537338257, 18.28285527229309, 19.032605171203613, 19.764678955078125, 20.496752738952637, 21.296351194381714, 22.09594964981079, 22.87353229522705, 23.65111494064331, 24.37235426902771, 25.09359359741211, 25.897391080856323, 26.701188564300537, 27.50329041481018, 28.305392265319824, 29.093215465545654, 29.881038665771484, 30.689685821533203, 31.498332977294922, 32.22830533981323, 32.95827770233154, 33.692152976989746, 34.42602825164795, 35.168769121170044, 35.91150999069214, 36.68334484100342, 37.4551796913147, 38.266809940338135, 39.07844018936157, 39.8878333568573, 40.69722652435303, 41.475090980529785, 42.25295543670654, 43.00212121009827, 43.75128698348999, 44.46848177909851, 45.18567657470703, 45.979817152023315, 46.7739577293396, 47.57876753807068, 48.38357734680176, 49.16060209274292, 49.93762683868408, 50.72744560241699, 51.5172643661499, 52.292341232299805, 53.06741809844971, 53.87555480003357, 54.68369150161743, 55.504976987838745, 56.32626247406006, 57.1263861656189, 57.926509857177734, 58.76382565498352, 59.60114145278931, 60.3879554271698, 61.17476940155029, 61.94718408584595, 62.7195987701416, 63.57116460800171, 64.42273044586182, 65.2951672077179, 66.16760396957397, 66.97661447525024, 67.78562498092651, 68.62285017967224, 69.46007537841797, 70.22833323478699, 70.996591091156, 71.73783755302429, 72.47908401489258, 73.30959486961365, 74.14010572433472, 74.89757466316223, 75.65504360198975, 76.4175717830658, 77.18009996414185, 77.95907306671143, 78.738046169281, 79.51169633865356, 80.28534650802612, 81.10744452476501, 81.9295425415039, 82.72527694702148, 83.52101135253906, 84.32242465019226, 85.12383794784546, 85.86912608146667, 86.61441421508789, 87.3991231918335, 88.1838321685791, 88.92599129676819, 89.66815042495728, 90.51553344726562, 91.36291646957397, 92.2021050453186, 93.04129362106323, 93.82372713088989, 94.60616064071655, 95.3891053199768, 96.17204999923706, 96.9127185344696, 97.65338706970215, 98.41142177581787, 99.1694564819336, 99.95365786552429, 100.73785924911499, 101.53106832504272, 102.32427740097046, 103.12520599365234, 103.92613458633423, 104.73385739326477, 105.54158020019531, 106.32687830924988, 107.11217641830444, 107.90177750587463, 108.69137859344482, 109.47809314727783, 110.26480770111084, 111.07795476913452, 111.8911018371582, 112.64877104759216, 113.40644025802612, 114.14249110221863, 114.87854194641113, 115.66844081878662, 116.45833969116211, 117.27810788154602, 118.09787607192993, 118.91418647766113, 119.73049688339233, 120.55782556533813, 121.38515424728394, 122.12121653556824, 122.85727882385254, 123.61159777641296, 124.36591672897339, 125.20525741577148, 126.04459810256958, 126.7859206199646, 127.52724313735962, 128.33972215652466, 129.1522011756897, 129.96511697769165, 130.7780327796936, 131.55923414230347, 132.34043550491333, 133.12525629997253, 133.91007709503174, 134.71157503128052, 135.5130729675293, 136.29111123085022, 137.06914949417114, 137.85109543800354, 138.63304138183594, 139.37630820274353, 140.11957502365112, 140.86345982551575, 141.60734462738037, 142.38824915885925, 143.16915369033813, 143.9605221748352, 144.75189065933228, 145.61501741409302, 146.47814416885376, 147.2843451499939, 148.09054613113403, 148.82809138298035, 149.56563663482666, 150.3201560974121, 151.07467555999756, 151.84093570709229, 152.607195854187, 153.38736057281494, 154.16752529144287, 154.93794012069702, 155.70835494995117, 156.505473613739, 157.30259227752686, 158.86659169197083, 160.4305911064148]
[26.083333333333332, 26.083333333333332, 41.03333333333333, 41.03333333333333, 44.016666666666666, 44.016666666666666, 52.666666666666664, 52.666666666666664, 58.233333333333334, 58.233333333333334, 58.983333333333334, 58.983333333333334, 63.13333333333333, 63.13333333333333, 65.06666666666666, 65.06666666666666, 65.71666666666667, 65.71666666666667, 66.83333333333333, 66.83333333333333, 68.15, 68.15, 70.88333333333334, 70.88333333333334, 69.45, 69.45, 69.45, 69.45, 70.66666666666667, 70.66666666666667, 70.0, 70.0, 70.95, 70.95, 71.08333333333333, 71.08333333333333, 71.98333333333333, 71.98333333333333, 74.23333333333333, 74.23333333333333, 74.98333333333333, 74.98333333333333, 74.91666666666667, 74.91666666666667, 75.26666666666667, 75.26666666666667, 75.01666666666667, 75.01666666666667, 75.03333333333333, 75.03333333333333, 74.91666666666667, 74.91666666666667, 74.88333333333334, 74.88333333333334, 74.81666666666666, 74.81666666666666, 75.65, 75.65, 75.25, 75.25, 75.53333333333333, 75.53333333333333, 75.88333333333334, 75.88333333333334, 77.15, 77.15, 76.85, 76.85, 77.51666666666667, 77.51666666666667, 76.5, 76.5, 77.03333333333333, 77.03333333333333, 77.6, 77.6, 78.03333333333333, 78.03333333333333, 77.9, 77.9, 77.68333333333334, 77.68333333333334, 77.5, 77.5, 77.55, 77.55, 78.13333333333334, 78.13333333333334, 77.96666666666667, 77.96666666666667, 78.18333333333334, 78.18333333333334, 77.61666666666666, 77.61666666666666, 77.83333333333333, 77.83333333333333, 78.35, 78.35, 78.13333333333334, 78.13333333333334, 78.4, 78.4, 78.78333333333333, 78.78333333333333, 78.5, 78.5, 78.63333333333334, 78.63333333333334, 79.21666666666667, 79.21666666666667, 78.91666666666667, 78.91666666666667, 78.98333333333333, 78.98333333333333, 79.0, 79.0, 79.05, 79.05, 78.78333333333333, 78.78333333333333, 78.51666666666667, 78.51666666666667, 78.16666666666667, 78.16666666666667, 78.08333333333333, 78.08333333333333, 78.58333333333333, 78.58333333333333, 79.0, 79.0, 78.36666666666666, 78.36666666666666, 79.75, 79.75, 79.76666666666667, 79.76666666666667, 80.18333333333334, 80.18333333333334, 80.3, 80.3, 79.75, 79.75, 79.3, 79.3, 79.5, 79.5, 79.65, 79.65, 79.48333333333333, 79.48333333333333, 79.73333333333333, 79.73333333333333, 80.11666666666666, 80.11666666666666, 79.81666666666666, 79.81666666666666, 80.26666666666667, 80.26666666666667, 79.78333333333333, 79.78333333333333, 79.83333333333333, 79.83333333333333, 79.73333333333333, 79.73333333333333, 79.63333333333334, 79.63333333333334, 78.65, 78.65, 80.05, 80.05, 79.73333333333333, 79.73333333333333, 79.61666666666666, 79.61666666666666, 80.35, 80.35, 79.96666666666667, 79.96666666666667, 79.98333333333333, 79.98333333333333, 80.88333333333334, 80.88333333333334, 80.81666666666666, 80.81666666666666, 80.9, 80.9, 80.96666666666667, 80.96666666666667, 79.95, 79.95, 79.65, 79.65, 79.58333333333333, 79.58333333333333, 79.7, 79.7, 80.11666666666666, 80.11666666666666, 80.63333333333334, 80.63333333333334, 81.53333333333333, 81.53333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.248, Test loss: 2.007, Test accuracy: 26.63
Round   0, Global train loss: 1.248, Global test loss: 2.311, Global test accuracy: 19.67
Round   1, Train loss: 1.120, Test loss: 1.622, Test accuracy: 35.47
Round   1, Global train loss: 1.120, Global test loss: 2.226, Global test accuracy: 17.23
Round   2, Train loss: 0.943, Test loss: 1.500, Test accuracy: 40.52
Round   2, Global train loss: 0.943, Global test loss: 2.301, Global test accuracy: 18.87
Round   3, Train loss: 0.971, Test loss: 1.221, Test accuracy: 48.27
Round   3, Global train loss: 0.971, Global test loss: 2.044, Global test accuracy: 27.53
Round   4, Train loss: 0.888, Test loss: 1.053, Test accuracy: 53.77
Round   4, Global train loss: 0.888, Global test loss: 1.955, Global test accuracy: 28.47
Round   5, Train loss: 0.874, Test loss: 1.057, Test accuracy: 55.58
Round   5, Global train loss: 0.874, Global test loss: 2.090, Global test accuracy: 27.67
Round   6, Train loss: 0.773, Test loss: 0.981, Test accuracy: 58.88
Round   6, Global train loss: 0.773, Global test loss: 1.908, Global test accuracy: 35.80
Round   7, Train loss: 0.845, Test loss: 0.934, Test accuracy: 59.85
Round   7, Global train loss: 0.845, Global test loss: 1.760, Global test accuracy: 36.02
Round   8, Train loss: 0.877, Test loss: 0.849, Test accuracy: 63.88
Round   8, Global train loss: 0.877, Global test loss: 1.744, Global test accuracy: 36.48
Round   9, Train loss: 0.837, Test loss: 0.816, Test accuracy: 65.22
Round   9, Global train loss: 0.837, Global test loss: 1.828, Global test accuracy: 33.60
Round  10, Train loss: 0.747, Test loss: 0.769, Test accuracy: 67.65
Round  10, Global train loss: 0.747, Global test loss: 1.748, Global test accuracy: 38.83
Round  11, Train loss: 0.754, Test loss: 0.749, Test accuracy: 68.97
Round  11, Global train loss: 0.754, Global test loss: 1.958, Global test accuracy: 29.95
Round  12, Train loss: 0.721, Test loss: 0.784, Test accuracy: 67.98
Round  12, Global train loss: 0.721, Global test loss: 1.763, Global test accuracy: 40.38
Round  13, Train loss: 0.691, Test loss: 0.791, Test accuracy: 68.43
Round  13, Global train loss: 0.691, Global test loss: 2.118, Global test accuracy: 32.27
Round  14, Train loss: 0.634, Test loss: 0.781, Test accuracy: 68.83
Round  14, Global train loss: 0.634, Global test loss: 1.972, Global test accuracy: 36.52
Round  15, Train loss: 0.703, Test loss: 0.756, Test accuracy: 68.15
Round  15, Global train loss: 0.703, Global test loss: 1.568, Global test accuracy: 40.50
Round  16, Train loss: 0.658, Test loss: 0.757, Test accuracy: 69.00
Round  16, Global train loss: 0.658, Global test loss: 1.614, Global test accuracy: 42.12
Round  17, Train loss: 0.689, Test loss: 0.775, Test accuracy: 68.28
Round  17, Global train loss: 0.689, Global test loss: 1.690, Global test accuracy: 40.45
Round  18, Train loss: 0.630, Test loss: 0.778, Test accuracy: 70.03
Round  18, Global train loss: 0.630, Global test loss: 1.909, Global test accuracy: 38.42
Round  19, Train loss: 0.619, Test loss: 0.703, Test accuracy: 71.62
Round  19, Global train loss: 0.619, Global test loss: 1.736, Global test accuracy: 36.27
Round  20, Train loss: 0.585, Test loss: 0.690, Test accuracy: 72.05
Round  20, Global train loss: 0.585, Global test loss: 1.542, Global test accuracy: 43.67
Round  21, Train loss: 0.638, Test loss: 0.680, Test accuracy: 72.28
Round  21, Global train loss: 0.638, Global test loss: 1.706, Global test accuracy: 39.93
Round  22, Train loss: 0.666, Test loss: 0.685, Test accuracy: 72.48
Round  22, Global train loss: 0.666, Global test loss: 1.497, Global test accuracy: 45.62
Round  23, Train loss: 0.660, Test loss: 0.667, Test accuracy: 73.28
Round  23, Global train loss: 0.660, Global test loss: 1.562, Global test accuracy: 44.73
Round  24, Train loss: 0.694, Test loss: 0.665, Test accuracy: 73.00
Round  24, Global train loss: 0.694, Global test loss: 1.623, Global test accuracy: 41.05
Round  25, Train loss: 0.558, Test loss: 0.658, Test accuracy: 73.38
Round  25, Global train loss: 0.558, Global test loss: 1.470, Global test accuracy: 49.10
Round  26, Train loss: 0.605, Test loss: 0.656, Test accuracy: 73.45
Round  26, Global train loss: 0.605, Global test loss: 1.627, Global test accuracy: 40.97
Round  27, Train loss: 0.609, Test loss: 0.652, Test accuracy: 74.18
Round  27, Global train loss: 0.609, Global test loss: 1.450, Global test accuracy: 44.30
Round  28, Train loss: 0.575, Test loss: 0.632, Test accuracy: 74.70
Round  28, Global train loss: 0.575, Global test loss: 1.508, Global test accuracy: 44.53
Round  29, Train loss: 0.607, Test loss: 0.641, Test accuracy: 74.23
Round  29, Global train loss: 0.607, Global test loss: 1.485, Global test accuracy: 47.12
Round  30, Train loss: 0.537, Test loss: 0.625, Test accuracy: 75.62
Round  30, Global train loss: 0.537, Global test loss: 1.638, Global test accuracy: 46.77
Round  31, Train loss: 0.566, Test loss: 0.629, Test accuracy: 75.60
Round  31, Global train loss: 0.566, Global test loss: 1.660, Global test accuracy: 44.22
Round  32, Train loss: 0.546, Test loss: 0.633, Test accuracy: 75.42
Round  32, Global train loss: 0.546, Global test loss: 1.520, Global test accuracy: 45.20
Round  33, Train loss: 0.597, Test loss: 0.647, Test accuracy: 74.97
Round  33, Global train loss: 0.597, Global test loss: 1.532, Global test accuracy: 42.57
Round  34, Train loss: 0.496, Test loss: 0.628, Test accuracy: 75.57
Round  34, Global train loss: 0.496, Global test loss: 1.460, Global test accuracy: 48.92
Round  35, Train loss: 0.497, Test loss: 0.634, Test accuracy: 75.30
Round  35, Global train loss: 0.497, Global test loss: 1.377, Global test accuracy: 51.17
Round  36, Train loss: 0.527, Test loss: 0.641, Test accuracy: 75.00
Round  36, Global train loss: 0.527, Global test loss: 1.398, Global test accuracy: 51.05
Round  37, Train loss: 0.512, Test loss: 0.626, Test accuracy: 75.95
Round  37, Global train loss: 0.512, Global test loss: 1.415, Global test accuracy: 49.35
Round  38, Train loss: 0.512, Test loss: 0.630, Test accuracy: 76.10
Round  38, Global train loss: 0.512, Global test loss: 1.434, Global test accuracy: 49.33
Round  39, Train loss: 0.510, Test loss: 0.640, Test accuracy: 75.33
Round  39, Global train loss: 0.510, Global test loss: 1.667, Global test accuracy: 44.67
Round  40, Train loss: 0.464, Test loss: 0.650, Test accuracy: 74.98
Round  40, Global train loss: 0.464, Global test loss: 1.421, Global test accuracy: 49.92
Round  41, Train loss: 0.430, Test loss: 0.653, Test accuracy: 75.02
Round  41, Global train loss: 0.430, Global test loss: 1.362, Global test accuracy: 51.15
Round  42, Train loss: 0.599, Test loss: 0.665, Test accuracy: 74.60
Round  42, Global train loss: 0.599, Global test loss: 1.331, Global test accuracy: 53.33
Round  43, Train loss: 0.499, Test loss: 0.665, Test accuracy: 74.50
Round  43, Global train loss: 0.499, Global test loss: 1.289, Global test accuracy: 54.13
Round  44, Train loss: 0.414, Test loss: 0.638, Test accuracy: 75.73
Round  44, Global train loss: 0.414, Global test loss: 1.436, Global test accuracy: 47.18
Round  45, Train loss: 0.452, Test loss: 0.627, Test accuracy: 75.93
Round  45, Global train loss: 0.452, Global test loss: 1.545, Global test accuracy: 45.42
Round  46, Train loss: 0.460, Test loss: 0.629, Test accuracy: 75.95
Round  46, Global train loss: 0.460, Global test loss: 1.359, Global test accuracy: 51.92
Round  47, Train loss: 0.429, Test loss: 0.626, Test accuracy: 76.43
Round  47, Global train loss: 0.429, Global test loss: 1.426, Global test accuracy: 52.03
Round  48, Train loss: 0.499, Test loss: 0.601, Test accuracy: 77.40
Round  48, Global train loss: 0.499, Global test loss: 1.359, Global test accuracy: 51.58
Round  49, Train loss: 0.407, Test loss: 0.605, Test accuracy: 77.35
Round  49, Global train loss: 0.407, Global test loss: 1.477, Global test accuracy: 50.63
Round  50, Train loss: 0.442, Test loss: 0.607, Test accuracy: 77.33
Round  50, Global train loss: 0.442, Global test loss: 1.249, Global test accuracy: 55.92
Round  51, Train loss: 0.443, Test loss: 0.609, Test accuracy: 77.38
Round  51, Global train loss: 0.443, Global test loss: 1.331, Global test accuracy: 53.90
Round  52, Train loss: 0.400, Test loss: 0.614, Test accuracy: 77.77
Round  52, Global train loss: 0.400, Global test loss: 1.346, Global test accuracy: 53.25
Round  53, Train loss: 0.495, Test loss: 0.612, Test accuracy: 77.60
Round  53, Global train loss: 0.495, Global test loss: 1.264, Global test accuracy: 55.70
Round  54, Train loss: 0.386, Test loss: 0.607, Test accuracy: 77.88
Round  54, Global train loss: 0.386, Global test loss: 1.322, Global test accuracy: 53.22
Round  55, Train loss: 0.491, Test loss: 0.625, Test accuracy: 77.22
Round  55, Global train loss: 0.491, Global test loss: 1.344, Global test accuracy: 53.00
Round  56, Train loss: 0.521, Test loss: 0.621, Test accuracy: 77.35
Round  56, Global train loss: 0.521, Global test loss: 1.291, Global test accuracy: 55.42
Round  57, Train loss: 0.470, Test loss: 0.626, Test accuracy: 77.33
Round  57, Global train loss: 0.470, Global test loss: 1.314, Global test accuracy: 54.52
Round  58, Train loss: 0.409, Test loss: 0.632, Test accuracy: 77.43
Round  58, Global train loss: 0.409, Global test loss: 1.388, Global test accuracy: 52.97
Round  59, Train loss: 0.380, Test loss: 0.646, Test accuracy: 76.87
Round  59, Global train loss: 0.380, Global test loss: 1.534, Global test accuracy: 51.38
Round  60, Train loss: 0.454, Test loss: 0.639, Test accuracy: 77.38
Round  60, Global train loss: 0.454, Global test loss: 1.313, Global test accuracy: 54.42
Round  61, Train loss: 0.420, Test loss: 0.649, Test accuracy: 77.07
Round  61, Global train loss: 0.420, Global test loss: 1.524, Global test accuracy: 51.32
Round  62, Train loss: 0.397, Test loss: 0.638, Test accuracy: 77.45
Round  62, Global train loss: 0.397, Global test loss: 1.332, Global test accuracy: 54.97
Round  63, Train loss: 0.429, Test loss: 0.618, Test accuracy: 77.55
Round  63, Global train loss: 0.429, Global test loss: 1.458, Global test accuracy: 52.13
Round  64, Train loss: 0.384, Test loss: 0.622, Test accuracy: 77.93
Round  64, Global train loss: 0.384, Global test loss: 1.480, Global test accuracy: 51.98
Round  65, Train loss: 0.387, Test loss: 0.631, Test accuracy: 77.27
Round  65, Global train loss: 0.387, Global test loss: 1.435, Global test accuracy: 53.28
Round  66, Train loss: 0.437, Test loss: 0.626, Test accuracy: 77.70
Round  66, Global train loss: 0.437, Global test loss: 1.349, Global test accuracy: 53.68
Round  67, Train loss: 0.430, Test loss: 0.627, Test accuracy: 77.93
Round  67, Global train loss: 0.430, Global test loss: 1.339, Global test accuracy: 53.42
Round  68, Train loss: 0.328, Test loss: 0.642, Test accuracy: 77.77
Round  68, Global train loss: 0.328, Global test loss: 1.669, Global test accuracy: 48.75
Round  69, Train loss: 0.404, Test loss: 0.646, Test accuracy: 77.57
Round  69, Global train loss: 0.404, Global test loss: 1.278, Global test accuracy: 57.03
Round  70, Train loss: 0.389, Test loss: 0.635, Test accuracy: 77.78
Round  70, Global train loss: 0.389, Global test loss: 1.263, Global test accuracy: 57.25
Round  71, Train loss: 0.396, Test loss: 0.633, Test accuracy: 77.97
Round  71, Global train loss: 0.396, Global test loss: 1.481, Global test accuracy: 51.93
Round  72, Train loss: 0.306, Test loss: 0.628, Test accuracy: 79.08
Round  72, Global train loss: 0.306, Global test loss: 1.362, Global test accuracy: 55.13
Round  73, Train loss: 0.405, Test loss: 0.634, Test accuracy: 78.88
Round  73, Global train loss: 0.405, Global test loss: 1.779, Global test accuracy: 47.18
Round  74, Train loss: 0.358, Test loss: 0.649, Test accuracy: 78.42
Round  74, Global train loss: 0.358, Global test loss: 1.572, Global test accuracy: 50.90
Round  75, Train loss: 0.356, Test loss: 0.635, Test accuracy: 78.68
Round  75, Global train loss: 0.356, Global test loss: 1.469, Global test accuracy: 53.27
Round  76, Train loss: 0.405, Test loss: 0.621, Test accuracy: 78.80
Round  76, Global train loss: 0.405, Global test loss: 1.255, Global test accuracy: 57.18
Round  77, Train loss: 0.360, Test loss: 0.629, Test accuracy: 78.60
Round  77, Global train loss: 0.360, Global test loss: 1.592, Global test accuracy: 53.65
Round  78, Train loss: 0.347, Test loss: 0.634, Test accuracy: 78.20
Round  78, Global train loss: 0.347, Global test loss: 1.331, Global test accuracy: 55.83
Round  79, Train loss: 0.330, Test loss: 0.653, Test accuracy: 78.38
Round  79, Global train loss: 0.330, Global test loss: 1.317, Global test accuracy: 56.88
Round  80, Train loss: 0.326, Test loss: 0.661, Test accuracy: 78.15
Round  80, Global train loss: 0.326, Global test loss: 1.445, Global test accuracy: 53.25
Round  81, Train loss: 0.351, Test loss: 0.656, Test accuracy: 78.05
Round  81, Global train loss: 0.351, Global test loss: 1.345, Global test accuracy: 55.47
Round  82, Train loss: 0.318, Test loss: 0.672, Test accuracy: 77.63
Round  82, Global train loss: 0.318, Global test loss: 1.271, Global test accuracy: 57.75
Round  83, Train loss: 0.285, Test loss: 0.693, Test accuracy: 77.67
Round  83, Global train loss: 0.285, Global test loss: 1.392, Global test accuracy: 54.63
Round  84, Train loss: 0.294, Test loss: 0.668, Test accuracy: 78.45
Round  84, Global train loss: 0.294, Global test loss: 1.298, Global test accuracy: 57.45
Round  85, Train loss: 0.333, Test loss: 0.670, Test accuracy: 78.83
Round  85, Global train loss: 0.333, Global test loss: 1.435, Global test accuracy: 54.50
Round  86, Train loss: 0.322, Test loss: 0.680, Test accuracy: 78.50
Round  86, Global train loss: 0.322, Global test loss: 1.520, Global test accuracy: 54.73
Round  87, Train loss: 0.346, Test loss: 0.689, Test accuracy: 78.23
Round  87, Global train loss: 0.346, Global test loss: 1.272, Global test accuracy: 58.68
Round  88, Train loss: 0.340, Test loss: 0.673, Test accuracy: 79.12
Round  88, Global train loss: 0.340, Global test loss: 1.357, Global test accuracy: 57.12
Round  89, Train loss: 0.304, Test loss: 0.665, Test accuracy: 79.33
Round  89, Global train loss: 0.304, Global test loss: 1.309, Global test accuracy: 56.75
Round  90, Train loss: 0.350, Test loss: 0.689, Test accuracy: 78.73
Round  90, Global train loss: 0.350, Global test loss: 1.486, Global test accuracy: 53.72
Round  91, Train loss: 0.288, Test loss: 0.670, Test accuracy: 78.85
Round  91, Global train loss: 0.288, Global test loss: 1.563, Global test accuracy: 52.62
Round  92, Train loss: 0.238, Test loss: 0.683, Test accuracy: 78.97
Round  92, Global train loss: 0.238, Global test loss: 1.521, Global test accuracy: 53.88
Round  93, Train loss: 0.278, Test loss: 0.687, Test accuracy: 78.80
Round  93, Global train loss: 0.278, Global test loss: 1.352, Global test accuracy: 57.12
Round  94, Train loss: 0.363, Test loss: 0.686, Test accuracy: 78.52
Round  94, Global train loss: 0.363, Global test loss: 1.503, Global test accuracy: 53.45/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 0.358, Test loss: 0.714, Test accuracy: 77.72
Round  95, Global train loss: 0.358, Global test loss: 1.482, Global test accuracy: 53.25
Round  96, Train loss: 0.326, Test loss: 0.701, Test accuracy: 78.37
Round  96, Global train loss: 0.326, Global test loss: 1.773, Global test accuracy: 50.43
Round  97, Train loss: 0.277, Test loss: 0.686, Test accuracy: 78.85
Round  97, Global train loss: 0.277, Global test loss: 1.677, Global test accuracy: 51.27
Round  98, Train loss: 0.271, Test loss: 0.702, Test accuracy: 78.80
Round  98, Global train loss: 0.271, Global test loss: 1.667, Global test accuracy: 52.47
Round  99, Train loss: 0.261, Test loss: 0.700, Test accuracy: 79.23
Round  99, Global train loss: 0.261, Global test loss: 1.417, Global test accuracy: 56.08
Final Round, Train loss: 0.217, Test loss: 0.778, Test accuracy: 78.40
Final Round, Global train loss: 0.217, Global test loss: 1.417, Global test accuracy: 56.08
Average accuracy final 10 rounds: 78.68333333333334 

Average global accuracy final 10 rounds: 53.42833333333334 

1213.5610797405243
[1.1058754920959473, 2.2117509841918945, 3.0256381034851074, 3.8395252227783203, 4.673443078994751, 5.507360935211182, 6.3731529712677, 7.238945007324219, 8.144968509674072, 9.050992012023926, 9.90628957748413, 10.761587142944336, 11.581951141357422, 12.402315139770508, 13.225547313690186, 14.048779487609863, 14.868460893630981, 15.6881422996521, 16.58035373687744, 17.472565174102783, 18.392992973327637, 19.31342077255249, 20.233253479003906, 21.153086185455322, 22.02312994003296, 22.893173694610596, 23.729534149169922, 24.565894603729248, 25.39100694656372, 26.216119289398193, 27.11028814315796, 28.004456996917725, 28.84669804573059, 29.688939094543457, 30.587860584259033, 31.48678207397461, 32.328908920288086, 33.17103576660156, 34.04274773597717, 34.91445970535278, 35.80776119232178, 36.70106267929077, 37.58826684951782, 38.47547101974487, 39.3313205242157, 40.18717002868652, 41.022191286087036, 41.85721254348755, 42.67024278640747, 43.48327302932739, 44.28338289260864, 45.08349275588989, 46.00225472450256, 46.921016693115234, 47.78743863105774, 48.653860569000244, 49.50111484527588, 50.348369121551514, 51.201361894607544, 52.054354667663574, 52.856701374053955, 53.659048080444336, 54.52625799179077, 55.39346790313721, 56.24641251564026, 57.09935712814331, 57.94963359832764, 58.79991006851196, 59.65355157852173, 60.507193088531494, 61.35157895088196, 62.19596481323242, 63.05003547668457, 63.90410614013672, 64.81117224693298, 65.71823835372925, 66.59892392158508, 67.47960948944092, 68.27188420295715, 69.06415891647339, 69.86018204689026, 70.65620517730713, 71.49691581726074, 72.33762645721436, 73.21423149108887, 74.09083652496338, 74.95801854133606, 75.82520055770874, 76.6998724937439, 77.57454442977905, 78.4028389453888, 79.23113346099854, 80.05692267417908, 80.88271188735962, 81.71937608718872, 82.55604028701782, 83.37918615341187, 84.20233201980591, 85.06179809570312, 85.92126417160034, 86.779057264328, 87.63685035705566, 88.48510956764221, 89.33336877822876, 90.17756056785583, 91.02175235748291, 91.91365098953247, 92.80554962158203, 93.69069528579712, 94.5758409500122, 95.41445136070251, 96.25306177139282, 97.05676531791687, 97.86046886444092, 98.6712851524353, 99.48210144042969, 100.35837459564209, 101.23464775085449, 102.10062909126282, 102.96661043167114, 103.84721755981445, 104.72782468795776, 105.57242178916931, 106.41701889038086, 107.1935887336731, 107.97015857696533, 108.77107644081116, 109.57199430465698, 110.3898720741272, 111.20774984359741, 112.04442930221558, 112.88110876083374, 113.71069049835205, 114.54027223587036, 115.36821866035461, 116.19616508483887, 117.04145193099976, 117.88673877716064, 118.7482237815857, 119.60970878601074, 120.58006072044373, 121.55041265487671, 122.43808388710022, 123.32575511932373, 124.2448501586914, 125.16394519805908, 126.06956601142883, 126.97518682479858, 127.91122698783875, 128.8472671508789, 129.8066589832306, 130.76605081558228, 131.7252516746521, 132.68445253372192, 133.53808283805847, 134.39171314239502, 135.25447964668274, 136.11724615097046, 136.99767470359802, 137.8781032562256, 138.7664532661438, 139.654803276062, 140.58547258377075, 141.5161418914795, 142.42564392089844, 143.33514595031738, 144.23023509979248, 145.12532424926758, 146.01462697982788, 146.90392971038818, 147.72548699378967, 148.54704427719116, 149.3733217716217, 150.19959926605225, 151.0066261291504, 151.81365299224854, 152.60655808448792, 153.3994631767273, 154.20438957214355, 155.00931596755981, 155.8790602684021, 156.74880456924438, 157.60124802589417, 158.45369148254395, 159.30419993400574, 160.15470838546753, 160.9461212158203, 161.7375340461731, 162.52141666412354, 163.30529928207397, 164.09924745559692, 164.89319562911987, 165.73931884765625, 166.58544206619263, 167.4190173149109, 168.25259256362915, 169.15586376190186, 170.05913496017456, 170.87006759643555, 171.68100023269653, 173.34199333190918, 175.00298643112183]
[26.633333333333333, 26.633333333333333, 35.46666666666667, 35.46666666666667, 40.516666666666666, 40.516666666666666, 48.266666666666666, 48.266666666666666, 53.766666666666666, 53.766666666666666, 55.583333333333336, 55.583333333333336, 58.88333333333333, 58.88333333333333, 59.85, 59.85, 63.88333333333333, 63.88333333333333, 65.21666666666667, 65.21666666666667, 67.65, 67.65, 68.96666666666667, 68.96666666666667, 67.98333333333333, 67.98333333333333, 68.43333333333334, 68.43333333333334, 68.83333333333333, 68.83333333333333, 68.15, 68.15, 69.0, 69.0, 68.28333333333333, 68.28333333333333, 70.03333333333333, 70.03333333333333, 71.61666666666666, 71.61666666666666, 72.05, 72.05, 72.28333333333333, 72.28333333333333, 72.48333333333333, 72.48333333333333, 73.28333333333333, 73.28333333333333, 73.0, 73.0, 73.38333333333334, 73.38333333333334, 73.45, 73.45, 74.18333333333334, 74.18333333333334, 74.7, 74.7, 74.23333333333333, 74.23333333333333, 75.61666666666666, 75.61666666666666, 75.6, 75.6, 75.41666666666667, 75.41666666666667, 74.96666666666667, 74.96666666666667, 75.56666666666666, 75.56666666666666, 75.3, 75.3, 75.0, 75.0, 75.95, 75.95, 76.1, 76.1, 75.33333333333333, 75.33333333333333, 74.98333333333333, 74.98333333333333, 75.01666666666667, 75.01666666666667, 74.6, 74.6, 74.5, 74.5, 75.73333333333333, 75.73333333333333, 75.93333333333334, 75.93333333333334, 75.95, 75.95, 76.43333333333334, 76.43333333333334, 77.4, 77.4, 77.35, 77.35, 77.33333333333333, 77.33333333333333, 77.38333333333334, 77.38333333333334, 77.76666666666667, 77.76666666666667, 77.6, 77.6, 77.88333333333334, 77.88333333333334, 77.21666666666667, 77.21666666666667, 77.35, 77.35, 77.33333333333333, 77.33333333333333, 77.43333333333334, 77.43333333333334, 76.86666666666666, 76.86666666666666, 77.38333333333334, 77.38333333333334, 77.06666666666666, 77.06666666666666, 77.45, 77.45, 77.55, 77.55, 77.93333333333334, 77.93333333333334, 77.26666666666667, 77.26666666666667, 77.7, 77.7, 77.93333333333334, 77.93333333333334, 77.76666666666667, 77.76666666666667, 77.56666666666666, 77.56666666666666, 77.78333333333333, 77.78333333333333, 77.96666666666667, 77.96666666666667, 79.08333333333333, 79.08333333333333, 78.88333333333334, 78.88333333333334, 78.41666666666667, 78.41666666666667, 78.68333333333334, 78.68333333333334, 78.8, 78.8, 78.6, 78.6, 78.2, 78.2, 78.38333333333334, 78.38333333333334, 78.15, 78.15, 78.05, 78.05, 77.63333333333334, 77.63333333333334, 77.66666666666667, 77.66666666666667, 78.45, 78.45, 78.83333333333333, 78.83333333333333, 78.5, 78.5, 78.23333333333333, 78.23333333333333, 79.11666666666666, 79.11666666666666, 79.33333333333333, 79.33333333333333, 78.73333333333333, 78.73333333333333, 78.85, 78.85, 78.96666666666667, 78.96666666666667, 78.8, 78.8, 78.51666666666667, 78.51666666666667, 77.71666666666667, 77.71666666666667, 78.36666666666666, 78.36666666666666, 78.85, 78.85, 78.8, 78.8, 79.23333333333333, 79.23333333333333, 78.4, 78.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.687, Test loss: 2.063, Test accuracy: 26.95
Round   1, Train loss: 1.100, Test loss: 1.777, Test accuracy: 34.62
Round   2, Train loss: 0.958, Test loss: 1.627, Test accuracy: 36.68
Round   3, Train loss: 0.969, Test loss: 1.264, Test accuracy: 47.50
Round   4, Train loss: 0.886, Test loss: 1.120, Test accuracy: 54.15
Round   5, Train loss: 0.827, Test loss: 1.127, Test accuracy: 55.05
Round   6, Train loss: 0.773, Test loss: 0.980, Test accuracy: 58.62
Round   7, Train loss: 0.742, Test loss: 0.933, Test accuracy: 60.58
Round   8, Train loss: 0.780, Test loss: 0.888, Test accuracy: 60.62
Round   9, Train loss: 0.799, Test loss: 0.865, Test accuracy: 61.88
Round  10, Train loss: 0.736, Test loss: 0.767, Test accuracy: 67.42
Round  11, Train loss: 0.702, Test loss: 0.774, Test accuracy: 67.62
Round  12, Train loss: 0.706, Test loss: 0.811, Test accuracy: 66.35
Round  13, Train loss: 0.633, Test loss: 0.821, Test accuracy: 66.52
Round  14, Train loss: 0.624, Test loss: 0.766, Test accuracy: 69.28
Round  15, Train loss: 0.688, Test loss: 0.729, Test accuracy: 69.00
Round  16, Train loss: 0.651, Test loss: 0.717, Test accuracy: 70.87
Round  17, Train loss: 0.589, Test loss: 0.734, Test accuracy: 70.88
Round  18, Train loss: 0.635, Test loss: 0.755, Test accuracy: 71.47
Round  19, Train loss: 0.636, Test loss: 0.605, Test accuracy: 74.32
Round  20, Train loss: 0.570, Test loss: 0.600, Test accuracy: 74.15
Round  21, Train loss: 0.626, Test loss: 0.591, Test accuracy: 74.48
Round  22, Train loss: 0.609, Test loss: 0.593, Test accuracy: 74.78
Round  23, Train loss: 0.657, Test loss: 0.584, Test accuracy: 75.20
Round  24, Train loss: 0.692, Test loss: 0.582, Test accuracy: 75.43
Round  25, Train loss: 0.541, Test loss: 0.577, Test accuracy: 75.37
Round  26, Train loss: 0.555, Test loss: 0.570, Test accuracy: 75.60
Round  27, Train loss: 0.561, Test loss: 0.572, Test accuracy: 75.92
Round  28, Train loss: 0.580, Test loss: 0.568, Test accuracy: 76.75
Round  29, Train loss: 0.578, Test loss: 0.560, Test accuracy: 76.13
Round  30, Train loss: 0.546, Test loss: 0.546, Test accuracy: 76.95
Round  31, Train loss: 0.524, Test loss: 0.543, Test accuracy: 77.17
Round  32, Train loss: 0.488, Test loss: 0.546, Test accuracy: 77.33
Round  33, Train loss: 0.551, Test loss: 0.546, Test accuracy: 76.90
Round  34, Train loss: 0.463, Test loss: 0.543, Test accuracy: 77.28
Round  35, Train loss: 0.500, Test loss: 0.543, Test accuracy: 76.97
Round  36, Train loss: 0.490, Test loss: 0.540, Test accuracy: 77.07
Round  37, Train loss: 0.480, Test loss: 0.532, Test accuracy: 77.65
Round  38, Train loss: 0.515, Test loss: 0.525, Test accuracy: 77.82
Round  39, Train loss: 0.485, Test loss: 0.521, Test accuracy: 77.37
Round  40, Train loss: 0.478, Test loss: 0.522, Test accuracy: 78.40
Round  41, Train loss: 0.449, Test loss: 0.521, Test accuracy: 78.38
Round  42, Train loss: 0.511, Test loss: 0.514, Test accuracy: 78.28
Round  43, Train loss: 0.467, Test loss: 0.510, Test accuracy: 78.85
Round  44, Train loss: 0.434, Test loss: 0.505, Test accuracy: 78.75
Round  45, Train loss: 0.427, Test loss: 0.502, Test accuracy: 78.83
Round  46, Train loss: 0.465, Test loss: 0.506, Test accuracy: 78.65
Round  47, Train loss: 0.443, Test loss: 0.509, Test accuracy: 78.57
Round  48, Train loss: 0.465, Test loss: 0.497, Test accuracy: 78.78
Round  49, Train loss: 0.431, Test loss: 0.493, Test accuracy: 79.37
Round  50, Train loss: 0.405, Test loss: 0.492, Test accuracy: 79.88
Round  51, Train loss: 0.452, Test loss: 0.495, Test accuracy: 79.78
Round  52, Train loss: 0.383, Test loss: 0.503, Test accuracy: 79.38
Round  53, Train loss: 0.433, Test loss: 0.490, Test accuracy: 79.98
Round  54, Train loss: 0.360, Test loss: 0.489, Test accuracy: 79.93
Round  55, Train loss: 0.508, Test loss: 0.482, Test accuracy: 79.97
Round  56, Train loss: 0.487, Test loss: 0.471, Test accuracy: 80.38
Round  57, Train loss: 0.452, Test loss: 0.481, Test accuracy: 80.30
Round  58, Train loss: 0.431, Test loss: 0.487, Test accuracy: 79.75
Round  59, Train loss: 0.355, Test loss: 0.488, Test accuracy: 79.72
Round  60, Train loss: 0.396, Test loss: 0.473, Test accuracy: 80.67
Round  61, Train loss: 0.410, Test loss: 0.470, Test accuracy: 80.63
Round  62, Train loss: 0.405, Test loss: 0.476, Test accuracy: 80.47
Round  63, Train loss: 0.412, Test loss: 0.479, Test accuracy: 80.12
Round  64, Train loss: 0.369, Test loss: 0.467, Test accuracy: 80.72
Round  65, Train loss: 0.369, Test loss: 0.467, Test accuracy: 80.43
Round  66, Train loss: 0.444, Test loss: 0.466, Test accuracy: 80.55
Round  67, Train loss: 0.423, Test loss: 0.465, Test accuracy: 80.82
Round  68, Train loss: 0.320, Test loss: 0.466, Test accuracy: 80.42
Round  69, Train loss: 0.379, Test loss: 0.466, Test accuracy: 81.05
Round  70, Train loss: 0.412, Test loss: 0.461, Test accuracy: 81.03
Round  71, Train loss: 0.361, Test loss: 0.459, Test accuracy: 81.25
Round  72, Train loss: 0.298, Test loss: 0.460, Test accuracy: 81.32
Round  73, Train loss: 0.430, Test loss: 0.467, Test accuracy: 80.97
Round  74, Train loss: 0.338, Test loss: 0.463, Test accuracy: 81.10
Round  75, Train loss: 0.312, Test loss: 0.455, Test accuracy: 81.67
Round  76, Train loss: 0.424, Test loss: 0.457, Test accuracy: 81.42
Round  77, Train loss: 0.367, Test loss: 0.456, Test accuracy: 81.55
Round  78, Train loss: 0.347, Test loss: 0.449, Test accuracy: 81.57
Round  79, Train loss: 0.332, Test loss: 0.448, Test accuracy: 82.02
Round  80, Train loss: 0.344, Test loss: 0.450, Test accuracy: 81.67
Round  81, Train loss: 0.326, Test loss: 0.457, Test accuracy: 81.55
Round  82, Train loss: 0.338, Test loss: 0.445, Test accuracy: 81.95
Round  83, Train loss: 0.308, Test loss: 0.451, Test accuracy: 81.90
Round  84, Train loss: 0.288, Test loss: 0.444, Test accuracy: 81.95
Round  85, Train loss: 0.360, Test loss: 0.442, Test accuracy: 81.83
Round  86, Train loss: 0.304, Test loss: 0.441, Test accuracy: 82.22
Round  87, Train loss: 0.366, Test loss: 0.444, Test accuracy: 82.12
Round  88, Train loss: 0.300, Test loss: 0.456, Test accuracy: 81.97
Round  89, Train loss: 0.326, Test loss: 0.445, Test accuracy: 82.08
Round  90, Train loss: 0.312, Test loss: 0.435, Test accuracy: 82.25
Round  91, Train loss: 0.323, Test loss: 0.441, Test accuracy: 82.07
Round  92, Train loss: 0.258, Test loss: 0.446, Test accuracy: 82.12
Round  93, Train loss: 0.312, Test loss: 0.442, Test accuracy: 82.13
Round  94, Train loss: 0.345, Test loss: 0.446, Test accuracy: 81.95
Round  95, Train loss: 0.376, Test loss: 0.436, Test accuracy: 82.78
Round  96, Train loss: 0.330, Test loss: 0.441, Test accuracy: 82.27
Round  97, Train loss: 0.271, Test loss: 0.449, Test accuracy: 81.80
Round  98, Train loss: 0.291, Test loss: 0.442, Test accuracy: 82.17
Round  99, Train loss: 0.278, Test loss: 0.443, Test accuracy: 82.58
Final Round, Train loss: 0.235, Test loss: 0.443, Test accuracy: 83.12
Average accuracy final 10 rounds: 82.21166666666667
833.1403234004974
[1.3479201793670654, 2.3886783123016357, 3.4741132259368896, 4.503761291503906, 5.5371270179748535, 6.5952465534210205, 7.724300861358643, 8.755130052566528, 9.763277053833008, 10.707279682159424, 11.61963415145874, 12.648141384124756, 13.651080846786499, 14.764507532119751, 15.865726232528687, 16.992203950881958, 18.011507987976074, 18.998082876205444, 19.97192096710205, 20.92624521255493, 21.942317962646484, 22.90559458732605, 23.91055727005005, 24.93858575820923, 25.898855924606323, 26.928877592086792, 27.971903562545776, 28.994236707687378, 30.03175163269043, 31.145819902420044, 32.12045097351074, 33.12617063522339, 34.035505056381226, 34.9869019985199, 35.95809459686279, 36.97088098526001, 38.05336356163025, 39.14806580543518, 40.26618552207947, 41.379173278808594, 42.36855101585388, 43.28155303001404, 44.2578706741333, 45.19672203063965, 46.2516610622406, 47.22783946990967, 48.28326869010925, 49.39678478240967, 50.45538091659546, 51.52557635307312, 52.515880823135376, 53.552197217941284, 54.618523359298706, 55.691900968551636, 56.74048614501953, 57.72033190727234, 58.676793336868286, 59.64829063415527, 60.662883043289185, 61.7828950881958, 62.908069372177124, 63.92258095741272, 65.04355907440186, 66.09271454811096, 66.99576044082642, 67.93229794502258, 68.88018441200256, 69.87778043746948, 70.90852999687195, 71.96297144889832, 73.03478622436523, 74.07621335983276, 75.04873538017273, 76.02782368659973, 76.97774982452393, 77.97211122512817, 79.02962064743042, 80.03890633583069, 80.99862551689148, 81.91947793960571, 82.90349864959717, 83.92426085472107, 84.92097401618958, 85.98282504081726, 87.09606766700745, 88.20792412757874, 89.27698016166687, 90.18720984458923, 91.13738894462585, 92.0699348449707, 93.02869009971619, 94.0539813041687, 95.08279824256897, 96.20484447479248, 97.35157442092896, 98.34646940231323, 99.31939435005188, 100.29324150085449, 101.21562314033508, 102.24212312698364, 103.77620458602905]
[26.95, 34.61666666666667, 36.68333333333333, 47.5, 54.15, 55.05, 58.61666666666667, 60.583333333333336, 60.61666666666667, 61.88333333333333, 67.41666666666667, 67.61666666666666, 66.35, 66.51666666666667, 69.28333333333333, 69.0, 70.86666666666666, 70.88333333333334, 71.46666666666667, 74.31666666666666, 74.15, 74.48333333333333, 74.78333333333333, 75.2, 75.43333333333334, 75.36666666666666, 75.6, 75.91666666666667, 76.75, 76.13333333333334, 76.95, 77.16666666666667, 77.33333333333333, 76.9, 77.28333333333333, 76.96666666666667, 77.06666666666666, 77.65, 77.81666666666666, 77.36666666666666, 78.4, 78.38333333333334, 78.28333333333333, 78.85, 78.75, 78.83333333333333, 78.65, 78.56666666666666, 78.78333333333333, 79.36666666666666, 79.88333333333334, 79.78333333333333, 79.38333333333334, 79.98333333333333, 79.93333333333334, 79.96666666666667, 80.38333333333334, 80.3, 79.75, 79.71666666666667, 80.66666666666667, 80.63333333333334, 80.46666666666667, 80.11666666666666, 80.71666666666667, 80.43333333333334, 80.55, 80.81666666666666, 80.41666666666667, 81.05, 81.03333333333333, 81.25, 81.31666666666666, 80.96666666666667, 81.1, 81.66666666666667, 81.41666666666667, 81.55, 81.56666666666666, 82.01666666666667, 81.66666666666667, 81.55, 81.95, 81.9, 81.95, 81.83333333333333, 82.21666666666667, 82.11666666666666, 81.96666666666667, 82.08333333333333, 82.25, 82.06666666666666, 82.11666666666666, 82.13333333333334, 81.95, 82.78333333333333, 82.26666666666667, 81.8, 82.16666666666667, 82.58333333333333, 83.11666666666666]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  12.9200
Round 1 global test acc  18.7500
Round 2 global test acc  21.6600
Round 3 global test acc  18.2600
Round 4 global test acc  19.6500
Round 5 global test acc  22.0700
Round 6 global test acc  23.0000
Round 7 global test acc  24.7700
Round 8 global test acc  25.6800
Round 9 global test acc  24.6200
Round 10 global test acc  19.3600
Round 11 global test acc  22.8900
Round 12 global test acc  24.3600
Round 13 global test acc  26.4100
Round 14 global test acc  15.2600
Round 15 global test acc  26.2800
Round 16 global test acc  21.3900
Round 17 global test acc  20.4800
Round 18 global test acc  20.8900
Round 19 global test acc  23.8500
Round 20 global test acc  23.3700
Round 21 global test acc  33.0200
Round 22 global test acc  26.9600
Round 23 global test acc  30.3700
Round 24 global test acc  30.7900
Round 25 global test acc  25.1200
Round 26 global test acc  27.8700
Round 27 global test acc  22.3100
Round 28 global test acc  25.8000
Round 29 global test acc  23.9700
Round 30 global test acc  32.1800
Round 31 global test acc  31.4100
Round 32 global test acc  31.9400
Round 33 global test acc  28.8200
Round 34 global test acc  26.0400
Round 35 global test acc  33.0100
Round 36 global test acc  25.6100
Round 37 global test acc  27.1400
Round 38 global test acc  33.4900
Round 39 global test acc  25.8800
Round 40 global test acc  31.1700
Round 41 global test acc  27.5200
Round 42 global test acc  23.4900
Round 43 global test acc  35.7000
Round 44 global test acc  26.6000
Round 45 global test acc  28.6500
Round 46 global test acc  29.7400
Round 47 global test acc  27.8800
Round 48 global test acc  30.6900
Round 49 global test acc  26.7900
Round 50 global test acc  29.5700
Round 51 global test acc  29.8800
Round 52 global test acc  25.5900
Round 53 global test acc  27.8400
Round 54 global test acc  35.4100
Round 55 global test acc  27.8700
Round 56 global test acc  33.9200
Round 57 global test acc  37.2900
Round 58 global test acc  29.6200
Round 59 global test acc  29.9700
Round 60 global test acc  25.7400
Round 61 global test acc  31.9500
Round 62 global test acc  28.6000
Round 63 global test acc  32.5600
Round 64 global test acc  35.7000
Round 65 global test acc  27.5400
Round 66 global test acc  25.7900
Round 67 global test acc  32.5200
Round 68 global test acc  28.4400
Round 69 global test acc  31.5900
Round 70 global test acc  30.0100
Round 71 global test acc  36.1100
Round 72 global test acc  30.0200
Round 73 global test acc  33.2000
Round 74 global test acc  28.9800
Round 75 global test acc  36.3000
Round 76 global test acc  23.2600
Round 77 global test acc  29.9700
Round 78 global test acc  30.1400
Round 79 global test acc  38.6500
Round 80 global test acc  36.3600
Round 81 global test acc  32.0900
Round 82 global test acc  30.1000
Round 83 global test acc  28.8300
Round 84 global test acc  26.3300
Round 85 global test acc  25.7600
Round 86 global test acc  24.5200
Round 87 global test acc  23.3000
Round 88 global test acc  22.2400
Round 89 global test acc  21.9400
Round 90 global test acc  20.8000
Round 91 global test acc  20.6200
Round 92 global test acc  20.3200
Round 93 global test acc  19.7800
Round 94 global test acc  18.8000
Round 95 global test acc  18.6000
Round 96 global test acc  17.9800
Round 97 global test acc  17.3800
Round 98 global test acc  17.1400
Round 99 global test acc  16.8600
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.701, Test loss: 2.191, Test accuracy: 22.52
Round   1, Train loss: 1.112, Test loss: 1.770, Test accuracy: 33.43
Round   2, Train loss: 1.021, Test loss: 1.571, Test accuracy: 37.77
Round   3, Train loss: 0.973, Test loss: 1.299, Test accuracy: 45.12
Round   4, Train loss: 0.889, Test loss: 1.137, Test accuracy: 53.72
Round   5, Train loss: 0.883, Test loss: 1.165, Test accuracy: 53.82
Round   6, Train loss: 0.833, Test loss: 1.007, Test accuracy: 58.12
Round   7, Train loss: 0.793, Test loss: 0.913, Test accuracy: 62.25
Round   8, Train loss: 0.783, Test loss: 0.843, Test accuracy: 63.07
Round   9, Train loss: 0.898, Test loss: 0.830, Test accuracy: 65.07
Round  10, Train loss: 0.723, Test loss: 0.776, Test accuracy: 67.92
Round  11, Train loss: 0.697, Test loss: 0.761, Test accuracy: 69.53
Round  12, Train loss: 0.743, Test loss: 0.816, Test accuracy: 67.38
Round  13, Train loss: 0.623, Test loss: 0.823, Test accuracy: 67.43
Round  14, Train loss: 0.619, Test loss: 0.779, Test accuracy: 69.97
Round  15, Train loss: 0.727, Test loss: 0.770, Test accuracy: 67.92
Round  16, Train loss: 0.687, Test loss: 0.766, Test accuracy: 68.72
Round  17, Train loss: 0.622, Test loss: 0.766, Test accuracy: 69.55
Round  18, Train loss: 0.671, Test loss: 0.771, Test accuracy: 70.00
Round  19, Train loss: 0.671, Test loss: 0.655, Test accuracy: 71.77
Round  20, Train loss: 0.568, Test loss: 0.618, Test accuracy: 73.43
Round  21, Train loss: 0.619, Test loss: 0.601, Test accuracy: 74.27
Round  22, Train loss: 0.640, Test loss: 0.594, Test accuracy: 74.82
Round  23, Train loss: 0.639, Test loss: 0.593, Test accuracy: 74.77
Round  24, Train loss: 0.681, Test loss: 0.591, Test accuracy: 74.85
Round  25, Train loss: 0.597, Test loss: 0.590, Test accuracy: 75.17
Round  26, Train loss: 0.599, Test loss: 0.574, Test accuracy: 75.37
Round  27, Train loss: 0.605, Test loss: 0.580, Test accuracy: 75.25
Round  28, Train loss: 0.665, Test loss: 0.588, Test accuracy: 75.45
Round  29, Train loss: 0.570, Test loss: 0.572, Test accuracy: 75.95
Round  30, Train loss: 0.592, Test loss: 0.565, Test accuracy: 76.45
Round  31, Train loss: 0.558, Test loss: 0.566, Test accuracy: 76.43
Round  32, Train loss: 0.486, Test loss: 0.558, Test accuracy: 76.93
Round  33, Train loss: 0.592, Test loss: 0.557, Test accuracy: 77.17
Round  34, Train loss: 0.508, Test loss: 0.552, Test accuracy: 77.15
Round  35, Train loss: 0.584, Test loss: 0.553, Test accuracy: 77.35
Round  36, Train loss: 0.533, Test loss: 0.541, Test accuracy: 77.47
Round  37, Train loss: 0.476, Test loss: 0.535, Test accuracy: 77.62
Round  38, Train loss: 0.514, Test loss: 0.533, Test accuracy: 77.67
Round  39, Train loss: 0.475, Test loss: 0.540, Test accuracy: 77.73
Round  40, Train loss: 0.539, Test loss: 0.538, Test accuracy: 77.52
Round  41, Train loss: 0.458, Test loss: 0.544, Test accuracy: 77.60
Round  42, Train loss: 0.507, Test loss: 0.535, Test accuracy: 78.05
Round  43, Train loss: 0.514, Test loss: 0.531, Test accuracy: 77.78
Round  44, Train loss: 0.522, Test loss: 0.521, Test accuracy: 78.33
Round  45, Train loss: 0.517, Test loss: 0.519, Test accuracy: 78.48
Round  46, Train loss: 0.520, Test loss: 0.515, Test accuracy: 78.92
Round  47, Train loss: 0.449, Test loss: 0.515, Test accuracy: 78.50
Round  48, Train loss: 0.550, Test loss: 0.511, Test accuracy: 78.70
Round  49, Train loss: 0.474, Test loss: 0.513, Test accuracy: 78.37
Round  50, Train loss: 0.461, Test loss: 0.510, Test accuracy: 78.95
Round  51, Train loss: 0.459, Test loss: 0.506, Test accuracy: 78.98
Round  52, Train loss: 0.433, Test loss: 0.504, Test accuracy: 78.75
Round  53, Train loss: 0.439, Test loss: 0.497, Test accuracy: 79.38
Round  54, Train loss: 0.406, Test loss: 0.507, Test accuracy: 79.18
Round  55, Train loss: 0.542, Test loss: 0.500, Test accuracy: 79.30
Round  56, Train loss: 0.495, Test loss: 0.493, Test accuracy: 79.23
Round  57, Train loss: 0.501, Test loss: 0.511, Test accuracy: 78.88
Round  58, Train loss: 0.472, Test loss: 0.495, Test accuracy: 79.85
Round  59, Train loss: 0.396, Test loss: 0.506, Test accuracy: 79.35
Round  60, Train loss: 0.434, Test loss: 0.504, Test accuracy: 79.43
Round  61, Train loss: 0.415, Test loss: 0.500, Test accuracy: 79.38
Round  62, Train loss: 0.500, Test loss: 0.494, Test accuracy: 79.92
Round  63, Train loss: 0.431, Test loss: 0.495, Test accuracy: 79.73
Round  64, Train loss: 0.408, Test loss: 0.490, Test accuracy: 79.93
Round  65, Train loss: 0.424, Test loss: 0.484, Test accuracy: 80.05
Round  66, Train loss: 0.455, Test loss: 0.484, Test accuracy: 79.97
Round  67, Train loss: 0.418, Test loss: 0.485, Test accuracy: 79.97
Round  68, Train loss: 0.327, Test loss: 0.499, Test accuracy: 79.77
Round  69, Train loss: 0.378, Test loss: 0.493, Test accuracy: 79.77
Round  70, Train loss: 0.438, Test loss: 0.473, Test accuracy: 80.65
Round  71, Train loss: 0.361, Test loss: 0.488, Test accuracy: 80.30
Round  72, Train loss: 0.367, Test loss: 0.474, Test accuracy: 80.60
Round  73, Train loss: 0.481, Test loss: 0.488, Test accuracy: 80.38
Round  74, Train loss: 0.348, Test loss: 0.484, Test accuracy: 80.23
Round  75, Train loss: 0.304, Test loss: 0.490, Test accuracy: 80.95
Round  76, Train loss: 0.425, Test loss: 0.482, Test accuracy: 80.72
Round  77, Train loss: 0.415, Test loss: 0.485, Test accuracy: 80.75
Round  78, Train loss: 0.353, Test loss: 0.488, Test accuracy: 81.15
Round  79, Train loss: 0.346, Test loss: 0.483, Test accuracy: 80.78
Round  80, Train loss: 0.339, Test loss: 0.491, Test accuracy: 80.62
Round  81, Train loss: 0.374, Test loss: 0.486, Test accuracy: 80.68
Round  82, Train loss: 0.379, Test loss: 0.481, Test accuracy: 81.25
Round  83, Train loss: 0.405, Test loss: 0.473, Test accuracy: 81.27
Round  84, Train loss: 0.285, Test loss: 0.480, Test accuracy: 81.10
Round  85, Train loss: 0.409, Test loss: 0.471, Test accuracy: 81.75
Round  86, Train loss: 0.366, Test loss: 0.470, Test accuracy: 81.35
Round  87, Train loss: 0.415, Test loss: 0.482, Test accuracy: 80.78
Round  88, Train loss: 0.345, Test loss: 0.480, Test accuracy: 81.03
Round  89, Train loss: 0.368, Test loss: 0.484, Test accuracy: 80.82
Round  90, Train loss: 0.348, Test loss: 0.471, Test accuracy: 81.78
Round  91, Train loss: 0.323, Test loss: 0.471, Test accuracy: 81.65
Round  92, Train loss: 0.315, Test loss: 0.469, Test accuracy: 81.83
Round  93, Train loss: 0.363, Test loss: 0.470, Test accuracy: 82.08
Round  94, Train loss: 0.349, Test loss: 0.479, Test accuracy: 81.28
Round  95, Train loss: 0.372, Test loss: 0.483, Test accuracy: 81.20
Round  96, Train loss: 0.336, Test loss: 0.477, Test accuracy: 81.38
Round  97, Train loss: 0.277, Test loss: 0.477, Test accuracy: 81.45
Round  98, Train loss: 0.297, Test loss: 0.468, Test accuracy: 81.90
Round  99, Train loss: 0.283, Test loss: 0.477, Test accuracy: 81.90
Final Round, Train loss: 0.269, Test loss: 0.484, Test accuracy: 81.68
Average accuracy final 10 rounds: 81.64666666666666
811.9043152332306
[1.5131301879882812, 2.610086679458618, 3.5534980297088623, 4.529866456985474, 5.486874103546143, 6.440170049667358, 7.436802387237549, 8.570022821426392, 9.6841299533844, 10.770245790481567, 11.786590337753296, 12.781250476837158, 13.816014766693115, 14.769651889801025, 15.73884654045105, 16.701116800308228, 17.62324094772339, 18.56874442100525, 19.55867886543274, 20.479004383087158, 21.521376848220825, 22.51885175704956, 23.52669048309326, 24.548553705215454, 25.567219018936157, 26.461049556732178, 27.352266788482666, 28.263622045516968, 29.17542004585266, 30.19342279434204, 31.22913694381714, 32.24422264099121, 33.255571603775024, 34.28726577758789, 35.28309893608093, 36.21176862716675, 37.106234312057495, 38.1289119720459, 39.09551191329956, 40.05322289466858, 41.02987217903137, 41.947919607162476, 42.96430540084839, 43.98377990722656, 44.97991156578064, 46.04842686653137, 47.10973262786865, 48.12489652633667, 49.08934307098389, 49.97077035903931, 50.87301683425903, 51.81675982475281, 52.71180200576782, 53.72093391418457, 54.77434730529785, 55.78177356719971, 56.91952133178711, 57.866050004959106, 58.798996925354004, 59.70127773284912, 60.619953870773315, 61.602644205093384, 62.60305428504944, 63.588634967803955, 64.56755328178406, 65.52656078338623, 66.50567865371704, 67.4921464920044, 68.43959617614746, 69.5000216960907, 70.48632287979126, 71.4763777256012, 72.4281485080719, 73.3452296257019, 74.27259302139282, 75.1706645488739, 76.13919067382812, 77.16387820243835, 78.25558376312256, 79.33985328674316, 80.39625096321106, 81.29888439178467, 82.20905208587646, 83.1106584072113, 84.0043318271637, 84.9622654914856, 85.9631736278534, 86.95297122001648, 87.89944887161255, 88.84565162658691, 89.87493300437927, 90.90666937828064, 91.96317410469055, 93.03438448905945, 94.03036952018738, 95.09896349906921, 96.16483402252197, 97.13863444328308, 98.13962173461914, 99.19087243080139, 100.82940411567688]
[22.516666666666666, 33.43333333333333, 37.766666666666666, 45.11666666666667, 53.71666666666667, 53.81666666666667, 58.11666666666667, 62.25, 63.06666666666667, 65.06666666666666, 67.91666666666667, 69.53333333333333, 67.38333333333334, 67.43333333333334, 69.96666666666667, 67.91666666666667, 68.71666666666667, 69.55, 70.0, 71.76666666666667, 73.43333333333334, 74.26666666666667, 74.81666666666666, 74.76666666666667, 74.85, 75.16666666666667, 75.36666666666666, 75.25, 75.45, 75.95, 76.45, 76.43333333333334, 76.93333333333334, 77.16666666666667, 77.15, 77.35, 77.46666666666667, 77.61666666666666, 77.66666666666667, 77.73333333333333, 77.51666666666667, 77.6, 78.05, 77.78333333333333, 78.33333333333333, 78.48333333333333, 78.91666666666667, 78.5, 78.7, 78.36666666666666, 78.95, 78.98333333333333, 78.75, 79.38333333333334, 79.18333333333334, 79.3, 79.23333333333333, 78.88333333333334, 79.85, 79.35, 79.43333333333334, 79.38333333333334, 79.91666666666667, 79.73333333333333, 79.93333333333334, 80.05, 79.96666666666667, 79.96666666666667, 79.76666666666667, 79.76666666666667, 80.65, 80.3, 80.6, 80.38333333333334, 80.23333333333333, 80.95, 80.71666666666667, 80.75, 81.15, 80.78333333333333, 80.61666666666666, 80.68333333333334, 81.25, 81.26666666666667, 81.1, 81.75, 81.35, 80.78333333333333, 81.03333333333333, 80.81666666666666, 81.78333333333333, 81.65, 81.83333333333333, 82.08333333333333, 81.28333333333333, 81.2, 81.38333333333334, 81.45, 81.9, 81.9, 81.68333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.667, Test loss: 2.072, Test accuracy: 21.95
Round   1, Train loss: 1.102, Test loss: 1.830, Test accuracy: 33.92
Round   2, Train loss: 0.965, Test loss: 1.643, Test accuracy: 36.37
Round   3, Train loss: 0.968, Test loss: 1.278, Test accuracy: 46.43
Round   4, Train loss: 0.941, Test loss: 1.125, Test accuracy: 53.53
Round   5, Train loss: 0.867, Test loss: 1.115, Test accuracy: 55.02
Round   6, Train loss: 0.825, Test loss: 0.964, Test accuracy: 59.45
Round   7, Train loss: 0.739, Test loss: 0.894, Test accuracy: 62.23
Round   8, Train loss: 0.777, Test loss: 0.839, Test accuracy: 63.32
Round   9, Train loss: 0.793, Test loss: 0.834, Test accuracy: 64.30
Round  10, Train loss: 0.725, Test loss: 0.779, Test accuracy: 67.60
Round  11, Train loss: 0.682, Test loss: 0.759, Test accuracy: 68.45
Round  12, Train loss: 0.744, Test loss: 0.818, Test accuracy: 66.55
Round  13, Train loss: 0.620, Test loss: 0.806, Test accuracy: 67.15
Round  14, Train loss: 0.664, Test loss: 0.758, Test accuracy: 69.52
Round  15, Train loss: 0.675, Test loss: 0.738, Test accuracy: 68.68
Round  16, Train loss: 0.648, Test loss: 0.716, Test accuracy: 71.18
Round  17, Train loss: 0.579, Test loss: 0.736, Test accuracy: 71.07
Round  18, Train loss: 0.677, Test loss: 0.741, Test accuracy: 71.22
Round  19, Train loss: 0.623, Test loss: 0.635, Test accuracy: 72.52
Round  20, Train loss: 0.614, Test loss: 0.629, Test accuracy: 73.32
Round  21, Train loss: 0.613, Test loss: 0.608, Test accuracy: 74.23
Round  22, Train loss: 0.593, Test loss: 0.593, Test accuracy: 75.03
Round  23, Train loss: 0.695, Test loss: 0.589, Test accuracy: 75.22
Round  24, Train loss: 0.673, Test loss: 0.589, Test accuracy: 75.80
Round  25, Train loss: 0.535, Test loss: 0.585, Test accuracy: 76.22
Round  26, Train loss: 0.547, Test loss: 0.578, Test accuracy: 76.00
Round  27, Train loss: 0.550, Test loss: 0.584, Test accuracy: 75.33
Round  28, Train loss: 0.569, Test loss: 0.572, Test accuracy: 75.97
Round  29, Train loss: 0.568, Test loss: 0.560, Test accuracy: 76.70
Round  30, Train loss: 0.534, Test loss: 0.568, Test accuracy: 76.40
Round  31, Train loss: 0.520, Test loss: 0.564, Test accuracy: 77.03
Round  32, Train loss: 0.489, Test loss: 0.563, Test accuracy: 76.58
Round  33, Train loss: 0.547, Test loss: 0.549, Test accuracy: 77.60
Round  34, Train loss: 0.505, Test loss: 0.549, Test accuracy: 76.98
Round  35, Train loss: 0.549, Test loss: 0.553, Test accuracy: 76.92
Round  36, Train loss: 0.531, Test loss: 0.553, Test accuracy: 76.87
Round  37, Train loss: 0.466, Test loss: 0.555, Test accuracy: 76.87
Round  38, Train loss: 0.555, Test loss: 0.539, Test accuracy: 77.37
Round  39, Train loss: 0.517, Test loss: 0.529, Test accuracy: 77.85
Round  40, Train loss: 0.530, Test loss: 0.535, Test accuracy: 78.03
Round  41, Train loss: 0.452, Test loss: 0.525, Test accuracy: 78.35
Round  42, Train loss: 0.495, Test loss: 0.525, Test accuracy: 78.03
Round  43, Train loss: 0.509, Test loss: 0.523, Test accuracy: 78.40
Round  44, Train loss: 0.422, Test loss: 0.513, Test accuracy: 79.23
Round  45, Train loss: 0.421, Test loss: 0.506, Test accuracy: 79.10
Round  46, Train loss: 0.473, Test loss: 0.505, Test accuracy: 78.87
Round  47, Train loss: 0.442, Test loss: 0.501, Test accuracy: 79.48
Round  48, Train loss: 0.449, Test loss: 0.501, Test accuracy: 79.35
Round  49, Train loss: 0.485, Test loss: 0.503, Test accuracy: 79.05
Round  50, Train loss: 0.402, Test loss: 0.492, Test accuracy: 79.88
Round  51, Train loss: 0.449, Test loss: 0.491, Test accuracy: 79.68
Round  52, Train loss: 0.422, Test loss: 0.498, Test accuracy: 79.42
Round  53, Train loss: 0.423, Test loss: 0.492, Test accuracy: 79.87
Round  54, Train loss: 0.404, Test loss: 0.498, Test accuracy: 79.40
Round  55, Train loss: 0.503, Test loss: 0.489, Test accuracy: 79.97
Round  56, Train loss: 0.485, Test loss: 0.487, Test accuracy: 79.85
Round  57, Train loss: 0.446, Test loss: 0.491, Test accuracy: 79.48
Round  58, Train loss: 0.427, Test loss: 0.493, Test accuracy: 79.55
Round  59, Train loss: 0.407, Test loss: 0.486, Test accuracy: 80.02
Round  60, Train loss: 0.389, Test loss: 0.485, Test accuracy: 79.93
Round  61, Train loss: 0.447, Test loss: 0.501, Test accuracy: 79.85
Round  62, Train loss: 0.458, Test loss: 0.493, Test accuracy: 79.62
Round  63, Train loss: 0.467, Test loss: 0.492, Test accuracy: 79.73
Round  64, Train loss: 0.366, Test loss: 0.488, Test accuracy: 79.92
Round  65, Train loss: 0.359, Test loss: 0.480, Test accuracy: 80.03
Round  66, Train loss: 0.449, Test loss: 0.486, Test accuracy: 80.15
Round  67, Train loss: 0.407, Test loss: 0.473, Test accuracy: 80.75
Round  68, Train loss: 0.311, Test loss: 0.477, Test accuracy: 80.52
Round  69, Train loss: 0.422, Test loss: 0.475, Test accuracy: 80.40
Round  70, Train loss: 0.415, Test loss: 0.470, Test accuracy: 80.82
Round  71, Train loss: 0.413, Test loss: 0.479, Test accuracy: 80.38
Round  72, Train loss: 0.306, Test loss: 0.475, Test accuracy: 80.70
Round  73, Train loss: 0.471, Test loss: 0.473, Test accuracy: 81.05
Round  74, Train loss: 0.343, Test loss: 0.465, Test accuracy: 81.17
Round  75, Train loss: 0.299, Test loss: 0.459, Test accuracy: 81.43
Round  76, Train loss: 0.420, Test loss: 0.461, Test accuracy: 81.10
Round  77, Train loss: 0.412, Test loss: 0.469, Test accuracy: 81.07
Round  78, Train loss: 0.342, Test loss: 0.467, Test accuracy: 81.38
Round  79, Train loss: 0.322, Test loss: 0.468, Test accuracy: 80.93
Round  80, Train loss: 0.336, Test loss: 0.470, Test accuracy: 80.97
Round  81, Train loss: 0.334, Test loss: 0.469, Test accuracy: 81.18
Round  82, Train loss: 0.350, Test loss: 0.475, Test accuracy: 80.90
Round  83, Train loss: 0.359, Test loss: 0.473, Test accuracy: 81.42
Round  84, Train loss: 0.331, Test loss: 0.467, Test accuracy: 81.57
Round  85, Train loss: 0.359, Test loss: 0.474, Test accuracy: 81.40
Round  86, Train loss: 0.362, Test loss: 0.469, Test accuracy: 81.45
Round  87, Train loss: 0.374, Test loss: 0.470, Test accuracy: 81.13
Round  88, Train loss: 0.305, Test loss: 0.457, Test accuracy: 81.65
Round  89, Train loss: 0.327, Test loss: 0.468, Test accuracy: 81.28
Round  90, Train loss: 0.315, Test loss: 0.460, Test accuracy: 81.75
Round  91, Train loss: 0.317, Test loss: 0.460, Test accuracy: 81.77
Round  92, Train loss: 0.269, Test loss: 0.467, Test accuracy: 81.43
Round  93, Train loss: 0.363, Test loss: 0.468, Test accuracy: 81.43
Round  94, Train loss: 0.337, Test loss: 0.470, Test accuracy: 81.17
Round  95, Train loss: 0.365, Test loss: 0.462, Test accuracy: 81.75
Round  96, Train loss: 0.377, Test loss: 0.465, Test accuracy: 81.60
Round  97, Train loss: 0.322, Test loss: 0.464, Test accuracy: 81.62
Round  98, Train loss: 0.301, Test loss: 0.460, Test accuracy: 81.65
Round  99, Train loss: 0.319, Test loss: 0.460, Test accuracy: 81.93
Final Round, Train loss: 0.251, Test loss: 0.465, Test accuracy: 81.88
Average accuracy final 10 rounds: 81.61
1563.1032116413116
[1.4081220626831055, 2.3710544109344482, 3.3730549812316895, 4.403723478317261, 5.4597859382629395, 6.553530931472778, 7.6537556648254395, 8.746283054351807, 9.777626514434814, 10.762778997421265, 11.743834972381592, 12.732284545898438, 13.742188453674316, 14.734425783157349, 15.70874285697937, 16.612303495407104, 17.661160469055176, 18.656681537628174, 19.635100603103638, 20.75973606109619, 21.808029174804688, 24.82039451599121, 27.29121470451355, 30.319272756576538, 33.637927293777466, 36.484018087387085, 39.27718639373779, 42.20169997215271, 44.896528482437134, 47.76684832572937, 50.93490791320801, 54.06295108795166, 56.43283462524414, 58.87652277946472, 62.06962490081787, 64.8724274635315, 67.68747019767761, 70.44325923919678, 73.28383445739746, 76.03868865966797, 78.97986388206482, 82.07515001296997, 85.01014041900635, 87.53397250175476, 90.6999409198761, 93.75155854225159, 96.59062361717224, 99.4084038734436, 102.21990060806274, 105.06176662445068, 107.7713840007782, 110.89671540260315, 113.7522246837616, 116.13862156867981, 118.96715307235718, 122.11569619178772, 125.18146681785583, 127.71413731575012, 130.5756208896637, 133.5847306251526, 136.30828952789307, 139.24087691307068, 142.02979731559753, 144.52754092216492, 146.90746402740479, 149.84633207321167, 153.0249752998352, 155.5671045780182, 157.98971700668335, 160.71240901947021, 163.76976704597473, 166.34131860733032, 169.0549886226654, 171.75772738456726, 174.2643632888794, 176.68543481826782, 179.76150226593018, 182.5963010787964, 184.95756196975708, 187.4709770679474, 190.1642324924469, 192.81432962417603, 195.43618440628052, 198.09090065956116, 200.87793684005737, 203.25025391578674, 205.82743501663208, 208.7697238922119, 211.93963193893433, 214.17794108390808, 216.6246428489685, 219.59109926223755, 222.35089993476868, 224.9301896095276, 227.65815925598145, 230.17954778671265, 232.7814507484436, 235.21127033233643, 238.3717634677887, 240.9620542526245, 242.44201493263245]
[21.95, 33.916666666666664, 36.36666666666667, 46.43333333333333, 53.53333333333333, 55.016666666666666, 59.45, 62.233333333333334, 63.31666666666667, 64.3, 67.6, 68.45, 66.55, 67.15, 69.51666666666667, 68.68333333333334, 71.18333333333334, 71.06666666666666, 71.21666666666667, 72.51666666666667, 73.31666666666666, 74.23333333333333, 75.03333333333333, 75.21666666666667, 75.8, 76.21666666666667, 76.0, 75.33333333333333, 75.96666666666667, 76.7, 76.4, 77.03333333333333, 76.58333333333333, 77.6, 76.98333333333333, 76.91666666666667, 76.86666666666666, 76.86666666666666, 77.36666666666666, 77.85, 78.03333333333333, 78.35, 78.03333333333333, 78.4, 79.23333333333333, 79.1, 78.86666666666666, 79.48333333333333, 79.35, 79.05, 79.88333333333334, 79.68333333333334, 79.41666666666667, 79.86666666666666, 79.4, 79.96666666666667, 79.85, 79.48333333333333, 79.55, 80.01666666666667, 79.93333333333334, 79.85, 79.61666666666666, 79.73333333333333, 79.91666666666667, 80.03333333333333, 80.15, 80.75, 80.51666666666667, 80.4, 80.81666666666666, 80.38333333333334, 80.7, 81.05, 81.16666666666667, 81.43333333333334, 81.1, 81.06666666666666, 81.38333333333334, 80.93333333333334, 80.96666666666667, 81.18333333333334, 80.9, 81.41666666666667, 81.56666666666666, 81.4, 81.45, 81.13333333333334, 81.65, 81.28333333333333, 81.75, 81.76666666666667, 81.43333333333334, 81.43333333333334, 81.16666666666667, 81.75, 81.6, 81.61666666666666, 81.65, 81.93333333333334, 81.88333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.239, Test loss: 1.909, Test accuracy: 26.70
Round   0, Global train loss: 1.239, Global test loss: 2.266, Global test accuracy: 16.70
Round   1, Train loss: 1.040, Test loss: 1.575, Test accuracy: 39.30
Round   1, Global train loss: 1.040, Global test loss: 2.213, Global test accuracy: 25.55
Round   2, Train loss: 0.958, Test loss: 1.464, Test accuracy: 45.45
Round   2, Global train loss: 0.958, Global test loss: 2.390, Global test accuracy: 25.52
Round   3, Train loss: 0.938, Test loss: 1.130, Test accuracy: 53.47
Round   3, Global train loss: 0.938, Global test loss: 2.205, Global test accuracy: 26.68
Round   4, Train loss: 0.928, Test loss: 1.122, Test accuracy: 51.78
Round   4, Global train loss: 0.928, Global test loss: 2.178, Global test accuracy: 14.80
Round   5, Train loss: 0.770, Test loss: 1.024, Test accuracy: 58.77
Round   5, Global train loss: 0.770, Global test loss: 2.542, Global test accuracy: 22.80
Round   6, Train loss: 0.872, Test loss: 0.900, Test accuracy: 60.93
Round   6, Global train loss: 0.872, Global test loss: 2.196, Global test accuracy: 24.72
Round   7, Train loss: 0.884, Test loss: 0.859, Test accuracy: 62.57
Round   7, Global train loss: 0.884, Global test loss: 2.161, Global test accuracy: 28.65
Round   8, Train loss: 0.811, Test loss: 0.781, Test accuracy: 65.57
Round   8, Global train loss: 0.811, Global test loss: 2.277, Global test accuracy: 13.33
Round   9, Train loss: 0.913, Test loss: 0.769, Test accuracy: 66.62
Round   9, Global train loss: 0.913, Global test loss: 2.214, Global test accuracy: 20.57
Round  10, Train loss: 0.699, Test loss: 0.747, Test accuracy: 67.55
Round  10, Global train loss: 0.699, Global test loss: 2.257, Global test accuracy: 26.30
Round  11, Train loss: 0.733, Test loss: 0.764, Test accuracy: 66.93
Round  11, Global train loss: 0.733, Global test loss: 2.224, Global test accuracy: 22.50
Round  12, Train loss: 0.671, Test loss: 0.766, Test accuracy: 67.73
Round  12, Global train loss: 0.671, Global test loss: 2.032, Global test accuracy: 28.55
Round  13, Train loss: 0.685, Test loss: 0.765, Test accuracy: 68.17
Round  13, Global train loss: 0.685, Global test loss: 2.198, Global test accuracy: 20.15
Round  14, Train loss: 0.742, Test loss: 0.761, Test accuracy: 68.68
Round  14, Global train loss: 0.742, Global test loss: 2.125, Global test accuracy: 27.27
Round  15, Train loss: 0.754, Test loss: 0.759, Test accuracy: 68.35
Round  15, Global train loss: 0.754, Global test loss: 2.137, Global test accuracy: 27.92
Round  16, Train loss: 0.656, Test loss: 0.731, Test accuracy: 69.32
Round  16, Global train loss: 0.656, Global test loss: 2.207, Global test accuracy: 23.52
Round  17, Train loss: 0.689, Test loss: 0.745, Test accuracy: 68.75
Round  17, Global train loss: 0.689, Global test loss: 2.090, Global test accuracy: 25.77
Round  18, Train loss: 0.531, Test loss: 0.723, Test accuracy: 69.37
Round  18, Global train loss: 0.531, Global test loss: 2.108, Global test accuracy: 24.62
Round  19, Train loss: 0.663, Test loss: 0.727, Test accuracy: 69.58
Round  19, Global train loss: 0.663, Global test loss: 2.109, Global test accuracy: 25.00
Round  20, Train loss: 0.582, Test loss: 0.721, Test accuracy: 69.93
Round  20, Global train loss: 0.582, Global test loss: 2.383, Global test accuracy: 25.23
Round  21, Train loss: 0.617, Test loss: 0.712, Test accuracy: 69.97
Round  21, Global train loss: 0.617, Global test loss: 2.237, Global test accuracy: 26.07
Round  22, Train loss: 0.632, Test loss: 0.713, Test accuracy: 70.38
Round  22, Global train loss: 0.632, Global test loss: 2.344, Global test accuracy: 28.42
Round  23, Train loss: 0.711, Test loss: 0.713, Test accuracy: 70.52
Round  23, Global train loss: 0.711, Global test loss: 2.110, Global test accuracy: 29.00
Round  24, Train loss: 0.595, Test loss: 0.712, Test accuracy: 71.07
Round  24, Global train loss: 0.595, Global test loss: 2.463, Global test accuracy: 24.20
Round  25, Train loss: 0.568, Test loss: 0.709, Test accuracy: 71.05
Round  25, Global train loss: 0.568, Global test loss: 2.207, Global test accuracy: 27.57
Round  26, Train loss: 0.484, Test loss: 0.729, Test accuracy: 70.75
Round  26, Global train loss: 0.484, Global test loss: 2.196, Global test accuracy: 29.88
Round  27, Train loss: 0.542, Test loss: 0.746, Test accuracy: 70.07
Round  27, Global train loss: 0.542, Global test loss: 2.144, Global test accuracy: 27.07
Round  28, Train loss: 0.503, Test loss: 0.722, Test accuracy: 71.28
Round  28, Global train loss: 0.503, Global test loss: 2.364, Global test accuracy: 27.15
Round  29, Train loss: 0.491, Test loss: 0.748, Test accuracy: 70.78
Round  29, Global train loss: 0.491, Global test loss: 2.085, Global test accuracy: 29.58
Round  30, Train loss: 0.470, Test loss: 0.747, Test accuracy: 70.92
Round  30, Global train loss: 0.470, Global test loss: 2.038, Global test accuracy: 31.33
Round  31, Train loss: 0.528, Test loss: 0.745, Test accuracy: 71.35
Round  31, Global train loss: 0.528, Global test loss: 2.146, Global test accuracy: 16.97
Round  32, Train loss: 0.533, Test loss: 0.738, Test accuracy: 72.18
Round  32, Global train loss: 0.533, Global test loss: 2.361, Global test accuracy: 23.62
Round  33, Train loss: 0.539, Test loss: 0.718, Test accuracy: 73.45
Round  33, Global train loss: 0.539, Global test loss: 2.315, Global test accuracy: 27.02
Round  34, Train loss: 0.495, Test loss: 0.743, Test accuracy: 72.88
Round  34, Global train loss: 0.495, Global test loss: 2.206, Global test accuracy: 27.68
Round  35, Train loss: 0.443, Test loss: 0.739, Test accuracy: 73.18
Round  35, Global train loss: 0.443, Global test loss: 2.155, Global test accuracy: 30.37
Round  36, Train loss: 0.451, Test loss: 0.727, Test accuracy: 73.03
Round  36, Global train loss: 0.451, Global test loss: 2.227, Global test accuracy: 25.68
Round  37, Train loss: 0.371, Test loss: 0.737, Test accuracy: 73.10
Round  37, Global train loss: 0.371, Global test loss: 2.026, Global test accuracy: 27.60
Round  38, Train loss: 0.365, Test loss: 0.756, Test accuracy: 72.67
Round  38, Global train loss: 0.365, Global test loss: 2.159, Global test accuracy: 25.47
Round  39, Train loss: 0.309, Test loss: 0.775, Test accuracy: 72.63
Round  39, Global train loss: 0.309, Global test loss: 2.369, Global test accuracy: 22.58
Round  40, Train loss: 0.407, Test loss: 0.745, Test accuracy: 73.37
Round  40, Global train loss: 0.407, Global test loss: 2.054, Global test accuracy: 26.87
Round  41, Train loss: 0.357, Test loss: 0.736, Test accuracy: 73.83
Round  41, Global train loss: 0.357, Global test loss: 2.107, Global test accuracy: 27.58
Round  42, Train loss: 0.445, Test loss: 0.748, Test accuracy: 73.95
Round  42, Global train loss: 0.445, Global test loss: 2.048, Global test accuracy: 28.25
Round  43, Train loss: 0.313, Test loss: 0.754, Test accuracy: 73.92
Round  43, Global train loss: 0.313, Global test loss: 2.196, Global test accuracy: 22.93
Round  44, Train loss: 0.411, Test loss: 0.775, Test accuracy: 73.72
Round  44, Global train loss: 0.411, Global test loss: 2.067, Global test accuracy: 27.07
Round  45, Train loss: 0.423, Test loss: 0.804, Test accuracy: 73.30
Round  45, Global train loss: 0.423, Global test loss: 2.120, Global test accuracy: 30.17
Round  46, Train loss: 0.276, Test loss: 0.813, Test accuracy: 73.48
Round  46, Global train loss: 0.276, Global test loss: 2.148, Global test accuracy: 20.00
Round  47, Train loss: 0.332, Test loss: 0.823, Test accuracy: 73.27
Round  47, Global train loss: 0.332, Global test loss: 2.129, Global test accuracy: 28.72
Round  48, Train loss: 0.378, Test loss: 0.833, Test accuracy: 73.32
Round  48, Global train loss: 0.378, Global test loss: 2.284, Global test accuracy: 15.35
Round  49, Train loss: 0.267, Test loss: 0.831, Test accuracy: 73.83
Round  49, Global train loss: 0.267, Global test loss: 2.103, Global test accuracy: 26.53
Round  50, Train loss: 0.389, Test loss: 0.855, Test accuracy: 73.08
Round  50, Global train loss: 0.389, Global test loss: 2.164, Global test accuracy: 28.10
Round  51, Train loss: 0.251, Test loss: 0.888, Test accuracy: 72.02
Round  51, Global train loss: 0.251, Global test loss: 2.204, Global test accuracy: 27.62
Round  52, Train loss: 0.169, Test loss: 0.910, Test accuracy: 72.28
Round  52, Global train loss: 0.169, Global test loss: 2.118, Global test accuracy: 30.22
Round  53, Train loss: 0.264, Test loss: 0.905, Test accuracy: 72.10
Round  53, Global train loss: 0.264, Global test loss: 2.100, Global test accuracy: 26.27
Round  54, Train loss: 0.269, Test loss: 0.928, Test accuracy: 72.07
Round  54, Global train loss: 0.269, Global test loss: 2.199, Global test accuracy: 27.63
Round  55, Train loss: 0.245, Test loss: 0.912, Test accuracy: 72.18
Round  55, Global train loss: 0.245, Global test loss: 2.031, Global test accuracy: 31.43
Round  56, Train loss: 0.323, Test loss: 0.892, Test accuracy: 72.62
Round  56, Global train loss: 0.323, Global test loss: 2.326, Global test accuracy: 27.57
Round  57, Train loss: 0.224, Test loss: 0.897, Test accuracy: 72.75
Round  57, Global train loss: 0.224, Global test loss: 2.140, Global test accuracy: 23.00
Round  58, Train loss: 0.244, Test loss: 0.915, Test accuracy: 73.05
Round  58, Global train loss: 0.244, Global test loss: 2.243, Global test accuracy: 28.45
Round  59, Train loss: 0.408, Test loss: 0.922, Test accuracy: 72.83
Round  59, Global train loss: 0.408, Global test loss: 2.140, Global test accuracy: 26.03
Round  60, Train loss: 0.209, Test loss: 0.934, Test accuracy: 72.63
Round  60, Global train loss: 0.209, Global test loss: 2.042, Global test accuracy: 29.78
Round  61, Train loss: 0.262, Test loss: 0.953, Test accuracy: 72.52
Round  61, Global train loss: 0.262, Global test loss: 2.885, Global test accuracy: 25.83
Round  62, Train loss: 0.253, Test loss: 0.950, Test accuracy: 72.37
Round  62, Global train loss: 0.253, Global test loss: 2.027, Global test accuracy: 27.47
Round  63, Train loss: 0.249, Test loss: 0.960, Test accuracy: 72.33
Round  63, Global train loss: 0.249, Global test loss: 2.174, Global test accuracy: 29.73
Round  64, Train loss: 0.276, Test loss: 0.982, Test accuracy: 72.28
Round  64, Global train loss: 0.276, Global test loss: 2.062, Global test accuracy: 27.27
Round  65, Train loss: 0.192, Test loss: 0.975, Test accuracy: 72.60
Round  65, Global train loss: 0.192, Global test loss: 2.078, Global test accuracy: 28.40
Round  66, Train loss: 0.202, Test loss: 0.975, Test accuracy: 72.88
Round  66, Global train loss: 0.202, Global test loss: 1.973, Global test accuracy: 32.28
Round  67, Train loss: 0.155, Test loss: 0.991, Test accuracy: 73.10
Round  67, Global train loss: 0.155, Global test loss: 2.050, Global test accuracy: 27.22
Round  68, Train loss: 0.248, Test loss: 0.974, Test accuracy: 72.97
Round  68, Global train loss: 0.248, Global test loss: 2.048, Global test accuracy: 27.78
Round  69, Train loss: 0.196, Test loss: 0.981, Test accuracy: 72.63
Round  69, Global train loss: 0.196, Global test loss: 2.275, Global test accuracy: 26.17
Round  70, Train loss: 0.215, Test loss: 0.999, Test accuracy: 72.83
Round  70, Global train loss: 0.215, Global test loss: 2.526, Global test accuracy: 26.12
Round  71, Train loss: 0.193, Test loss: 1.039, Test accuracy: 72.87
Round  71, Global train loss: 0.193, Global test loss: 2.268, Global test accuracy: 26.28
Round  72, Train loss: 0.199, Test loss: 1.048, Test accuracy: 72.78
Round  72, Global train loss: 0.199, Global test loss: 2.276, Global test accuracy: 26.97
Round  73, Train loss: 0.185, Test loss: 1.079, Test accuracy: 72.62
Round  73, Global train loss: 0.185, Global test loss: 2.005, Global test accuracy: 28.57
Round  74, Train loss: 0.178, Test loss: 1.081, Test accuracy: 72.88
Round  74, Global train loss: 0.178, Global test loss: 2.565, Global test accuracy: 20.40
Round  75, Train loss: 0.141, Test loss: 1.081, Test accuracy: 73.18
Round  75, Global train loss: 0.141, Global test loss: 2.020, Global test accuracy: 27.78
Round  76, Train loss: 0.124, Test loss: 1.067, Test accuracy: 73.42
Round  76, Global train loss: 0.124, Global test loss: 1.966, Global test accuracy: 30.95
Round  77, Train loss: 0.116, Test loss: 1.084, Test accuracy: 73.63
Round  77, Global train loss: 0.116, Global test loss: 2.292, Global test accuracy: 23.10
Round  78, Train loss: 0.154, Test loss: 1.095, Test accuracy: 72.62
Round  78, Global train loss: 0.154, Global test loss: 1.979, Global test accuracy: 34.58
Round  79, Train loss: 0.234, Test loss: 1.120, Test accuracy: 72.63
Round  79, Global train loss: 0.234, Global test loss: 2.127, Global test accuracy: 27.90
Round  80, Train loss: 0.175, Test loss: 1.097, Test accuracy: 73.02
Round  80, Global train loss: 0.175, Global test loss: 1.983, Global test accuracy: 36.72
Round  81, Train loss: 0.224, Test loss: 1.112, Test accuracy: 72.62
Round  81, Global train loss: 0.224, Global test loss: 2.156, Global test accuracy: 21.73
Round  82, Train loss: 0.130, Test loss: 1.110, Test accuracy: 72.85
Round  82, Global train loss: 0.130, Global test loss: 2.208, Global test accuracy: 22.57
Round  83, Train loss: 0.207, Test loss: 1.104, Test accuracy: 72.97
Round  83, Global train loss: 0.207, Global test loss: 2.119, Global test accuracy: 29.57
Round  84, Train loss: 0.098, Test loss: 1.125, Test accuracy: 72.83
Round  84, Global train loss: 0.098, Global test loss: 2.217, Global test accuracy: 24.42
Round  85, Train loss: 0.137, Test loss: 1.154, Test accuracy: 72.55
Round  85, Global train loss: 0.137, Global test loss: 2.210, Global test accuracy: 28.75
Round  86, Train loss: 0.118, Test loss: 1.165, Test accuracy: 72.82
Round  86, Global train loss: 0.118, Global test loss: 2.134, Global test accuracy: 22.02
Round  87, Train loss: 0.137, Test loss: 1.198, Test accuracy: 72.92
Round  87, Global train loss: 0.137, Global test loss: 2.009, Global test accuracy: 29.60
Round  88, Train loss: 0.123, Test loss: 1.183, Test accuracy: 73.38
Round  88, Global train loss: 0.123, Global test loss: 2.051, Global test accuracy: 29.43
Round  89, Train loss: 0.121, Test loss: 1.189, Test accuracy: 74.15
Round  89, Global train loss: 0.121, Global test loss: 2.067, Global test accuracy: 30.65
Round  90, Train loss: 0.139, Test loss: 1.191, Test accuracy: 73.98
Round  90, Global train loss: 0.139, Global test loss: 2.113, Global test accuracy: 23.72
Round  91, Train loss: 0.051, Test loss: 1.209, Test accuracy: 73.48
Round  91, Global train loss: 0.051, Global test loss: 2.690, Global test accuracy: 26.83
Round  92, Train loss: 0.090, Test loss: 1.254, Test accuracy: 73.02
Round  92, Global train loss: 0.090, Global test loss: 2.065, Global test accuracy: 25.07
Round  93, Train loss: 0.103, Test loss: 1.260, Test accuracy: 72.88
Round  93, Global train loss: 0.103, Global test loss: 2.153, Global test accuracy: 28.12
Round  94, Train loss: 0.086, Test loss: 1.271, Test accuracy: 73.33
Round  94, Global train loss: 0.086, Global test loss: 2.404, Global test accuracy: 27.40
Round  95, Train loss: 0.092, Test loss: 1.235, Test accuracy: 73.55
Round  95, Global train loss: 0.092, Global test loss: 2.199, Global test accuracy: 29.90
Round  96, Train loss: 0.117, Test loss: 1.254, Test accuracy: 73.88
Round  96, Global train loss: 0.117, Global test loss: 2.182, Global test accuracy: 27.67
Round  97, Train loss: 0.103, Test loss: 1.279, Test accuracy: 73.57
Round  97, Global train loss: 0.103, Global test loss: 2.056, Global test accuracy: 32.15
Round  98, Train loss: 0.124, Test loss: 1.284, Test accuracy: 73.28
Round  98, Global train loss: 0.124, Global test loss: 2.051, Global test accuracy: 30.85
Round  99, Train loss: 0.104, Test loss: 1.289, Test accuracy: 73.25
Round  99, Global train loss: 0.104, Global test loss: 2.051, Global test accuracy: 28.18
Final Round, Train loss: 0.094, Test loss: 1.313, Test accuracy: 73.35
Final Round, Global train loss: 0.094, Global test loss: 2.051, Global test accuracy: 28.18
Average accuracy final 10 rounds: 73.42333333333333 

Average global accuracy final 10 rounds: 27.98833333333333 

1104.6429846286774
[1.0919554233551025, 2.183910846710205, 2.9751853942871094, 3.7664599418640137, 4.478734493255615, 5.191009044647217, 5.903374195098877, 6.615739345550537, 7.3431901931762695, 8.070641040802002, 8.804409742355347, 9.538178443908691, 10.276464939117432, 11.014751434326172, 11.790989398956299, 12.567227363586426, 13.33237910270691, 14.097530841827393, 14.837361097335815, 15.577191352844238, 16.335657596588135, 17.09412384033203, 17.83108878135681, 18.568053722381592, 19.316086292266846, 20.0641188621521, 20.77437424659729, 21.48462963104248, 22.213461875915527, 22.942294120788574, 23.702232360839844, 24.462170600891113, 25.220800161361694, 25.979429721832275, 26.820476770401, 27.661523818969727, 28.443532943725586, 29.225542068481445, 29.955344676971436, 30.685147285461426, 31.40963625907898, 32.13412523269653, 32.862783670425415, 33.5914421081543, 34.35590481758118, 35.12036752700806, 35.88085317611694, 36.64133882522583, 37.40097737312317, 38.16061592102051, 38.912052392959595, 39.66348886489868, 40.43623900413513, 41.20898914337158, 41.98560881614685, 42.76222848892212, 43.51338219642639, 44.264535903930664, 45.02839756011963, 45.792259216308594, 46.5157904624939, 47.2393217086792, 48.008816719055176, 48.77831172943115, 49.546870946884155, 50.31543016433716, 51.09855389595032, 51.88167762756348, 52.688562870025635, 53.49544811248779, 54.26887798309326, 55.04230785369873, 55.75139594078064, 56.46048402786255, 57.171427488327026, 57.882370948791504, 58.606910943984985, 59.33145093917847, 60.10875988006592, 60.88606882095337, 61.672558307647705, 62.45904779434204, 63.201690435409546, 63.94433307647705, 64.7012107372284, 65.45808839797974, 66.18772459030151, 66.91736078262329, 67.69097423553467, 68.46458768844604, 69.24790668487549, 70.03122568130493, 70.78463768959045, 71.53804969787598, 72.25268626213074, 72.9673228263855, 73.73175764083862, 74.49619245529175, 75.2582483291626, 76.02030420303345, 76.79757142066956, 77.57483863830566, 78.35681414604187, 79.13878965377808, 79.89883971214294, 80.65888977050781, 81.37178778648376, 82.08468580245972, 82.80067682266235, 83.51666784286499, 84.27256631851196, 85.02846479415894, 85.80055332183838, 86.57264184951782, 87.3489556312561, 88.12526941299438, 88.86637496948242, 89.60748052597046, 90.34437394142151, 91.08126735687256, 91.79046964645386, 92.49967193603516, 93.25101923942566, 94.00236654281616, 94.76901268959045, 95.53565883636475, 96.27636504173279, 97.01707124710083, 97.77430176734924, 98.53153228759766, 99.28897666931152, 100.04642105102539, 100.8108696937561, 101.57531833648682, 102.37080001831055, 103.16628170013428, 103.92653131484985, 104.68678092956543, 105.44767618179321, 106.208571434021, 106.93288803100586, 107.65720462799072, 108.38186073303223, 109.10651683807373, 109.90837860107422, 110.7102403640747, 111.503741979599, 112.29724359512329, 113.08126592636108, 113.86528825759888, 114.60987377166748, 115.35445928573608, 116.09107732772827, 116.82769536972046, 117.52911162376404, 118.23052787780762, 119.00059604644775, 119.77066421508789, 120.51458549499512, 121.25850677490234, 121.9949746131897, 122.73144245147705, 123.47301435470581, 124.21458625793457, 124.98246431350708, 125.75034236907959, 126.50603365898132, 127.26172494888306, 128.02953839302063, 128.7973518371582, 129.55477285385132, 130.31219387054443, 131.05553030967712, 131.79886674880981, 132.51408004760742, 133.22929334640503, 133.95285177230835, 134.67641019821167, 135.4465959072113, 136.21678161621094, 137.02516150474548, 137.83354139328003, 138.60669469833374, 139.37984800338745, 140.13654208183289, 140.89323616027832, 141.61816549301147, 142.34309482574463, 143.06192088127136, 143.7807469367981, 144.53568720817566, 145.29062747955322, 146.06257271766663, 146.83451795578003, 147.60327577590942, 148.37203359603882, 149.12269496917725, 149.87335634231567, 150.63513088226318, 151.3969054222107, 152.91258788108826, 154.42827033996582]
[26.7, 26.7, 39.3, 39.3, 45.45, 45.45, 53.46666666666667, 53.46666666666667, 51.78333333333333, 51.78333333333333, 58.766666666666666, 58.766666666666666, 60.93333333333333, 60.93333333333333, 62.56666666666667, 62.56666666666667, 65.56666666666666, 65.56666666666666, 66.61666666666666, 66.61666666666666, 67.55, 67.55, 66.93333333333334, 66.93333333333334, 67.73333333333333, 67.73333333333333, 68.16666666666667, 68.16666666666667, 68.68333333333334, 68.68333333333334, 68.35, 68.35, 69.31666666666666, 69.31666666666666, 68.75, 68.75, 69.36666666666666, 69.36666666666666, 69.58333333333333, 69.58333333333333, 69.93333333333334, 69.93333333333334, 69.96666666666667, 69.96666666666667, 70.38333333333334, 70.38333333333334, 70.51666666666667, 70.51666666666667, 71.06666666666666, 71.06666666666666, 71.05, 71.05, 70.75, 70.75, 70.06666666666666, 70.06666666666666, 71.28333333333333, 71.28333333333333, 70.78333333333333, 70.78333333333333, 70.91666666666667, 70.91666666666667, 71.35, 71.35, 72.18333333333334, 72.18333333333334, 73.45, 73.45, 72.88333333333334, 72.88333333333334, 73.18333333333334, 73.18333333333334, 73.03333333333333, 73.03333333333333, 73.1, 73.1, 72.66666666666667, 72.66666666666667, 72.63333333333334, 72.63333333333334, 73.36666666666666, 73.36666666666666, 73.83333333333333, 73.83333333333333, 73.95, 73.95, 73.91666666666667, 73.91666666666667, 73.71666666666667, 73.71666666666667, 73.3, 73.3, 73.48333333333333, 73.48333333333333, 73.26666666666667, 73.26666666666667, 73.31666666666666, 73.31666666666666, 73.83333333333333, 73.83333333333333, 73.08333333333333, 73.08333333333333, 72.01666666666667, 72.01666666666667, 72.28333333333333, 72.28333333333333, 72.1, 72.1, 72.06666666666666, 72.06666666666666, 72.18333333333334, 72.18333333333334, 72.61666666666666, 72.61666666666666, 72.75, 72.75, 73.05, 73.05, 72.83333333333333, 72.83333333333333, 72.63333333333334, 72.63333333333334, 72.51666666666667, 72.51666666666667, 72.36666666666666, 72.36666666666666, 72.33333333333333, 72.33333333333333, 72.28333333333333, 72.28333333333333, 72.6, 72.6, 72.88333333333334, 72.88333333333334, 73.1, 73.1, 72.96666666666667, 72.96666666666667, 72.63333333333334, 72.63333333333334, 72.83333333333333, 72.83333333333333, 72.86666666666666, 72.86666666666666, 72.78333333333333, 72.78333333333333, 72.61666666666666, 72.61666666666666, 72.88333333333334, 72.88333333333334, 73.18333333333334, 73.18333333333334, 73.41666666666667, 73.41666666666667, 73.63333333333334, 73.63333333333334, 72.61666666666666, 72.61666666666666, 72.63333333333334, 72.63333333333334, 73.01666666666667, 73.01666666666667, 72.61666666666666, 72.61666666666666, 72.85, 72.85, 72.96666666666667, 72.96666666666667, 72.83333333333333, 72.83333333333333, 72.55, 72.55, 72.81666666666666, 72.81666666666666, 72.91666666666667, 72.91666666666667, 73.38333333333334, 73.38333333333334, 74.15, 74.15, 73.98333333333333, 73.98333333333333, 73.48333333333333, 73.48333333333333, 73.01666666666667, 73.01666666666667, 72.88333333333334, 72.88333333333334, 73.33333333333333, 73.33333333333333, 73.55, 73.55, 73.88333333333334, 73.88333333333334, 73.56666666666666, 73.56666666666666, 73.28333333333333, 73.28333333333333, 73.25, 73.25, 73.35, 73.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.212, Test loss: 1.904, Test accuracy: 32.70
Round   0, Global train loss: 1.212, Global test loss: 2.258, Global test accuracy: 25.62
Round   1, Train loss: 1.049, Test loss: 1.510, Test accuracy: 40.27
Round   1, Global train loss: 1.049, Global test loss: 2.128, Global test accuracy: 25.85
Round   2, Train loss: 0.912, Test loss: 1.438, Test accuracy: 46.72
Round   2, Global train loss: 0.912, Global test loss: 2.307, Global test accuracy: 28.07
Round   3, Train loss: 0.945, Test loss: 1.136, Test accuracy: 51.97
Round   3, Global train loss: 0.945, Global test loss: 2.160, Global test accuracy: 27.13
Round   4, Train loss: 0.937, Test loss: 1.056, Test accuracy: 56.02
Round   4, Global train loss: 0.937, Global test loss: 1.912, Global test accuracy: 28.92
Round   5, Train loss: 0.779, Test loss: 0.964, Test accuracy: 60.75
Round   5, Global train loss: 0.779, Global test loss: 2.263, Global test accuracy: 25.92
Round   6, Train loss: 0.890, Test loss: 0.858, Test accuracy: 63.43
Round   6, Global train loss: 0.890, Global test loss: 1.967, Global test accuracy: 27.53
Round   7, Train loss: 0.764, Test loss: 0.824, Test accuracy: 64.58
Round   7, Global train loss: 0.764, Global test loss: 1.899, Global test accuracy: 31.92
Round   8, Train loss: 0.812, Test loss: 0.723, Test accuracy: 68.97
Round   8, Global train loss: 0.812, Global test loss: 1.906, Global test accuracy: 32.47
Round   9, Train loss: 0.828, Test loss: 0.710, Test accuracy: 69.48
Round   9, Global train loss: 0.828, Global test loss: 1.971, Global test accuracy: 28.33
Round  10, Train loss: 0.643, Test loss: 0.703, Test accuracy: 70.05
Round  10, Global train loss: 0.643, Global test loss: 1.890, Global test accuracy: 34.82
Round  11, Train loss: 0.773, Test loss: 0.707, Test accuracy: 70.35
Round  11, Global train loss: 0.773, Global test loss: 1.801, Global test accuracy: 35.55
Round  12, Train loss: 0.765, Test loss: 0.692, Test accuracy: 71.00
Round  12, Global train loss: 0.765, Global test loss: 1.593, Global test accuracy: 40.10
Round  13, Train loss: 0.685, Test loss: 0.690, Test accuracy: 71.28
Round  13, Global train loss: 0.685, Global test loss: 1.641, Global test accuracy: 40.77
Round  14, Train loss: 0.746, Test loss: 0.679, Test accuracy: 71.82
Round  14, Global train loss: 0.746, Global test loss: 1.585, Global test accuracy: 41.75
Round  15, Train loss: 0.661, Test loss: 0.675, Test accuracy: 72.10
Round  15, Global train loss: 0.661, Global test loss: 1.650, Global test accuracy: 44.30
Round  16, Train loss: 0.702, Test loss: 0.662, Test accuracy: 73.00
Round  16, Global train loss: 0.702, Global test loss: 1.660, Global test accuracy: 41.97
Round  17, Train loss: 0.643, Test loss: 0.642, Test accuracy: 73.92
Round  17, Global train loss: 0.643, Global test loss: 1.643, Global test accuracy: 39.78
Round  18, Train loss: 0.585, Test loss: 0.643, Test accuracy: 73.88
Round  18, Global train loss: 0.585, Global test loss: 1.609, Global test accuracy: 40.80
Round  19, Train loss: 0.654, Test loss: 0.664, Test accuracy: 72.73
Round  19, Global train loss: 0.654, Global test loss: 1.619, Global test accuracy: 40.23
Round  20, Train loss: 0.636, Test loss: 0.648, Test accuracy: 73.17
Round  20, Global train loss: 0.636, Global test loss: 1.735, Global test accuracy: 37.72
Round  21, Train loss: 0.587, Test loss: 0.626, Test accuracy: 74.58
Round  21, Global train loss: 0.587, Global test loss: 1.655, Global test accuracy: 43.30
Round  22, Train loss: 0.563, Test loss: 0.617, Test accuracy: 74.92
Round  22, Global train loss: 0.563, Global test loss: 1.775, Global test accuracy: 40.00
Round  23, Train loss: 0.671, Test loss: 0.600, Test accuracy: 75.68
Round  23, Global train loss: 0.671, Global test loss: 1.614, Global test accuracy: 44.62
Round  24, Train loss: 0.613, Test loss: 0.597, Test accuracy: 75.88
Round  24, Global train loss: 0.613, Global test loss: 1.697, Global test accuracy: 39.12
Round  25, Train loss: 0.630, Test loss: 0.614, Test accuracy: 75.62
Round  25, Global train loss: 0.630, Global test loss: 1.638, Global test accuracy: 39.90
Round  26, Train loss: 0.547, Test loss: 0.619, Test accuracy: 75.27
Round  26, Global train loss: 0.547, Global test loss: 1.824, Global test accuracy: 44.22
Round  27, Train loss: 0.543, Test loss: 0.613, Test accuracy: 75.50
Round  27, Global train loss: 0.543, Global test loss: 1.649, Global test accuracy: 44.25
Round  28, Train loss: 0.535, Test loss: 0.613, Test accuracy: 76.03
Round  28, Global train loss: 0.535, Global test loss: 1.560, Global test accuracy: 44.52
Round  29, Train loss: 0.569, Test loss: 0.595, Test accuracy: 76.42
Round  29, Global train loss: 0.569, Global test loss: 1.377, Global test accuracy: 50.40
Round  30, Train loss: 0.522, Test loss: 0.591, Test accuracy: 76.68
Round  30, Global train loss: 0.522, Global test loss: 1.428, Global test accuracy: 50.13
Round  31, Train loss: 0.541, Test loss: 0.612, Test accuracy: 76.05
Round  31, Global train loss: 0.541, Global test loss: 1.382, Global test accuracy: 49.32
Round  32, Train loss: 0.601, Test loss: 0.592, Test accuracy: 77.03
Round  32, Global train loss: 0.601, Global test loss: 1.626, Global test accuracy: 40.52
Round  33, Train loss: 0.544, Test loss: 0.577, Test accuracy: 77.45
Round  33, Global train loss: 0.544, Global test loss: 1.652, Global test accuracy: 45.75
Round  34, Train loss: 0.573, Test loss: 0.581, Test accuracy: 77.07
Round  34, Global train loss: 0.573, Global test loss: 1.610, Global test accuracy: 43.87
Round  35, Train loss: 0.466, Test loss: 0.565, Test accuracy: 77.82
Round  35, Global train loss: 0.466, Global test loss: 1.503, Global test accuracy: 46.70
Round  36, Train loss: 0.563, Test loss: 0.560, Test accuracy: 77.93
Round  36, Global train loss: 0.563, Global test loss: 1.518, Global test accuracy: 44.92
Round  37, Train loss: 0.526, Test loss: 0.579, Test accuracy: 77.78
Round  37, Global train loss: 0.526, Global test loss: 1.375, Global test accuracy: 49.57
Round  38, Train loss: 0.448, Test loss: 0.572, Test accuracy: 77.80
Round  38, Global train loss: 0.448, Global test loss: 1.648, Global test accuracy: 46.93
Round  39, Train loss: 0.381, Test loss: 0.572, Test accuracy: 78.23
Round  39, Global train loss: 0.381, Global test loss: 1.865, Global test accuracy: 41.70
Round  40, Train loss: 0.506, Test loss: 0.558, Test accuracy: 78.33
Round  40, Global train loss: 0.506, Global test loss: 1.322, Global test accuracy: 53.18
Round  41, Train loss: 0.472, Test loss: 0.581, Test accuracy: 77.47
Round  41, Global train loss: 0.472, Global test loss: 1.448, Global test accuracy: 50.08
Round  42, Train loss: 0.506, Test loss: 0.583, Test accuracy: 77.40
Round  42, Global train loss: 0.506, Global test loss: 1.403, Global test accuracy: 51.03
Round  43, Train loss: 0.444, Test loss: 0.581, Test accuracy: 77.45
Round  43, Global train loss: 0.444, Global test loss: 1.747, Global test accuracy: 42.22
Round  44, Train loss: 0.473, Test loss: 0.591, Test accuracy: 76.95
Round  44, Global train loss: 0.473, Global test loss: 1.386, Global test accuracy: 52.25
Round  45, Train loss: 0.603, Test loss: 0.565, Test accuracy: 77.93
Round  45, Global train loss: 0.603, Global test loss: 1.302, Global test accuracy: 54.25
Round  46, Train loss: 0.428, Test loss: 0.566, Test accuracy: 78.05
Round  46, Global train loss: 0.428, Global test loss: 1.550, Global test accuracy: 48.22
Round  47, Train loss: 0.424, Test loss: 0.549, Test accuracy: 78.90
Round  47, Global train loss: 0.424, Global test loss: 1.600, Global test accuracy: 49.27
Round  48, Train loss: 0.483, Test loss: 0.551, Test accuracy: 78.43
Round  48, Global train loss: 0.483, Global test loss: 1.630, Global test accuracy: 46.97
Round  49, Train loss: 0.419, Test loss: 0.567, Test accuracy: 78.27
Round  49, Global train loss: 0.419, Global test loss: 1.331, Global test accuracy: 53.65
Round  50, Train loss: 0.412, Test loss: 0.565, Test accuracy: 78.65
Round  50, Global train loss: 0.412, Global test loss: 1.344, Global test accuracy: 53.13
Round  51, Train loss: 0.307, Test loss: 0.571, Test accuracy: 78.55
Round  51, Global train loss: 0.307, Global test loss: 1.363, Global test accuracy: 54.38
Round  52, Train loss: 0.336, Test loss: 0.550, Test accuracy: 79.35
Round  52, Global train loss: 0.336, Global test loss: 1.605, Global test accuracy: 50.18
Round  53, Train loss: 0.356, Test loss: 0.537, Test accuracy: 79.63
Round  53, Global train loss: 0.356, Global test loss: 1.246, Global test accuracy: 55.85
Round  54, Train loss: 0.395, Test loss: 0.537, Test accuracy: 79.97
Round  54, Global train loss: 0.395, Global test loss: 1.452, Global test accuracy: 51.30
Round  55, Train loss: 0.307, Test loss: 0.548, Test accuracy: 79.93
Round  55, Global train loss: 0.307, Global test loss: 1.337, Global test accuracy: 52.38
Round  56, Train loss: 0.448, Test loss: 0.541, Test accuracy: 79.92
Round  56, Global train loss: 0.448, Global test loss: 1.568, Global test accuracy: 47.72
Round  57, Train loss: 0.348, Test loss: 0.541, Test accuracy: 80.20
Round  57, Global train loss: 0.348, Global test loss: 1.468, Global test accuracy: 52.73
Round  58, Train loss: 0.368, Test loss: 0.551, Test accuracy: 79.90
Round  58, Global train loss: 0.368, Global test loss: 1.571, Global test accuracy: 50.43
Round  59, Train loss: 0.423, Test loss: 0.556, Test accuracy: 79.75
Round  59, Global train loss: 0.423, Global test loss: 1.397, Global test accuracy: 51.53
Round  60, Train loss: 0.409, Test loss: 0.556, Test accuracy: 80.00
Round  60, Global train loss: 0.409, Global test loss: 1.457, Global test accuracy: 51.45
Round  61, Train loss: 0.314, Test loss: 0.553, Test accuracy: 80.13
Round  61, Global train loss: 0.314, Global test loss: 1.905, Global test accuracy: 45.27
Round  62, Train loss: 0.416, Test loss: 0.548, Test accuracy: 80.10
Round  62, Global train loss: 0.416, Global test loss: 1.227, Global test accuracy: 57.95
Round  63, Train loss: 0.389, Test loss: 0.557, Test accuracy: 80.27
Round  63, Global train loss: 0.389, Global test loss: 1.473, Global test accuracy: 51.55
Round  64, Train loss: 0.405, Test loss: 0.538, Test accuracy: 80.37
Round  64, Global train loss: 0.405, Global test loss: 1.385, Global test accuracy: 52.93
Round  65, Train loss: 0.299, Test loss: 0.556, Test accuracy: 79.90
Round  65, Global train loss: 0.299, Global test loss: 1.391, Global test accuracy: 53.17
Round  66, Train loss: 0.359, Test loss: 0.553, Test accuracy: 80.12
Round  66, Global train loss: 0.359, Global test loss: 1.424, Global test accuracy: 50.68
Round  67, Train loss: 0.292, Test loss: 0.558, Test accuracy: 80.30
Round  67, Global train loss: 0.292, Global test loss: 1.514, Global test accuracy: 49.82
Round  68, Train loss: 0.410, Test loss: 0.551, Test accuracy: 80.10
Round  68, Global train loss: 0.410, Global test loss: 1.291, Global test accuracy: 56.87
Round  69, Train loss: 0.336, Test loss: 0.556, Test accuracy: 80.05
Round  69, Global train loss: 0.336, Global test loss: 1.545, Global test accuracy: 50.48
Round  70, Train loss: 0.346, Test loss: 0.559, Test accuracy: 80.35
Round  70, Global train loss: 0.346, Global test loss: 1.685, Global test accuracy: 47.78
Round  71, Train loss: 0.415, Test loss: 0.555, Test accuracy: 80.58
Round  71, Global train loss: 0.415, Global test loss: 1.555, Global test accuracy: 50.03
Round  72, Train loss: 0.314, Test loss: 0.548, Test accuracy: 80.85
Round  72, Global train loss: 0.314, Global test loss: 1.589, Global test accuracy: 50.40
Round  73, Train loss: 0.349, Test loss: 0.552, Test accuracy: 80.53
Round  73, Global train loss: 0.349, Global test loss: 1.312, Global test accuracy: 56.00
Round  74, Train loss: 0.321, Test loss: 0.554, Test accuracy: 80.65
Round  74, Global train loss: 0.321, Global test loss: 1.638, Global test accuracy: 48.80
Round  75, Train loss: 0.291, Test loss: 0.560, Test accuracy: 80.58
Round  75, Global train loss: 0.291, Global test loss: 1.248, Global test accuracy: 58.15
Round  76, Train loss: 0.324, Test loss: 0.552, Test accuracy: 80.75
Round  76, Global train loss: 0.324, Global test loss: 1.221, Global test accuracy: 58.22
Round  77, Train loss: 0.262, Test loss: 0.546, Test accuracy: 80.83
Round  77, Global train loss: 0.262, Global test loss: 1.481, Global test accuracy: 52.92
Round  78, Train loss: 0.323, Test loss: 0.544, Test accuracy: 81.05
Round  78, Global train loss: 0.323, Global test loss: 1.461, Global test accuracy: 53.10
Round  79, Train loss: 0.362, Test loss: 0.547, Test accuracy: 81.15
Round  79, Global train loss: 0.362, Global test loss: 1.397, Global test accuracy: 54.70
Round  80, Train loss: 0.280, Test loss: 0.549, Test accuracy: 81.05
Round  80, Global train loss: 0.280, Global test loss: 1.317, Global test accuracy: 56.42
Round  81, Train loss: 0.329, Test loss: 0.567, Test accuracy: 80.57
Round  81, Global train loss: 0.329, Global test loss: 1.465, Global test accuracy: 54.10
Round  82, Train loss: 0.309, Test loss: 0.556, Test accuracy: 81.10
Round  82, Global train loss: 0.309, Global test loss: 1.653, Global test accuracy: 50.82
Round  83, Train loss: 0.338, Test loss: 0.550, Test accuracy: 81.28
Round  83, Global train loss: 0.338, Global test loss: 1.544, Global test accuracy: 54.30
Round  84, Train loss: 0.247, Test loss: 0.559, Test accuracy: 81.37
Round  84, Global train loss: 0.247, Global test loss: 1.541, Global test accuracy: 52.92
Round  85, Train loss: 0.279, Test loss: 0.575, Test accuracy: 80.78
Round  85, Global train loss: 0.279, Global test loss: 1.440, Global test accuracy: 54.12
Round  86, Train loss: 0.258, Test loss: 0.570, Test accuracy: 80.68
Round  86, Global train loss: 0.258, Global test loss: 1.414, Global test accuracy: 55.70
Round  87, Train loss: 0.328, Test loss: 0.583, Test accuracy: 80.63
Round  87, Global train loss: 0.328, Global test loss: 1.304, Global test accuracy: 56.42
Round  88, Train loss: 0.243, Test loss: 0.577, Test accuracy: 80.78
Round  88, Global train loss: 0.243, Global test loss: 1.423, Global test accuracy: 56.10
Round  89, Train loss: 0.293, Test loss: 0.563, Test accuracy: 81.25
Round  89, Global train loss: 0.293, Global test loss: 1.358, Global test accuracy: 55.83
Round  90, Train loss: 0.325, Test loss: 0.560, Test accuracy: 81.77
Round  90, Global train loss: 0.325, Global test loss: 1.338, Global test accuracy: 56.83
Round  91, Train loss: 0.256, Test loss: 0.561, Test accuracy: 81.38
Round  91, Global train loss: 0.256, Global test loss: 2.140, Global test accuracy: 47.92
Round  92, Train loss: 0.268, Test loss: 0.572, Test accuracy: 81.12
Round  92, Global train loss: 0.268, Global test loss: 1.400, Global test accuracy: 56.60
Round  93, Train loss: 0.246, Test loss: 0.588, Test accuracy: 80.72
Round  93, Global train loss: 0.246, Global test loss: 1.592, Global test accuracy: 52.18
Round  94, Train loss: 0.281, Test loss: 0.595, Test accuracy: 80.42
Round  94, Global train loss: 0.281, Global test loss: 1.718, Global test accuracy: 48.28
Round  95, Train loss: 0.237, Test loss: 0.607, Test accuracy: 80.55
Round  95, Global train loss: 0.237, Global test loss: 1.475, Global test accuracy: 54.37
Round  96, Train loss: 0.254, Test loss: 0.598, Test accuracy: 81.00
Round  96, Global train loss: 0.254, Global test loss: 1.561, Global test accuracy: 53.07
Round  97, Train loss: 0.323, Test loss: 0.575, Test accuracy: 81.23
Round  97, Global train loss: 0.323, Global test loss: 1.523, Global test accuracy: 53.92
Round  98, Train loss: 0.248, Test loss: 0.573, Test accuracy: 81.48
Round  98, Global train loss: 0.248, Global test loss: 1.440, Global test accuracy: 56.68
Round  99, Train loss: 0.285, Test loss: 0.583, Test accuracy: 81.32
Round  99, Global train loss: 0.285, Global test loss: 1.445, Global test accuracy: 55.73
Final Round, Train loss: 0.200, Test loss: 0.599, Test accuracy: 81.62
Final Round, Global train loss: 0.200, Global test loss: 1.445, Global test accuracy: 55.73
Average accuracy final 10 rounds: 81.09833333333333 

Average global accuracy final 10 rounds: 53.55833333333333 

1113.693259716034
[1.0651445388793945, 2.130289077758789, 2.8482420444488525, 3.566195011138916, 4.319249391555786, 5.072303771972656, 5.836180925369263, 6.600058078765869, 7.392424821853638, 8.184791564941406, 8.963783264160156, 9.742774963378906, 10.487691640853882, 11.232608318328857, 11.948468685150146, 12.664329051971436, 13.458427429199219, 14.252525806427002, 14.995424032211304, 15.738322257995605, 16.55160427093506, 17.36488628387451, 18.10969591140747, 18.85450553894043, 19.6308650970459, 20.407224655151367, 21.148011922836304, 21.88879919052124, 22.684372663497925, 23.47994613647461, 24.237017154693604, 24.994088172912598, 25.750967741012573, 26.50784730911255, 27.241398096084595, 27.97494888305664, 28.71641254425049, 29.457876205444336, 30.228387117385864, 30.998898029327393, 31.7947416305542, 32.590585231781006, 33.392038345336914, 34.19349145889282, 34.904167890548706, 35.61484432220459, 36.334354400634766, 37.05386447906494, 37.77256369590759, 38.491262912750244, 39.24915909767151, 40.00705528259277, 40.841442823410034, 41.675830364227295, 42.451138734817505, 43.226447105407715, 43.997180700302124, 44.76791429519653, 45.505255937576294, 46.242597579956055, 46.96995425224304, 47.69731092453003, 48.44961643218994, 49.20192193984985, 49.973543882369995, 50.74516582489014, 51.519702672958374, 52.29423952102661, 53.055891275405884, 53.817543029785156, 54.58442139625549, 55.35129976272583, 56.13158917427063, 56.91187858581543, 57.69127941131592, 58.470680236816406, 59.22911310195923, 59.98754596710205, 60.711634159088135, 61.43572235107422, 62.1605966091156, 62.88547086715698, 63.602750301361084, 64.32002973556519, 65.09582805633545, 65.87162637710571, 66.66276597976685, 67.45390558242798, 68.25293016433716, 69.05195474624634, 69.79993867874146, 70.54792261123657, 71.27255702018738, 71.99719142913818, 72.70646381378174, 73.4157361984253, 74.16971349716187, 74.92369079589844, 75.6823365688324, 76.44098234176636, 77.23337507247925, 78.02576780319214, 78.76968502998352, 79.5136022567749, 80.26099944114685, 81.0083966255188, 81.79445433616638, 82.58051204681396, 83.37287020683289, 84.1652283668518, 84.93769931793213, 85.71017026901245, 86.42803406715393, 87.14589786529541, 87.87013912200928, 88.59438037872314, 89.34199070930481, 90.08960103988647, 90.86794447898865, 91.64628791809082, 92.46004366874695, 93.27379941940308, 94.07087230682373, 94.86794519424438, 95.61199116706848, 96.35603713989258, 97.08758068084717, 97.81912422180176, 98.60544085502625, 99.39175748825073, 100.14196801185608, 100.89217853546143, 101.67690682411194, 102.46163511276245, 103.22805953025818, 103.9944839477539, 104.74610328674316, 105.49772262573242, 106.29539251327515, 107.09306240081787, 107.88658785820007, 108.68011331558228, 109.45281171798706, 110.22551012039185, 111.02141952514648, 111.81732892990112, 112.56798481941223, 113.31864070892334, 114.09729290008545, 114.87594509124756, 115.63311719894409, 116.39028930664062, 117.1935362815857, 117.99678325653076, 118.7811164855957, 119.56544971466064, 120.29957628250122, 121.0337028503418, 121.74654150009155, 122.45938014984131, 123.19122886657715, 123.92307758331299, 124.66822361946106, 125.41336965560913, 126.18346762657166, 126.95356559753418, 127.75198531150818, 128.55040502548218, 129.31704354286194, 130.0836820602417, 130.8218457698822, 131.5600094795227, 132.31167936325073, 133.06334924697876, 133.8093695640564, 134.55538988113403, 135.31331610679626, 136.0712423324585, 136.84633946418762, 137.62143659591675, 138.3655035495758, 139.10957050323486, 139.87878894805908, 140.6480073928833, 141.42882084846497, 142.20963430404663, 142.9845323562622, 143.75943040847778, 144.52932047843933, 145.29921054840088, 146.02251601219177, 146.74582147598267, 147.4916787147522, 148.23753595352173, 148.96839690208435, 149.69925785064697, 150.49141645431519, 151.2835750579834, 152.073237657547, 152.8629002571106, 154.4626190662384, 156.0623378753662]
[32.7, 32.7, 40.266666666666666, 40.266666666666666, 46.71666666666667, 46.71666666666667, 51.96666666666667, 51.96666666666667, 56.016666666666666, 56.016666666666666, 60.75, 60.75, 63.43333333333333, 63.43333333333333, 64.58333333333333, 64.58333333333333, 68.96666666666667, 68.96666666666667, 69.48333333333333, 69.48333333333333, 70.05, 70.05, 70.35, 70.35, 71.0, 71.0, 71.28333333333333, 71.28333333333333, 71.81666666666666, 71.81666666666666, 72.1, 72.1, 73.0, 73.0, 73.91666666666667, 73.91666666666667, 73.88333333333334, 73.88333333333334, 72.73333333333333, 72.73333333333333, 73.16666666666667, 73.16666666666667, 74.58333333333333, 74.58333333333333, 74.91666666666667, 74.91666666666667, 75.68333333333334, 75.68333333333334, 75.88333333333334, 75.88333333333334, 75.61666666666666, 75.61666666666666, 75.26666666666667, 75.26666666666667, 75.5, 75.5, 76.03333333333333, 76.03333333333333, 76.41666666666667, 76.41666666666667, 76.68333333333334, 76.68333333333334, 76.05, 76.05, 77.03333333333333, 77.03333333333333, 77.45, 77.45, 77.06666666666666, 77.06666666666666, 77.81666666666666, 77.81666666666666, 77.93333333333334, 77.93333333333334, 77.78333333333333, 77.78333333333333, 77.8, 77.8, 78.23333333333333, 78.23333333333333, 78.33333333333333, 78.33333333333333, 77.46666666666667, 77.46666666666667, 77.4, 77.4, 77.45, 77.45, 76.95, 76.95, 77.93333333333334, 77.93333333333334, 78.05, 78.05, 78.9, 78.9, 78.43333333333334, 78.43333333333334, 78.26666666666667, 78.26666666666667, 78.65, 78.65, 78.55, 78.55, 79.35, 79.35, 79.63333333333334, 79.63333333333334, 79.96666666666667, 79.96666666666667, 79.93333333333334, 79.93333333333334, 79.91666666666667, 79.91666666666667, 80.2, 80.2, 79.9, 79.9, 79.75, 79.75, 80.0, 80.0, 80.13333333333334, 80.13333333333334, 80.1, 80.1, 80.26666666666667, 80.26666666666667, 80.36666666666666, 80.36666666666666, 79.9, 79.9, 80.11666666666666, 80.11666666666666, 80.3, 80.3, 80.1, 80.1, 80.05, 80.05, 80.35, 80.35, 80.58333333333333, 80.58333333333333, 80.85, 80.85, 80.53333333333333, 80.53333333333333, 80.65, 80.65, 80.58333333333333, 80.58333333333333, 80.75, 80.75, 80.83333333333333, 80.83333333333333, 81.05, 81.05, 81.15, 81.15, 81.05, 81.05, 80.56666666666666, 80.56666666666666, 81.1, 81.1, 81.28333333333333, 81.28333333333333, 81.36666666666666, 81.36666666666666, 80.78333333333333, 80.78333333333333, 80.68333333333334, 80.68333333333334, 80.63333333333334, 80.63333333333334, 80.78333333333333, 80.78333333333333, 81.25, 81.25, 81.76666666666667, 81.76666666666667, 81.38333333333334, 81.38333333333334, 81.11666666666666, 81.11666666666666, 80.71666666666667, 80.71666666666667, 80.41666666666667, 80.41666666666667, 80.55, 80.55, 81.0, 81.0, 81.23333333333333, 81.23333333333333, 81.48333333333333, 81.48333333333333, 81.31666666666666, 81.31666666666666, 81.61666666666666, 81.61666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.224, Test loss: 1.989, Test accuracy: 27.38
Round   0, Global train loss: 1.224, Global test loss: 2.346, Global test accuracy: 16.67
Round   1, Train loss: 1.051, Test loss: 1.618, Test accuracy: 39.37
Round   1, Global train loss: 1.051, Global test loss: 2.256, Global test accuracy: 25.58
Round   2, Train loss: 0.968, Test loss: 1.476, Test accuracy: 45.70
Round   2, Global train loss: 0.968, Global test loss: 2.329, Global test accuracy: 26.12
Round   3, Train loss: 0.963, Test loss: 1.161, Test accuracy: 52.05
Round   3, Global train loss: 0.963, Global test loss: 2.184, Global test accuracy: 26.40
Round   4, Train loss: 0.938, Test loss: 1.096, Test accuracy: 54.52
Round   4, Global train loss: 0.938, Global test loss: 1.950, Global test accuracy: 29.95
Round   5, Train loss: 0.822, Test loss: 0.996, Test accuracy: 59.57
Round   5, Global train loss: 0.822, Global test loss: 2.309, Global test accuracy: 25.50
Round   6, Train loss: 0.844, Test loss: 0.899, Test accuracy: 61.93
Round   6, Global train loss: 0.844, Global test loss: 2.083, Global test accuracy: 26.78
Round   7, Train loss: 0.772, Test loss: 0.852, Test accuracy: 63.63
Round   7, Global train loss: 0.772, Global test loss: 1.963, Global test accuracy: 30.50
Round   8, Train loss: 0.802, Test loss: 0.741, Test accuracy: 68.12
Round   8, Global train loss: 0.802, Global test loss: 1.843, Global test accuracy: 33.62
Round   9, Train loss: 0.859, Test loss: 0.742, Test accuracy: 68.50
Round   9, Global train loss: 0.859, Global test loss: 1.947, Global test accuracy: 28.63
Round  10, Train loss: 0.700, Test loss: 0.739, Test accuracy: 68.88
Round  10, Global train loss: 0.700, Global test loss: 1.925, Global test accuracy: 34.68
Round  11, Train loss: 0.798, Test loss: 0.729, Test accuracy: 69.00
Round  11, Global train loss: 0.798, Global test loss: 1.799, Global test accuracy: 35.37
Round  12, Train loss: 0.721, Test loss: 0.749, Test accuracy: 67.85
Round  12, Global train loss: 0.721, Global test loss: 1.619, Global test accuracy: 41.25
Round  13, Train loss: 0.689, Test loss: 0.723, Test accuracy: 69.45
Round  13, Global train loss: 0.689, Global test loss: 1.715, Global test accuracy: 39.40
Round  14, Train loss: 0.810, Test loss: 0.709, Test accuracy: 70.43
Round  14, Global train loss: 0.810, Global test loss: 1.629, Global test accuracy: 41.38
Round  15, Train loss: 0.695, Test loss: 0.681, Test accuracy: 72.37
Round  15, Global train loss: 0.695, Global test loss: 1.686, Global test accuracy: 42.78
Round  16, Train loss: 0.695, Test loss: 0.665, Test accuracy: 72.72
Round  16, Global train loss: 0.695, Global test loss: 1.644, Global test accuracy: 41.85
Round  17, Train loss: 0.681, Test loss: 0.677, Test accuracy: 72.10
Round  17, Global train loss: 0.681, Global test loss: 1.638, Global test accuracy: 40.02
Round  18, Train loss: 0.597, Test loss: 0.668, Test accuracy: 72.75
Round  18, Global train loss: 0.597, Global test loss: 1.639, Global test accuracy: 39.93
Round  19, Train loss: 0.679, Test loss: 0.665, Test accuracy: 72.45
Round  19, Global train loss: 0.679, Global test loss: 1.615, Global test accuracy: 40.35
Round  20, Train loss: 0.649, Test loss: 0.653, Test accuracy: 73.53
Round  20, Global train loss: 0.649, Global test loss: 1.771, Global test accuracy: 35.42
Round  21, Train loss: 0.605, Test loss: 0.640, Test accuracy: 73.97
Round  21, Global train loss: 0.605, Global test loss: 1.616, Global test accuracy: 43.10
Round  22, Train loss: 0.589, Test loss: 0.640, Test accuracy: 73.50
Round  22, Global train loss: 0.589, Global test loss: 1.791, Global test accuracy: 38.48
Round  23, Train loss: 0.698, Test loss: 0.634, Test accuracy: 73.92
Round  23, Global train loss: 0.698, Global test loss: 1.649, Global test accuracy: 42.92
Round  24, Train loss: 0.614, Test loss: 0.634, Test accuracy: 74.33
Round  24, Global train loss: 0.614, Global test loss: 1.781, Global test accuracy: 37.60
Round  25, Train loss: 0.581, Test loss: 0.603, Test accuracy: 75.62
Round  25, Global train loss: 0.581, Global test loss: 1.734, Global test accuracy: 37.57
Round  26, Train loss: 0.538, Test loss: 0.602, Test accuracy: 75.75
Round  26, Global train loss: 0.538, Global test loss: 1.664, Global test accuracy: 43.90
Round  27, Train loss: 0.536, Test loss: 0.610, Test accuracy: 75.53
Round  27, Global train loss: 0.536, Global test loss: 1.600, Global test accuracy: 44.20
Round  28, Train loss: 0.589, Test loss: 0.594, Test accuracy: 76.12
Round  28, Global train loss: 0.589, Global test loss: 1.621, Global test accuracy: 41.92
Round  29, Train loss: 0.619, Test loss: 0.600, Test accuracy: 75.88
Round  29, Global train loss: 0.619, Global test loss: 1.448, Global test accuracy: 48.77
Round  30, Train loss: 0.575, Test loss: 0.594, Test accuracy: 76.08
Round  30, Global train loss: 0.575, Global test loss: 1.469, Global test accuracy: 46.65
Round  31, Train loss: 0.569, Test loss: 0.593, Test accuracy: 76.08
Round  31, Global train loss: 0.569, Global test loss: 1.389, Global test accuracy: 50.55
Round  32, Train loss: 0.576, Test loss: 0.589, Test accuracy: 76.50
Round  32, Global train loss: 0.576, Global test loss: 1.721, Global test accuracy: 36.80
Round  33, Train loss: 0.585, Test loss: 0.600, Test accuracy: 76.38
Round  33, Global train loss: 0.585, Global test loss: 1.615, Global test accuracy: 45.47
Round  34, Train loss: 0.579, Test loss: 0.613, Test accuracy: 75.98
Round  34, Global train loss: 0.579, Global test loss: 1.632, Global test accuracy: 42.37
Round  35, Train loss: 0.546, Test loss: 0.602, Test accuracy: 76.37
Round  35, Global train loss: 0.546, Global test loss: 1.464, Global test accuracy: 47.92
Round  36, Train loss: 0.572, Test loss: 0.590, Test accuracy: 76.87
Round  36, Global train loss: 0.572, Global test loss: 1.456, Global test accuracy: 46.62
Round  37, Train loss: 0.538, Test loss: 0.594, Test accuracy: 76.67
Round  37, Global train loss: 0.538, Global test loss: 1.369, Global test accuracy: 50.43
Round  38, Train loss: 0.490, Test loss: 0.579, Test accuracy: 77.20
Round  38, Global train loss: 0.490, Global test loss: 1.525, Global test accuracy: 46.37
Round  39, Train loss: 0.450, Test loss: 0.577, Test accuracy: 77.22
Round  39, Global train loss: 0.450, Global test loss: 1.781, Global test accuracy: 40.72
Round  40, Train loss: 0.554, Test loss: 0.568, Test accuracy: 77.70
Round  40, Global train loss: 0.554, Global test loss: 1.384, Global test accuracy: 51.62
Round  41, Train loss: 0.464, Test loss: 0.582, Test accuracy: 77.48
Round  41, Global train loss: 0.464, Global test loss: 1.419, Global test accuracy: 49.38
Round  42, Train loss: 0.506, Test loss: 0.576, Test accuracy: 77.77
Round  42, Global train loss: 0.506, Global test loss: 1.400, Global test accuracy: 49.78
Round  43, Train loss: 0.478, Test loss: 0.591, Test accuracy: 77.73
Round  43, Global train loss: 0.478, Global test loss: 1.619, Global test accuracy: 44.25
Round  44, Train loss: 0.511, Test loss: 0.565, Test accuracy: 78.72
Round  44, Global train loss: 0.511, Global test loss: 1.418, Global test accuracy: 51.22
Round  45, Train loss: 0.600, Test loss: 0.586, Test accuracy: 78.37
Round  45, Global train loss: 0.600, Global test loss: 1.482, Global test accuracy: 48.12
Round  46, Train loss: 0.438, Test loss: 0.576, Test accuracy: 78.03
Round  46, Global train loss: 0.438, Global test loss: 1.502, Global test accuracy: 47.90
Round  47, Train loss: 0.459, Test loss: 0.587, Test accuracy: 77.47
Round  47, Global train loss: 0.459, Global test loss: 1.542, Global test accuracy: 47.85
Round  48, Train loss: 0.485, Test loss: 0.605, Test accuracy: 76.90
Round  48, Global train loss: 0.485, Global test loss: 1.704, Global test accuracy: 46.30
Round  49, Train loss: 0.432, Test loss: 0.614, Test accuracy: 77.02
Round  49, Global train loss: 0.432, Global test loss: 1.498, Global test accuracy: 50.70
Round  50, Train loss: 0.460, Test loss: 0.596, Test accuracy: 77.48
Round  50, Global train loss: 0.460, Global test loss: 1.345, Global test accuracy: 54.13
Round  51, Train loss: 0.381, Test loss: 0.579, Test accuracy: 78.30
Round  51, Global train loss: 0.381, Global test loss: 1.406, Global test accuracy: 51.57
Round  52, Train loss: 0.340, Test loss: 0.589, Test accuracy: 77.93
Round  52, Global train loss: 0.340, Global test loss: 1.580, Global test accuracy: 49.12
Round  53, Train loss: 0.437, Test loss: 0.582, Test accuracy: 77.90
Round  53, Global train loss: 0.437, Global test loss: 1.314, Global test accuracy: 53.67
Round  54, Train loss: 0.411, Test loss: 0.559, Test accuracy: 79.25
Round  54, Global train loss: 0.411, Global test loss: 1.472, Global test accuracy: 50.05
Round  55, Train loss: 0.377, Test loss: 0.544, Test accuracy: 79.82
Round  55, Global train loss: 0.377, Global test loss: 1.323, Global test accuracy: 53.38
Round  56, Train loss: 0.470, Test loss: 0.544, Test accuracy: 79.72
Round  56, Global train loss: 0.470, Global test loss: 1.470, Global test accuracy: 48.55
Round  57, Train loss: 0.405, Test loss: 0.559, Test accuracy: 79.27
Round  57, Global train loss: 0.405, Global test loss: 1.482, Global test accuracy: 51.48
Round  58, Train loss: 0.371, Test loss: 0.550, Test accuracy: 79.70
Round  58, Global train loss: 0.371, Global test loss: 1.629, Global test accuracy: 48.38
Round  59, Train loss: 0.500, Test loss: 0.544, Test accuracy: 79.95
Round  59, Global train loss: 0.500, Global test loss: 1.463, Global test accuracy: 50.13
Round  60, Train loss: 0.397, Test loss: 0.547, Test accuracy: 80.00
Round  60, Global train loss: 0.397, Global test loss: 1.375, Global test accuracy: 52.50
Round  61, Train loss: 0.377, Test loss: 0.568, Test accuracy: 79.18
Round  61, Global train loss: 0.377, Global test loss: 1.673, Global test accuracy: 46.33
Round  62, Train loss: 0.425, Test loss: 0.563, Test accuracy: 78.78
Round  62, Global train loss: 0.425, Global test loss: 1.265, Global test accuracy: 55.15
Round  63, Train loss: 0.425, Test loss: 0.587, Test accuracy: 78.63
Round  63, Global train loss: 0.425, Global test loss: 1.422, Global test accuracy: 50.68
Round  64, Train loss: 0.424, Test loss: 0.598, Test accuracy: 78.22
Round  64, Global train loss: 0.424, Global test loss: 1.361, Global test accuracy: 53.02
Round  65, Train loss: 0.315, Test loss: 0.582, Test accuracy: 78.60
Round  65, Global train loss: 0.315, Global test loss: 1.392, Global test accuracy: 52.22
Round  66, Train loss: 0.331, Test loss: 0.612, Test accuracy: 78.03
Round  66, Global train loss: 0.331, Global test loss: 1.454, Global test accuracy: 50.67
Round  67, Train loss: 0.341, Test loss: 0.592, Test accuracy: 78.78
Round  67, Global train loss: 0.341, Global test loss: 1.477, Global test accuracy: 50.05
Round  68, Train loss: 0.419, Test loss: 0.600, Test accuracy: 78.67
Round  68, Global train loss: 0.419, Global test loss: 1.327, Global test accuracy: 53.58
Round  69, Train loss: 0.348, Test loss: 0.596, Test accuracy: 78.90
Round  69, Global train loss: 0.348, Global test loss: 1.511, Global test accuracy: 50.58
Round  70, Train loss: 0.413, Test loss: 0.586, Test accuracy: 79.32
Round  70, Global train loss: 0.413, Global test loss: 1.686, Global test accuracy: 46.45
Round  71, Train loss: 0.453, Test loss: 0.593, Test accuracy: 79.13
Round  71, Global train loss: 0.453, Global test loss: 1.540, Global test accuracy: 49.17
Round  72, Train loss: 0.364, Test loss: 0.577, Test accuracy: 79.53
Round  72, Global train loss: 0.364, Global test loss: 1.492, Global test accuracy: 50.75
Round  73, Train loss: 0.348, Test loss: 0.586, Test accuracy: 79.28
Round  73, Global train loss: 0.348, Global test loss: 1.384, Global test accuracy: 53.27
Round  74, Train loss: 0.396, Test loss: 0.567, Test accuracy: 79.90
Round  74, Global train loss: 0.396, Global test loss: 1.604, Global test accuracy: 48.77
Round  75, Train loss: 0.337, Test loss: 0.565, Test accuracy: 79.88
Round  75, Global train loss: 0.337, Global test loss: 1.296, Global test accuracy: 56.23
Round  76, Train loss: 0.333, Test loss: 0.564, Test accuracy: 79.97
Round  76, Global train loss: 0.333, Global test loss: 1.324, Global test accuracy: 55.72
Round  77, Train loss: 0.333, Test loss: 0.563, Test accuracy: 80.27
Round  77, Global train loss: 0.333, Global test loss: 1.470, Global test accuracy: 51.28
Round  78, Train loss: 0.349, Test loss: 0.581, Test accuracy: 79.67
Round  78, Global train loss: 0.349, Global test loss: 1.534, Global test accuracy: 50.15
Round  79, Train loss: 0.396, Test loss: 0.581, Test accuracy: 79.87
Round  79, Global train loss: 0.396, Global test loss: 1.420, Global test accuracy: 52.95
Round  80, Train loss: 0.301, Test loss: 0.571, Test accuracy: 80.18
Round  80, Global train loss: 0.301, Global test loss: 1.354, Global test accuracy: 54.18
Round  81, Train loss: 0.378, Test loss: 0.588, Test accuracy: 79.92
Round  81, Global train loss: 0.378, Global test loss: 1.493, Global test accuracy: 51.92
Round  82, Train loss: 0.334, Test loss: 0.559, Test accuracy: 80.55
Round  82, Global train loss: 0.334, Global test loss: 1.671, Global test accuracy: 48.60
Round  83, Train loss: 0.380, Test loss: 0.564, Test accuracy: 80.43
Round  83, Global train loss: 0.380, Global test loss: 1.509, Global test accuracy: 52.85
Round  84, Train loss: 0.286, Test loss: 0.565, Test accuracy: 79.97
Round  84, Global train loss: 0.286, Global test loss: 1.498, Global test accuracy: 51.98
Round  85, Train loss: 0.314, Test loss: 0.571, Test accuracy: 79.45
Round  85, Global train loss: 0.314, Global test loss: 1.429, Global test accuracy: 53.25
Round  86, Train loss: 0.294, Test loss: 0.567, Test accuracy: 79.97
Round  86, Global train loss: 0.294, Global test loss: 1.419, Global test accuracy: 56.15
Round  87, Train loss: 0.328, Test loss: 0.577, Test accuracy: 80.10
Round  87, Global train loss: 0.328, Global test loss: 1.311, Global test accuracy: 55.78
Round  88, Train loss: 0.282, Test loss: 0.585, Test accuracy: 80.28
Round  88, Global train loss: 0.282, Global test loss: 1.446, Global test accuracy: 55.28
Round  89, Train loss: 0.309, Test loss: 0.576, Test accuracy: 80.77
Round  89, Global train loss: 0.309, Global test loss: 1.394, Global test accuracy: 55.08
Round  90, Train loss: 0.363, Test loss: 0.587, Test accuracy: 80.27
Round  90, Global train loss: 0.363, Global test loss: 1.350, Global test accuracy: 55.55
Round  91, Train loss: 0.276, Test loss: 0.602, Test accuracy: 79.58
Round  91, Global train loss: 0.276, Global test loss: 2.197, Global test accuracy: 45.22
Round  92, Train loss: 0.319, Test loss: 0.589, Test accuracy: 79.65
Round  92, Global train loss: 0.319, Global test loss: 1.331, Global test accuracy: 56.78
Round  93, Train loss: 0.281, Test loss: 0.582, Test accuracy: 79.97
Round  93, Global train loss: 0.281, Global test loss: 1.552, Global test accuracy: 51.77
Round  94, Train loss: 0.320, Test loss: 0.580, Test accuracy: 79.82
Round  94, Global train loss: 0.320, Global test loss: 1.498, Global test accuracy: 52.53
Round  95, Train loss: 0.254, Test loss: 0.583, Test accuracy: 80.05
Round  95, Global train loss: 0.254, Global test loss: 1.380, Global test accuracy: 55.38
Round  96, Train loss: 0.272, Test loss: 0.573, Test accuracy: 80.27
Round  96, Global train loss: 0.272, Global test loss: 1.646, Global test accuracy: 50.30
Round  97, Train loss: 0.345, Test loss: 0.565, Test accuracy: 80.87
Round  97, Global train loss: 0.345, Global test loss: 1.472, Global test accuracy: 51.75
Round  98, Train loss: 0.267, Test loss: 0.578, Test accuracy: 80.60
Round  98, Global train loss: 0.267, Global test loss: 1.370, Global test accuracy: 55.45
Round  99, Train loss: 0.288, Test loss: 0.574, Test accuracy: 80.58
Round  99, Global train loss: 0.288, Global test loss: 1.364, Global test accuracy: 55.88
Final Round, Train loss: 0.231, Test loss: 0.658, Test accuracy: 79.85
Final Round, Global train loss: 0.231, Global test loss: 1.364, Global test accuracy: 55.88
Average accuracy final 10 rounds: 80.16500000000002 

Average global accuracy final 10 rounds: 53.06166666666666 

1141.8197996616364
[1.1062378883361816, 2.2124757766723633, 3.0438897609710693, 3.8753037452697754, 4.688038349151611, 5.500772953033447, 6.330375671386719, 7.15997838973999, 7.99771523475647, 8.83545207977295, 9.666642904281616, 10.497833728790283, 11.369728803634644, 12.241623878479004, 13.071816444396973, 13.902009010314941, 14.700122117996216, 15.49823522567749, 16.27967381477356, 17.06111240386963, 17.854283094406128, 18.647453784942627, 19.499647855758667, 20.351841926574707, 21.213039875030518, 22.074237823486328, 22.877046585083008, 23.679855346679688, 24.48704767227173, 25.29423999786377, 26.075838565826416, 26.857437133789062, 27.68673324584961, 28.516029357910156, 29.352315425872803, 30.18860149383545, 31.011120796203613, 31.833640098571777, 32.64660620689392, 33.459572315216064, 34.29427933692932, 35.12898635864258, 35.932981967926025, 36.73697757720947, 37.56745409965515, 38.39793062210083, 39.22054386138916, 40.04315710067749, 40.82038593292236, 41.597614765167236, 42.381388425827026, 43.165162086486816, 43.97877049446106, 44.7923789024353, 45.66731023788452, 46.54224157333374, 47.38746666908264, 48.23269176483154, 49.08126497268677, 49.92983818054199, 50.71475648880005, 51.499674797058105, 52.25996994972229, 53.020265102386475, 53.845396757125854, 54.670528411865234, 55.482075929641724, 56.29362344741821, 57.12455177307129, 57.955480098724365, 58.742894649505615, 59.530309200286865, 60.342612981796265, 61.154916763305664, 61.92998933792114, 62.70506191253662, 63.523536920547485, 64.34201192855835, 65.16081190109253, 65.97961187362671, 66.79471755027771, 67.60982322692871, 68.38227200508118, 69.15472078323364, 69.93647694587708, 70.71823310852051, 71.52732133865356, 72.33640956878662, 73.18667960166931, 74.036949634552, 74.88872861862183, 75.74050760269165, 76.52920293807983, 77.31789827346802, 78.08846068382263, 78.85902309417725, 79.63055896759033, 80.40209484100342, 81.2055606842041, 82.00902652740479, 82.8286714553833, 83.64831638336182, 84.46879053115845, 85.28926467895508, 86.11161065101624, 86.93395662307739, 87.7223379611969, 88.5107192993164, 89.27686595916748, 90.04301261901855, 90.85957503318787, 91.67613744735718, 92.46243739128113, 93.24873733520508, 94.01428079605103, 94.77982425689697, 95.56053972244263, 96.34125518798828, 97.17131018638611, 98.00136518478394, 98.81684827804565, 99.63233137130737, 100.45168733596802, 101.27104330062866, 102.11548900604248, 102.9599347114563, 103.72688293457031, 104.49383115768433, 105.27136325836182, 106.0488953590393, 106.83359241485596, 107.61828947067261, 108.4507417678833, 109.283194065094, 110.12554025650024, 110.9678864479065, 111.7575330734253, 112.54717969894409, 113.3607246875763, 114.1742696762085, 114.93713116645813, 115.69999265670776, 116.49903297424316, 117.29807329177856, 118.09204006195068, 118.8860068321228, 119.68327689170837, 120.48054695129395, 121.26840734481812, 122.05626773834229, 122.86620759963989, 123.6761474609375, 124.49222159385681, 125.30829572677612, 126.12563562393188, 126.94297552108765, 127.74708771705627, 128.5511999130249, 129.30150961875916, 130.0518193244934, 130.82795214653015, 131.6040849685669, 132.36306428909302, 133.12204360961914, 133.95147585868835, 134.78090810775757, 135.62634682655334, 136.47178554534912, 137.29146885871887, 138.11115217208862, 138.89824318885803, 139.68533420562744, 140.44411325454712, 141.2028923034668, 141.96708011627197, 142.73126792907715, 143.52024459838867, 144.3092212677002, 145.12386322021484, 145.9385051727295, 146.75465607643127, 147.57080698013306, 148.37303280830383, 149.1752586364746, 149.9774980545044, 150.77973747253418, 151.59268474578857, 152.40563201904297, 153.20732259750366, 154.00901317596436, 154.8527126312256, 155.69641208648682, 156.46376419067383, 157.23111629486084, 158.01082825660706, 158.79054021835327, 159.58528470993042, 160.38002920150757, 161.19842553138733, 162.0168218612671, 163.6513032913208, 165.2857847213745]
[27.383333333333333, 27.383333333333333, 39.36666666666667, 39.36666666666667, 45.7, 45.7, 52.05, 52.05, 54.516666666666666, 54.516666666666666, 59.56666666666667, 59.56666666666667, 61.93333333333333, 61.93333333333333, 63.63333333333333, 63.63333333333333, 68.11666666666666, 68.11666666666666, 68.5, 68.5, 68.88333333333334, 68.88333333333334, 69.0, 69.0, 67.85, 67.85, 69.45, 69.45, 70.43333333333334, 70.43333333333334, 72.36666666666666, 72.36666666666666, 72.71666666666667, 72.71666666666667, 72.1, 72.1, 72.75, 72.75, 72.45, 72.45, 73.53333333333333, 73.53333333333333, 73.96666666666667, 73.96666666666667, 73.5, 73.5, 73.91666666666667, 73.91666666666667, 74.33333333333333, 74.33333333333333, 75.61666666666666, 75.61666666666666, 75.75, 75.75, 75.53333333333333, 75.53333333333333, 76.11666666666666, 76.11666666666666, 75.88333333333334, 75.88333333333334, 76.08333333333333, 76.08333333333333, 76.08333333333333, 76.08333333333333, 76.5, 76.5, 76.38333333333334, 76.38333333333334, 75.98333333333333, 75.98333333333333, 76.36666666666666, 76.36666666666666, 76.86666666666666, 76.86666666666666, 76.66666666666667, 76.66666666666667, 77.2, 77.2, 77.21666666666667, 77.21666666666667, 77.7, 77.7, 77.48333333333333, 77.48333333333333, 77.76666666666667, 77.76666666666667, 77.73333333333333, 77.73333333333333, 78.71666666666667, 78.71666666666667, 78.36666666666666, 78.36666666666666, 78.03333333333333, 78.03333333333333, 77.46666666666667, 77.46666666666667, 76.9, 76.9, 77.01666666666667, 77.01666666666667, 77.48333333333333, 77.48333333333333, 78.3, 78.3, 77.93333333333334, 77.93333333333334, 77.9, 77.9, 79.25, 79.25, 79.81666666666666, 79.81666666666666, 79.71666666666667, 79.71666666666667, 79.26666666666667, 79.26666666666667, 79.7, 79.7, 79.95, 79.95, 80.0, 80.0, 79.18333333333334, 79.18333333333334, 78.78333333333333, 78.78333333333333, 78.63333333333334, 78.63333333333334, 78.21666666666667, 78.21666666666667, 78.6, 78.6, 78.03333333333333, 78.03333333333333, 78.78333333333333, 78.78333333333333, 78.66666666666667, 78.66666666666667, 78.9, 78.9, 79.31666666666666, 79.31666666666666, 79.13333333333334, 79.13333333333334, 79.53333333333333, 79.53333333333333, 79.28333333333333, 79.28333333333333, 79.9, 79.9, 79.88333333333334, 79.88333333333334, 79.96666666666667, 79.96666666666667, 80.26666666666667, 80.26666666666667, 79.66666666666667, 79.66666666666667, 79.86666666666666, 79.86666666666666, 80.18333333333334, 80.18333333333334, 79.91666666666667, 79.91666666666667, 80.55, 80.55, 80.43333333333334, 80.43333333333334, 79.96666666666667, 79.96666666666667, 79.45, 79.45, 79.96666666666667, 79.96666666666667, 80.1, 80.1, 80.28333333333333, 80.28333333333333, 80.76666666666667, 80.76666666666667, 80.26666666666667, 80.26666666666667, 79.58333333333333, 79.58333333333333, 79.65, 79.65, 79.96666666666667, 79.96666666666667, 79.81666666666666, 79.81666666666666, 80.05, 80.05, 80.26666666666667, 80.26666666666667, 80.86666666666666, 80.86666666666666, 80.6, 80.6, 80.58333333333333, 80.58333333333333, 79.85, 79.85]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.711, Test loss: 2.108, Test accuracy: 23.02
Round   1, Train loss: 1.141, Test loss: 1.798, Test accuracy: 33.88
Round   2, Train loss: 0.985, Test loss: 1.637, Test accuracy: 43.07
Round   3, Train loss: 0.974, Test loss: 1.245, Test accuracy: 49.10
Round   4, Train loss: 0.940, Test loss: 1.162, Test accuracy: 49.60
Round   5, Train loss: 0.803, Test loss: 1.091, Test accuracy: 56.85
Round   6, Train loss: 0.858, Test loss: 0.953, Test accuracy: 58.73
Round   7, Train loss: 0.782, Test loss: 0.866, Test accuracy: 62.22
Round   8, Train loss: 0.796, Test loss: 0.769, Test accuracy: 66.07
Round   9, Train loss: 0.849, Test loss: 0.738, Test accuracy: 68.25
Round  10, Train loss: 0.660, Test loss: 0.695, Test accuracy: 69.15
Round  11, Train loss: 0.742, Test loss: 0.682, Test accuracy: 70.23
Round  12, Train loss: 0.716, Test loss: 0.673, Test accuracy: 70.75
Round  13, Train loss: 0.672, Test loss: 0.667, Test accuracy: 71.02
Round  14, Train loss: 0.757, Test loss: 0.657, Test accuracy: 71.53
Round  15, Train loss: 0.677, Test loss: 0.648, Test accuracy: 72.78
Round  16, Train loss: 0.671, Test loss: 0.652, Test accuracy: 72.05
Round  17, Train loss: 0.654, Test loss: 0.631, Test accuracy: 72.82
Round  18, Train loss: 0.574, Test loss: 0.617, Test accuracy: 72.90
Round  19, Train loss: 0.681, Test loss: 0.615, Test accuracy: 73.47
Round  20, Train loss: 0.619, Test loss: 0.604, Test accuracy: 73.87
Round  21, Train loss: 0.592, Test loss: 0.602, Test accuracy: 73.73
Round  22, Train loss: 0.575, Test loss: 0.608, Test accuracy: 73.75
Round  23, Train loss: 0.698, Test loss: 0.595, Test accuracy: 74.08
Round  24, Train loss: 0.593, Test loss: 0.586, Test accuracy: 75.05
Round  25, Train loss: 0.585, Test loss: 0.582, Test accuracy: 75.38
Round  26, Train loss: 0.521, Test loss: 0.576, Test accuracy: 75.03
Round  27, Train loss: 0.534, Test loss: 0.572, Test accuracy: 75.38
Round  28, Train loss: 0.578, Test loss: 0.569, Test accuracy: 75.18
Round  29, Train loss: 0.616, Test loss: 0.559, Test accuracy: 75.83
Round  30, Train loss: 0.559, Test loss: 0.554, Test accuracy: 76.05
Round  31, Train loss: 0.562, Test loss: 0.555, Test accuracy: 76.27
Round  32, Train loss: 0.595, Test loss: 0.559, Test accuracy: 76.62
Round  33, Train loss: 0.597, Test loss: 0.567, Test accuracy: 76.02
Round  34, Train loss: 0.603, Test loss: 0.553, Test accuracy: 75.63
Round  35, Train loss: 0.508, Test loss: 0.533, Test accuracy: 77.30
Round  36, Train loss: 0.585, Test loss: 0.536, Test accuracy: 77.77
Round  37, Train loss: 0.566, Test loss: 0.524, Test accuracy: 77.53
Round  38, Train loss: 0.490, Test loss: 0.529, Test accuracy: 77.77
Round  39, Train loss: 0.430, Test loss: 0.521, Test accuracy: 78.12
Round  40, Train loss: 0.567, Test loss: 0.523, Test accuracy: 77.70
Round  41, Train loss: 0.481, Test loss: 0.515, Test accuracy: 77.73
Round  42, Train loss: 0.515, Test loss: 0.521, Test accuracy: 77.70
Round  43, Train loss: 0.508, Test loss: 0.516, Test accuracy: 77.70
Round  44, Train loss: 0.561, Test loss: 0.507, Test accuracy: 78.23
Round  45, Train loss: 0.601, Test loss: 0.507, Test accuracy: 78.80
Round  46, Train loss: 0.449, Test loss: 0.499, Test accuracy: 78.43
Round  47, Train loss: 0.475, Test loss: 0.495, Test accuracy: 78.98
Round  48, Train loss: 0.524, Test loss: 0.497, Test accuracy: 79.05
Round  49, Train loss: 0.460, Test loss: 0.496, Test accuracy: 79.02
Round  50, Train loss: 0.444, Test loss: 0.485, Test accuracy: 79.37
Round  51, Train loss: 0.359, Test loss: 0.481, Test accuracy: 79.77
Round  52, Train loss: 0.358, Test loss: 0.480, Test accuracy: 79.67
Round  53, Train loss: 0.420, Test loss: 0.476, Test accuracy: 79.53
Round  54, Train loss: 0.425, Test loss: 0.471, Test accuracy: 80.12
Round  55, Train loss: 0.352, Test loss: 0.471, Test accuracy: 79.82
Round  56, Train loss: 0.485, Test loss: 0.478, Test accuracy: 79.63
Round  57, Train loss: 0.420, Test loss: 0.475, Test accuracy: 79.90
Round  58, Train loss: 0.390, Test loss: 0.467, Test accuracy: 80.50
Round  59, Train loss: 0.485, Test loss: 0.456, Test accuracy: 81.15
Round  60, Train loss: 0.401, Test loss: 0.460, Test accuracy: 80.55
Round  61, Train loss: 0.380, Test loss: 0.457, Test accuracy: 80.88
Round  62, Train loss: 0.448, Test loss: 0.460, Test accuracy: 80.58
Round  63, Train loss: 0.457, Test loss: 0.465, Test accuracy: 80.73
Round  64, Train loss: 0.440, Test loss: 0.455, Test accuracy: 81.12
Round  65, Train loss: 0.313, Test loss: 0.444, Test accuracy: 81.67
Round  66, Train loss: 0.358, Test loss: 0.457, Test accuracy: 80.72
Round  67, Train loss: 0.346, Test loss: 0.448, Test accuracy: 81.48
Round  68, Train loss: 0.462, Test loss: 0.451, Test accuracy: 81.45
Round  69, Train loss: 0.364, Test loss: 0.445, Test accuracy: 81.72
Round  70, Train loss: 0.423, Test loss: 0.445, Test accuracy: 81.73
Round  71, Train loss: 0.506, Test loss: 0.453, Test accuracy: 81.03
Round  72, Train loss: 0.380, Test loss: 0.440, Test accuracy: 81.53
Round  73, Train loss: 0.388, Test loss: 0.435, Test accuracy: 82.32
Round  74, Train loss: 0.386, Test loss: 0.438, Test accuracy: 81.97
Round  75, Train loss: 0.366, Test loss: 0.440, Test accuracy: 81.78
Round  76, Train loss: 0.366, Test loss: 0.432, Test accuracy: 82.28
Round  77, Train loss: 0.334, Test loss: 0.437, Test accuracy: 82.12
Round  78, Train loss: 0.362, Test loss: 0.429, Test accuracy: 82.38
Round  79, Train loss: 0.420, Test loss: 0.434, Test accuracy: 82.13
Round  80, Train loss: 0.306, Test loss: 0.430, Test accuracy: 82.23
Round  81, Train loss: 0.425, Test loss: 0.426, Test accuracy: 82.12
Round  82, Train loss: 0.374, Test loss: 0.429, Test accuracy: 82.38
Round  83, Train loss: 0.453, Test loss: 0.435, Test accuracy: 82.22
Round  84, Train loss: 0.280, Test loss: 0.422, Test accuracy: 82.63
Round  85, Train loss: 0.342, Test loss: 0.429, Test accuracy: 82.67
Round  86, Train loss: 0.329, Test loss: 0.425, Test accuracy: 82.50
Round  87, Train loss: 0.366, Test loss: 0.438, Test accuracy: 82.25
Round  88, Train loss: 0.303, Test loss: 0.425, Test accuracy: 82.42
Round  89, Train loss: 0.342, Test loss: 0.425, Test accuracy: 82.75
Round  90, Train loss: 0.383, Test loss: 0.420, Test accuracy: 82.85
Round  91, Train loss: 0.291, Test loss: 0.424, Test accuracy: 82.47
Round  92, Train loss: 0.344, Test loss: 0.414, Test accuracy: 83.32
Round  93, Train loss: 0.298, Test loss: 0.423, Test accuracy: 83.17
Round  94, Train loss: 0.362, Test loss: 0.417, Test accuracy: 83.08
Round  95, Train loss: 0.290, Test loss: 0.414, Test accuracy: 83.43
Round  96, Train loss: 0.312, Test loss: 0.412, Test accuracy: 83.05
Round  97, Train loss: 0.392, Test loss: 0.420, Test accuracy: 82.93
Round  98, Train loss: 0.292, Test loss: 0.412, Test accuracy: 83.20
Round  99, Train loss: 0.324, Test loss: 0.413, Test accuracy: 83.00
Final Round, Train loss: 0.268, Test loss: 0.412, Test accuracy: 83.33
Average accuracy final 10 rounds: 83.05
793.9571394920349
[1.2810986042022705, 2.3060405254364014, 3.2643542289733887, 4.343905210494995, 5.2723708152771, 6.261961936950684, 7.217072248458862, 8.189226150512695, 9.19190764427185, 10.138809204101562, 11.12110161781311, 12.11596393585205, 12.994643449783325, 13.908096075057983, 14.837192296981812, 15.78343939781189, 16.84833860397339, 17.901970386505127, 18.928845643997192, 19.93428325653076, 20.823192834854126, 21.718036890029907, 22.62477946281433, 23.540167331695557, 24.48457145690918, 25.491424322128296, 26.558297157287598, 27.611462116241455, 28.58284091949463, 29.59375262260437, 30.53493070602417, 31.494561910629272, 32.43563199043274, 33.45188355445862, 34.42058253288269, 35.376402378082275, 36.28424620628357, 37.224501848220825, 38.199737310409546, 39.15456223487854, 40.20891737937927, 41.21271586418152, 42.235737800598145, 43.238381147384644, 44.147058963775635, 45.03826642036438, 45.9458646774292, 46.83339881896973, 47.87670302391052, 48.92325949668884, 49.952025413513184, 50.99319338798523, 51.887126445770264, 52.82783126831055, 53.77112007141113, 54.661693811416626, 55.644460678100586, 56.59546160697937, 57.5599091053009, 58.513535261154175, 59.44289588928223, 60.38172769546509, 61.352150440216064, 62.28842210769653, 63.34763956069946, 64.36610507965088, 65.32287240028381, 66.30640363693237, 67.19218587875366, 68.08666396141052, 68.96289110183716, 69.94227194786072, 70.95107412338257, 71.9779109954834, 73.00722670555115, 74.03596091270447, 74.96965599060059, 75.85197973251343, 76.73867678642273, 77.65239119529724, 78.6072633266449, 79.58734107017517, 80.56946897506714, 81.54420113563538, 82.51137638092041, 83.51625180244446, 84.48852634429932, 85.44916820526123, 86.45699167251587, 87.43725252151489, 88.41593670845032, 89.35574436187744, 90.24746894836426, 91.14128828048706, 92.0780713558197, 93.03540754318237, 94.10168790817261, 95.10122561454773, 96.12887763977051, 97.16409254074097, 98.62133550643921]
[23.016666666666666, 33.88333333333333, 43.06666666666667, 49.1, 49.6, 56.85, 58.733333333333334, 62.21666666666667, 66.06666666666666, 68.25, 69.15, 70.23333333333333, 70.75, 71.01666666666667, 71.53333333333333, 72.78333333333333, 72.05, 72.81666666666666, 72.9, 73.46666666666667, 73.86666666666666, 73.73333333333333, 73.75, 74.08333333333333, 75.05, 75.38333333333334, 75.03333333333333, 75.38333333333334, 75.18333333333334, 75.83333333333333, 76.05, 76.26666666666667, 76.61666666666666, 76.01666666666667, 75.63333333333334, 77.3, 77.76666666666667, 77.53333333333333, 77.76666666666667, 78.11666666666666, 77.7, 77.73333333333333, 77.7, 77.7, 78.23333333333333, 78.8, 78.43333333333334, 78.98333333333333, 79.05, 79.01666666666667, 79.36666666666666, 79.76666666666667, 79.66666666666667, 79.53333333333333, 80.11666666666666, 79.81666666666666, 79.63333333333334, 79.9, 80.5, 81.15, 80.55, 80.88333333333334, 80.58333333333333, 80.73333333333333, 81.11666666666666, 81.66666666666667, 80.71666666666667, 81.48333333333333, 81.45, 81.71666666666667, 81.73333333333333, 81.03333333333333, 81.53333333333333, 82.31666666666666, 81.96666666666667, 81.78333333333333, 82.28333333333333, 82.11666666666666, 82.38333333333334, 82.13333333333334, 82.23333333333333, 82.11666666666666, 82.38333333333334, 82.21666666666667, 82.63333333333334, 82.66666666666667, 82.5, 82.25, 82.41666666666667, 82.75, 82.85, 82.46666666666667, 83.31666666666666, 83.16666666666667, 83.08333333333333, 83.43333333333334, 83.05, 82.93333333333334, 83.2, 83.0, 83.33333333333333]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  17.2600
Round 1 global test acc  19.5100
Round 2 global test acc  18.1000
Round 3 global test acc  19.5200
Round 4 global test acc  21.7500
Round 5 global test acc  21.2000
Round 6 global test acc  18.9200
Round 7 global test acc  24.2600
Round 8 global test acc  21.1900
Round 9 global test acc  27.4000
Round 10 global test acc  24.0700
Round 11 global test acc  24.3200
Round 12 global test acc  21.3300
Round 13 global test acc  24.7800
Round 14 global test acc  26.3100
Round 15 global test acc  29.7700
Round 16 global test acc  24.9600
Round 17 global test acc  21.8800
Round 18 global test acc  17.2100
Round 19 global test acc  17.1300
Round 20 global test acc  21.5400
Round 21 global test acc  28.7700
Round 22 global test acc  31.8700
Round 23 global test acc  19.1000
Round 24 global test acc  26.1500
Round 25 global test acc  36.2800
Round 26 global test acc  26.8200
Round 27 global test acc  30.4600
Round 28 global test acc  27.8700
Round 29 global test acc  20.1800
Round 30 global test acc  27.5400
Round 31 global test acc  24.6400
Round 32 global test acc  25.2900
Round 33 global test acc  33.7800
Round 34 global test acc  31.0500
Round 35 global test acc  31.0400
Round 36 global test acc  30.2200
Round 37 global test acc  28.3500
Round 38 global test acc  34.4800
Round 39 global test acc  31.8900
Round 40 global test acc  29.0400
Round 41 global test acc  28.5400
Round 42 global test acc  31.0300
Round 43 global test acc  27.7000
Round 44 global test acc  30.5000
Round 45 global test acc  28.7600
Round 46 global test acc  34.7000
Round 47 global test acc  21.7500
Round 48 global test acc  29.6500
Round 49 global test acc  25.2900
Round 50 global test acc  29.1500
Round 51 global test acc  27.7000
Round 52 global test acc  27.1500
Round 53 global test acc  28.2900
Round 54 global test acc  36.1800
Round 55 global test acc  33.5600
Round 56 global test acc  38.0300
Round 57 global test acc  33.5400
Round 58 global test acc  37.3800
Round 59 global test acc  29.0900
Round 60 global test acc  32.6000
Round 61 global test acc  27.2900
Round 62 global test acc  35.9500
Round 63 global test acc  29.9700
Round 64 global test acc  41.4100
Round 65 global test acc  27.5300
Round 66 global test acc  38.7600
Round 67 global test acc  23.2300
Round 68 global test acc  33.8900
Round 69 global test acc  29.7600
Round 70 global test acc  37.4500
Round 71 global test acc  32.9600
Round 72 global test acc  38.4400
Round 73 global test acc  31.8000
Round 74 global test acc  35.5700
Round 75 global test acc  30.1900
Round 76 global test acc  36.9400
Round 77 global test acc  25.6100
Round 78 global test acc  35.4600
Round 79 global test acc  32.7200
Round 80 global test acc  29.7700
Round 81 global test acc  27.2800
Round 82 global test acc  23.8500
Round 83 global test acc  22.3600
Round 84 global test acc  21.5000
Round 85 global test acc  20.6100
Round 86 global test acc  19.9400
Round 87 global test acc  17.6200
Round 88 global test acc  16.8600
Round 89 global test acc  16.0100
Round 90 global test acc  15.7600
Round 91 global test acc  14.4700
Round 92 global test acc  14.7600
Round 93 global test acc  15.0000
Round 94 global test acc  14.4700
Round 95 global test acc  14.6200
Round 96 global test acc  14.7300
Round 97 global test acc  14.3400
Round 98 global test acc  14.8200
Round 99 global test acc  14.9400
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 15, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.726, Test loss: 2.087, Test accuracy: 26.65
Round   1, Train loss: 1.178, Test loss: 1.725, Test accuracy: 37.30
Round   2, Train loss: 0.976, Test loss: 1.632, Test accuracy: 44.53
Round   3, Train loss: 0.987, Test loss: 1.237, Test accuracy: 51.62
Round   4, Train loss: 1.030, Test loss: 1.138, Test accuracy: 51.22
Round   5, Train loss: 0.834, Test loss: 1.050, Test accuracy: 58.03
Round   6, Train loss: 0.918, Test loss: 0.919, Test accuracy: 61.65
Round   7, Train loss: 0.811, Test loss: 0.865, Test accuracy: 63.90
Round   8, Train loss: 0.866, Test loss: 0.780, Test accuracy: 66.87
Round   9, Train loss: 0.947, Test loss: 0.761, Test accuracy: 68.00
Round  10, Train loss: 0.696, Test loss: 0.721, Test accuracy: 69.32
Round  11, Train loss: 0.778, Test loss: 0.712, Test accuracy: 69.93
Round  12, Train loss: 0.766, Test loss: 0.716, Test accuracy: 69.90
Round  13, Train loss: 0.711, Test loss: 0.680, Test accuracy: 71.30
Round  14, Train loss: 0.812, Test loss: 0.677, Test accuracy: 71.75
Round  15, Train loss: 0.741, Test loss: 0.654, Test accuracy: 72.75
Round  16, Train loss: 0.678, Test loss: 0.637, Test accuracy: 72.80
Round  17, Train loss: 0.713, Test loss: 0.641, Test accuracy: 73.02
Round  18, Train loss: 0.602, Test loss: 0.635, Test accuracy: 72.68
Round  19, Train loss: 0.692, Test loss: 0.631, Test accuracy: 73.68
Round  20, Train loss: 0.618, Test loss: 0.611, Test accuracy: 74.42
Round  21, Train loss: 0.614, Test loss: 0.610, Test accuracy: 74.22
Round  22, Train loss: 0.571, Test loss: 0.605, Test accuracy: 74.58
Round  23, Train loss: 0.787, Test loss: 0.594, Test accuracy: 75.02
Round  24, Train loss: 0.651, Test loss: 0.592, Test accuracy: 74.92
Round  25, Train loss: 0.643, Test loss: 0.597, Test accuracy: 75.42
Round  26, Train loss: 0.577, Test loss: 0.584, Test accuracy: 75.28
Round  27, Train loss: 0.566, Test loss: 0.587, Test accuracy: 75.10
Round  28, Train loss: 0.604, Test loss: 0.569, Test accuracy: 75.68
Round  29, Train loss: 0.654, Test loss: 0.566, Test accuracy: 76.20
Round  30, Train loss: 0.589, Test loss: 0.561, Test accuracy: 76.40
Round  31, Train loss: 0.598, Test loss: 0.553, Test accuracy: 76.77
Round  32, Train loss: 0.651, Test loss: 0.554, Test accuracy: 77.47
Round  33, Train loss: 0.625, Test loss: 0.561, Test accuracy: 77.73
Round  34, Train loss: 0.600, Test loss: 0.541, Test accuracy: 77.92
Round  35, Train loss: 0.535, Test loss: 0.530, Test accuracy: 77.73
Round  36, Train loss: 0.620, Test loss: 0.527, Test accuracy: 77.85
Round  37, Train loss: 0.593, Test loss: 0.533, Test accuracy: 78.13
Round  38, Train loss: 0.515, Test loss: 0.529, Test accuracy: 78.27
Round  39, Train loss: 0.466, Test loss: 0.525, Test accuracy: 78.80
Round  40, Train loss: 0.613, Test loss: 0.514, Test accuracy: 79.20
Round  41, Train loss: 0.571, Test loss: 0.513, Test accuracy: 79.17
Round  42, Train loss: 0.534, Test loss: 0.509, Test accuracy: 79.60
Round  43, Train loss: 0.539, Test loss: 0.512, Test accuracy: 79.65
Round  44, Train loss: 0.588, Test loss: 0.507, Test accuracy: 79.75
Round  45, Train loss: 0.694, Test loss: 0.504, Test accuracy: 78.92
Round  46, Train loss: 0.483, Test loss: 0.496, Test accuracy: 79.68
Round  47, Train loss: 0.496, Test loss: 0.493, Test accuracy: 79.92
Round  48, Train loss: 0.546, Test loss: 0.488, Test accuracy: 80.13
Round  49, Train loss: 0.496, Test loss: 0.496, Test accuracy: 79.43
Round  50, Train loss: 0.477, Test loss: 0.481, Test accuracy: 80.57
Round  51, Train loss: 0.354, Test loss: 0.480, Test accuracy: 80.35
Round  52, Train loss: 0.404, Test loss: 0.482, Test accuracy: 80.65
Round  53, Train loss: 0.415, Test loss: 0.473, Test accuracy: 80.45
Round  54, Train loss: 0.469, Test loss: 0.483, Test accuracy: 80.30
Round  55, Train loss: 0.381, Test loss: 0.470, Test accuracy: 80.78
Round  56, Train loss: 0.508, Test loss: 0.476, Test accuracy: 80.50
Round  57, Train loss: 0.466, Test loss: 0.482, Test accuracy: 81.15
Round  58, Train loss: 0.422, Test loss: 0.466, Test accuracy: 81.43
Round  59, Train loss: 0.533, Test loss: 0.465, Test accuracy: 81.53
Round  60, Train loss: 0.431, Test loss: 0.467, Test accuracy: 81.55
Round  61, Train loss: 0.377, Test loss: 0.470, Test accuracy: 81.40
Round  62, Train loss: 0.498, Test loss: 0.463, Test accuracy: 81.62
Round  63, Train loss: 0.466, Test loss: 0.462, Test accuracy: 81.72
Round  64, Train loss: 0.485, Test loss: 0.465, Test accuracy: 81.35
Round  65, Train loss: 0.374, Test loss: 0.454, Test accuracy: 81.62
Round  66, Train loss: 0.403, Test loss: 0.452, Test accuracy: 81.37
Round  67, Train loss: 0.340, Test loss: 0.450, Test accuracy: 81.90
Round  68, Train loss: 0.460, Test loss: 0.445, Test accuracy: 82.22
Round  69, Train loss: 0.378, Test loss: 0.441, Test accuracy: 82.30
Round  70, Train loss: 0.450, Test loss: 0.446, Test accuracy: 82.08
Round  71, Train loss: 0.524, Test loss: 0.455, Test accuracy: 82.07
Round  72, Train loss: 0.434, Test loss: 0.447, Test accuracy: 82.18
Round  73, Train loss: 0.426, Test loss: 0.447, Test accuracy: 81.77
Round  74, Train loss: 0.438, Test loss: 0.435, Test accuracy: 82.35
Round  75, Train loss: 0.371, Test loss: 0.438, Test accuracy: 82.52
Round  76, Train loss: 0.420, Test loss: 0.445, Test accuracy: 82.55
Round  77, Train loss: 0.330, Test loss: 0.440, Test accuracy: 82.27
Round  78, Train loss: 0.382, Test loss: 0.435, Test accuracy: 82.12
Round  79, Train loss: 0.492, Test loss: 0.435, Test accuracy: 82.35
Round  80, Train loss: 0.383, Test loss: 0.436, Test accuracy: 82.37
Round  81, Train loss: 0.477, Test loss: 0.436, Test accuracy: 82.98
Round  82, Train loss: 0.421, Test loss: 0.447, Test accuracy: 81.87
Round  83, Train loss: 0.508, Test loss: 0.450, Test accuracy: 82.08
Round  84, Train loss: 0.297, Test loss: 0.433, Test accuracy: 82.85
Round  85, Train loss: 0.368, Test loss: 0.434, Test accuracy: 82.40
Round  86, Train loss: 0.382, Test loss: 0.443, Test accuracy: 82.63
Round  87, Train loss: 0.418, Test loss: 0.439, Test accuracy: 82.58
Round  88, Train loss: 0.297, Test loss: 0.433, Test accuracy: 82.82
Round  89, Train loss: 0.366, Test loss: 0.435, Test accuracy: 82.85
Round  90, Train loss: 0.463, Test loss: 0.436, Test accuracy: 82.88
Round  91, Train loss: 0.302, Test loss: 0.435, Test accuracy: 82.37
Round  92, Train loss: 0.359, Test loss: 0.436, Test accuracy: 82.50
Round  93, Train loss: 0.291, Test loss: 0.437, Test accuracy: 82.42
Round  94, Train loss: 0.357, Test loss: 0.429, Test accuracy: 82.97
Round  95, Train loss: 0.291, Test loss: 0.425, Test accuracy: 83.03
Round  96, Train loss: 0.369, Test loss: 0.433, Test accuracy: 82.63
Round  97, Train loss: 0.443, Test loss: 0.440, Test accuracy: 82.75
Round  98, Train loss: 0.336, Test loss: 0.429, Test accuracy: 83.10
Round  99, Train loss: 0.388, Test loss: 0.432, Test accuracy: 83.15
Final Round, Train loss: 0.296, Test loss: 0.423, Test accuracy: 83.48
Average accuracy final 10 rounds: 82.78
823.2506740093231
[1.3522417545318604, 2.280714273452759, 3.2373111248016357, 4.190037965774536, 5.1372389793396, 6.127061128616333, 7.117085218429565, 8.100948572158813, 9.023765802383423, 9.908724069595337, 10.8218355178833, 11.857012033462524, 12.873747110366821, 13.920358419418335, 15.035671472549438, 16.200534105300903, 17.30201554298401, 18.24471426010132, 19.113096475601196, 20.015591859817505, 20.942246437072754, 21.883974075317383, 22.871790647506714, 23.829904079437256, 24.867889404296875, 25.80496120452881, 26.726061582565308, 27.728157997131348, 28.69807767868042, 29.660640239715576, 30.638702154159546, 31.540995836257935, 32.520055294036865, 33.41681146621704, 34.39377450942993, 35.382224559783936, 36.30105924606323, 37.33830904960632, 38.34904170036316, 39.38136076927185, 40.36559700965881, 41.228049755096436, 42.12686228752136, 43.01622033119202, 43.88950490951538, 44.85570502281189, 45.89996266365051, 46.9353289604187, 47.953985929489136, 48.90094542503357, 49.859983682632446, 50.83383822441101, 51.789825677871704, 52.9029483795166, 53.9424262046814, 54.90643763542175, 55.91242551803589, 56.91176509857178, 57.9943585395813, 59.05608940124512, 60.08691120147705, 61.14632964134216, 62.18051838874817, 63.24010920524597, 64.29733729362488, 65.28183484077454, 66.24618291854858, 67.20775938034058, 68.15506434440613, 69.18495059013367, 70.33088779449463, 71.47399997711182, 72.65358114242554, 73.65545535087585, 74.59292197227478, 75.5486969947815, 76.49502992630005, 77.52717089653015, 78.59360265731812, 79.59112882614136, 80.6230697631836, 81.62653064727783, 82.69667553901672, 83.75560760498047, 84.74808287620544, 85.79127907752991, 86.8074643611908, 87.84844589233398, 88.94984316825867, 89.9760057926178, 90.95136141777039, 91.89419174194336, 92.909250497818, 93.94492149353027, 95.04968929290771, 96.14969897270203, 97.30609774589539, 98.33393979072571, 99.26000785827637, 100.18928813934326, 101.73377728462219]
[26.65, 37.3, 44.53333333333333, 51.61666666666667, 51.21666666666667, 58.03333333333333, 61.65, 63.9, 66.86666666666666, 68.0, 69.31666666666666, 69.93333333333334, 69.9, 71.3, 71.75, 72.75, 72.8, 73.01666666666667, 72.68333333333334, 73.68333333333334, 74.41666666666667, 74.21666666666667, 74.58333333333333, 75.01666666666667, 74.91666666666667, 75.41666666666667, 75.28333333333333, 75.1, 75.68333333333334, 76.2, 76.4, 76.76666666666667, 77.46666666666667, 77.73333333333333, 77.91666666666667, 77.73333333333333, 77.85, 78.13333333333334, 78.26666666666667, 78.8, 79.2, 79.16666666666667, 79.6, 79.65, 79.75, 78.91666666666667, 79.68333333333334, 79.91666666666667, 80.13333333333334, 79.43333333333334, 80.56666666666666, 80.35, 80.65, 80.45, 80.3, 80.78333333333333, 80.5, 81.15, 81.43333333333334, 81.53333333333333, 81.55, 81.4, 81.61666666666666, 81.71666666666667, 81.35, 81.61666666666666, 81.36666666666666, 81.9, 82.21666666666667, 82.3, 82.08333333333333, 82.06666666666666, 82.18333333333334, 81.76666666666667, 82.35, 82.51666666666667, 82.55, 82.26666666666667, 82.11666666666666, 82.35, 82.36666666666666, 82.98333333333333, 81.86666666666666, 82.08333333333333, 82.85, 82.4, 82.63333333333334, 82.58333333333333, 82.81666666666666, 82.85, 82.88333333333334, 82.36666666666666, 82.5, 82.41666666666667, 82.96666666666667, 83.03333333333333, 82.63333333333334, 82.75, 83.1, 83.15, 83.48333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.691, Test loss: 2.093, Test accuracy: 22.50
Round   1, Train loss: 1.124, Test loss: 1.713, Test accuracy: 37.57
Round   2, Train loss: 0.973, Test loss: 1.608, Test accuracy: 43.85
Round   3, Train loss: 0.954, Test loss: 1.230, Test accuracy: 49.55
Round   4, Train loss: 0.927, Test loss: 1.126, Test accuracy: 52.38
Round   5, Train loss: 0.821, Test loss: 1.059, Test accuracy: 56.65
Round   6, Train loss: 0.845, Test loss: 0.925, Test accuracy: 61.03
Round   7, Train loss: 0.772, Test loss: 0.866, Test accuracy: 61.42
Round   8, Train loss: 0.790, Test loss: 0.761, Test accuracy: 65.92
Round   9, Train loss: 0.846, Test loss: 0.744, Test accuracy: 67.85
Round  10, Train loss: 0.700, Test loss: 0.701, Test accuracy: 69.98
Round  11, Train loss: 0.763, Test loss: 0.683, Test accuracy: 70.75
Round  12, Train loss: 0.703, Test loss: 0.682, Test accuracy: 70.55
Round  13, Train loss: 0.648, Test loss: 0.660, Test accuracy: 71.77
Round  14, Train loss: 0.778, Test loss: 0.646, Test accuracy: 73.10
Round  15, Train loss: 0.667, Test loss: 0.638, Test accuracy: 73.15
Round  16, Train loss: 0.666, Test loss: 0.633, Test accuracy: 72.33
Round  17, Train loss: 0.651, Test loss: 0.635, Test accuracy: 72.72
Round  18, Train loss: 0.564, Test loss: 0.613, Test accuracy: 73.50
Round  19, Train loss: 0.656, Test loss: 0.604, Test accuracy: 74.37
Round  20, Train loss: 0.643, Test loss: 0.606, Test accuracy: 73.98
Round  21, Train loss: 0.586, Test loss: 0.604, Test accuracy: 74.68
Round  22, Train loss: 0.567, Test loss: 0.601, Test accuracy: 74.80
Round  23, Train loss: 0.681, Test loss: 0.582, Test accuracy: 76.10
Round  24, Train loss: 0.588, Test loss: 0.577, Test accuracy: 75.75
Round  25, Train loss: 0.575, Test loss: 0.573, Test accuracy: 75.90
Round  26, Train loss: 0.515, Test loss: 0.572, Test accuracy: 75.45
Round  27, Train loss: 0.525, Test loss: 0.580, Test accuracy: 74.68
Round  28, Train loss: 0.563, Test loss: 0.557, Test accuracy: 76.43
Round  29, Train loss: 0.622, Test loss: 0.559, Test accuracy: 76.72
Round  30, Train loss: 0.582, Test loss: 0.550, Test accuracy: 77.60
Round  31, Train loss: 0.560, Test loss: 0.540, Test accuracy: 77.15
Round  32, Train loss: 0.576, Test loss: 0.537, Test accuracy: 78.02
Round  33, Train loss: 0.568, Test loss: 0.526, Test accuracy: 78.60
Round  34, Train loss: 0.567, Test loss: 0.521, Test accuracy: 78.50
Round  35, Train loss: 0.516, Test loss: 0.522, Test accuracy: 79.03
Round  36, Train loss: 0.570, Test loss: 0.520, Test accuracy: 78.53
Round  37, Train loss: 0.534, Test loss: 0.514, Test accuracy: 79.07
Round  38, Train loss: 0.490, Test loss: 0.516, Test accuracy: 79.25
Round  39, Train loss: 0.457, Test loss: 0.508, Test accuracy: 79.67
Round  40, Train loss: 0.581, Test loss: 0.506, Test accuracy: 79.90
Round  41, Train loss: 0.470, Test loss: 0.495, Test accuracy: 79.70
Round  42, Train loss: 0.496, Test loss: 0.493, Test accuracy: 79.97
Round  43, Train loss: 0.471, Test loss: 0.490, Test accuracy: 80.37
Round  44, Train loss: 0.523, Test loss: 0.486, Test accuracy: 80.18
Round  45, Train loss: 0.614, Test loss: 0.492, Test accuracy: 80.17
Round  46, Train loss: 0.441, Test loss: 0.484, Test accuracy: 80.38
Round  47, Train loss: 0.458, Test loss: 0.486, Test accuracy: 80.05
Round  48, Train loss: 0.491, Test loss: 0.480, Test accuracy: 80.73
Round  49, Train loss: 0.440, Test loss: 0.479, Test accuracy: 80.57
Round  50, Train loss: 0.442, Test loss: 0.461, Test accuracy: 81.52
Round  51, Train loss: 0.378, Test loss: 0.461, Test accuracy: 81.17
Round  52, Train loss: 0.343, Test loss: 0.467, Test accuracy: 80.50
Round  53, Train loss: 0.417, Test loss: 0.459, Test accuracy: 81.03
Round  54, Train loss: 0.402, Test loss: 0.459, Test accuracy: 81.20
Round  55, Train loss: 0.369, Test loss: 0.456, Test accuracy: 81.37
Round  56, Train loss: 0.487, Test loss: 0.460, Test accuracy: 81.55
Round  57, Train loss: 0.438, Test loss: 0.459, Test accuracy: 81.42
Round  58, Train loss: 0.381, Test loss: 0.454, Test accuracy: 81.38
Round  59, Train loss: 0.506, Test loss: 0.449, Test accuracy: 81.25
Round  60, Train loss: 0.383, Test loss: 0.454, Test accuracy: 81.00
Round  61, Train loss: 0.375, Test loss: 0.454, Test accuracy: 81.55
Round  62, Train loss: 0.430, Test loss: 0.453, Test accuracy: 81.70
Round  63, Train loss: 0.464, Test loss: 0.453, Test accuracy: 81.70
Round  64, Train loss: 0.425, Test loss: 0.453, Test accuracy: 81.62
Round  65, Train loss: 0.311, Test loss: 0.448, Test accuracy: 82.13
Round  66, Train loss: 0.339, Test loss: 0.442, Test accuracy: 82.12
Round  67, Train loss: 0.354, Test loss: 0.436, Test accuracy: 82.42
Round  68, Train loss: 0.424, Test loss: 0.438, Test accuracy: 82.32
Round  69, Train loss: 0.338, Test loss: 0.437, Test accuracy: 82.50
Round  70, Train loss: 0.435, Test loss: 0.449, Test accuracy: 81.57
Round  71, Train loss: 0.471, Test loss: 0.440, Test accuracy: 82.42
Round  72, Train loss: 0.401, Test loss: 0.432, Test accuracy: 82.82
Round  73, Train loss: 0.351, Test loss: 0.437, Test accuracy: 82.45
Round  74, Train loss: 0.406, Test loss: 0.428, Test accuracy: 82.78
Round  75, Train loss: 0.358, Test loss: 0.434, Test accuracy: 82.63
Round  76, Train loss: 0.335, Test loss: 0.445, Test accuracy: 82.17
Round  77, Train loss: 0.339, Test loss: 0.432, Test accuracy: 82.65
Round  78, Train loss: 0.375, Test loss: 0.438, Test accuracy: 82.43
Round  79, Train loss: 0.413, Test loss: 0.426, Test accuracy: 83.05
Round  80, Train loss: 0.321, Test loss: 0.422, Test accuracy: 83.30
Round  81, Train loss: 0.423, Test loss: 0.441, Test accuracy: 82.22
Round  82, Train loss: 0.374, Test loss: 0.442, Test accuracy: 82.22
Round  83, Train loss: 0.430, Test loss: 0.431, Test accuracy: 82.67
Round  84, Train loss: 0.285, Test loss: 0.427, Test accuracy: 82.92
Round  85, Train loss: 0.336, Test loss: 0.422, Test accuracy: 83.13
Round  86, Train loss: 0.319, Test loss: 0.425, Test accuracy: 82.82
Round  87, Train loss: 0.357, Test loss: 0.419, Test accuracy: 83.08
Round  88, Train loss: 0.297, Test loss: 0.427, Test accuracy: 83.23
Round  89, Train loss: 0.338, Test loss: 0.421, Test accuracy: 83.12
Round  90, Train loss: 0.375, Test loss: 0.415, Test accuracy: 83.60
Round  91, Train loss: 0.300, Test loss: 0.425, Test accuracy: 83.13
Round  92, Train loss: 0.331, Test loss: 0.418, Test accuracy: 83.58
Round  93, Train loss: 0.307, Test loss: 0.417, Test accuracy: 83.63
Round  94, Train loss: 0.320, Test loss: 0.416, Test accuracy: 83.72
Round  95, Train loss: 0.273, Test loss: 0.419, Test accuracy: 83.45
Round  96, Train loss: 0.274, Test loss: 0.423, Test accuracy: 83.42
Round  97, Train loss: 0.390, Test loss: 0.423, Test accuracy: 83.67
Round  98, Train loss: 0.295, Test loss: 0.416, Test accuracy: 83.83
Round  99, Train loss: 0.317, Test loss: 0.426, Test accuracy: 83.38
Final Round, Train loss: 0.267, Test loss: 0.415, Test accuracy: 83.83
Average accuracy final 10 rounds: 83.54166666666666
1799.220417022705
[1.3301749229431152, 2.425650119781494, 3.542869806289673, 4.634127616882324, 5.624484300613403, 6.64044713973999, 7.740710735321045, 8.801612377166748, 9.868510723114014, 10.790194988250732, 11.809527158737183, 12.912975311279297, 13.940782070159912, 15.036770105361938, 16.156152486801147, 17.21540331840515, 18.270697593688965, 19.203938961029053, 20.170942306518555, 21.16009545326233, 22.16905903816223, 25.68589496612549, 29.0771586894989, 32.44409203529358, 35.66083574295044, 39.172972440719604, 42.17909574508667, 45.91341495513916, 49.114153146743774, 52.00084137916565, 54.929657220840454, 58.43693685531616, 62.13945150375366, 64.79841899871826, 68.12764525413513, 71.24683713912964, 74.51052951812744, 78.05366063117981, 81.24054336547852, 84.13717460632324, 87.55736565589905, 91.32457637786865, 94.64559054374695, 97.67770981788635, 101.06006932258606, 104.0753538608551, 107.55910754203796, 110.58129262924194, 113.95668125152588, 116.66841316223145, 120.18115091323853, 123.78971028327942, 126.52018666267395, 129.78537487983704, 133.00767588615417, 136.29953932762146, 139.79719257354736, 143.2218255996704, 146.5518012046814, 149.57298827171326, 153.3112177848816, 156.76190400123596, 159.71834707260132, 162.83215141296387, 166.21011519432068, 169.7107002735138, 172.46666073799133, 175.84461212158203, 179.233966588974, 182.4822280406952, 186.29248642921448, 189.41227316856384, 192.2391712665558, 195.32609844207764, 199.0647406578064, 202.21828627586365, 205.38323163986206, 208.8248109817505, 211.8902096748352, 215.43183088302612, 218.59640669822693, 221.65271139144897, 224.53990006446838, 228.170836687088, 231.94070649147034, 234.73142409324646, 238.00481176376343, 241.3848044872284, 244.56339955329895, 247.87542390823364, 250.8220500946045, 253.87180948257446, 256.7828664779663, 260.34678173065186, 263.96936440467834, 266.69902896881104, 270.0079040527344, 273.27643275260925, 276.51375246047974, 279.43292689323425, 281.0061089992523]
[22.5, 37.56666666666667, 43.85, 49.55, 52.38333333333333, 56.65, 61.03333333333333, 61.416666666666664, 65.91666666666667, 67.85, 69.98333333333333, 70.75, 70.55, 71.76666666666667, 73.1, 73.15, 72.33333333333333, 72.71666666666667, 73.5, 74.36666666666666, 73.98333333333333, 74.68333333333334, 74.8, 76.1, 75.75, 75.9, 75.45, 74.68333333333334, 76.43333333333334, 76.71666666666667, 77.6, 77.15, 78.01666666666667, 78.6, 78.5, 79.03333333333333, 78.53333333333333, 79.06666666666666, 79.25, 79.66666666666667, 79.9, 79.7, 79.96666666666667, 80.36666666666666, 80.18333333333334, 80.16666666666667, 80.38333333333334, 80.05, 80.73333333333333, 80.56666666666666, 81.51666666666667, 81.16666666666667, 80.5, 81.03333333333333, 81.2, 81.36666666666666, 81.55, 81.41666666666667, 81.38333333333334, 81.25, 81.0, 81.55, 81.7, 81.7, 81.61666666666666, 82.13333333333334, 82.11666666666666, 82.41666666666667, 82.31666666666666, 82.5, 81.56666666666666, 82.41666666666667, 82.81666666666666, 82.45, 82.78333333333333, 82.63333333333334, 82.16666666666667, 82.65, 82.43333333333334, 83.05, 83.3, 82.21666666666667, 82.21666666666667, 82.66666666666667, 82.91666666666667, 83.13333333333334, 82.81666666666666, 83.08333333333333, 83.23333333333333, 83.11666666666666, 83.6, 83.13333333333334, 83.58333333333333, 83.63333333333334, 83.71666666666667, 83.45, 83.41666666666667, 83.66666666666667, 83.83333333333333, 83.38333333333334, 83.83333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.235, Test loss: 1.951, Test accuracy: 25.00
Round   0, Global train loss: 1.235, Global test loss: 2.249, Global test accuracy: 19.60
Round   1, Train loss: 1.054, Test loss: 1.592, Test accuracy: 36.45
Round   1, Global train loss: 1.054, Global test loss: 2.193, Global test accuracy: 23.80
Round   2, Train loss: 1.085, Test loss: 1.500, Test accuracy: 37.30
Round   2, Global train loss: 1.085, Global test loss: 2.329, Global test accuracy: 10.92
Round   3, Train loss: 0.927, Test loss: 1.202, Test accuracy: 47.32
Round   3, Global train loss: 0.927, Global test loss: 2.180, Global test accuracy: 21.43
Round   4, Train loss: 0.871, Test loss: 1.043, Test accuracy: 52.15
Round   4, Global train loss: 0.871, Global test loss: 2.132, Global test accuracy: 23.43
Round   5, Train loss: 0.980, Test loss: 1.054, Test accuracy: 53.73
Round   5, Global train loss: 0.980, Global test loss: 2.554, Global test accuracy: 13.33
Round   6, Train loss: 0.846, Test loss: 0.969, Test accuracy: 55.65
Round   6, Global train loss: 0.846, Global test loss: 2.170, Global test accuracy: 15.43
Round   7, Train loss: 0.845, Test loss: 0.946, Test accuracy: 60.10
Round   7, Global train loss: 0.845, Global test loss: 2.124, Global test accuracy: 26.57
Round   8, Train loss: 0.808, Test loss: 0.920, Test accuracy: 61.45
Round   8, Global train loss: 0.808, Global test loss: 2.094, Global test accuracy: 30.25
Round   9, Train loss: 0.878, Test loss: 0.958, Test accuracy: 57.38
Round   9, Global train loss: 0.878, Global test loss: 2.129, Global test accuracy: 17.58
Round  10, Train loss: 0.956, Test loss: 0.905, Test accuracy: 60.62
Round  10, Global train loss: 0.956, Global test loss: 2.302, Global test accuracy: 18.13
Round  11, Train loss: 0.858, Test loss: 0.819, Test accuracy: 63.80
Round  11, Global train loss: 0.858, Global test loss: 2.130, Global test accuracy: 27.08
Round  12, Train loss: 0.722, Test loss: 0.800, Test accuracy: 64.60
Round  12, Global train loss: 0.722, Global test loss: 2.278, Global test accuracy: 24.92
Round  13, Train loss: 0.727, Test loss: 0.786, Test accuracy: 65.38
Round  13, Global train loss: 0.727, Global test loss: 2.056, Global test accuracy: 28.53
Round  14, Train loss: 0.752, Test loss: 0.779, Test accuracy: 65.62
Round  14, Global train loss: 0.752, Global test loss: 2.086, Global test accuracy: 20.78
Round  15, Train loss: 0.789, Test loss: 0.793, Test accuracy: 64.77
Round  15, Global train loss: 0.789, Global test loss: 2.221, Global test accuracy: 21.30
Round  16, Train loss: 0.815, Test loss: 0.798, Test accuracy: 64.82
Round  16, Global train loss: 0.815, Global test loss: 2.165, Global test accuracy: 26.35
Round  17, Train loss: 0.871, Test loss: 0.783, Test accuracy: 64.45
Round  17, Global train loss: 0.871, Global test loss: 2.129, Global test accuracy: 21.77
Round  18, Train loss: 0.781, Test loss: 0.766, Test accuracy: 66.30
Round  18, Global train loss: 0.781, Global test loss: 2.104, Global test accuracy: 22.10
Round  19, Train loss: 0.705, Test loss: 0.775, Test accuracy: 65.75
Round  19, Global train loss: 0.705, Global test loss: 2.139, Global test accuracy: 19.45
Round  20, Train loss: 0.642, Test loss: 0.763, Test accuracy: 66.18
Round  20, Global train loss: 0.642, Global test loss: 2.106, Global test accuracy: 23.55
Round  21, Train loss: 0.704, Test loss: 0.764, Test accuracy: 66.08
Round  21, Global train loss: 0.704, Global test loss: 2.351, Global test accuracy: 21.93
Round  22, Train loss: 0.776, Test loss: 0.796, Test accuracy: 65.87
Round  22, Global train loss: 0.776, Global test loss: 2.158, Global test accuracy: 18.57
Round  23, Train loss: 0.767, Test loss: 0.749, Test accuracy: 67.32
Round  23, Global train loss: 0.767, Global test loss: 2.072, Global test accuracy: 24.63
Round  24, Train loss: 0.623, Test loss: 0.752, Test accuracy: 67.02
Round  24, Global train loss: 0.623, Global test loss: 2.375, Global test accuracy: 15.48
Round  25, Train loss: 0.548, Test loss: 0.756, Test accuracy: 66.82
Round  25, Global train loss: 0.548, Global test loss: 2.089, Global test accuracy: 20.22
Round  26, Train loss: 0.749, Test loss: 0.754, Test accuracy: 66.78
Round  26, Global train loss: 0.749, Global test loss: 2.178, Global test accuracy: 22.63
Round  27, Train loss: 0.775, Test loss: 0.746, Test accuracy: 68.45
Round  27, Global train loss: 0.775, Global test loss: 2.054, Global test accuracy: 24.78
Round  28, Train loss: 0.763, Test loss: 0.762, Test accuracy: 68.22
Round  28, Global train loss: 0.763, Global test loss: 2.186, Global test accuracy: 23.03
Round  29, Train loss: 0.697, Test loss: 0.763, Test accuracy: 68.15
Round  29, Global train loss: 0.697, Global test loss: 2.042, Global test accuracy: 25.05
Round  30, Train loss: 0.570, Test loss: 0.745, Test accuracy: 68.70
Round  30, Global train loss: 0.570, Global test loss: 2.169, Global test accuracy: 22.05
Round  31, Train loss: 0.584, Test loss: 0.760, Test accuracy: 68.02
Round  31, Global train loss: 0.584, Global test loss: 2.002, Global test accuracy: 27.40
Round  32, Train loss: 0.594, Test loss: 0.762, Test accuracy: 67.78
Round  32, Global train loss: 0.594, Global test loss: 2.205, Global test accuracy: 26.38
Round  33, Train loss: 0.517, Test loss: 0.776, Test accuracy: 67.65
Round  33, Global train loss: 0.517, Global test loss: 2.111, Global test accuracy: 28.23
Round  34, Train loss: 0.547, Test loss: 0.769, Test accuracy: 68.10
Round  34, Global train loss: 0.547, Global test loss: 2.139, Global test accuracy: 22.02
Round  35, Train loss: 0.581, Test loss: 0.760, Test accuracy: 68.67
Round  35, Global train loss: 0.581, Global test loss: 2.097, Global test accuracy: 24.47
Round  36, Train loss: 0.618, Test loss: 0.763, Test accuracy: 67.98
Round  36, Global train loss: 0.618, Global test loss: 2.168, Global test accuracy: 26.88
Round  37, Train loss: 0.597, Test loss: 0.779, Test accuracy: 67.85
Round  37, Global train loss: 0.597, Global test loss: 2.059, Global test accuracy: 24.32
Round  38, Train loss: 0.575, Test loss: 0.783, Test accuracy: 68.13
Round  38, Global train loss: 0.575, Global test loss: 2.296, Global test accuracy: 13.43
Round  39, Train loss: 0.529, Test loss: 0.799, Test accuracy: 67.15
Round  39, Global train loss: 0.529, Global test loss: 2.098, Global test accuracy: 24.60
Round  40, Train loss: 0.438, Test loss: 0.818, Test accuracy: 67.82
Round  40, Global train loss: 0.438, Global test loss: 2.155, Global test accuracy: 16.30
Round  41, Train loss: 0.467, Test loss: 0.821, Test accuracy: 67.88
Round  41, Global train loss: 0.467, Global test loss: 2.244, Global test accuracy: 25.75
Round  42, Train loss: 0.607, Test loss: 0.825, Test accuracy: 67.90
Round  42, Global train loss: 0.607, Global test loss: 2.313, Global test accuracy: 24.33
Round  43, Train loss: 0.411, Test loss: 0.836, Test accuracy: 67.40
Round  43, Global train loss: 0.411, Global test loss: 1.990, Global test accuracy: 29.65
Round  44, Train loss: 0.491, Test loss: 0.834, Test accuracy: 67.08
Round  44, Global train loss: 0.491, Global test loss: 2.044, Global test accuracy: 30.90
Round  45, Train loss: 0.263, Test loss: 0.814, Test accuracy: 67.57
Round  45, Global train loss: 0.263, Global test loss: 2.118, Global test accuracy: 26.83
Round  46, Train loss: 0.607, Test loss: 0.822, Test accuracy: 68.33
Round  46, Global train loss: 0.607, Global test loss: 2.173, Global test accuracy: 16.18
Round  47, Train loss: 0.444, Test loss: 0.829, Test accuracy: 68.07
Round  47, Global train loss: 0.444, Global test loss: 2.071, Global test accuracy: 28.47
Round  48, Train loss: 0.378, Test loss: 0.835, Test accuracy: 68.20
Round  48, Global train loss: 0.378, Global test loss: 2.006, Global test accuracy: 32.45
Round  49, Train loss: 0.442, Test loss: 0.830, Test accuracy: 68.77
Round  49, Global train loss: 0.442, Global test loss: 2.292, Global test accuracy: 19.47
Round  50, Train loss: 0.480, Test loss: 0.848, Test accuracy: 68.95
Round  50, Global train loss: 0.480, Global test loss: 2.105, Global test accuracy: 26.32
Round  51, Train loss: 0.300, Test loss: 0.841, Test accuracy: 69.20
Round  51, Global train loss: 0.300, Global test loss: 2.232, Global test accuracy: 17.40
Round  52, Train loss: 0.410, Test loss: 0.831, Test accuracy: 69.62
Round  52, Global train loss: 0.410, Global test loss: 2.162, Global test accuracy: 29.53
Round  53, Train loss: 0.360, Test loss: 0.842, Test accuracy: 69.47
Round  53, Global train loss: 0.360, Global test loss: 2.126, Global test accuracy: 17.27
Round  54, Train loss: 0.379, Test loss: 0.834, Test accuracy: 69.78
Round  54, Global train loss: 0.379, Global test loss: 2.061, Global test accuracy: 27.47
Round  55, Train loss: 0.364, Test loss: 0.856, Test accuracy: 69.82
Round  55, Global train loss: 0.364, Global test loss: 2.060, Global test accuracy: 23.85
Round  56, Train loss: 0.544, Test loss: 0.880, Test accuracy: 69.70
Round  56, Global train loss: 0.544, Global test loss: 2.066, Global test accuracy: 29.53
Round  57, Train loss: 0.339, Test loss: 0.894, Test accuracy: 69.25
Round  57, Global train loss: 0.339, Global test loss: 2.114, Global test accuracy: 19.32
Round  58, Train loss: 0.504, Test loss: 0.894, Test accuracy: 69.43
Round  58, Global train loss: 0.504, Global test loss: 2.059, Global test accuracy: 27.75
Round  59, Train loss: 0.365, Test loss: 0.933, Test accuracy: 68.83
Round  59, Global train loss: 0.365, Global test loss: 1.986, Global test accuracy: 35.80
Round  60, Train loss: 0.452, Test loss: 0.922, Test accuracy: 69.30
Round  60, Global train loss: 0.452, Global test loss: 2.096, Global test accuracy: 29.80
Round  61, Train loss: 0.470, Test loss: 0.913, Test accuracy: 69.73
Round  61, Global train loss: 0.470, Global test loss: 2.278, Global test accuracy: 13.55
Round  62, Train loss: 0.285, Test loss: 0.969, Test accuracy: 69.17
Round  62, Global train loss: 0.285, Global test loss: 2.081, Global test accuracy: 19.48
Round  63, Train loss: 0.393, Test loss: 0.976, Test accuracy: 68.70
Round  63, Global train loss: 0.393, Global test loss: 2.093, Global test accuracy: 25.55
Round  64, Train loss: 0.255, Test loss: 0.955, Test accuracy: 68.83
Round  64, Global train loss: 0.255, Global test loss: 2.164, Global test accuracy: 29.25
Round  65, Train loss: 0.148, Test loss: 0.981, Test accuracy: 68.78
Round  65, Global train loss: 0.148, Global test loss: 1.958, Global test accuracy: 28.40
Round  66, Train loss: 0.216, Test loss: 1.008, Test accuracy: 68.55
Round  66, Global train loss: 0.216, Global test loss: 2.073, Global test accuracy: 22.90
Round  67, Train loss: 0.436, Test loss: 1.008, Test accuracy: 68.13
Round  67, Global train loss: 0.436, Global test loss: 2.085, Global test accuracy: 33.12
Round  68, Train loss: 0.408, Test loss: 1.032, Test accuracy: 68.12
Round  68, Global train loss: 0.408, Global test loss: 2.061, Global test accuracy: 25.93
Round  69, Train loss: 0.262, Test loss: 1.052, Test accuracy: 68.47
Round  69, Global train loss: 0.262, Global test loss: 2.029, Global test accuracy: 29.77
Round  70, Train loss: 0.494, Test loss: 1.040, Test accuracy: 67.87
Round  70, Global train loss: 0.494, Global test loss: 2.170, Global test accuracy: 14.60
Round  71, Train loss: 0.221, Test loss: 1.062, Test accuracy: 67.73
Round  71, Global train loss: 0.221, Global test loss: 2.133, Global test accuracy: 16.70
Round  72, Train loss: 0.219, Test loss: 1.102, Test accuracy: 67.43
Round  72, Global train loss: 0.219, Global test loss: 2.155, Global test accuracy: 25.37
Round  73, Train loss: 0.365, Test loss: 1.105, Test accuracy: 67.90
Round  73, Global train loss: 0.365, Global test loss: 2.056, Global test accuracy: 27.93
Round  74, Train loss: 0.149, Test loss: 1.146, Test accuracy: 67.22
Round  74, Global train loss: 0.149, Global test loss: 2.032, Global test accuracy: 22.90
Round  75, Train loss: 0.148, Test loss: 1.165, Test accuracy: 67.48
Round  75, Global train loss: 0.148, Global test loss: 2.063, Global test accuracy: 19.80
Round  76, Train loss: 0.321, Test loss: 1.180, Test accuracy: 67.30
Round  76, Global train loss: 0.321, Global test loss: 2.162, Global test accuracy: 23.75
Round  77, Train loss: 0.353, Test loss: 1.161, Test accuracy: 67.80
Round  77, Global train loss: 0.353, Global test loss: 2.125, Global test accuracy: 27.18
Round  78, Train loss: 0.232, Test loss: 1.184, Test accuracy: 67.77
Round  78, Global train loss: 0.232, Global test loss: 1.997, Global test accuracy: 29.93
Round  79, Train loss: 0.200, Test loss: 1.185, Test accuracy: 68.05
Round  79, Global train loss: 0.200, Global test loss: 2.124, Global test accuracy: 25.22
Round  80, Train loss: 0.271, Test loss: 1.202, Test accuracy: 67.88
Round  80, Global train loss: 0.271, Global test loss: 2.090, Global test accuracy: 22.15
Round  81, Train loss: 0.270, Test loss: 1.186, Test accuracy: 68.00
Round  81, Global train loss: 0.270, Global test loss: 2.125, Global test accuracy: 26.63
Round  82, Train loss: 0.187, Test loss: 1.178, Test accuracy: 67.77
Round  82, Global train loss: 0.187, Global test loss: 2.221, Global test accuracy: 29.08
Round  83, Train loss: 0.181, Test loss: 1.205, Test accuracy: 67.45
Round  83, Global train loss: 0.181, Global test loss: 1.975, Global test accuracy: 26.42
Round  84, Train loss: 0.256, Test loss: 1.218, Test accuracy: 67.35
Round  84, Global train loss: 0.256, Global test loss: 2.015, Global test accuracy: 30.40
Round  85, Train loss: 0.160, Test loss: 1.231, Test accuracy: 67.80
Round  85, Global train loss: 0.160, Global test loss: 1.986, Global test accuracy: 30.30
Round  86, Train loss: 0.183, Test loss: 1.243, Test accuracy: 67.78
Round  86, Global train loss: 0.183, Global test loss: 2.132, Global test accuracy: 26.98
Round  87, Train loss: 0.188, Test loss: 1.272, Test accuracy: 67.68
Round  87, Global train loss: 0.188, Global test loss: 2.008, Global test accuracy: 26.52
Round  88, Train loss: 0.161, Test loss: 1.286, Test accuracy: 67.25
Round  88, Global train loss: 0.161, Global test loss: 2.075, Global test accuracy: 27.15
Round  89, Train loss: 0.157, Test loss: 1.280, Test accuracy: 67.45
Round  89, Global train loss: 0.157, Global test loss: 2.016, Global test accuracy: 25.47
Round  90, Train loss: 0.168, Test loss: 1.312, Test accuracy: 66.93
Round  90, Global train loss: 0.168, Global test loss: 2.228, Global test accuracy: 18.02
Round  91, Train loss: 0.163, Test loss: 1.302, Test accuracy: 67.05
Round  91, Global train loss: 0.163, Global test loss: 2.077, Global test accuracy: 29.53
Round  92, Train loss: 0.183, Test loss: 1.318, Test accuracy: 67.08
Round  92, Global train loss: 0.183, Global test loss: 1.963, Global test accuracy: 28.72
Round  93, Train loss: 0.172, Test loss: 1.303, Test accuracy: 67.52
Round  93, Global train loss: 0.172, Global test loss: 2.181, Global test accuracy: 25.57
Round  94, Train loss: 0.113, Test loss: 1.370, Test accuracy: 66.97
Round  94, Global train loss: 0.113, Global test loss: 2.047, Global test accuracy: 28.38
Round  95, Train loss: 0.169, Test loss: 1.378, Test accuracy: 66.68
Round  95, Global train loss: 0.169, Global test loss: 2.100, Global test accuracy: 19.73
Round  96, Train loss: 0.142, Test loss: 1.382, Test accuracy: 67.05
Round  96, Global train loss: 0.142, Global test loss: 2.093, Global test accuracy: 24.10
Round  97, Train loss: 0.167, Test loss: 1.401, Test accuracy: 67.00
Round  97, Global train loss: 0.167, Global test loss: 2.094, Global test accuracy: 25.10
Round  98, Train loss: 0.074, Test loss: 1.401, Test accuracy: 67.40
Round  98, Global train loss: 0.074, Global test loss: 2.008, Global test accuracy: 26.67
Round  99, Train loss: 0.065, Test loss: 1.410, Test accuracy: 67.45
Round  99, Global train loss: 0.065, Global test loss: 2.065, Global test accuracy: 26.55
Final Round, Train loss: 0.155, Test loss: 1.442, Test accuracy: 67.17
Final Round, Global train loss: 0.155, Global test loss: 2.065, Global test accuracy: 26.55
Average accuracy final 10 rounds: 67.11333333333334 

Average global accuracy final 10 rounds: 25.23666666666667 

1169.9557683467865
[1.103952407836914, 2.207904815673828, 2.9751739501953125, 3.742443084716797, 4.523601770401001, 5.304760456085205, 6.0805983543396, 6.856436252593994, 7.60840630531311, 8.360376358032227, 9.106752395629883, 9.853128433227539, 10.628010272979736, 11.402892112731934, 12.183685541152954, 12.964478969573975, 13.782017946243286, 14.599556922912598, 15.427357912063599, 16.2551589012146, 17.0668203830719, 17.8784818649292, 18.652520656585693, 19.426559448242188, 20.148961544036865, 20.871363639831543, 21.681203603744507, 22.49104356765747, 23.260255575180054, 24.029467582702637, 24.811633348464966, 25.593799114227295, 26.353230714797974, 27.112662315368652, 27.87724781036377, 28.641833305358887, 29.46308445930481, 30.284335613250732, 31.106202602386475, 31.928069591522217, 32.73150396347046, 33.5349383354187, 34.289204597473145, 35.04347085952759, 35.813042640686035, 36.58261442184448, 37.36375546455383, 38.144896507263184, 38.85539531707764, 39.56589412689209, 40.36670517921448, 41.167516231536865, 41.99404311180115, 42.82056999206543, 43.645137548446655, 44.46970510482788, 45.257742166519165, 46.04577922821045, 46.77270841598511, 47.499637603759766, 48.24842715263367, 48.99721670150757, 49.789037227630615, 50.58085775375366, 51.353241205215454, 52.125624656677246, 52.94639539718628, 53.76716613769531, 54.53818893432617, 55.30921173095703, 56.12584066390991, 56.94246959686279, 57.723479986190796, 58.5044903755188, 59.24053692817688, 59.97658348083496, 60.74408173561096, 61.51157999038696, 62.25348997116089, 62.995399951934814, 63.75222611427307, 64.50905227661133, 65.25361752510071, 65.99818277359009, 66.82662534713745, 67.65506792068481, 68.48058938980103, 69.30611085891724, 70.12080931663513, 70.93550777435303, 71.65435981750488, 72.37321186065674, 73.12357234954834, 73.87393283843994, 74.61295342445374, 75.35197401046753, 76.1404218673706, 76.92886972427368, 77.71447372436523, 78.50007772445679, 79.30422067642212, 80.10836362838745, 80.89783811569214, 81.68731260299683, 82.498783826828, 83.31025505065918, 84.06184959411621, 84.81344413757324, 85.5935411453247, 86.37363815307617, 87.15201592445374, 87.9303936958313, 88.70381021499634, 89.47722673416138, 90.23096680641174, 90.98470687866211, 91.75139474868774, 92.51808261871338, 93.29187321662903, 94.06566381454468, 94.86469554901123, 95.66372728347778, 96.44426798820496, 97.22480869293213, 97.94214391708374, 98.65947914123535, 99.38141083717346, 100.10334253311157, 100.84559559822083, 101.58784866333008, 102.38251543045044, 103.1771821975708, 103.96326684951782, 104.74935150146484, 105.57028579711914, 106.39122009277344, 107.21002888679504, 108.02883768081665, 108.83334803581238, 109.6378583908081, 110.3611204624176, 111.0843825340271, 111.86324310302734, 112.64210367202759, 113.42416644096375, 114.2062292098999, 114.98941779136658, 115.77260637283325, 116.53284287452698, 117.2930793762207, 118.08635950088501, 118.87963962554932, 119.65330457687378, 120.42696952819824, 121.26252245903015, 122.09807538986206, 122.86642789840698, 123.6347804069519, 124.40671706199646, 125.17865371704102, 125.91520166397095, 126.65174961090088, 127.4157464504242, 128.1797432899475, 128.91734385490417, 129.65494441986084, 130.46718311309814, 131.27942180633545, 132.10887384414673, 132.938325881958, 133.71528577804565, 134.4922456741333, 135.27197337150574, 136.05170106887817, 136.77358722686768, 137.49547338485718, 138.25820136070251, 139.02092933654785, 139.8055934906006, 140.59025764465332, 141.3879635334015, 142.18566942214966, 142.9604811668396, 143.73529291152954, 144.55482506752014, 145.37435722351074, 146.15629124641418, 146.93822526931763, 147.72000432014465, 148.50178337097168, 149.26626777648926, 150.03075218200684, 150.80366110801697, 151.5765700340271, 152.32918572425842, 153.08180141448975, 153.84738898277283, 154.6129765510559, 155.37909984588623, 156.14522314071655, 157.75810503959656, 159.37098693847656]
[25.0, 25.0, 36.45, 36.45, 37.3, 37.3, 47.31666666666667, 47.31666666666667, 52.15, 52.15, 53.733333333333334, 53.733333333333334, 55.65, 55.65, 60.1, 60.1, 61.45, 61.45, 57.38333333333333, 57.38333333333333, 60.61666666666667, 60.61666666666667, 63.8, 63.8, 64.6, 64.6, 65.38333333333334, 65.38333333333334, 65.61666666666666, 65.61666666666666, 64.76666666666667, 64.76666666666667, 64.81666666666666, 64.81666666666666, 64.45, 64.45, 66.3, 66.3, 65.75, 65.75, 66.18333333333334, 66.18333333333334, 66.08333333333333, 66.08333333333333, 65.86666666666666, 65.86666666666666, 67.31666666666666, 67.31666666666666, 67.01666666666667, 67.01666666666667, 66.81666666666666, 66.81666666666666, 66.78333333333333, 66.78333333333333, 68.45, 68.45, 68.21666666666667, 68.21666666666667, 68.15, 68.15, 68.7, 68.7, 68.01666666666667, 68.01666666666667, 67.78333333333333, 67.78333333333333, 67.65, 67.65, 68.1, 68.1, 68.66666666666667, 68.66666666666667, 67.98333333333333, 67.98333333333333, 67.85, 67.85, 68.13333333333334, 68.13333333333334, 67.15, 67.15, 67.81666666666666, 67.81666666666666, 67.88333333333334, 67.88333333333334, 67.9, 67.9, 67.4, 67.4, 67.08333333333333, 67.08333333333333, 67.56666666666666, 67.56666666666666, 68.33333333333333, 68.33333333333333, 68.06666666666666, 68.06666666666666, 68.2, 68.2, 68.76666666666667, 68.76666666666667, 68.95, 68.95, 69.2, 69.2, 69.61666666666666, 69.61666666666666, 69.46666666666667, 69.46666666666667, 69.78333333333333, 69.78333333333333, 69.81666666666666, 69.81666666666666, 69.7, 69.7, 69.25, 69.25, 69.43333333333334, 69.43333333333334, 68.83333333333333, 68.83333333333333, 69.3, 69.3, 69.73333333333333, 69.73333333333333, 69.16666666666667, 69.16666666666667, 68.7, 68.7, 68.83333333333333, 68.83333333333333, 68.78333333333333, 68.78333333333333, 68.55, 68.55, 68.13333333333334, 68.13333333333334, 68.11666666666666, 68.11666666666666, 68.46666666666667, 68.46666666666667, 67.86666666666666, 67.86666666666666, 67.73333333333333, 67.73333333333333, 67.43333333333334, 67.43333333333334, 67.9, 67.9, 67.21666666666667, 67.21666666666667, 67.48333333333333, 67.48333333333333, 67.3, 67.3, 67.8, 67.8, 67.76666666666667, 67.76666666666667, 68.05, 68.05, 67.88333333333334, 67.88333333333334, 68.0, 68.0, 67.76666666666667, 67.76666666666667, 67.45, 67.45, 67.35, 67.35, 67.8, 67.8, 67.78333333333333, 67.78333333333333, 67.68333333333334, 67.68333333333334, 67.25, 67.25, 67.45, 67.45, 66.93333333333334, 66.93333333333334, 67.05, 67.05, 67.08333333333333, 67.08333333333333, 67.51666666666667, 67.51666666666667, 66.96666666666667, 66.96666666666667, 66.68333333333334, 66.68333333333334, 67.05, 67.05, 67.0, 67.0, 67.4, 67.4, 67.45, 67.45, 67.16666666666667, 67.16666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.256, Test loss: 1.935, Test accuracy: 24.85
Round   0, Global train loss: 1.256, Global test loss: 2.265, Global test accuracy: 15.07
Round   1, Train loss: 1.109, Test loss: 1.514, Test accuracy: 40.57
Round   1, Global train loss: 1.109, Global test loss: 2.101, Global test accuracy: 24.27
Round   2, Train loss: 0.992, Test loss: 1.468, Test accuracy: 41.45
Round   2, Global train loss: 0.992, Global test loss: 2.235, Global test accuracy: 18.28
Round   3, Train loss: 0.989, Test loss: 1.166, Test accuracy: 51.47
Round   3, Global train loss: 0.989, Global test loss: 2.068, Global test accuracy: 24.17
Round   4, Train loss: 0.795, Test loss: 0.966, Test accuracy: 58.15
Round   4, Global train loss: 0.795, Global test loss: 2.056, Global test accuracy: 32.15
Round   5, Train loss: 0.914, Test loss: 0.959, Test accuracy: 58.23
Round   5, Global train loss: 0.914, Global test loss: 2.278, Global test accuracy: 14.83
Round   6, Train loss: 0.856, Test loss: 0.892, Test accuracy: 60.87
Round   6, Global train loss: 0.856, Global test loss: 1.820, Global test accuracy: 32.88
Round   7, Train loss: 0.790, Test loss: 0.863, Test accuracy: 63.60
Round   7, Global train loss: 0.790, Global test loss: 1.838, Global test accuracy: 39.83
Round   8, Train loss: 0.752, Test loss: 0.815, Test accuracy: 65.28
Round   8, Global train loss: 0.752, Global test loss: 1.795, Global test accuracy: 42.32
Round   9, Train loss: 0.793, Test loss: 0.832, Test accuracy: 64.48
Round   9, Global train loss: 0.793, Global test loss: 1.752, Global test accuracy: 42.03
Round  10, Train loss: 0.764, Test loss: 0.770, Test accuracy: 66.90
Round  10, Global train loss: 0.764, Global test loss: 1.724, Global test accuracy: 39.73
Round  11, Train loss: 0.837, Test loss: 0.708, Test accuracy: 69.70
Round  11, Global train loss: 0.837, Global test loss: 1.724, Global test accuracy: 39.57
Round  12, Train loss: 0.734, Test loss: 0.690, Test accuracy: 70.65
Round  12, Global train loss: 0.734, Global test loss: 1.875, Global test accuracy: 37.92
Round  13, Train loss: 0.719, Test loss: 0.677, Test accuracy: 70.98
Round  13, Global train loss: 0.719, Global test loss: 1.629, Global test accuracy: 43.92
Round  14, Train loss: 0.700, Test loss: 0.661, Test accuracy: 71.95
Round  14, Global train loss: 0.700, Global test loss: 1.570, Global test accuracy: 45.20
Round  15, Train loss: 0.757, Test loss: 0.654, Test accuracy: 72.10
Round  15, Global train loss: 0.757, Global test loss: 1.685, Global test accuracy: 43.17
Round  16, Train loss: 0.654, Test loss: 0.668, Test accuracy: 71.95
Round  16, Global train loss: 0.654, Global test loss: 1.709, Global test accuracy: 43.90
Round  17, Train loss: 0.786, Test loss: 0.675, Test accuracy: 72.33
Round  17, Global train loss: 0.786, Global test loss: 1.538, Global test accuracy: 47.95
Round  18, Train loss: 0.645, Test loss: 0.666, Test accuracy: 72.72
Round  18, Global train loss: 0.645, Global test loss: 1.655, Global test accuracy: 44.85
Round  19, Train loss: 0.699, Test loss: 0.652, Test accuracy: 73.33
Round  19, Global train loss: 0.699, Global test loss: 1.736, Global test accuracy: 44.35
Round  20, Train loss: 0.716, Test loss: 0.646, Test accuracy: 73.85
Round  20, Global train loss: 0.716, Global test loss: 1.425, Global test accuracy: 50.47
Round  21, Train loss: 0.629, Test loss: 0.645, Test accuracy: 73.93
Round  21, Global train loss: 0.629, Global test loss: 1.734, Global test accuracy: 41.40
Round  22, Train loss: 0.667, Test loss: 0.630, Test accuracy: 74.25
Round  22, Global train loss: 0.667, Global test loss: 1.454, Global test accuracy: 50.27
Round  23, Train loss: 0.612, Test loss: 0.641, Test accuracy: 73.88
Round  23, Global train loss: 0.612, Global test loss: 1.436, Global test accuracy: 50.73
Round  24, Train loss: 0.615, Test loss: 0.624, Test accuracy: 74.90
Round  24, Global train loss: 0.615, Global test loss: 1.587, Global test accuracy: 47.67
Round  25, Train loss: 0.598, Test loss: 0.616, Test accuracy: 75.87
Round  25, Global train loss: 0.598, Global test loss: 1.528, Global test accuracy: 45.13
Round  26, Train loss: 0.642, Test loss: 0.622, Test accuracy: 75.82
Round  26, Global train loss: 0.642, Global test loss: 1.586, Global test accuracy: 46.83
Round  27, Train loss: 0.664, Test loss: 0.617, Test accuracy: 76.40
Round  27, Global train loss: 0.664, Global test loss: 1.338, Global test accuracy: 53.03
Round  28, Train loss: 0.622, Test loss: 0.612, Test accuracy: 76.58
Round  28, Global train loss: 0.622, Global test loss: 1.529, Global test accuracy: 45.72
Round  29, Train loss: 0.603, Test loss: 0.617, Test accuracy: 76.58
Round  29, Global train loss: 0.603, Global test loss: 1.418, Global test accuracy: 51.07
Round  30, Train loss: 0.556, Test loss: 0.638, Test accuracy: 76.50
Round  30, Global train loss: 0.556, Global test loss: 1.555, Global test accuracy: 46.75
Round  31, Train loss: 0.585, Test loss: 0.620, Test accuracy: 76.90
Round  31, Global train loss: 0.585, Global test loss: 1.312, Global test accuracy: 54.13
Round  32, Train loss: 0.582, Test loss: 0.585, Test accuracy: 77.08
Round  32, Global train loss: 0.582, Global test loss: 1.545, Global test accuracy: 48.87
Round  33, Train loss: 0.473, Test loss: 0.573, Test accuracy: 77.63
Round  33, Global train loss: 0.473, Global test loss: 1.730, Global test accuracy: 49.28
Round  34, Train loss: 0.595, Test loss: 0.561, Test accuracy: 78.78
Round  34, Global train loss: 0.595, Global test loss: 1.480, Global test accuracy: 51.17
Round  35, Train loss: 0.571, Test loss: 0.552, Test accuracy: 79.05
Round  35, Global train loss: 0.571, Global test loss: 1.417, Global test accuracy: 50.30
Round  36, Train loss: 0.568, Test loss: 0.566, Test accuracy: 78.45
Round  36, Global train loss: 0.568, Global test loss: 1.453, Global test accuracy: 50.27
Round  37, Train loss: 0.555, Test loss: 0.571, Test accuracy: 78.17
Round  37, Global train loss: 0.555, Global test loss: 1.464, Global test accuracy: 51.80
Round  38, Train loss: 0.575, Test loss: 0.579, Test accuracy: 78.00
Round  38, Global train loss: 0.575, Global test loss: 1.615, Global test accuracy: 43.20
Round  39, Train loss: 0.508, Test loss: 0.570, Test accuracy: 78.43
Round  39, Global train loss: 0.508, Global test loss: 1.494, Global test accuracy: 48.48
Round  40, Train loss: 0.459, Test loss: 0.583, Test accuracy: 78.55
Round  40, Global train loss: 0.459, Global test loss: 1.455, Global test accuracy: 54.65
Round  41, Train loss: 0.489, Test loss: 0.575, Test accuracy: 78.33
Round  41, Global train loss: 0.489, Global test loss: 1.544, Global test accuracy: 49.82
Round  42, Train loss: 0.557, Test loss: 0.584, Test accuracy: 78.05
Round  42, Global train loss: 0.557, Global test loss: 1.522, Global test accuracy: 48.97
Round  43, Train loss: 0.458, Test loss: 0.576, Test accuracy: 78.50
Round  43, Global train loss: 0.458, Global test loss: 1.380, Global test accuracy: 54.32
Round  44, Train loss: 0.478, Test loss: 0.583, Test accuracy: 78.22
Round  44, Global train loss: 0.478, Global test loss: 1.435, Global test accuracy: 54.38
Round  45, Train loss: 0.405, Test loss: 0.569, Test accuracy: 78.65
Round  45, Global train loss: 0.405, Global test loss: 1.481, Global test accuracy: 53.17
Round  46, Train loss: 0.477, Test loss: 0.568, Test accuracy: 79.20
Round  46, Global train loss: 0.477, Global test loss: 1.504, Global test accuracy: 51.82
Round  47, Train loss: 0.411, Test loss: 0.579, Test accuracy: 78.82
Round  47, Global train loss: 0.411, Global test loss: 1.399, Global test accuracy: 53.77
Round  48, Train loss: 0.422, Test loss: 0.584, Test accuracy: 78.32
Round  48, Global train loss: 0.422, Global test loss: 1.359, Global test accuracy: 54.80
Round  49, Train loss: 0.427, Test loss: 0.580, Test accuracy: 78.65
Round  49, Global train loss: 0.427, Global test loss: 1.520, Global test accuracy: 53.38
Round  50, Train loss: 0.525, Test loss: 0.577, Test accuracy: 78.98
Round  50, Global train loss: 0.525, Global test loss: 1.310, Global test accuracy: 56.10
Round  51, Train loss: 0.480, Test loss: 0.585, Test accuracy: 78.75
Round  51, Global train loss: 0.480, Global test loss: 1.521, Global test accuracy: 47.47
Round  52, Train loss: 0.421, Test loss: 0.613, Test accuracy: 77.92
Round  52, Global train loss: 0.421, Global test loss: 1.485, Global test accuracy: 51.27
Round  53, Train loss: 0.504, Test loss: 0.609, Test accuracy: 78.27
Round  53, Global train loss: 0.504, Global test loss: 1.357, Global test accuracy: 55.30
Round  54, Train loss: 0.367, Test loss: 0.562, Test accuracy: 79.90
Round  54, Global train loss: 0.367, Global test loss: 1.418, Global test accuracy: 55.07
Round  55, Train loss: 0.486, Test loss: 0.579, Test accuracy: 78.93
Round  55, Global train loss: 0.486, Global test loss: 1.279, Global test accuracy: 56.22
Round  56, Train loss: 0.419, Test loss: 0.578, Test accuracy: 79.30
Round  56, Global train loss: 0.419, Global test loss: 1.342, Global test accuracy: 55.92
Round  57, Train loss: 0.371, Test loss: 0.591, Test accuracy: 78.77
Round  57, Global train loss: 0.371, Global test loss: 1.340, Global test accuracy: 55.32
Round  58, Train loss: 0.433, Test loss: 0.582, Test accuracy: 78.82
Round  58, Global train loss: 0.433, Global test loss: 1.181, Global test accuracy: 59.83
Round  59, Train loss: 0.401, Test loss: 0.583, Test accuracy: 79.02
Round  59, Global train loss: 0.401, Global test loss: 1.308, Global test accuracy: 56.82
Round  60, Train loss: 0.404, Test loss: 0.581, Test accuracy: 79.15
Round  60, Global train loss: 0.404, Global test loss: 1.353, Global test accuracy: 55.33
Round  61, Train loss: 0.416, Test loss: 0.575, Test accuracy: 79.22
Round  61, Global train loss: 0.416, Global test loss: 1.441, Global test accuracy: 53.77
Round  62, Train loss: 0.429, Test loss: 0.584, Test accuracy: 79.13
Round  62, Global train loss: 0.429, Global test loss: 1.462, Global test accuracy: 52.42
Round  63, Train loss: 0.376, Test loss: 0.561, Test accuracy: 79.95
Round  63, Global train loss: 0.376, Global test loss: 1.355, Global test accuracy: 56.40
Round  64, Train loss: 0.348, Test loss: 0.567, Test accuracy: 79.83
Round  64, Global train loss: 0.348, Global test loss: 1.507, Global test accuracy: 54.72
Round  65, Train loss: 0.341, Test loss: 0.571, Test accuracy: 80.20
Round  65, Global train loss: 0.341, Global test loss: 1.192, Global test accuracy: 61.05
Round  66, Train loss: 0.337, Test loss: 0.571, Test accuracy: 79.73
Round  66, Global train loss: 0.337, Global test loss: 1.398, Global test accuracy: 55.58
Round  67, Train loss: 0.320, Test loss: 0.585, Test accuracy: 79.60
Round  67, Global train loss: 0.320, Global test loss: 1.392, Global test accuracy: 56.78
Round  68, Train loss: 0.418, Test loss: 0.592, Test accuracy: 79.47
Round  68, Global train loss: 0.418, Global test loss: 1.217, Global test accuracy: 58.72
Round  69, Train loss: 0.375, Test loss: 0.565, Test accuracy: 80.23
Round  69, Global train loss: 0.375, Global test loss: 1.240, Global test accuracy: 59.70
Round  70, Train loss: 0.348, Test loss: 0.599, Test accuracy: 79.38
Round  70, Global train loss: 0.348, Global test loss: 1.340, Global test accuracy: 57.92
Round  71, Train loss: 0.341, Test loss: 0.614, Test accuracy: 79.50
Round  71, Global train loss: 0.341, Global test loss: 1.394, Global test accuracy: 57.17
Round  72, Train loss: 0.317, Test loss: 0.628, Test accuracy: 78.77
Round  72, Global train loss: 0.317, Global test loss: 1.459, Global test accuracy: 55.43
Round  73, Train loss: 0.332, Test loss: 0.602, Test accuracy: 79.88
Round  73, Global train loss: 0.332, Global test loss: 1.293, Global test accuracy: 58.03
Round  74, Train loss: 0.314, Test loss: 0.579, Test accuracy: 80.55
Round  74, Global train loss: 0.314, Global test loss: 1.293, Global test accuracy: 59.23
Round  75, Train loss: 0.337, Test loss: 0.606, Test accuracy: 79.93
Round  75, Global train loss: 0.337, Global test loss: 1.236, Global test accuracy: 60.08
Round  76, Train loss: 0.328, Test loss: 0.615, Test accuracy: 79.65
Round  76, Global train loss: 0.328, Global test loss: 1.521, Global test accuracy: 53.47
Round  77, Train loss: 0.318, Test loss: 0.611, Test accuracy: 79.85
Round  77, Global train loss: 0.318, Global test loss: 1.422, Global test accuracy: 55.35
Round  78, Train loss: 0.312, Test loss: 0.608, Test accuracy: 80.38
Round  78, Global train loss: 0.312, Global test loss: 1.324, Global test accuracy: 59.18
Round  79, Train loss: 0.360, Test loss: 0.591, Test accuracy: 80.47
Round  79, Global train loss: 0.360, Global test loss: 1.340, Global test accuracy: 59.07
Round  80, Train loss: 0.347, Test loss: 0.624, Test accuracy: 79.62
Round  80, Global train loss: 0.347, Global test loss: 1.357, Global test accuracy: 57.93
Round  81, Train loss: 0.327, Test loss: 0.635, Test accuracy: 79.13
Round  81, Global train loss: 0.327, Global test loss: 1.498, Global test accuracy: 55.43
Round  82, Train loss: 0.325, Test loss: 0.639, Test accuracy: 79.15
Round  82, Global train loss: 0.325, Global test loss: 1.475, Global test accuracy: 55.93
Round  83, Train loss: 0.313, Test loss: 0.626, Test accuracy: 79.27
Round  83, Global train loss: 0.313, Global test loss: 1.238, Global test accuracy: 60.50
Round  84, Train loss: 0.264, Test loss: 0.615, Test accuracy: 79.70
Round  84, Global train loss: 0.264, Global test loss: 1.404, Global test accuracy: 57.40
Round  85, Train loss: 0.240, Test loss: 0.606, Test accuracy: 80.13
Round  85, Global train loss: 0.240, Global test loss: 1.312, Global test accuracy: 59.60
Round  86, Train loss: 0.279, Test loss: 0.623, Test accuracy: 80.23
Round  86, Global train loss: 0.279, Global test loss: 1.345, Global test accuracy: 58.67
Round  87, Train loss: 0.289, Test loss: 0.619, Test accuracy: 80.28
Round  87, Global train loss: 0.289, Global test loss: 1.301, Global test accuracy: 58.98
Round  88, Train loss: 0.245, Test loss: 0.623, Test accuracy: 80.48
Round  88, Global train loss: 0.245, Global test loss: 1.466, Global test accuracy: 56.58
Round  89, Train loss: 0.261, Test loss: 0.629, Test accuracy: 79.95
Round  89, Global train loss: 0.261, Global test loss: 1.364, Global test accuracy: 57.93
Round  90, Train loss: 0.390, Test loss: 0.628, Test accuracy: 79.97
Round  90, Global train loss: 0.390, Global test loss: 1.349, Global test accuracy: 57.02
Round  91, Train loss: 0.256, Test loss: 0.620, Test accuracy: 80.38
Round  91, Global train loss: 0.256, Global test loss: 1.435, Global test accuracy: 57.58
Round  92, Train loss: 0.278, Test loss: 0.612, Test accuracy: 80.40
Round  92, Global train loss: 0.278, Global test loss: 1.315, Global test accuracy: 59.08
Round  93, Train loss: 0.246, Test loss: 0.609, Test accuracy: 80.58
Round  93, Global train loss: 0.246, Global test loss: 1.487, Global test accuracy: 56.35
Round  94, Train loss: 0.260, Test loss: 0.607, Test accuracy: 80.55
Round  94, Global train loss: 0.260, Global test loss: 1.516, Global test accuracy: 55.70
Round  95, Train loss: 0.284, Test loss: 0.591, Test accuracy: 80.97
Round  95, Global train loss: 0.284, Global test loss: 1.406, Global test accuracy: 57.12
Round  96, Train loss: 0.244, Test loss: 0.625, Test accuracy: 80.20
Round  96, Global train loss: 0.244, Global test loss: 1.429, Global test accuracy: 56.57
Round  97, Train loss: 0.241, Test loss: 0.615, Test accuracy: 80.32
Round  97, Global train loss: 0.241, Global test loss: 1.497, Global test accuracy: 55.38
Round  98, Train loss: 0.272, Test loss: 0.638, Test accuracy: 80.23
Round  98, Global train loss: 0.272, Global test loss: 1.232, Global test accuracy: 61.60
Round  99, Train loss: 0.258, Test loss: 0.636, Test accuracy: 80.00
Round  99, Global train loss: 0.258, Global test loss: 1.328, Global test accuracy: 59.20
Final Round, Train loss: 0.205, Test loss: 0.695, Test accuracy: 80.10
Final Round, Global train loss: 0.205, Global test loss: 1.328, Global test accuracy: 59.20
Average accuracy final 10 rounds: 80.36000000000001 

Average global accuracy final 10 rounds: 57.56 

1196.1841287612915
[1.038341760635376, 2.076683521270752, 2.870849609375, 3.665015697479248, 4.510783910751343, 5.3565521240234375, 6.162527561187744, 6.968502998352051, 7.854419231414795, 8.740335464477539, 9.574192523956299, 10.408049583435059, 11.297944784164429, 12.187839984893799, 13.02270245552063, 13.857564926147461, 14.688318014144897, 15.519071102142334, 16.35044240951538, 17.181813716888428, 18.02574110031128, 18.86966848373413, 19.670279502868652, 20.470890522003174, 21.300939559936523, 22.130988597869873, 22.989066123962402, 23.84714365005493, 24.699395656585693, 25.551647663116455, 26.337754011154175, 27.123860359191895, 27.937304258346558, 28.75074815750122, 29.555577993392944, 30.360407829284668, 31.221596240997314, 32.08278465270996, 32.91668438911438, 33.7505841255188, 34.598896980285645, 35.44720983505249, 36.28017830848694, 37.11314678192139, 37.92061948776245, 38.728092193603516, 39.53771185874939, 40.347331523895264, 41.12435817718506, 41.90138483047485, 42.71737051010132, 43.53335618972778, 44.373379945755005, 45.21340370178223, 46.04059553146362, 46.86778736114502, 47.68308877944946, 48.498390197753906, 49.33570885658264, 50.17302751541138, 51.00315475463867, 51.83328199386597, 52.64131283760071, 53.44934368133545, 54.184630393981934, 54.91991710662842, 55.6633563041687, 56.406795501708984, 57.164997577667236, 57.92319965362549, 58.70786213874817, 59.49252462387085, 60.278483390808105, 61.06444215774536, 61.90057015419006, 62.736698150634766, 63.54212689399719, 64.34755563735962, 65.14787077903748, 65.94818592071533, 66.67379212379456, 67.39939832687378, 68.17494201660156, 68.95048570632935, 69.75151228904724, 70.55253887176514, 71.35316348075867, 72.1537880897522, 72.91537690162659, 73.67696571350098, 74.45913410186768, 75.24130249023438, 76.06801342964172, 76.89472436904907, 77.70711398124695, 78.51950359344482, 79.3035638332367, 80.08762407302856, 80.87484812736511, 81.66207218170166, 82.43844509124756, 83.21481800079346, 83.97065305709839, 84.72648811340332, 85.53265523910522, 86.33882236480713, 87.15608072280884, 87.97333908081055, 88.80742263793945, 89.64150619506836, 90.44712114334106, 91.25273609161377, 91.99760222434998, 92.74246835708618, 93.4896457195282, 94.23682308197021, 95.05214881896973, 95.86747455596924, 96.67256426811218, 97.47765398025513, 98.27041625976562, 99.06317853927612, 99.87655472755432, 100.68993091583252, 101.49217391014099, 102.29441690444946, 103.09409260749817, 103.89376831054688, 104.67110109329224, 105.4484338760376, 106.23764443397522, 107.02685499191284, 107.77473521232605, 108.52261543273926, 109.30459403991699, 110.08657264709473, 110.82388424873352, 111.56119585037231, 112.3484103679657, 113.13562488555908, 113.95397663116455, 114.77232837677002, 115.60894560813904, 116.44556283950806, 117.20084762573242, 117.95613241195679, 118.70705008506775, 119.45796775817871, 120.21164202690125, 120.96531629562378, 121.77678060531616, 122.58824491500854, 123.3501992225647, 124.11215353012085, 124.8994026184082, 125.68665170669556, 126.47081875801086, 127.25498580932617, 128.08182406425476, 128.90866231918335, 129.69938039779663, 130.4900984764099, 131.25515222549438, 132.02020597457886, 132.8324921131134, 133.64477825164795, 134.39563083648682, 135.14648342132568, 135.9282476902008, 136.71001195907593, 137.4976246356964, 138.2852373123169, 139.11729335784912, 139.94934940338135, 140.80631184577942, 141.6632742881775, 142.4864637851715, 143.30965328216553, 144.02857780456543, 144.74750232696533, 145.49580192565918, 146.24410152435303, 147.01071047782898, 147.77731943130493, 148.57857728004456, 149.37983512878418, 150.21680450439453, 151.05377388000488, 151.8890199661255, 152.7242660522461, 153.55300879478455, 154.381751537323, 155.2095546722412, 156.03735780715942, 156.81608891487122, 157.594820022583, 158.37405943870544, 159.15329885482788, 159.96633124351501, 160.77936363220215, 162.31425666809082, 163.8491497039795]
[24.85, 24.85, 40.56666666666667, 40.56666666666667, 41.45, 41.45, 51.46666666666667, 51.46666666666667, 58.15, 58.15, 58.233333333333334, 58.233333333333334, 60.86666666666667, 60.86666666666667, 63.6, 63.6, 65.28333333333333, 65.28333333333333, 64.48333333333333, 64.48333333333333, 66.9, 66.9, 69.7, 69.7, 70.65, 70.65, 70.98333333333333, 70.98333333333333, 71.95, 71.95, 72.1, 72.1, 71.95, 71.95, 72.33333333333333, 72.33333333333333, 72.71666666666667, 72.71666666666667, 73.33333333333333, 73.33333333333333, 73.85, 73.85, 73.93333333333334, 73.93333333333334, 74.25, 74.25, 73.88333333333334, 73.88333333333334, 74.9, 74.9, 75.86666666666666, 75.86666666666666, 75.81666666666666, 75.81666666666666, 76.4, 76.4, 76.58333333333333, 76.58333333333333, 76.58333333333333, 76.58333333333333, 76.5, 76.5, 76.9, 76.9, 77.08333333333333, 77.08333333333333, 77.63333333333334, 77.63333333333334, 78.78333333333333, 78.78333333333333, 79.05, 79.05, 78.45, 78.45, 78.16666666666667, 78.16666666666667, 78.0, 78.0, 78.43333333333334, 78.43333333333334, 78.55, 78.55, 78.33333333333333, 78.33333333333333, 78.05, 78.05, 78.5, 78.5, 78.21666666666667, 78.21666666666667, 78.65, 78.65, 79.2, 79.2, 78.81666666666666, 78.81666666666666, 78.31666666666666, 78.31666666666666, 78.65, 78.65, 78.98333333333333, 78.98333333333333, 78.75, 78.75, 77.91666666666667, 77.91666666666667, 78.26666666666667, 78.26666666666667, 79.9, 79.9, 78.93333333333334, 78.93333333333334, 79.3, 79.3, 78.76666666666667, 78.76666666666667, 78.81666666666666, 78.81666666666666, 79.01666666666667, 79.01666666666667, 79.15, 79.15, 79.21666666666667, 79.21666666666667, 79.13333333333334, 79.13333333333334, 79.95, 79.95, 79.83333333333333, 79.83333333333333, 80.2, 80.2, 79.73333333333333, 79.73333333333333, 79.6, 79.6, 79.46666666666667, 79.46666666666667, 80.23333333333333, 80.23333333333333, 79.38333333333334, 79.38333333333334, 79.5, 79.5, 78.76666666666667, 78.76666666666667, 79.88333333333334, 79.88333333333334, 80.55, 80.55, 79.93333333333334, 79.93333333333334, 79.65, 79.65, 79.85, 79.85, 80.38333333333334, 80.38333333333334, 80.46666666666667, 80.46666666666667, 79.61666666666666, 79.61666666666666, 79.13333333333334, 79.13333333333334, 79.15, 79.15, 79.26666666666667, 79.26666666666667, 79.7, 79.7, 80.13333333333334, 80.13333333333334, 80.23333333333333, 80.23333333333333, 80.28333333333333, 80.28333333333333, 80.48333333333333, 80.48333333333333, 79.95, 79.95, 79.96666666666667, 79.96666666666667, 80.38333333333334, 80.38333333333334, 80.4, 80.4, 80.58333333333333, 80.58333333333333, 80.55, 80.55, 80.96666666666667, 80.96666666666667, 80.2, 80.2, 80.31666666666666, 80.31666666666666, 80.23333333333333, 80.23333333333333, 80.0, 80.0, 80.1, 80.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.261, Test loss: 1.908, Test accuracy: 22.53
Round   0, Global train loss: 1.261, Global test loss: 2.230, Global test accuracy: 13.50
Round   1, Train loss: 1.101, Test loss: 1.566, Test accuracy: 37.23
Round   1, Global train loss: 1.101, Global test loss: 2.162, Global test accuracy: 24.62
Round   2, Train loss: 1.011, Test loss: 1.430, Test accuracy: 40.68
Round   2, Global train loss: 1.011, Global test loss: 2.133, Global test accuracy: 23.13
Round   3, Train loss: 0.948, Test loss: 1.164, Test accuracy: 49.70
Round   3, Global train loss: 0.948, Global test loss: 1.999, Global test accuracy: 27.62
Round   4, Train loss: 0.834, Test loss: 1.016, Test accuracy: 54.70
Round   4, Global train loss: 0.834, Global test loss: 2.077, Global test accuracy: 29.68
Round   5, Train loss: 0.952, Test loss: 0.960, Test accuracy: 57.13
Round   5, Global train loss: 0.952, Global test loss: 2.123, Global test accuracy: 14.98
Round   6, Train loss: 0.918, Test loss: 0.913, Test accuracy: 59.45
Round   6, Global train loss: 0.918, Global test loss: 1.858, Global test accuracy: 30.05
Round   7, Train loss: 0.820, Test loss: 0.874, Test accuracy: 62.82
Round   7, Global train loss: 0.820, Global test loss: 1.822, Global test accuracy: 39.08
Round   8, Train loss: 0.734, Test loss: 0.836, Test accuracy: 64.90
Round   8, Global train loss: 0.734, Global test loss: 1.929, Global test accuracy: 38.33
Round   9, Train loss: 0.809, Test loss: 0.829, Test accuracy: 64.53
Round   9, Global train loss: 0.809, Global test loss: 1.725, Global test accuracy: 41.68
Round  10, Train loss: 0.752, Test loss: 0.784, Test accuracy: 66.75
Round  10, Global train loss: 0.752, Global test loss: 1.793, Global test accuracy: 38.80
Round  11, Train loss: 0.723, Test loss: 0.699, Test accuracy: 70.13
Round  11, Global train loss: 0.723, Global test loss: 1.723, Global test accuracy: 39.00
Round  12, Train loss: 0.760, Test loss: 0.700, Test accuracy: 70.38
Round  12, Global train loss: 0.760, Global test loss: 1.930, Global test accuracy: 35.97
Round  13, Train loss: 0.646, Test loss: 0.678, Test accuracy: 71.28
Round  13, Global train loss: 0.646, Global test loss: 1.664, Global test accuracy: 42.05
Round  14, Train loss: 0.769, Test loss: 0.678, Test accuracy: 71.73
Round  14, Global train loss: 0.769, Global test loss: 1.535, Global test accuracy: 45.52
Round  15, Train loss: 0.686, Test loss: 0.694, Test accuracy: 71.23
Round  15, Global train loss: 0.686, Global test loss: 1.704, Global test accuracy: 42.33
Round  16, Train loss: 0.642, Test loss: 0.675, Test accuracy: 71.55
Round  16, Global train loss: 0.642, Global test loss: 1.631, Global test accuracy: 46.02
Round  17, Train loss: 0.744, Test loss: 0.633, Test accuracy: 73.18
Round  17, Global train loss: 0.744, Global test loss: 1.568, Global test accuracy: 48.03
Round  18, Train loss: 0.669, Test loss: 0.641, Test accuracy: 73.12
Round  18, Global train loss: 0.669, Global test loss: 1.688, Global test accuracy: 42.97
Round  19, Train loss: 0.737, Test loss: 0.640, Test accuracy: 73.22
Round  19, Global train loss: 0.737, Global test loss: 1.693, Global test accuracy: 46.08
Round  20, Train loss: 0.709, Test loss: 0.627, Test accuracy: 74.12
Round  20, Global train loss: 0.709, Global test loss: 1.451, Global test accuracy: 49.12
Round  21, Train loss: 0.596, Test loss: 0.625, Test accuracy: 74.00
Round  21, Global train loss: 0.596, Global test loss: 1.724, Global test accuracy: 40.58
Round  22, Train loss: 0.651, Test loss: 0.655, Test accuracy: 73.30
Round  22, Global train loss: 0.651, Global test loss: 1.534, Global test accuracy: 49.10
Round  23, Train loss: 0.596, Test loss: 0.662, Test accuracy: 73.10
Round  23, Global train loss: 0.596, Global test loss: 1.434, Global test accuracy: 50.23
Round  24, Train loss: 0.655, Test loss: 0.651, Test accuracy: 73.57
Round  24, Global train loss: 0.655, Global test loss: 1.573, Global test accuracy: 48.42
Round  25, Train loss: 0.636, Test loss: 0.651, Test accuracy: 73.42
Round  25, Global train loss: 0.636, Global test loss: 1.537, Global test accuracy: 45.32
Round  26, Train loss: 0.631, Test loss: 0.639, Test accuracy: 73.95
Round  26, Global train loss: 0.631, Global test loss: 1.593, Global test accuracy: 47.52
Round  27, Train loss: 0.684, Test loss: 0.636, Test accuracy: 74.38
Round  27, Global train loss: 0.684, Global test loss: 1.375, Global test accuracy: 50.25
Round  28, Train loss: 0.647, Test loss: 0.637, Test accuracy: 74.03
Round  28, Global train loss: 0.647, Global test loss: 1.520, Global test accuracy: 45.48
Round  29, Train loss: 0.587, Test loss: 0.626, Test accuracy: 74.97
Round  29, Global train loss: 0.587, Global test loss: 1.447, Global test accuracy: 50.17
Round  30, Train loss: 0.583, Test loss: 0.606, Test accuracy: 75.50
Round  30, Global train loss: 0.583, Global test loss: 1.564, Global test accuracy: 46.48
Round  31, Train loss: 0.580, Test loss: 0.610, Test accuracy: 75.52
Round  31, Global train loss: 0.580, Global test loss: 1.303, Global test accuracy: 53.72
Round  32, Train loss: 0.576, Test loss: 0.591, Test accuracy: 76.75
Round  32, Global train loss: 0.576, Global test loss: 1.531, Global test accuracy: 48.30
Round  33, Train loss: 0.546, Test loss: 0.592, Test accuracy: 76.93
Round  33, Global train loss: 0.546, Global test loss: 1.694, Global test accuracy: 48.13
Round  34, Train loss: 0.593, Test loss: 0.588, Test accuracy: 77.07
Round  34, Global train loss: 0.593, Global test loss: 1.550, Global test accuracy: 49.13
Round  35, Train loss: 0.602, Test loss: 0.593, Test accuracy: 76.83
Round  35, Global train loss: 0.602, Global test loss: 1.433, Global test accuracy: 49.92
Round  36, Train loss: 0.558, Test loss: 0.594, Test accuracy: 77.23
Round  36, Global train loss: 0.558, Global test loss: 1.417, Global test accuracy: 52.65
Round  37, Train loss: 0.528, Test loss: 0.581, Test accuracy: 77.23
Round  37, Global train loss: 0.528, Global test loss: 1.503, Global test accuracy: 49.77
Round  38, Train loss: 0.569, Test loss: 0.571, Test accuracy: 77.25
Round  38, Global train loss: 0.569, Global test loss: 1.461, Global test accuracy: 46.67
Round  39, Train loss: 0.451, Test loss: 0.587, Test accuracy: 77.27
Round  39, Global train loss: 0.451, Global test loss: 1.404, Global test accuracy: 50.45
Round  40, Train loss: 0.449, Test loss: 0.590, Test accuracy: 77.45
Round  40, Global train loss: 0.449, Global test loss: 1.382, Global test accuracy: 54.78
Round  41, Train loss: 0.521, Test loss: 0.571, Test accuracy: 77.73
Round  41, Global train loss: 0.521, Global test loss: 1.481, Global test accuracy: 50.20
Round  42, Train loss: 0.546, Test loss: 0.596, Test accuracy: 76.90
Round  42, Global train loss: 0.546, Global test loss: 1.531, Global test accuracy: 48.05
Round  43, Train loss: 0.491, Test loss: 0.585, Test accuracy: 77.10
Round  43, Global train loss: 0.491, Global test loss: 1.354, Global test accuracy: 54.38
Round  44, Train loss: 0.515, Test loss: 0.569, Test accuracy: 78.00
Round  44, Global train loss: 0.515, Global test loss: 1.467, Global test accuracy: 52.87
Round  45, Train loss: 0.448, Test loss: 0.572, Test accuracy: 78.00
Round  45, Global train loss: 0.448, Global test loss: 1.446, Global test accuracy: 52.95
Round  46, Train loss: 0.467, Test loss: 0.572, Test accuracy: 78.38
Round  46, Global train loss: 0.467, Global test loss: 1.523, Global test accuracy: 51.73
Round  47, Train loss: 0.441, Test loss: 0.577, Test accuracy: 77.92
Round  47, Global train loss: 0.441, Global test loss: 1.343, Global test accuracy: 55.95
Round  48, Train loss: 0.493, Test loss: 0.584, Test accuracy: 78.18
Round  48, Global train loss: 0.493, Global test loss: 1.365, Global test accuracy: 53.88
Round  49, Train loss: 0.465, Test loss: 0.570, Test accuracy: 78.28
Round  49, Global train loss: 0.465, Global test loss: 1.489, Global test accuracy: 52.07
Round  50, Train loss: 0.477, Test loss: 0.566, Test accuracy: 78.40
Round  50, Global train loss: 0.477, Global test loss: 1.329, Global test accuracy: 55.28
Round  51, Train loss: 0.510, Test loss: 0.589, Test accuracy: 77.92
Round  51, Global train loss: 0.510, Global test loss: 1.484, Global test accuracy: 48.57
Round  52, Train loss: 0.458, Test loss: 0.577, Test accuracy: 78.57
Round  52, Global train loss: 0.458, Global test loss: 1.407, Global test accuracy: 53.30
Round  53, Train loss: 0.450, Test loss: 0.580, Test accuracy: 78.02
Round  53, Global train loss: 0.450, Global test loss: 1.473, Global test accuracy: 53.48
Round  54, Train loss: 0.402, Test loss: 0.548, Test accuracy: 79.48
Round  54, Global train loss: 0.402, Global test loss: 1.382, Global test accuracy: 55.33
Round  55, Train loss: 0.445, Test loss: 0.538, Test accuracy: 79.92
Round  55, Global train loss: 0.445, Global test loss: 1.318, Global test accuracy: 54.90
Round  56, Train loss: 0.383, Test loss: 0.531, Test accuracy: 79.85
Round  56, Global train loss: 0.383, Global test loss: 1.266, Global test accuracy: 57.22
Round  57, Train loss: 0.398, Test loss: 0.530, Test accuracy: 80.05
Round  57, Global train loss: 0.398, Global test loss: 1.386, Global test accuracy: 54.62
Round  58, Train loss: 0.477, Test loss: 0.543, Test accuracy: 79.78
Round  58, Global train loss: 0.477, Global test loss: 1.184, Global test accuracy: 59.25
Round  59, Train loss: 0.393, Test loss: 0.519, Test accuracy: 80.38
Round  59, Global train loss: 0.393, Global test loss: 1.304, Global test accuracy: 57.53
Round  60, Train loss: 0.354, Test loss: 0.533, Test accuracy: 80.50
Round  60, Global train loss: 0.354, Global test loss: 1.485, Global test accuracy: 53.07
Round  61, Train loss: 0.408, Test loss: 0.538, Test accuracy: 80.43
Round  61, Global train loss: 0.408, Global test loss: 1.446, Global test accuracy: 53.67
Round  62, Train loss: 0.393, Test loss: 0.527, Test accuracy: 80.75
Round  62, Global train loss: 0.393, Global test loss: 1.361, Global test accuracy: 55.53
Round  63, Train loss: 0.337, Test loss: 0.528, Test accuracy: 80.57
Round  63, Global train loss: 0.337, Global test loss: 1.284, Global test accuracy: 58.27
Round  64, Train loss: 0.383, Test loss: 0.540, Test accuracy: 80.37
Round  64, Global train loss: 0.383, Global test loss: 1.419, Global test accuracy: 55.47
Round  65, Train loss: 0.412, Test loss: 0.553, Test accuracy: 79.80
Round  65, Global train loss: 0.412, Global test loss: 1.208, Global test accuracy: 60.28
Round  66, Train loss: 0.387, Test loss: 0.547, Test accuracy: 79.97
Round  66, Global train loss: 0.387, Global test loss: 1.353, Global test accuracy: 56.27
Round  67, Train loss: 0.324, Test loss: 0.548, Test accuracy: 79.97
Round  67, Global train loss: 0.324, Global test loss: 1.395, Global test accuracy: 56.90
Round  68, Train loss: 0.430, Test loss: 0.567, Test accuracy: 79.50
Round  68, Global train loss: 0.430, Global test loss: 1.238, Global test accuracy: 59.50
Round  69, Train loss: 0.373, Test loss: 0.557, Test accuracy: 79.97
Round  69, Global train loss: 0.373, Global test loss: 1.320, Global test accuracy: 57.42
Round  70, Train loss: 0.374, Test loss: 0.549, Test accuracy: 80.47
Round  70, Global train loss: 0.374, Global test loss: 1.355, Global test accuracy: 57.97
Round  71, Train loss: 0.381, Test loss: 0.536, Test accuracy: 80.98
Round  71, Global train loss: 0.381, Global test loss: 1.416, Global test accuracy: 55.75
Round  72, Train loss: 0.350, Test loss: 0.546, Test accuracy: 80.77
Round  72, Global train loss: 0.350, Global test loss: 1.363, Global test accuracy: 56.37
Round  73, Train loss: 0.339, Test loss: 0.534, Test accuracy: 81.08
Round  73, Global train loss: 0.339, Global test loss: 1.247, Global test accuracy: 59.00
Round  74, Train loss: 0.340, Test loss: 0.542, Test accuracy: 80.82
Round  74, Global train loss: 0.340, Global test loss: 1.264, Global test accuracy: 59.07
Round  75, Train loss: 0.352, Test loss: 0.537, Test accuracy: 80.93
Round  75, Global train loss: 0.352, Global test loss: 1.230, Global test accuracy: 59.68
Round  76, Train loss: 0.342, Test loss: 0.553, Test accuracy: 80.32
Round  76, Global train loss: 0.342, Global test loss: 1.600, Global test accuracy: 51.55
Round  77, Train loss: 0.270, Test loss: 0.581, Test accuracy: 79.67
Round  77, Global train loss: 0.270, Global test loss: 1.297, Global test accuracy: 57.92
Round  78, Train loss: 0.330, Test loss: 0.579, Test accuracy: 80.15
Round  78, Global train loss: 0.330, Global test loss: 1.214, Global test accuracy: 61.20
Round  79, Train loss: 0.413, Test loss: 0.582, Test accuracy: 80.23
Round  79, Global train loss: 0.413, Global test loss: 1.232, Global test accuracy: 59.95
Round  80, Train loss: 0.344, Test loss: 0.571, Test accuracy: 80.67
Round  80, Global train loss: 0.344, Global test loss: 1.304, Global test accuracy: 60.02
Round  81, Train loss: 0.328, Test loss: 0.565, Test accuracy: 80.72
Round  81, Global train loss: 0.328, Global test loss: 1.493, Global test accuracy: 55.35
Round  82, Train loss: 0.336, Test loss: 0.557, Test accuracy: 80.67
Round  82, Global train loss: 0.336, Global test loss: 1.380, Global test accuracy: 56.23
Round  83, Train loss: 0.337, Test loss: 0.553, Test accuracy: 80.63
Round  83, Global train loss: 0.337, Global test loss: 1.256, Global test accuracy: 59.25
Round  84, Train loss: 0.244, Test loss: 0.553, Test accuracy: 80.53
Round  84, Global train loss: 0.244, Global test loss: 1.348, Global test accuracy: 58.17
Round  85, Train loss: 0.255, Test loss: 0.543, Test accuracy: 81.10
Round  85, Global train loss: 0.255, Global test loss: 1.330, Global test accuracy: 60.38
Round  86, Train loss: 0.301, Test loss: 0.549, Test accuracy: 81.15
Round  86, Global train loss: 0.301, Global test loss: 1.361, Global test accuracy: 56.98
Round  87, Train loss: 0.299, Test loss: 0.563, Test accuracy: 80.80
Round  87, Global train loss: 0.299, Global test loss: 1.215, Global test accuracy: 60.25
Round  88, Train loss: 0.240, Test loss: 0.554, Test accuracy: 81.07
Round  88, Global train loss: 0.240, Global test loss: 1.414, Global test accuracy: 56.70
Round  89, Train loss: 0.220, Test loss: 0.559, Test accuracy: 81.03
Round  89, Global train loss: 0.220, Global test loss: 1.373, Global test accuracy: 58.17
Round  90, Train loss: 0.368, Test loss: 0.548, Test accuracy: 81.17
Round  90, Global train loss: 0.368, Global test loss: 1.353, Global test accuracy: 57.72
Round  91, Train loss: 0.303, Test loss: 0.541, Test accuracy: 81.02
Round  91, Global train loss: 0.303, Global test loss: 1.426, Global test accuracy: 56.47
Round  92, Train loss: 0.294, Test loss: 0.565, Test accuracy: 80.75
Round  92, Global train loss: 0.294, Global test loss: 1.260, Global test accuracy: 61.05
Round  93, Train loss: 0.278, Test loss: 0.586, Test accuracy: 80.13
Round  93, Global train loss: 0.278, Global test loss: 1.474, Global test accuracy: 55.97
Round  94, Train loss: 0.316, Test loss: 0.599, Test accuracy: 79.77
Round  94, Global train loss: 0.316, Global test loss: 1.298, Global test accuracy: 60.07
Round  95, Train loss: 0.295, Test loss: 0.601, Test accuracy: 80.23
Round  95, Global train loss: 0.295, Global test loss: 1.371, Global test accuracy: 56.52
Round  96, Train loss: 0.238, Test loss: 0.606, Test accuracy: 80.38
Round  96, Global train loss: 0.238, Global test loss: 1.373, Global test accuracy: 57.77
Round  97, Train loss: 0.255, Test loss: 0.621, Test accuracy: 79.93
Round  97, Global train loss: 0.255, Global test loss: 1.439, Global test accuracy: 55.57
Round  98, Train loss: 0.320, Test loss: 0.630, Test accuracy: 79.77
Round  98, Global train loss: 0.320, Global test loss: 1.182, Global test accuracy: 61.97
Round  99, Train loss: 0.303, Test loss: 0.631, Test accuracy: 79.80
Round  99, Global train loss: 0.303, Global test loss: 1.268, Global test accuracy: 60.10
Final Round, Train loss: 0.224, Test loss: 0.578, Test accuracy: 81.60
Final Round, Global train loss: 0.224, Global test loss: 1.268, Global test accuracy: 60.10
Average accuracy final 10 rounds: 80.295 

Average global accuracy final 10 rounds: 58.31833333333333 

1098.4485652446747
[1.1439571380615234, 2.287914276123047, 3.1275129318237305, 3.967111587524414, 4.762976169586182, 5.558840751647949, 6.374379873275757, 7.1899189949035645, 8.009235858917236, 8.828552722930908, 9.649625539779663, 10.470698356628418, 11.319609880447388, 12.168521404266357, 13.04226303100586, 13.916004657745361, 14.77109432220459, 15.626183986663818, 16.45654320716858, 17.28690242767334, 18.116831064224243, 18.946759700775146, 19.788467168807983, 20.63017463684082, 21.47455358505249, 22.31893253326416, 23.09374213218689, 23.86855173110962, 24.663362741470337, 25.458173751831055, 26.299261569976807, 27.14034938812256, 27.96173882484436, 28.783128261566162, 29.55228304862976, 30.32143783569336, 31.094888925552368, 31.868340015411377, 32.68675947189331, 33.505178928375244, 34.27809405326843, 35.05100917816162, 35.84592366218567, 36.64083814620972, 37.41838812828064, 38.19593811035156, 39.001715898513794, 39.807493686676025, 40.632251501083374, 41.45700931549072, 42.243141174316406, 43.02927303314209, 43.79496121406555, 44.560649394989014, 45.353721380233765, 46.146793365478516, 46.926127195358276, 47.70546102523804, 48.48929190635681, 49.273122787475586, 50.08076882362366, 50.88841485977173, 51.69422674179077, 52.500038623809814, 53.3185076713562, 54.13697671890259, 54.94263815879822, 55.74829959869385, 56.500795125961304, 57.25329065322876, 58.01794743537903, 58.7826042175293, 59.56545686721802, 60.34830951690674, 61.10431122779846, 61.860312938690186, 62.669963359832764, 63.47961378097534, 64.33947658538818, 65.19933938980103, 66.03235125541687, 66.86536312103271, 67.65888023376465, 68.45239734649658, 69.2297191619873, 70.00704097747803, 70.78301954269409, 71.55899810791016, 72.34399938583374, 73.12900066375732, 73.90650129318237, 74.68400192260742, 75.48197984695435, 76.27995777130127, 77.0945131778717, 77.90906858444214, 78.74597477912903, 79.58288097381592, 80.37610006332397, 81.16931915283203, 81.93660020828247, 82.70388126373291, 83.4826729297638, 84.26146459579468, 85.03852725028992, 85.81558990478516, 86.60654520988464, 87.39750051498413, 88.19981694221497, 89.0021333694458, 89.8209297657013, 90.63972616195679, 91.49180340766907, 92.34388065338135, 93.12974500656128, 93.91560935974121, 94.67184710502625, 95.42808485031128, 96.20732164382935, 96.98655843734741, 97.78567719459534, 98.58479595184326, 99.3605387210846, 100.13628149032593, 100.92045021057129, 101.70461893081665, 102.48646140098572, 103.26830387115479, 104.04400134086609, 104.81969881057739, 105.59553527832031, 106.37137174606323, 107.13644862174988, 107.90152549743652, 108.63500761985779, 109.36848974227905, 110.1087965965271, 110.84910345077515, 111.5881130695343, 112.32712268829346, 113.08949255943298, 113.85186243057251, 114.63361167907715, 115.41536092758179, 116.20097804069519, 116.9865951538086, 117.76846146583557, 118.55032777786255, 119.31754422187805, 120.08476066589355, 120.83412575721741, 121.58349084854126, 122.32973337173462, 123.07597589492798, 123.82739424705505, 124.57881259918213, 125.36497759819031, 126.15114259719849, 126.92226719856262, 127.69339179992676, 128.4868471622467, 129.28030252456665, 130.06435179710388, 130.8484010696411, 131.60357332229614, 132.35874557495117, 133.1010603904724, 133.84337520599365, 134.5836398601532, 135.32390451431274, 136.0683867931366, 136.81286907196045, 137.5640046596527, 138.31514024734497, 139.09637689590454, 139.8776135444641, 140.64653158187866, 141.4154496192932, 142.20121097564697, 142.98697233200073, 143.7447633743286, 144.5025544166565, 145.2406234741211, 145.9786925315857, 146.72644925117493, 147.47420597076416, 148.22642159461975, 148.97863721847534, 149.73053860664368, 150.482439994812, 151.2555751800537, 152.0287103652954, 152.80173563957214, 153.57476091384888, 154.34033155441284, 155.1059021949768, 155.8741147518158, 156.64232730865479, 157.38366389274597, 158.12500047683716, 159.6270182132721, 161.12903594970703]
[22.533333333333335, 22.533333333333335, 37.233333333333334, 37.233333333333334, 40.68333333333333, 40.68333333333333, 49.7, 49.7, 54.7, 54.7, 57.13333333333333, 57.13333333333333, 59.45, 59.45, 62.81666666666667, 62.81666666666667, 64.9, 64.9, 64.53333333333333, 64.53333333333333, 66.75, 66.75, 70.13333333333334, 70.13333333333334, 70.38333333333334, 70.38333333333334, 71.28333333333333, 71.28333333333333, 71.73333333333333, 71.73333333333333, 71.23333333333333, 71.23333333333333, 71.55, 71.55, 73.18333333333334, 73.18333333333334, 73.11666666666666, 73.11666666666666, 73.21666666666667, 73.21666666666667, 74.11666666666666, 74.11666666666666, 74.0, 74.0, 73.3, 73.3, 73.1, 73.1, 73.56666666666666, 73.56666666666666, 73.41666666666667, 73.41666666666667, 73.95, 73.95, 74.38333333333334, 74.38333333333334, 74.03333333333333, 74.03333333333333, 74.96666666666667, 74.96666666666667, 75.5, 75.5, 75.51666666666667, 75.51666666666667, 76.75, 76.75, 76.93333333333334, 76.93333333333334, 77.06666666666666, 77.06666666666666, 76.83333333333333, 76.83333333333333, 77.23333333333333, 77.23333333333333, 77.23333333333333, 77.23333333333333, 77.25, 77.25, 77.26666666666667, 77.26666666666667, 77.45, 77.45, 77.73333333333333, 77.73333333333333, 76.9, 76.9, 77.1, 77.1, 78.0, 78.0, 78.0, 78.0, 78.38333333333334, 78.38333333333334, 77.91666666666667, 77.91666666666667, 78.18333333333334, 78.18333333333334, 78.28333333333333, 78.28333333333333, 78.4, 78.4, 77.91666666666667, 77.91666666666667, 78.56666666666666, 78.56666666666666, 78.01666666666667, 78.01666666666667, 79.48333333333333, 79.48333333333333, 79.91666666666667, 79.91666666666667, 79.85, 79.85, 80.05, 80.05, 79.78333333333333, 79.78333333333333, 80.38333333333334, 80.38333333333334, 80.5, 80.5, 80.43333333333334, 80.43333333333334, 80.75, 80.75, 80.56666666666666, 80.56666666666666, 80.36666666666666, 80.36666666666666, 79.8, 79.8, 79.96666666666667, 79.96666666666667, 79.96666666666667, 79.96666666666667, 79.5, 79.5, 79.96666666666667, 79.96666666666667, 80.46666666666667, 80.46666666666667, 80.98333333333333, 80.98333333333333, 80.76666666666667, 80.76666666666667, 81.08333333333333, 81.08333333333333, 80.81666666666666, 80.81666666666666, 80.93333333333334, 80.93333333333334, 80.31666666666666, 80.31666666666666, 79.66666666666667, 79.66666666666667, 80.15, 80.15, 80.23333333333333, 80.23333333333333, 80.66666666666667, 80.66666666666667, 80.71666666666667, 80.71666666666667, 80.66666666666667, 80.66666666666667, 80.63333333333334, 80.63333333333334, 80.53333333333333, 80.53333333333333, 81.1, 81.1, 81.15, 81.15, 80.8, 80.8, 81.06666666666666, 81.06666666666666, 81.03333333333333, 81.03333333333333, 81.16666666666667, 81.16666666666667, 81.01666666666667, 81.01666666666667, 80.75, 80.75, 80.13333333333334, 80.13333333333334, 79.76666666666667, 79.76666666666667, 80.23333333333333, 80.23333333333333, 80.38333333333334, 80.38333333333334, 79.93333333333334, 79.93333333333334, 79.76666666666667, 79.76666666666667, 79.8, 79.8, 81.6, 81.6]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.728, Test loss: 2.112, Test accuracy: 22.87
Round   1, Train loss: 1.148, Test loss: 1.714, Test accuracy: 36.10
Round   2, Train loss: 1.065, Test loss: 1.665, Test accuracy: 35.77
Round   3, Train loss: 1.019, Test loss: 1.266, Test accuracy: 47.05
Round   4, Train loss: 0.907, Test loss: 1.094, Test accuracy: 52.27
Round   5, Train loss: 1.051, Test loss: 1.080, Test accuracy: 54.27
Round   6, Train loss: 0.882, Test loss: 1.018, Test accuracy: 56.83
Round   7, Train loss: 0.778, Test loss: 0.956, Test accuracy: 60.48
Round   8, Train loss: 0.797, Test loss: 0.879, Test accuracy: 63.05
Round   9, Train loss: 0.813, Test loss: 0.909, Test accuracy: 61.20
Round  10, Train loss: 0.759, Test loss: 0.852, Test accuracy: 65.02
Round  11, Train loss: 0.787, Test loss: 0.710, Test accuracy: 68.33
Round  12, Train loss: 0.701, Test loss: 0.709, Test accuracy: 68.75
Round  13, Train loss: 0.681, Test loss: 0.696, Test accuracy: 70.15
Round  14, Train loss: 0.755, Test loss: 0.684, Test accuracy: 70.50
Round  15, Train loss: 0.719, Test loss: 0.680, Test accuracy: 70.53
Round  16, Train loss: 0.695, Test loss: 0.663, Test accuracy: 71.83
Round  17, Train loss: 0.738, Test loss: 0.645, Test accuracy: 72.83
Round  18, Train loss: 0.682, Test loss: 0.645, Test accuracy: 72.57
Round  19, Train loss: 0.686, Test loss: 0.642, Test accuracy: 73.62
Round  20, Train loss: 0.737, Test loss: 0.614, Test accuracy: 74.75
Round  21, Train loss: 0.637, Test loss: 0.613, Test accuracy: 74.43
Round  22, Train loss: 0.647, Test loss: 0.615, Test accuracy: 73.90
Round  23, Train loss: 0.693, Test loss: 0.602, Test accuracy: 74.30
Round  24, Train loss: 0.657, Test loss: 0.594, Test accuracy: 75.18
Round  25, Train loss: 0.634, Test loss: 0.591, Test accuracy: 75.62
Round  26, Train loss: 0.649, Test loss: 0.588, Test accuracy: 75.28
Round  27, Train loss: 0.695, Test loss: 0.581, Test accuracy: 75.72
Round  28, Train loss: 0.672, Test loss: 0.578, Test accuracy: 75.88
Round  29, Train loss: 0.587, Test loss: 0.574, Test accuracy: 75.90
Round  30, Train loss: 0.672, Test loss: 0.571, Test accuracy: 76.90
Round  31, Train loss: 0.682, Test loss: 0.560, Test accuracy: 77.35
Round  32, Train loss: 0.591, Test loss: 0.550, Test accuracy: 77.80
Round  33, Train loss: 0.571, Test loss: 0.542, Test accuracy: 78.00
Round  34, Train loss: 0.585, Test loss: 0.542, Test accuracy: 78.17
Round  35, Train loss: 0.659, Test loss: 0.538, Test accuracy: 77.85
Round  36, Train loss: 0.578, Test loss: 0.533, Test accuracy: 78.43
Round  37, Train loss: 0.525, Test loss: 0.520, Test accuracy: 79.35
Round  38, Train loss: 0.581, Test loss: 0.515, Test accuracy: 79.40
Round  39, Train loss: 0.442, Test loss: 0.511, Test accuracy: 79.07
Round  40, Train loss: 0.473, Test loss: 0.521, Test accuracy: 79.07
Round  41, Train loss: 0.589, Test loss: 0.514, Test accuracy: 79.60
Round  42, Train loss: 0.575, Test loss: 0.505, Test accuracy: 79.62
Round  43, Train loss: 0.502, Test loss: 0.500, Test accuracy: 79.55
Round  44, Train loss: 0.497, Test loss: 0.497, Test accuracy: 80.15
Round  45, Train loss: 0.471, Test loss: 0.495, Test accuracy: 79.87
Round  46, Train loss: 0.538, Test loss: 0.483, Test accuracy: 80.98
Round  47, Train loss: 0.399, Test loss: 0.489, Test accuracy: 80.25
Round  48, Train loss: 0.461, Test loss: 0.497, Test accuracy: 79.98
Round  49, Train loss: 0.491, Test loss: 0.485, Test accuracy: 80.32
Round  50, Train loss: 0.532, Test loss: 0.477, Test accuracy: 80.45
Round  51, Train loss: 0.572, Test loss: 0.477, Test accuracy: 80.65
Round  52, Train loss: 0.427, Test loss: 0.471, Test accuracy: 81.08
Round  53, Train loss: 0.463, Test loss: 0.467, Test accuracy: 81.10
Round  54, Train loss: 0.370, Test loss: 0.465, Test accuracy: 81.03
Round  55, Train loss: 0.506, Test loss: 0.466, Test accuracy: 80.73
Round  56, Train loss: 0.432, Test loss: 0.462, Test accuracy: 80.92
Round  57, Train loss: 0.423, Test loss: 0.467, Test accuracy: 80.82
Round  58, Train loss: 0.512, Test loss: 0.459, Test accuracy: 81.82
Round  59, Train loss: 0.383, Test loss: 0.453, Test accuracy: 81.98
Round  60, Train loss: 0.431, Test loss: 0.459, Test accuracy: 81.37
Round  61, Train loss: 0.436, Test loss: 0.458, Test accuracy: 81.27
Round  62, Train loss: 0.427, Test loss: 0.454, Test accuracy: 81.93
Round  63, Train loss: 0.405, Test loss: 0.463, Test accuracy: 81.77
Round  64, Train loss: 0.383, Test loss: 0.459, Test accuracy: 81.77
Round  65, Train loss: 0.448, Test loss: 0.451, Test accuracy: 81.88
Round  66, Train loss: 0.370, Test loss: 0.459, Test accuracy: 81.67
Round  67, Train loss: 0.389, Test loss: 0.457, Test accuracy: 82.30
Round  68, Train loss: 0.443, Test loss: 0.459, Test accuracy: 81.78
Round  69, Train loss: 0.352, Test loss: 0.450, Test accuracy: 82.47
Round  70, Train loss: 0.438, Test loss: 0.450, Test accuracy: 82.38
Round  71, Train loss: 0.426, Test loss: 0.447, Test accuracy: 82.42
Round  72, Train loss: 0.329, Test loss: 0.442, Test accuracy: 82.63
Round  73, Train loss: 0.358, Test loss: 0.445, Test accuracy: 82.73
Round  74, Train loss: 0.381, Test loss: 0.439, Test accuracy: 82.93
Round  75, Train loss: 0.381, Test loss: 0.443, Test accuracy: 82.63
Round  76, Train loss: 0.375, Test loss: 0.443, Test accuracy: 82.48
Round  77, Train loss: 0.288, Test loss: 0.450, Test accuracy: 82.33
Round  78, Train loss: 0.367, Test loss: 0.440, Test accuracy: 82.95
Round  79, Train loss: 0.447, Test loss: 0.436, Test accuracy: 83.18
Round  80, Train loss: 0.473, Test loss: 0.433, Test accuracy: 82.97
Round  81, Train loss: 0.372, Test loss: 0.430, Test accuracy: 83.05
Round  82, Train loss: 0.368, Test loss: 0.426, Test accuracy: 83.43
Round  83, Train loss: 0.410, Test loss: 0.432, Test accuracy: 83.33
Round  84, Train loss: 0.324, Test loss: 0.432, Test accuracy: 83.05
Round  85, Train loss: 0.298, Test loss: 0.422, Test accuracy: 83.27
Round  86, Train loss: 0.364, Test loss: 0.433, Test accuracy: 83.33
Round  87, Train loss: 0.412, Test loss: 0.432, Test accuracy: 83.38
Round  88, Train loss: 0.265, Test loss: 0.432, Test accuracy: 82.72
Round  89, Train loss: 0.237, Test loss: 0.432, Test accuracy: 83.12
Round  90, Train loss: 0.463, Test loss: 0.430, Test accuracy: 83.00
Round  91, Train loss: 0.394, Test loss: 0.424, Test accuracy: 83.25
Round  92, Train loss: 0.327, Test loss: 0.423, Test accuracy: 83.42
Round  93, Train loss: 0.302, Test loss: 0.432, Test accuracy: 83.28
Round  94, Train loss: 0.402, Test loss: 0.429, Test accuracy: 83.07
Round  95, Train loss: 0.356, Test loss: 0.433, Test accuracy: 83.00
Round  96, Train loss: 0.254, Test loss: 0.436, Test accuracy: 83.02
Round  97, Train loss: 0.326, Test loss: 0.435, Test accuracy: 82.80
Round  98, Train loss: 0.359, Test loss: 0.431, Test accuracy: 83.33
Round  99, Train loss: 0.326, Test loss: 0.430, Test accuracy: 83.05
Final Round, Train loss: 0.286, Test loss: 0.425, Test accuracy: 83.58
Average accuracy final 10 rounds: 83.12166666666667
726.9952964782715
[1.2128562927246094, 2.1342148780822754, 3.053088665008545, 3.944716215133667, 4.807667016983032, 5.671168327331543, 6.50951886177063, 7.371537685394287, 8.229909658432007, 9.140159606933594, 10.03217363357544, 10.891958713531494, 11.832167625427246, 12.72402310371399, 13.597792387008667, 14.451124906539917, 15.316328763961792, 16.17243528366089, 17.04262089729309, 17.888628005981445, 18.742550373077393, 19.660767793655396, 20.56058955192566, 21.440252780914307, 22.345160722732544, 23.268324851989746, 24.168413639068604, 25.009807109832764, 25.82912516593933, 26.68221378326416, 27.546531915664673, 28.410890817642212, 29.306641101837158, 30.221874713897705, 31.096596240997314, 32.01293587684631, 32.91669845581055, 33.80581593513489, 34.68968391418457, 35.548673152923584, 36.39541149139404, 37.23136353492737, 38.08527112007141, 38.94329810142517, 39.79828500747681, 40.68451499938965, 41.59070611000061, 42.510700702667236, 43.43348479270935, 44.303709506988525, 45.14748215675354, 46.00680589675903, 46.86724829673767, 47.71324825286865, 48.57026195526123, 49.439905405044556, 50.34970450401306, 51.251734256744385, 52.138336420059204, 53.069257974624634, 53.9913969039917, 54.87312340736389, 55.71333193778992, 56.5700945854187, 57.43261957168579, 58.29945969581604, 59.15752363204956, 60.062894344329834, 60.991750955581665, 61.916959285736084, 62.78289318084717, 63.68963122367859, 64.62231779098511, 65.49639654159546, 66.33264207839966, 67.19988584518433, 68.07071328163147, 68.93126392364502, 69.78735399246216, 70.66183710098267, 71.58349275588989, 72.50922346115112, 73.41193985939026, 74.30973196029663, 75.19557881355286, 76.05997252464294, 76.92381477355957, 77.77275085449219, 78.62643337249756, 79.48244857788086, 80.34753632545471, 81.22663593292236, 82.13437986373901, 83.05519890785217, 83.96002984046936, 84.86458039283752, 85.75085210800171, 86.6084668636322, 87.47328424453735, 88.32900905609131, 89.70221185684204]
[22.866666666666667, 36.1, 35.766666666666666, 47.05, 52.266666666666666, 54.266666666666666, 56.833333333333336, 60.483333333333334, 63.05, 61.2, 65.01666666666667, 68.33333333333333, 68.75, 70.15, 70.5, 70.53333333333333, 71.83333333333333, 72.83333333333333, 72.56666666666666, 73.61666666666666, 74.75, 74.43333333333334, 73.9, 74.3, 75.18333333333334, 75.61666666666666, 75.28333333333333, 75.71666666666667, 75.88333333333334, 75.9, 76.9, 77.35, 77.8, 78.0, 78.16666666666667, 77.85, 78.43333333333334, 79.35, 79.4, 79.06666666666666, 79.06666666666666, 79.6, 79.61666666666666, 79.55, 80.15, 79.86666666666666, 80.98333333333333, 80.25, 79.98333333333333, 80.31666666666666, 80.45, 80.65, 81.08333333333333, 81.1, 81.03333333333333, 80.73333333333333, 80.91666666666667, 80.81666666666666, 81.81666666666666, 81.98333333333333, 81.36666666666666, 81.26666666666667, 81.93333333333334, 81.76666666666667, 81.76666666666667, 81.88333333333334, 81.66666666666667, 82.3, 81.78333333333333, 82.46666666666667, 82.38333333333334, 82.41666666666667, 82.63333333333334, 82.73333333333333, 82.93333333333334, 82.63333333333334, 82.48333333333333, 82.33333333333333, 82.95, 83.18333333333334, 82.96666666666667, 83.05, 83.43333333333334, 83.33333333333333, 83.05, 83.26666666666667, 83.33333333333333, 83.38333333333334, 82.71666666666667, 83.11666666666666, 83.0, 83.25, 83.41666666666667, 83.28333333333333, 83.06666666666666, 83.0, 83.01666666666667, 82.8, 83.33333333333333, 83.05, 83.58333333333333]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  10.0000
Round 1 global test acc  18.1600
Round 2 global test acc  18.8400
Round 3 global test acc  10.4100
Round 4 global test acc  20.4600
Round 5 global test acc  24.3100
Round 6 global test acc  26.5600
Round 7 global test acc  25.2600
Round 8 global test acc  27.1500
Round 9 global test acc  25.4500
Round 10 global test acc  26.6200
Round 11 global test acc  19.8500
Round 12 global test acc  20.4800
Round 13 global test acc  20.8200
Round 14 global test acc  29.3800
Round 15 global test acc  29.1800
Round 16 global test acc  25.4200
Round 17 global test acc  19.0600
Round 18 global test acc  23.7100
Round 19 global test acc  29.8600
Round 20 global test acc  26.9700
Round 21 global test acc  32.0900
Round 22 global test acc  22.7200
Round 23 global test acc  22.0000
Round 24 global test acc  33.2900
Round 25 global test acc  31.5000
Round 26 global test acc  23.2500
Round 27 global test acc  32.7300
Round 28 global test acc  25.6000
Round 29 global test acc  34.3700
Round 30 global test acc  29.9300
Round 31 global test acc  35.8500
Round 32 global test acc  34.5900
Round 33 global test acc  32.9500
Round 34 global test acc  31.5700
Round 35 global test acc  28.0500
Round 36 global test acc  24.3300
Round 37 global test acc  34.6400
Round 38 global test acc  34.7300
Round 39 global test acc  31.6200
Round 40 global test acc  24.8400
Round 41 global test acc  28.6600
Round 42 global test acc  27.1500
Round 43 global test acc  28.9600
Round 44 global test acc  26.4800
Round 45 global test acc  32.3600
Round 46 global test acc  26.8800
Round 47 global test acc  23.3900
Round 48 global test acc  35.8700
Round 49 global test acc  29.2800
Round 50 global test acc  29.7200
Round 51 global test acc  27.3500
Round 52 global test acc  36.5500
Round 53 global test acc  27.9700
Round 54 global test acc  29.5100
Round 55 global test acc  27.7300
Round 56 global test acc  29.2000
Round 57 global test acc  33.0100
Round 58 global test acc  35.8800
Round 59 global test acc  31.6800
Round 60 global test acc  30.9900
Round 61 global test acc  37.6100
Round 62 global test acc  36.1700
Round 63 global test acc  38.1100
Round 64 global test acc  27.4900
Round 65 global test acc  27.1300
Round 66 global test acc  40.0000
Round 67 global test acc  33.8300
Round 68 global test acc  33.6700
Round 69 global test acc  28.1400
Round 70 global test acc  33.5200
Round 71 global test acc  29.6400
Round 72 global test acc  27.1200
Round 73 global test acc  27.9200
Round 74 global test acc  31.4900
Round 75 global test acc  32.3200
Round 76 global test acc  36.2800
Round 77 global test acc  29.3200
Round 78 global test acc  31.0600
Round 79 global test acc  29.9600
Round 80 global test acc  25.7000
Round 81 global test acc  25.5100
Round 82 global test acc  22.9200
Round 83 global test acc  20.3500
Round 84 global test acc  19.0600
Round 85 global test acc  16.0400
Round 86 global test acc  14.4100
Round 87 global test acc  12.8300
Round 88 global test acc  12.2700
Round 89 global test acc  10.2500
Round 90 global test acc  10.3800
Round 91 global test acc  10.0000
Round 92 global test acc  10.0000
Round 93 global test acc  10.0000
Round 94 global test acc  10.0000
Round 95 global test acc  10.0000
Round 96 global test acc  10.0100
Round 97 global test acc  10.0000
Round 98 global test acc  10.0000
Round 99 global test acc  10.0000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.668, Test loss: 2.106, Test accuracy: 18.92
Round   1, Train loss: 1.129, Test loss: 1.677, Test accuracy: 37.08
Round   2, Train loss: 1.038, Test loss: 1.606, Test accuracy: 40.83
Round   3, Train loss: 0.943, Test loss: 1.223, Test accuracy: 49.33
Round   4, Train loss: 0.812, Test loss: 1.028, Test accuracy: 54.87
Round   5, Train loss: 0.926, Test loss: 1.056, Test accuracy: 56.82
Round   6, Train loss: 0.854, Test loss: 0.969, Test accuracy: 57.40
Round   7, Train loss: 0.772, Test loss: 0.894, Test accuracy: 61.18
Round   8, Train loss: 0.718, Test loss: 0.839, Test accuracy: 63.85
Round   9, Train loss: 0.789, Test loss: 0.858, Test accuracy: 62.08
Round  10, Train loss: 0.736, Test loss: 0.813, Test accuracy: 65.08
Round  11, Train loss: 0.717, Test loss: 0.681, Test accuracy: 69.78
Round  12, Train loss: 0.693, Test loss: 0.668, Test accuracy: 70.32
Round  13, Train loss: 0.623, Test loss: 0.658, Test accuracy: 71.20
Round  14, Train loss: 0.701, Test loss: 0.652, Test accuracy: 71.72
Round  15, Train loss: 0.667, Test loss: 0.632, Test accuracy: 72.48
Round  16, Train loss: 0.634, Test loss: 0.625, Test accuracy: 72.92
Round  17, Train loss: 0.732, Test loss: 0.617, Test accuracy: 73.42
Round  18, Train loss: 0.625, Test loss: 0.607, Test accuracy: 74.00
Round  19, Train loss: 0.685, Test loss: 0.609, Test accuracy: 74.28
Round  20, Train loss: 0.683, Test loss: 0.601, Test accuracy: 74.53
Round  21, Train loss: 0.539, Test loss: 0.585, Test accuracy: 75.15
Round  22, Train loss: 0.646, Test loss: 0.587, Test accuracy: 75.37
Round  23, Train loss: 0.585, Test loss: 0.588, Test accuracy: 75.75
Round  24, Train loss: 0.661, Test loss: 0.581, Test accuracy: 76.05
Round  25, Train loss: 0.591, Test loss: 0.579, Test accuracy: 75.82
Round  26, Train loss: 0.641, Test loss: 0.586, Test accuracy: 75.68
Round  27, Train loss: 0.688, Test loss: 0.569, Test accuracy: 76.27
Round  28, Train loss: 0.671, Test loss: 0.563, Test accuracy: 76.05
Round  29, Train loss: 0.588, Test loss: 0.555, Test accuracy: 76.27
Round  30, Train loss: 0.575, Test loss: 0.546, Test accuracy: 76.92
Round  31, Train loss: 0.582, Test loss: 0.536, Test accuracy: 77.68
Round  32, Train loss: 0.545, Test loss: 0.538, Test accuracy: 77.45
Round  33, Train loss: 0.525, Test loss: 0.534, Test accuracy: 77.83
Round  34, Train loss: 0.547, Test loss: 0.523, Test accuracy: 78.03
Round  35, Train loss: 0.604, Test loss: 0.518, Test accuracy: 78.77
Round  36, Train loss: 0.522, Test loss: 0.520, Test accuracy: 78.77
Round  37, Train loss: 0.542, Test loss: 0.521, Test accuracy: 78.45
Round  38, Train loss: 0.581, Test loss: 0.518, Test accuracy: 78.90
Round  39, Train loss: 0.456, Test loss: 0.505, Test accuracy: 79.38
Round  40, Train loss: 0.475, Test loss: 0.504, Test accuracy: 79.40
Round  41, Train loss: 0.495, Test loss: 0.498, Test accuracy: 79.68
Round  42, Train loss: 0.576, Test loss: 0.489, Test accuracy: 80.10
Round  43, Train loss: 0.461, Test loss: 0.491, Test accuracy: 79.87
Round  44, Train loss: 0.502, Test loss: 0.491, Test accuracy: 80.30
Round  45, Train loss: 0.438, Test loss: 0.488, Test accuracy: 80.15
Round  46, Train loss: 0.490, Test loss: 0.482, Test accuracy: 80.40
Round  47, Train loss: 0.405, Test loss: 0.487, Test accuracy: 80.30
Round  48, Train loss: 0.474, Test loss: 0.479, Test accuracy: 80.80
Round  49, Train loss: 0.483, Test loss: 0.475, Test accuracy: 80.78
Round  50, Train loss: 0.499, Test loss: 0.468, Test accuracy: 81.12
Round  51, Train loss: 0.528, Test loss: 0.471, Test accuracy: 80.88
Round  52, Train loss: 0.429, Test loss: 0.465, Test accuracy: 81.52
Round  53, Train loss: 0.483, Test loss: 0.460, Test accuracy: 81.98
Round  54, Train loss: 0.375, Test loss: 0.461, Test accuracy: 81.75
Round  55, Train loss: 0.469, Test loss: 0.468, Test accuracy: 81.10
Round  56, Train loss: 0.401, Test loss: 0.455, Test accuracy: 81.58
Round  57, Train loss: 0.418, Test loss: 0.460, Test accuracy: 80.92
Round  58, Train loss: 0.510, Test loss: 0.448, Test accuracy: 81.62
Round  59, Train loss: 0.379, Test loss: 0.451, Test accuracy: 81.45
Round  60, Train loss: 0.384, Test loss: 0.442, Test accuracy: 81.63
Round  61, Train loss: 0.441, Test loss: 0.446, Test accuracy: 81.25
Round  62, Train loss: 0.419, Test loss: 0.441, Test accuracy: 82.05
Round  63, Train loss: 0.355, Test loss: 0.454, Test accuracy: 81.63
Round  64, Train loss: 0.386, Test loss: 0.441, Test accuracy: 82.00
Round  65, Train loss: 0.404, Test loss: 0.440, Test accuracy: 82.42
Round  66, Train loss: 0.381, Test loss: 0.442, Test accuracy: 82.03
Round  67, Train loss: 0.349, Test loss: 0.444, Test accuracy: 81.93
Round  68, Train loss: 0.445, Test loss: 0.434, Test accuracy: 82.13
Round  69, Train loss: 0.360, Test loss: 0.426, Test accuracy: 83.17
Round  70, Train loss: 0.391, Test loss: 0.425, Test accuracy: 83.43
Round  71, Train loss: 0.414, Test loss: 0.427, Test accuracy: 83.20
Round  72, Train loss: 0.346, Test loss: 0.427, Test accuracy: 82.83
Round  73, Train loss: 0.383, Test loss: 0.425, Test accuracy: 83.37
Round  74, Train loss: 0.387, Test loss: 0.427, Test accuracy: 83.38
Round  75, Train loss: 0.394, Test loss: 0.431, Test accuracy: 83.20
Round  76, Train loss: 0.379, Test loss: 0.424, Test accuracy: 83.40
Round  77, Train loss: 0.288, Test loss: 0.419, Test accuracy: 83.58
Round  78, Train loss: 0.370, Test loss: 0.418, Test accuracy: 83.58
Round  79, Train loss: 0.394, Test loss: 0.419, Test accuracy: 83.43
Round  80, Train loss: 0.372, Test loss: 0.421, Test accuracy: 83.48
Round  81, Train loss: 0.335, Test loss: 0.415, Test accuracy: 83.78
Round  82, Train loss: 0.373, Test loss: 0.417, Test accuracy: 83.48
Round  83, Train loss: 0.373, Test loss: 0.410, Test accuracy: 84.02
Round  84, Train loss: 0.275, Test loss: 0.407, Test accuracy: 84.45
Round  85, Train loss: 0.256, Test loss: 0.415, Test accuracy: 83.98
Round  86, Train loss: 0.337, Test loss: 0.409, Test accuracy: 83.95
Round  87, Train loss: 0.328, Test loss: 0.416, Test accuracy: 83.27
Round  88, Train loss: 0.276, Test loss: 0.410, Test accuracy: 84.07
Round  89, Train loss: 0.247, Test loss: 0.411, Test accuracy: 83.97
Round  90, Train loss: 0.417, Test loss: 0.403, Test accuracy: 84.38
Round  91, Train loss: 0.305, Test loss: 0.408, Test accuracy: 83.97
Round  92, Train loss: 0.325, Test loss: 0.403, Test accuracy: 83.82
Round  93, Train loss: 0.271, Test loss: 0.405, Test accuracy: 83.85
Round  94, Train loss: 0.324, Test loss: 0.405, Test accuracy: 83.92
Round  95, Train loss: 0.323, Test loss: 0.405, Test accuracy: 83.93
Round  96, Train loss: 0.263, Test loss: 0.411, Test accuracy: 84.15
Round  97, Train loss: 0.281, Test loss: 0.414, Test accuracy: 83.82
Round  98, Train loss: 0.326, Test loss: 0.406, Test accuracy: 84.38
Round  99, Train loss: 0.327, Test loss: 0.406, Test accuracy: 84.13
Final Round, Train loss: 0.264, Test loss: 0.399, Test accuracy: 84.72
Average accuracy final 10 rounds: 84.035
729.7575988769531
[1.1827232837677002, 2.0891852378845215, 2.998194694519043, 3.901333808898926, 4.7970476150512695, 5.708315372467041, 6.619365692138672, 7.5232579708099365, 8.354253053665161, 9.1904935836792, 10.048030853271484, 10.90895962715149, 11.741483926773071, 12.585875272750854, 13.490778923034668, 14.397704601287842, 15.299779891967773, 16.197638750076294, 17.095564603805542, 17.976171493530273, 18.81537413597107, 19.65724754333496, 20.515175342559814, 21.374706745147705, 22.210768461227417, 23.12806749343872, 24.034045696258545, 24.903205394744873, 25.779253244400024, 26.701739072799683, 27.624544620513916, 28.501976251602173, 29.32706093788147, 30.182387828826904, 31.041218757629395, 31.902690887451172, 32.75375509262085, 33.649577617645264, 34.53672814369202, 35.430031538009644, 36.32077169418335, 37.20875883102417, 38.08661651611328, 38.93763732910156, 39.79916572570801, 40.67432737350464, 41.53648924827576, 42.37228584289551, 43.24069166183472, 44.139824867248535, 45.07538676261902, 45.9665961265564, 46.88374733924866, 47.788124084472656, 48.684383392333984, 49.52093505859375, 50.37849473953247, 51.254244804382324, 52.10981345176697, 52.94957733154297, 53.8384428024292, 54.75159978866577, 55.66910171508789, 56.56623363494873, 57.4906120300293, 58.44263792037964, 59.316826820373535, 60.18154335021973, 61.05640697479248, 61.923330783843994, 62.76647901535034, 63.63772630691528, 64.56037735939026, 65.46005940437317, 66.3529121875763, 67.24533939361572, 68.15773463249207, 69.05530738830566, 69.88725161552429, 70.73967266082764, 71.60524106025696, 72.45478391647339, 73.30475997924805, 74.16810965538025, 75.046462059021, 75.96246671676636, 76.876953125, 77.81807351112366, 78.72053980827332, 79.60226058959961, 80.46180868148804, 81.33390069007874, 82.19947695732117, 83.05369997024536, 83.92130827903748, 84.8147234916687, 85.72327136993408, 86.60521459579468, 87.52207088470459, 88.42724561691284, 89.83700895309448]
[18.916666666666668, 37.083333333333336, 40.833333333333336, 49.333333333333336, 54.86666666666667, 56.81666666666667, 57.4, 61.18333333333333, 63.85, 62.083333333333336, 65.08333333333333, 69.78333333333333, 70.31666666666666, 71.2, 71.71666666666667, 72.48333333333333, 72.91666666666667, 73.41666666666667, 74.0, 74.28333333333333, 74.53333333333333, 75.15, 75.36666666666666, 75.75, 76.05, 75.81666666666666, 75.68333333333334, 76.26666666666667, 76.05, 76.26666666666667, 76.91666666666667, 77.68333333333334, 77.45, 77.83333333333333, 78.03333333333333, 78.76666666666667, 78.76666666666667, 78.45, 78.9, 79.38333333333334, 79.4, 79.68333333333334, 80.1, 79.86666666666666, 80.3, 80.15, 80.4, 80.3, 80.8, 80.78333333333333, 81.11666666666666, 80.88333333333334, 81.51666666666667, 81.98333333333333, 81.75, 81.1, 81.58333333333333, 80.91666666666667, 81.61666666666666, 81.45, 81.63333333333334, 81.25, 82.05, 81.63333333333334, 82.0, 82.41666666666667, 82.03333333333333, 81.93333333333334, 82.13333333333334, 83.16666666666667, 83.43333333333334, 83.2, 82.83333333333333, 83.36666666666666, 83.38333333333334, 83.2, 83.4, 83.58333333333333, 83.58333333333333, 83.43333333333334, 83.48333333333333, 83.78333333333333, 83.48333333333333, 84.01666666666667, 84.45, 83.98333333333333, 83.95, 83.26666666666667, 84.06666666666666, 83.96666666666667, 84.38333333333334, 83.96666666666667, 83.81666666666666, 83.85, 83.91666666666667, 83.93333333333334, 84.15, 83.81666666666666, 84.38333333333334, 84.13333333333334, 84.71666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 12, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.736, Test loss: 2.139, Test accuracy: 19.75
Round   1, Train loss: 1.280, Test loss: 1.724, Test accuracy: 34.30
Round   2, Train loss: 1.174, Test loss: 1.677, Test accuracy: 35.58
Round   3, Train loss: 1.074, Test loss: 1.331, Test accuracy: 44.40
Round   4, Train loss: 0.950, Test loss: 1.061, Test accuracy: 54.53
Round   5, Train loss: 0.996, Test loss: 1.100, Test accuracy: 56.85
Round   6, Train loss: 0.971, Test loss: 1.045, Test accuracy: 57.27
Round   7, Train loss: 0.834, Test loss: 0.914, Test accuracy: 62.93
Round   8, Train loss: 0.739, Test loss: 0.879, Test accuracy: 63.32
Round   9, Train loss: 0.850, Test loss: 0.902, Test accuracy: 61.00
Round  10, Train loss: 0.796, Test loss: 0.848, Test accuracy: 65.33
Round  11, Train loss: 0.725, Test loss: 0.718, Test accuracy: 68.92
Round  12, Train loss: 0.760, Test loss: 0.705, Test accuracy: 70.20
Round  13, Train loss: 0.632, Test loss: 0.694, Test accuracy: 70.70
Round  14, Train loss: 0.759, Test loss: 0.677, Test accuracy: 71.57
Round  15, Train loss: 0.723, Test loss: 0.674, Test accuracy: 71.87
Round  16, Train loss: 0.639, Test loss: 0.667, Test accuracy: 72.90
Round  17, Train loss: 0.778, Test loss: 0.646, Test accuracy: 72.93
Round  18, Train loss: 0.674, Test loss: 0.643, Test accuracy: 73.13
Round  19, Train loss: 0.774, Test loss: 0.643, Test accuracy: 73.65
Round  20, Train loss: 0.691, Test loss: 0.644, Test accuracy: 73.95
Round  21, Train loss: 0.596, Test loss: 0.629, Test accuracy: 73.20
Round  22, Train loss: 0.651, Test loss: 0.624, Test accuracy: 74.53
Round  23, Train loss: 0.594, Test loss: 0.628, Test accuracy: 74.35
Round  24, Train loss: 0.710, Test loss: 0.618, Test accuracy: 74.02
Round  25, Train loss: 0.636, Test loss: 0.616, Test accuracy: 74.72
Round  26, Train loss: 0.681, Test loss: 0.609, Test accuracy: 75.72
Round  27, Train loss: 0.740, Test loss: 0.619, Test accuracy: 75.77
Round  28, Train loss: 0.721, Test loss: 0.603, Test accuracy: 76.08
Round  29, Train loss: 0.585, Test loss: 0.594, Test accuracy: 76.22
Round  30, Train loss: 0.626, Test loss: 0.580, Test accuracy: 77.27
Round  31, Train loss: 0.581, Test loss: 0.573, Test accuracy: 76.68
Round  32, Train loss: 0.586, Test loss: 0.567, Test accuracy: 76.93
Round  33, Train loss: 0.633, Test loss: 0.575, Test accuracy: 77.10
Round  34, Train loss: 0.638, Test loss: 0.562, Test accuracy: 77.42
Round  35, Train loss: 0.660, Test loss: 0.560, Test accuracy: 77.57
Round  36, Train loss: 0.627, Test loss: 0.547, Test accuracy: 78.12
Round  37, Train loss: 0.587, Test loss: 0.557, Test accuracy: 77.62
Round  38, Train loss: 0.682, Test loss: 0.541, Test accuracy: 78.38
Round  39, Train loss: 0.453, Test loss: 0.539, Test accuracy: 78.68
Round  40, Train loss: 0.482, Test loss: 0.529, Test accuracy: 78.60
Round  41, Train loss: 0.546, Test loss: 0.525, Test accuracy: 78.93
Round  42, Train loss: 0.630, Test loss: 0.524, Test accuracy: 79.07
Round  43, Train loss: 0.549, Test loss: 0.527, Test accuracy: 79.25
Round  44, Train loss: 0.599, Test loss: 0.520, Test accuracy: 79.53
Round  45, Train loss: 0.530, Test loss: 0.526, Test accuracy: 79.10
Round  46, Train loss: 0.496, Test loss: 0.519, Test accuracy: 79.58
Round  47, Train loss: 0.445, Test loss: 0.512, Test accuracy: 80.03
Round  48, Train loss: 0.558, Test loss: 0.519, Test accuracy: 80.12
Round  49, Train loss: 0.540, Test loss: 0.514, Test accuracy: 79.85
Round  50, Train loss: 0.495, Test loss: 0.513, Test accuracy: 80.65
Round  51, Train loss: 0.581, Test loss: 0.511, Test accuracy: 80.83
Round  52, Train loss: 0.485, Test loss: 0.506, Test accuracy: 80.65
Round  53, Train loss: 0.485, Test loss: 0.514, Test accuracy: 80.35
Round  54, Train loss: 0.411, Test loss: 0.504, Test accuracy: 80.63
Round  55, Train loss: 0.461, Test loss: 0.496, Test accuracy: 80.25
Round  56, Train loss: 0.438, Test loss: 0.491, Test accuracy: 81.03
Round  57, Train loss: 0.422, Test loss: 0.490, Test accuracy: 80.85
Round  58, Train loss: 0.604, Test loss: 0.485, Test accuracy: 81.00
Round  59, Train loss: 0.482, Test loss: 0.480, Test accuracy: 81.22
Round  60, Train loss: 0.396, Test loss: 0.483, Test accuracy: 81.40
Round  61, Train loss: 0.490, Test loss: 0.479, Test accuracy: 81.20
Round  62, Train loss: 0.472, Test loss: 0.482, Test accuracy: 81.50
Round  63, Train loss: 0.357, Test loss: 0.479, Test accuracy: 81.38
Round  64, Train loss: 0.479, Test loss: 0.493, Test accuracy: 81.13
Round  65, Train loss: 0.552, Test loss: 0.487, Test accuracy: 80.93
Round  66, Train loss: 0.469, Test loss: 0.482, Test accuracy: 81.57
Round  67, Train loss: 0.356, Test loss: 0.480, Test accuracy: 81.57
Round  68, Train loss: 0.453, Test loss: 0.472, Test accuracy: 81.95
Round  69, Train loss: 0.453, Test loss: 0.466, Test accuracy: 81.80
Round  70, Train loss: 0.435, Test loss: 0.465, Test accuracy: 82.23
Round  71, Train loss: 0.425, Test loss: 0.468, Test accuracy: 82.27
Round  72, Train loss: 0.375, Test loss: 0.468, Test accuracy: 82.23
Round  73, Train loss: 0.417, Test loss: 0.465, Test accuracy: 82.23
Round  74, Train loss: 0.431, Test loss: 0.466, Test accuracy: 81.88
Round  75, Train loss: 0.479, Test loss: 0.462, Test accuracy: 82.07
Round  76, Train loss: 0.417, Test loss: 0.455, Test accuracy: 82.73
Round  77, Train loss: 0.288, Test loss: 0.461, Test accuracy: 82.68
Round  78, Train loss: 0.456, Test loss: 0.456, Test accuracy: 82.68
Round  79, Train loss: 0.483, Test loss: 0.463, Test accuracy: 82.17
Round  80, Train loss: 0.430, Test loss: 0.450, Test accuracy: 82.95
Round  81, Train loss: 0.372, Test loss: 0.453, Test accuracy: 82.65
Round  82, Train loss: 0.379, Test loss: 0.449, Test accuracy: 82.78
Round  83, Train loss: 0.370, Test loss: 0.445, Test accuracy: 83.05
Round  84, Train loss: 0.273, Test loss: 0.454, Test accuracy: 82.70
Round  85, Train loss: 0.341, Test loss: 0.447, Test accuracy: 82.88
Round  86, Train loss: 0.328, Test loss: 0.451, Test accuracy: 82.53
Round  87, Train loss: 0.317, Test loss: 0.453, Test accuracy: 82.83
Round  88, Train loss: 0.267, Test loss: 0.451, Test accuracy: 82.80
Round  89, Train loss: 0.289, Test loss: 0.455, Test accuracy: 82.72
Round  90, Train loss: 0.467, Test loss: 0.457, Test accuracy: 82.45
Round  91, Train loss: 0.398, Test loss: 0.463, Test accuracy: 82.70
Round  92, Train loss: 0.332, Test loss: 0.448, Test accuracy: 83.07
Round  93, Train loss: 0.303, Test loss: 0.448, Test accuracy: 82.93
Round  94, Train loss: 0.445, Test loss: 0.455, Test accuracy: 82.98
Round  95, Train loss: 0.320, Test loss: 0.453, Test accuracy: 82.85
Round  96, Train loss: 0.294, Test loss: 0.446, Test accuracy: 83.38
Round  97, Train loss: 0.280, Test loss: 0.444, Test accuracy: 83.45
Round  98, Train loss: 0.364, Test loss: 0.445, Test accuracy: 83.08
Round  99, Train loss: 0.425, Test loss: 0.445, Test accuracy: 83.47
Final Round, Train loss: 0.303, Test loss: 0.442, Test accuracy: 83.65
Average accuracy final 10 rounds: 83.03666666666666
1313.9994549751282
[1.1721861362457275, 2.0514721870422363, 2.9764177799224854, 3.88775634765625, 4.779797315597534, 5.69297981262207, 6.616360425949097, 7.514812231063843, 8.371042251586914, 9.237110137939453, 10.111872911453247, 10.958503484725952, 11.808482646942139, 12.666887283325195, 13.56101107597351, 14.446133136749268, 15.360847473144531, 16.289510011672974, 17.211974143981934, 18.088773727416992, 18.94811463356018, 21.14021897315979, 23.22280502319336, 25.428699016571045, 27.62250018119812, 29.949624061584473, 32.24605369567871, 34.37314224243164, 36.51210594177246, 38.844420433044434, 41.131380796432495, 43.53113889694214, 45.61685061454773, 47.64903974533081, 49.85048222541809, 52.021488666534424, 54.39934158325195, 56.685983657836914, 58.8326051235199, 60.928945779800415, 63.26468348503113, 65.45525932312012, 67.80039739608765, 70.06172037124634, 72.13081121444702, 74.24574208259583, 76.51386213302612, 78.7955424785614, 81.2230498790741, 83.3594434261322, 85.39463138580322, 87.55836772918701, 89.75218629837036, 92.21983647346497, 94.52204465866089, 96.67241024971008, 98.68733954429626, 100.90485286712646, 103.04041934013367, 105.38059663772583, 107.65387558937073, 109.69788336753845, 111.80641222000122, 114.09726667404175, 116.5313549041748, 118.89493489265442, 121.18517231941223, 123.37403345108032, 125.50630569458008, 127.9056556224823, 130.2099530696869, 132.62137722969055, 134.829359292984, 136.85979533195496, 139.0555305480957, 141.28911662101746, 143.5541000366211, 145.79512977600098, 147.90176558494568, 149.9424443244934, 152.25629925727844, 154.52663230895996, 156.83293342590332, 159.08109855651855, 161.11997365951538, 163.26705360412598, 165.4908492565155, 167.71501445770264, 170.0745975971222, 172.1323709487915, 174.20546579360962, 176.25239419937134, 178.4886989593506, 180.76064038276672, 183.01090502738953, 185.16167736053467, 187.10182905197144, 189.3525791168213, 191.4574224948883, 193.8351755142212, 195.21201348304749]
[19.75, 34.3, 35.583333333333336, 44.4, 54.53333333333333, 56.85, 57.266666666666666, 62.93333333333333, 63.31666666666667, 61.0, 65.33333333333333, 68.91666666666667, 70.2, 70.7, 71.56666666666666, 71.86666666666666, 72.9, 72.93333333333334, 73.13333333333334, 73.65, 73.95, 73.2, 74.53333333333333, 74.35, 74.01666666666667, 74.71666666666667, 75.71666666666667, 75.76666666666667, 76.08333333333333, 76.21666666666667, 77.26666666666667, 76.68333333333334, 76.93333333333334, 77.1, 77.41666666666667, 77.56666666666666, 78.11666666666666, 77.61666666666666, 78.38333333333334, 78.68333333333334, 78.6, 78.93333333333334, 79.06666666666666, 79.25, 79.53333333333333, 79.1, 79.58333333333333, 80.03333333333333, 80.11666666666666, 79.85, 80.65, 80.83333333333333, 80.65, 80.35, 80.63333333333334, 80.25, 81.03333333333333, 80.85, 81.0, 81.21666666666667, 81.4, 81.2, 81.5, 81.38333333333334, 81.13333333333334, 80.93333333333334, 81.56666666666666, 81.56666666666666, 81.95, 81.8, 82.23333333333333, 82.26666666666667, 82.23333333333333, 82.23333333333333, 81.88333333333334, 82.06666666666666, 82.73333333333333, 82.68333333333334, 82.68333333333334, 82.16666666666667, 82.95, 82.65, 82.78333333333333, 83.05, 82.7, 82.88333333333334, 82.53333333333333, 82.83333333333333, 82.8, 82.71666666666667, 82.45, 82.7, 83.06666666666666, 82.93333333333334, 82.98333333333333, 82.85, 83.38333333333334, 83.45, 83.08333333333333, 83.46666666666667, 83.65]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.280, Test loss: 1.968, Test accuracy: 20.75
Round   0, Global train loss: 1.280, Global test loss: 2.327, Global test accuracy: 11.40
Round   1, Train loss: 1.106, Test loss: 1.700, Test accuracy: 37.15
Round   1, Global train loss: 1.106, Global test loss: 2.324, Global test accuracy: 19.17
Round   2, Train loss: 1.041, Test loss: 1.345, Test accuracy: 43.98
Round   2, Global train loss: 1.041, Global test loss: 2.318, Global test accuracy: 17.12
Round   3, Train loss: 1.002, Test loss: 1.127, Test accuracy: 52.98
Round   3, Global train loss: 1.002, Global test loss: 2.184, Global test accuracy: 21.83
Round   4, Train loss: 0.977, Test loss: 1.085, Test accuracy: 55.65
Round   4, Global train loss: 0.977, Global test loss: 2.370, Global test accuracy: 22.15
Round   5, Train loss: 0.867, Test loss: 0.922, Test accuracy: 59.18
Round   5, Global train loss: 0.867, Global test loss: 2.151, Global test accuracy: 23.13
Round   6, Train loss: 0.851, Test loss: 0.808, Test accuracy: 63.53
Round   6, Global train loss: 0.851, Global test loss: 2.294, Global test accuracy: 20.03
Round   7, Train loss: 0.836, Test loss: 0.792, Test accuracy: 64.63
Round   7, Global train loss: 0.836, Global test loss: 2.243, Global test accuracy: 22.08
Round   8, Train loss: 0.920, Test loss: 0.771, Test accuracy: 66.05
Round   8, Global train loss: 0.920, Global test loss: 2.161, Global test accuracy: 21.35
Round   9, Train loss: 0.829, Test loss: 0.754, Test accuracy: 67.73
Round   9, Global train loss: 0.829, Global test loss: 2.177, Global test accuracy: 21.87
Round  10, Train loss: 0.765, Test loss: 0.756, Test accuracy: 67.85
Round  10, Global train loss: 0.765, Global test loss: 2.219, Global test accuracy: 18.12
Round  11, Train loss: 0.696, Test loss: 0.760, Test accuracy: 67.32
Round  11, Global train loss: 0.696, Global test loss: 2.151, Global test accuracy: 23.92
Round  12, Train loss: 0.840, Test loss: 0.748, Test accuracy: 68.10
Round  12, Global train loss: 0.840, Global test loss: 2.161, Global test accuracy: 22.45
Round  13, Train loss: 0.766, Test loss: 0.767, Test accuracy: 67.65
Round  13, Global train loss: 0.766, Global test loss: 2.075, Global test accuracy: 21.87
Round  14, Train loss: 0.858, Test loss: 0.742, Test accuracy: 68.45
Round  14, Global train loss: 0.858, Global test loss: 2.329, Global test accuracy: 25.78
Round  15, Train loss: 0.707, Test loss: 0.739, Test accuracy: 69.10
Round  15, Global train loss: 0.707, Global test loss: 2.145, Global test accuracy: 22.70
Round  16, Train loss: 0.639, Test loss: 0.735, Test accuracy: 68.98
Round  16, Global train loss: 0.639, Global test loss: 2.412, Global test accuracy: 19.80
Round  17, Train loss: 0.688, Test loss: 0.720, Test accuracy: 69.67
Round  17, Global train loss: 0.688, Global test loss: 2.266, Global test accuracy: 23.73
Round  18, Train loss: 0.615, Test loss: 0.717, Test accuracy: 69.52
Round  18, Global train loss: 0.615, Global test loss: 2.114, Global test accuracy: 28.37
Round  19, Train loss: 0.705, Test loss: 0.706, Test accuracy: 70.62
Round  19, Global train loss: 0.705, Global test loss: 2.186, Global test accuracy: 27.98
Round  20, Train loss: 0.705, Test loss: 0.691, Test accuracy: 71.38
Round  20, Global train loss: 0.705, Global test loss: 2.198, Global test accuracy: 18.20
Round  21, Train loss: 0.621, Test loss: 0.690, Test accuracy: 71.32
Round  21, Global train loss: 0.621, Global test loss: 2.244, Global test accuracy: 21.63
Round  22, Train loss: 0.580, Test loss: 0.678, Test accuracy: 71.17
Round  22, Global train loss: 0.580, Global test loss: 2.046, Global test accuracy: 26.20
Round  23, Train loss: 0.619, Test loss: 0.670, Test accuracy: 71.55
Round  23, Global train loss: 0.619, Global test loss: 2.220, Global test accuracy: 23.97
Round  24, Train loss: 0.600, Test loss: 0.685, Test accuracy: 70.95
Round  24, Global train loss: 0.600, Global test loss: 2.029, Global test accuracy: 24.30
Round  25, Train loss: 0.622, Test loss: 0.677, Test accuracy: 71.78
Round  25, Global train loss: 0.622, Global test loss: 2.123, Global test accuracy: 27.93
Round  26, Train loss: 0.475, Test loss: 0.671, Test accuracy: 72.18
Round  26, Global train loss: 0.475, Global test loss: 2.050, Global test accuracy: 26.77
Round  27, Train loss: 0.550, Test loss: 0.685, Test accuracy: 72.03
Round  27, Global train loss: 0.550, Global test loss: 2.114, Global test accuracy: 30.53
Round  28, Train loss: 0.544, Test loss: 0.673, Test accuracy: 72.67
Round  28, Global train loss: 0.544, Global test loss: 2.259, Global test accuracy: 17.85
Round  29, Train loss: 0.607, Test loss: 0.693, Test accuracy: 71.93
Round  29, Global train loss: 0.607, Global test loss: 2.167, Global test accuracy: 29.67
Round  30, Train loss: 0.600, Test loss: 0.680, Test accuracy: 72.45
Round  30, Global train loss: 0.600, Global test loss: 2.212, Global test accuracy: 23.90
Round  31, Train loss: 0.474, Test loss: 0.692, Test accuracy: 72.05
Round  31, Global train loss: 0.474, Global test loss: 2.266, Global test accuracy: 23.25
Round  32, Train loss: 0.495, Test loss: 0.675, Test accuracy: 72.98
Round  32, Global train loss: 0.495, Global test loss: 2.160, Global test accuracy: 22.58
Round  33, Train loss: 0.637, Test loss: 0.664, Test accuracy: 73.70
Round  33, Global train loss: 0.637, Global test loss: 2.184, Global test accuracy: 23.53
Round  34, Train loss: 0.566, Test loss: 0.667, Test accuracy: 73.85
Round  34, Global train loss: 0.566, Global test loss: 2.537, Global test accuracy: 25.28
Round  35, Train loss: 0.345, Test loss: 0.670, Test accuracy: 73.88
Round  35, Global train loss: 0.345, Global test loss: 2.125, Global test accuracy: 25.10
Round  36, Train loss: 0.483, Test loss: 0.674, Test accuracy: 73.18
Round  36, Global train loss: 0.483, Global test loss: 2.125, Global test accuracy: 26.67
Round  37, Train loss: 0.493, Test loss: 0.690, Test accuracy: 72.65
Round  37, Global train loss: 0.493, Global test loss: 2.173, Global test accuracy: 26.58
Round  38, Train loss: 0.467, Test loss: 0.706, Test accuracy: 72.08
Round  38, Global train loss: 0.467, Global test loss: 2.064, Global test accuracy: 25.87
Round  39, Train loss: 0.433, Test loss: 0.706, Test accuracy: 72.02
Round  39, Global train loss: 0.433, Global test loss: 2.038, Global test accuracy: 30.73
Round  40, Train loss: 0.463, Test loss: 0.701, Test accuracy: 72.52
Round  40, Global train loss: 0.463, Global test loss: 2.287, Global test accuracy: 27.85
Round  41, Train loss: 0.469, Test loss: 0.710, Test accuracy: 73.13
Round  41, Global train loss: 0.469, Global test loss: 2.023, Global test accuracy: 32.47
Round  42, Train loss: 0.460, Test loss: 0.729, Test accuracy: 72.87
Round  42, Global train loss: 0.460, Global test loss: 2.231, Global test accuracy: 24.02
Round  43, Train loss: 0.465, Test loss: 0.726, Test accuracy: 72.75
Round  43, Global train loss: 0.465, Global test loss: 2.000, Global test accuracy: 31.92
Round  44, Train loss: 0.451, Test loss: 0.723, Test accuracy: 73.33
Round  44, Global train loss: 0.451, Global test loss: 2.162, Global test accuracy: 19.95
Round  45, Train loss: 0.370, Test loss: 0.746, Test accuracy: 72.82
Round  45, Global train loss: 0.370, Global test loss: 2.042, Global test accuracy: 33.57
Round  46, Train loss: 0.515, Test loss: 0.732, Test accuracy: 72.92
Round  46, Global train loss: 0.515, Global test loss: 2.147, Global test accuracy: 23.08
Round  47, Train loss: 0.470, Test loss: 0.732, Test accuracy: 73.27
Round  47, Global train loss: 0.470, Global test loss: 2.168, Global test accuracy: 18.88
Round  48, Train loss: 0.460, Test loss: 0.733, Test accuracy: 73.12
Round  48, Global train loss: 0.460, Global test loss: 2.106, Global test accuracy: 32.90
Round  49, Train loss: 0.417, Test loss: 0.752, Test accuracy: 72.85
Round  49, Global train loss: 0.417, Global test loss: 2.149, Global test accuracy: 20.05
Round  50, Train loss: 0.377, Test loss: 0.718, Test accuracy: 73.68
Round  50, Global train loss: 0.377, Global test loss: 2.016, Global test accuracy: 30.23
Round  51, Train loss: 0.413, Test loss: 0.730, Test accuracy: 73.15
Round  51, Global train loss: 0.413, Global test loss: 2.179, Global test accuracy: 20.10
Round  52, Train loss: 0.386, Test loss: 0.751, Test accuracy: 73.08
Round  52, Global train loss: 0.386, Global test loss: 2.071, Global test accuracy: 29.53
Round  53, Train loss: 0.343, Test loss: 0.741, Test accuracy: 73.42
Round  53, Global train loss: 0.343, Global test loss: 2.153, Global test accuracy: 28.30
Round  54, Train loss: 0.360, Test loss: 0.759, Test accuracy: 73.12
Round  54, Global train loss: 0.360, Global test loss: 2.145, Global test accuracy: 31.18
Round  55, Train loss: 0.250, Test loss: 0.772, Test accuracy: 73.00
Round  55, Global train loss: 0.250, Global test loss: 2.010, Global test accuracy: 29.03
Round  56, Train loss: 0.289, Test loss: 0.795, Test accuracy: 72.33
Round  56, Global train loss: 0.289, Global test loss: 2.137, Global test accuracy: 20.60
Round  57, Train loss: 0.355, Test loss: 0.802, Test accuracy: 72.32
Round  57, Global train loss: 0.355, Global test loss: 2.129, Global test accuracy: 16.22
Round  58, Train loss: 0.327, Test loss: 0.842, Test accuracy: 72.18
Round  58, Global train loss: 0.327, Global test loss: 2.177, Global test accuracy: 21.02
Round  59, Train loss: 0.278, Test loss: 0.841, Test accuracy: 73.18
Round  59, Global train loss: 0.278, Global test loss: 2.215, Global test accuracy: 24.97
Round  60, Train loss: 0.357, Test loss: 0.876, Test accuracy: 72.65
Round  60, Global train loss: 0.357, Global test loss: 2.050, Global test accuracy: 26.68
Round  61, Train loss: 0.297, Test loss: 0.875, Test accuracy: 72.95
Round  61, Global train loss: 0.297, Global test loss: 2.235, Global test accuracy: 11.38
Round  62, Train loss: 0.288, Test loss: 0.899, Test accuracy: 72.08
Round  62, Global train loss: 0.288, Global test loss: 2.225, Global test accuracy: 20.52
Round  63, Train loss: 0.188, Test loss: 0.897, Test accuracy: 72.35
Round  63, Global train loss: 0.188, Global test loss: 2.015, Global test accuracy: 30.03
Round  64, Train loss: 0.307, Test loss: 0.886, Test accuracy: 72.82
Round  64, Global train loss: 0.307, Global test loss: 2.289, Global test accuracy: 25.48
Round  65, Train loss: 0.229, Test loss: 0.879, Test accuracy: 72.92
Round  65, Global train loss: 0.229, Global test loss: 2.062, Global test accuracy: 28.37
Round  66, Train loss: 0.233, Test loss: 0.890, Test accuracy: 73.12
Round  66, Global train loss: 0.233, Global test loss: 2.125, Global test accuracy: 20.80
Round  67, Train loss: 0.320, Test loss: 0.891, Test accuracy: 73.35
Round  67, Global train loss: 0.320, Global test loss: 2.103, Global test accuracy: 24.35
Round  68, Train loss: 0.257, Test loss: 0.928, Test accuracy: 72.90
Round  68, Global train loss: 0.257, Global test loss: 1.985, Global test accuracy: 30.48
Round  69, Train loss: 0.263, Test loss: 0.930, Test accuracy: 72.87
Round  69, Global train loss: 0.263, Global test loss: 2.129, Global test accuracy: 20.25
Round  70, Train loss: 0.227, Test loss: 0.947, Test accuracy: 72.85
Round  70, Global train loss: 0.227, Global test loss: 2.197, Global test accuracy: 20.43
Round  71, Train loss: 0.239, Test loss: 0.971, Test accuracy: 72.38
Round  71, Global train loss: 0.239, Global test loss: 2.165, Global test accuracy: 22.73
Round  72, Train loss: 0.185, Test loss: 0.989, Test accuracy: 72.27
Round  72, Global train loss: 0.185, Global test loss: 2.054, Global test accuracy: 30.95
Round  73, Train loss: 0.227, Test loss: 0.988, Test accuracy: 72.33
Round  73, Global train loss: 0.227, Global test loss: 1.975, Global test accuracy: 32.88
Round  74, Train loss: 0.151, Test loss: 1.032, Test accuracy: 71.98
Round  74, Global train loss: 0.151, Global test loss: 2.104, Global test accuracy: 26.68
Round  75, Train loss: 0.197, Test loss: 1.023, Test accuracy: 72.17
Round  75, Global train loss: 0.197, Global test loss: 2.064, Global test accuracy: 27.90
Round  76, Train loss: 0.216, Test loss: 1.015, Test accuracy: 72.58
Round  76, Global train loss: 0.216, Global test loss: 2.015, Global test accuracy: 30.25
Round  77, Train loss: 0.191, Test loss: 1.021, Test accuracy: 72.43
Round  77, Global train loss: 0.191, Global test loss: 2.064, Global test accuracy: 28.53
Round  78, Train loss: 0.183, Test loss: 1.006, Test accuracy: 72.45
Round  78, Global train loss: 0.183, Global test loss: 2.073, Global test accuracy: 27.10
Round  79, Train loss: 0.196, Test loss: 1.003, Test accuracy: 73.07
Round  79, Global train loss: 0.196, Global test loss: 2.105, Global test accuracy: 31.28
Round  80, Train loss: 0.147, Test loss: 1.009, Test accuracy: 72.87
Round  80, Global train loss: 0.147, Global test loss: 1.976, Global test accuracy: 30.78
Round  81, Train loss: 0.205, Test loss: 1.041, Test accuracy: 72.43
Round  81, Global train loss: 0.205, Global test loss: 2.298, Global test accuracy: 23.85
Round  82, Train loss: 0.196, Test loss: 1.063, Test accuracy: 72.57
Round  82, Global train loss: 0.196, Global test loss: 2.233, Global test accuracy: 22.55
Round  83, Train loss: 0.106, Test loss: 1.069, Test accuracy: 72.95
Round  83, Global train loss: 0.106, Global test loss: 2.108, Global test accuracy: 27.25
Round  84, Train loss: 0.164, Test loss: 1.099, Test accuracy: 72.50
Round  84, Global train loss: 0.164, Global test loss: 2.021, Global test accuracy: 28.27
Round  85, Train loss: 0.181, Test loss: 1.146, Test accuracy: 72.22
Round  85, Global train loss: 0.181, Global test loss: 2.178, Global test accuracy: 19.40
Round  86, Train loss: 0.188, Test loss: 1.141, Test accuracy: 72.27
Round  86, Global train loss: 0.188, Global test loss: 2.037, Global test accuracy: 34.28
Round  87, Train loss: 0.185, Test loss: 1.129, Test accuracy: 72.17
Round  87, Global train loss: 0.185, Global test loss: 2.023, Global test accuracy: 32.90
Round  88, Train loss: 0.126, Test loss: 1.144, Test accuracy: 71.80
Round  88, Global train loss: 0.126, Global test loss: 2.041, Global test accuracy: 30.87
Round  89, Train loss: 0.140, Test loss: 1.175, Test accuracy: 71.37
Round  89, Global train loss: 0.140, Global test loss: 2.017, Global test accuracy: 32.57
Round  90, Train loss: 0.102, Test loss: 1.199, Test accuracy: 71.85
Round  90, Global train loss: 0.102, Global test loss: 1.962, Global test accuracy: 31.77
Round  91, Train loss: 0.130, Test loss: 1.212, Test accuracy: 71.52
Round  91, Global train loss: 0.130, Global test loss: 2.185, Global test accuracy: 14.05
Round  92, Train loss: 0.133, Test loss: 1.237, Test accuracy: 71.47
Round  92, Global train loss: 0.133, Global test loss: 2.033, Global test accuracy: 29.32
Round  93, Train loss: 0.132, Test loss: 1.225, Test accuracy: 71.60
Round  93, Global train loss: 0.132, Global test loss: 2.355, Global test accuracy: 19.72
Round  94, Train loss: 0.129, Test loss: 1.203, Test accuracy: 72.33
Round  94, Global train loss: 0.129, Global test loss: 2.211, Global test accuracy: 26.37
Round  95, Train loss: 0.126, Test loss: 1.230, Test accuracy: 72.12
Round  95, Global train loss: 0.126, Global test loss: 2.063, Global test accuracy: 32.63
Round  96, Train loss: 0.115, Test loss: 1.233, Test accuracy: 72.07
Round  96, Global train loss: 0.115, Global test loss: 2.082, Global test accuracy: 23.80
Round  97, Train loss: 0.078, Test loss: 1.233, Test accuracy: 72.72
Round  97, Global train loss: 0.078, Global test loss: 2.070, Global test accuracy: 31.27
Round  98, Train loss: 0.100, Test loss: 1.234, Test accuracy: 72.48
Round  98, Global train loss: 0.100, Global test loss: 1.992, Global test accuracy: 27.17
Round  99, Train loss: 0.103, Test loss: 1.240, Test accuracy: 71.88
Round  99, Global train loss: 0.103, Global test loss: 2.171, Global test accuracy: 28.20
Final Round, Train loss: 0.105, Test loss: 1.283, Test accuracy: 72.90
Final Round, Global train loss: 0.105, Global test loss: 2.171, Global test accuracy: 28.20
Average accuracy final 10 rounds: 72.00333333333333 

Average global accuracy final 10 rounds: 26.428333333333335 

1026.6371541023254
[1.0132238864898682, 2.0264477729797363, 2.7587761878967285, 3.4911046028137207, 4.224845886230469, 4.958587169647217, 5.692986965179443, 6.42738676071167, 7.167803764343262, 7.9082207679748535, 8.6194908618927, 9.330760955810547, 10.033575773239136, 10.736390590667725, 11.447609424591064, 12.158828258514404, 12.849992036819458, 13.541155815124512, 14.242521047592163, 14.943886280059814, 15.670248746871948, 16.396611213684082, 17.116998434066772, 17.837385654449463, 18.573287963867188, 19.309190273284912, 20.025916576385498, 20.742642879486084, 21.447402715682983, 22.152162551879883, 22.85720205307007, 23.562241554260254, 24.248274326324463, 24.934307098388672, 25.63611912727356, 26.337931156158447, 27.070367336273193, 27.80280351638794, 28.534761905670166, 29.266720294952393, 30.010607957839966, 30.75449562072754, 31.48476481437683, 32.21503400802612, 32.916680574417114, 33.618327140808105, 34.323806285858154, 35.0292854309082, 35.733192682266235, 36.43709993362427, 37.137274980545044, 37.83745002746582, 38.59253811836243, 39.34762620925903, 40.06429076194763, 40.78095531463623, 41.51305294036865, 42.245150566101074, 42.9599187374115, 43.674686908721924, 44.36538243293762, 45.05607795715332, 45.751444816589355, 46.44681167602539, 47.13530349731445, 47.823795318603516, 48.51726317405701, 49.2107310295105, 49.941821813583374, 50.67291259765625, 51.397523164749146, 52.12213373184204, 52.858922719955444, 53.59571170806885, 54.333428382873535, 55.07114505767822, 55.7794394493103, 56.48773384094238, 57.179651975631714, 57.871570110321045, 58.56614303588867, 59.2607159614563, 59.951642990112305, 60.64257001876831, 61.360233783721924, 62.07789754867554, 62.80155920982361, 63.52522087097168, 64.26381969451904, 65.0024185180664, 65.73392009735107, 66.46542167663574, 67.16741609573364, 67.86941051483154, 68.5685863494873, 69.26776218414307, 69.97024011611938, 70.6727180480957, 71.35621237754822, 72.03970670700073, 72.73540735244751, 73.43110799789429, 74.16683626174927, 74.90256452560425, 75.63535356521606, 76.36814260482788, 77.09538292884827, 77.82262325286865, 78.53761100769043, 79.2525987625122, 79.94235682487488, 80.63211488723755, 81.33417177200317, 82.0362286567688, 82.73071002960205, 83.4251914024353, 84.14026713371277, 84.85534286499023, 85.59595394134521, 86.3365650177002, 87.06901288032532, 87.80146074295044, 88.54588460922241, 89.29030847549438, 90.00709962844849, 90.72389078140259, 91.40842628479004, 92.09296178817749, 92.79782032966614, 93.50267887115479, 94.20049381256104, 94.89830875396729, 95.60809969902039, 96.31789064407349, 97.05707859992981, 97.79626655578613, 98.52014064788818, 99.24401473999023, 99.99248719215393, 100.74095964431763, 101.48167872428894, 102.22239780426025, 102.9215841293335, 103.62077045440674, 104.32930040359497, 105.0378303527832, 105.736896276474, 106.4359622001648, 107.12925910949707, 107.82255601882935, 108.57371354103088, 109.32487106323242, 110.04159092903137, 110.75831079483032, 111.49541568756104, 112.23252058029175, 112.9629020690918, 113.69328355789185, 114.40209221839905, 115.11090087890625, 115.80123782157898, 116.49157476425171, 117.18872594833374, 117.88587713241577, 118.5735228061676, 119.26116847991943, 119.96404194831848, 120.66691541671753, 121.39743566513062, 122.1279559135437, 122.86288452148438, 123.59781312942505, 124.33540940284729, 125.07300567626953, 125.79576301574707, 126.51852035522461, 127.20682549476624, 127.89513063430786, 128.59887623786926, 129.30262184143066, 130.00585556030273, 130.7090892791748, 131.40491485595703, 132.10074043273926, 132.8329005241394, 133.56506061553955, 134.2866771221161, 135.00829362869263, 135.7510826587677, 136.49387168884277, 137.20600152015686, 137.91813135147095, 138.60782480239868, 139.29751825332642, 139.99811458587646, 140.6987109184265, 141.3906180858612, 142.0825252532959, 142.78025650978088, 143.47798776626587, 144.90821433067322, 146.33844089508057]
[20.75, 20.75, 37.15, 37.15, 43.983333333333334, 43.983333333333334, 52.983333333333334, 52.983333333333334, 55.65, 55.65, 59.18333333333333, 59.18333333333333, 63.53333333333333, 63.53333333333333, 64.63333333333334, 64.63333333333334, 66.05, 66.05, 67.73333333333333, 67.73333333333333, 67.85, 67.85, 67.31666666666666, 67.31666666666666, 68.1, 68.1, 67.65, 67.65, 68.45, 68.45, 69.1, 69.1, 68.98333333333333, 68.98333333333333, 69.66666666666667, 69.66666666666667, 69.51666666666667, 69.51666666666667, 70.61666666666666, 70.61666666666666, 71.38333333333334, 71.38333333333334, 71.31666666666666, 71.31666666666666, 71.16666666666667, 71.16666666666667, 71.55, 71.55, 70.95, 70.95, 71.78333333333333, 71.78333333333333, 72.18333333333334, 72.18333333333334, 72.03333333333333, 72.03333333333333, 72.66666666666667, 72.66666666666667, 71.93333333333334, 71.93333333333334, 72.45, 72.45, 72.05, 72.05, 72.98333333333333, 72.98333333333333, 73.7, 73.7, 73.85, 73.85, 73.88333333333334, 73.88333333333334, 73.18333333333334, 73.18333333333334, 72.65, 72.65, 72.08333333333333, 72.08333333333333, 72.01666666666667, 72.01666666666667, 72.51666666666667, 72.51666666666667, 73.13333333333334, 73.13333333333334, 72.86666666666666, 72.86666666666666, 72.75, 72.75, 73.33333333333333, 73.33333333333333, 72.81666666666666, 72.81666666666666, 72.91666666666667, 72.91666666666667, 73.26666666666667, 73.26666666666667, 73.11666666666666, 73.11666666666666, 72.85, 72.85, 73.68333333333334, 73.68333333333334, 73.15, 73.15, 73.08333333333333, 73.08333333333333, 73.41666666666667, 73.41666666666667, 73.11666666666666, 73.11666666666666, 73.0, 73.0, 72.33333333333333, 72.33333333333333, 72.31666666666666, 72.31666666666666, 72.18333333333334, 72.18333333333334, 73.18333333333334, 73.18333333333334, 72.65, 72.65, 72.95, 72.95, 72.08333333333333, 72.08333333333333, 72.35, 72.35, 72.81666666666666, 72.81666666666666, 72.91666666666667, 72.91666666666667, 73.11666666666666, 73.11666666666666, 73.35, 73.35, 72.9, 72.9, 72.86666666666666, 72.86666666666666, 72.85, 72.85, 72.38333333333334, 72.38333333333334, 72.26666666666667, 72.26666666666667, 72.33333333333333, 72.33333333333333, 71.98333333333333, 71.98333333333333, 72.16666666666667, 72.16666666666667, 72.58333333333333, 72.58333333333333, 72.43333333333334, 72.43333333333334, 72.45, 72.45, 73.06666666666666, 73.06666666666666, 72.86666666666666, 72.86666666666666, 72.43333333333334, 72.43333333333334, 72.56666666666666, 72.56666666666666, 72.95, 72.95, 72.5, 72.5, 72.21666666666667, 72.21666666666667, 72.26666666666667, 72.26666666666667, 72.16666666666667, 72.16666666666667, 71.8, 71.8, 71.36666666666666, 71.36666666666666, 71.85, 71.85, 71.51666666666667, 71.51666666666667, 71.46666666666667, 71.46666666666667, 71.6, 71.6, 72.33333333333333, 72.33333333333333, 72.11666666666666, 72.11666666666666, 72.06666666666666, 72.06666666666666, 72.71666666666667, 72.71666666666667, 72.48333333333333, 72.48333333333333, 71.88333333333334, 71.88333333333334, 72.9, 72.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.253, Test loss: 1.926, Test accuracy: 25.57
Round   0, Global train loss: 1.253, Global test loss: 2.298, Global test accuracy: 15.82
Round   1, Train loss: 1.056, Test loss: 1.657, Test accuracy: 39.10
Round   1, Global train loss: 1.056, Global test loss: 2.283, Global test accuracy: 23.17
Round   2, Train loss: 0.957, Test loss: 1.334, Test accuracy: 46.17
Round   2, Global train loss: 0.957, Global test loss: 2.323, Global test accuracy: 20.35
Round   3, Train loss: 0.925, Test loss: 1.105, Test accuracy: 53.47
Round   3, Global train loss: 0.925, Global test loss: 2.257, Global test accuracy: 25.32
Round   4, Train loss: 0.901, Test loss: 1.011, Test accuracy: 58.42
Round   4, Global train loss: 0.901, Global test loss: 2.138, Global test accuracy: 32.18
Round   5, Train loss: 0.820, Test loss: 0.864, Test accuracy: 61.23
Round   5, Global train loss: 0.820, Global test loss: 1.967, Global test accuracy: 27.97
Round   6, Train loss: 0.754, Test loss: 0.746, Test accuracy: 66.83
Round   6, Global train loss: 0.754, Global test loss: 2.042, Global test accuracy: 30.03
Round   7, Train loss: 0.772, Test loss: 0.735, Test accuracy: 67.65
Round   7, Global train loss: 0.772, Global test loss: 1.937, Global test accuracy: 31.05
Round   8, Train loss: 0.778, Test loss: 0.721, Test accuracy: 68.42
Round   8, Global train loss: 0.778, Global test loss: 1.818, Global test accuracy: 33.53
Round   9, Train loss: 0.820, Test loss: 0.700, Test accuracy: 69.03
Round   9, Global train loss: 0.820, Global test loss: 1.828, Global test accuracy: 33.18
Round  10, Train loss: 0.736, Test loss: 0.695, Test accuracy: 69.27
Round  10, Global train loss: 0.736, Global test loss: 1.750, Global test accuracy: 33.73
Round  11, Train loss: 0.657, Test loss: 0.693, Test accuracy: 69.77
Round  11, Global train loss: 0.657, Global test loss: 1.711, Global test accuracy: 38.78
Round  12, Train loss: 0.680, Test loss: 0.683, Test accuracy: 70.62
Round  12, Global train loss: 0.680, Global test loss: 1.572, Global test accuracy: 44.48
Round  13, Train loss: 0.674, Test loss: 0.669, Test accuracy: 71.82
Round  13, Global train loss: 0.674, Global test loss: 1.695, Global test accuracy: 38.43
Round  14, Train loss: 0.756, Test loss: 0.658, Test accuracy: 72.70
Round  14, Global train loss: 0.756, Global test loss: 1.768, Global test accuracy: 38.35
Round  15, Train loss: 0.665, Test loss: 0.635, Test accuracy: 73.37
Round  15, Global train loss: 0.665, Global test loss: 1.746, Global test accuracy: 37.63
Round  16, Train loss: 0.682, Test loss: 0.640, Test accuracy: 73.10
Round  16, Global train loss: 0.682, Global test loss: 1.937, Global test accuracy: 34.77
Round  17, Train loss: 0.651, Test loss: 0.622, Test accuracy: 73.88
Round  17, Global train loss: 0.651, Global test loss: 1.761, Global test accuracy: 39.82
Round  18, Train loss: 0.691, Test loss: 0.621, Test accuracy: 74.05
Round  18, Global train loss: 0.691, Global test loss: 1.714, Global test accuracy: 42.32
Round  19, Train loss: 0.617, Test loss: 0.628, Test accuracy: 73.60
Round  19, Global train loss: 0.617, Global test loss: 1.725, Global test accuracy: 38.18
Round  20, Train loss: 0.645, Test loss: 0.615, Test accuracy: 74.05
Round  20, Global train loss: 0.645, Global test loss: 1.743, Global test accuracy: 35.80
Round  21, Train loss: 0.615, Test loss: 0.617, Test accuracy: 73.78
Round  21, Global train loss: 0.615, Global test loss: 1.543, Global test accuracy: 46.90
Round  22, Train loss: 0.533, Test loss: 0.620, Test accuracy: 73.58
Round  22, Global train loss: 0.533, Global test loss: 1.498, Global test accuracy: 46.97
Round  23, Train loss: 0.703, Test loss: 0.639, Test accuracy: 73.12
Round  23, Global train loss: 0.703, Global test loss: 1.688, Global test accuracy: 40.83
Round  24, Train loss: 0.553, Test loss: 0.604, Test accuracy: 74.80
Round  24, Global train loss: 0.553, Global test loss: 1.510, Global test accuracy: 44.98
Round  25, Train loss: 0.600, Test loss: 0.603, Test accuracy: 74.68
Round  25, Global train loss: 0.600, Global test loss: 1.473, Global test accuracy: 47.70
Round  26, Train loss: 0.575, Test loss: 0.594, Test accuracy: 75.13
Round  26, Global train loss: 0.575, Global test loss: 1.552, Global test accuracy: 46.82
Round  27, Train loss: 0.558, Test loss: 0.586, Test accuracy: 75.33
Round  27, Global train loss: 0.558, Global test loss: 1.646, Global test accuracy: 47.55
Round  28, Train loss: 0.512, Test loss: 0.608, Test accuracy: 74.90
Round  28, Global train loss: 0.512, Global test loss: 1.595, Global test accuracy: 49.80
Round  29, Train loss: 0.613, Test loss: 0.605, Test accuracy: 75.58
Round  29, Global train loss: 0.613, Global test loss: 1.656, Global test accuracy: 42.85
Round  30, Train loss: 0.564, Test loss: 0.606, Test accuracy: 75.45
Round  30, Global train loss: 0.564, Global test loss: 1.513, Global test accuracy: 44.80
Round  31, Train loss: 0.470, Test loss: 0.581, Test accuracy: 76.75
Round  31, Global train loss: 0.470, Global test loss: 1.739, Global test accuracy: 45.70
Round  32, Train loss: 0.452, Test loss: 0.575, Test accuracy: 76.87
Round  32, Global train loss: 0.452, Global test loss: 1.468, Global test accuracy: 51.42
Round  33, Train loss: 0.535, Test loss: 0.600, Test accuracy: 75.92
Round  33, Global train loss: 0.535, Global test loss: 1.459, Global test accuracy: 51.07
Round  34, Train loss: 0.456, Test loss: 0.590, Test accuracy: 76.37
Round  34, Global train loss: 0.456, Global test loss: 2.014, Global test accuracy: 41.93
Round  35, Train loss: 0.549, Test loss: 0.584, Test accuracy: 76.82
Round  35, Global train loss: 0.549, Global test loss: 1.499, Global test accuracy: 47.57
Round  36, Train loss: 0.437, Test loss: 0.567, Test accuracy: 77.63
Round  36, Global train loss: 0.437, Global test loss: 1.703, Global test accuracy: 44.53
Round  37, Train loss: 0.500, Test loss: 0.566, Test accuracy: 77.67
Round  37, Global train loss: 0.500, Global test loss: 1.440, Global test accuracy: 50.88
Round  38, Train loss: 0.433, Test loss: 0.571, Test accuracy: 77.58
Round  38, Global train loss: 0.433, Global test loss: 1.412, Global test accuracy: 51.73
Round  39, Train loss: 0.470, Test loss: 0.586, Test accuracy: 77.20
Round  39, Global train loss: 0.470, Global test loss: 1.385, Global test accuracy: 51.67
Round  40, Train loss: 0.459, Test loss: 0.591, Test accuracy: 77.75
Round  40, Global train loss: 0.459, Global test loss: 1.755, Global test accuracy: 47.02
Round  41, Train loss: 0.470, Test loss: 0.593, Test accuracy: 77.73
Round  41, Global train loss: 0.470, Global test loss: 1.503, Global test accuracy: 49.47
Round  42, Train loss: 0.539, Test loss: 0.605, Test accuracy: 77.58
Round  42, Global train loss: 0.539, Global test loss: 1.447, Global test accuracy: 48.87
Round  43, Train loss: 0.442, Test loss: 0.593, Test accuracy: 77.53
Round  43, Global train loss: 0.442, Global test loss: 1.334, Global test accuracy: 54.05
Round  44, Train loss: 0.471, Test loss: 0.575, Test accuracy: 78.30
Round  44, Global train loss: 0.471, Global test loss: 1.443, Global test accuracy: 49.75
Round  45, Train loss: 0.475, Test loss: 0.582, Test accuracy: 77.93
Round  45, Global train loss: 0.475, Global test loss: 1.373, Global test accuracy: 53.95
Round  46, Train loss: 0.525, Test loss: 0.572, Test accuracy: 78.27
Round  46, Global train loss: 0.525, Global test loss: 1.379, Global test accuracy: 52.35
Round  47, Train loss: 0.496, Test loss: 0.565, Test accuracy: 78.47
Round  47, Global train loss: 0.496, Global test loss: 1.474, Global test accuracy: 50.00
Round  48, Train loss: 0.433, Test loss: 0.561, Test accuracy: 78.55
Round  48, Global train loss: 0.433, Global test loss: 1.348, Global test accuracy: 52.05
Round  49, Train loss: 0.459, Test loss: 0.556, Test accuracy: 78.67
Round  49, Global train loss: 0.459, Global test loss: 1.417, Global test accuracy: 52.30
Round  50, Train loss: 0.440, Test loss: 0.565, Test accuracy: 78.43
Round  50, Global train loss: 0.440, Global test loss: 1.316, Global test accuracy: 55.80
Round  51, Train loss: 0.420, Test loss: 0.585, Test accuracy: 78.18
Round  51, Global train loss: 0.420, Global test loss: 1.502, Global test accuracy: 48.03
Round  52, Train loss: 0.384, Test loss: 0.576, Test accuracy: 78.65
Round  52, Global train loss: 0.384, Global test loss: 1.478, Global test accuracy: 50.93
Round  53, Train loss: 0.376, Test loss: 0.584, Test accuracy: 78.73
Round  53, Global train loss: 0.376, Global test loss: 1.420, Global test accuracy: 52.98
Round  54, Train loss: 0.325, Test loss: 0.578, Test accuracy: 78.57
Round  54, Global train loss: 0.325, Global test loss: 1.670, Global test accuracy: 46.68
Round  55, Train loss: 0.413, Test loss: 0.567, Test accuracy: 79.27
Round  55, Global train loss: 0.413, Global test loss: 1.480, Global test accuracy: 51.83
Round  56, Train loss: 0.414, Test loss: 0.561, Test accuracy: 79.23
Round  56, Global train loss: 0.414, Global test loss: 1.282, Global test accuracy: 56.83
Round  57, Train loss: 0.449, Test loss: 0.564, Test accuracy: 79.42
Round  57, Global train loss: 0.449, Global test loss: 1.287, Global test accuracy: 57.15
Round  58, Train loss: 0.449, Test loss: 0.589, Test accuracy: 78.63
Round  58, Global train loss: 0.449, Global test loss: 1.600, Global test accuracy: 48.13
Round  59, Train loss: 0.396, Test loss: 0.570, Test accuracy: 79.25
Round  59, Global train loss: 0.396, Global test loss: 1.508, Global test accuracy: 50.03
Round  60, Train loss: 0.384, Test loss: 0.543, Test accuracy: 80.53
Round  60, Global train loss: 0.384, Global test loss: 1.223, Global test accuracy: 57.52
Round  61, Train loss: 0.365, Test loss: 0.541, Test accuracy: 80.37
Round  61, Global train loss: 0.365, Global test loss: 1.333, Global test accuracy: 55.32
Round  62, Train loss: 0.366, Test loss: 0.563, Test accuracy: 79.22
Round  62, Global train loss: 0.366, Global test loss: 1.570, Global test accuracy: 49.80
Round  63, Train loss: 0.366, Test loss: 0.555, Test accuracy: 79.70
Round  63, Global train loss: 0.366, Global test loss: 1.346, Global test accuracy: 56.02
Round  64, Train loss: 0.341, Test loss: 0.608, Test accuracy: 78.75
Round  64, Global train loss: 0.341, Global test loss: 1.913, Global test accuracy: 49.37
Round  65, Train loss: 0.393, Test loss: 0.594, Test accuracy: 79.42
Round  65, Global train loss: 0.393, Global test loss: 1.487, Global test accuracy: 50.92
Round  66, Train loss: 0.360, Test loss: 0.615, Test accuracy: 78.55
Round  66, Global train loss: 0.360, Global test loss: 1.390, Global test accuracy: 54.33
Round  67, Train loss: 0.433, Test loss: 0.629, Test accuracy: 78.40
Round  67, Global train loss: 0.433, Global test loss: 1.273, Global test accuracy: 56.82
Round  68, Train loss: 0.344, Test loss: 0.597, Test accuracy: 78.95
Round  68, Global train loss: 0.344, Global test loss: 1.475, Global test accuracy: 53.00
Round  69, Train loss: 0.330, Test loss: 0.591, Test accuracy: 79.02
Round  69, Global train loss: 0.330, Global test loss: 1.543, Global test accuracy: 50.83
Round  70, Train loss: 0.318, Test loss: 0.610, Test accuracy: 78.70
Round  70, Global train loss: 0.318, Global test loss: 1.552, Global test accuracy: 51.48
Round  71, Train loss: 0.378, Test loss: 0.586, Test accuracy: 79.83
Round  71, Global train loss: 0.378, Global test loss: 1.469, Global test accuracy: 52.67
Round  72, Train loss: 0.382, Test loss: 0.579, Test accuracy: 80.08
Round  72, Global train loss: 0.382, Global test loss: 1.278, Global test accuracy: 57.88
Round  73, Train loss: 0.313, Test loss: 0.569, Test accuracy: 79.97
Round  73, Global train loss: 0.313, Global test loss: 1.361, Global test accuracy: 55.58
Round  74, Train loss: 0.260, Test loss: 0.561, Test accuracy: 80.55
Round  74, Global train loss: 0.260, Global test loss: 1.456, Global test accuracy: 54.52
Round  75, Train loss: 0.337, Test loss: 0.567, Test accuracy: 80.32
Round  75, Global train loss: 0.337, Global test loss: 1.368, Global test accuracy: 55.57
Round  76, Train loss: 0.346, Test loss: 0.584, Test accuracy: 79.62
Round  76, Global train loss: 0.346, Global test loss: 1.385, Global test accuracy: 52.73
Round  77, Train loss: 0.291, Test loss: 0.601, Test accuracy: 79.33
Round  77, Global train loss: 0.291, Global test loss: 1.440, Global test accuracy: 53.85
Round  78, Train loss: 0.346, Test loss: 0.596, Test accuracy: 79.78
Round  78, Global train loss: 0.346, Global test loss: 1.368, Global test accuracy: 56.82
Round  79, Train loss: 0.327, Test loss: 0.591, Test accuracy: 79.98
Round  79, Global train loss: 0.327, Global test loss: 1.402, Global test accuracy: 54.72
Round  80, Train loss: 0.267, Test loss: 0.591, Test accuracy: 79.48
Round  80, Global train loss: 0.267, Global test loss: 1.340, Global test accuracy: 56.38
Round  81, Train loss: 0.302, Test loss: 0.601, Test accuracy: 79.95
Round  81, Global train loss: 0.302, Global test loss: 1.989, Global test accuracy: 43.82
Round  82, Train loss: 0.356, Test loss: 0.604, Test accuracy: 80.22
Round  82, Global train loss: 0.356, Global test loss: 1.518, Global test accuracy: 52.47
Round  83, Train loss: 0.332, Test loss: 0.609, Test accuracy: 80.33
Round  83, Global train loss: 0.332, Global test loss: 1.581, Global test accuracy: 51.65
Round  84, Train loss: 0.274, Test loss: 0.605, Test accuracy: 80.22
Round  84, Global train loss: 0.274, Global test loss: 1.515, Global test accuracy: 54.37
Round  85, Train loss: 0.266, Test loss: 0.574, Test accuracy: 81.02
Round  85, Global train loss: 0.266, Global test loss: 1.562, Global test accuracy: 53.00
Round  86, Train loss: 0.314, Test loss: 0.592, Test accuracy: 80.43
Round  86, Global train loss: 0.314, Global test loss: 1.486, Global test accuracy: 54.15
Round  87, Train loss: 0.251, Test loss: 0.611, Test accuracy: 80.35
Round  87, Global train loss: 0.251, Global test loss: 1.617, Global test accuracy: 53.40
Round  88, Train loss: 0.255, Test loss: 0.632, Test accuracy: 80.03
Round  88, Global train loss: 0.255, Global test loss: 1.421, Global test accuracy: 56.88
Round  89, Train loss: 0.281, Test loss: 0.621, Test accuracy: 80.43
Round  89, Global train loss: 0.281, Global test loss: 1.399, Global test accuracy: 57.25
Round  90, Train loss: 0.289, Test loss: 0.623, Test accuracy: 80.37
Round  90, Global train loss: 0.289, Global test loss: 1.450, Global test accuracy: 54.92
Round  91, Train loss: 0.273, Test loss: 0.625, Test accuracy: 80.30
Round  91, Global train loss: 0.273, Global test loss: 1.507, Global test accuracy: 55.65
Round  92, Train loss: 0.218, Test loss: 0.635, Test accuracy: 80.23
Round  92, Global train loss: 0.218, Global test loss: 1.511, Global test accuracy: 54.97
Round  93, Train loss: 0.312, Test loss: 0.624, Test accuracy: 80.35
Round  93, Global train loss: 0.312, Global test loss: 1.695, Global test accuracy: 49.88
Round  94, Train loss: 0.305, Test loss: 0.629, Test accuracy: 80.02
Round  94, Global train loss: 0.305, Global test loss: 1.602, Global test accuracy: 51.23
Round  95, Train loss: 0.231, Test loss: 0.620, Test accuracy: 80.57
Round  95, Global train loss: 0.231, Global test loss: 1.605, Global test accuracy: 54.23
Round  96, Train loss: 0.250, Test loss: 0.631, Test accuracy: 80.13
Round  96, Global train loss: 0.250, Global test loss: 1.330, Global test accuracy: 59.42
Round  97, Train loss: 0.294, Test loss: 0.618, Test accuracy: 80.50
Round  97, Global train loss: 0.294, Global test loss: 1.560, Global test accuracy: 53.78
Round  98, Train loss: 0.276, Test loss: 0.617, Test accuracy: 80.73
Round  98, Global train loss: 0.276, Global test loss: 1.398, Global test accuracy: 56.45
Round  99, Train loss: 0.258, Test loss: 0.650, Test accuracy: 79.93
Round  99, Global train loss: 0.258, Global test loss: 1.636, Global test accuracy: 54.12
Final Round, Train loss: 0.204, Test loss: 0.694, Test accuracy: 80.17
Final Round, Global train loss: 0.204, Global test loss: 1.636, Global test accuracy: 54.12
Average accuracy final 10 rounds: 80.31333333333335 

Average global accuracy final 10 rounds: 54.465 

1021.0228188037872
[1.0438573360443115, 2.087714672088623, 2.789194345474243, 3.4906740188598633, 4.198937892913818, 4.907201766967773, 5.609791278839111, 6.312380790710449, 7.013519287109375, 7.714657783508301, 8.451186656951904, 9.187715530395508, 9.89976954460144, 10.611823558807373, 11.352843999862671, 12.093864440917969, 12.802237033843994, 13.51060962677002, 14.20562481880188, 14.90064001083374, 15.60189700126648, 16.30315399169922, 16.999273777008057, 17.695393562316895, 18.399919033050537, 19.10444450378418, 19.836122751235962, 20.567800998687744, 21.281976461410522, 21.9961519241333, 22.727773427963257, 23.459394931793213, 24.175844192504883, 24.892293453216553, 25.586241483688354, 26.280189514160156, 26.981569290161133, 27.68294906616211, 28.382184982299805, 29.0814208984375, 29.78479290008545, 30.4881649017334, 31.221710681915283, 31.955256462097168, 32.67009472846985, 33.38493299484253, 34.109222173690796, 34.83351135253906, 35.56269025802612, 36.291869163513184, 36.99811792373657, 37.70436668395996, 38.39514875411987, 39.085930824279785, 39.78089237213135, 40.47585391998291, 41.168848276138306, 41.8618426322937, 42.555853843688965, 43.24986505508423, 43.96387434005737, 44.67788362503052, 45.40188789367676, 46.125892162323, 46.858606576919556, 47.59132099151611, 48.30424380302429, 49.01716661453247, 49.712730407714844, 50.40829420089722, 51.109493017196655, 51.810691833496094, 52.51672649383545, 53.222761154174805, 53.918524503707886, 54.61428785324097, 55.35344481468201, 56.09260177612305, 56.82164978981018, 57.550697803497314, 58.28276228904724, 59.01482677459717, 59.72760081291199, 60.44037485122681, 61.13336229324341, 61.82634973526001, 62.52976369857788, 63.23317766189575, 63.925776958465576, 64.6183762550354, 65.32658672332764, 66.03479719161987, 66.7646369934082, 67.49447679519653, 68.2345039844513, 68.97453117370605, 69.71495509147644, 70.45537900924683, 71.18706059455872, 71.9187421798706, 72.62013626098633, 73.32153034210205, 74.01854920387268, 74.71556806564331, 75.4158308506012, 76.11609363555908, 76.81634378433228, 77.51659393310547, 78.22757315635681, 78.93855237960815, 79.66993927955627, 80.4013261795044, 81.15084886550903, 81.90037155151367, 82.62103867530823, 83.34170579910278, 84.04706358909607, 84.75242137908936, 85.45134925842285, 86.15027713775635, 86.85021162033081, 87.55014610290527, 88.23579716682434, 88.92144823074341, 89.61450505256653, 90.30756187438965, 91.04085493087769, 91.77414798736572, 92.49610328674316, 93.2180585861206, 93.9562304019928, 94.69440221786499, 95.40756893157959, 96.12073564529419, 96.80630564689636, 97.49187564849854, 98.1862313747406, 98.88058710098267, 99.56912779808044, 100.25766849517822, 100.95286345481873, 101.64805841445923, 102.39010453224182, 103.13215065002441, 103.8666443824768, 104.6011381149292, 105.33498358726501, 106.06882905960083, 106.80662178993225, 107.54441452026367, 108.23150992393494, 108.9186053276062, 109.61603808403015, 110.3134708404541, 111.01303601264954, 111.71260118484497, 112.40562033653259, 113.09863948822021, 113.8124508857727, 114.5262622833252, 115.2439181804657, 115.9615740776062, 116.7019944190979, 117.4424147605896, 118.16320466995239, 118.88399457931519, 119.58659839630127, 120.28920221328735, 120.98408889770508, 121.6789755821228, 122.3716311454773, 123.06428670883179, 123.74638056755066, 124.42847442626953, 125.1487250328064, 125.86897563934326, 126.59238004684448, 127.3157844543457, 128.04676914215088, 128.77775382995605, 129.52617859840393, 130.2746033668518, 130.97187447547913, 131.66914558410645, 132.36774826049805, 133.06635093688965, 133.7648265361786, 134.46330213546753, 135.16275596618652, 135.86220979690552, 136.5640652179718, 137.2659206390381, 138.00835347175598, 138.75078630447388, 139.47675681114197, 140.20272731781006, 140.9207570552826, 141.63878679275513, 142.34654450416565, 143.05430221557617, 144.43946886062622, 145.82463550567627]
[25.566666666666666, 25.566666666666666, 39.1, 39.1, 46.166666666666664, 46.166666666666664, 53.46666666666667, 53.46666666666667, 58.416666666666664, 58.416666666666664, 61.233333333333334, 61.233333333333334, 66.83333333333333, 66.83333333333333, 67.65, 67.65, 68.41666666666667, 68.41666666666667, 69.03333333333333, 69.03333333333333, 69.26666666666667, 69.26666666666667, 69.76666666666667, 69.76666666666667, 70.61666666666666, 70.61666666666666, 71.81666666666666, 71.81666666666666, 72.7, 72.7, 73.36666666666666, 73.36666666666666, 73.1, 73.1, 73.88333333333334, 73.88333333333334, 74.05, 74.05, 73.6, 73.6, 74.05, 74.05, 73.78333333333333, 73.78333333333333, 73.58333333333333, 73.58333333333333, 73.11666666666666, 73.11666666666666, 74.8, 74.8, 74.68333333333334, 74.68333333333334, 75.13333333333334, 75.13333333333334, 75.33333333333333, 75.33333333333333, 74.9, 74.9, 75.58333333333333, 75.58333333333333, 75.45, 75.45, 76.75, 76.75, 76.86666666666666, 76.86666666666666, 75.91666666666667, 75.91666666666667, 76.36666666666666, 76.36666666666666, 76.81666666666666, 76.81666666666666, 77.63333333333334, 77.63333333333334, 77.66666666666667, 77.66666666666667, 77.58333333333333, 77.58333333333333, 77.2, 77.2, 77.75, 77.75, 77.73333333333333, 77.73333333333333, 77.58333333333333, 77.58333333333333, 77.53333333333333, 77.53333333333333, 78.3, 78.3, 77.93333333333334, 77.93333333333334, 78.26666666666667, 78.26666666666667, 78.46666666666667, 78.46666666666667, 78.55, 78.55, 78.66666666666667, 78.66666666666667, 78.43333333333334, 78.43333333333334, 78.18333333333334, 78.18333333333334, 78.65, 78.65, 78.73333333333333, 78.73333333333333, 78.56666666666666, 78.56666666666666, 79.26666666666667, 79.26666666666667, 79.23333333333333, 79.23333333333333, 79.41666666666667, 79.41666666666667, 78.63333333333334, 78.63333333333334, 79.25, 79.25, 80.53333333333333, 80.53333333333333, 80.36666666666666, 80.36666666666666, 79.21666666666667, 79.21666666666667, 79.7, 79.7, 78.75, 78.75, 79.41666666666667, 79.41666666666667, 78.55, 78.55, 78.4, 78.4, 78.95, 78.95, 79.01666666666667, 79.01666666666667, 78.7, 78.7, 79.83333333333333, 79.83333333333333, 80.08333333333333, 80.08333333333333, 79.96666666666667, 79.96666666666667, 80.55, 80.55, 80.31666666666666, 80.31666666666666, 79.61666666666666, 79.61666666666666, 79.33333333333333, 79.33333333333333, 79.78333333333333, 79.78333333333333, 79.98333333333333, 79.98333333333333, 79.48333333333333, 79.48333333333333, 79.95, 79.95, 80.21666666666667, 80.21666666666667, 80.33333333333333, 80.33333333333333, 80.21666666666667, 80.21666666666667, 81.01666666666667, 81.01666666666667, 80.43333333333334, 80.43333333333334, 80.35, 80.35, 80.03333333333333, 80.03333333333333, 80.43333333333334, 80.43333333333334, 80.36666666666666, 80.36666666666666, 80.3, 80.3, 80.23333333333333, 80.23333333333333, 80.35, 80.35, 80.01666666666667, 80.01666666666667, 80.56666666666666, 80.56666666666666, 80.13333333333334, 80.13333333333334, 80.5, 80.5, 80.73333333333333, 80.73333333333333, 79.93333333333334, 79.93333333333334, 80.16666666666667, 80.16666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.234, Test loss: 1.925, Test accuracy: 24.25
Round   0, Global train loss: 1.234, Global test loss: 2.282, Global test accuracy: 14.80
Round   1, Train loss: 1.046, Test loss: 1.699, Test accuracy: 39.92
Round   1, Global train loss: 1.046, Global test loss: 2.337, Global test accuracy: 21.80
Round   2, Train loss: 0.950, Test loss: 1.319, Test accuracy: 47.60
Round   2, Global train loss: 0.950, Global test loss: 2.246, Global test accuracy: 22.13
Round   3, Train loss: 0.940, Test loss: 1.150, Test accuracy: 52.77
Round   3, Global train loss: 0.940, Global test loss: 2.221, Global test accuracy: 26.98
Round   4, Train loss: 0.950, Test loss: 1.048, Test accuracy: 56.35
Round   4, Global train loss: 0.950, Global test loss: 2.117, Global test accuracy: 30.18
Round   5, Train loss: 0.848, Test loss: 0.898, Test accuracy: 60.27
Round   5, Global train loss: 0.848, Global test loss: 1.989, Global test accuracy: 26.37
Round   6, Train loss: 0.767, Test loss: 0.776, Test accuracy: 64.83
Round   6, Global train loss: 0.767, Global test loss: 2.020, Global test accuracy: 29.98
Round   7, Train loss: 0.792, Test loss: 0.755, Test accuracy: 65.47
Round   7, Global train loss: 0.792, Global test loss: 1.948, Global test accuracy: 29.93
Round   8, Train loss: 0.777, Test loss: 0.739, Test accuracy: 66.78
Round   8, Global train loss: 0.777, Global test loss: 1.830, Global test accuracy: 29.87
Round   9, Train loss: 0.784, Test loss: 0.731, Test accuracy: 67.40
Round   9, Global train loss: 0.784, Global test loss: 1.822, Global test accuracy: 33.83
Round  10, Train loss: 0.760, Test loss: 0.711, Test accuracy: 68.03
Round  10, Global train loss: 0.760, Global test loss: 1.715, Global test accuracy: 33.97
Round  11, Train loss: 0.695, Test loss: 0.701, Test accuracy: 68.38
Round  11, Global train loss: 0.695, Global test loss: 1.794, Global test accuracy: 35.72
Round  12, Train loss: 0.710, Test loss: 0.682, Test accuracy: 69.68
Round  12, Global train loss: 0.710, Global test loss: 1.646, Global test accuracy: 42.08
Round  13, Train loss: 0.686, Test loss: 0.685, Test accuracy: 70.85
Round  13, Global train loss: 0.686, Global test loss: 1.671, Global test accuracy: 39.28
Round  14, Train loss: 0.772, Test loss: 0.682, Test accuracy: 70.98
Round  14, Global train loss: 0.772, Global test loss: 1.700, Global test accuracy: 38.90
Round  15, Train loss: 0.692, Test loss: 0.674, Test accuracy: 71.42
Round  15, Global train loss: 0.692, Global test loss: 1.655, Global test accuracy: 40.02
Round  16, Train loss: 0.648, Test loss: 0.660, Test accuracy: 72.32
Round  16, Global train loss: 0.648, Global test loss: 1.891, Global test accuracy: 36.62
Round  17, Train loss: 0.656, Test loss: 0.665, Test accuracy: 72.02
Round  17, Global train loss: 0.656, Global test loss: 1.804, Global test accuracy: 39.13
Round  18, Train loss: 0.653, Test loss: 0.647, Test accuracy: 72.62
Round  18, Global train loss: 0.653, Global test loss: 1.797, Global test accuracy: 39.87
Round  19, Train loss: 0.646, Test loss: 0.643, Test accuracy: 73.00
Round  19, Global train loss: 0.646, Global test loss: 1.672, Global test accuracy: 39.13
Round  20, Train loss: 0.610, Test loss: 0.644, Test accuracy: 73.27
Round  20, Global train loss: 0.610, Global test loss: 1.728, Global test accuracy: 35.85
Round  21, Train loss: 0.587, Test loss: 0.645, Test accuracy: 73.45
Round  21, Global train loss: 0.587, Global test loss: 1.559, Global test accuracy: 45.85
Round  22, Train loss: 0.585, Test loss: 0.639, Test accuracy: 73.70
Round  22, Global train loss: 0.585, Global test loss: 1.507, Global test accuracy: 45.30
Round  23, Train loss: 0.652, Test loss: 0.614, Test accuracy: 74.60
Round  23, Global train loss: 0.652, Global test loss: 1.609, Global test accuracy: 41.60
Round  24, Train loss: 0.552, Test loss: 0.637, Test accuracy: 73.83
Round  24, Global train loss: 0.552, Global test loss: 1.492, Global test accuracy: 46.20
Round  25, Train loss: 0.582, Test loss: 0.636, Test accuracy: 74.03
Round  25, Global train loss: 0.582, Global test loss: 1.459, Global test accuracy: 47.98
Round  26, Train loss: 0.571, Test loss: 0.632, Test accuracy: 74.35
Round  26, Global train loss: 0.571, Global test loss: 1.663, Global test accuracy: 44.88
Round  27, Train loss: 0.547, Test loss: 0.637, Test accuracy: 74.22
Round  27, Global train loss: 0.547, Global test loss: 1.729, Global test accuracy: 45.70
Round  28, Train loss: 0.569, Test loss: 0.632, Test accuracy: 74.50
Round  28, Global train loss: 0.569, Global test loss: 1.691, Global test accuracy: 45.75
Round  29, Train loss: 0.603, Test loss: 0.610, Test accuracy: 74.90
Round  29, Global train loss: 0.603, Global test loss: 1.644, Global test accuracy: 42.75
Round  30, Train loss: 0.564, Test loss: 0.597, Test accuracy: 75.60
Round  30, Global train loss: 0.564, Global test loss: 1.436, Global test accuracy: 47.77
Round  31, Train loss: 0.531, Test loss: 0.578, Test accuracy: 76.78
Round  31, Global train loss: 0.531, Global test loss: 1.737, Global test accuracy: 44.47
Round  32, Train loss: 0.502, Test loss: 0.598, Test accuracy: 76.53
Round  32, Global train loss: 0.502, Global test loss: 1.543, Global test accuracy: 49.57
Round  33, Train loss: 0.566, Test loss: 0.590, Test accuracy: 77.00
Round  33, Global train loss: 0.566, Global test loss: 1.572, Global test accuracy: 47.10
Round  34, Train loss: 0.498, Test loss: 0.607, Test accuracy: 76.57
Round  34, Global train loss: 0.498, Global test loss: 1.981, Global test accuracy: 39.67
Round  35, Train loss: 0.542, Test loss: 0.586, Test accuracy: 77.32
Round  35, Global train loss: 0.542, Global test loss: 1.583, Global test accuracy: 44.02
Round  36, Train loss: 0.469, Test loss: 0.566, Test accuracy: 77.98
Round  36, Global train loss: 0.469, Global test loss: 1.673, Global test accuracy: 44.77
Round  37, Train loss: 0.533, Test loss: 0.576, Test accuracy: 77.60
Round  37, Global train loss: 0.533, Global test loss: 1.542, Global test accuracy: 45.78
Round  38, Train loss: 0.469, Test loss: 0.557, Test accuracy: 78.17
Round  38, Global train loss: 0.469, Global test loss: 1.408, Global test accuracy: 51.75
Round  39, Train loss: 0.500, Test loss: 0.565, Test accuracy: 78.02
Round  39, Global train loss: 0.500, Global test loss: 1.452, Global test accuracy: 50.50
Round  40, Train loss: 0.525, Test loss: 0.552, Test accuracy: 78.08
Round  40, Global train loss: 0.525, Global test loss: 1.845, Global test accuracy: 44.47
Round  41, Train loss: 0.498, Test loss: 0.561, Test accuracy: 77.62
Round  41, Global train loss: 0.498, Global test loss: 1.574, Global test accuracy: 47.97
Round  42, Train loss: 0.517, Test loss: 0.573, Test accuracy: 77.42
Round  42, Global train loss: 0.517, Global test loss: 1.438, Global test accuracy: 49.43
Round  43, Train loss: 0.490, Test loss: 0.556, Test accuracy: 78.62
Round  43, Global train loss: 0.490, Global test loss: 1.337, Global test accuracy: 53.03
Round  44, Train loss: 0.439, Test loss: 0.556, Test accuracy: 78.27
Round  44, Global train loss: 0.439, Global test loss: 1.396, Global test accuracy: 49.67
Round  45, Train loss: 0.470, Test loss: 0.562, Test accuracy: 78.08
Round  45, Global train loss: 0.470, Global test loss: 1.344, Global test accuracy: 54.90
Round  46, Train loss: 0.565, Test loss: 0.574, Test accuracy: 77.65
Round  46, Global train loss: 0.565, Global test loss: 1.342, Global test accuracy: 53.12
Round  47, Train loss: 0.469, Test loss: 0.573, Test accuracy: 77.35
Round  47, Global train loss: 0.469, Global test loss: 1.427, Global test accuracy: 51.22
Round  48, Train loss: 0.488, Test loss: 0.567, Test accuracy: 77.70
Round  48, Global train loss: 0.488, Global test loss: 1.336, Global test accuracy: 53.27
Round  49, Train loss: 0.455, Test loss: 0.569, Test accuracy: 78.20
Round  49, Global train loss: 0.455, Global test loss: 1.413, Global test accuracy: 50.98
Round  50, Train loss: 0.442, Test loss: 0.556, Test accuracy: 78.62
Round  50, Global train loss: 0.442, Global test loss: 1.300, Global test accuracy: 54.80
Round  51, Train loss: 0.436, Test loss: 0.569, Test accuracy: 78.20
Round  51, Global train loss: 0.436, Global test loss: 1.536, Global test accuracy: 45.75
Round  52, Train loss: 0.379, Test loss: 0.571, Test accuracy: 78.58
Round  52, Global train loss: 0.379, Global test loss: 1.430, Global test accuracy: 51.43
Round  53, Train loss: 0.426, Test loss: 0.567, Test accuracy: 78.55
Round  53, Global train loss: 0.426, Global test loss: 1.470, Global test accuracy: 50.38
Round  54, Train loss: 0.391, Test loss: 0.554, Test accuracy: 79.38
Round  54, Global train loss: 0.391, Global test loss: 1.578, Global test accuracy: 48.08
Round  55, Train loss: 0.426, Test loss: 0.566, Test accuracy: 79.00
Round  55, Global train loss: 0.426, Global test loss: 1.379, Global test accuracy: 52.75
Round  56, Train loss: 0.394, Test loss: 0.568, Test accuracy: 78.90
Round  56, Global train loss: 0.394, Global test loss: 1.325, Global test accuracy: 55.33
Round  57, Train loss: 0.474, Test loss: 0.574, Test accuracy: 78.65
Round  57, Global train loss: 0.474, Global test loss: 1.321, Global test accuracy: 55.75
Round  58, Train loss: 0.428, Test loss: 0.570, Test accuracy: 78.53
Round  58, Global train loss: 0.428, Global test loss: 1.528, Global test accuracy: 51.83
Round  59, Train loss: 0.370, Test loss: 0.576, Test accuracy: 78.45
Round  59, Global train loss: 0.370, Global test loss: 1.485, Global test accuracy: 52.37
Round  60, Train loss: 0.388, Test loss: 0.585, Test accuracy: 78.10
Round  60, Global train loss: 0.388, Global test loss: 1.207, Global test accuracy: 58.45
Round  61, Train loss: 0.405, Test loss: 0.575, Test accuracy: 78.20
Round  61, Global train loss: 0.405, Global test loss: 1.330, Global test accuracy: 53.95
Round  62, Train loss: 0.384, Test loss: 0.577, Test accuracy: 78.50
Round  62, Global train loss: 0.384, Global test loss: 1.461, Global test accuracy: 52.88
Round  63, Train loss: 0.367, Test loss: 0.574, Test accuracy: 78.87
Round  63, Global train loss: 0.367, Global test loss: 1.364, Global test accuracy: 54.93
Round  64, Train loss: 0.390, Test loss: 0.572, Test accuracy: 78.85
Round  64, Global train loss: 0.390, Global test loss: 1.857, Global test accuracy: 48.97
Round  65, Train loss: 0.422, Test loss: 0.570, Test accuracy: 78.73
Round  65, Global train loss: 0.422, Global test loss: 1.414, Global test accuracy: 51.93
Round  66, Train loss: 0.383, Test loss: 0.563, Test accuracy: 79.13
Round  66, Global train loss: 0.383, Global test loss: 1.359, Global test accuracy: 53.77
Round  67, Train loss: 0.434, Test loss: 0.560, Test accuracy: 79.40
Round  67, Global train loss: 0.434, Global test loss: 1.281, Global test accuracy: 56.43
Round  68, Train loss: 0.386, Test loss: 0.560, Test accuracy: 79.48
Round  68, Global train loss: 0.386, Global test loss: 1.418, Global test accuracy: 54.97
Round  69, Train loss: 0.340, Test loss: 0.551, Test accuracy: 79.55
Round  69, Global train loss: 0.340, Global test loss: 1.512, Global test accuracy: 50.90
Round  70, Train loss: 0.358, Test loss: 0.570, Test accuracy: 79.17
Round  70, Global train loss: 0.358, Global test loss: 1.425, Global test accuracy: 53.62
Round  71, Train loss: 0.351, Test loss: 0.576, Test accuracy: 79.23
Round  71, Global train loss: 0.351, Global test loss: 1.488, Global test accuracy: 52.30
Round  72, Train loss: 0.405, Test loss: 0.580, Test accuracy: 79.20
Round  72, Global train loss: 0.405, Global test loss: 1.248, Global test accuracy: 58.30
Round  73, Train loss: 0.363, Test loss: 0.553, Test accuracy: 80.13
Round  73, Global train loss: 0.363, Global test loss: 1.314, Global test accuracy: 57.03
Round  74, Train loss: 0.330, Test loss: 0.574, Test accuracy: 79.70
Round  74, Global train loss: 0.330, Global test loss: 1.426, Global test accuracy: 54.12
Round  75, Train loss: 0.329, Test loss: 0.587, Test accuracy: 79.37
Round  75, Global train loss: 0.329, Global test loss: 1.280, Global test accuracy: 57.03
Round  76, Train loss: 0.329, Test loss: 0.582, Test accuracy: 79.45
Round  76, Global train loss: 0.329, Global test loss: 1.291, Global test accuracy: 56.10
Round  77, Train loss: 0.321, Test loss: 0.593, Test accuracy: 79.35
Round  77, Global train loss: 0.321, Global test loss: 1.319, Global test accuracy: 55.02
Round  78, Train loss: 0.366, Test loss: 0.554, Test accuracy: 80.40
Round  78, Global train loss: 0.366, Global test loss: 1.321, Global test accuracy: 57.00
Round  79, Train loss: 0.359, Test loss: 0.553, Test accuracy: 80.92
Round  79, Global train loss: 0.359, Global test loss: 1.380, Global test accuracy: 54.90
Round  80, Train loss: 0.316, Test loss: 0.561, Test accuracy: 80.65
Round  80, Global train loss: 0.316, Global test loss: 1.358, Global test accuracy: 56.50
Round  81, Train loss: 0.319, Test loss: 0.556, Test accuracy: 80.28
Round  81, Global train loss: 0.319, Global test loss: 1.879, Global test accuracy: 44.83
Round  82, Train loss: 0.327, Test loss: 0.583, Test accuracy: 80.20
Round  82, Global train loss: 0.327, Global test loss: 1.450, Global test accuracy: 54.23
Round  83, Train loss: 0.351, Test loss: 0.589, Test accuracy: 80.18
Round  83, Global train loss: 0.351, Global test loss: 1.578, Global test accuracy: 51.63
Round  84, Train loss: 0.313, Test loss: 0.581, Test accuracy: 80.57
Round  84, Global train loss: 0.313, Global test loss: 1.501, Global test accuracy: 53.67
Round  85, Train loss: 0.285, Test loss: 0.574, Test accuracy: 80.40
Round  85, Global train loss: 0.285, Global test loss: 1.460, Global test accuracy: 53.63
Round  86, Train loss: 0.331, Test loss: 0.566, Test accuracy: 80.98
Round  86, Global train loss: 0.331, Global test loss: 1.578, Global test accuracy: 53.32
Round  87, Train loss: 0.280, Test loss: 0.566, Test accuracy: 80.52
Round  87, Global train loss: 0.280, Global test loss: 1.490, Global test accuracy: 54.78
Round  88, Train loss: 0.334, Test loss: 0.577, Test accuracy: 80.03
Round  88, Global train loss: 0.334, Global test loss: 1.428, Global test accuracy: 56.70
Round  89, Train loss: 0.317, Test loss: 0.577, Test accuracy: 80.07
Round  89, Global train loss: 0.317, Global test loss: 1.434, Global test accuracy: 56.22
Round  90, Train loss: 0.290, Test loss: 0.579, Test accuracy: 80.65
Round  90, Global train loss: 0.290, Global test loss: 1.331, Global test accuracy: 57.87
Round  91, Train loss: 0.280, Test loss: 0.563, Test accuracy: 80.98
Round  91, Global train loss: 0.280, Global test loss: 1.426, Global test accuracy: 55.18
Round  92, Train loss: 0.236, Test loss: 0.578, Test accuracy: 80.55
Round  92, Global train loss: 0.236, Global test loss: 1.367, Global test accuracy: 56.95/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  93, Train loss: 0.295, Test loss: 0.581, Test accuracy: 80.57
Round  93, Global train loss: 0.295, Global test loss: 1.635, Global test accuracy: 52.68
Round  94, Train loss: 0.342, Test loss: 0.575, Test accuracy: 80.83
Round  94, Global train loss: 0.342, Global test loss: 1.482, Global test accuracy: 54.02
Round  95, Train loss: 0.265, Test loss: 0.575, Test accuracy: 80.80
Round  95, Global train loss: 0.265, Global test loss: 1.523, Global test accuracy: 53.85
Round  96, Train loss: 0.265, Test loss: 0.620, Test accuracy: 79.45
Round  96, Global train loss: 0.265, Global test loss: 1.277, Global test accuracy: 59.77
Round  97, Train loss: 0.338, Test loss: 0.615, Test accuracy: 79.17
Round  97, Global train loss: 0.338, Global test loss: 1.556, Global test accuracy: 52.60
Round  98, Train loss: 0.282, Test loss: 0.618, Test accuracy: 79.35
Round  98, Global train loss: 0.282, Global test loss: 1.298, Global test accuracy: 57.67
Round  99, Train loss: 0.261, Test loss: 0.624, Test accuracy: 79.42
Round  99, Global train loss: 0.261, Global test loss: 1.461, Global test accuracy: 57.28
Final Round, Train loss: 0.230, Test loss: 0.676, Test accuracy: 79.60
Final Round, Global train loss: 0.230, Global test loss: 1.461, Global test accuracy: 57.28
Average accuracy final 10 rounds: 80.17666666666666 

Average global accuracy final 10 rounds: 55.78666666666666 

1064.0271666049957
[1.0869033336639404, 2.173806667327881, 2.9905030727386475, 3.807199478149414, 4.667053699493408, 5.526907920837402, 6.359849452972412, 7.192790985107422, 7.955066442489624, 8.717341899871826, 9.486799955368042, 10.256258010864258, 11.015396356582642, 11.774534702301025, 12.541057825088501, 13.307580947875977, 14.094779253005981, 14.881977558135986, 15.674561738967896, 16.467145919799805, 17.252556085586548, 18.03796625137329, 18.81463932991028, 19.591312408447266, 20.34717321395874, 21.103034019470215, 21.86126971244812, 22.619505405426025, 23.382628917694092, 24.145752429962158, 24.912043571472168, 25.678334712982178, 26.464380502700806, 27.250426292419434, 28.037564754486084, 28.824703216552734, 29.62364649772644, 30.422589778900146, 31.202105283737183, 31.98162078857422, 32.73189616203308, 33.48217153549194, 34.247581481933594, 35.012991428375244, 35.76816749572754, 36.523343563079834, 37.283560276031494, 38.043776988983154, 38.850945711135864, 39.658114433288574, 40.4469940662384, 41.23587369918823, 42.0379843711853, 42.84009504318237, 43.62398386001587, 44.407872676849365, 45.16981792449951, 45.93176317214966, 46.69412398338318, 47.4564847946167, 48.21132016181946, 48.96615552902222, 49.74230360984802, 50.51845169067383, 51.32207465171814, 52.12569761276245, 52.91802620887756, 53.710354804992676, 54.5135440826416, 55.31673336029053, 56.09633779525757, 56.87594223022461, 57.629533767700195, 58.38312530517578, 59.14894437789917, 59.91476345062256, 60.67137861251831, 61.42799377441406, 62.208566665649414, 62.989139556884766, 63.77115440368652, 64.55316925048828, 65.34626269340515, 66.13935613632202, 66.94809341430664, 67.75683069229126, 68.54192686080933, 69.32702302932739, 70.08250665664673, 70.83799028396606, 71.61571550369263, 72.39344072341919, 73.15679454803467, 73.92014837265015, 74.70392799377441, 75.48770761489868, 76.28206992149353, 77.07643222808838, 77.86690616607666, 78.65738010406494, 79.44766807556152, 80.2379560470581, 81.0306305885315, 81.82330513000488, 82.58882641792297, 83.35434770584106, 84.12200784683228, 84.88966798782349, 85.65071368217468, 86.41175937652588, 87.20130014419556, 87.99084091186523, 88.7857894897461, 89.58073806762695, 90.37631702423096, 91.17189598083496, 91.96342301368713, 92.7549500465393, 93.50986886024475, 94.2647876739502, 95.03075981140137, 95.79673194885254, 96.56938648223877, 97.342041015625, 98.10684943199158, 98.87165784835815, 99.66025924682617, 100.44886064529419, 101.22989320755005, 102.01092576980591, 102.82155680656433, 103.63218784332275, 104.43570399284363, 105.2392201423645, 105.99737977981567, 106.75553941726685, 107.5258378982544, 108.29613637924194, 109.0615668296814, 109.82699728012085, 110.58811044692993, 111.34922361373901, 112.14203572273254, 112.93484783172607, 113.7077214717865, 114.48059511184692, 115.27648043632507, 116.07236576080322, 116.85587310791016, 117.63938045501709, 118.39656925201416, 119.15375804901123, 119.91511011123657, 120.67646217346191, 121.44373607635498, 122.21100997924805, 122.96781253814697, 123.7246150970459, 124.52813601493835, 125.33165693283081, 126.11119961738586, 126.89074230194092, 127.678231716156, 128.4657211303711, 129.24842596054077, 130.03113079071045, 130.80160546302795, 131.57208013534546, 132.35384321212769, 133.1356062889099, 133.91112279891968, 134.68663930892944, 135.46278595924377, 136.2389326095581, 137.03609681129456, 137.833261013031, 138.61417031288147, 139.39507961273193, 140.20046520233154, 141.00585079193115, 141.79364275932312, 142.5814347267151, 143.33224058151245, 144.08304643630981, 144.84560990333557, 145.60817337036133, 146.38067984580994, 147.15318632125854, 147.90506052970886, 148.65693473815918, 149.4545452594757, 150.25215578079224, 151.0272614955902, 151.80236721038818, 152.60096955299377, 153.39957189559937, 154.17834043502808, 154.9571089744568, 155.7118513584137, 156.4665937423706, 158.00669932365417, 159.54680490493774]
[24.25, 24.25, 39.916666666666664, 39.916666666666664, 47.6, 47.6, 52.766666666666666, 52.766666666666666, 56.35, 56.35, 60.266666666666666, 60.266666666666666, 64.83333333333333, 64.83333333333333, 65.46666666666667, 65.46666666666667, 66.78333333333333, 66.78333333333333, 67.4, 67.4, 68.03333333333333, 68.03333333333333, 68.38333333333334, 68.38333333333334, 69.68333333333334, 69.68333333333334, 70.85, 70.85, 70.98333333333333, 70.98333333333333, 71.41666666666667, 71.41666666666667, 72.31666666666666, 72.31666666666666, 72.01666666666667, 72.01666666666667, 72.61666666666666, 72.61666666666666, 73.0, 73.0, 73.26666666666667, 73.26666666666667, 73.45, 73.45, 73.7, 73.7, 74.6, 74.6, 73.83333333333333, 73.83333333333333, 74.03333333333333, 74.03333333333333, 74.35, 74.35, 74.21666666666667, 74.21666666666667, 74.5, 74.5, 74.9, 74.9, 75.6, 75.6, 76.78333333333333, 76.78333333333333, 76.53333333333333, 76.53333333333333, 77.0, 77.0, 76.56666666666666, 76.56666666666666, 77.31666666666666, 77.31666666666666, 77.98333333333333, 77.98333333333333, 77.6, 77.6, 78.16666666666667, 78.16666666666667, 78.01666666666667, 78.01666666666667, 78.08333333333333, 78.08333333333333, 77.61666666666666, 77.61666666666666, 77.41666666666667, 77.41666666666667, 78.61666666666666, 78.61666666666666, 78.26666666666667, 78.26666666666667, 78.08333333333333, 78.08333333333333, 77.65, 77.65, 77.35, 77.35, 77.7, 77.7, 78.2, 78.2, 78.61666666666666, 78.61666666666666, 78.2, 78.2, 78.58333333333333, 78.58333333333333, 78.55, 78.55, 79.38333333333334, 79.38333333333334, 79.0, 79.0, 78.9, 78.9, 78.65, 78.65, 78.53333333333333, 78.53333333333333, 78.45, 78.45, 78.1, 78.1, 78.2, 78.2, 78.5, 78.5, 78.86666666666666, 78.86666666666666, 78.85, 78.85, 78.73333333333333, 78.73333333333333, 79.13333333333334, 79.13333333333334, 79.4, 79.4, 79.48333333333333, 79.48333333333333, 79.55, 79.55, 79.16666666666667, 79.16666666666667, 79.23333333333333, 79.23333333333333, 79.2, 79.2, 80.13333333333334, 80.13333333333334, 79.7, 79.7, 79.36666666666666, 79.36666666666666, 79.45, 79.45, 79.35, 79.35, 80.4, 80.4, 80.91666666666667, 80.91666666666667, 80.65, 80.65, 80.28333333333333, 80.28333333333333, 80.2, 80.2, 80.18333333333334, 80.18333333333334, 80.56666666666666, 80.56666666666666, 80.4, 80.4, 80.98333333333333, 80.98333333333333, 80.51666666666667, 80.51666666666667, 80.03333333333333, 80.03333333333333, 80.06666666666666, 80.06666666666666, 80.65, 80.65, 80.98333333333333, 80.98333333333333, 80.55, 80.55, 80.56666666666666, 80.56666666666666, 80.83333333333333, 80.83333333333333, 80.8, 80.8, 79.45, 79.45, 79.16666666666667, 79.16666666666667, 79.35, 79.35, 79.41666666666667, 79.41666666666667, 79.6, 79.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.698, Test loss: 2.158, Test accuracy: 16.47
Round   1, Train loss: 1.135, Test loss: 1.967, Test accuracy: 31.68
Round   2, Train loss: 1.033, Test loss: 1.444, Test accuracy: 41.65
Round   3, Train loss: 0.949, Test loss: 1.212, Test accuracy: 50.15
Round   4, Train loss: 0.926, Test loss: 1.117, Test accuracy: 55.08
Round   5, Train loss: 0.876, Test loss: 0.903, Test accuracy: 60.25
Round   6, Train loss: 0.802, Test loss: 0.777, Test accuracy: 65.92
Round   7, Train loss: 0.761, Test loss: 0.754, Test accuracy: 68.62
Round   8, Train loss: 0.816, Test loss: 0.729, Test accuracy: 69.23
Round   9, Train loss: 0.768, Test loss: 0.708, Test accuracy: 69.03
Round  10, Train loss: 0.765, Test loss: 0.694, Test accuracy: 70.78
Round  11, Train loss: 0.642, Test loss: 0.678, Test accuracy: 70.92
Round  12, Train loss: 0.711, Test loss: 0.669, Test accuracy: 71.00
Round  13, Train loss: 0.744, Test loss: 0.655, Test accuracy: 71.87
Round  14, Train loss: 0.729, Test loss: 0.644, Test accuracy: 72.15
Round  15, Train loss: 0.647, Test loss: 0.638, Test accuracy: 72.75
Round  16, Train loss: 0.654, Test loss: 0.627, Test accuracy: 72.27
Round  17, Train loss: 0.642, Test loss: 0.610, Test accuracy: 73.73
Round  18, Train loss: 0.622, Test loss: 0.602, Test accuracy: 73.67
Round  19, Train loss: 0.667, Test loss: 0.602, Test accuracy: 74.02
Round  20, Train loss: 0.643, Test loss: 0.589, Test accuracy: 75.13
Round  21, Train loss: 0.618, Test loss: 0.586, Test accuracy: 75.50
Round  22, Train loss: 0.555, Test loss: 0.584, Test accuracy: 76.12
Round  23, Train loss: 0.665, Test loss: 0.567, Test accuracy: 76.73
Round  24, Train loss: 0.569, Test loss: 0.566, Test accuracy: 76.53
Round  25, Train loss: 0.574, Test loss: 0.563, Test accuracy: 76.55
Round  26, Train loss: 0.547, Test loss: 0.552, Test accuracy: 77.25
Round  27, Train loss: 0.562, Test loss: 0.561, Test accuracy: 77.25
Round  28, Train loss: 0.555, Test loss: 0.546, Test accuracy: 77.70
Round  29, Train loss: 0.601, Test loss: 0.536, Test accuracy: 78.50
Round  30, Train loss: 0.547, Test loss: 0.525, Test accuracy: 78.55
Round  31, Train loss: 0.459, Test loss: 0.526, Test accuracy: 78.63
Round  32, Train loss: 0.492, Test loss: 0.527, Test accuracy: 78.52
Round  33, Train loss: 0.597, Test loss: 0.517, Test accuracy: 78.68
Round  34, Train loss: 0.502, Test loss: 0.522, Test accuracy: 78.95
Round  35, Train loss: 0.537, Test loss: 0.520, Test accuracy: 79.12
Round  36, Train loss: 0.494, Test loss: 0.527, Test accuracy: 78.00
Round  37, Train loss: 0.511, Test loss: 0.517, Test accuracy: 78.55
Round  38, Train loss: 0.499, Test loss: 0.509, Test accuracy: 78.92
Round  39, Train loss: 0.507, Test loss: 0.507, Test accuracy: 78.93
Round  40, Train loss: 0.529, Test loss: 0.500, Test accuracy: 79.43
Round  41, Train loss: 0.492, Test loss: 0.496, Test accuracy: 79.50
Round  42, Train loss: 0.541, Test loss: 0.498, Test accuracy: 79.57
Round  43, Train loss: 0.508, Test loss: 0.485, Test accuracy: 80.18
Round  44, Train loss: 0.488, Test loss: 0.483, Test accuracy: 80.57
Round  45, Train loss: 0.502, Test loss: 0.483, Test accuracy: 80.42
Round  46, Train loss: 0.562, Test loss: 0.465, Test accuracy: 80.82
Round  47, Train loss: 0.505, Test loss: 0.468, Test accuracy: 80.93
Round  48, Train loss: 0.496, Test loss: 0.467, Test accuracy: 81.18
Round  49, Train loss: 0.495, Test loss: 0.463, Test accuracy: 81.40
Round  50, Train loss: 0.474, Test loss: 0.466, Test accuracy: 81.40
Round  51, Train loss: 0.496, Test loss: 0.457, Test accuracy: 81.28
Round  52, Train loss: 0.383, Test loss: 0.467, Test accuracy: 81.17
Round  53, Train loss: 0.474, Test loss: 0.462, Test accuracy: 81.28
Round  54, Train loss: 0.400, Test loss: 0.459, Test accuracy: 80.92
Round  55, Train loss: 0.400, Test loss: 0.455, Test accuracy: 81.08
Round  56, Train loss: 0.372, Test loss: 0.450, Test accuracy: 81.63
Round  57, Train loss: 0.427, Test loss: 0.448, Test accuracy: 81.85
Round  58, Train loss: 0.463, Test loss: 0.451, Test accuracy: 81.95
Round  59, Train loss: 0.413, Test loss: 0.447, Test accuracy: 82.15
Round  60, Train loss: 0.458, Test loss: 0.439, Test accuracy: 82.70
Round  61, Train loss: 0.367, Test loss: 0.440, Test accuracy: 82.47
Round  62, Train loss: 0.437, Test loss: 0.439, Test accuracy: 82.10
Round  63, Train loss: 0.351, Test loss: 0.436, Test accuracy: 82.20
Round  64, Train loss: 0.410, Test loss: 0.432, Test accuracy: 82.50
Round  65, Train loss: 0.392, Test loss: 0.427, Test accuracy: 83.13
Round  66, Train loss: 0.376, Test loss: 0.429, Test accuracy: 83.05
Round  67, Train loss: 0.464, Test loss: 0.433, Test accuracy: 83.03
Round  68, Train loss: 0.426, Test loss: 0.428, Test accuracy: 83.03
Round  69, Train loss: 0.386, Test loss: 0.429, Test accuracy: 82.97
Round  70, Train loss: 0.412, Test loss: 0.429, Test accuracy: 83.23
Round  71, Train loss: 0.404, Test loss: 0.427, Test accuracy: 83.18
Round  72, Train loss: 0.429, Test loss: 0.429, Test accuracy: 82.85
Round  73, Train loss: 0.436, Test loss: 0.418, Test accuracy: 83.77
Round  74, Train loss: 0.370, Test loss: 0.415, Test accuracy: 83.65
Round  75, Train loss: 0.368, Test loss: 0.424, Test accuracy: 83.08
Round  76, Train loss: 0.348, Test loss: 0.427, Test accuracy: 83.27
Round  77, Train loss: 0.317, Test loss: 0.430, Test accuracy: 83.10
Round  78, Train loss: 0.391, Test loss: 0.427, Test accuracy: 83.02
Round  79, Train loss: 0.399, Test loss: 0.421, Test accuracy: 83.13
Round  80, Train loss: 0.332, Test loss: 0.417, Test accuracy: 83.25
Round  81, Train loss: 0.360, Test loss: 0.422, Test accuracy: 83.20
Round  82, Train loss: 0.358, Test loss: 0.437, Test accuracy: 82.43
Round  83, Train loss: 0.361, Test loss: 0.421, Test accuracy: 83.55
Round  84, Train loss: 0.351, Test loss: 0.419, Test accuracy: 83.85
Round  85, Train loss: 0.339, Test loss: 0.418, Test accuracy: 83.62
Round  86, Train loss: 0.372, Test loss: 0.422, Test accuracy: 83.35
Round  87, Train loss: 0.335, Test loss: 0.417, Test accuracy: 83.53
Round  88, Train loss: 0.302, Test loss: 0.413, Test accuracy: 84.18
Round  89, Train loss: 0.340, Test loss: 0.411, Test accuracy: 84.08
Round  90, Train loss: 0.308, Test loss: 0.411, Test accuracy: 83.85
Round  91, Train loss: 0.300, Test loss: 0.416, Test accuracy: 83.65
Round  92, Train loss: 0.246, Test loss: 0.414, Test accuracy: 83.93
Round  93, Train loss: 0.331, Test loss: 0.416, Test accuracy: 83.87
Round  94, Train loss: 0.383, Test loss: 0.410, Test accuracy: 84.45
Round  95, Train loss: 0.314, Test loss: 0.401, Test accuracy: 84.57
Round  96, Train loss: 0.309, Test loss: 0.405, Test accuracy: 84.38
Round  97, Train loss: 0.326, Test loss: 0.413, Test accuracy: 84.12
Round  98, Train loss: 0.356, Test loss: 0.405, Test accuracy: 84.42
Round  99, Train loss: 0.290, Test loss: 0.412, Test accuracy: 84.07
Final Round, Train loss: 0.266, Test loss: 0.412, Test accuracy: 84.45
Average accuracy final 10 rounds: 84.13
745.5804460048676
[1.1835196018218994, 2.127500057220459, 3.047227382659912, 3.955132007598877, 4.835400819778442, 5.7226104736328125, 6.61951208114624, 7.511286020278931, 8.369977235794067, 9.312349319458008, 10.214441299438477, 11.16258716583252, 12.097468376159668, 13.05052399635315, 13.970664739608765, 14.849767208099365, 15.732284307479858, 16.628621101379395, 17.507392644882202, 18.37146496772766, 19.257450580596924, 20.18656325340271, 21.09909677505493, 22.029316425323486, 22.975661993026733, 23.919288873672485, 24.84712791442871, 25.738653659820557, 26.603007316589355, 27.494382858276367, 28.3919997215271, 29.28870177268982, 30.157819986343384, 31.10768985748291, 32.017245054244995, 32.93477654457092, 33.85763335227966, 34.84524607658386, 35.76187181472778, 36.64072775840759, 37.52098989486694, 38.41512966156006, 39.273768186569214, 40.153242111206055, 41.088873863220215, 42.02822947502136, 42.95500135421753, 43.90037798881531, 44.84011697769165, 45.77331781387329, 46.65820908546448, 47.54051661491394, 48.412131547927856, 49.28913068771362, 50.15702772140503, 51.03447413444519, 51.95371913909912, 52.84653353691101, 53.74320340156555, 54.702293395996094, 55.643863677978516, 56.53303790092468, 57.38214421272278, 58.27426195144653, 59.16015291213989, 60.00699257850647, 60.887285470962524, 61.78280305862427, 62.717249155044556, 63.597161531448364, 64.53134727478027, 65.4767439365387, 66.37890219688416, 67.28657102584839, 68.17431020736694, 69.02795910835266, 69.88131070137024, 70.738272190094, 71.62274742126465, 72.53233504295349, 73.42517924308777, 74.32953715324402, 75.26448130607605, 76.2348518371582, 77.20028781890869, 78.10642099380493, 78.97966051101685, 79.87368512153625, 80.74629044532776, 81.60691714286804, 82.51585531234741, 83.45721101760864, 84.35846257209778, 85.28603672981262, 86.23580384254456, 87.16334295272827, 88.05301904678345, 88.92787885665894, 89.81613636016846, 90.69108986854553, 92.10972476005554]
[16.466666666666665, 31.683333333333334, 41.65, 50.15, 55.083333333333336, 60.25, 65.91666666666667, 68.61666666666666, 69.23333333333333, 69.03333333333333, 70.78333333333333, 70.91666666666667, 71.0, 71.86666666666666, 72.15, 72.75, 72.26666666666667, 73.73333333333333, 73.66666666666667, 74.01666666666667, 75.13333333333334, 75.5, 76.11666666666666, 76.73333333333333, 76.53333333333333, 76.55, 77.25, 77.25, 77.7, 78.5, 78.55, 78.63333333333334, 78.51666666666667, 78.68333333333334, 78.95, 79.11666666666666, 78.0, 78.55, 78.91666666666667, 78.93333333333334, 79.43333333333334, 79.5, 79.56666666666666, 80.18333333333334, 80.56666666666666, 80.41666666666667, 80.81666666666666, 80.93333333333334, 81.18333333333334, 81.4, 81.4, 81.28333333333333, 81.16666666666667, 81.28333333333333, 80.91666666666667, 81.08333333333333, 81.63333333333334, 81.85, 81.95, 82.15, 82.7, 82.46666666666667, 82.1, 82.2, 82.5, 83.13333333333334, 83.05, 83.03333333333333, 83.03333333333333, 82.96666666666667, 83.23333333333333, 83.18333333333334, 82.85, 83.76666666666667, 83.65, 83.08333333333333, 83.26666666666667, 83.1, 83.01666666666667, 83.13333333333334, 83.25, 83.2, 82.43333333333334, 83.55, 83.85, 83.61666666666666, 83.35, 83.53333333333333, 84.18333333333334, 84.08333333333333, 83.85, 83.65, 83.93333333333334, 83.86666666666666, 84.45, 84.56666666666666, 84.38333333333334, 84.11666666666666, 84.41666666666667, 84.06666666666666, 84.45]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  10.3800
Round 1 global test acc  14.4900
Round 2 global test acc  16.5000
Round 3 global test acc  22.3400
Round 4 global test acc  22.4100
Round 5 global test acc  22.5100
Round 6 global test acc  18.7000
Round 7 global test acc  21.9000
Round 8 global test acc  22.0000
Round 9 global test acc  23.1600
Round 10 global test acc  24.5800
Round 11 global test acc  27.2300
Round 12 global test acc  26.6500
Round 13 global test acc  25.6100
Round 14 global test acc  21.6300
Round 15 global test acc  24.0400
Round 16 global test acc  25.1200
Round 17 global test acc  25.6100
Round 18 global test acc  31.1900
Round 19 global test acc  23.5100
Round 20 global test acc  21.1600
Round 21 global test acc  29.9600
Round 22 global test acc  26.0200
Round 23 global test acc  24.3600
Round 24 global test acc  21.7900
Round 25 global test acc  28.7700
Round 26 global test acc  32.1900
Round 27 global test acc  32.5300
Round 28 global test acc  29.5900
Round 29 global test acc  26.5300
Round 30 global test acc  32.2900
Round 31 global test acc  35.2100
Round 32 global test acc  24.2300
Round 33 global test acc  24.0500
Round 34 global test acc  28.6300
Round 35 global test acc  32.3400
Round 36 global test acc  35.9700
Round 37 global test acc  37.4200
Round 38 global test acc  25.5600
Round 39 global test acc  22.9100
Round 40 global test acc  34.5700
Round 41 global test acc  34.8600
Round 42 global test acc  32.1300
Round 43 global test acc  30.0300
Round 44 global test acc  36.4600
Round 45 global test acc  24.0900
Round 46 global test acc  29.6100
Round 47 global test acc  37.5700
Round 48 global test acc  34.5500
Round 49 global test acc  29.6100
Round 50 global test acc  35.1200
Round 51 global test acc  35.2800
Round 52 global test acc  26.5800
Round 53 global test acc  26.8100
Round 54 global test acc  26.6500
Round 55 global test acc  30.4200
Round 56 global test acc  32.5800
Round 57 global test acc  29.6700
Round 58 global test acc  27.9800
Round 59 global test acc  28.9100
Round 60 global test acc  28.3800
Round 61 global test acc  35.3400
Round 62 global test acc  21.7600
Round 63 global test acc  32.6900
Round 64 global test acc  32.5900
Round 65 global test acc  30.3300
Round 66 global test acc  33.5700
Round 67 global test acc  32.7200
Round 68 global test acc  33.5700
Round 69 global test acc  29.7800
Round 70 global test acc  36.8400
Round 71 global test acc  37.3000
Round 72 global test acc  36.3600
Round 73 global test acc  28.0000
Round 74 global test acc  32.6700
Round 75 global test acc  34.4000
Round 76 global test acc  29.2700
Round 77 global test acc  38.7700
Round 78 global test acc  30.2200
Round 79 global test acc  33.2900
Round 80 global test acc  31.5400
Round 81 global test acc  33.4800
Round 82 global test acc  29.1700
Round 83 global test acc  31.5700
Round 84 global test acc  29.3100
Round 85 global test acc  29.2300
Round 86 global test acc  28.3800
Round 87 global test acc  27.2800
Round 88 global test acc  24.0000
Round 89 global test acc  23.1600
Round 90 global test acc  22.0600
Round 91 global test acc  22.4700
Round 92 global test acc  21.5200
Round 93 global test acc  22.8000
Round 94 global test acc  22.9200
Round 95 global test acc  23.2300
Round 96 global test acc  22.7300
Round 97 global test acc  22.4500
Round 98 global test acc  22.0400
Round 99 global test acc  22.2200
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.715, Test loss: 2.243, Test accuracy: 16.32
Round   1, Train loss: 1.175, Test loss: 1.997, Test accuracy: 32.30
Round   2, Train loss: 1.059, Test loss: 1.504, Test accuracy: 41.98
Round   3, Train loss: 1.023, Test loss: 1.237, Test accuracy: 49.43
Round   4, Train loss: 0.926, Test loss: 1.134, Test accuracy: 54.13
Round   5, Train loss: 0.882, Test loss: 0.928, Test accuracy: 58.87
Round   6, Train loss: 0.794, Test loss: 0.800, Test accuracy: 63.53
Round   7, Train loss: 0.748, Test loss: 0.788, Test accuracy: 63.70
Round   8, Train loss: 0.826, Test loss: 0.748, Test accuracy: 66.28
Round   9, Train loss: 0.801, Test loss: 0.736, Test accuracy: 68.47
Round  10, Train loss: 0.748, Test loss: 0.713, Test accuracy: 69.60
Round  11, Train loss: 0.666, Test loss: 0.697, Test accuracy: 69.17
Round  12, Train loss: 0.699, Test loss: 0.685, Test accuracy: 70.87
Round  13, Train loss: 0.747, Test loss: 0.663, Test accuracy: 72.23
Round  14, Train loss: 0.772, Test loss: 0.643, Test accuracy: 72.47
Round  15, Train loss: 0.686, Test loss: 0.653, Test accuracy: 71.70
Round  16, Train loss: 0.662, Test loss: 0.639, Test accuracy: 73.02
Round  17, Train loss: 0.673, Test loss: 0.616, Test accuracy: 73.77
Round  18, Train loss: 0.684, Test loss: 0.612, Test accuracy: 74.23
Round  19, Train loss: 0.652, Test loss: 0.610, Test accuracy: 74.77
Round  20, Train loss: 0.686, Test loss: 0.609, Test accuracy: 74.62
Round  21, Train loss: 0.608, Test loss: 0.598, Test accuracy: 74.90
Round  22, Train loss: 0.582, Test loss: 0.591, Test accuracy: 75.63
Round  23, Train loss: 0.727, Test loss: 0.582, Test accuracy: 75.42
Round  24, Train loss: 0.615, Test loss: 0.573, Test accuracy: 76.57
Round  25, Train loss: 0.635, Test loss: 0.572, Test accuracy: 76.22
Round  26, Train loss: 0.618, Test loss: 0.565, Test accuracy: 76.67
Round  27, Train loss: 0.592, Test loss: 0.560, Test accuracy: 76.93
Round  28, Train loss: 0.516, Test loss: 0.558, Test accuracy: 76.50
Round  29, Train loss: 0.636, Test loss: 0.547, Test accuracy: 76.87
Round  30, Train loss: 0.595, Test loss: 0.543, Test accuracy: 77.38
Round  31, Train loss: 0.467, Test loss: 0.539, Test accuracy: 77.47
Round  32, Train loss: 0.449, Test loss: 0.544, Test accuracy: 77.43
Round  33, Train loss: 0.585, Test loss: 0.526, Test accuracy: 78.28
Round  34, Train loss: 0.488, Test loss: 0.523, Test accuracy: 78.32
Round  35, Train loss: 0.601, Test loss: 0.525, Test accuracy: 78.83
Round  36, Train loss: 0.513, Test loss: 0.525, Test accuracy: 78.40
Round  37, Train loss: 0.525, Test loss: 0.523, Test accuracy: 78.68
Round  38, Train loss: 0.466, Test loss: 0.528, Test accuracy: 78.73
Round  39, Train loss: 0.556, Test loss: 0.512, Test accuracy: 79.30
Round  40, Train loss: 0.524, Test loss: 0.513, Test accuracy: 79.07
Round  41, Train loss: 0.511, Test loss: 0.513, Test accuracy: 79.18
Round  42, Train loss: 0.588, Test loss: 0.509, Test accuracy: 78.95
Round  43, Train loss: 0.516, Test loss: 0.501, Test accuracy: 79.83
Round  44, Train loss: 0.529, Test loss: 0.489, Test accuracy: 80.37
Round  45, Train loss: 0.536, Test loss: 0.503, Test accuracy: 80.18
Round  46, Train loss: 0.625, Test loss: 0.485, Test accuracy: 80.32
Round  47, Train loss: 0.519, Test loss: 0.482, Test accuracy: 80.42
Round  48, Train loss: 0.515, Test loss: 0.485, Test accuracy: 80.70
Round  49, Train loss: 0.527, Test loss: 0.480, Test accuracy: 81.03
Round  50, Train loss: 0.550, Test loss: 0.477, Test accuracy: 80.82
Round  51, Train loss: 0.530, Test loss: 0.473, Test accuracy: 80.92
Round  52, Train loss: 0.451, Test loss: 0.473, Test accuracy: 80.72
Round  53, Train loss: 0.502, Test loss: 0.476, Test accuracy: 80.60
Round  54, Train loss: 0.415, Test loss: 0.477, Test accuracy: 81.20
Round  55, Train loss: 0.474, Test loss: 0.483, Test accuracy: 80.58
Round  56, Train loss: 0.426, Test loss: 0.468, Test accuracy: 81.18
Round  57, Train loss: 0.478, Test loss: 0.477, Test accuracy: 80.42
Round  58, Train loss: 0.524, Test loss: 0.476, Test accuracy: 80.53
Round  59, Train loss: 0.439, Test loss: 0.465, Test accuracy: 81.17
Round  60, Train loss: 0.460, Test loss: 0.462, Test accuracy: 81.07
Round  61, Train loss: 0.423, Test loss: 0.457, Test accuracy: 81.63
Round  62, Train loss: 0.409, Test loss: 0.470, Test accuracy: 80.95
Round  63, Train loss: 0.408, Test loss: 0.460, Test accuracy: 81.53
Round  64, Train loss: 0.435, Test loss: 0.451, Test accuracy: 81.70
Round  65, Train loss: 0.447, Test loss: 0.446, Test accuracy: 82.22
Round  66, Train loss: 0.432, Test loss: 0.449, Test accuracy: 81.93
Round  67, Train loss: 0.494, Test loss: 0.454, Test accuracy: 81.70
Round  68, Train loss: 0.453, Test loss: 0.446, Test accuracy: 82.12
Round  69, Train loss: 0.397, Test loss: 0.441, Test accuracy: 82.58
Round  70, Train loss: 0.396, Test loss: 0.449, Test accuracy: 82.02
Round  71, Train loss: 0.466, Test loss: 0.452, Test accuracy: 81.88
Round  72, Train loss: 0.453, Test loss: 0.450, Test accuracy: 82.43
Round  73, Train loss: 0.421, Test loss: 0.446, Test accuracy: 82.35
Round  74, Train loss: 0.367, Test loss: 0.442, Test accuracy: 82.72
Round  75, Train loss: 0.430, Test loss: 0.439, Test accuracy: 82.83
Round  76, Train loss: 0.430, Test loss: 0.431, Test accuracy: 82.92
Round  77, Train loss: 0.364, Test loss: 0.427, Test accuracy: 82.95
Round  78, Train loss: 0.387, Test loss: 0.436, Test accuracy: 82.65
Round  79, Train loss: 0.411, Test loss: 0.436, Test accuracy: 82.70
Round  80, Train loss: 0.320, Test loss: 0.433, Test accuracy: 82.95
Round  81, Train loss: 0.409, Test loss: 0.433, Test accuracy: 82.78
Round  82, Train loss: 0.397, Test loss: 0.433, Test accuracy: 82.98
Round  83, Train loss: 0.420, Test loss: 0.435, Test accuracy: 82.75
Round  84, Train loss: 0.387, Test loss: 0.429, Test accuracy: 83.38
Round  85, Train loss: 0.332, Test loss: 0.429, Test accuracy: 83.25
Round  86, Train loss: 0.415, Test loss: 0.439, Test accuracy: 83.00
Round  87, Train loss: 0.323, Test loss: 0.436, Test accuracy: 83.52
Round  88, Train loss: 0.304, Test loss: 0.427, Test accuracy: 83.13
Round  89, Train loss: 0.351, Test loss: 0.427, Test accuracy: 83.53
Round  90, Train loss: 0.338, Test loss: 0.431, Test accuracy: 83.48
Round  91, Train loss: 0.320, Test loss: 0.430, Test accuracy: 83.13
Round  92, Train loss: 0.277, Test loss: 0.432, Test accuracy: 83.00
Round  93, Train loss: 0.357, Test loss: 0.441, Test accuracy: 82.38
Round  94, Train loss: 0.423, Test loss: 0.429, Test accuracy: 83.18
Round  95, Train loss: 0.282, Test loss: 0.424, Test accuracy: 83.67
Round  96, Train loss: 0.321, Test loss: 0.423, Test accuracy: 83.83
Round  97, Train loss: 0.397, Test loss: 0.432, Test accuracy: 83.32
Round  98, Train loss: 0.395, Test loss: 0.432, Test accuracy: 83.40
Round  99, Train loss: 0.337, Test loss: 0.431, Test accuracy: 83.53
Final Round, Train loss: 0.291, Test loss: 0.430, Test accuracy: 83.72
Average accuracy final 10 rounds: 83.29333333333335
728.3196506500244
[1.1981868743896484, 2.07216739654541, 2.944326877593994, 3.801309585571289, 4.678768634796143, 5.605695724487305, 6.514477968215942, 7.414235830307007, 8.3226957321167, 9.227038860321045, 10.103851079940796, 10.974760055541992, 11.825108289718628, 12.681892395019531, 13.553207159042358, 14.41769528388977, 15.299824237823486, 16.2103168964386, 17.120973110198975, 18.043489933013916, 18.910429000854492, 19.810015439987183, 20.696556568145752, 21.531553506851196, 22.386740922927856, 23.262288570404053, 24.13503885269165, 24.990499258041382, 25.886383533477783, 26.78532123565674, 27.705052375793457, 28.59983515739441, 29.502044677734375, 30.392893075942993, 31.260007619857788, 32.11187815666199, 32.94917416572571, 33.8158438205719, 34.685627937316895, 35.54191470146179, 36.423866748809814, 37.319828033447266, 38.201103925704956, 39.09372353553772, 39.9838604927063, 40.87661004066467, 41.72617173194885, 42.561286211013794, 43.43176341056824, 44.30505132675171, 45.15574264526367, 46.034454107284546, 46.96633791923523, 47.827781677246094, 48.71374702453613, 49.61945915222168, 50.49439811706543, 51.35243797302246, 52.19595432281494, 53.04691696166992, 53.883065700531006, 54.74149441719055, 55.611034631729126, 56.481133699417114, 57.372289180755615, 58.261109590530396, 59.145535707473755, 60.045271158218384, 60.92627167701721, 61.7640540599823, 62.594656229019165, 63.45452046394348, 64.31963872909546, 65.15653395652771, 66.0525312423706, 66.98618507385254, 67.87098026275635, 68.78356146812439, 69.69640231132507, 70.58346939086914, 71.44850468635559, 72.30852365493774, 73.17216730117798, 74.04600644111633, 74.90405416488647, 75.75167179107666, 76.6551125049591, 77.53998255729675, 78.47160911560059, 79.34459614753723, 80.22342157363892, 81.11573791503906, 81.9700620174408, 82.8199245929718, 83.70538926124573, 84.58073472976685, 85.43616771697998, 86.30867743492126, 87.2177803516388, 88.11721849441528, 89.52010464668274]
[16.316666666666666, 32.3, 41.983333333333334, 49.43333333333333, 54.13333333333333, 58.86666666666667, 63.53333333333333, 63.7, 66.28333333333333, 68.46666666666667, 69.6, 69.16666666666667, 70.86666666666666, 72.23333333333333, 72.46666666666667, 71.7, 73.01666666666667, 73.76666666666667, 74.23333333333333, 74.76666666666667, 74.61666666666666, 74.9, 75.63333333333334, 75.41666666666667, 76.56666666666666, 76.21666666666667, 76.66666666666667, 76.93333333333334, 76.5, 76.86666666666666, 77.38333333333334, 77.46666666666667, 77.43333333333334, 78.28333333333333, 78.31666666666666, 78.83333333333333, 78.4, 78.68333333333334, 78.73333333333333, 79.3, 79.06666666666666, 79.18333333333334, 78.95, 79.83333333333333, 80.36666666666666, 80.18333333333334, 80.31666666666666, 80.41666666666667, 80.7, 81.03333333333333, 80.81666666666666, 80.91666666666667, 80.71666666666667, 80.6, 81.2, 80.58333333333333, 81.18333333333334, 80.41666666666667, 80.53333333333333, 81.16666666666667, 81.06666666666666, 81.63333333333334, 80.95, 81.53333333333333, 81.7, 82.21666666666667, 81.93333333333334, 81.7, 82.11666666666666, 82.58333333333333, 82.01666666666667, 81.88333333333334, 82.43333333333334, 82.35, 82.71666666666667, 82.83333333333333, 82.91666666666667, 82.95, 82.65, 82.7, 82.95, 82.78333333333333, 82.98333333333333, 82.75, 83.38333333333334, 83.25, 83.0, 83.51666666666667, 83.13333333333334, 83.53333333333333, 83.48333333333333, 83.13333333333334, 83.0, 82.38333333333334, 83.18333333333334, 83.66666666666667, 83.83333333333333, 83.31666666666666, 83.4, 83.53333333333333, 83.71666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.724, Test loss: 2.136, Test accuracy: 17.78
Round   1, Train loss: 1.161, Test loss: 1.924, Test accuracy: 32.62
Round   2, Train loss: 1.006, Test loss: 1.398, Test accuracy: 44.50
Round   3, Train loss: 0.997, Test loss: 1.207, Test accuracy: 52.23
Round   4, Train loss: 0.948, Test loss: 1.107, Test accuracy: 56.17
Round   5, Train loss: 0.882, Test loss: 0.902, Test accuracy: 61.17
Round   6, Train loss: 0.854, Test loss: 0.791, Test accuracy: 64.35
Round   7, Train loss: 0.745, Test loss: 0.774, Test accuracy: 66.92
Round   8, Train loss: 0.842, Test loss: 0.745, Test accuracy: 67.12
Round   9, Train loss: 0.748, Test loss: 0.721, Test accuracy: 67.72
Round  10, Train loss: 0.830, Test loss: 0.707, Test accuracy: 69.45
Round  11, Train loss: 0.675, Test loss: 0.692, Test accuracy: 69.70
Round  12, Train loss: 0.689, Test loss: 0.669, Test accuracy: 70.75
Round  13, Train loss: 0.758, Test loss: 0.656, Test accuracy: 71.38
Round  14, Train loss: 0.747, Test loss: 0.645, Test accuracy: 71.93
Round  15, Train loss: 0.662, Test loss: 0.654, Test accuracy: 72.32
Round  16, Train loss: 0.671, Test loss: 0.632, Test accuracy: 72.78
Round  17, Train loss: 0.648, Test loss: 0.626, Test accuracy: 73.65
Round  18, Train loss: 0.651, Test loss: 0.616, Test accuracy: 74.15
Round  19, Train loss: 0.714, Test loss: 0.614, Test accuracy: 73.95
Round  20, Train loss: 0.665, Test loss: 0.605, Test accuracy: 73.73
Round  21, Train loss: 0.635, Test loss: 0.602, Test accuracy: 73.98
Round  22, Train loss: 0.589, Test loss: 0.586, Test accuracy: 75.08
Round  23, Train loss: 0.709, Test loss: 0.585, Test accuracy: 75.45
Round  24, Train loss: 0.563, Test loss: 0.587, Test accuracy: 76.05
Round  25, Train loss: 0.618, Test loss: 0.566, Test accuracy: 76.28
Round  26, Train loss: 0.588, Test loss: 0.573, Test accuracy: 76.57
Round  27, Train loss: 0.593, Test loss: 0.561, Test accuracy: 76.67
Round  28, Train loss: 0.530, Test loss: 0.556, Test accuracy: 77.45
Round  29, Train loss: 0.605, Test loss: 0.555, Test accuracy: 77.87
Round  30, Train loss: 0.579, Test loss: 0.537, Test accuracy: 78.57
Round  31, Train loss: 0.496, Test loss: 0.543, Test accuracy: 78.40
Round  32, Train loss: 0.494, Test loss: 0.547, Test accuracy: 78.38
Round  33, Train loss: 0.582, Test loss: 0.541, Test accuracy: 78.65
Round  34, Train loss: 0.538, Test loss: 0.540, Test accuracy: 78.67
Round  35, Train loss: 0.592, Test loss: 0.542, Test accuracy: 78.02
Round  36, Train loss: 0.569, Test loss: 0.540, Test accuracy: 78.43
Round  37, Train loss: 0.567, Test loss: 0.528, Test accuracy: 79.05
Round  38, Train loss: 0.537, Test loss: 0.528, Test accuracy: 78.90
Round  39, Train loss: 0.560, Test loss: 0.523, Test accuracy: 78.67
Round  40, Train loss: 0.578, Test loss: 0.513, Test accuracy: 78.93
Round  41, Train loss: 0.575, Test loss: 0.514, Test accuracy: 79.23
Round  42, Train loss: 0.569, Test loss: 0.513, Test accuracy: 79.37
Round  43, Train loss: 0.596, Test loss: 0.506, Test accuracy: 79.68
Round  44, Train loss: 0.458, Test loss: 0.505, Test accuracy: 79.85
Round  45, Train loss: 0.538, Test loss: 0.509, Test accuracy: 79.17
Round  46, Train loss: 0.607, Test loss: 0.497, Test accuracy: 79.53
Round  47, Train loss: 0.502, Test loss: 0.487, Test accuracy: 80.53
Round  48, Train loss: 0.563, Test loss: 0.485, Test accuracy: 80.43
Round  49, Train loss: 0.558, Test loss: 0.480, Test accuracy: 80.35
Round  50, Train loss: 0.505, Test loss: 0.480, Test accuracy: 80.30
Round  51, Train loss: 0.509, Test loss: 0.477, Test accuracy: 80.80
Round  52, Train loss: 0.429, Test loss: 0.488, Test accuracy: 80.42
Round  53, Train loss: 0.555, Test loss: 0.473, Test accuracy: 81.08
Round  54, Train loss: 0.434, Test loss: 0.474, Test accuracy: 80.75
Round  55, Train loss: 0.446, Test loss: 0.469, Test accuracy: 80.80
Round  56, Train loss: 0.437, Test loss: 0.468, Test accuracy: 81.38
Round  57, Train loss: 0.451, Test loss: 0.470, Test accuracy: 80.93
Round  58, Train loss: 0.458, Test loss: 0.467, Test accuracy: 81.18
Round  59, Train loss: 0.428, Test loss: 0.462, Test accuracy: 81.03
Round  60, Train loss: 0.430, Test loss: 0.459, Test accuracy: 81.35
Round  61, Train loss: 0.403, Test loss: 0.462, Test accuracy: 81.15
Round  62, Train loss: 0.447, Test loss: 0.456, Test accuracy: 81.72
Round  63, Train loss: 0.413, Test loss: 0.455, Test accuracy: 81.58
Round  64, Train loss: 0.431, Test loss: 0.454, Test accuracy: 82.07
Round  65, Train loss: 0.413, Test loss: 0.442, Test accuracy: 82.27
Round  66, Train loss: 0.399, Test loss: 0.459, Test accuracy: 82.05
Round  67, Train loss: 0.473, Test loss: 0.443, Test accuracy: 82.58
Round  68, Train loss: 0.467, Test loss: 0.448, Test accuracy: 82.70
Round  69, Train loss: 0.382, Test loss: 0.447, Test accuracy: 82.72
Round  70, Train loss: 0.436, Test loss: 0.445, Test accuracy: 82.37
Round  71, Train loss: 0.379, Test loss: 0.447, Test accuracy: 82.50
Round  72, Train loss: 0.503, Test loss: 0.445, Test accuracy: 82.45
Round  73, Train loss: 0.444, Test loss: 0.447, Test accuracy: 82.23
Round  74, Train loss: 0.404, Test loss: 0.441, Test accuracy: 83.08
Round  75, Train loss: 0.393, Test loss: 0.445, Test accuracy: 82.90
Round  76, Train loss: 0.400, Test loss: 0.438, Test accuracy: 82.87
Round  77, Train loss: 0.334, Test loss: 0.440, Test accuracy: 82.68
Round  78, Train loss: 0.405, Test loss: 0.437, Test accuracy: 82.47
Round  79, Train loss: 0.442, Test loss: 0.444, Test accuracy: 82.47
Round  80, Train loss: 0.347, Test loss: 0.440, Test accuracy: 82.73
Round  81, Train loss: 0.400, Test loss: 0.447, Test accuracy: 82.47
Round  82, Train loss: 0.391, Test loss: 0.440, Test accuracy: 82.92
Round  83, Train loss: 0.401, Test loss: 0.442, Test accuracy: 82.58
Round  84, Train loss: 0.412, Test loss: 0.442, Test accuracy: 82.77
Round  85, Train loss: 0.323, Test loss: 0.442, Test accuracy: 82.25
Round  86, Train loss: 0.385, Test loss: 0.441, Test accuracy: 82.53
Round  87, Train loss: 0.339, Test loss: 0.443, Test accuracy: 82.33
Round  88, Train loss: 0.303, Test loss: 0.433, Test accuracy: 82.95
Round  89, Train loss: 0.395, Test loss: 0.429, Test accuracy: 82.85
Round  90, Train loss: 0.285, Test loss: 0.435, Test accuracy: 82.98
Round  91, Train loss: 0.286, Test loss: 0.429, Test accuracy: 83.08
Round  92, Train loss: 0.223, Test loss: 0.433, Test accuracy: 83.27
Round  93, Train loss: 0.365, Test loss: 0.449, Test accuracy: 82.58
Round  94, Train loss: 0.466, Test loss: 0.439, Test accuracy: 83.10
Round  95, Train loss: 0.304, Test loss: 0.435, Test accuracy: 83.03
Round  96, Train loss: 0.344, Test loss: 0.438, Test accuracy: 82.83
Round  97, Train loss: 0.357, Test loss: 0.443, Test accuracy: 82.72
Round  98, Train loss: 0.392, Test loss: 0.440, Test accuracy: 82.83
Round  99, Train loss: 0.327, Test loss: 0.435, Test accuracy: 83.27
Final Round, Train loss: 0.299, Test loss: 0.436, Test accuracy: 83.18
Average accuracy final 10 rounds: 82.97
1311.911378622055
[1.2200932502746582, 2.1028711795806885, 2.953300952911377, 3.814337968826294, 4.762540102005005, 5.642820119857788, 6.5376670360565186, 7.462985515594482, 8.359552383422852, 9.222996234893799, 10.082467794418335, 10.937083721160889, 11.78278374671936, 12.651291608810425, 13.504021406173706, 14.339565515518188, 15.21002984046936, 16.13205575942993, 17.052225589752197, 17.940509796142578, 18.85250759124756, 21.185303688049316, 23.233977556228638, 25.199222564697266, 27.50624966621399, 29.66323184967041, 32.033841371536255, 34.074639320373535, 36.21654963493347, 38.359471559524536, 40.52763366699219, 42.7350800037384, 45.15485191345215, 47.18055963516235, 49.22669839859009, 51.248215675354004, 53.47337293624878, 55.662192583084106, 58.008169412612915, 60.047751903533936, 62.20079278945923, 64.3868567943573, 66.58538126945496, 68.76129531860352, 71.14255928993225, 73.13397336006165, 75.25532245635986, 77.44591546058655, 79.57606911659241, 81.92621922492981, 84.15644264221191, 86.21595072746277, 88.29667568206787, 90.47871351242065, 92.70870542526245, 95.11042523384094, 97.14480638504028, 99.28853607177734, 101.31998896598816, 103.5391685962677, 105.75597381591797, 108.17123103141785, 110.36069869995117, 112.38321995735168, 114.62524366378784, 116.82066178321838, 119.07033491134644, 121.3091607093811, 123.44782209396362, 125.46558165550232, 127.61175036430359, 129.8479826450348, 132.2605917453766, 134.3986279964447, 136.52896976470947, 138.51925468444824, 140.8031177520752, 143.00199437141418, 145.2577769756317, 147.39935445785522, 149.3554391860962, 151.48906302452087, 153.7036600112915, 155.83795881271362, 158.2526457309723, 160.2348072528839, 162.30311846733093, 164.67137837409973, 166.94793176651, 169.32520604133606, 171.67768597602844, 173.8168122768402, 175.9501667022705, 178.2139277458191, 180.53823518753052, 183.04347968101501, 185.13516473770142, 187.35191226005554, 189.48085474967957, 191.78992700576782, 193.24612832069397]
[17.783333333333335, 32.61666666666667, 44.5, 52.233333333333334, 56.166666666666664, 61.166666666666664, 64.35, 66.91666666666667, 67.11666666666666, 67.71666666666667, 69.45, 69.7, 70.75, 71.38333333333334, 71.93333333333334, 72.31666666666666, 72.78333333333333, 73.65, 74.15, 73.95, 73.73333333333333, 73.98333333333333, 75.08333333333333, 75.45, 76.05, 76.28333333333333, 76.56666666666666, 76.66666666666667, 77.45, 77.86666666666666, 78.56666666666666, 78.4, 78.38333333333334, 78.65, 78.66666666666667, 78.01666666666667, 78.43333333333334, 79.05, 78.9, 78.66666666666667, 78.93333333333334, 79.23333333333333, 79.36666666666666, 79.68333333333334, 79.85, 79.16666666666667, 79.53333333333333, 80.53333333333333, 80.43333333333334, 80.35, 80.3, 80.8, 80.41666666666667, 81.08333333333333, 80.75, 80.8, 81.38333333333334, 80.93333333333334, 81.18333333333334, 81.03333333333333, 81.35, 81.15, 81.71666666666667, 81.58333333333333, 82.06666666666666, 82.26666666666667, 82.05, 82.58333333333333, 82.7, 82.71666666666667, 82.36666666666666, 82.5, 82.45, 82.23333333333333, 83.08333333333333, 82.9, 82.86666666666666, 82.68333333333334, 82.46666666666667, 82.46666666666667, 82.73333333333333, 82.46666666666667, 82.91666666666667, 82.58333333333333, 82.76666666666667, 82.25, 82.53333333333333, 82.33333333333333, 82.95, 82.85, 82.98333333333333, 83.08333333333333, 83.26666666666667, 82.58333333333333, 83.1, 83.03333333333333, 82.83333333333333, 82.71666666666667, 82.83333333333333, 83.26666666666667, 83.18333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 12, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.321, Test loss: 2.091, Test accuracy: 17.02
Round   0, Global train loss: 1.321, Global test loss: 2.389, Global test accuracy: 11.67
Round   1, Train loss: 1.207, Test loss: 1.843, Test accuracy: 27.17
Round   1, Global train loss: 1.207, Global test loss: 2.430, Global test accuracy: 13.33
Round   2, Train loss: 1.162, Test loss: 1.534, Test accuracy: 34.15
Round   2, Global train loss: 1.162, Global test loss: 2.361, Global test accuracy: 13.68
Round   3, Train loss: 1.141, Test loss: 1.234, Test accuracy: 43.37
Round   3, Global train loss: 1.141, Global test loss: 2.246, Global test accuracy: 16.28
Round   4, Train loss: 1.119, Test loss: 1.212, Test accuracy: 45.57
Round   4, Global train loss: 1.119, Global test loss: 2.392, Global test accuracy: 17.95
Round   5, Train loss: 1.084, Test loss: 1.156, Test accuracy: 48.48
Round   5, Global train loss: 1.084, Global test loss: 2.225, Global test accuracy: 18.20
Round   6, Train loss: 1.132, Test loss: 1.069, Test accuracy: 50.55
Round   6, Global train loss: 1.132, Global test loss: 2.391, Global test accuracy: 18.25
Round   7, Train loss: 1.096, Test loss: 1.037, Test accuracy: 52.37
Round   7, Global train loss: 1.096, Global test loss: 2.294, Global test accuracy: 17.92
Round   8, Train loss: 1.045, Test loss: 1.041, Test accuracy: 54.10
Round   8, Global train loss: 1.045, Global test loss: 2.408, Global test accuracy: 23.17
Round   9, Train loss: 1.127, Test loss: 1.024, Test accuracy: 52.28
Round   9, Global train loss: 1.127, Global test loss: 2.260, Global test accuracy: 13.13
Round  10, Train loss: 1.066, Test loss: 0.999, Test accuracy: 55.37
Round  10, Global train loss: 1.066, Global test loss: 2.161, Global test accuracy: 22.28
Round  11, Train loss: 1.058, Test loss: 1.014, Test accuracy: 54.32
Round  11, Global train loss: 1.058, Global test loss: 2.285, Global test accuracy: 14.53
Round  12, Train loss: 0.966, Test loss: 0.961, Test accuracy: 57.32
Round  12, Global train loss: 0.966, Global test loss: 2.420, Global test accuracy: 17.92
Round  13, Train loss: 1.027, Test loss: 0.911, Test accuracy: 59.18
Round  13, Global train loss: 1.027, Global test loss: 2.281, Global test accuracy: 21.78
Round  14, Train loss: 0.934, Test loss: 0.907, Test accuracy: 59.85
Round  14, Global train loss: 0.934, Global test loss: 2.224, Global test accuracy: 20.98
Round  15, Train loss: 0.976, Test loss: 0.889, Test accuracy: 60.80
Round  15, Global train loss: 0.976, Global test loss: 2.223, Global test accuracy: 17.60
Round  16, Train loss: 0.961, Test loss: 0.904, Test accuracy: 59.53
Round  16, Global train loss: 0.961, Global test loss: 2.388, Global test accuracy: 10.00
Round  17, Train loss: 0.780, Test loss: 0.883, Test accuracy: 61.27
Round  17, Global train loss: 0.780, Global test loss: 2.110, Global test accuracy: 25.12
Round  18, Train loss: 0.820, Test loss: 0.879, Test accuracy: 61.28
Round  18, Global train loss: 0.820, Global test loss: 2.159, Global test accuracy: 23.00
Round  19, Train loss: 0.777, Test loss: 0.882, Test accuracy: 61.17
Round  19, Global train loss: 0.777, Global test loss: 2.202, Global test accuracy: 23.50
Round  20, Train loss: 0.820, Test loss: 0.875, Test accuracy: 62.12
Round  20, Global train loss: 0.820, Global test loss: 2.411, Global test accuracy: 21.43
Round  21, Train loss: 0.831, Test loss: 0.888, Test accuracy: 61.15
Round  21, Global train loss: 0.831, Global test loss: 2.203, Global test accuracy: 24.17
Round  22, Train loss: 0.989, Test loss: 0.882, Test accuracy: 61.78
Round  22, Global train loss: 0.989, Global test loss: 2.196, Global test accuracy: 25.12
Round  23, Train loss: 0.807, Test loss: 0.883, Test accuracy: 61.32
Round  23, Global train loss: 0.807, Global test loss: 2.208, Global test accuracy: 30.60
Round  24, Train loss: 0.859, Test loss: 0.872, Test accuracy: 62.68
Round  24, Global train loss: 0.859, Global test loss: 2.095, Global test accuracy: 29.08
Round  25, Train loss: 0.799, Test loss: 0.860, Test accuracy: 62.90
Round  25, Global train loss: 0.799, Global test loss: 2.142, Global test accuracy: 25.15
Round  26, Train loss: 0.855, Test loss: 0.855, Test accuracy: 63.52
Round  26, Global train loss: 0.855, Global test loss: 2.259, Global test accuracy: 24.88
Round  27, Train loss: 0.775, Test loss: 0.869, Test accuracy: 62.93
Round  27, Global train loss: 0.775, Global test loss: 2.157, Global test accuracy: 22.27
Round  28, Train loss: 0.812, Test loss: 0.870, Test accuracy: 63.40
Round  28, Global train loss: 0.812, Global test loss: 2.195, Global test accuracy: 18.12
Round  29, Train loss: 0.872, Test loss: 0.867, Test accuracy: 63.90
Round  29, Global train loss: 0.872, Global test loss: 2.259, Global test accuracy: 22.07
Round  30, Train loss: 0.824, Test loss: 0.855, Test accuracy: 64.48
Round  30, Global train loss: 0.824, Global test loss: 2.217, Global test accuracy: 14.80
Round  31, Train loss: 0.801, Test loss: 0.867, Test accuracy: 63.68
Round  31, Global train loss: 0.801, Global test loss: 2.191, Global test accuracy: 19.83
Round  32, Train loss: 0.763, Test loss: 0.853, Test accuracy: 64.42
Round  32, Global train loss: 0.763, Global test loss: 2.277, Global test accuracy: 15.17
Round  33, Train loss: 0.900, Test loss: 0.857, Test accuracy: 64.02
Round  33, Global train loss: 0.900, Global test loss: 2.187, Global test accuracy: 19.08
Round  34, Train loss: 0.682, Test loss: 0.866, Test accuracy: 63.20
Round  34, Global train loss: 0.682, Global test loss: 2.129, Global test accuracy: 28.18
Round  35, Train loss: 0.841, Test loss: 0.867, Test accuracy: 63.45
Round  35, Global train loss: 0.841, Global test loss: 2.147, Global test accuracy: 23.82
Round  36, Train loss: 0.812, Test loss: 0.871, Test accuracy: 63.75
Round  36, Global train loss: 0.812, Global test loss: 2.164, Global test accuracy: 21.10
Round  37, Train loss: 0.582, Test loss: 0.891, Test accuracy: 64.20
Round  37, Global train loss: 0.582, Global test loss: 2.095, Global test accuracy: 29.90
Round  38, Train loss: 0.686, Test loss: 0.906, Test accuracy: 63.53
Round  38, Global train loss: 0.686, Global test loss: 2.104, Global test accuracy: 29.50
Round  39, Train loss: 0.674, Test loss: 0.911, Test accuracy: 63.78
Round  39, Global train loss: 0.674, Global test loss: 2.172, Global test accuracy: 22.60
Round  40, Train loss: 0.636, Test loss: 0.901, Test accuracy: 63.53
Round  40, Global train loss: 0.636, Global test loss: 2.204, Global test accuracy: 25.37
Round  41, Train loss: 0.669, Test loss: 0.882, Test accuracy: 64.57
Round  41, Global train loss: 0.669, Global test loss: 2.199, Global test accuracy: 27.98
Round  42, Train loss: 0.661, Test loss: 0.892, Test accuracy: 63.90
Round  42, Global train loss: 0.661, Global test loss: 2.125, Global test accuracy: 23.38
Round  43, Train loss: 0.679, Test loss: 0.891, Test accuracy: 64.32
Round  43, Global train loss: 0.679, Global test loss: 2.147, Global test accuracy: 30.07
Round  44, Train loss: 0.705, Test loss: 0.907, Test accuracy: 64.30
Round  44, Global train loss: 0.705, Global test loss: 2.340, Global test accuracy: 14.42
Round  45, Train loss: 0.638, Test loss: 0.939, Test accuracy: 62.97
Round  45, Global train loss: 0.638, Global test loss: 2.165, Global test accuracy: 26.82
Round  46, Train loss: 0.619, Test loss: 0.940, Test accuracy: 63.17
Round  46, Global train loss: 0.619, Global test loss: 2.125, Global test accuracy: 26.58
Round  47, Train loss: 0.544, Test loss: 0.974, Test accuracy: 62.50
Round  47, Global train loss: 0.544, Global test loss: 2.139, Global test accuracy: 27.50
Round  48, Train loss: 0.654, Test loss: 1.001, Test accuracy: 62.15
Round  48, Global train loss: 0.654, Global test loss: 2.203, Global test accuracy: 23.85
Round  49, Train loss: 0.535, Test loss: 1.007, Test accuracy: 61.93
Round  49, Global train loss: 0.535, Global test loss: 2.135, Global test accuracy: 26.45
Round  50, Train loss: 0.633, Test loss: 1.019, Test accuracy: 62.47
Round  50, Global train loss: 0.633, Global test loss: 2.376, Global test accuracy: 16.95
Round  51, Train loss: 0.661, Test loss: 1.002, Test accuracy: 63.18
Round  51, Global train loss: 0.661, Global test loss: 2.181, Global test accuracy: 29.30
Round  52, Train loss: 0.529, Test loss: 1.025, Test accuracy: 62.37
Round  52, Global train loss: 0.529, Global test loss: 2.200, Global test accuracy: 25.92
Round  53, Train loss: 0.424, Test loss: 1.035, Test accuracy: 62.28
Round  53, Global train loss: 0.424, Global test loss: 2.185, Global test accuracy: 26.27
Round  54, Train loss: 0.396, Test loss: 1.027, Test accuracy: 62.65
Round  54, Global train loss: 0.396, Global test loss: 2.044, Global test accuracy: 27.53
Round  55, Train loss: 0.489, Test loss: 1.063, Test accuracy: 61.57
Round  55, Global train loss: 0.489, Global test loss: 2.194, Global test accuracy: 23.28
Round  56, Train loss: 0.646, Test loss: 1.060, Test accuracy: 62.23
Round  56, Global train loss: 0.646, Global test loss: 2.189, Global test accuracy: 24.17
Round  57, Train loss: 0.561, Test loss: 1.075, Test accuracy: 62.33
Round  57, Global train loss: 0.561, Global test loss: 2.196, Global test accuracy: 12.90
Round  58, Train loss: 0.438, Test loss: 1.127, Test accuracy: 61.53
Round  58, Global train loss: 0.438, Global test loss: 2.121, Global test accuracy: 25.25
Round  59, Train loss: 0.415, Test loss: 1.164, Test accuracy: 60.90
Round  59, Global train loss: 0.415, Global test loss: 2.094, Global test accuracy: 22.28
Round  60, Train loss: 0.526, Test loss: 1.163, Test accuracy: 60.82
Round  60, Global train loss: 0.526, Global test loss: 2.215, Global test accuracy: 24.62
Round  61, Train loss: 0.329, Test loss: 1.132, Test accuracy: 61.95
Round  61, Global train loss: 0.329, Global test loss: 2.021, Global test accuracy: 26.62
Round  62, Train loss: 0.360, Test loss: 1.127, Test accuracy: 62.08
Round  62, Global train loss: 0.360, Global test loss: 2.125, Global test accuracy: 25.67
Round  63, Train loss: 0.309, Test loss: 1.166, Test accuracy: 61.35
Round  63, Global train loss: 0.309, Global test loss: 2.074, Global test accuracy: 29.53
Round  64, Train loss: 0.350, Test loss: 1.211, Test accuracy: 61.17
Round  64, Global train loss: 0.350, Global test loss: 2.106, Global test accuracy: 29.88
Round  65, Train loss: 0.366, Test loss: 1.236, Test accuracy: 60.50
Round  65, Global train loss: 0.366, Global test loss: 2.069, Global test accuracy: 30.40
Round  66, Train loss: 0.521, Test loss: 1.260, Test accuracy: 60.77
Round  66, Global train loss: 0.521, Global test loss: 2.235, Global test accuracy: 20.80
Round  67, Train loss: 0.316, Test loss: 1.220, Test accuracy: 62.27
Round  67, Global train loss: 0.316, Global test loss: 2.099, Global test accuracy: 26.33
Round  68, Train loss: 0.448, Test loss: 1.253, Test accuracy: 61.17
Round  68, Global train loss: 0.448, Global test loss: 2.205, Global test accuracy: 22.68
Round  69, Train loss: 0.446, Test loss: 1.207, Test accuracy: 62.05
Round  69, Global train loss: 0.446, Global test loss: 2.303, Global test accuracy: 12.55
Round  70, Train loss: 0.360, Test loss: 1.262, Test accuracy: 61.13
Round  70, Global train loss: 0.360, Global test loss: 2.090, Global test accuracy: 27.17
Round  71, Train loss: 0.447, Test loss: 1.290, Test accuracy: 60.83
Round  71, Global train loss: 0.447, Global test loss: 2.223, Global test accuracy: 19.83
Round  72, Train loss: 0.434, Test loss: 1.269, Test accuracy: 61.23
Round  72, Global train loss: 0.434, Global test loss: 2.140, Global test accuracy: 26.22
Round  73, Train loss: 0.265, Test loss: 1.261, Test accuracy: 61.90
Round  73, Global train loss: 0.265, Global test loss: 2.261, Global test accuracy: 20.20
Round  74, Train loss: 0.398, Test loss: 1.283, Test accuracy: 61.92
Round  74, Global train loss: 0.398, Global test loss: 2.073, Global test accuracy: 25.17
Round  75, Train loss: 0.412, Test loss: 1.306, Test accuracy: 61.38
Round  75, Global train loss: 0.412, Global test loss: 2.148, Global test accuracy: 25.58
Round  76, Train loss: 0.397, Test loss: 1.319, Test accuracy: 61.42
Round  76, Global train loss: 0.397, Global test loss: 2.141, Global test accuracy: 26.80
Round  77, Train loss: 0.329, Test loss: 1.304, Test accuracy: 61.63
Round  77, Global train loss: 0.329, Global test loss: 2.188, Global test accuracy: 14.73
Round  78, Train loss: 0.303, Test loss: 1.331, Test accuracy: 60.62
Round  78, Global train loss: 0.303, Global test loss: 2.147, Global test accuracy: 23.37
Round  79, Train loss: 0.337, Test loss: 1.358, Test accuracy: 60.88
Round  79, Global train loss: 0.337, Global test loss: 2.186, Global test accuracy: 20.13
Round  80, Train loss: 0.218, Test loss: 1.370, Test accuracy: 60.98
Round  80, Global train loss: 0.218, Global test loss: 2.199, Global test accuracy: 17.75
Round  81, Train loss: 0.274, Test loss: 1.411, Test accuracy: 60.27
Round  81, Global train loss: 0.274, Global test loss: 2.081, Global test accuracy: 27.82
Round  82, Train loss: 0.279, Test loss: 1.366, Test accuracy: 61.62
Round  82, Global train loss: 0.279, Global test loss: 2.296, Global test accuracy: 11.23
Round  83, Train loss: 0.180, Test loss: 1.405, Test accuracy: 61.35
Round  83, Global train loss: 0.180, Global test loss: 2.134, Global test accuracy: 19.70
Round  84, Train loss: 0.314, Test loss: 1.454, Test accuracy: 61.23
Round  84, Global train loss: 0.314, Global test loss: 2.116, Global test accuracy: 28.82
Round  85, Train loss: 0.252, Test loss: 1.486, Test accuracy: 60.45
Round  85, Global train loss: 0.252, Global test loss: 2.050, Global test accuracy: 27.85
Round  86, Train loss: 0.314, Test loss: 1.523, Test accuracy: 59.90
Round  86, Global train loss: 0.314, Global test loss: 2.262, Global test accuracy: 18.35
Round  87, Train loss: 0.192, Test loss: 1.520, Test accuracy: 60.37
Round  87, Global train loss: 0.192, Global test loss: 2.159, Global test accuracy: 22.48
Round  88, Train loss: 0.165, Test loss: 1.556, Test accuracy: 60.50
Round  88, Global train loss: 0.165, Global test loss: 2.110, Global test accuracy: 29.72
Round  89, Train loss: 0.214, Test loss: 1.568, Test accuracy: 60.17
Round  89, Global train loss: 0.214, Global test loss: 2.208, Global test accuracy: 11.28
Round  90, Train loss: 0.263, Test loss: 1.604, Test accuracy: 60.08
Round  90, Global train loss: 0.263, Global test loss: 2.194, Global test accuracy: 13.72
Round  91, Train loss: 0.171, Test loss: 1.602, Test accuracy: 60.53
Round  91, Global train loss: 0.171, Global test loss: 2.077, Global test accuracy: 25.80
Round  92, Train loss: 0.232, Test loss: 1.603, Test accuracy: 60.62
Round  92, Global train loss: 0.232, Global test loss: 2.240, Global test accuracy: 15.72
Round  93, Train loss: 0.255, Test loss: 1.620, Test accuracy: 60.18
Round  93, Global train loss: 0.255, Global test loss: 2.239, Global test accuracy: 21.33
Round  94, Train loss: 0.167, Test loss: 1.656, Test accuracy: 59.80
Round  94, Global train loss: 0.167, Global test loss: 2.168, Global test accuracy: 24.30
Round  95, Train loss: 0.155, Test loss: 1.661, Test accuracy: 59.88
Round  95, Global train loss: 0.155, Global test loss: 2.061, Global test accuracy: 27.68
Round  96, Train loss: 0.182, Test loss: 1.719, Test accuracy: 59.28
Round  96, Global train loss: 0.182, Global test loss: 2.236, Global test accuracy: 20.07
Round  97, Train loss: 0.206, Test loss: 1.702, Test accuracy: 60.58
Round  97, Global train loss: 0.206, Global test loss: 2.225, Global test accuracy: 23.18
Round  98, Train loss: 0.213, Test loss: 1.683, Test accuracy: 60.88
Round  98, Global train loss: 0.213, Global test loss: 2.151, Global test accuracy: 26.82
Round  99, Train loss: 0.143, Test loss: 1.670, Test accuracy: 61.60
Round  99, Global train loss: 0.143, Global test loss: 2.164, Global test accuracy: 20.63
Final Round, Train loss: 0.191, Test loss: 1.762, Test accuracy: 60.52
Final Round, Global train loss: 0.191, Global test loss: 2.164, Global test accuracy: 20.63
Average accuracy final 10 rounds: 60.345 

Average global accuracy final 10 rounds: 21.924999999999997 

1031.9262869358063
[0.991633415222168, 1.983266830444336, 2.688469648361206, 3.393672466278076, 4.119741201400757, 4.8458099365234375, 5.578503847122192, 6.311197757720947, 7.063994884490967, 7.816792011260986, 8.565481662750244, 9.314171314239502, 10.060875654220581, 10.80757999420166, 11.540328979492188, 12.273077964782715, 12.970558166503906, 13.668038368225098, 14.384426593780518, 15.100814819335938, 15.812931537628174, 16.52504825592041, 17.22547483444214, 17.925901412963867, 18.668017625808716, 19.410133838653564, 20.132346391677856, 20.85455894470215, 21.604430437088013, 22.354301929473877, 23.071574449539185, 23.788846969604492, 24.491520404815674, 25.194193840026855, 25.89868927001953, 26.603184700012207, 27.319873571395874, 28.03656244277954, 28.744086742401123, 29.451611042022705, 30.208927154541016, 30.966243267059326, 31.71107268333435, 32.455902099609375, 33.2106568813324, 33.96541166305542, 34.69457411766052, 35.423736572265625, 36.155218839645386, 36.88670110702515, 37.59417176246643, 38.301642417907715, 39.00555920600891, 39.70947599411011, 40.438337087631226, 41.167198181152344, 41.91725277900696, 42.66730737686157, 43.42177486419678, 44.17624235153198, 44.90369176864624, 45.6311411857605, 46.378960847854614, 47.12678050994873, 47.83819031715393, 48.54960012435913, 49.24967980384827, 49.9497594833374, 50.64777374267578, 51.34578800201416, 52.04324674606323, 52.740705490112305, 53.443137407302856, 54.14556932449341, 54.86988854408264, 55.594207763671875, 56.32047367095947, 57.04673957824707, 57.760592222213745, 58.47444486618042, 59.19097948074341, 59.9075140953064, 60.60850214958191, 61.30949020385742, 62.00322461128235, 62.696959018707275, 63.402177572250366, 64.10739612579346, 64.80099058151245, 65.49458503723145, 66.22129583358765, 66.94800662994385, 67.68031239509583, 68.4126181602478, 69.1506245136261, 69.8886308670044, 70.62637400627136, 71.36411714553833, 72.06128430366516, 72.75845146179199, 73.44864463806152, 74.13883781433105, 74.83652305603027, 75.53420829772949, 76.24466347694397, 76.95511865615845, 77.64737939834595, 78.33964014053345, 79.08818125724792, 79.8367223739624, 80.58053660392761, 81.32435083389282, 82.0188353061676, 82.71331977844238, 83.43656587600708, 84.15981197357178, 84.85377717018127, 85.54774236679077, 86.24734091758728, 86.94693946838379, 87.65216183662415, 88.3573842048645, 89.05170845985413, 89.74603271484375, 90.48020792007446, 91.21438312530518, 91.9477047920227, 92.68102645874023, 93.4108510017395, 94.14067554473877, 94.88896012306213, 95.6372447013855, 96.34224510192871, 97.04724550247192, 97.74802899360657, 98.44881248474121, 99.1454336643219, 99.84205484390259, 100.54727411270142, 101.25249338150024, 101.99135661125183, 102.73021984100342, 103.4521815776825, 104.17414331436157, 104.9112696647644, 105.64839601516724, 106.38189673423767, 107.1153974533081, 107.83368945121765, 108.5519814491272, 109.24311208724976, 109.93424272537231, 110.63430094718933, 111.33435916900635, 112.05467009544373, 112.7749810218811, 113.48627018928528, 114.19755935668945, 114.93010306358337, 115.6626467704773, 116.38564729690552, 117.10864782333374, 117.84026312828064, 118.57187843322754, 119.27545142173767, 119.9790244102478, 120.67034196853638, 121.36165952682495, 122.06013011932373, 122.75860071182251, 123.4530463218689, 124.14749193191528, 124.85095119476318, 125.55441045761108, 126.2968020439148, 127.0391936302185, 127.7602641582489, 128.4813346862793, 129.214439868927, 129.9475450515747, 130.67386150360107, 131.40017795562744, 132.10024428367615, 132.80031061172485, 133.486230134964, 134.17214965820312, 134.85648036003113, 135.54081106185913, 136.2436990737915, 136.94658708572388, 137.6416413784027, 138.33669567108154, 139.09447145462036, 139.85224723815918, 140.5751850605011, 141.29812288284302, 142.03604412078857, 142.77396535873413, 143.48482275009155, 144.19568014144897, 145.57978868484497, 146.96389722824097]
[17.016666666666666, 17.016666666666666, 27.166666666666668, 27.166666666666668, 34.15, 34.15, 43.36666666666667, 43.36666666666667, 45.56666666666667, 45.56666666666667, 48.483333333333334, 48.483333333333334, 50.55, 50.55, 52.36666666666667, 52.36666666666667, 54.1, 54.1, 52.28333333333333, 52.28333333333333, 55.36666666666667, 55.36666666666667, 54.31666666666667, 54.31666666666667, 57.31666666666667, 57.31666666666667, 59.18333333333333, 59.18333333333333, 59.85, 59.85, 60.8, 60.8, 59.53333333333333, 59.53333333333333, 61.266666666666666, 61.266666666666666, 61.28333333333333, 61.28333333333333, 61.166666666666664, 61.166666666666664, 62.11666666666667, 62.11666666666667, 61.15, 61.15, 61.78333333333333, 61.78333333333333, 61.31666666666667, 61.31666666666667, 62.68333333333333, 62.68333333333333, 62.9, 62.9, 63.516666666666666, 63.516666666666666, 62.93333333333333, 62.93333333333333, 63.4, 63.4, 63.9, 63.9, 64.48333333333333, 64.48333333333333, 63.68333333333333, 63.68333333333333, 64.41666666666667, 64.41666666666667, 64.01666666666667, 64.01666666666667, 63.2, 63.2, 63.45, 63.45, 63.75, 63.75, 64.2, 64.2, 63.53333333333333, 63.53333333333333, 63.78333333333333, 63.78333333333333, 63.53333333333333, 63.53333333333333, 64.56666666666666, 64.56666666666666, 63.9, 63.9, 64.31666666666666, 64.31666666666666, 64.3, 64.3, 62.96666666666667, 62.96666666666667, 63.166666666666664, 63.166666666666664, 62.5, 62.5, 62.15, 62.15, 61.93333333333333, 61.93333333333333, 62.46666666666667, 62.46666666666667, 63.18333333333333, 63.18333333333333, 62.36666666666667, 62.36666666666667, 62.28333333333333, 62.28333333333333, 62.65, 62.65, 61.56666666666667, 61.56666666666667, 62.233333333333334, 62.233333333333334, 62.333333333333336, 62.333333333333336, 61.53333333333333, 61.53333333333333, 60.9, 60.9, 60.81666666666667, 60.81666666666667, 61.95, 61.95, 62.083333333333336, 62.083333333333336, 61.35, 61.35, 61.166666666666664, 61.166666666666664, 60.5, 60.5, 60.766666666666666, 60.766666666666666, 62.266666666666666, 62.266666666666666, 61.166666666666664, 61.166666666666664, 62.05, 62.05, 61.13333333333333, 61.13333333333333, 60.833333333333336, 60.833333333333336, 61.233333333333334, 61.233333333333334, 61.9, 61.9, 61.916666666666664, 61.916666666666664, 61.38333333333333, 61.38333333333333, 61.416666666666664, 61.416666666666664, 61.63333333333333, 61.63333333333333, 60.61666666666667, 60.61666666666667, 60.88333333333333, 60.88333333333333, 60.983333333333334, 60.983333333333334, 60.266666666666666, 60.266666666666666, 61.61666666666667, 61.61666666666667, 61.35, 61.35, 61.233333333333334, 61.233333333333334, 60.45, 60.45, 59.9, 59.9, 60.36666666666667, 60.36666666666667, 60.5, 60.5, 60.166666666666664, 60.166666666666664, 60.083333333333336, 60.083333333333336, 60.53333333333333, 60.53333333333333, 60.61666666666667, 60.61666666666667, 60.18333333333333, 60.18333333333333, 59.8, 59.8, 59.88333333333333, 59.88333333333333, 59.28333333333333, 59.28333333333333, 60.583333333333336, 60.583333333333336, 60.88333333333333, 60.88333333333333, 61.6, 61.6, 60.516666666666666, 60.516666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.278, Test loss: 2.058, Test accuracy: 20.20
Round   0, Global train loss: 1.278, Global test loss: 2.380, Global test accuracy: 11.85
Round   1, Train loss: 1.043, Test loss: 1.793, Test accuracy: 32.53
Round   1, Global train loss: 1.043, Global test loss: 2.422, Global test accuracy: 13.85
Round   2, Train loss: 0.995, Test loss: 1.363, Test accuracy: 46.50
Round   2, Global train loss: 0.995, Global test loss: 2.144, Global test accuracy: 25.95
Round   3, Train loss: 0.902, Test loss: 1.023, Test accuracy: 54.98
Round   3, Global train loss: 0.902, Global test loss: 1.976, Global test accuracy: 28.23
Round   4, Train loss: 0.930, Test loss: 1.020, Test accuracy: 57.68
Round   4, Global train loss: 0.930, Global test loss: 2.188, Global test accuracy: 24.93
Round   5, Train loss: 0.928, Test loss: 0.928, Test accuracy: 60.75
Round   5, Global train loss: 0.928, Global test loss: 1.832, Global test accuracy: 33.68
Round   6, Train loss: 0.834, Test loss: 0.856, Test accuracy: 63.50
Round   6, Global train loss: 0.834, Global test loss: 2.033, Global test accuracy: 27.70
Round   7, Train loss: 0.845, Test loss: 0.760, Test accuracy: 67.00
Round   7, Global train loss: 0.845, Global test loss: 2.132, Global test accuracy: 29.60
Round   8, Train loss: 0.744, Test loss: 0.781, Test accuracy: 67.67
Round   8, Global train loss: 0.744, Global test loss: 2.094, Global test accuracy: 28.28
Round   9, Train loss: 0.716, Test loss: 0.775, Test accuracy: 67.30
Round   9, Global train loss: 0.716, Global test loss: 1.735, Global test accuracy: 35.73
Round  10, Train loss: 0.636, Test loss: 0.726, Test accuracy: 69.63
Round  10, Global train loss: 0.636, Global test loss: 1.657, Global test accuracy: 42.12
Round  11, Train loss: 0.768, Test loss: 0.765, Test accuracy: 68.07
Round  11, Global train loss: 0.768, Global test loss: 1.733, Global test accuracy: 36.83
Round  12, Train loss: 0.723, Test loss: 0.731, Test accuracy: 70.02
Round  12, Global train loss: 0.723, Global test loss: 2.140, Global test accuracy: 36.80
Round  13, Train loss: 0.738, Test loss: 0.687, Test accuracy: 71.48
Round  13, Global train loss: 0.738, Global test loss: 1.823, Global test accuracy: 43.35
Round  14, Train loss: 0.700, Test loss: 0.682, Test accuracy: 72.05
Round  14, Global train loss: 0.700, Global test loss: 1.853, Global test accuracy: 37.93
Round  15, Train loss: 0.636, Test loss: 0.672, Test accuracy: 72.78
Round  15, Global train loss: 0.636, Global test loss: 1.736, Global test accuracy: 39.23
Round  16, Train loss: 0.858, Test loss: 0.667, Test accuracy: 73.27
Round  16, Global train loss: 0.858, Global test loss: 1.794, Global test accuracy: 38.53
Round  17, Train loss: 0.701, Test loss: 0.673, Test accuracy: 73.03
Round  17, Global train loss: 0.701, Global test loss: 1.684, Global test accuracy: 41.53
Round  18, Train loss: 0.593, Test loss: 0.672, Test accuracy: 73.12
Round  18, Global train loss: 0.593, Global test loss: 1.713, Global test accuracy: 41.62
Round  19, Train loss: 0.606, Test loss: 0.674, Test accuracy: 73.47
Round  19, Global train loss: 0.606, Global test loss: 1.732, Global test accuracy: 42.72
Round  20, Train loss: 0.636, Test loss: 0.662, Test accuracy: 73.47
Round  20, Global train loss: 0.636, Global test loss: 1.856, Global test accuracy: 37.55
Round  21, Train loss: 0.733, Test loss: 0.672, Test accuracy: 72.93
Round  21, Global train loss: 0.733, Global test loss: 1.556, Global test accuracy: 45.55
Round  22, Train loss: 0.760, Test loss: 0.641, Test accuracy: 74.33
Round  22, Global train loss: 0.760, Global test loss: 1.447, Global test accuracy: 48.65
Round  23, Train loss: 0.669, Test loss: 0.634, Test accuracy: 74.72
Round  23, Global train loss: 0.669, Global test loss: 1.718, Global test accuracy: 43.90
Round  24, Train loss: 0.589, Test loss: 0.622, Test accuracy: 75.22
Round  24, Global train loss: 0.589, Global test loss: 1.531, Global test accuracy: 45.35
Round  25, Train loss: 0.552, Test loss: 0.639, Test accuracy: 74.35
Round  25, Global train loss: 0.552, Global test loss: 1.560, Global test accuracy: 45.05
Round  26, Train loss: 0.611, Test loss: 0.638, Test accuracy: 74.60
Round  26, Global train loss: 0.611, Global test loss: 1.661, Global test accuracy: 43.17
Round  27, Train loss: 0.511, Test loss: 0.643, Test accuracy: 74.33
Round  27, Global train loss: 0.511, Global test loss: 1.674, Global test accuracy: 45.47
Round  28, Train loss: 0.564, Test loss: 0.639, Test accuracy: 74.72
Round  28, Global train loss: 0.564, Global test loss: 1.729, Global test accuracy: 41.95
Round  29, Train loss: 0.676, Test loss: 0.639, Test accuracy: 74.60
Round  29, Global train loss: 0.676, Global test loss: 1.670, Global test accuracy: 43.93
Round  30, Train loss: 0.552, Test loss: 0.647, Test accuracy: 74.42
Round  30, Global train loss: 0.552, Global test loss: 1.502, Global test accuracy: 47.35
Round  31, Train loss: 0.478, Test loss: 0.626, Test accuracy: 75.22
Round  31, Global train loss: 0.478, Global test loss: 1.476, Global test accuracy: 49.15
Round  32, Train loss: 0.579, Test loss: 0.627, Test accuracy: 75.37
Round  32, Global train loss: 0.579, Global test loss: 1.696, Global test accuracy: 41.97
Round  33, Train loss: 0.591, Test loss: 0.629, Test accuracy: 75.13
Round  33, Global train loss: 0.591, Global test loss: 1.512, Global test accuracy: 49.58
Round  34, Train loss: 0.590, Test loss: 0.592, Test accuracy: 76.88
Round  34, Global train loss: 0.590, Global test loss: 1.527, Global test accuracy: 48.72
Round  35, Train loss: 0.502, Test loss: 0.612, Test accuracy: 75.73
Round  35, Global train loss: 0.502, Global test loss: 1.402, Global test accuracy: 51.28
Round  36, Train loss: 0.461, Test loss: 0.623, Test accuracy: 75.72
Round  36, Global train loss: 0.461, Global test loss: 1.717, Global test accuracy: 48.68
Round  37, Train loss: 0.555, Test loss: 0.626, Test accuracy: 76.05
Round  37, Global train loss: 0.555, Global test loss: 1.650, Global test accuracy: 46.95
Round  38, Train loss: 0.588, Test loss: 0.611, Test accuracy: 76.85
Round  38, Global train loss: 0.588, Global test loss: 1.535, Global test accuracy: 49.68
Round  39, Train loss: 0.530, Test loss: 0.610, Test accuracy: 77.10
Round  39, Global train loss: 0.530, Global test loss: 1.500, Global test accuracy: 49.80
Round  40, Train loss: 0.481, Test loss: 0.623, Test accuracy: 76.77
Round  40, Global train loss: 0.481, Global test loss: 1.672, Global test accuracy: 46.03
Round  41, Train loss: 0.573, Test loss: 0.615, Test accuracy: 77.12
Round  41, Global train loss: 0.573, Global test loss: 1.624, Global test accuracy: 46.23
Round  42, Train loss: 0.520, Test loss: 0.602, Test accuracy: 77.42
Round  42, Global train loss: 0.520, Global test loss: 1.442, Global test accuracy: 51.53
Round  43, Train loss: 0.498, Test loss: 0.600, Test accuracy: 77.80
Round  43, Global train loss: 0.498, Global test loss: 1.448, Global test accuracy: 50.83
Round  44, Train loss: 0.464, Test loss: 0.620, Test accuracy: 77.22
Round  44, Global train loss: 0.464, Global test loss: 1.635, Global test accuracy: 44.18
Round  45, Train loss: 0.472, Test loss: 0.609, Test accuracy: 77.77
Round  45, Global train loss: 0.472, Global test loss: 1.438, Global test accuracy: 52.20
Round  46, Train loss: 0.488, Test loss: 0.612, Test accuracy: 77.67
Round  46, Global train loss: 0.488, Global test loss: 1.425, Global test accuracy: 52.87
Round  47, Train loss: 0.513, Test loss: 0.608, Test accuracy: 77.65
Round  47, Global train loss: 0.513, Global test loss: 1.730, Global test accuracy: 49.52
Round  48, Train loss: 0.525, Test loss: 0.618, Test accuracy: 77.15
Round  48, Global train loss: 0.525, Global test loss: 1.517, Global test accuracy: 47.87
Round  49, Train loss: 0.434, Test loss: 0.595, Test accuracy: 77.82
Round  49, Global train loss: 0.434, Global test loss: 1.469, Global test accuracy: 50.63
Round  50, Train loss: 0.455, Test loss: 0.604, Test accuracy: 77.70
Round  50, Global train loss: 0.455, Global test loss: 1.667, Global test accuracy: 48.37
Round  51, Train loss: 0.402, Test loss: 0.640, Test accuracy: 76.07
Round  51, Global train loss: 0.402, Global test loss: 1.508, Global test accuracy: 51.62
Round  52, Train loss: 0.506, Test loss: 0.631, Test accuracy: 76.87
Round  52, Global train loss: 0.506, Global test loss: 1.562, Global test accuracy: 48.50
Round  53, Train loss: 0.513, Test loss: 0.612, Test accuracy: 77.53
Round  53, Global train loss: 0.513, Global test loss: 1.621, Global test accuracy: 46.42
Round  54, Train loss: 0.442, Test loss: 0.599, Test accuracy: 78.30
Round  54, Global train loss: 0.442, Global test loss: 1.500, Global test accuracy: 50.77
Round  55, Train loss: 0.482, Test loss: 0.621, Test accuracy: 77.58
Round  55, Global train loss: 0.482, Global test loss: 1.739, Global test accuracy: 46.43
Round  56, Train loss: 0.456, Test loss: 0.628, Test accuracy: 77.00
Round  56, Global train loss: 0.456, Global test loss: 1.405, Global test accuracy: 52.53
Round  57, Train loss: 0.444, Test loss: 0.610, Test accuracy: 78.12
Round  57, Global train loss: 0.444, Global test loss: 1.351, Global test accuracy: 54.15
Round  58, Train loss: 0.443, Test loss: 0.604, Test accuracy: 78.40
Round  58, Global train loss: 0.443, Global test loss: 1.319, Global test accuracy: 55.47
Round  59, Train loss: 0.494, Test loss: 0.616, Test accuracy: 78.57
Round  59, Global train loss: 0.494, Global test loss: 1.515, Global test accuracy: 50.53
Round  60, Train loss: 0.400, Test loss: 0.634, Test accuracy: 77.23
Round  60, Global train loss: 0.400, Global test loss: 1.538, Global test accuracy: 50.78
Round  61, Train loss: 0.428, Test loss: 0.643, Test accuracy: 76.70
Round  61, Global train loss: 0.428, Global test loss: 1.401, Global test accuracy: 55.35
Round  62, Train loss: 0.389, Test loss: 0.666, Test accuracy: 76.48
Round  62, Global train loss: 0.389, Global test loss: 1.430, Global test accuracy: 52.13
Round  63, Train loss: 0.428, Test loss: 0.643, Test accuracy: 77.32
Round  63, Global train loss: 0.428, Global test loss: 1.441, Global test accuracy: 52.92
Round  64, Train loss: 0.351, Test loss: 0.648, Test accuracy: 77.52
Round  64, Global train loss: 0.351, Global test loss: 1.580, Global test accuracy: 52.52
Round  65, Train loss: 0.344, Test loss: 0.651, Test accuracy: 77.60
Round  65, Global train loss: 0.344, Global test loss: 1.568, Global test accuracy: 50.85
Round  66, Train loss: 0.345, Test loss: 0.640, Test accuracy: 77.80
Round  66, Global train loss: 0.345, Global test loss: 1.496, Global test accuracy: 52.40
Round  67, Train loss: 0.348, Test loss: 0.639, Test accuracy: 77.72
Round  67, Global train loss: 0.348, Global test loss: 1.573, Global test accuracy: 53.67
Round  68, Train loss: 0.273, Test loss: 0.629, Test accuracy: 78.22
Round  68, Global train loss: 0.273, Global test loss: 1.636, Global test accuracy: 52.67
Round  69, Train loss: 0.407, Test loss: 0.632, Test accuracy: 78.52
Round  69, Global train loss: 0.407, Global test loss: 1.777, Global test accuracy: 46.30
Round  70, Train loss: 0.239, Test loss: 0.626, Test accuracy: 78.50
Round  70, Global train loss: 0.239, Global test loss: 1.663, Global test accuracy: 52.85
Round  71, Train loss: 0.338, Test loss: 0.626, Test accuracy: 78.35
Round  71, Global train loss: 0.338, Global test loss: 1.328, Global test accuracy: 56.20
Round  72, Train loss: 0.375, Test loss: 0.639, Test accuracy: 78.00
Round  72, Global train loss: 0.375, Global test loss: 1.322, Global test accuracy: 57.57
Round  73, Train loss: 0.284, Test loss: 0.647, Test accuracy: 77.98
Round  73, Global train loss: 0.284, Global test loss: 1.714, Global test accuracy: 50.82
Round  74, Train loss: 0.377, Test loss: 0.617, Test accuracy: 78.95
Round  74, Global train loss: 0.377, Global test loss: 1.617, Global test accuracy: 52.65
Round  75, Train loss: 0.496, Test loss: 0.619, Test accuracy: 78.43
Round  75, Global train loss: 0.496, Global test loss: 1.433, Global test accuracy: 53.82
Round  76, Train loss: 0.277, Test loss: 0.624, Test accuracy: 78.28
Round  76, Global train loss: 0.277, Global test loss: 1.406, Global test accuracy: 55.85
Round  77, Train loss: 0.310, Test loss: 0.612, Test accuracy: 78.68
Round  77, Global train loss: 0.310, Global test loss: 1.383, Global test accuracy: 57.08
Round  78, Train loss: 0.361, Test loss: 0.629, Test accuracy: 78.70
Round  78, Global train loss: 0.361, Global test loss: 1.450, Global test accuracy: 54.78
Round  79, Train loss: 0.299, Test loss: 0.646, Test accuracy: 78.45
Round  79, Global train loss: 0.299, Global test loss: 1.408, Global test accuracy: 54.05
Round  80, Train loss: 0.372, Test loss: 0.645, Test accuracy: 78.13
Round  80, Global train loss: 0.372, Global test loss: 1.472, Global test accuracy: 52.63
Round  81, Train loss: 0.376, Test loss: 0.645, Test accuracy: 78.08
Round  81, Global train loss: 0.376, Global test loss: 1.650, Global test accuracy: 54.08
Round  82, Train loss: 0.332, Test loss: 0.665, Test accuracy: 77.97
Round  82, Global train loss: 0.332, Global test loss: 1.760, Global test accuracy: 47.52
Round  83, Train loss: 0.275, Test loss: 0.644, Test accuracy: 78.23
Round  83, Global train loss: 0.275, Global test loss: 1.494, Global test accuracy: 54.45
Round  84, Train loss: 0.245, Test loss: 0.638, Test accuracy: 78.62
Round  84, Global train loss: 0.245, Global test loss: 1.733, Global test accuracy: 53.53
Round  85, Train loss: 0.220, Test loss: 0.642, Test accuracy: 78.60
Round  85, Global train loss: 0.220, Global test loss: 1.517, Global test accuracy: 57.43
Round  86, Train loss: 0.383, Test loss: 0.678, Test accuracy: 77.62
Round  86, Global train loss: 0.383, Global test loss: 1.572, Global test accuracy: 52.98
Round  87, Train loss: 0.307, Test loss: 0.707, Test accuracy: 77.22
Round  87, Global train loss: 0.307, Global test loss: 1.691, Global test accuracy: 52.98
Round  88, Train loss: 0.321, Test loss: 0.699, Test accuracy: 77.62
Round  88, Global train loss: 0.321, Global test loss: 1.909, Global test accuracy: 49.73
Round  89, Train loss: 0.332, Test loss: 0.689, Test accuracy: 78.07
Round  89, Global train loss: 0.332, Global test loss: 1.588, Global test accuracy: 52.37
Round  90, Train loss: 0.342, Test loss: 0.667, Test accuracy: 78.52
Round  90, Global train loss: 0.342, Global test loss: 1.377, Global test accuracy: 56.25
Round  91, Train loss: 0.247, Test loss: 0.686, Test accuracy: 78.48
Round  91, Global train loss: 0.247, Global test loss: 1.736, Global test accuracy: 54.32
Round  92, Train loss: 0.343, Test loss: 0.664, Test accuracy: 79.08
Round  92, Global train loss: 0.343, Global test loss: 1.481, Global test accuracy: 54.15
Round  93, Train loss: 0.346, Test loss: 0.669, Test accuracy: 78.97
Round  93, Global train loss: 0.346, Global test loss: 1.671, Global test accuracy: 49.75
Round  94, Train loss: 0.266, Test loss: 0.667, Test accuracy: 79.33
Round  94, Global train loss: 0.266, Global test loss: 2.060, Global test accuracy: 49.47
Round  95, Train loss: 0.319, Test loss: 0.673, Test accuracy: 78.93
Round  95, Global train loss: 0.319, Global test loss: 1.522, Global test accuracy: 54.53
Round  96, Train loss: 0.300, Test loss: 0.664, Test accuracy: 79.17
Round  96, Global train loss: 0.300, Global test loss: 1.545, Global test accuracy: 53.40
Round  97, Train loss: 0.308, Test loss: 0.669, Test accuracy: 79.37
Round  97, Global train loss: 0.308, Global test loss: 1.626, Global test accuracy: 51.23
Round  98, Train loss: 0.304, Test loss: 0.682, Test accuracy: 79.12
Round  98, Global train loss: 0.304, Global test loss: 1.433, Global test accuracy: 56.95
Round  99, Train loss: 0.251, Test loss: 0.677, Test accuracy: 79.23
Round  99, Global train loss: 0.251, Global test loss: 1.490, Global test accuracy: 56.65
Final Round, Train loss: 0.224, Test loss: 0.739, Test accuracy: 78.77
Final Round, Global train loss: 0.224, Global test loss: 1.490, Global test accuracy: 56.65
Average accuracy final 10 rounds: 79.02 

Average global accuracy final 10 rounds: 53.67 

1018.9220762252808
[1.047987937927246, 2.095975875854492, 2.8525919914245605, 3.609208106994629, 4.375169515609741, 5.1411309242248535, 5.89182448387146, 6.642518043518066, 7.3467419147491455, 8.050965785980225, 8.750866174697876, 9.450766563415527, 10.163538932800293, 10.876311302185059, 11.580158472061157, 12.284005641937256, 13.018916606903076, 13.753827571868896, 14.489007949829102, 15.224188327789307, 15.96483063697815, 16.705472946166992, 17.437479257583618, 18.169485569000244, 18.881743669509888, 19.59400177001953, 20.308082818984985, 21.02216386795044, 21.719358682632446, 22.416553497314453, 23.127021551132202, 23.83748960494995, 24.54512882232666, 25.25276803970337, 25.990083932876587, 26.727399826049805, 27.4692120552063, 28.211024284362793, 28.957024812698364, 29.703025341033936, 30.441649913787842, 31.180274486541748, 31.889724016189575, 32.5991735458374, 33.323232889175415, 34.04729223251343, 34.7729606628418, 35.498629093170166, 36.210524559020996, 36.922420024871826, 37.678412675857544, 38.43440532684326, 39.18004035949707, 39.92567539215088, 40.6850950717926, 41.444514751434326, 42.15599513053894, 42.867475509643555, 43.57036781311035, 44.27326011657715, 44.97587823867798, 45.67849636077881, 46.378833532333374, 47.07917070388794, 47.78244495391846, 48.485719203948975, 49.18865418434143, 49.89158916473389, 50.59184432029724, 51.292099475860596, 51.99762535095215, 52.7031512260437, 53.401233434677124, 54.09931564331055, 54.800904750823975, 55.5024938583374, 56.19522523880005, 56.887956619262695, 57.59152841567993, 58.29510021209717, 58.9905891418457, 59.68607807159424, 60.394193172454834, 61.10230827331543, 61.807374238967896, 62.51244020462036, 63.205944776535034, 63.89944934844971, 64.60303330421448, 65.30661725997925, 66.0036313533783, 66.70064544677734, 67.40933537483215, 68.11802530288696, 68.81482195854187, 69.51161861419678, 70.21421527862549, 70.9168119430542, 71.61792731285095, 72.3190426826477, 73.01138281822205, 73.70372295379639, 74.41123628616333, 75.11874961853027, 75.81244444847107, 76.50613927841187, 77.20463037490845, 77.90312147140503, 78.59551095962524, 79.28790044784546, 79.9933729171753, 80.69884538650513, 81.40116477012634, 82.10348415374756, 82.79566836357117, 83.48785257339478, 84.18797016143799, 84.8880877494812, 85.61451649665833, 86.34094524383545, 87.04687643051147, 87.7528076171875, 88.4503231048584, 89.1478385925293, 89.85651135444641, 90.56518411636353, 91.27012658119202, 91.97506904602051, 92.67986989021301, 93.38467073440552, 94.08013987541199, 94.77560901641846, 95.47898435592651, 96.18235969543457, 96.88927412033081, 97.59618854522705, 98.29502177238464, 98.99385499954224, 99.70596599578857, 100.41807699203491, 101.12087917327881, 101.8236813545227, 102.5203914642334, 103.21710157394409, 103.91203808784485, 104.6069746017456, 105.29681658744812, 105.98665857315063, 106.68757677078247, 107.3884949684143, 108.08407068252563, 108.77964639663696, 109.48313975334167, 110.18663311004639, 110.8917863368988, 111.59693956375122, 112.29979014396667, 113.00264072418213, 113.69906401634216, 114.3954873085022, 115.08981847763062, 115.78414964675903, 116.48093581199646, 117.17772197723389, 117.87862515449524, 118.57952833175659, 119.27107048034668, 119.96261262893677, 120.66349816322327, 121.36438369750977, 122.05848336219788, 122.75258302688599, 123.45571756362915, 124.15885210037231, 124.85594344139099, 125.55303478240967, 126.24920320510864, 126.94537162780762, 127.65092372894287, 128.35647583007812, 129.0608229637146, 129.76517009735107, 130.4723162651062, 131.17946243286133, 131.87035393714905, 132.56124544143677, 133.25907826423645, 133.95691108703613, 134.65380358695984, 135.35069608688354, 136.04102444648743, 136.7313528060913, 137.43321537971497, 138.13507795333862, 138.82618880271912, 139.5172996520996, 140.21682286262512, 140.91634607315063, 141.61588501930237, 142.3154239654541, 143.71461749076843, 145.11381101608276]
[20.2, 20.2, 32.53333333333333, 32.53333333333333, 46.5, 46.5, 54.983333333333334, 54.983333333333334, 57.68333333333333, 57.68333333333333, 60.75, 60.75, 63.5, 63.5, 67.0, 67.0, 67.66666666666667, 67.66666666666667, 67.3, 67.3, 69.63333333333334, 69.63333333333334, 68.06666666666666, 68.06666666666666, 70.01666666666667, 70.01666666666667, 71.48333333333333, 71.48333333333333, 72.05, 72.05, 72.78333333333333, 72.78333333333333, 73.26666666666667, 73.26666666666667, 73.03333333333333, 73.03333333333333, 73.11666666666666, 73.11666666666666, 73.46666666666667, 73.46666666666667, 73.46666666666667, 73.46666666666667, 72.93333333333334, 72.93333333333334, 74.33333333333333, 74.33333333333333, 74.71666666666667, 74.71666666666667, 75.21666666666667, 75.21666666666667, 74.35, 74.35, 74.6, 74.6, 74.33333333333333, 74.33333333333333, 74.71666666666667, 74.71666666666667, 74.6, 74.6, 74.41666666666667, 74.41666666666667, 75.21666666666667, 75.21666666666667, 75.36666666666666, 75.36666666666666, 75.13333333333334, 75.13333333333334, 76.88333333333334, 76.88333333333334, 75.73333333333333, 75.73333333333333, 75.71666666666667, 75.71666666666667, 76.05, 76.05, 76.85, 76.85, 77.1, 77.1, 76.76666666666667, 76.76666666666667, 77.11666666666666, 77.11666666666666, 77.41666666666667, 77.41666666666667, 77.8, 77.8, 77.21666666666667, 77.21666666666667, 77.76666666666667, 77.76666666666667, 77.66666666666667, 77.66666666666667, 77.65, 77.65, 77.15, 77.15, 77.81666666666666, 77.81666666666666, 77.7, 77.7, 76.06666666666666, 76.06666666666666, 76.86666666666666, 76.86666666666666, 77.53333333333333, 77.53333333333333, 78.3, 78.3, 77.58333333333333, 77.58333333333333, 77.0, 77.0, 78.11666666666666, 78.11666666666666, 78.4, 78.4, 78.56666666666666, 78.56666666666666, 77.23333333333333, 77.23333333333333, 76.7, 76.7, 76.48333333333333, 76.48333333333333, 77.31666666666666, 77.31666666666666, 77.51666666666667, 77.51666666666667, 77.6, 77.6, 77.8, 77.8, 77.71666666666667, 77.71666666666667, 78.21666666666667, 78.21666666666667, 78.51666666666667, 78.51666666666667, 78.5, 78.5, 78.35, 78.35, 78.0, 78.0, 77.98333333333333, 77.98333333333333, 78.95, 78.95, 78.43333333333334, 78.43333333333334, 78.28333333333333, 78.28333333333333, 78.68333333333334, 78.68333333333334, 78.7, 78.7, 78.45, 78.45, 78.13333333333334, 78.13333333333334, 78.08333333333333, 78.08333333333333, 77.96666666666667, 77.96666666666667, 78.23333333333333, 78.23333333333333, 78.61666666666666, 78.61666666666666, 78.6, 78.6, 77.61666666666666, 77.61666666666666, 77.21666666666667, 77.21666666666667, 77.61666666666666, 77.61666666666666, 78.06666666666666, 78.06666666666666, 78.51666666666667, 78.51666666666667, 78.48333333333333, 78.48333333333333, 79.08333333333333, 79.08333333333333, 78.96666666666667, 78.96666666666667, 79.33333333333333, 79.33333333333333, 78.93333333333334, 78.93333333333334, 79.16666666666667, 79.16666666666667, 79.36666666666666, 79.36666666666666, 79.11666666666666, 79.11666666666666, 79.23333333333333, 79.23333333333333, 78.76666666666667, 78.76666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.263, Test loss: 2.096, Test accuracy: 19.27
Round   0, Global train loss: 1.263, Global test loss: 2.414, Global test accuracy: 12.28
Round   1, Train loss: 1.093, Test loss: 1.786, Test accuracy: 30.95
Round   1, Global train loss: 1.093, Global test loss: 2.386, Global test accuracy: 14.20
Round   2, Train loss: 0.953, Test loss: 1.415, Test accuracy: 43.12
Round   2, Global train loss: 0.953, Global test loss: 2.241, Global test accuracy: 21.37
Round   3, Train loss: 0.941, Test loss: 1.056, Test accuracy: 52.33
Round   3, Global train loss: 0.941, Global test loss: 2.014, Global test accuracy: 25.77
Round   4, Train loss: 0.912, Test loss: 1.049, Test accuracy: 55.47
Round   4, Global train loss: 0.912, Global test loss: 2.284, Global test accuracy: 23.88
Round   5, Train loss: 0.918, Test loss: 0.972, Test accuracy: 57.80
Round   5, Global train loss: 0.918, Global test loss: 1.907, Global test accuracy: 32.57
Round   6, Train loss: 0.903, Test loss: 0.862, Test accuracy: 61.65
Round   6, Global train loss: 0.903, Global test loss: 1.961, Global test accuracy: 30.08
Round   7, Train loss: 0.798, Test loss: 0.848, Test accuracy: 62.20
Round   7, Global train loss: 0.798, Global test loss: 2.216, Global test accuracy: 27.63
Round   8, Train loss: 0.764, Test loss: 0.856, Test accuracy: 63.58
Round   8, Global train loss: 0.764, Global test loss: 2.148, Global test accuracy: 28.78
Round   9, Train loss: 0.750, Test loss: 0.852, Test accuracy: 63.70
Round   9, Global train loss: 0.750, Global test loss: 1.837, Global test accuracy: 32.53
Round  10, Train loss: 0.680, Test loss: 0.793, Test accuracy: 66.75
Round  10, Global train loss: 0.680, Global test loss: 1.686, Global test accuracy: 40.35
Round  11, Train loss: 0.760, Test loss: 0.824, Test accuracy: 66.22
Round  11, Global train loss: 0.760, Global test loss: 1.808, Global test accuracy: 35.20
Round  12, Train loss: 0.710, Test loss: 0.742, Test accuracy: 68.83
Round  12, Global train loss: 0.710, Global test loss: 2.001, Global test accuracy: 38.93
Round  13, Train loss: 0.711, Test loss: 0.682, Test accuracy: 70.77
Round  13, Global train loss: 0.711, Global test loss: 1.933, Global test accuracy: 42.07
Round  14, Train loss: 0.708, Test loss: 0.676, Test accuracy: 71.02
Round  14, Global train loss: 0.708, Global test loss: 1.981, Global test accuracy: 36.53
Round  15, Train loss: 0.725, Test loss: 0.671, Test accuracy: 71.10
Round  15, Global train loss: 0.725, Global test loss: 1.674, Global test accuracy: 41.10
Round  16, Train loss: 0.787, Test loss: 0.659, Test accuracy: 72.00
Round  16, Global train loss: 0.787, Global test loss: 1.831, Global test accuracy: 35.47
Round  17, Train loss: 0.777, Test loss: 0.661, Test accuracy: 72.03
Round  17, Global train loss: 0.777, Global test loss: 1.740, Global test accuracy: 40.58
Round  18, Train loss: 0.591, Test loss: 0.659, Test accuracy: 72.33
Round  18, Global train loss: 0.591, Global test loss: 1.615, Global test accuracy: 42.87
Round  19, Train loss: 0.639, Test loss: 0.641, Test accuracy: 73.23
Round  19, Global train loss: 0.639, Global test loss: 1.832, Global test accuracy: 40.53
Round  20, Train loss: 0.627, Test loss: 0.676, Test accuracy: 72.23
Round  20, Global train loss: 0.627, Global test loss: 1.923, Global test accuracy: 35.88
Round  21, Train loss: 0.760, Test loss: 0.673, Test accuracy: 72.77
Round  21, Global train loss: 0.760, Global test loss: 1.530, Global test accuracy: 46.65
Round  22, Train loss: 0.680, Test loss: 0.643, Test accuracy: 73.57
Round  22, Global train loss: 0.680, Global test loss: 1.518, Global test accuracy: 46.47
Round  23, Train loss: 0.685, Test loss: 0.641, Test accuracy: 73.53
Round  23, Global train loss: 0.685, Global test loss: 1.647, Global test accuracy: 44.70
Round  24, Train loss: 0.625, Test loss: 0.638, Test accuracy: 73.87
Round  24, Global train loss: 0.625, Global test loss: 1.551, Global test accuracy: 45.93
Round  25, Train loss: 0.591, Test loss: 0.615, Test accuracy: 74.38
Round  25, Global train loss: 0.591, Global test loss: 1.502, Global test accuracy: 47.78
Round  26, Train loss: 0.606, Test loss: 0.621, Test accuracy: 74.27
Round  26, Global train loss: 0.606, Global test loss: 1.697, Global test accuracy: 43.37
Round  27, Train loss: 0.550, Test loss: 0.639, Test accuracy: 73.85
Round  27, Global train loss: 0.550, Global test loss: 1.606, Global test accuracy: 46.18
Round  28, Train loss: 0.570, Test loss: 0.618, Test accuracy: 74.50
Round  28, Global train loss: 0.570, Global test loss: 1.638, Global test accuracy: 43.73
Round  29, Train loss: 0.609, Test loss: 0.629, Test accuracy: 74.17
Round  29, Global train loss: 0.609, Global test loss: 1.601, Global test accuracy: 46.17
Round  30, Train loss: 0.542, Test loss: 0.624, Test accuracy: 74.52
Round  30, Global train loss: 0.542, Global test loss: 1.535, Global test accuracy: 45.12
Round  31, Train loss: 0.515, Test loss: 0.643, Test accuracy: 74.30
Round  31, Global train loss: 0.515, Global test loss: 1.483, Global test accuracy: 48.42
Round  32, Train loss: 0.620, Test loss: 0.645, Test accuracy: 74.35
Round  32, Global train loss: 0.620, Global test loss: 1.806, Global test accuracy: 38.83
Round  33, Train loss: 0.550, Test loss: 0.613, Test accuracy: 75.17
Round  33, Global train loss: 0.550, Global test loss: 1.490, Global test accuracy: 48.78
Round  34, Train loss: 0.585, Test loss: 0.619, Test accuracy: 75.10
Round  34, Global train loss: 0.585, Global test loss: 1.582, Global test accuracy: 47.73
Round  35, Train loss: 0.501, Test loss: 0.600, Test accuracy: 76.02
Round  35, Global train loss: 0.501, Global test loss: 1.435, Global test accuracy: 50.48
Round  36, Train loss: 0.468, Test loss: 0.607, Test accuracy: 75.68
Round  36, Global train loss: 0.468, Global test loss: 1.726, Global test accuracy: 47.27
Round  37, Train loss: 0.570, Test loss: 0.592, Test accuracy: 76.03
Round  37, Global train loss: 0.570, Global test loss: 1.649, Global test accuracy: 47.83
Round  38, Train loss: 0.566, Test loss: 0.612, Test accuracy: 75.40
Round  38, Global train loss: 0.566, Global test loss: 1.608, Global test accuracy: 49.08
Round  39, Train loss: 0.508, Test loss: 0.624, Test accuracy: 75.30
Round  39, Global train loss: 0.508, Global test loss: 1.470, Global test accuracy: 50.00
Round  40, Train loss: 0.516, Test loss: 0.613, Test accuracy: 75.53
Round  40, Global train loss: 0.516, Global test loss: 1.684, Global test accuracy: 44.93
Round  41, Train loss: 0.606, Test loss: 0.619, Test accuracy: 75.43
Round  41, Global train loss: 0.606, Global test loss: 1.554, Global test accuracy: 46.50
Round  42, Train loss: 0.537, Test loss: 0.630, Test accuracy: 75.32
Round  42, Global train loss: 0.537, Global test loss: 1.388, Global test accuracy: 51.53
Round  43, Train loss: 0.502, Test loss: 0.619, Test accuracy: 75.72
Round  43, Global train loss: 0.502, Global test loss: 1.469, Global test accuracy: 50.50
Round  44, Train loss: 0.455, Test loss: 0.603, Test accuracy: 76.73
Round  44, Global train loss: 0.455, Global test loss: 1.798, Global test accuracy: 39.12
Round  45, Train loss: 0.475, Test loss: 0.599, Test accuracy: 76.98
Round  45, Global train loss: 0.475, Global test loss: 1.406, Global test accuracy: 52.95
Round  46, Train loss: 0.502, Test loss: 0.586, Test accuracy: 77.67
Round  46, Global train loss: 0.502, Global test loss: 1.400, Global test accuracy: 54.72
Round  47, Train loss: 0.485, Test loss: 0.577, Test accuracy: 77.60
Round  47, Global train loss: 0.485, Global test loss: 1.611, Global test accuracy: 50.75
Round  48, Train loss: 0.516, Test loss: 0.564, Test accuracy: 77.90
Round  48, Global train loss: 0.516, Global test loss: 1.500, Global test accuracy: 48.77
Round  49, Train loss: 0.492, Test loss: 0.572, Test accuracy: 78.02
Round  49, Global train loss: 0.492, Global test loss: 1.421, Global test accuracy: 51.00
Round  50, Train loss: 0.529, Test loss: 0.573, Test accuracy: 77.95
Round  50, Global train loss: 0.529, Global test loss: 1.477, Global test accuracy: 50.83
Round  51, Train loss: 0.414, Test loss: 0.575, Test accuracy: 77.90
Round  51, Global train loss: 0.414, Global test loss: 1.523, Global test accuracy: 51.42
Round  52, Train loss: 0.504, Test loss: 0.586, Test accuracy: 77.40
Round  52, Global train loss: 0.504, Global test loss: 1.547, Global test accuracy: 49.00
Round  53, Train loss: 0.484, Test loss: 0.621, Test accuracy: 76.78
Round  53, Global train loss: 0.484, Global test loss: 1.553, Global test accuracy: 50.15
Round  54, Train loss: 0.493, Test loss: 0.601, Test accuracy: 77.53
Round  54, Global train loss: 0.493, Global test loss: 1.396, Global test accuracy: 52.87
Round  55, Train loss: 0.480, Test loss: 0.594, Test accuracy: 77.57
Round  55, Global train loss: 0.480, Global test loss: 1.632, Global test accuracy: 47.65
Round  56, Train loss: 0.456, Test loss: 0.555, Test accuracy: 78.38
Round  56, Global train loss: 0.456, Global test loss: 1.353, Global test accuracy: 53.73
Round  57, Train loss: 0.426, Test loss: 0.560, Test accuracy: 78.68
Round  57, Global train loss: 0.426, Global test loss: 1.329, Global test accuracy: 54.40
Round  58, Train loss: 0.520, Test loss: 0.573, Test accuracy: 78.08
Round  58, Global train loss: 0.520, Global test loss: 1.323, Global test accuracy: 55.13
Round  59, Train loss: 0.435, Test loss: 0.585, Test accuracy: 77.93
Round  59, Global train loss: 0.435, Global test loss: 1.462, Global test accuracy: 52.15
Round  60, Train loss: 0.400, Test loss: 0.589, Test accuracy: 77.63
Round  60, Global train loss: 0.400, Global test loss: 1.482, Global test accuracy: 51.47
Round  61, Train loss: 0.472, Test loss: 0.590, Test accuracy: 77.52
Round  61, Global train loss: 0.472, Global test loss: 1.378, Global test accuracy: 55.50
Round  62, Train loss: 0.438, Test loss: 0.587, Test accuracy: 77.57
Round  62, Global train loss: 0.438, Global test loss: 1.444, Global test accuracy: 51.93
Round  63, Train loss: 0.442, Test loss: 0.608, Test accuracy: 77.65
Round  63, Global train loss: 0.442, Global test loss: 1.416, Global test accuracy: 54.13
Round  64, Train loss: 0.390, Test loss: 0.593, Test accuracy: 78.22
Round  64, Global train loss: 0.390, Global test loss: 1.483, Global test accuracy: 53.67
Round  65, Train loss: 0.404, Test loss: 0.598, Test accuracy: 77.80
Round  65, Global train loss: 0.404, Global test loss: 1.459, Global test accuracy: 53.08
Round  66, Train loss: 0.373, Test loss: 0.588, Test accuracy: 78.30
Round  66, Global train loss: 0.373, Global test loss: 1.434, Global test accuracy: 52.60
Round  67, Train loss: 0.363, Test loss: 0.579, Test accuracy: 78.65
Round  67, Global train loss: 0.363, Global test loss: 1.454, Global test accuracy: 54.80
Round  68, Train loss: 0.301, Test loss: 0.593, Test accuracy: 78.30
Round  68, Global train loss: 0.301, Global test loss: 1.522, Global test accuracy: 53.68
Round  69, Train loss: 0.417, Test loss: 0.600, Test accuracy: 78.27
Round  69, Global train loss: 0.417, Global test loss: 1.652, Global test accuracy: 46.15
Round  70, Train loss: 0.318, Test loss: 0.603, Test accuracy: 78.28
Round  70, Global train loss: 0.318, Global test loss: 1.437, Global test accuracy: 55.18
Round  71, Train loss: 0.378, Test loss: 0.579, Test accuracy: 78.62
Round  71, Global train loss: 0.378, Global test loss: 1.341, Global test accuracy: 54.67
Round  72, Train loss: 0.360, Test loss: 0.591, Test accuracy: 78.98
Round  72, Global train loss: 0.360, Global test loss: 1.312, Global test accuracy: 56.87
Round  73, Train loss: 0.338, Test loss: 0.603, Test accuracy: 78.33
Round  73, Global train loss: 0.338, Global test loss: 1.696, Global test accuracy: 50.80
Round  74, Train loss: 0.377, Test loss: 0.584, Test accuracy: 78.95
Round  74, Global train loss: 0.377, Global test loss: 1.632, Global test accuracy: 51.95
Round  75, Train loss: 0.479, Test loss: 0.591, Test accuracy: 78.57
Round  75, Global train loss: 0.479, Global test loss: 1.474, Global test accuracy: 53.47
Round  76, Train loss: 0.300, Test loss: 0.628, Test accuracy: 78.00
Round  76, Global train loss: 0.300, Global test loss: 1.308, Global test accuracy: 57.62
Round  77, Train loss: 0.307, Test loss: 0.629, Test accuracy: 77.83
Round  77, Global train loss: 0.307, Global test loss: 1.349, Global test accuracy: 57.45
Round  78, Train loss: 0.394, Test loss: 0.609, Test accuracy: 78.37
Round  78, Global train loss: 0.394, Global test loss: 1.338, Global test accuracy: 56.72
Round  79, Train loss: 0.334, Test loss: 0.593, Test accuracy: 78.68
Round  79, Global train loss: 0.334, Global test loss: 1.313, Global test accuracy: 55.78
Round  80, Train loss: 0.366, Test loss: 0.602, Test accuracy: 78.47
Round  80, Global train loss: 0.366, Global test loss: 1.436, Global test accuracy: 53.17
Round  81, Train loss: 0.373, Test loss: 0.619, Test accuracy: 78.27
Round  81, Global train loss: 0.373, Global test loss: 1.687, Global test accuracy: 52.65
Round  82, Train loss: 0.372, Test loss: 0.620, Test accuracy: 78.27
Round  82, Global train loss: 0.372, Global test loss: 1.634, Global test accuracy: 48.60
Round  83, Train loss: 0.272, Test loss: 0.635, Test accuracy: 78.00
Round  83, Global train loss: 0.272, Global test loss: 1.366, Global test accuracy: 57.20
Round  84, Train loss: 0.261, Test loss: 0.638, Test accuracy: 78.13
Round  84, Global train loss: 0.261, Global test loss: 1.620, Global test accuracy: 54.92
Round  85, Train loss: 0.280, Test loss: 0.631, Test accuracy: 78.00
Round  85, Global train loss: 0.280, Global test loss: 1.412, Global test accuracy: 57.93
Round  86, Train loss: 0.417, Test loss: 0.632, Test accuracy: 78.20
Round  86, Global train loss: 0.417, Global test loss: 1.472, Global test accuracy: 53.27
Round  87, Train loss: 0.296, Test loss: 0.640, Test accuracy: 78.43
Round  87, Global train loss: 0.296, Global test loss: 1.589, Global test accuracy: 54.38
Round  88, Train loss: 0.364, Test loss: 0.629, Test accuracy: 78.55
Round  88, Global train loss: 0.364, Global test loss: 1.618, Global test accuracy: 53.20
Round  89, Train loss: 0.379, Test loss: 0.637, Test accuracy: 78.47
Round  89, Global train loss: 0.379, Global test loss: 1.420, Global test accuracy: 53.78
Round  90, Train loss: 0.321, Test loss: 0.637, Test accuracy: 78.72
Round  90, Global train loss: 0.321, Global test loss: 1.330, Global test accuracy: 56.67
Round  91, Train loss: 0.254, Test loss: 0.640, Test accuracy: 78.88
Round  91, Global train loss: 0.254, Global test loss: 1.772, Global test accuracy: 53.25
Round  92, Train loss: 0.354, Test loss: 0.613, Test accuracy: 79.45
Round  92, Global train loss: 0.354, Global test loss: 1.482, Global test accuracy: 53.38
Round  93, Train loss: 0.316, Test loss: 0.629, Test accuracy: 79.00
Round  93, Global train loss: 0.316, Global test loss: 1.675, Global test accuracy: 49.88
Round  94, Train loss: 0.281, Test loss: 0.628, Test accuracy: 79.12
Round  94, Global train loss: 0.281, Global test loss: 1.957, Global test accuracy: 49.12
Round  95, Train loss: 0.373, Test loss: 0.604, Test accuracy: 79.77
Round  95, Global train loss: 0.373, Global test loss: 1.420, Global test accuracy: 55.17
Round  96, Train loss: 0.304, Test loss: 0.612, Test accuracy: 79.43
Round  96, Global train loss: 0.304, Global test loss: 1.585, Global test accuracy: 52.23
Round  97, Train loss: 0.319, Test loss: 0.641, Test accuracy: 79.17
Round  97, Global train loss: 0.319, Global test loss: 1.709, Global test accuracy: 49.57
Round  98, Train loss: 0.349, Test loss: 0.643, Test accuracy: 79.18
Round  98, Global train loss: 0.349, Global test loss: 1.394, Global test accuracy: 55.90
Round  99, Train loss: 0.302, Test loss: 0.625, Test accuracy: 79.68
Round  99, Global train loss: 0.302, Global test loss: 1.468, Global test accuracy: 55.22
Final Round, Train loss: 0.236, Test loss: 0.666, Test accuracy: 79.25
Final Round, Global train loss: 0.236, Global test loss: 1.468, Global test accuracy: 55.22
Average accuracy final 10 rounds: 79.24000000000001 

Average global accuracy final 10 rounds: 53.038333333333334 

1027.644615650177
[1.0361535549163818, 2.0723071098327637, 2.865823984146118, 3.6593408584594727, 4.407675266265869, 5.156009674072266, 5.904062986373901, 6.652116298675537, 7.413886547088623, 8.175656795501709, 8.929200649261475, 9.68274450302124, 10.437670469284058, 11.192596435546875, 11.939828157424927, 12.687059879302979, 13.443548440933228, 14.200037002563477, 14.98644208908081, 15.772847175598145, 16.508899688720703, 17.24495220184326, 17.991739988327026, 18.73852777481079, 19.483997583389282, 20.229467391967773, 20.986337661743164, 21.743207931518555, 22.495443105697632, 23.24767827987671, 23.998555183410645, 24.74943208694458, 25.50211501121521, 26.25479793548584, 27.038665294647217, 27.822532653808594, 28.564116716384888, 29.30570077896118, 30.043964385986328, 30.782227993011475, 31.529191732406616, 32.27615547180176, 33.01501965522766, 33.753883838653564, 34.50153398513794, 35.249184131622314, 35.99694037437439, 36.744696617126465, 37.487650632858276, 38.23060464859009, 38.97832679748535, 39.726048946380615, 40.47389316558838, 41.22173738479614, 41.96782732009888, 42.71391725540161, 43.45586562156677, 44.197813987731934, 44.953768491744995, 45.70972299575806, 46.4536554813385, 47.197587966918945, 47.952624559402466, 48.707661151885986, 49.45366144180298, 50.19966173171997, 50.96100091934204, 51.72234010696411, 52.49102830886841, 53.259716510772705, 54.012452125549316, 54.76518774032593, 55.51682233810425, 56.26845693588257, 57.01761341094971, 57.766769886016846, 58.51189708709717, 59.25702428817749, 60.00811505317688, 60.75920581817627, 61.505523681640625, 62.25184154510498, 62.99721813201904, 63.742594718933105, 64.4905354976654, 65.2384762763977, 65.98315453529358, 66.72783279418945, 67.47701525688171, 68.22619771957397, 68.96985173225403, 69.71350574493408, 70.4612283706665, 71.20895099639893, 71.9662344455719, 72.72351789474487, 73.47846174240112, 74.23340559005737, 74.97280025482178, 75.71219491958618, 76.47552442550659, 77.238853931427, 77.980544090271, 78.72223424911499, 79.46998572349548, 80.21773719787598, 80.96767520904541, 81.71761322021484, 82.46513772010803, 83.21266222000122, 83.97145915031433, 84.73025608062744, 85.47866487503052, 86.2270736694336, 86.97998094558716, 87.73288822174072, 88.46876525878906, 89.2046422958374, 89.9643304347992, 90.72401857376099, 91.47089672088623, 92.21777486801147, 92.96501874923706, 93.71226263046265, 94.46093511581421, 95.20960760116577, 95.95829963684082, 96.70699167251587, 97.46142745018005, 98.21586322784424, 98.96141481399536, 99.70696640014648, 100.45842981338501, 101.20989322662354, 101.9575846195221, 102.70527601242065, 103.45397996902466, 104.20268392562866, 104.96502661705017, 105.72736930847168, 106.47424054145813, 107.22111177444458, 107.97101426124573, 108.72091674804688, 109.46616649627686, 110.21141624450684, 110.96573328971863, 111.72005033493042, 112.47572660446167, 113.23140287399292, 113.98064589500427, 114.72988891601562, 115.47907376289368, 116.22825860977173, 116.98399949073792, 117.7397403717041, 118.48748826980591, 119.23523616790771, 119.97987699508667, 120.72451782226562, 121.4718279838562, 122.21913814544678, 122.97416067123413, 123.72918319702148, 124.4721908569336, 125.2151985168457, 125.95999050140381, 126.70478248596191, 127.44043731689453, 128.17609214782715, 128.92697024345398, 129.6778483390808, 130.42822575569153, 131.17860317230225, 131.93674540519714, 132.69488763809204, 133.4448688030243, 134.19484996795654, 134.93993163108826, 135.68501329421997, 136.42736887931824, 137.1697244644165, 137.9095070362091, 138.6492896080017, 139.40483856201172, 140.16038751602173, 140.89923238754272, 141.63807725906372, 142.38435220718384, 143.13062715530396, 143.87242531776428, 144.6142234802246, 145.35534954071045, 146.0964756011963, 146.83724355697632, 147.57801151275635, 148.3244731426239, 149.07093477249146, 149.816175699234, 150.56141662597656, 152.0500774383545, 153.53873825073242]
[19.266666666666666, 19.266666666666666, 30.95, 30.95, 43.11666666666667, 43.11666666666667, 52.333333333333336, 52.333333333333336, 55.46666666666667, 55.46666666666667, 57.8, 57.8, 61.65, 61.65, 62.2, 62.2, 63.583333333333336, 63.583333333333336, 63.7, 63.7, 66.75, 66.75, 66.21666666666667, 66.21666666666667, 68.83333333333333, 68.83333333333333, 70.76666666666667, 70.76666666666667, 71.01666666666667, 71.01666666666667, 71.1, 71.1, 72.0, 72.0, 72.03333333333333, 72.03333333333333, 72.33333333333333, 72.33333333333333, 73.23333333333333, 73.23333333333333, 72.23333333333333, 72.23333333333333, 72.76666666666667, 72.76666666666667, 73.56666666666666, 73.56666666666666, 73.53333333333333, 73.53333333333333, 73.86666666666666, 73.86666666666666, 74.38333333333334, 74.38333333333334, 74.26666666666667, 74.26666666666667, 73.85, 73.85, 74.5, 74.5, 74.16666666666667, 74.16666666666667, 74.51666666666667, 74.51666666666667, 74.3, 74.3, 74.35, 74.35, 75.16666666666667, 75.16666666666667, 75.1, 75.1, 76.01666666666667, 76.01666666666667, 75.68333333333334, 75.68333333333334, 76.03333333333333, 76.03333333333333, 75.4, 75.4, 75.3, 75.3, 75.53333333333333, 75.53333333333333, 75.43333333333334, 75.43333333333334, 75.31666666666666, 75.31666666666666, 75.71666666666667, 75.71666666666667, 76.73333333333333, 76.73333333333333, 76.98333333333333, 76.98333333333333, 77.66666666666667, 77.66666666666667, 77.6, 77.6, 77.9, 77.9, 78.01666666666667, 78.01666666666667, 77.95, 77.95, 77.9, 77.9, 77.4, 77.4, 76.78333333333333, 76.78333333333333, 77.53333333333333, 77.53333333333333, 77.56666666666666, 77.56666666666666, 78.38333333333334, 78.38333333333334, 78.68333333333334, 78.68333333333334, 78.08333333333333, 78.08333333333333, 77.93333333333334, 77.93333333333334, 77.63333333333334, 77.63333333333334, 77.51666666666667, 77.51666666666667, 77.56666666666666, 77.56666666666666, 77.65, 77.65, 78.21666666666667, 78.21666666666667, 77.8, 77.8, 78.3, 78.3, 78.65, 78.65, 78.3, 78.3, 78.26666666666667, 78.26666666666667, 78.28333333333333, 78.28333333333333, 78.61666666666666, 78.61666666666666, 78.98333333333333, 78.98333333333333, 78.33333333333333, 78.33333333333333, 78.95, 78.95, 78.56666666666666, 78.56666666666666, 78.0, 78.0, 77.83333333333333, 77.83333333333333, 78.36666666666666, 78.36666666666666, 78.68333333333334, 78.68333333333334, 78.46666666666667, 78.46666666666667, 78.26666666666667, 78.26666666666667, 78.26666666666667, 78.26666666666667, 78.0, 78.0, 78.13333333333334, 78.13333333333334, 78.0, 78.0, 78.2, 78.2, 78.43333333333334, 78.43333333333334, 78.55, 78.55, 78.46666666666667, 78.46666666666667, 78.71666666666667, 78.71666666666667, 78.88333333333334, 78.88333333333334, 79.45, 79.45, 79.0, 79.0, 79.11666666666666, 79.11666666666666, 79.76666666666667, 79.76666666666667, 79.43333333333334, 79.43333333333334, 79.16666666666667, 79.16666666666667, 79.18333333333334, 79.18333333333334, 79.68333333333334, 79.68333333333334, 79.25, 79.25]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.780, Test loss: 2.219, Test accuracy: 15.80
Round   1, Train loss: 1.304, Test loss: 2.135, Test accuracy: 27.40
Round   2, Train loss: 1.104, Test loss: 1.624, Test accuracy: 38.03
Round   3, Train loss: 1.009, Test loss: 1.214, Test accuracy: 49.95
Round   4, Train loss: 1.014, Test loss: 1.174, Test accuracy: 54.48
Round   5, Train loss: 0.975, Test loss: 1.088, Test accuracy: 57.50
Round   6, Train loss: 1.064, Test loss: 0.957, Test accuracy: 59.72
Round   7, Train loss: 0.872, Test loss: 0.863, Test accuracy: 61.55
Round   8, Train loss: 0.859, Test loss: 0.877, Test accuracy: 61.58
Round   9, Train loss: 0.868, Test loss: 0.868, Test accuracy: 61.28
Round  10, Train loss: 0.860, Test loss: 0.834, Test accuracy: 64.15
Round  11, Train loss: 0.822, Test loss: 0.837, Test accuracy: 65.75
Round  12, Train loss: 0.817, Test loss: 0.768, Test accuracy: 69.77
Round  13, Train loss: 0.703, Test loss: 0.673, Test accuracy: 72.30
Round  14, Train loss: 0.690, Test loss: 0.685, Test accuracy: 71.80
Round  15, Train loss: 0.753, Test loss: 0.663, Test accuracy: 73.37
Round  16, Train loss: 0.750, Test loss: 0.655, Test accuracy: 73.50
Round  17, Train loss: 0.693, Test loss: 0.634, Test accuracy: 74.52
Round  18, Train loss: 0.657, Test loss: 0.635, Test accuracy: 74.22
Round  19, Train loss: 0.725, Test loss: 0.638, Test accuracy: 75.10
Round  20, Train loss: 0.637, Test loss: 0.633, Test accuracy: 74.88
Round  21, Train loss: 0.689, Test loss: 0.611, Test accuracy: 76.57
Round  22, Train loss: 0.680, Test loss: 0.592, Test accuracy: 76.07
Round  23, Train loss: 0.722, Test loss: 0.587, Test accuracy: 76.62
Round  24, Train loss: 0.654, Test loss: 0.596, Test accuracy: 77.32
Round  25, Train loss: 0.677, Test loss: 0.588, Test accuracy: 77.23
Round  26, Train loss: 0.738, Test loss: 0.588, Test accuracy: 77.22
Round  27, Train loss: 0.586, Test loss: 0.576, Test accuracy: 77.00
Round  28, Train loss: 0.691, Test loss: 0.573, Test accuracy: 77.17
Round  29, Train loss: 0.642, Test loss: 0.567, Test accuracy: 77.42
Round  30, Train loss: 0.578, Test loss: 0.576, Test accuracy: 77.43
Round  31, Train loss: 0.605, Test loss: 0.576, Test accuracy: 77.58
Round  32, Train loss: 0.600, Test loss: 0.573, Test accuracy: 77.88
Round  33, Train loss: 0.624, Test loss: 0.557, Test accuracy: 78.08
Round  34, Train loss: 0.580, Test loss: 0.556, Test accuracy: 78.32
Round  35, Train loss: 0.587, Test loss: 0.543, Test accuracy: 78.10
Round  36, Train loss: 0.535, Test loss: 0.535, Test accuracy: 78.37
Round  37, Train loss: 0.668, Test loss: 0.543, Test accuracy: 78.07
Round  38, Train loss: 0.530, Test loss: 0.543, Test accuracy: 78.78
Round  39, Train loss: 0.613, Test loss: 0.546, Test accuracy: 78.05
Round  40, Train loss: 0.606, Test loss: 0.540, Test accuracy: 78.30
Round  41, Train loss: 0.578, Test loss: 0.542, Test accuracy: 78.20
Round  42, Train loss: 0.595, Test loss: 0.536, Test accuracy: 78.70
Round  43, Train loss: 0.560, Test loss: 0.536, Test accuracy: 78.42
Round  44, Train loss: 0.556, Test loss: 0.539, Test accuracy: 78.77
Round  45, Train loss: 0.505, Test loss: 0.533, Test accuracy: 79.05
Round  46, Train loss: 0.608, Test loss: 0.533, Test accuracy: 78.95
Round  47, Train loss: 0.439, Test loss: 0.514, Test accuracy: 79.68
Round  48, Train loss: 0.612, Test loss: 0.524, Test accuracy: 79.18
Round  49, Train loss: 0.578, Test loss: 0.516, Test accuracy: 79.40
Round  50, Train loss: 0.568, Test loss: 0.512, Test accuracy: 79.60
Round  51, Train loss: 0.523, Test loss: 0.521, Test accuracy: 79.03
Round  52, Train loss: 0.565, Test loss: 0.511, Test accuracy: 79.43
Round  53, Train loss: 0.498, Test loss: 0.514, Test accuracy: 79.58
Round  54, Train loss: 0.457, Test loss: 0.519, Test accuracy: 79.12
Round  55, Train loss: 0.604, Test loss: 0.528, Test accuracy: 78.95
Round  56, Train loss: 0.568, Test loss: 0.514, Test accuracy: 79.23
Round  57, Train loss: 0.441, Test loss: 0.509, Test accuracy: 79.27
Round  58, Train loss: 0.506, Test loss: 0.503, Test accuracy: 79.97
Round  59, Train loss: 0.383, Test loss: 0.507, Test accuracy: 79.68
Round  60, Train loss: 0.433, Test loss: 0.503, Test accuracy: 79.67
Round  61, Train loss: 0.415, Test loss: 0.504, Test accuracy: 80.08
Round  62, Train loss: 0.486, Test loss: 0.506, Test accuracy: 80.07
Round  63, Train loss: 0.466, Test loss: 0.513, Test accuracy: 79.47
Round  64, Train loss: 0.416, Test loss: 0.509, Test accuracy: 79.57
Round  65, Train loss: 0.460, Test loss: 0.507, Test accuracy: 79.73
Round  66, Train loss: 0.390, Test loss: 0.502, Test accuracy: 80.03
Round  67, Train loss: 0.421, Test loss: 0.494, Test accuracy: 80.52
Round  68, Train loss: 0.419, Test loss: 0.497, Test accuracy: 80.13
Round  69, Train loss: 0.565, Test loss: 0.497, Test accuracy: 80.55
Round  70, Train loss: 0.420, Test loss: 0.494, Test accuracy: 80.35
Round  71, Train loss: 0.490, Test loss: 0.489, Test accuracy: 80.62
Round  72, Train loss: 0.433, Test loss: 0.486, Test accuracy: 80.58
Round  73, Train loss: 0.436, Test loss: 0.488, Test accuracy: 80.50
Round  74, Train loss: 0.422, Test loss: 0.489, Test accuracy: 80.42
Round  75, Train loss: 0.473, Test loss: 0.476, Test accuracy: 80.98
Round  76, Train loss: 0.463, Test loss: 0.476, Test accuracy: 80.87
Round  77, Train loss: 0.424, Test loss: 0.478, Test accuracy: 81.03
Round  78, Train loss: 0.469, Test loss: 0.476, Test accuracy: 81.40
Round  79, Train loss: 0.414, Test loss: 0.480, Test accuracy: 80.77
Round  80, Train loss: 0.457, Test loss: 0.484, Test accuracy: 80.50
Round  81, Train loss: 0.378, Test loss: 0.479, Test accuracy: 81.05
Round  82, Train loss: 0.446, Test loss: 0.484, Test accuracy: 80.47
Round  83, Train loss: 0.389, Test loss: 0.484, Test accuracy: 80.65
Round  84, Train loss: 0.463, Test loss: 0.485, Test accuracy: 80.33
Round  85, Train loss: 0.398, Test loss: 0.484, Test accuracy: 80.47
Round  86, Train loss: 0.480, Test loss: 0.478, Test accuracy: 80.93
Round  87, Train loss: 0.460, Test loss: 0.484, Test accuracy: 80.63
Round  88, Train loss: 0.362, Test loss: 0.484, Test accuracy: 80.40
Round  89, Train loss: 0.444, Test loss: 0.478, Test accuracy: 80.90
Round  90, Train loss: 0.365, Test loss: 0.475, Test accuracy: 80.97
Round  91, Train loss: 0.344, Test loss: 0.473, Test accuracy: 80.60
Round  92, Train loss: 0.410, Test loss: 0.478, Test accuracy: 81.22
Round  93, Train loss: 0.471, Test loss: 0.488, Test accuracy: 81.07
Round  94, Train loss: 0.446, Test loss: 0.491, Test accuracy: 80.92
Round  95, Train loss: 0.327, Test loss: 0.494, Test accuracy: 80.92
Round  96, Train loss: 0.461, Test loss: 0.493, Test accuracy: 80.68
Round  97, Train loss: 0.432, Test loss: 0.490, Test accuracy: 80.90
Round  98, Train loss: 0.343, Test loss: 0.486, Test accuracy: 81.27
Round  99, Train loss: 0.383, Test loss: 0.491, Test accuracy: 80.77
Final Round, Train loss: 0.324, Test loss: 0.484, Test accuracy: 81.25
Average accuracy final 10 rounds: 80.93
696.3071446418762
[1.1812984943389893, 2.027064561843872, 2.8685808181762695, 3.7081449031829834, 4.548434495925903, 5.396040439605713, 6.258094072341919, 7.10518741607666, 7.9327239990234375, 8.78655457496643, 9.640579462051392, 10.485631465911865, 11.348540544509888, 12.198323726654053, 13.03634262084961, 13.882537841796875, 14.734583377838135, 15.5728120803833, 16.416379690170288, 17.273600101470947, 18.108714818954468, 18.942321062088013, 19.801799297332764, 20.6644287109375, 21.50027823448181, 22.35729217529297, 23.215975761413574, 24.0472571849823, 24.87881565093994, 25.727566480636597, 26.582571744918823, 27.427213430404663, 28.281884908676147, 29.130539417266846, 29.964311838150024, 30.808173894882202, 31.62928557395935, 32.448726415634155, 33.28039789199829, 34.108694314956665, 34.93063187599182, 35.753570556640625, 36.57550287246704, 37.40735602378845, 38.23948860168457, 39.065375566482544, 39.87513208389282, 40.68844389915466, 41.525336503982544, 42.35170865058899, 43.16908311843872, 43.99150228500366, 44.81553292274475, 45.6478705406189, 46.48036289215088, 47.31487441062927, 48.13117551803589, 48.96266508102417, 49.79649090766907, 50.615904092788696, 51.43523597717285, 52.25771522521973, 53.102115869522095, 53.925259828567505, 54.74740028381348, 55.55888628959656, 56.38694763183594, 57.21947741508484, 58.0381121635437, 58.8621461391449, 59.6899938583374, 60.519564151763916, 61.33357858657837, 62.15199661254883, 62.97327756881714, 63.79731011390686, 64.62824273109436, 65.45071005821228, 66.25655746459961, 67.07935643196106, 67.90424466133118, 68.73182988166809, 69.55674576759338, 70.38561344146729, 71.20889353752136, 72.03928399085999, 72.86853051185608, 73.69090867042542, 74.51572060585022, 75.34343314170837, 76.17049312591553, 76.98369073867798, 77.80446887016296, 78.63483595848083, 79.47547817230225, 80.30483174324036, 81.12985968589783, 81.94746541976929, 82.77461075782776, 83.61105394363403, 84.93984484672546]
[15.8, 27.4, 38.03333333333333, 49.95, 54.483333333333334, 57.5, 59.71666666666667, 61.55, 61.583333333333336, 61.28333333333333, 64.15, 65.75, 69.76666666666667, 72.3, 71.8, 73.36666666666666, 73.5, 74.51666666666667, 74.21666666666667, 75.1, 74.88333333333334, 76.56666666666666, 76.06666666666666, 76.61666666666666, 77.31666666666666, 77.23333333333333, 77.21666666666667, 77.0, 77.16666666666667, 77.41666666666667, 77.43333333333334, 77.58333333333333, 77.88333333333334, 78.08333333333333, 78.31666666666666, 78.1, 78.36666666666666, 78.06666666666666, 78.78333333333333, 78.05, 78.3, 78.2, 78.7, 78.41666666666667, 78.76666666666667, 79.05, 78.95, 79.68333333333334, 79.18333333333334, 79.4, 79.6, 79.03333333333333, 79.43333333333334, 79.58333333333333, 79.11666666666666, 78.95, 79.23333333333333, 79.26666666666667, 79.96666666666667, 79.68333333333334, 79.66666666666667, 80.08333333333333, 80.06666666666666, 79.46666666666667, 79.56666666666666, 79.73333333333333, 80.03333333333333, 80.51666666666667, 80.13333333333334, 80.55, 80.35, 80.61666666666666, 80.58333333333333, 80.5, 80.41666666666667, 80.98333333333333, 80.86666666666666, 81.03333333333333, 81.4, 80.76666666666667, 80.5, 81.05, 80.46666666666667, 80.65, 80.33333333333333, 80.46666666666667, 80.93333333333334, 80.63333333333334, 80.4, 80.9, 80.96666666666667, 80.6, 81.21666666666667, 81.06666666666666, 80.91666666666667, 80.91666666666667, 80.68333333333334, 80.9, 81.26666666666667, 80.76666666666667, 81.25]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  13.3900
Round 1 global test acc  13.1500
Round 2 global test acc  10.0000
Round 3 global test acc  10.1600
Round 4 global test acc  18.0700
Round 5 global test acc  21.3600
Round 6 global test acc  23.9200
Round 7 global test acc  18.8300
Round 8 global test acc  30.1000
Round 9 global test acc  17.9800
Round 10 global test acc  24.3000
Round 11 global test acc  30.2600
Round 12 global test acc  25.9900
Round 13 global test acc  22.4500
Round 14 global test acc  22.3500
Round 15 global test acc  28.5400
Round 16 global test acc  28.5500
Round 17 global test acc  24.5600
Round 18 global test acc  29.2500
Round 19 global test acc  29.4000
Round 20 global test acc  29.0800
Round 21 global test acc  20.4900
Round 22 global test acc  30.3700
Round 23 global test acc  28.6000
Round 24 global test acc  24.1600
Round 25 global test acc  33.0400
Round 26 global test acc  32.9500
Round 27 global test acc  31.7500
Round 28 global test acc  31.5500
Round 29 global test acc  25.0400
Round 30 global test acc  35.7300
Round 31 global test acc  30.8800
Round 32 global test acc  31.3700
Round 33 global test acc  26.2700
Round 34 global test acc  32.2200
Round 35 global test acc  26.2700
Round 36 global test acc  35.2600
Round 37 global test acc  27.5400
Round 38 global test acc  33.5700
Round 39 global test acc  31.7100
Round 40 global test acc  31.4300
Round 41 global test acc  31.9600
Round 42 global test acc  23.5400
Round 43 global test acc  23.9100
Round 44 global test acc  34.7100
Round 45 global test acc  34.1600
Round 46 global test acc  31.1100
Round 47 global test acc  22.7500
Round 48 global test acc  26.8500
Round 49 global test acc  35.5700
Round 50 global test acc  34.0600
Round 51 global test acc  27.5600
Round 52 global test acc  37.1600
Round 53 global test acc  37.7500
Round 54 global test acc  34.2500
Round 55 global test acc  25.5200
Round 56 global test acc  31.7400
Round 57 global test acc  34.0200
Round 58 global test acc  32.2600
Round 59 global test acc  23.1500
Round 60 global test acc  34.8000
Round 61 global test acc  31.2400
Round 62 global test acc  32.5000
Round 63 global test acc  32.4300
Round 64 global test acc  33.0300
Round 65 global test acc  31.3000
Round 66 global test acc  37.4300
Round 67 global test acc  31.9000
Round 68 global test acc  36.0600
Round 69 global test acc  23.9300
Round 70 global test acc  23.5200
Round 71 global test acc  31.2500
Round 72 global test acc  30.1200
Round 73 global test acc  32.1000
Round 74 global test acc  38.2000
Round 75 global test acc  21.5200
Round 76 global test acc  38.3700
Round 77 global test acc  30.7200
Round 78 global test acc  26.8500
Round 79 global test acc  31.3800
Round 80 global test acc  31.7500
Round 81 global test acc  29.5000
Round 82 global test acc  29.5800
Round 83 global test acc  29.5100
Round 84 global test acc  28.1000
Round 85 global test acc  27.2200
Round 86 global test acc  26.1600
Round 87 global test acc  23.7100
Round 88 global test acc  23.0800
Round 89 global test acc  23.6300
Round 90 global test acc  22.8800
Round 91 global test acc  21.6100
Round 92 global test acc  20.9400
Round 93 global test acc  20.7100
Round 94 global test acc  20.2300
Round 95 global test acc  19.6800
Round 96 global test acc  18.1400
Round 97 global test acc  18.2200
Round 98 global test acc  17.9500
Round 99 global test acc  17.1900
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.756, Test loss: 2.202, Test accuracy: 16.38
Round   1, Train loss: 1.303, Test loss: 2.210, Test accuracy: 26.90
Round   2, Train loss: 1.207, Test loss: 1.651, Test accuracy: 39.03
Round   3, Train loss: 1.022, Test loss: 1.203, Test accuracy: 49.47
Round   4, Train loss: 1.090, Test loss: 1.253, Test accuracy: 50.80
Round   5, Train loss: 0.963, Test loss: 1.107, Test accuracy: 56.60
Round   6, Train loss: 0.920, Test loss: 0.966, Test accuracy: 59.73
Round   7, Train loss: 0.814, Test loss: 0.839, Test accuracy: 63.78
Round   8, Train loss: 0.804, Test loss: 0.878, Test accuracy: 64.22
Round   9, Train loss: 0.773, Test loss: 0.817, Test accuracy: 66.10
Round  10, Train loss: 0.786, Test loss: 0.797, Test accuracy: 66.85
Round  11, Train loss: 0.766, Test loss: 0.833, Test accuracy: 67.68
Round  12, Train loss: 0.745, Test loss: 0.761, Test accuracy: 70.28
Round  13, Train loss: 0.668, Test loss: 0.689, Test accuracy: 72.02
Round  14, Train loss: 0.697, Test loss: 0.693, Test accuracy: 71.57
Round  15, Train loss: 0.740, Test loss: 0.675, Test accuracy: 72.38
Round  16, Train loss: 0.810, Test loss: 0.667, Test accuracy: 73.53
Round  17, Train loss: 0.766, Test loss: 0.656, Test accuracy: 73.37
Round  18, Train loss: 0.698, Test loss: 0.637, Test accuracy: 72.98
Round  19, Train loss: 0.656, Test loss: 0.627, Test accuracy: 74.65
Round  20, Train loss: 0.696, Test loss: 0.618, Test accuracy: 74.25
Round  21, Train loss: 0.641, Test loss: 0.605, Test accuracy: 75.65
Round  22, Train loss: 0.721, Test loss: 0.584, Test accuracy: 76.83
Round  23, Train loss: 0.733, Test loss: 0.596, Test accuracy: 77.00
Round  24, Train loss: 0.697, Test loss: 0.577, Test accuracy: 76.95
Round  25, Train loss: 0.653, Test loss: 0.575, Test accuracy: 77.23
Round  26, Train loss: 0.667, Test loss: 0.583, Test accuracy: 76.93
Round  27, Train loss: 0.612, Test loss: 0.574, Test accuracy: 77.37
Round  28, Train loss: 0.733, Test loss: 0.578, Test accuracy: 77.20
Round  29, Train loss: 0.647, Test loss: 0.580, Test accuracy: 77.28
Round  30, Train loss: 0.665, Test loss: 0.567, Test accuracy: 77.75
Round  31, Train loss: 0.642, Test loss: 0.561, Test accuracy: 78.18
Round  32, Train loss: 0.642, Test loss: 0.571, Test accuracy: 77.78
Round  33, Train loss: 0.602, Test loss: 0.561, Test accuracy: 76.98
Round  34, Train loss: 0.560, Test loss: 0.548, Test accuracy: 77.90
Round  35, Train loss: 0.543, Test loss: 0.555, Test accuracy: 78.03
Round  36, Train loss: 0.516, Test loss: 0.546, Test accuracy: 78.18
Round  37, Train loss: 0.672, Test loss: 0.552, Test accuracy: 78.03
Round  38, Train loss: 0.517, Test loss: 0.545, Test accuracy: 78.53
Round  39, Train loss: 0.647, Test loss: 0.539, Test accuracy: 78.78
Round  40, Train loss: 0.608, Test loss: 0.534, Test accuracy: 79.05
Round  41, Train loss: 0.594, Test loss: 0.532, Test accuracy: 79.12
Round  42, Train loss: 0.560, Test loss: 0.532, Test accuracy: 79.17
Round  43, Train loss: 0.538, Test loss: 0.549, Test accuracy: 78.75
Round  44, Train loss: 0.582, Test loss: 0.540, Test accuracy: 78.63
Round  45, Train loss: 0.526, Test loss: 0.529, Test accuracy: 79.27
Round  46, Train loss: 0.599, Test loss: 0.518, Test accuracy: 79.27
Round  47, Train loss: 0.465, Test loss: 0.521, Test accuracy: 79.65
Round  48, Train loss: 0.541, Test loss: 0.523, Test accuracy: 79.63
Round  49, Train loss: 0.543, Test loss: 0.519, Test accuracy: 79.87
Round  50, Train loss: 0.442, Test loss: 0.516, Test accuracy: 80.02
Round  51, Train loss: 0.479, Test loss: 0.516, Test accuracy: 79.60
Round  52, Train loss: 0.482, Test loss: 0.518, Test accuracy: 79.73
Round  53, Train loss: 0.539, Test loss: 0.521, Test accuracy: 79.73
Round  54, Train loss: 0.437, Test loss: 0.520, Test accuracy: 79.37
Round  55, Train loss: 0.556, Test loss: 0.521, Test accuracy: 79.53
Round  56, Train loss: 0.547, Test loss: 0.520, Test accuracy: 79.55
Round  57, Train loss: 0.465, Test loss: 0.516, Test accuracy: 79.35
Round  58, Train loss: 0.453, Test loss: 0.517, Test accuracy: 79.67
Round  59, Train loss: 0.413, Test loss: 0.508, Test accuracy: 80.23
Round  60, Train loss: 0.467, Test loss: 0.513, Test accuracy: 80.17
Round  61, Train loss: 0.407, Test loss: 0.499, Test accuracy: 80.50
Round  62, Train loss: 0.541, Test loss: 0.502, Test accuracy: 80.75
Round  63, Train loss: 0.517, Test loss: 0.501, Test accuracy: 81.05
Round  64, Train loss: 0.456, Test loss: 0.492, Test accuracy: 81.22
Round  65, Train loss: 0.481, Test loss: 0.493, Test accuracy: 81.18
Round  66, Train loss: 0.465, Test loss: 0.495, Test accuracy: 80.70
Round  67, Train loss: 0.441, Test loss: 0.495, Test accuracy: 81.07
Round  68, Train loss: 0.458, Test loss: 0.502, Test accuracy: 80.82
Round  69, Train loss: 0.525, Test loss: 0.508, Test accuracy: 80.12
Round  70, Train loss: 0.422, Test loss: 0.499, Test accuracy: 80.60
Round  71, Train loss: 0.440, Test loss: 0.500, Test accuracy: 80.60
Round  72, Train loss: 0.436, Test loss: 0.493, Test accuracy: 80.73
Round  73, Train loss: 0.518, Test loss: 0.488, Test accuracy: 81.00
Round  74, Train loss: 0.394, Test loss: 0.486, Test accuracy: 81.23
Round  75, Train loss: 0.436, Test loss: 0.488, Test accuracy: 81.13
Round  76, Train loss: 0.411, Test loss: 0.479, Test accuracy: 81.38
Round  77, Train loss: 0.458, Test loss: 0.479, Test accuracy: 81.77
Round  78, Train loss: 0.457, Test loss: 0.485, Test accuracy: 81.35
Round  79, Train loss: 0.406, Test loss: 0.469, Test accuracy: 81.45
Round  80, Train loss: 0.524, Test loss: 0.494, Test accuracy: 80.50
Round  81, Train loss: 0.364, Test loss: 0.478, Test accuracy: 81.43
Round  82, Train loss: 0.468, Test loss: 0.490, Test accuracy: 81.03
Round  83, Train loss: 0.429, Test loss: 0.491, Test accuracy: 81.00
Round  84, Train loss: 0.419, Test loss: 0.500, Test accuracy: 80.38
Round  85, Train loss: 0.363, Test loss: 0.484, Test accuracy: 80.83
Round  86, Train loss: 0.450, Test loss: 0.480, Test accuracy: 81.30
Round  87, Train loss: 0.435, Test loss: 0.488, Test accuracy: 80.83
Round  88, Train loss: 0.348, Test loss: 0.492, Test accuracy: 81.10
Round  89, Train loss: 0.438, Test loss: 0.490, Test accuracy: 81.27
Round  90, Train loss: 0.377, Test loss: 0.486, Test accuracy: 81.37
Round  91, Train loss: 0.384, Test loss: 0.483, Test accuracy: 81.48
Round  92, Train loss: 0.406, Test loss: 0.486, Test accuracy: 81.62
Round  93, Train loss: 0.392, Test loss: 0.490, Test accuracy: 81.73
Round  94, Train loss: 0.450, Test loss: 0.494, Test accuracy: 81.63
Round  95, Train loss: 0.330, Test loss: 0.492, Test accuracy: 81.67
Round  96, Train loss: 0.429, Test loss: 0.487, Test accuracy: 81.58
Round  97, Train loss: 0.364, Test loss: 0.490, Test accuracy: 81.60
Round  98, Train loss: 0.376, Test loss: 0.487, Test accuracy: 81.93
Round  99, Train loss: 0.381, Test loss: 0.482, Test accuracy: 82.03
Final Round, Train loss: 0.326, Test loss: 0.477, Test accuracy: 82.17
Average accuracy final 10 rounds: 81.66499999999999
699.8230109214783
[1.1518394947052002, 2.006814479827881, 2.845947265625, 3.6873185634613037, 4.51153826713562, 5.34462833404541, 6.244908094406128, 7.082086563110352, 7.930603981018066, 8.758016586303711, 9.599308729171753, 10.442283630371094, 11.288142681121826, 12.126327514648438, 12.970404863357544, 13.809454441070557, 14.648228406906128, 15.481684446334839, 16.326021194458008, 17.176045894622803, 18.016434907913208, 18.839606523513794, 19.673692226409912, 20.528727769851685, 21.373114109039307, 22.206615924835205, 23.03585934638977, 23.886265993118286, 24.729122161865234, 25.566959381103516, 26.396826028823853, 27.242141485214233, 28.08880114555359, 28.93666911125183, 29.75027871131897, 30.598626136779785, 31.450067043304443, 32.29285907745361, 33.120551347732544, 33.94611883163452, 34.78779125213623, 35.635342836380005, 36.4735152721405, 37.30043005943298, 38.15202307701111, 39.004130601882935, 39.844642877578735, 40.667908906936646, 41.504136085510254, 42.3556764125824, 43.20473337173462, 44.03037095069885, 44.8554105758667, 45.70066571235657, 46.548070430755615, 47.37904334068298, 48.200578689575195, 49.0441837310791, 49.90852117538452, 50.75314164161682, 51.589383125305176, 52.494486570358276, 53.34763860702515, 54.19369602203369, 55.027820348739624, 55.869473934173584, 56.71403193473816, 57.553001403808594, 58.389681577682495, 59.236674308776855, 60.083988428115845, 60.926246881484985, 61.75519371032715, 62.58381485939026, 63.443899154663086, 64.28901410102844, 65.1254153251648, 65.96413064002991, 66.80868887901306, 67.65082716941833, 68.48427104949951, 69.30896234512329, 70.14243793487549, 70.97920680046082, 71.8183491230011, 72.63312268257141, 73.47680139541626, 74.31362771987915, 75.1620786190033, 75.98334074020386, 76.80834150314331, 77.65237617492676, 78.49556279182434, 79.3378119468689, 80.15896010398865, 81.00131607055664, 81.84036040306091, 82.67552709579468, 83.48910999298096, 84.32574963569641, 85.67281079292297]
[16.383333333333333, 26.9, 39.03333333333333, 49.46666666666667, 50.8, 56.6, 59.733333333333334, 63.78333333333333, 64.21666666666667, 66.1, 66.85, 67.68333333333334, 70.28333333333333, 72.01666666666667, 71.56666666666666, 72.38333333333334, 73.53333333333333, 73.36666666666666, 72.98333333333333, 74.65, 74.25, 75.65, 76.83333333333333, 77.0, 76.95, 77.23333333333333, 76.93333333333334, 77.36666666666666, 77.2, 77.28333333333333, 77.75, 78.18333333333334, 77.78333333333333, 76.98333333333333, 77.9, 78.03333333333333, 78.18333333333334, 78.03333333333333, 78.53333333333333, 78.78333333333333, 79.05, 79.11666666666666, 79.16666666666667, 78.75, 78.63333333333334, 79.26666666666667, 79.26666666666667, 79.65, 79.63333333333334, 79.86666666666666, 80.01666666666667, 79.6, 79.73333333333333, 79.73333333333333, 79.36666666666666, 79.53333333333333, 79.55, 79.35, 79.66666666666667, 80.23333333333333, 80.16666666666667, 80.5, 80.75, 81.05, 81.21666666666667, 81.18333333333334, 80.7, 81.06666666666666, 80.81666666666666, 80.11666666666666, 80.6, 80.6, 80.73333333333333, 81.0, 81.23333333333333, 81.13333333333334, 81.38333333333334, 81.76666666666667, 81.35, 81.45, 80.5, 81.43333333333334, 81.03333333333333, 81.0, 80.38333333333334, 80.83333333333333, 81.3, 80.83333333333333, 81.1, 81.26666666666667, 81.36666666666666, 81.48333333333333, 81.61666666666666, 81.73333333333333, 81.63333333333334, 81.66666666666667, 81.58333333333333, 81.6, 81.93333333333334, 82.03333333333333, 82.16666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.741, Test loss: 2.240, Test accuracy: 15.00
Round   1, Train loss: 1.187, Test loss: 2.141, Test accuracy: 24.82
Round   2, Train loss: 0.998, Test loss: 1.605, Test accuracy: 38.27
Round   3, Train loss: 1.103, Test loss: 1.208, Test accuracy: 48.15
Round   4, Train loss: 0.872, Test loss: 1.194, Test accuracy: 51.18
Round   5, Train loss: 0.932, Test loss: 1.072, Test accuracy: 55.88
Round   6, Train loss: 0.878, Test loss: 0.914, Test accuracy: 60.85
Round   7, Train loss: 0.851, Test loss: 0.823, Test accuracy: 65.22
Round   8, Train loss: 0.775, Test loss: 0.855, Test accuracy: 64.62
Round   9, Train loss: 0.854, Test loss: 0.825, Test accuracy: 65.02
Round  10, Train loss: 0.786, Test loss: 0.767, Test accuracy: 67.37
Round  11, Train loss: 0.783, Test loss: 0.810, Test accuracy: 66.43
Round  12, Train loss: 0.705, Test loss: 0.740, Test accuracy: 69.10
Round  13, Train loss: 0.720, Test loss: 0.675, Test accuracy: 71.33
Round  14, Train loss: 0.708, Test loss: 0.661, Test accuracy: 72.30
Round  15, Train loss: 0.652, Test loss: 0.649, Test accuracy: 72.82
Round  16, Train loss: 0.835, Test loss: 0.631, Test accuracy: 73.35
Round  17, Train loss: 0.707, Test loss: 0.628, Test accuracy: 74.27
Round  18, Train loss: 0.645, Test loss: 0.630, Test accuracy: 73.75
Round  19, Train loss: 0.576, Test loss: 0.625, Test accuracy: 74.25
Round  20, Train loss: 0.689, Test loss: 0.619, Test accuracy: 74.13
Round  21, Train loss: 0.723, Test loss: 0.606, Test accuracy: 74.25
Round  22, Train loss: 0.672, Test loss: 0.590, Test accuracy: 75.45
Round  23, Train loss: 0.675, Test loss: 0.596, Test accuracy: 75.08
Round  24, Train loss: 0.641, Test loss: 0.602, Test accuracy: 74.95
Round  25, Train loss: 0.579, Test loss: 0.600, Test accuracy: 74.52
Round  26, Train loss: 0.591, Test loss: 0.604, Test accuracy: 74.33
Round  27, Train loss: 0.497, Test loss: 0.597, Test accuracy: 74.32
Round  28, Train loss: 0.592, Test loss: 0.595, Test accuracy: 74.58
Round  29, Train loss: 0.604, Test loss: 0.590, Test accuracy: 75.20
Round  30, Train loss: 0.622, Test loss: 0.591, Test accuracy: 75.13
Round  31, Train loss: 0.592, Test loss: 0.575, Test accuracy: 75.60
Round  32, Train loss: 0.618, Test loss: 0.567, Test accuracy: 76.05
Round  33, Train loss: 0.556, Test loss: 0.554, Test accuracy: 76.87
Round  34, Train loss: 0.609, Test loss: 0.548, Test accuracy: 77.35
Round  35, Train loss: 0.553, Test loss: 0.549, Test accuracy: 77.82
Round  36, Train loss: 0.483, Test loss: 0.548, Test accuracy: 77.42
Round  37, Train loss: 0.571, Test loss: 0.562, Test accuracy: 77.38
Round  38, Train loss: 0.576, Test loss: 0.546, Test accuracy: 77.63
Round  39, Train loss: 0.514, Test loss: 0.547, Test accuracy: 77.43
Round  40, Train loss: 0.560, Test loss: 0.537, Test accuracy: 77.83
Round  41, Train loss: 0.524, Test loss: 0.528, Test accuracy: 78.15
Round  42, Train loss: 0.590, Test loss: 0.533, Test accuracy: 78.07
Round  43, Train loss: 0.509, Test loss: 0.522, Test accuracy: 78.53
Round  44, Train loss: 0.540, Test loss: 0.531, Test accuracy: 78.08
Round  45, Train loss: 0.510, Test loss: 0.534, Test accuracy: 78.27
Round  46, Train loss: 0.546, Test loss: 0.534, Test accuracy: 78.28
Round  47, Train loss: 0.491, Test loss: 0.529, Test accuracy: 78.93
Round  48, Train loss: 0.564, Test loss: 0.513, Test accuracy: 79.28
Round  49, Train loss: 0.619, Test loss: 0.522, Test accuracy: 79.22
Round  50, Train loss: 0.495, Test loss: 0.511, Test accuracy: 79.57
Round  51, Train loss: 0.522, Test loss: 0.510, Test accuracy: 79.37
Round  52, Train loss: 0.490, Test loss: 0.512, Test accuracy: 78.92
Round  53, Train loss: 0.537, Test loss: 0.513, Test accuracy: 79.77
Round  54, Train loss: 0.410, Test loss: 0.514, Test accuracy: 79.88
Round  55, Train loss: 0.469, Test loss: 0.508, Test accuracy: 79.90
Round  56, Train loss: 0.553, Test loss: 0.509, Test accuracy: 79.62
Round  57, Train loss: 0.500, Test loss: 0.510, Test accuracy: 79.57
Round  58, Train loss: 0.545, Test loss: 0.515, Test accuracy: 79.30
Round  59, Train loss: 0.480, Test loss: 0.516, Test accuracy: 79.00
Round  60, Train loss: 0.478, Test loss: 0.516, Test accuracy: 79.17
Round  61, Train loss: 0.415, Test loss: 0.505, Test accuracy: 79.57
Round  62, Train loss: 0.442, Test loss: 0.505, Test accuracy: 79.57
Round  63, Train loss: 0.468, Test loss: 0.505, Test accuracy: 79.78
Round  64, Train loss: 0.451, Test loss: 0.496, Test accuracy: 80.37
Round  65, Train loss: 0.352, Test loss: 0.495, Test accuracy: 80.22
Round  66, Train loss: 0.552, Test loss: 0.485, Test accuracy: 80.67
Round  67, Train loss: 0.375, Test loss: 0.491, Test accuracy: 80.47
Round  68, Train loss: 0.441, Test loss: 0.488, Test accuracy: 80.42
Round  69, Train loss: 0.451, Test loss: 0.501, Test accuracy: 79.52
Round  70, Train loss: 0.329, Test loss: 0.490, Test accuracy: 80.13
Round  71, Train loss: 0.565, Test loss: 0.489, Test accuracy: 80.58
Round  72, Train loss: 0.397, Test loss: 0.491, Test accuracy: 80.45
Round  73, Train loss: 0.378, Test loss: 0.495, Test accuracy: 80.35
Round  74, Train loss: 0.371, Test loss: 0.482, Test accuracy: 80.35
Round  75, Train loss: 0.481, Test loss: 0.490, Test accuracy: 80.08
Round  76, Train loss: 0.460, Test loss: 0.482, Test accuracy: 80.62
Round  77, Train loss: 0.387, Test loss: 0.495, Test accuracy: 80.72
Round  78, Train loss: 0.386, Test loss: 0.493, Test accuracy: 80.92
Round  79, Train loss: 0.465, Test loss: 0.490, Test accuracy: 80.63
Round  80, Train loss: 0.403, Test loss: 0.483, Test accuracy: 80.83
Round  81, Train loss: 0.427, Test loss: 0.475, Test accuracy: 81.07
Round  82, Train loss: 0.447, Test loss: 0.487, Test accuracy: 80.88
Round  83, Train loss: 0.340, Test loss: 0.502, Test accuracy: 80.40
Round  84, Train loss: 0.331, Test loss: 0.484, Test accuracy: 81.23
Round  85, Train loss: 0.266, Test loss: 0.477, Test accuracy: 81.07
Round  86, Train loss: 0.498, Test loss: 0.483, Test accuracy: 81.13
Round  87, Train loss: 0.318, Test loss: 0.493, Test accuracy: 80.58
Round  88, Train loss: 0.346, Test loss: 0.483, Test accuracy: 80.97
Round  89, Train loss: 0.465, Test loss: 0.486, Test accuracy: 80.88
Round  90, Train loss: 0.439, Test loss: 0.495, Test accuracy: 80.68
Round  91, Train loss: 0.384, Test loss: 0.475, Test accuracy: 81.47
Round  92, Train loss: 0.393, Test loss: 0.480, Test accuracy: 81.10
Round  93, Train loss: 0.367, Test loss: 0.483, Test accuracy: 80.65
Round  94, Train loss: 0.369, Test loss: 0.481, Test accuracy: 80.55
Round  95, Train loss: 0.340, Test loss: 0.486, Test accuracy: 80.83
Round  96, Train loss: 0.360, Test loss: 0.493, Test accuracy: 80.60
Round  97, Train loss: 0.385, Test loss: 0.489, Test accuracy: 80.30
Round  98, Train loss: 0.390, Test loss: 0.487, Test accuracy: 80.58
Round  99, Train loss: 0.321, Test loss: 0.487, Test accuracy: 80.55
Final Round, Train loss: 0.332, Test loss: 0.477, Test accuracy: 81.87
Average accuracy final 10 rounds: 80.73166666666668
1167.969882965088
[1.1917250156402588, 2.015164613723755, 2.827366828918457, 3.650817394256592, 4.476165533065796, 5.313701152801514, 6.14270281791687, 6.9753241539001465, 7.8014609813690186, 8.625631332397461, 9.431203842163086, 10.263765335083008, 11.103111267089844, 11.930850267410278, 12.75999402999878, 13.579971551895142, 14.4181649684906, 15.236797094345093, 16.06699848175049, 16.88840079307556, 17.719937801361084, 19.632798433303833, 21.44254755973816, 23.36624240875244, 25.22166395187378, 27.152584314346313, 29.05855107307434, 30.97466278076172, 32.8855767250061, 34.820438623428345, 36.75136923789978, 38.537020444869995, 40.50153684616089, 42.33637523651123, 44.24725317955017, 46.16239786148071, 48.00818204879761, 49.95872735977173, 51.77813005447388, 53.72300410270691, 55.610607862472534, 57.47560167312622, 59.3235821723938, 61.219626903533936, 63.04344344139099, 64.95638489723206, 66.83257007598877, 68.68897438049316, 70.59840369224548, 72.38077735900879, 74.37617945671082, 76.19941329956055, 78.0932686328888, 79.98579168319702, 81.89171814918518, 83.76615309715271, 85.57448172569275, 87.46155071258545, 89.22709488868713, 91.11547708511353, 92.94972276687622, 94.81458902359009, 96.70942521095276, 98.6337411403656, 100.50533390045166, 102.40114545822144, 104.25589108467102, 106.03448963165283, 107.94136238098145, 109.732590675354, 111.66069912910461, 113.54257607460022, 115.3983166217804, 117.35465216636658, 119.22099161148071, 121.09619116783142, 122.9400007724762, 124.84530472755432, 126.74320697784424, 128.70084977149963, 130.616366147995, 132.59183979034424, 134.62357473373413, 136.58235144615173, 138.59627151489258, 140.55601930618286, 142.58625054359436, 144.545725107193, 146.5457444190979, 148.59613919258118, 150.58671474456787, 152.52642178535461, 154.51676726341248, 156.51028442382812, 158.4447886943817, 160.47764658927917, 162.4352991580963, 164.44967365264893, 166.34121704101562, 168.36954522132874, 169.71967220306396]
[15.0, 24.816666666666666, 38.266666666666666, 48.15, 51.18333333333333, 55.88333333333333, 60.85, 65.21666666666667, 64.61666666666666, 65.01666666666667, 67.36666666666666, 66.43333333333334, 69.1, 71.33333333333333, 72.3, 72.81666666666666, 73.35, 74.26666666666667, 73.75, 74.25, 74.13333333333334, 74.25, 75.45, 75.08333333333333, 74.95, 74.51666666666667, 74.33333333333333, 74.31666666666666, 74.58333333333333, 75.2, 75.13333333333334, 75.6, 76.05, 76.86666666666666, 77.35, 77.81666666666666, 77.41666666666667, 77.38333333333334, 77.63333333333334, 77.43333333333334, 77.83333333333333, 78.15, 78.06666666666666, 78.53333333333333, 78.08333333333333, 78.26666666666667, 78.28333333333333, 78.93333333333334, 79.28333333333333, 79.21666666666667, 79.56666666666666, 79.36666666666666, 78.91666666666667, 79.76666666666667, 79.88333333333334, 79.9, 79.61666666666666, 79.56666666666666, 79.3, 79.0, 79.16666666666667, 79.56666666666666, 79.56666666666666, 79.78333333333333, 80.36666666666666, 80.21666666666667, 80.66666666666667, 80.46666666666667, 80.41666666666667, 79.51666666666667, 80.13333333333334, 80.58333333333333, 80.45, 80.35, 80.35, 80.08333333333333, 80.61666666666666, 80.71666666666667, 80.91666666666667, 80.63333333333334, 80.83333333333333, 81.06666666666666, 80.88333333333334, 80.4, 81.23333333333333, 81.06666666666666, 81.13333333333334, 80.58333333333333, 80.96666666666667, 80.88333333333334, 80.68333333333334, 81.46666666666667, 81.1, 80.65, 80.55, 80.83333333333333, 80.6, 80.3, 80.58333333333333, 80.55, 81.86666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.252, Test loss: 1.986, Test accuracy: 20.77
Round   0, Global train loss: 1.252, Global test loss: 2.308, Global test accuracy: 13.25
Round   1, Train loss: 1.135, Test loss: 1.758, Test accuracy: 32.27
Round   1, Global train loss: 1.135, Global test loss: 2.310, Global test accuracy: 18.63
Round   2, Train loss: 1.001, Test loss: 1.452, Test accuracy: 36.82
Round   2, Global train loss: 1.001, Global test loss: 2.225, Global test accuracy: 20.88
Round   3, Train loss: 0.998, Test loss: 1.271, Test accuracy: 41.75
Round   3, Global train loss: 0.998, Global test loss: 2.227, Global test accuracy: 17.37
Round   4, Train loss: 1.000, Test loss: 1.133, Test accuracy: 50.53
Round   4, Global train loss: 1.000, Global test loss: 2.206, Global test accuracy: 25.13
Round   5, Train loss: 0.936, Test loss: 1.188, Test accuracy: 50.27
Round   5, Global train loss: 0.936, Global test loss: 2.321, Global test accuracy: 23.20
Round   6, Train loss: 1.008, Test loss: 1.170, Test accuracy: 52.42
Round   6, Global train loss: 1.008, Global test loss: 2.291, Global test accuracy: 17.17
Round   7, Train loss: 0.997, Test loss: 1.028, Test accuracy: 55.50
Round   7, Global train loss: 0.997, Global test loss: 2.156, Global test accuracy: 16.87
Round   8, Train loss: 1.067, Test loss: 1.039, Test accuracy: 57.08
Round   8, Global train loss: 1.067, Global test loss: 2.544, Global test accuracy: 16.72
Round   9, Train loss: 0.957, Test loss: 0.906, Test accuracy: 61.10
Round   9, Global train loss: 0.957, Global test loss: 2.117, Global test accuracy: 30.32
Round  10, Train loss: 0.944, Test loss: 0.928, Test accuracy: 58.63
Round  10, Global train loss: 0.944, Global test loss: 2.126, Global test accuracy: 16.90
Round  11, Train loss: 0.893, Test loss: 0.914, Test accuracy: 60.62
Round  11, Global train loss: 0.893, Global test loss: 2.331, Global test accuracy: 19.52
Round  12, Train loss: 0.837, Test loss: 0.910, Test accuracy: 61.30
Round  12, Global train loss: 0.837, Global test loss: 2.105, Global test accuracy: 23.10
Round  13, Train loss: 0.852, Test loss: 0.816, Test accuracy: 64.50
Round  13, Global train loss: 0.852, Global test loss: 2.171, Global test accuracy: 22.27
Round  14, Train loss: 0.890, Test loss: 0.817, Test accuracy: 64.77
Round  14, Global train loss: 0.890, Global test loss: 2.253, Global test accuracy: 25.60
Round  15, Train loss: 0.803, Test loss: 0.806, Test accuracy: 65.72
Round  15, Global train loss: 0.803, Global test loss: 2.148, Global test accuracy: 21.28
Round  16, Train loss: 0.831, Test loss: 0.800, Test accuracy: 65.75
Round  16, Global train loss: 0.831, Global test loss: 2.135, Global test accuracy: 25.45
Round  17, Train loss: 0.888, Test loss: 0.813, Test accuracy: 65.22
Round  17, Global train loss: 0.888, Global test loss: 2.154, Global test accuracy: 21.35
Round  18, Train loss: 0.908, Test loss: 0.800, Test accuracy: 66.22
Round  18, Global train loss: 0.908, Global test loss: 2.123, Global test accuracy: 23.23
Round  19, Train loss: 0.793, Test loss: 0.796, Test accuracy: 66.68
Round  19, Global train loss: 0.793, Global test loss: 2.280, Global test accuracy: 19.82
Round  20, Train loss: 0.680, Test loss: 0.771, Test accuracy: 68.10
Round  20, Global train loss: 0.680, Global test loss: 2.231, Global test accuracy: 24.40
Round  21, Train loss: 0.788, Test loss: 0.779, Test accuracy: 67.23
Round  21, Global train loss: 0.788, Global test loss: 2.092, Global test accuracy: 31.13
Round  22, Train loss: 0.724, Test loss: 0.779, Test accuracy: 67.32
Round  22, Global train loss: 0.724, Global test loss: 2.462, Global test accuracy: 16.67
Round  23, Train loss: 0.740, Test loss: 0.785, Test accuracy: 66.85
Round  23, Global train loss: 0.740, Global test loss: 1.998, Global test accuracy: 30.52
Round  24, Train loss: 0.748, Test loss: 0.783, Test accuracy: 66.97
Round  24, Global train loss: 0.748, Global test loss: 2.138, Global test accuracy: 23.08
Round  25, Train loss: 0.810, Test loss: 0.796, Test accuracy: 67.27
Round  25, Global train loss: 0.810, Global test loss: 2.507, Global test accuracy: 16.67
Round  26, Train loss: 0.710, Test loss: 0.805, Test accuracy: 66.68
Round  26, Global train loss: 0.710, Global test loss: 2.143, Global test accuracy: 28.67
Round  27, Train loss: 0.665, Test loss: 0.768, Test accuracy: 67.52
Round  27, Global train loss: 0.665, Global test loss: 2.099, Global test accuracy: 22.37
Round  28, Train loss: 0.662, Test loss: 0.774, Test accuracy: 67.50
Round  28, Global train loss: 0.662, Global test loss: 2.082, Global test accuracy: 29.67
Round  29, Train loss: 0.599, Test loss: 0.778, Test accuracy: 67.60
Round  29, Global train loss: 0.599, Global test loss: 2.013, Global test accuracy: 34.37
Round  30, Train loss: 0.657, Test loss: 0.777, Test accuracy: 68.17
Round  30, Global train loss: 0.657, Global test loss: 2.177, Global test accuracy: 16.57
Round  31, Train loss: 0.627, Test loss: 0.790, Test accuracy: 68.32
Round  31, Global train loss: 0.627, Global test loss: 2.088, Global test accuracy: 21.02
Round  32, Train loss: 0.753, Test loss: 0.797, Test accuracy: 67.70
Round  32, Global train loss: 0.753, Global test loss: 2.108, Global test accuracy: 20.62
Round  33, Train loss: 0.727, Test loss: 0.798, Test accuracy: 67.97
Round  33, Global train loss: 0.727, Global test loss: 2.197, Global test accuracy: 24.30
Round  34, Train loss: 0.524, Test loss: 0.790, Test accuracy: 68.00
Round  34, Global train loss: 0.524, Global test loss: 2.015, Global test accuracy: 32.08
Round  35, Train loss: 0.652, Test loss: 0.792, Test accuracy: 68.13
Round  35, Global train loss: 0.652, Global test loss: 2.139, Global test accuracy: 23.87
Round  36, Train loss: 0.587, Test loss: 0.791, Test accuracy: 68.50
Round  36, Global train loss: 0.587, Global test loss: 2.173, Global test accuracy: 14.53
Round  37, Train loss: 0.588, Test loss: 0.793, Test accuracy: 68.48
Round  37, Global train loss: 0.588, Global test loss: 2.245, Global test accuracy: 21.33
Round  38, Train loss: 0.552, Test loss: 0.800, Test accuracy: 68.13
Round  38, Global train loss: 0.552, Global test loss: 2.102, Global test accuracy: 26.82
Round  39, Train loss: 0.500, Test loss: 0.786, Test accuracy: 68.65
Round  39, Global train loss: 0.500, Global test loss: 2.081, Global test accuracy: 23.97
Round  40, Train loss: 0.509, Test loss: 0.795, Test accuracy: 68.27
Round  40, Global train loss: 0.509, Global test loss: 2.220, Global test accuracy: 21.90
Round  41, Train loss: 0.664, Test loss: 0.798, Test accuracy: 68.63
Round  41, Global train loss: 0.664, Global test loss: 2.161, Global test accuracy: 24.18
Round  42, Train loss: 0.521, Test loss: 0.824, Test accuracy: 68.08
Round  42, Global train loss: 0.521, Global test loss: 2.206, Global test accuracy: 24.57
Round  43, Train loss: 0.613, Test loss: 0.814, Test accuracy: 68.22
Round  43, Global train loss: 0.613, Global test loss: 2.159, Global test accuracy: 15.67
Round  44, Train loss: 0.578, Test loss: 0.829, Test accuracy: 67.67
Round  44, Global train loss: 0.578, Global test loss: 2.203, Global test accuracy: 26.37
Round  45, Train loss: 0.473, Test loss: 0.852, Test accuracy: 67.43
Round  45, Global train loss: 0.473, Global test loss: 2.195, Global test accuracy: 25.55
Round  46, Train loss: 0.467, Test loss: 0.868, Test accuracy: 67.10
Round  46, Global train loss: 0.467, Global test loss: 2.082, Global test accuracy: 19.42
Round  47, Train loss: 0.601, Test loss: 0.890, Test accuracy: 67.48
Round  47, Global train loss: 0.601, Global test loss: 2.379, Global test accuracy: 15.65
Round  48, Train loss: 0.459, Test loss: 0.883, Test accuracy: 68.35
Round  48, Global train loss: 0.459, Global test loss: 2.230, Global test accuracy: 17.80
Round  49, Train loss: 0.450, Test loss: 0.914, Test accuracy: 68.63
Round  49, Global train loss: 0.450, Global test loss: 2.059, Global test accuracy: 25.25
Round  50, Train loss: 0.548, Test loss: 0.937, Test accuracy: 68.10
Round  50, Global train loss: 0.548, Global test loss: 2.132, Global test accuracy: 22.13
Round  51, Train loss: 0.467, Test loss: 0.926, Test accuracy: 68.10
Round  51, Global train loss: 0.467, Global test loss: 2.065, Global test accuracy: 21.18
Round  52, Train loss: 0.427, Test loss: 0.942, Test accuracy: 67.55
Round  52, Global train loss: 0.427, Global test loss: 2.176, Global test accuracy: 21.83
Round  53, Train loss: 0.450, Test loss: 0.947, Test accuracy: 67.40
Round  53, Global train loss: 0.450, Global test loss: 1.994, Global test accuracy: 37.25
Round  54, Train loss: 0.436, Test loss: 0.950, Test accuracy: 67.72
Round  54, Global train loss: 0.436, Global test loss: 2.050, Global test accuracy: 31.40
Round  55, Train loss: 0.443, Test loss: 0.992, Test accuracy: 66.98
Round  55, Global train loss: 0.443, Global test loss: 2.195, Global test accuracy: 21.03
Round  56, Train loss: 0.369, Test loss: 1.014, Test accuracy: 66.60
Round  56, Global train loss: 0.369, Global test loss: 2.151, Global test accuracy: 24.72
Round  57, Train loss: 0.397, Test loss: 0.996, Test accuracy: 66.85
Round  57, Global train loss: 0.397, Global test loss: 2.114, Global test accuracy: 22.32
Round  58, Train loss: 0.291, Test loss: 0.994, Test accuracy: 67.02
Round  58, Global train loss: 0.291, Global test loss: 2.025, Global test accuracy: 27.25
Round  59, Train loss: 0.434, Test loss: 0.990, Test accuracy: 67.18
Round  59, Global train loss: 0.434, Global test loss: 2.122, Global test accuracy: 22.03
Round  60, Train loss: 0.378, Test loss: 1.007, Test accuracy: 67.03
Round  60, Global train loss: 0.378, Global test loss: 2.075, Global test accuracy: 27.82
Round  61, Train loss: 0.274, Test loss: 1.019, Test accuracy: 66.75
Round  61, Global train loss: 0.274, Global test loss: 2.162, Global test accuracy: 22.32
Round  62, Train loss: 0.332, Test loss: 1.028, Test accuracy: 66.62
Round  62, Global train loss: 0.332, Global test loss: 2.029, Global test accuracy: 26.00
Round  63, Train loss: 0.387, Test loss: 1.065, Test accuracy: 66.30
Round  63, Global train loss: 0.387, Global test loss: 2.225, Global test accuracy: 25.17
Round  64, Train loss: 0.371, Test loss: 1.046, Test accuracy: 67.18
Round  64, Global train loss: 0.371, Global test loss: 2.104, Global test accuracy: 29.32
Round  65, Train loss: 0.217, Test loss: 1.026, Test accuracy: 67.63
Round  65, Global train loss: 0.217, Global test loss: 2.087, Global test accuracy: 28.03
Round  66, Train loss: 0.354, Test loss: 1.065, Test accuracy: 67.05
Round  66, Global train loss: 0.354, Global test loss: 2.108, Global test accuracy: 24.15
Round  67, Train loss: 0.267, Test loss: 1.103, Test accuracy: 67.25
Round  67, Global train loss: 0.267, Global test loss: 2.326, Global test accuracy: 17.00
Round  68, Train loss: 0.310, Test loss: 1.142, Test accuracy: 66.97
Round  68, Global train loss: 0.310, Global test loss: 2.065, Global test accuracy: 22.78
Round  69, Train loss: 0.320, Test loss: 1.167, Test accuracy: 66.73
Round  69, Global train loss: 0.320, Global test loss: 2.115, Global test accuracy: 19.55
Round  70, Train loss: 0.263, Test loss: 1.158, Test accuracy: 66.93
Round  70, Global train loss: 0.263, Global test loss: 2.097, Global test accuracy: 24.03
Round  71, Train loss: 0.250, Test loss: 1.165, Test accuracy: 67.23
Round  71, Global train loss: 0.250, Global test loss: 2.214, Global test accuracy: 24.67
Round  72, Train loss: 0.254, Test loss: 1.163, Test accuracy: 67.28
Round  72, Global train loss: 0.254, Global test loss: 2.022, Global test accuracy: 31.98
Round  73, Train loss: 0.243, Test loss: 1.171, Test accuracy: 67.28
Round  73, Global train loss: 0.243, Global test loss: 2.073, Global test accuracy: 28.65
Round  74, Train loss: 0.274, Test loss: 1.184, Test accuracy: 66.70
Round  74, Global train loss: 0.274, Global test loss: 2.159, Global test accuracy: 19.43
Round  75, Train loss: 0.233, Test loss: 1.222, Test accuracy: 66.53
Round  75, Global train loss: 0.233, Global test loss: 2.000, Global test accuracy: 30.82
Round  76, Train loss: 0.265, Test loss: 1.228, Test accuracy: 66.62
Round  76, Global train loss: 0.265, Global test loss: 2.176, Global test accuracy: 22.17
Round  77, Train loss: 0.254, Test loss: 1.268, Test accuracy: 66.18
Round  77, Global train loss: 0.254, Global test loss: 2.224, Global test accuracy: 16.65
Round  78, Train loss: 0.220, Test loss: 1.290, Test accuracy: 65.83
Round  78, Global train loss: 0.220, Global test loss: 2.167, Global test accuracy: 26.97
Round  79, Train loss: 0.235, Test loss: 1.316, Test accuracy: 65.68
Round  79, Global train loss: 0.235, Global test loss: 2.181, Global test accuracy: 14.43
Round  80, Train loss: 0.192, Test loss: 1.311, Test accuracy: 66.30
Round  80, Global train loss: 0.192, Global test loss: 2.019, Global test accuracy: 32.12
Round  81, Train loss: 0.203, Test loss: 1.293, Test accuracy: 66.43
Round  81, Global train loss: 0.203, Global test loss: 2.126, Global test accuracy: 20.62
Round  82, Train loss: 0.167, Test loss: 1.302, Test accuracy: 66.53
Round  82, Global train loss: 0.167, Global test loss: 2.001, Global test accuracy: 28.55
Round  83, Train loss: 0.214, Test loss: 1.331, Test accuracy: 66.48
Round  83, Global train loss: 0.214, Global test loss: 2.137, Global test accuracy: 19.88
Round  84, Train loss: 0.168, Test loss: 1.320, Test accuracy: 66.75
Round  84, Global train loss: 0.168, Global test loss: 2.042, Global test accuracy: 28.37
Round  85, Train loss: 0.177, Test loss: 1.369, Test accuracy: 66.68
Round  85, Global train loss: 0.177, Global test loss: 2.054, Global test accuracy: 23.12
Round  86, Train loss: 0.200, Test loss: 1.341, Test accuracy: 66.32
Round  86, Global train loss: 0.200, Global test loss: 2.117, Global test accuracy: 25.87
Round  87, Train loss: 0.153, Test loss: 1.384, Test accuracy: 66.30
Round  87, Global train loss: 0.153, Global test loss: 2.205, Global test accuracy: 20.80
Round  88, Train loss: 0.226, Test loss: 1.392, Test accuracy: 67.02
Round  88, Global train loss: 0.226, Global test loss: 2.319, Global test accuracy: 16.67
Round  89, Train loss: 0.121, Test loss: 1.414, Test accuracy: 66.55
Round  89, Global train loss: 0.121, Global test loss: 2.051, Global test accuracy: 23.63
Round  90, Train loss: 0.174, Test loss: 1.442, Test accuracy: 65.93
Round  90, Global train loss: 0.174, Global test loss: 2.092, Global test accuracy: 21.07
Round  91, Train loss: 0.120, Test loss: 1.441, Test accuracy: 66.12
Round  91, Global train loss: 0.120, Global test loss: 2.028, Global test accuracy: 26.45
Round  92, Train loss: 0.199, Test loss: 1.444, Test accuracy: 66.28
Round  92, Global train loss: 0.199, Global test loss: 2.115, Global test accuracy: 29.38
Round  93, Train loss: 0.128, Test loss: 1.458, Test accuracy: 66.38
Round  93, Global train loss: 0.128, Global test loss: 2.125, Global test accuracy: 25.05
Round  94, Train loss: 0.207, Test loss: 1.488, Test accuracy: 65.92
Round  94, Global train loss: 0.207, Global test loss: 2.138, Global test accuracy: 17.13
Round  95, Train loss: 0.185, Test loss: 1.524, Test accuracy: 66.47
Round  95, Global train loss: 0.185, Global test loss: 2.168, Global test accuracy: 27.13
Round  96, Train loss: 0.144, Test loss: 1.533, Test accuracy: 66.60
Round  96, Global train loss: 0.144, Global test loss: 2.097, Global test accuracy: 20.80
Round  97, Train loss: 0.154, Test loss: 1.545, Test accuracy: 65.83
Round  97, Global train loss: 0.154, Global test loss: 2.155, Global test accuracy: 25.87
Round  98, Train loss: 0.174, Test loss: 1.567, Test accuracy: 65.73
Round  98, Global train loss: 0.174, Global test loss: 2.457, Global test accuracy: 16.75
Round  99, Train loss: 0.154, Test loss: 1.555, Test accuracy: 65.65
Round  99, Global train loss: 0.154, Global test loss: 2.133, Global test accuracy: 24.32
Final Round, Train loss: 0.124, Test loss: 1.642, Test accuracy: 66.05
Final Round, Global train loss: 0.124, Global test loss: 2.133, Global test accuracy: 24.32
Average accuracy final 10 rounds: 66.09166666666667 

Average global accuracy final 10 rounds: 23.395000000000003 

997.7825603485107
[1.0173888206481934, 2.0347776412963867, 2.7507741451263428, 3.466770648956299, 4.1824352741241455, 4.898099899291992, 5.598973751068115, 6.299847602844238, 7.010490655899048, 7.721133708953857, 8.431907415390015, 9.142681121826172, 9.838048458099365, 10.533415794372559, 11.242408990859985, 11.951402187347412, 12.661422491073608, 13.371442794799805, 14.069298028945923, 14.767153263092041, 15.485174894332886, 16.20319652557373, 16.91914463043213, 17.635092735290527, 18.33777689933777, 19.04046106338501, 19.750001668930054, 20.459542274475098, 21.172277212142944, 21.88501214981079, 22.589929580688477, 23.294847011566162, 23.997816801071167, 24.700786590576172, 25.403475522994995, 26.10616445541382, 26.80806255340576, 27.509960651397705, 28.215222358703613, 28.92048406600952, 29.624655723571777, 30.328827381134033, 31.027705669403076, 31.72658395767212, 32.43739080429077, 33.148197650909424, 33.86289882659912, 34.57760000228882, 35.272661209106445, 35.96772241592407, 36.677528858184814, 37.38733530044556, 38.09178948402405, 38.79624366760254, 39.49152183532715, 40.18680000305176, 40.89400339126587, 41.60120677947998, 42.30280542373657, 43.004404067993164, 43.69968056678772, 44.394957065582275, 45.08656597137451, 45.77817487716675, 46.4853515625, 47.19252824783325, 47.88597106933594, 48.57941389083862, 49.28719401359558, 49.99497413635254, 50.69287848472595, 51.390782833099365, 52.087002992630005, 52.783223152160645, 53.48970127105713, 54.19617938995361, 54.893523931503296, 55.59086847305298, 56.290337562561035, 56.98980665206909, 57.69647407531738, 58.403141498565674, 59.105754375457764, 59.80836725234985, 60.508389711380005, 61.208412170410156, 61.921201944351196, 62.633991718292236, 63.34373378753662, 64.053475856781, 64.75605583190918, 65.45863580703735, 66.16665291786194, 66.87467002868652, 67.57645988464355, 68.27824974060059, 68.97801303863525, 69.67777633666992, 70.38106083869934, 71.08434534072876, 71.78156447410583, 72.47878360748291, 73.1754937171936, 73.8722038269043, 74.57070970535278, 75.26921558380127, 75.97697854042053, 76.6847414970398, 77.41120314598083, 78.13766479492188, 78.8364953994751, 79.53532600402832, 80.23918628692627, 80.94304656982422, 81.64308738708496, 82.3431282043457, 83.04165768623352, 83.74018716812134, 84.43457412719727, 85.1289610862732, 85.83608651161194, 86.54321193695068, 87.25195169448853, 87.96069145202637, 88.67660212516785, 89.39251279830933, 90.0984525680542, 90.80439233779907, 91.5072033405304, 92.21001434326172, 92.92052483558655, 93.63103532791138, 94.339519739151, 95.04800415039062, 95.75449681282043, 96.46098947525024, 97.16694283485413, 97.87289619445801, 98.57794380187988, 99.28299140930176, 99.98516583442688, 100.687340259552, 101.38519096374512, 102.08304166793823, 102.78611755371094, 103.48919343948364, 104.18632388114929, 104.88345432281494, 105.58406472206116, 106.28467512130737, 106.9816586971283, 107.67864227294922, 108.37256073951721, 109.0664792060852, 109.76215958595276, 110.45783996582031, 111.15598154067993, 111.85412311553955, 112.5570695400238, 113.26001596450806, 113.97307682037354, 114.68613767623901, 115.39305353164673, 116.09996938705444, 116.81055045127869, 117.52113151550293, 118.23642587661743, 118.95172023773193, 119.65630435943604, 120.36088848114014, 121.09389185905457, 121.826895236969, 122.57012796401978, 123.31336069107056, 124.01929020881653, 124.7252197265625, 125.42833948135376, 126.13145923614502, 126.8607907295227, 127.59012222290039, 128.29911422729492, 129.00810623168945, 129.7184247970581, 130.42874336242676, 131.13989305496216, 131.85104274749756, 132.5582480430603, 133.26545333862305, 133.98808932304382, 134.7107253074646, 135.4143407344818, 136.11795616149902, 136.82073497772217, 137.5235137939453, 138.23323464393616, 138.942955493927, 139.64339685440063, 140.34383821487427, 141.0434501171112, 141.74306201934814, 143.25021696090698, 144.75737190246582]
[20.766666666666666, 20.766666666666666, 32.266666666666666, 32.266666666666666, 36.81666666666667, 36.81666666666667, 41.75, 41.75, 50.53333333333333, 50.53333333333333, 50.266666666666666, 50.266666666666666, 52.416666666666664, 52.416666666666664, 55.5, 55.5, 57.083333333333336, 57.083333333333336, 61.1, 61.1, 58.63333333333333, 58.63333333333333, 60.61666666666667, 60.61666666666667, 61.3, 61.3, 64.5, 64.5, 64.76666666666667, 64.76666666666667, 65.71666666666667, 65.71666666666667, 65.75, 65.75, 65.21666666666667, 65.21666666666667, 66.21666666666667, 66.21666666666667, 66.68333333333334, 66.68333333333334, 68.1, 68.1, 67.23333333333333, 67.23333333333333, 67.31666666666666, 67.31666666666666, 66.85, 66.85, 66.96666666666667, 66.96666666666667, 67.26666666666667, 67.26666666666667, 66.68333333333334, 66.68333333333334, 67.51666666666667, 67.51666666666667, 67.5, 67.5, 67.6, 67.6, 68.16666666666667, 68.16666666666667, 68.31666666666666, 68.31666666666666, 67.7, 67.7, 67.96666666666667, 67.96666666666667, 68.0, 68.0, 68.13333333333334, 68.13333333333334, 68.5, 68.5, 68.48333333333333, 68.48333333333333, 68.13333333333334, 68.13333333333334, 68.65, 68.65, 68.26666666666667, 68.26666666666667, 68.63333333333334, 68.63333333333334, 68.08333333333333, 68.08333333333333, 68.21666666666667, 68.21666666666667, 67.66666666666667, 67.66666666666667, 67.43333333333334, 67.43333333333334, 67.1, 67.1, 67.48333333333333, 67.48333333333333, 68.35, 68.35, 68.63333333333334, 68.63333333333334, 68.1, 68.1, 68.1, 68.1, 67.55, 67.55, 67.4, 67.4, 67.71666666666667, 67.71666666666667, 66.98333333333333, 66.98333333333333, 66.6, 66.6, 66.85, 66.85, 67.01666666666667, 67.01666666666667, 67.18333333333334, 67.18333333333334, 67.03333333333333, 67.03333333333333, 66.75, 66.75, 66.61666666666666, 66.61666666666666, 66.3, 66.3, 67.18333333333334, 67.18333333333334, 67.63333333333334, 67.63333333333334, 67.05, 67.05, 67.25, 67.25, 66.96666666666667, 66.96666666666667, 66.73333333333333, 66.73333333333333, 66.93333333333334, 66.93333333333334, 67.23333333333333, 67.23333333333333, 67.28333333333333, 67.28333333333333, 67.28333333333333, 67.28333333333333, 66.7, 66.7, 66.53333333333333, 66.53333333333333, 66.61666666666666, 66.61666666666666, 66.18333333333334, 66.18333333333334, 65.83333333333333, 65.83333333333333, 65.68333333333334, 65.68333333333334, 66.3, 66.3, 66.43333333333334, 66.43333333333334, 66.53333333333333, 66.53333333333333, 66.48333333333333, 66.48333333333333, 66.75, 66.75, 66.68333333333334, 66.68333333333334, 66.31666666666666, 66.31666666666666, 66.3, 66.3, 67.01666666666667, 67.01666666666667, 66.55, 66.55, 65.93333333333334, 65.93333333333334, 66.11666666666666, 66.11666666666666, 66.28333333333333, 66.28333333333333, 66.38333333333334, 66.38333333333334, 65.91666666666667, 65.91666666666667, 66.46666666666667, 66.46666666666667, 66.6, 66.6, 65.83333333333333, 65.83333333333333, 65.73333333333333, 65.73333333333333, 65.65, 65.65, 66.05, 66.05]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.297, Test loss: 2.031, Test accuracy: 26.38
Round   0, Global train loss: 1.297, Global test loss: 2.349, Global test accuracy: 19.00
Round   1, Train loss: 1.132, Test loss: 1.724, Test accuracy: 38.42
Round   1, Global train loss: 1.132, Global test loss: 2.285, Global test accuracy: 27.43
Round   2, Train loss: 1.012, Test loss: 1.412, Test accuracy: 40.43
Round   2, Global train loss: 1.012, Global test loss: 2.208, Global test accuracy: 21.18
Round   3, Train loss: 0.926, Test loss: 1.165, Test accuracy: 49.32
Round   3, Global train loss: 0.926, Global test loss: 2.065, Global test accuracy: 27.60
Round   4, Train loss: 0.971, Test loss: 1.019, Test accuracy: 56.78
Round   4, Global train loss: 0.971, Global test loss: 1.983, Global test accuracy: 33.02
Round   5, Train loss: 0.853, Test loss: 1.066, Test accuracy: 54.13
Round   5, Global train loss: 0.853, Global test loss: 2.094, Global test accuracy: 26.82
Round   6, Train loss: 0.942, Test loss: 1.002, Test accuracy: 59.25
Round   6, Global train loss: 0.942, Global test loss: 1.891, Global test accuracy: 32.75
Round   7, Train loss: 0.911, Test loss: 0.901, Test accuracy: 62.25
Round   7, Global train loss: 0.911, Global test loss: 1.991, Global test accuracy: 24.90
Round   8, Train loss: 0.953, Test loss: 0.900, Test accuracy: 63.12
Round   8, Global train loss: 0.953, Global test loss: 2.292, Global test accuracy: 20.45
Round   9, Train loss: 0.861, Test loss: 0.768, Test accuracy: 67.28
Round   9, Global train loss: 0.861, Global test loss: 1.767, Global test accuracy: 38.92
Round  10, Train loss: 0.871, Test loss: 0.792, Test accuracy: 67.65
Round  10, Global train loss: 0.871, Global test loss: 1.756, Global test accuracy: 38.58
Round  11, Train loss: 0.804, Test loss: 0.776, Test accuracy: 67.68
Round  11, Global train loss: 0.804, Global test loss: 1.844, Global test accuracy: 38.10
Round  12, Train loss: 0.811, Test loss: 0.798, Test accuracy: 67.02
Round  12, Global train loss: 0.811, Global test loss: 1.695, Global test accuracy: 42.85
Round  13, Train loss: 0.785, Test loss: 0.743, Test accuracy: 69.00
Round  13, Global train loss: 0.785, Global test loss: 1.851, Global test accuracy: 35.38
Round  14, Train loss: 0.875, Test loss: 0.726, Test accuracy: 69.33
Round  14, Global train loss: 0.875, Global test loss: 1.973, Global test accuracy: 37.52
Round  15, Train loss: 0.679, Test loss: 0.719, Test accuracy: 69.45
Round  15, Global train loss: 0.679, Global test loss: 1.739, Global test accuracy: 41.67
Round  16, Train loss: 0.742, Test loss: 0.713, Test accuracy: 69.72
Round  16, Global train loss: 0.742, Global test loss: 1.851, Global test accuracy: 38.68
Round  17, Train loss: 0.820, Test loss: 0.700, Test accuracy: 70.23
Round  17, Global train loss: 0.820, Global test loss: 1.653, Global test accuracy: 41.35
Round  18, Train loss: 0.825, Test loss: 0.698, Test accuracy: 70.27
Round  18, Global train loss: 0.825, Global test loss: 1.501, Global test accuracy: 48.98
Round  19, Train loss: 0.676, Test loss: 0.685, Test accuracy: 71.00
Round  19, Global train loss: 0.676, Global test loss: 1.675, Global test accuracy: 42.40
Round  20, Train loss: 0.689, Test loss: 0.689, Test accuracy: 71.47
Round  20, Global train loss: 0.689, Global test loss: 2.004, Global test accuracy: 34.18
Round  21, Train loss: 0.784, Test loss: 0.679, Test accuracy: 72.15
Round  21, Global train loss: 0.784, Global test loss: 1.729, Global test accuracy: 42.05
Round  22, Train loss: 0.702, Test loss: 0.674, Test accuracy: 72.35
Round  22, Global train loss: 0.702, Global test loss: 1.889, Global test accuracy: 31.73
Round  23, Train loss: 0.661, Test loss: 0.680, Test accuracy: 72.27
Round  23, Global train loss: 0.661, Global test loss: 1.521, Global test accuracy: 47.22
Round  24, Train loss: 0.735, Test loss: 0.683, Test accuracy: 72.18
Round  24, Global train loss: 0.735, Global test loss: 1.630, Global test accuracy: 44.85
Round  25, Train loss: 0.735, Test loss: 0.674, Test accuracy: 72.87
Round  25, Global train loss: 0.735, Global test loss: 2.057, Global test accuracy: 28.70
Round  26, Train loss: 0.638, Test loss: 0.672, Test accuracy: 72.70
Round  26, Global train loss: 0.638, Global test loss: 1.807, Global test accuracy: 42.50
Round  27, Train loss: 0.616, Test loss: 0.665, Test accuracy: 73.00
Round  27, Global train loss: 0.616, Global test loss: 1.637, Global test accuracy: 44.15
Round  28, Train loss: 0.678, Test loss: 0.653, Test accuracy: 73.43
Round  28, Global train loss: 0.678, Global test loss: 1.739, Global test accuracy: 42.72
Round  29, Train loss: 0.535, Test loss: 0.667, Test accuracy: 73.00
Round  29, Global train loss: 0.535, Global test loss: 1.596, Global test accuracy: 46.60
Round  30, Train loss: 0.653, Test loss: 0.655, Test accuracy: 73.90
Round  30, Global train loss: 0.653, Global test loss: 1.429, Global test accuracy: 48.17
Round  31, Train loss: 0.589, Test loss: 0.645, Test accuracy: 74.13
Round  31, Global train loss: 0.589, Global test loss: 1.410, Global test accuracy: 51.35
Round  32, Train loss: 0.623, Test loss: 0.640, Test accuracy: 74.27
Round  32, Global train loss: 0.623, Global test loss: 1.510, Global test accuracy: 47.40
Round  33, Train loss: 0.644, Test loss: 0.634, Test accuracy: 74.65
Round  33, Global train loss: 0.644, Global test loss: 1.461, Global test accuracy: 49.60
Round  34, Train loss: 0.509, Test loss: 0.638, Test accuracy: 74.55
Round  34, Global train loss: 0.509, Global test loss: 1.396, Global test accuracy: 54.52
Round  35, Train loss: 0.647, Test loss: 0.645, Test accuracy: 74.57
Round  35, Global train loss: 0.647, Global test loss: 1.412, Global test accuracy: 51.20
Round  36, Train loss: 0.593, Test loss: 0.641, Test accuracy: 74.97
Round  36, Global train loss: 0.593, Global test loss: 1.488, Global test accuracy: 50.10
Round  37, Train loss: 0.549, Test loss: 0.650, Test accuracy: 74.20
Round  37, Global train loss: 0.549, Global test loss: 1.630, Global test accuracy: 44.07
Round  38, Train loss: 0.580, Test loss: 0.663, Test accuracy: 73.88
Round  38, Global train loss: 0.580, Global test loss: 1.399, Global test accuracy: 54.82
Round  39, Train loss: 0.507, Test loss: 0.638, Test accuracy: 74.58
Round  39, Global train loss: 0.507, Global test loss: 1.651, Global test accuracy: 47.12
Round  40, Train loss: 0.479, Test loss: 0.644, Test accuracy: 74.65
Round  40, Global train loss: 0.479, Global test loss: 1.936, Global test accuracy: 44.93
Round  41, Train loss: 0.658, Test loss: 0.662, Test accuracy: 74.75
Round  41, Global train loss: 0.658, Global test loss: 1.540, Global test accuracy: 46.87
Round  42, Train loss: 0.572, Test loss: 0.649, Test accuracy: 75.23
Round  42, Global train loss: 0.572, Global test loss: 1.579, Global test accuracy: 45.67
Round  43, Train loss: 0.578, Test loss: 0.659, Test accuracy: 75.28
Round  43, Global train loss: 0.578, Global test loss: 1.553, Global test accuracy: 48.20
Round  44, Train loss: 0.543, Test loss: 0.631, Test accuracy: 76.40
Round  44, Global train loss: 0.543, Global test loss: 1.501, Global test accuracy: 48.83
Round  45, Train loss: 0.525, Test loss: 0.631, Test accuracy: 76.25
Round  45, Global train loss: 0.525, Global test loss: 1.535, Global test accuracy: 47.40
Round  46, Train loss: 0.526, Test loss: 0.620, Test accuracy: 76.55
Round  46, Global train loss: 0.526, Global test loss: 1.435, Global test accuracy: 50.98
Round  47, Train loss: 0.531, Test loss: 0.637, Test accuracy: 76.33
Round  47, Global train loss: 0.531, Global test loss: 1.631, Global test accuracy: 48.23
Round  48, Train loss: 0.486, Test loss: 0.646, Test accuracy: 75.88
Round  48, Global train loss: 0.486, Global test loss: 1.420, Global test accuracy: 51.60
Round  49, Train loss: 0.513, Test loss: 0.643, Test accuracy: 76.02
Round  49, Global train loss: 0.513, Global test loss: 1.283, Global test accuracy: 55.78
Round  50, Train loss: 0.559, Test loss: 0.647, Test accuracy: 76.17
Round  50, Global train loss: 0.559, Global test loss: 1.417, Global test accuracy: 52.47
Round  51, Train loss: 0.538, Test loss: 0.658, Test accuracy: 75.85
Round  51, Global train loss: 0.538, Global test loss: 1.410, Global test accuracy: 52.62
Round  52, Train loss: 0.493, Test loss: 0.653, Test accuracy: 76.10
Round  52, Global train loss: 0.493, Global test loss: 1.402, Global test accuracy: 51.53
Round  53, Train loss: 0.478, Test loss: 0.625, Test accuracy: 77.40
Round  53, Global train loss: 0.478, Global test loss: 1.379, Global test accuracy: 54.18
Round  54, Train loss: 0.440, Test loss: 0.624, Test accuracy: 77.63
Round  54, Global train loss: 0.440, Global test loss: 1.427, Global test accuracy: 54.13
Round  55, Train loss: 0.456, Test loss: 0.625, Test accuracy: 77.35
Round  55, Global train loss: 0.456, Global test loss: 1.492, Global test accuracy: 51.43
Round  56, Train loss: 0.383, Test loss: 0.628, Test accuracy: 77.48
Round  56, Global train loss: 0.383, Global test loss: 1.522, Global test accuracy: 49.73
Round  57, Train loss: 0.496, Test loss: 0.611, Test accuracy: 78.02
Round  57, Global train loss: 0.496, Global test loss: 1.430, Global test accuracy: 53.00
Round  58, Train loss: 0.376, Test loss: 0.621, Test accuracy: 77.82
Round  58, Global train loss: 0.376, Global test loss: 1.625, Global test accuracy: 48.60
Round  59, Train loss: 0.576, Test loss: 0.624, Test accuracy: 77.90
Round  59, Global train loss: 0.576, Global test loss: 1.497, Global test accuracy: 49.57
Round  60, Train loss: 0.506, Test loss: 0.606, Test accuracy: 78.52
Round  60, Global train loss: 0.506, Global test loss: 1.390, Global test accuracy: 54.50
Round  61, Train loss: 0.406, Test loss: 0.617, Test accuracy: 77.85
Round  61, Global train loss: 0.406, Global test loss: 1.457, Global test accuracy: 53.63
Round  62, Train loss: 0.460, Test loss: 0.635, Test accuracy: 77.48
Round  62, Global train loss: 0.460, Global test loss: 1.282, Global test accuracy: 58.15
Round  63, Train loss: 0.489, Test loss: 0.643, Test accuracy: 77.20
Round  63, Global train loss: 0.489, Global test loss: 1.665, Global test accuracy: 48.17
Round  64, Train loss: 0.470, Test loss: 0.619, Test accuracy: 77.78
Round  64, Global train loss: 0.470, Global test loss: 1.310, Global test accuracy: 58.23
Round  65, Train loss: 0.335, Test loss: 0.628, Test accuracy: 77.72
Round  65, Global train loss: 0.335, Global test loss: 1.492, Global test accuracy: 52.92
Round  66, Train loss: 0.482, Test loss: 0.652, Test accuracy: 77.62
Round  66, Global train loss: 0.482, Global test loss: 1.275, Global test accuracy: 57.85
Round  67, Train loss: 0.390, Test loss: 0.647, Test accuracy: 77.80
Round  67, Global train loss: 0.390, Global test loss: 1.656, Global test accuracy: 47.50
Round  68, Train loss: 0.520, Test loss: 0.666, Test accuracy: 77.08
Round  68, Global train loss: 0.520, Global test loss: 1.263, Global test accuracy: 56.37
Round  69, Train loss: 0.473, Test loss: 0.655, Test accuracy: 77.32
Round  69, Global train loss: 0.473, Global test loss: 1.357, Global test accuracy: 53.07
Round  70, Train loss: 0.372, Test loss: 0.662, Test accuracy: 77.22
Round  70, Global train loss: 0.372, Global test loss: 1.419, Global test accuracy: 55.57
Round  71, Train loss: 0.374, Test loss: 0.655, Test accuracy: 77.18
Round  71, Global train loss: 0.374, Global test loss: 1.439, Global test accuracy: 53.77
Round  72, Train loss: 0.335, Test loss: 0.659, Test accuracy: 77.22
Round  72, Global train loss: 0.335, Global test loss: 1.453, Global test accuracy: 56.80
Round  73, Train loss: 0.392, Test loss: 0.660, Test accuracy: 76.83
Round  73, Global train loss: 0.392, Global test loss: 1.581, Global test accuracy: 52.97
Round  74, Train loss: 0.406, Test loss: 0.650, Test accuracy: 77.60
Round  74, Global train loss: 0.406, Global test loss: 1.318, Global test accuracy: 56.98
Round  75, Train loss: 0.404, Test loss: 0.654, Test accuracy: 77.55
Round  75, Global train loss: 0.404, Global test loss: 1.329, Global test accuracy: 55.73
Round  76, Train loss: 0.427, Test loss: 0.638, Test accuracy: 78.08
Round  76, Global train loss: 0.427, Global test loss: 1.567, Global test accuracy: 51.57
Round  77, Train loss: 0.380, Test loss: 0.634, Test accuracy: 77.78
Round  77, Global train loss: 0.380, Global test loss: 1.605, Global test accuracy: 52.50
Round  78, Train loss: 0.393, Test loss: 0.659, Test accuracy: 77.95
Round  78, Global train loss: 0.393, Global test loss: 1.374, Global test accuracy: 55.95
Round  79, Train loss: 0.428, Test loss: 0.648, Test accuracy: 78.08
Round  79, Global train loss: 0.428, Global test loss: 1.526, Global test accuracy: 53.27
Round  80, Train loss: 0.379, Test loss: 0.658, Test accuracy: 77.88
Round  80, Global train loss: 0.379, Global test loss: 1.461, Global test accuracy: 54.45
Round  81, Train loss: 0.398, Test loss: 0.640, Test accuracy: 78.07
Round  81, Global train loss: 0.398, Global test loss: 1.603, Global test accuracy: 49.67
Round  82, Train loss: 0.329, Test loss: 0.649, Test accuracy: 77.82
Round  82, Global train loss: 0.329, Global test loss: 1.675, Global test accuracy: 51.28
Round  83, Train loss: 0.421, Test loss: 0.649, Test accuracy: 78.18
Round  83, Global train loss: 0.421, Global test loss: 1.388, Global test accuracy: 55.50
Round  84, Train loss: 0.377, Test loss: 0.659, Test accuracy: 78.03
Round  84, Global train loss: 0.377, Global test loss: 1.507, Global test accuracy: 51.82
Round  85, Train loss: 0.385, Test loss: 0.662, Test accuracy: 78.27
Round  85, Global train loss: 0.385, Global test loss: 1.389, Global test accuracy: 56.72
Round  86, Train loss: 0.387, Test loss: 0.654, Test accuracy: 78.07
Round  86, Global train loss: 0.387, Global test loss: 1.680, Global test accuracy: 53.60
Round  87, Train loss: 0.354, Test loss: 0.664, Test accuracy: 77.93
Round  87, Global train loss: 0.354, Global test loss: 1.793, Global test accuracy: 47.70
Round  88, Train loss: 0.443, Test loss: 0.699, Test accuracy: 77.53
Round  88, Global train loss: 0.443, Global test loss: 1.524, Global test accuracy: 50.60
Round  89, Train loss: 0.345, Test loss: 0.678, Test accuracy: 77.95
Round  89, Global train loss: 0.345, Global test loss: 1.435, Global test accuracy: 54.77
Round  90, Train loss: 0.330, Test loss: 0.696, Test accuracy: 77.87
Round  90, Global train loss: 0.330, Global test loss: 1.414, Global test accuracy: 56.88
Round  91, Train loss: 0.272, Test loss: 0.695, Test accuracy: 78.27
Round  91, Global train loss: 0.272, Global test loss: 1.687, Global test accuracy: 53.50
Round  92, Train loss: 0.325, Test loss: 0.711, Test accuracy: 77.88
Round  92, Global train loss: 0.325, Global test loss: 1.499, Global test accuracy: 54.50
Round  93, Train loss: 0.319, Test loss: 0.725, Test accuracy: 77.70
Round  93, Global train loss: 0.319, Global test loss: 1.298, Global test accuracy: 58.58
Round  94, Train loss: 0.385, Test loss: 0.721, Test accuracy: 77.95
Round  94, Global train loss: 0.385, Global test loss: 1.400, Global test accuracy: 55.12
Round  95, Train loss: 0.364, Test loss: 0.680, Test accuracy: 78.30
Round  95, Global train loss: 0.364, Global test loss: 1.524, Global test accuracy: 55.30
Round  96, Train loss: 0.313, Test loss: 0.696, Test accuracy: 78.08
Round  96, Global train loss: 0.313, Global test loss: 1.513, Global test accuracy: 55.37
Round  97, Train loss: 0.329, Test loss: 0.682, Test accuracy: 78.02
Round  97, Global train loss: 0.329, Global test loss: 1.356, Global test accuracy: 56.60
Round  98, Train loss: 0.399, Test loss: 0.684, Test accuracy: 77.70
Round  98, Global train loss: 0.399, Global test loss: 2.023, Global test accuracy: 46.10
Round  99, Train loss: 0.357, Test loss: 0.684, Test accuracy: 77.95
Round  99, Global train loss: 0.357, Global test loss: 1.434, Global test accuracy: 57.28
Final Round, Train loss: 0.254, Test loss: 0.754, Test accuracy: 78.15
Final Round, Global train loss: 0.254, Global test loss: 1.434, Global test accuracy: 57.28
Average accuracy final 10 rounds: 77.97166666666666 

Average global accuracy final 10 rounds: 54.92333333333334 

990.0980546474457
[0.9935097694396973, 1.9870195388793945, 2.756497621536255, 3.5259757041931152, 4.268673896789551, 5.011372089385986, 5.710565090179443, 6.4097580909729, 7.10889196395874, 7.80802583694458, 8.503552675247192, 9.199079513549805, 9.897705554962158, 10.596331596374512, 11.296710729598999, 11.997089862823486, 12.699528932571411, 13.401968002319336, 14.107172727584839, 14.812377452850342, 15.51346230506897, 16.214547157287598, 16.910544633865356, 17.606542110443115, 18.305927515029907, 19.0053129196167, 19.714446306228638, 20.423579692840576, 21.1158230304718, 21.808066368103027, 22.512660026550293, 23.21725368499756, 23.915339946746826, 24.613426208496094, 25.30548930168152, 25.997552394866943, 26.694035291671753, 27.390518188476562, 28.083466053009033, 28.776413917541504, 29.476725339889526, 30.17703676223755, 30.87543749809265, 31.573838233947754, 32.273956537246704, 32.974074840545654, 33.6732702255249, 34.37246561050415, 35.07777810096741, 35.783090591430664, 36.482752561569214, 37.182414531707764, 37.87739419937134, 38.57237386703491, 39.26965093612671, 39.966928005218506, 40.66132950782776, 41.35573101043701, 42.05131411552429, 42.74689722061157, 43.44040894508362, 44.133920669555664, 44.82796311378479, 45.522005558013916, 46.22216844558716, 46.9223313331604, 47.62144923210144, 48.32056713104248, 49.02135372161865, 49.722140312194824, 50.421769857406616, 51.12139940261841, 51.82403302192688, 52.52666664123535, 53.22681212425232, 53.92695760726929, 54.63344931602478, 55.33994102478027, 56.04049730300903, 56.74105358123779, 57.437989234924316, 58.13492488861084, 58.82998466491699, 59.525044441223145, 60.21472215652466, 60.90439987182617, 61.598180294036865, 62.29196071624756, 62.97949409484863, 63.66702747344971, 64.3733263015747, 65.0796251296997, 65.7754373550415, 66.4712495803833, 67.1738076210022, 67.8763656616211, 68.5674102306366, 69.2584547996521, 69.94226121902466, 70.62606763839722, 71.3113341331482, 71.99660062789917, 72.68749642372131, 73.37839221954346, 74.0656201839447, 74.75284814834595, 75.43718695640564, 76.12152576446533, 76.82325315475464, 77.52498054504395, 78.228600025177, 78.93221950531006, 79.62333345413208, 80.3144474029541, 81.00321888923645, 81.6919903755188, 82.37630915641785, 83.0606279373169, 83.75248622894287, 84.44434452056885, 85.13687252998352, 85.8294005393982, 86.51864528656006, 87.20789003372192, 87.90280365943909, 88.59771728515625, 89.31139326095581, 90.02506923675537, 90.71865725517273, 91.41224527359009, 92.1064841747284, 92.8007230758667, 93.4993314743042, 94.1979398727417, 94.89450335502625, 95.59106683731079, 96.29176378250122, 96.99246072769165, 97.6977891921997, 98.40311765670776, 99.10951924324036, 99.81592082977295, 100.51076793670654, 101.20561504364014, 101.90225768089294, 102.59890031814575, 103.2937650680542, 103.98862981796265, 104.68488073348999, 105.38113164901733, 106.07631206512451, 106.77149248123169, 107.46537041664124, 108.15924835205078, 108.84718036651611, 109.53511238098145, 110.23096179962158, 110.92681121826172, 111.62079381942749, 112.31477642059326, 113.0132622718811, 113.71174812316895, 114.41716504096985, 115.12258195877075, 115.82256603240967, 116.52255010604858, 117.22441816329956, 117.92628622055054, 118.62407445907593, 119.32186269760132, 120.02773833274841, 120.73361396789551, 121.42393326759338, 122.11425256729126, 122.81268644332886, 123.51112031936646, 124.2170262336731, 124.92293214797974, 125.63484001159668, 126.34674787521362, 127.04730725288391, 127.7478666305542, 128.44908595085144, 129.15030527114868, 129.84606671333313, 130.54182815551758, 131.24883913993835, 131.95585012435913, 132.66184449195862, 133.3678388595581, 134.0698275566101, 134.7718162536621, 135.47581005096436, 136.1798038482666, 136.88442277908325, 137.5890417098999, 138.29103469848633, 138.99302768707275, 139.699604511261, 140.40618133544922, 141.81550884246826, 143.2248363494873]
[26.383333333333333, 26.383333333333333, 38.416666666666664, 38.416666666666664, 40.43333333333333, 40.43333333333333, 49.31666666666667, 49.31666666666667, 56.78333333333333, 56.78333333333333, 54.13333333333333, 54.13333333333333, 59.25, 59.25, 62.25, 62.25, 63.11666666666667, 63.11666666666667, 67.28333333333333, 67.28333333333333, 67.65, 67.65, 67.68333333333334, 67.68333333333334, 67.01666666666667, 67.01666666666667, 69.0, 69.0, 69.33333333333333, 69.33333333333333, 69.45, 69.45, 69.71666666666667, 69.71666666666667, 70.23333333333333, 70.23333333333333, 70.26666666666667, 70.26666666666667, 71.0, 71.0, 71.46666666666667, 71.46666666666667, 72.15, 72.15, 72.35, 72.35, 72.26666666666667, 72.26666666666667, 72.18333333333334, 72.18333333333334, 72.86666666666666, 72.86666666666666, 72.7, 72.7, 73.0, 73.0, 73.43333333333334, 73.43333333333334, 73.0, 73.0, 73.9, 73.9, 74.13333333333334, 74.13333333333334, 74.26666666666667, 74.26666666666667, 74.65, 74.65, 74.55, 74.55, 74.56666666666666, 74.56666666666666, 74.96666666666667, 74.96666666666667, 74.2, 74.2, 73.88333333333334, 73.88333333333334, 74.58333333333333, 74.58333333333333, 74.65, 74.65, 74.75, 74.75, 75.23333333333333, 75.23333333333333, 75.28333333333333, 75.28333333333333, 76.4, 76.4, 76.25, 76.25, 76.55, 76.55, 76.33333333333333, 76.33333333333333, 75.88333333333334, 75.88333333333334, 76.01666666666667, 76.01666666666667, 76.16666666666667, 76.16666666666667, 75.85, 75.85, 76.1, 76.1, 77.4, 77.4, 77.63333333333334, 77.63333333333334, 77.35, 77.35, 77.48333333333333, 77.48333333333333, 78.01666666666667, 78.01666666666667, 77.81666666666666, 77.81666666666666, 77.9, 77.9, 78.51666666666667, 78.51666666666667, 77.85, 77.85, 77.48333333333333, 77.48333333333333, 77.2, 77.2, 77.78333333333333, 77.78333333333333, 77.71666666666667, 77.71666666666667, 77.61666666666666, 77.61666666666666, 77.8, 77.8, 77.08333333333333, 77.08333333333333, 77.31666666666666, 77.31666666666666, 77.21666666666667, 77.21666666666667, 77.18333333333334, 77.18333333333334, 77.21666666666667, 77.21666666666667, 76.83333333333333, 76.83333333333333, 77.6, 77.6, 77.55, 77.55, 78.08333333333333, 78.08333333333333, 77.78333333333333, 77.78333333333333, 77.95, 77.95, 78.08333333333333, 78.08333333333333, 77.88333333333334, 77.88333333333334, 78.06666666666666, 78.06666666666666, 77.81666666666666, 77.81666666666666, 78.18333333333334, 78.18333333333334, 78.03333333333333, 78.03333333333333, 78.26666666666667, 78.26666666666667, 78.06666666666666, 78.06666666666666, 77.93333333333334, 77.93333333333334, 77.53333333333333, 77.53333333333333, 77.95, 77.95, 77.86666666666666, 77.86666666666666, 78.26666666666667, 78.26666666666667, 77.88333333333334, 77.88333333333334, 77.7, 77.7, 77.95, 77.95, 78.3, 78.3, 78.08333333333333, 78.08333333333333, 78.01666666666667, 78.01666666666667, 77.7, 77.7, 77.95, 77.95, 78.15, 78.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 5, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.287, Test loss: 1.941, Test accuracy: 25.52
Round   0, Global train loss: 1.287, Global test loss: 2.258, Global test accuracy: 17.05
Round   1, Train loss: 1.093, Test loss: 1.721, Test accuracy: 37.63
Round   1, Global train loss: 1.093, Global test loss: 2.253, Global test accuracy: 26.95
Round   2, Train loss: 0.986, Test loss: 1.431, Test accuracy: 38.68
Round   2, Global train loss: 0.986, Global test loss: 2.177, Global test accuracy: 19.93
Round   3, Train loss: 0.946, Test loss: 1.211, Test accuracy: 45.93
Round   3, Global train loss: 0.946, Global test loss: 2.087, Global test accuracy: 25.82
Round   4, Train loss: 0.934, Test loss: 1.036, Test accuracy: 55.32
Round   4, Global train loss: 0.934, Global test loss: 1.955, Global test accuracy: 32.97
Round   5, Train loss: 0.828, Test loss: 1.054, Test accuracy: 53.83
Round   5, Global train loss: 0.828, Global test loss: 2.008, Global test accuracy: 24.67
Round   6, Train loss: 0.920, Test loss: 1.018, Test accuracy: 57.50
Round   6, Global train loss: 0.920, Global test loss: 1.912, Global test accuracy: 33.37
Round   7, Train loss: 0.874, Test loss: 0.910, Test accuracy: 62.28
Round   7, Global train loss: 0.874, Global test loss: 1.873, Global test accuracy: 32.23
Round   8, Train loss: 0.943, Test loss: 0.919, Test accuracy: 61.77
Round   8, Global train loss: 0.943, Global test loss: 2.162, Global test accuracy: 21.92
Round   9, Train loss: 0.863, Test loss: 0.812, Test accuracy: 65.25
Round   9, Global train loss: 0.863, Global test loss: 1.766, Global test accuracy: 36.08
Round  10, Train loss: 0.861, Test loss: 0.824, Test accuracy: 65.53
Round  10, Global train loss: 0.861, Global test loss: 1.771, Global test accuracy: 36.83
Round  11, Train loss: 0.843, Test loss: 0.824, Test accuracy: 65.93
Round  11, Global train loss: 0.843, Global test loss: 1.842, Global test accuracy: 37.08
Round  12, Train loss: 0.799, Test loss: 0.847, Test accuracy: 65.87
Round  12, Global train loss: 0.799, Global test loss: 1.723, Global test accuracy: 40.70
Round  13, Train loss: 0.788, Test loss: 0.779, Test accuracy: 66.75
Round  13, Global train loss: 0.788, Global test loss: 1.814, Global test accuracy: 36.55
Round  14, Train loss: 0.857, Test loss: 0.782, Test accuracy: 66.98
Round  14, Global train loss: 0.857, Global test loss: 1.899, Global test accuracy: 37.45
Round  15, Train loss: 0.703, Test loss: 0.774, Test accuracy: 67.40
Round  15, Global train loss: 0.703, Global test loss: 1.674, Global test accuracy: 42.87
Round  16, Train loss: 0.711, Test loss: 0.757, Test accuracy: 67.85
Round  16, Global train loss: 0.711, Global test loss: 1.853, Global test accuracy: 37.55
Round  17, Train loss: 0.804, Test loss: 0.745, Test accuracy: 68.27
Round  17, Global train loss: 0.804, Global test loss: 1.590, Global test accuracy: 44.52
Round  18, Train loss: 0.819, Test loss: 0.723, Test accuracy: 69.75
Round  18, Global train loss: 0.819, Global test loss: 1.577, Global test accuracy: 43.75
Round  19, Train loss: 0.668, Test loss: 0.720, Test accuracy: 69.77
Round  19, Global train loss: 0.668, Global test loss: 1.660, Global test accuracy: 42.10
Round  20, Train loss: 0.680, Test loss: 0.702, Test accuracy: 70.48
Round  20, Global train loss: 0.680, Global test loss: 1.894, Global test accuracy: 34.75
Round  21, Train loss: 0.772, Test loss: 0.680, Test accuracy: 71.12
Round  21, Global train loss: 0.772, Global test loss: 1.657, Global test accuracy: 44.55
Round  22, Train loss: 0.699, Test loss: 0.686, Test accuracy: 71.35
Round  22, Global train loss: 0.699, Global test loss: 1.782, Global test accuracy: 34.45
Round  23, Train loss: 0.672, Test loss: 0.690, Test accuracy: 71.03
Round  23, Global train loss: 0.672, Global test loss: 1.504, Global test accuracy: 47.80
Round  24, Train loss: 0.701, Test loss: 0.696, Test accuracy: 70.90
Round  24, Global train loss: 0.701, Global test loss: 1.654, Global test accuracy: 45.35
Round  25, Train loss: 0.731, Test loss: 0.689, Test accuracy: 71.45
Round  25, Global train loss: 0.731, Global test loss: 1.878, Global test accuracy: 31.65
Round  26, Train loss: 0.673, Test loss: 0.686, Test accuracy: 71.98
Round  26, Global train loss: 0.673, Global test loss: 1.777, Global test accuracy: 43.18
Round  27, Train loss: 0.625, Test loss: 0.668, Test accuracy: 72.07
Round  27, Global train loss: 0.625, Global test loss: 1.624, Global test accuracy: 43.48
Round  28, Train loss: 0.630, Test loss: 0.669, Test accuracy: 72.38
Round  28, Global train loss: 0.630, Global test loss: 1.732, Global test accuracy: 43.95
Round  29, Train loss: 0.565, Test loss: 0.667, Test accuracy: 72.92
Round  29, Global train loss: 0.565, Global test loss: 1.601, Global test accuracy: 46.92
Round  30, Train loss: 0.650, Test loss: 0.649, Test accuracy: 73.38
Round  30, Global train loss: 0.650, Global test loss: 1.526, Global test accuracy: 45.13
Round  31, Train loss: 0.632, Test loss: 0.642, Test accuracy: 73.57
Round  31, Global train loss: 0.632, Global test loss: 1.505, Global test accuracy: 48.48
Round  32, Train loss: 0.668, Test loss: 0.650, Test accuracy: 73.45
Round  32, Global train loss: 0.668, Global test loss: 1.492, Global test accuracy: 48.55
Round  33, Train loss: 0.575, Test loss: 0.661, Test accuracy: 73.47
Round  33, Global train loss: 0.575, Global test loss: 1.507, Global test accuracy: 48.58
Round  34, Train loss: 0.531, Test loss: 0.683, Test accuracy: 72.93
Round  34, Global train loss: 0.531, Global test loss: 1.451, Global test accuracy: 52.80
Round  35, Train loss: 0.605, Test loss: 0.680, Test accuracy: 73.42
Round  35, Global train loss: 0.605, Global test loss: 1.422, Global test accuracy: 52.22
Round  36, Train loss: 0.611, Test loss: 0.673, Test accuracy: 73.32
Round  36, Global train loss: 0.611, Global test loss: 1.392, Global test accuracy: 52.22
Round  37, Train loss: 0.572, Test loss: 0.670, Test accuracy: 73.53
Round  37, Global train loss: 0.572, Global test loss: 1.560, Global test accuracy: 45.03
Round  38, Train loss: 0.574, Test loss: 0.667, Test accuracy: 73.28
Round  38, Global train loss: 0.574, Global test loss: 1.406, Global test accuracy: 52.73
Round  39, Train loss: 0.522, Test loss: 0.651, Test accuracy: 73.58
Round  39, Global train loss: 0.522, Global test loss: 1.585, Global test accuracy: 47.03
Round  40, Train loss: 0.515, Test loss: 0.666, Test accuracy: 73.25
Round  40, Global train loss: 0.515, Global test loss: 1.729, Global test accuracy: 46.07
Round  41, Train loss: 0.665, Test loss: 0.645, Test accuracy: 73.87
Round  41, Global train loss: 0.665, Global test loss: 1.509, Global test accuracy: 47.80
Round  42, Train loss: 0.576, Test loss: 0.644, Test accuracy: 74.10
Round  42, Global train loss: 0.576, Global test loss: 1.432, Global test accuracy: 50.32
Round  43, Train loss: 0.572, Test loss: 0.648, Test accuracy: 74.58
Round  43, Global train loss: 0.572, Global test loss: 1.481, Global test accuracy: 49.85
Round  44, Train loss: 0.555, Test loss: 0.621, Test accuracy: 75.97
Round  44, Global train loss: 0.555, Global test loss: 1.490, Global test accuracy: 47.33
Round  45, Train loss: 0.541, Test loss: 0.614, Test accuracy: 76.38
Round  45, Global train loss: 0.541, Global test loss: 1.481, Global test accuracy: 49.02
Round  46, Train loss: 0.529, Test loss: 0.617, Test accuracy: 76.53
Round  46, Global train loss: 0.529, Global test loss: 1.372, Global test accuracy: 52.17
Round  47, Train loss: 0.566, Test loss: 0.641, Test accuracy: 75.55
Round  47, Global train loss: 0.566, Global test loss: 1.521, Global test accuracy: 49.87
Round  48, Train loss: 0.476, Test loss: 0.622, Test accuracy: 76.08
Round  48, Global train loss: 0.476, Global test loss: 1.592, Global test accuracy: 46.47
Round  49, Train loss: 0.553, Test loss: 0.609, Test accuracy: 76.47
Round  49, Global train loss: 0.553, Global test loss: 1.295, Global test accuracy: 54.65
Round  50, Train loss: 0.542, Test loss: 0.600, Test accuracy: 77.00
Round  50, Global train loss: 0.542, Global test loss: 1.372, Global test accuracy: 52.12
Round  51, Train loss: 0.560, Test loss: 0.626, Test accuracy: 76.37
Round  51, Global train loss: 0.560, Global test loss: 1.398, Global test accuracy: 51.90
Round  52, Train loss: 0.536, Test loss: 0.619, Test accuracy: 77.02
Round  52, Global train loss: 0.536, Global test loss: 1.329, Global test accuracy: 52.87
Round  53, Train loss: 0.461, Test loss: 0.629, Test accuracy: 76.30
Round  53, Global train loss: 0.461, Global test loss: 1.351, Global test accuracy: 55.02
Round  54, Train loss: 0.435, Test loss: 0.621, Test accuracy: 76.90
Round  54, Global train loss: 0.435, Global test loss: 1.376, Global test accuracy: 55.15
Round  55, Train loss: 0.454, Test loss: 0.621, Test accuracy: 76.58
Round  55, Global train loss: 0.454, Global test loss: 1.466, Global test accuracy: 53.43
Round  56, Train loss: 0.416, Test loss: 0.634, Test accuracy: 76.88
Round  56, Global train loss: 0.416, Global test loss: 1.458, Global test accuracy: 51.22
Round  57, Train loss: 0.511, Test loss: 0.627, Test accuracy: 76.83
Round  57, Global train loss: 0.511, Global test loss: 1.444, Global test accuracy: 52.27
Round  58, Train loss: 0.403, Test loss: 0.612, Test accuracy: 77.30
Round  58, Global train loss: 0.403, Global test loss: 1.517, Global test accuracy: 51.33
Round  59, Train loss: 0.544, Test loss: 0.603, Test accuracy: 77.55
Round  59, Global train loss: 0.544, Global test loss: 1.502, Global test accuracy: 48.80
Round  60, Train loss: 0.510, Test loss: 0.609, Test accuracy: 77.38
Round  60, Global train loss: 0.510, Global test loss: 1.318, Global test accuracy: 55.93
Round  61, Train loss: 0.432, Test loss: 0.608, Test accuracy: 77.53
Round  61, Global train loss: 0.432, Global test loss: 1.460, Global test accuracy: 53.42
Round  62, Train loss: 0.462, Test loss: 0.629, Test accuracy: 76.85
Round  62, Global train loss: 0.462, Global test loss: 1.289, Global test accuracy: 57.28
Round  63, Train loss: 0.512, Test loss: 0.607, Test accuracy: 77.52
Round  63, Global train loss: 0.512, Global test loss: 1.446, Global test accuracy: 52.35
Round  64, Train loss: 0.445, Test loss: 0.624, Test accuracy: 76.93
Round  64, Global train loss: 0.445, Global test loss: 1.448, Global test accuracy: 53.52
Round  65, Train loss: 0.384, Test loss: 0.642, Test accuracy: 76.62
Round  65, Global train loss: 0.384, Global test loss: 1.433, Global test accuracy: 52.25
Round  66, Train loss: 0.482, Test loss: 0.639, Test accuracy: 76.32
Round  66, Global train loss: 0.482, Global test loss: 1.337, Global test accuracy: 55.15
Round  67, Train loss: 0.411, Test loss: 0.645, Test accuracy: 76.43
Round  67, Global train loss: 0.411, Global test loss: 1.475, Global test accuracy: 51.15
Round  68, Train loss: 0.476, Test loss: 0.642, Test accuracy: 76.70
Round  68, Global train loss: 0.476, Global test loss: 1.233, Global test accuracy: 57.52
Round  69, Train loss: 0.506, Test loss: 0.658, Test accuracy: 76.40
Round  69, Global train loss: 0.506, Global test loss: 1.365, Global test accuracy: 53.28
Round  70, Train loss: 0.386, Test loss: 0.664, Test accuracy: 76.52
Round  70, Global train loss: 0.386, Global test loss: 1.472, Global test accuracy: 53.95
Round  71, Train loss: 0.358, Test loss: 0.663, Test accuracy: 76.48
Round  71, Global train loss: 0.358, Global test loss: 1.442, Global test accuracy: 53.73
Round  72, Train loss: 0.326, Test loss: 0.657, Test accuracy: 76.65
Round  72, Global train loss: 0.326, Global test loss: 1.447, Global test accuracy: 57.42
Round  73, Train loss: 0.370, Test loss: 0.642, Test accuracy: 77.10
Round  73, Global train loss: 0.370, Global test loss: 1.559, Global test accuracy: 54.55
Round  74, Train loss: 0.427, Test loss: 0.641, Test accuracy: 77.15
Round  74, Global train loss: 0.427, Global test loss: 1.371, Global test accuracy: 54.82
Round  75, Train loss: 0.397, Test loss: 0.670, Test accuracy: 76.97
Round  75, Global train loss: 0.397, Global test loss: 1.292, Global test accuracy: 57.07
Round  76, Train loss: 0.416, Test loss: 0.701, Test accuracy: 76.15
Round  76, Global train loss: 0.416, Global test loss: 1.741, Global test accuracy: 49.32
Round  77, Train loss: 0.408, Test loss: 0.663, Test accuracy: 76.82
Round  77, Global train loss: 0.408, Global test loss: 1.521, Global test accuracy: 53.60
Round  78, Train loss: 0.400, Test loss: 0.656, Test accuracy: 77.27
Round  78, Global train loss: 0.400, Global test loss: 1.442, Global test accuracy: 53.88
Round  79, Train loss: 0.414, Test loss: 0.628, Test accuracy: 78.05
Round  79, Global train loss: 0.414, Global test loss: 1.499, Global test accuracy: 52.70
Round  80, Train loss: 0.386, Test loss: 0.640, Test accuracy: 77.83
Round  80, Global train loss: 0.386, Global test loss: 1.357, Global test accuracy: 55.77
Round  81, Train loss: 0.387, Test loss: 0.636, Test accuracy: 78.13
Round  81, Global train loss: 0.387, Global test loss: 1.471, Global test accuracy: 52.50
Round  82, Train loss: 0.302, Test loss: 0.630, Test accuracy: 78.45
Round  82, Global train loss: 0.302, Global test loss: 1.508, Global test accuracy: 53.50
Round  83, Train loss: 0.441, Test loss: 0.636, Test accuracy: 78.42
Round  83, Global train loss: 0.441, Global test loss: 1.389, Global test accuracy: 54.80
Round  84, Train loss: 0.388, Test loss: 0.636, Test accuracy: 77.90
Round  84, Global train loss: 0.388, Global test loss: 1.446, Global test accuracy: 55.15
Round  85, Train loss: 0.380, Test loss: 0.643, Test accuracy: 77.75
Round  85, Global train loss: 0.380, Global test loss: 1.394, Global test accuracy: 55.62
Round  86, Train loss: 0.418, Test loss: 0.654, Test accuracy: 77.68
Round  86, Global train loss: 0.418, Global test loss: 1.497, Global test accuracy: 54.78
Round  87, Train loss: 0.364, Test loss: 0.660, Test accuracy: 77.63
Round  87, Global train loss: 0.364, Global test loss: 1.571, Global test accuracy: 52.07
Round  88, Train loss: 0.437, Test loss: 0.645, Test accuracy: 77.73
Round  88, Global train loss: 0.437, Global test loss: 1.470, Global test accuracy: 50.98
Round  89, Train loss: 0.332, Test loss: 0.637, Test accuracy: 78.18
Round  89, Global train loss: 0.332, Global test loss: 1.402, Global test accuracy: 56.37
Round  90, Train loss: 0.336, Test loss: 0.651, Test accuracy: 78.12
Round  90, Global train loss: 0.336, Global test loss: 1.332, Global test accuracy: 59.00
Round  91, Train loss: 0.281, Test loss: 0.670, Test accuracy: 77.67
Round  91, Global train loss: 0.281, Global test loss: 1.687, Global test accuracy: 53.03
Round  92, Train loss: 0.331, Test loss: 0.676, Test accuracy: 77.52
Round  92, Global train loss: 0.331, Global test loss: 1.414, Global test accuracy: 56.82
Round  93, Train loss: 0.297, Test loss: 0.679, Test accuracy: 77.30
Round  93, Global train loss: 0.297, Global test loss: 1.385, Global test accuracy: 57.32
Round  94, Train loss: 0.415, Test loss: 0.667, Test accuracy: 77.73
Round  94, Global train loss: 0.415, Global test loss: 1.391, Global test accuracy: 55.78
Round  95, Train loss: 0.374, Test loss: 0.676, Test accuracy: 77.20
Round  95, Global train loss: 0.374, Global test loss: 1.446, Global test accuracy: 57.15
Round  96, Train loss: 0.317, Test loss: 0.706, Test accuracy: 76.60
Round  96, Global train loss: 0.317, Global test loss: 1.449, Global test accuracy: 56.55
Round  97, Train loss: 0.337, Test loss: 0.714, Test accuracy: 76.25
Round  97, Global train loss: 0.337, Global test loss: 1.344, Global test accuracy: 58.02
Round  98, Train loss: 0.389, Test loss: 0.698, Test accuracy: 76.68
Round  98, Global train loss: 0.389, Global test loss: 1.908, Global test accuracy: 46.05
Round  99, Train loss: 0.343, Test loss: 0.696, Test accuracy: 77.40
Round  99, Global train loss: 0.343, Global test loss: 1.331, Global test accuracy: 59.10
Final Round, Train loss: 0.270, Test loss: 0.683, Test accuracy: 78.05
Final Round, Global train loss: 0.270, Global test loss: 1.331, Global test accuracy: 59.10
Average accuracy final 10 rounds: 77.24666666666666 

Average global accuracy final 10 rounds: 55.88166666666666 

993.7229042053223
[1.0392653942108154, 2.078530788421631, 2.8121306896209717, 3.5457305908203125, 4.290061712265015, 5.034392833709717, 5.764495611190796, 6.494598388671875, 7.2306742668151855, 7.966750144958496, 8.698169469833374, 9.429588794708252, 10.16097640991211, 10.892364025115967, 11.629211664199829, 12.366059303283691, 13.096620321273804, 13.827181339263916, 14.558539628982544, 15.289897918701172, 16.024040937423706, 16.75818395614624, 17.495147705078125, 18.23211145401001, 18.960036039352417, 19.687960624694824, 20.416646718978882, 21.14533281326294, 21.87249445915222, 22.599656105041504, 23.322596549987793, 24.045536994934082, 24.772555351257324, 25.499573707580566, 26.232808589935303, 26.96604347229004, 27.68875527381897, 28.4114670753479, 29.133686065673828, 29.855905055999756, 30.588501453399658, 31.32109785079956, 32.04578423500061, 32.77047061920166, 33.49555063247681, 34.22063064575195, 34.95100378990173, 35.681376934051514, 36.406768560409546, 37.13216018676758, 37.87952160835266, 38.626883029937744, 39.372695207595825, 40.118507385253906, 40.856470823287964, 41.59443426132202, 42.33028960227966, 43.066144943237305, 43.80409908294678, 44.54205322265625, 45.27658820152283, 46.011123180389404, 46.73854875564575, 47.4659743309021, 48.20200872421265, 48.93804311752319, 49.67621445655823, 50.41438579559326, 51.14707541465759, 51.879765033721924, 52.58679986000061, 53.2938346862793, 54.024657249450684, 54.75547981262207, 55.48116850852966, 56.206857204437256, 56.92744565010071, 57.64803409576416, 58.374383211135864, 59.10073232650757, 59.8413462638855, 60.58196020126343, 61.30573034286499, 62.02950048446655, 62.7641487121582, 63.49879693984985, 64.22861194610596, 64.95842695236206, 65.68541669845581, 66.41240644454956, 67.1414122581482, 67.87041807174683, 68.59731554985046, 69.3242130279541, 70.05305194854736, 70.78189086914062, 71.51375460624695, 72.24561834335327, 72.97793006896973, 73.71024179458618, 74.4425835609436, 75.17492532730103, 75.90709710121155, 76.63926887512207, 77.36463809013367, 78.09000730514526, 78.83157134056091, 79.57313537597656, 80.30899167060852, 81.04484796524048, 81.77988886833191, 82.51492977142334, 83.25511407852173, 83.99529838562012, 84.72337007522583, 85.45144176483154, 86.18164253234863, 86.91184329986572, 87.64889645576477, 88.38594961166382, 89.1235625743866, 89.86117553710938, 90.57659578323364, 91.29201602935791, 92.02782559394836, 92.76363515853882, 93.49961924552917, 94.23560333251953, 94.96670985221863, 95.69781637191772, 96.43117094039917, 97.16452550888062, 97.9019923210144, 98.6394591331482, 99.36521315574646, 100.09096717834473, 100.82140731811523, 101.55184745788574, 102.27882075309753, 103.00579404830933, 103.73482179641724, 104.46384954452515, 105.19426608085632, 105.9246826171875, 106.6479971408844, 107.3713116645813, 108.10676646232605, 108.8422212600708, 109.5775556564331, 110.31289005279541, 111.0452253818512, 111.77756071090698, 112.50156283378601, 113.22556495666504, 113.94783592224121, 114.67010688781738, 115.39907836914062, 116.12804985046387, 116.85568857192993, 117.583327293396, 118.31148719787598, 119.03964710235596, 119.76966881752014, 120.49969053268433, 121.23453140258789, 121.96937227249146, 122.69698786735535, 123.42460346221924, 124.15857148170471, 124.89253950119019, 125.62523651123047, 126.35793352127075, 127.0926718711853, 127.82741022109985, 128.55147123336792, 129.275532245636, 130.0109167098999, 130.74630117416382, 131.47001194953918, 132.19372272491455, 132.919100522995, 133.64447832107544, 134.37748503684998, 135.1104917526245, 135.84170126914978, 136.57291078567505, 137.2963423728943, 138.01977396011353, 138.75525999069214, 139.49074602127075, 140.21910786628723, 140.9474697113037, 141.6728138923645, 142.3981580734253, 143.12780213356018, 143.85744619369507, 144.5842227935791, 145.31099939346313, 146.04027700424194, 146.76955461502075, 148.23604941368103, 149.7025442123413]
[25.516666666666666, 25.516666666666666, 37.63333333333333, 37.63333333333333, 38.68333333333333, 38.68333333333333, 45.93333333333333, 45.93333333333333, 55.31666666666667, 55.31666666666667, 53.833333333333336, 53.833333333333336, 57.5, 57.5, 62.28333333333333, 62.28333333333333, 61.766666666666666, 61.766666666666666, 65.25, 65.25, 65.53333333333333, 65.53333333333333, 65.93333333333334, 65.93333333333334, 65.86666666666666, 65.86666666666666, 66.75, 66.75, 66.98333333333333, 66.98333333333333, 67.4, 67.4, 67.85, 67.85, 68.26666666666667, 68.26666666666667, 69.75, 69.75, 69.76666666666667, 69.76666666666667, 70.48333333333333, 70.48333333333333, 71.11666666666666, 71.11666666666666, 71.35, 71.35, 71.03333333333333, 71.03333333333333, 70.9, 70.9, 71.45, 71.45, 71.98333333333333, 71.98333333333333, 72.06666666666666, 72.06666666666666, 72.38333333333334, 72.38333333333334, 72.91666666666667, 72.91666666666667, 73.38333333333334, 73.38333333333334, 73.56666666666666, 73.56666666666666, 73.45, 73.45, 73.46666666666667, 73.46666666666667, 72.93333333333334, 72.93333333333334, 73.41666666666667, 73.41666666666667, 73.31666666666666, 73.31666666666666, 73.53333333333333, 73.53333333333333, 73.28333333333333, 73.28333333333333, 73.58333333333333, 73.58333333333333, 73.25, 73.25, 73.86666666666666, 73.86666666666666, 74.1, 74.1, 74.58333333333333, 74.58333333333333, 75.96666666666667, 75.96666666666667, 76.38333333333334, 76.38333333333334, 76.53333333333333, 76.53333333333333, 75.55, 75.55, 76.08333333333333, 76.08333333333333, 76.46666666666667, 76.46666666666667, 77.0, 77.0, 76.36666666666666, 76.36666666666666, 77.01666666666667, 77.01666666666667, 76.3, 76.3, 76.9, 76.9, 76.58333333333333, 76.58333333333333, 76.88333333333334, 76.88333333333334, 76.83333333333333, 76.83333333333333, 77.3, 77.3, 77.55, 77.55, 77.38333333333334, 77.38333333333334, 77.53333333333333, 77.53333333333333, 76.85, 76.85, 77.51666666666667, 77.51666666666667, 76.93333333333334, 76.93333333333334, 76.61666666666666, 76.61666666666666, 76.31666666666666, 76.31666666666666, 76.43333333333334, 76.43333333333334, 76.7, 76.7, 76.4, 76.4, 76.51666666666667, 76.51666666666667, 76.48333333333333, 76.48333333333333, 76.65, 76.65, 77.1, 77.1, 77.15, 77.15, 76.96666666666667, 76.96666666666667, 76.15, 76.15, 76.81666666666666, 76.81666666666666, 77.26666666666667, 77.26666666666667, 78.05, 78.05, 77.83333333333333, 77.83333333333333, 78.13333333333334, 78.13333333333334, 78.45, 78.45, 78.41666666666667, 78.41666666666667, 77.9, 77.9, 77.75, 77.75, 77.68333333333334, 77.68333333333334, 77.63333333333334, 77.63333333333334, 77.73333333333333, 77.73333333333333, 78.18333333333334, 78.18333333333334, 78.11666666666666, 78.11666666666666, 77.66666666666667, 77.66666666666667, 77.51666666666667, 77.51666666666667, 77.3, 77.3, 77.73333333333333, 77.73333333333333, 77.2, 77.2, 76.6, 76.6, 76.25, 76.25, 76.68333333333334, 76.68333333333334, 77.4, 77.4, 78.05, 78.05]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 19, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.733, Test loss: 2.094, Test accuracy: 14.48
Round   1, Train loss: 1.152, Test loss: 1.858, Test accuracy: 36.25
Round   2, Train loss: 1.094, Test loss: 1.449, Test accuracy: 38.25
Round   3, Train loss: 0.990, Test loss: 1.284, Test accuracy: 44.82
Round   4, Train loss: 0.961, Test loss: 1.134, Test accuracy: 51.63
Round   5, Train loss: 0.880, Test loss: 1.180, Test accuracy: 52.52
Round   6, Train loss: 0.992, Test loss: 1.123, Test accuracy: 55.40
Round   7, Train loss: 0.953, Test loss: 0.981, Test accuracy: 56.72
Round   8, Train loss: 0.937, Test loss: 1.047, Test accuracy: 57.63
Round   9, Train loss: 0.930, Test loss: 0.835, Test accuracy: 64.03
Round  10, Train loss: 0.923, Test loss: 0.865, Test accuracy: 61.98
Round  11, Train loss: 0.855, Test loss: 0.833, Test accuracy: 64.40
Round  12, Train loss: 0.856, Test loss: 0.862, Test accuracy: 64.03
Round  13, Train loss: 0.817, Test loss: 0.745, Test accuracy: 67.95
Round  14, Train loss: 0.860, Test loss: 0.756, Test accuracy: 67.57
Round  15, Train loss: 0.714, Test loss: 0.723, Test accuracy: 69.97
Round  16, Train loss: 0.771, Test loss: 0.717, Test accuracy: 70.45
Round  17, Train loss: 0.844, Test loss: 0.715, Test accuracy: 70.22
Round  18, Train loss: 0.866, Test loss: 0.702, Test accuracy: 70.27
Round  19, Train loss: 0.667, Test loss: 0.695, Test accuracy: 71.33
Round  20, Train loss: 0.716, Test loss: 0.697, Test accuracy: 70.90
Round  21, Train loss: 0.814, Test loss: 0.682, Test accuracy: 71.93
Round  22, Train loss: 0.782, Test loss: 0.703, Test accuracy: 71.32
Round  23, Train loss: 0.750, Test loss: 0.692, Test accuracy: 71.18
Round  24, Train loss: 0.813, Test loss: 0.695, Test accuracy: 71.52
Round  25, Train loss: 0.759, Test loss: 0.670, Test accuracy: 72.67
Round  26, Train loss: 0.691, Test loss: 0.658, Test accuracy: 73.48
Round  27, Train loss: 0.730, Test loss: 0.651, Test accuracy: 73.85
Round  28, Train loss: 0.648, Test loss: 0.645, Test accuracy: 73.68
Round  29, Train loss: 0.687, Test loss: 0.642, Test accuracy: 73.23
Round  30, Train loss: 0.654, Test loss: 0.626, Test accuracy: 74.70
Round  31, Train loss: 0.627, Test loss: 0.616, Test accuracy: 74.13
Round  32, Train loss: 0.646, Test loss: 0.624, Test accuracy: 73.98
Round  33, Train loss: 0.580, Test loss: 0.615, Test accuracy: 75.10
Round  34, Train loss: 0.590, Test loss: 0.614, Test accuracy: 74.65
Round  35, Train loss: 0.616, Test loss: 0.597, Test accuracy: 74.87
Round  36, Train loss: 0.597, Test loss: 0.598, Test accuracy: 75.57
Round  37, Train loss: 0.539, Test loss: 0.601, Test accuracy: 75.03
Round  38, Train loss: 0.627, Test loss: 0.587, Test accuracy: 75.73
Round  39, Train loss: 0.672, Test loss: 0.597, Test accuracy: 75.42
Round  40, Train loss: 0.639, Test loss: 0.587, Test accuracy: 75.35
Round  41, Train loss: 0.720, Test loss: 0.585, Test accuracy: 76.02
Round  42, Train loss: 0.633, Test loss: 0.590, Test accuracy: 75.55
Round  43, Train loss: 0.586, Test loss: 0.576, Test accuracy: 76.65
Round  44, Train loss: 0.539, Test loss: 0.573, Test accuracy: 76.93
Round  45, Train loss: 0.576, Test loss: 0.569, Test accuracy: 76.55
Round  46, Train loss: 0.535, Test loss: 0.565, Test accuracy: 76.50
Round  47, Train loss: 0.650, Test loss: 0.567, Test accuracy: 76.72
Round  48, Train loss: 0.476, Test loss: 0.564, Test accuracy: 76.80
Round  49, Train loss: 0.658, Test loss: 0.568, Test accuracy: 76.37
Round  50, Train loss: 0.604, Test loss: 0.560, Test accuracy: 76.65
Round  51, Train loss: 0.622, Test loss: 0.563, Test accuracy: 77.23
Round  52, Train loss: 0.516, Test loss: 0.550, Test accuracy: 77.77
Round  53, Train loss: 0.472, Test loss: 0.551, Test accuracy: 77.95
Round  54, Train loss: 0.502, Test loss: 0.549, Test accuracy: 77.58
Round  55, Train loss: 0.540, Test loss: 0.555, Test accuracy: 78.03
Round  56, Train loss: 0.494, Test loss: 0.569, Test accuracy: 77.17
Round  57, Train loss: 0.545, Test loss: 0.558, Test accuracy: 78.08
Round  58, Train loss: 0.488, Test loss: 0.544, Test accuracy: 77.97
Round  59, Train loss: 0.635, Test loss: 0.547, Test accuracy: 78.33
Round  60, Train loss: 0.606, Test loss: 0.535, Test accuracy: 78.60
Round  61, Train loss: 0.470, Test loss: 0.536, Test accuracy: 78.05
Round  62, Train loss: 0.579, Test loss: 0.534, Test accuracy: 78.67
Round  63, Train loss: 0.532, Test loss: 0.539, Test accuracy: 78.17
Round  64, Train loss: 0.454, Test loss: 0.529, Test accuracy: 78.95
Round  65, Train loss: 0.406, Test loss: 0.535, Test accuracy: 78.68
Round  66, Train loss: 0.561, Test loss: 0.523, Test accuracy: 79.18
Round  67, Train loss: 0.491, Test loss: 0.531, Test accuracy: 78.62
Round  68, Train loss: 0.559, Test loss: 0.521, Test accuracy: 79.15
Round  69, Train loss: 0.563, Test loss: 0.527, Test accuracy: 79.25
Round  70, Train loss: 0.548, Test loss: 0.519, Test accuracy: 78.98
Round  71, Train loss: 0.399, Test loss: 0.516, Test accuracy: 79.30
Round  72, Train loss: 0.376, Test loss: 0.517, Test accuracy: 79.35
Round  73, Train loss: 0.384, Test loss: 0.516, Test accuracy: 79.10
Round  74, Train loss: 0.429, Test loss: 0.514, Test accuracy: 79.52
Round  75, Train loss: 0.500, Test loss: 0.523, Test accuracy: 79.38
Round  76, Train loss: 0.421, Test loss: 0.523, Test accuracy: 79.33
Round  77, Train loss: 0.423, Test loss: 0.510, Test accuracy: 79.53
Round  78, Train loss: 0.456, Test loss: 0.511, Test accuracy: 78.97
Round  79, Train loss: 0.432, Test loss: 0.513, Test accuracy: 79.07
Round  80, Train loss: 0.541, Test loss: 0.513, Test accuracy: 79.13
Round  81, Train loss: 0.465, Test loss: 0.506, Test accuracy: 79.77
Round  82, Train loss: 0.413, Test loss: 0.510, Test accuracy: 79.72
Round  83, Train loss: 0.457, Test loss: 0.520, Test accuracy: 79.42
Round  84, Train loss: 0.502, Test loss: 0.515, Test accuracy: 80.07
Round  85, Train loss: 0.472, Test loss: 0.511, Test accuracy: 79.93
Round  86, Train loss: 0.466, Test loss: 0.515, Test accuracy: 79.93
Round  87, Train loss: 0.450, Test loss: 0.512, Test accuracy: 80.62
Round  88, Train loss: 0.597, Test loss: 0.507, Test accuracy: 80.38
Round  89, Train loss: 0.442, Test loss: 0.503, Test accuracy: 80.75
Round  90, Train loss: 0.465, Test loss: 0.500, Test accuracy: 80.88
Round  91, Train loss: 0.369, Test loss: 0.499, Test accuracy: 80.53
Round  92, Train loss: 0.370, Test loss: 0.501, Test accuracy: 80.13
Round  93, Train loss: 0.340, Test loss: 0.503, Test accuracy: 80.55
Round  94, Train loss: 0.481, Test loss: 0.496, Test accuracy: 81.17
Round  95, Train loss: 0.478, Test loss: 0.506, Test accuracy: 80.05
Round  96, Train loss: 0.399, Test loss: 0.501, Test accuracy: 80.77
Round  97, Train loss: 0.366, Test loss: 0.502, Test accuracy: 80.43
Round  98, Train loss: 0.440, Test loss: 0.499, Test accuracy: 80.87
Round  99, Train loss: 0.425, Test loss: 0.497, Test accuracy: 80.48
Final Round, Train loss: 0.365, Test loss: 0.501, Test accuracy: 80.97
Average accuracy final 10 rounds: 80.58666666666666
710.4944620132446
[1.2049174308776855, 2.063375473022461, 2.959406614303589, 3.8397161960601807, 4.754873275756836, 5.631203651428223, 6.471562385559082, 7.326138257980347, 8.170873880386353, 9.012813091278076, 9.851485013961792, 10.699121952056885, 11.545201063156128, 12.387456178665161, 13.220786094665527, 14.063302516937256, 14.911459684371948, 15.756746768951416, 16.594691276550293, 17.425522327423096, 18.271997451782227, 19.113110303878784, 19.96114492416382, 20.801045656204224, 21.64551830291748, 22.49024200439453, 23.338128089904785, 24.190333604812622, 25.030409812927246, 25.881686687469482, 26.72855234146118, 27.577489852905273, 28.41733741760254, 29.264107704162598, 30.107149839401245, 30.951903820037842, 31.801501512527466, 32.648200273513794, 33.492440938949585, 34.33218836784363, 35.17987084388733, 36.01443290710449, 36.850356101989746, 37.683314085006714, 38.53440475463867, 39.37597322463989, 40.217488050460815, 41.06169056892395, 41.90535593032837, 42.74288320541382, 43.58014893531799, 44.427326917648315, 45.27698111534119, 46.1363091468811, 46.98042845726013, 47.82485818862915, 48.67322516441345, 49.52438473701477, 50.37903881072998, 51.2238986492157, 52.076700925827026, 52.90517044067383, 53.75285482406616, 54.59269905090332, 55.425769329071045, 56.26452016830444, 57.106589794158936, 57.951942920684814, 58.78960609436035, 59.633086919784546, 60.48589277267456, 61.335222005844116, 62.17151641845703, 63.007691383361816, 63.855910301208496, 64.70501613616943, 65.54177284240723, 66.38595080375671, 67.22424006462097, 68.05386972427368, 68.89377737045288, 69.73410677909851, 70.57223868370056, 71.4168541431427, 72.26053595542908, 73.10491919517517, 73.93995332717896, 74.78378057479858, 75.62863636016846, 76.47098469734192, 77.31225824356079, 78.15291833877563, 78.9989504814148, 79.8468382358551, 80.68997859954834, 81.52836036682129, 82.36550545692444, 83.21400761604309, 84.05893969535828, 84.90525269508362, 86.24171495437622]
[14.483333333333333, 36.25, 38.25, 44.81666666666667, 51.63333333333333, 52.516666666666666, 55.4, 56.71666666666667, 57.63333333333333, 64.03333333333333, 61.983333333333334, 64.4, 64.03333333333333, 67.95, 67.56666666666666, 69.96666666666667, 70.45, 70.21666666666667, 70.26666666666667, 71.33333333333333, 70.9, 71.93333333333334, 71.31666666666666, 71.18333333333334, 71.51666666666667, 72.66666666666667, 73.48333333333333, 73.85, 73.68333333333334, 73.23333333333333, 74.7, 74.13333333333334, 73.98333333333333, 75.1, 74.65, 74.86666666666666, 75.56666666666666, 75.03333333333333, 75.73333333333333, 75.41666666666667, 75.35, 76.01666666666667, 75.55, 76.65, 76.93333333333334, 76.55, 76.5, 76.71666666666667, 76.8, 76.36666666666666, 76.65, 77.23333333333333, 77.76666666666667, 77.95, 77.58333333333333, 78.03333333333333, 77.16666666666667, 78.08333333333333, 77.96666666666667, 78.33333333333333, 78.6, 78.05, 78.66666666666667, 78.16666666666667, 78.95, 78.68333333333334, 79.18333333333334, 78.61666666666666, 79.15, 79.25, 78.98333333333333, 79.3, 79.35, 79.1, 79.51666666666667, 79.38333333333334, 79.33333333333333, 79.53333333333333, 78.96666666666667, 79.06666666666666, 79.13333333333334, 79.76666666666667, 79.71666666666667, 79.41666666666667, 80.06666666666666, 79.93333333333334, 79.93333333333334, 80.61666666666666, 80.38333333333334, 80.75, 80.88333333333334, 80.53333333333333, 80.13333333333334, 80.55, 81.16666666666667, 80.05, 80.76666666666667, 80.43333333333334, 80.86666666666666, 80.48333333333333, 80.96666666666667]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
   Client 8, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 15, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  10.2100
Round 1 global test acc  18.6100
Round 2 global test acc  10.7300
Round 3 global test acc  21.5000
Round 4 global test acc  18.2200
Round 5 global test acc  11.6800
Round 6 global test acc  14.4300
Round 7 global test acc  25.4500
Round 8 global test acc  24.3300
Round 9 global test acc  23.9800
Round 10 global test acc  16.6300
Round 11 global test acc  21.6400
Round 12 global test acc  31.2800
Round 13 global test acc  29.8400
Round 14 global test acc  18.2100
Round 15 global test acc  28.3300
Round 16 global test acc  33.0800
Round 17 global test acc  26.2900
Round 18 global test acc  23.2100
Round 19 global test acc  24.1300
Round 20 global test acc  34.0900
Round 21 global test acc  19.7500
Round 22 global test acc  32.4800
Round 23 global test acc  32.5100
Round 24 global test acc  28.0000
Round 25 global test acc  26.6900
Round 26 global test acc  32.6500
Round 27 global test acc  23.7700
Round 28 global test acc  25.0800
Round 29 global test acc  25.8400
Round 30 global test acc  22.6900
Round 31 global test acc  32.9700
Round 32 global test acc  23.5200
Round 33 global test acc  25.5900
Round 34 global test acc  28.3500
Round 35 global test acc  30.7100
Round 36 global test acc  33.5900
Round 37 global test acc  36.3600
Round 38 global test acc  33.6500
Round 39 global test acc  24.8600
Round 40 global test acc  34.9000
Round 41 global test acc  23.1100
Round 42 global test acc  26.7700
Round 43 global test acc  28.1000
Round 44 global test acc  33.9700
Round 45 global test acc  27.6100
Round 46 global test acc  23.0500
Round 47 global test acc  24.4900
Round 48 global test acc  25.7500
Round 49 global test acc  29.5400
Round 50 global test acc  25.4200
Round 51 global test acc  24.8500
Round 52 global test acc  29.5300
Round 53 global test acc  24.9600
Round 54 global test acc  27.5000
Round 55 global test acc  25.4200
Round 56 global test acc  29.9900
Round 57 global test acc  28.3100
Round 58 global test acc  29.9000
Round 59 global test acc  26.7800
Round 60 global test acc  38.3300
Round 61 global test acc  30.5100
Round 62 global test acc  31.8100
Round 63 global test acc  26.5200
Round 64 global test acc  33.6800
Round 65 global test acc  38.2000
Round 66 global test acc  29.6200
Round 67 global test acc  22.7200
Round 68 global test acc  30.6900
Round 69 global test acc  31.1200
Round 70 global test acc  27.1000
Round 71 global test acc  27.3800
Round 72 global test acc  27.0600
Round 73 global test acc  33.5200
Round 74 global test acc  34.1300
Round 75 global test acc  30.5400
Round 76 global test acc  40.1100
Round 77 global test acc  34.0700
Round 78 global test acc  32.3100
Round 79 global test acc  36.6800
Round 80 global test acc  32.1600
Round 81 global test acc  29.9400
Round 82 global test acc  27.8400
Round 83 global test acc  24.7500
Round 84 global test acc  20.4300
Round 85 global test acc  16.8100
Round 86 global test acc  14.7300
Round 87 global test acc  15.0500
Round 88 global test acc  15.8900
Round 89 global test acc  14.2100
Round 90 global test acc  12.4500
Round 91 global test acc  11.6200
Round 92 global test acc  12.3300
Round 93 global test acc  11.7000
Round 94 global test acc  11.5500
Round 95 global test acc  11.1500
Round 96 global test acc  10.8400
Round 97 global test acc  11.8100
Round 98 global test acc  12.2000
Round 99 global test acc  11.2400
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 12, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 18, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.665, Test loss: 2.145, Test accuracy: 19.58
Round   1, Train loss: 1.166, Test loss: 1.864, Test accuracy: 36.38
Round   2, Train loss: 0.999, Test loss: 1.523, Test accuracy: 36.45
Round   3, Train loss: 1.023, Test loss: 1.289, Test accuracy: 44.92
Round   4, Train loss: 0.915, Test loss: 1.138, Test accuracy: 53.10
Round   5, Train loss: 0.888, Test loss: 1.178, Test accuracy: 51.53
Round   6, Train loss: 0.947, Test loss: 1.142, Test accuracy: 54.83
Round   7, Train loss: 0.979, Test loss: 0.978, Test accuracy: 57.43
Round   8, Train loss: 1.016, Test loss: 0.999, Test accuracy: 59.33
Round   9, Train loss: 0.848, Test loss: 0.827, Test accuracy: 65.68
Round  10, Train loss: 0.828, Test loss: 0.871, Test accuracy: 63.70
Round  11, Train loss: 0.832, Test loss: 0.853, Test accuracy: 65.33
Round  12, Train loss: 0.807, Test loss: 0.846, Test accuracy: 64.22
Round  13, Train loss: 0.809, Test loss: 0.745, Test accuracy: 68.88
Round  14, Train loss: 0.881, Test loss: 0.748, Test accuracy: 68.32
Round  15, Train loss: 0.733, Test loss: 0.711, Test accuracy: 70.23
Round  16, Train loss: 0.760, Test loss: 0.714, Test accuracy: 70.02
Round  17, Train loss: 0.843, Test loss: 0.700, Test accuracy: 70.92
Round  18, Train loss: 0.826, Test loss: 0.699, Test accuracy: 71.05
Round  19, Train loss: 0.747, Test loss: 0.697, Test accuracy: 71.22
Round  20, Train loss: 0.719, Test loss: 0.701, Test accuracy: 70.82
Round  21, Train loss: 0.770, Test loss: 0.684, Test accuracy: 71.58
Round  22, Train loss: 0.758, Test loss: 0.685, Test accuracy: 71.45
Round  23, Train loss: 0.788, Test loss: 0.680, Test accuracy: 72.07
Round  24, Train loss: 0.677, Test loss: 0.671, Test accuracy: 72.03
Round  25, Train loss: 0.802, Test loss: 0.657, Test accuracy: 72.80
Round  26, Train loss: 0.686, Test loss: 0.658, Test accuracy: 73.25
Round  27, Train loss: 0.728, Test loss: 0.654, Test accuracy: 73.27
Round  28, Train loss: 0.685, Test loss: 0.640, Test accuracy: 73.67
Round  29, Train loss: 0.568, Test loss: 0.632, Test accuracy: 74.13
Round  30, Train loss: 0.671, Test loss: 0.626, Test accuracy: 74.62
Round  31, Train loss: 0.626, Test loss: 0.629, Test accuracy: 74.43
Round  32, Train loss: 0.726, Test loss: 0.633, Test accuracy: 73.72
Round  33, Train loss: 0.602, Test loss: 0.606, Test accuracy: 74.67
Round  34, Train loss: 0.593, Test loss: 0.610, Test accuracy: 75.22
Round  35, Train loss: 0.619, Test loss: 0.610, Test accuracy: 75.27
Round  36, Train loss: 0.567, Test loss: 0.608, Test accuracy: 75.05
Round  37, Train loss: 0.577, Test loss: 0.620, Test accuracy: 74.60
Round  38, Train loss: 0.536, Test loss: 0.602, Test accuracy: 75.28
Round  39, Train loss: 0.591, Test loss: 0.597, Test accuracy: 75.48
Round  40, Train loss: 0.535, Test loss: 0.593, Test accuracy: 76.38
Round  41, Train loss: 0.684, Test loss: 0.589, Test accuracy: 76.07
Round  42, Train loss: 0.626, Test loss: 0.588, Test accuracy: 76.65
Round  43, Train loss: 0.621, Test loss: 0.589, Test accuracy: 76.90
Round  44, Train loss: 0.575, Test loss: 0.569, Test accuracy: 77.55
Round  45, Train loss: 0.571, Test loss: 0.573, Test accuracy: 77.25
Round  46, Train loss: 0.554, Test loss: 0.575, Test accuracy: 76.85
Round  47, Train loss: 0.645, Test loss: 0.574, Test accuracy: 77.07
Round  48, Train loss: 0.467, Test loss: 0.569, Test accuracy: 77.33
Round  49, Train loss: 0.641, Test loss: 0.561, Test accuracy: 77.20
Round  50, Train loss: 0.666, Test loss: 0.557, Test accuracy: 77.75
Round  51, Train loss: 0.612, Test loss: 0.560, Test accuracy: 77.80
Round  52, Train loss: 0.525, Test loss: 0.562, Test accuracy: 78.05
Round  53, Train loss: 0.518, Test loss: 0.550, Test accuracy: 78.42
Round  54, Train loss: 0.495, Test loss: 0.554, Test accuracy: 77.77
Round  55, Train loss: 0.519, Test loss: 0.544, Test accuracy: 77.90
Round  56, Train loss: 0.529, Test loss: 0.561, Test accuracy: 77.52
Round  57, Train loss: 0.580, Test loss: 0.552, Test accuracy: 78.33
Round  58, Train loss: 0.484, Test loss: 0.544, Test accuracy: 78.27
Round  59, Train loss: 0.618, Test loss: 0.542, Test accuracy: 78.32
Round  60, Train loss: 0.550, Test loss: 0.545, Test accuracy: 78.38
Round  61, Train loss: 0.391, Test loss: 0.537, Test accuracy: 78.93
Round  62, Train loss: 0.559, Test loss: 0.528, Test accuracy: 78.93
Round  63, Train loss: 0.511, Test loss: 0.530, Test accuracy: 78.92
Round  64, Train loss: 0.503, Test loss: 0.527, Test accuracy: 79.25
Round  65, Train loss: 0.488, Test loss: 0.525, Test accuracy: 79.05
Round  66, Train loss: 0.515, Test loss: 0.522, Test accuracy: 79.45
Round  67, Train loss: 0.491, Test loss: 0.530, Test accuracy: 78.98
Round  68, Train loss: 0.601, Test loss: 0.521, Test accuracy: 79.37
Round  69, Train loss: 0.518, Test loss: 0.525, Test accuracy: 79.80
Round  70, Train loss: 0.495, Test loss: 0.528, Test accuracy: 79.40
Round  71, Train loss: 0.497, Test loss: 0.523, Test accuracy: 79.25
Round  72, Train loss: 0.397, Test loss: 0.520, Test accuracy: 79.93
Round  73, Train loss: 0.410, Test loss: 0.517, Test accuracy: 79.82
Round  74, Train loss: 0.419, Test loss: 0.514, Test accuracy: 79.73
Round  75, Train loss: 0.452, Test loss: 0.517, Test accuracy: 79.52
Round  76, Train loss: 0.396, Test loss: 0.515, Test accuracy: 79.67
Round  77, Train loss: 0.407, Test loss: 0.522, Test accuracy: 79.17
Round  78, Train loss: 0.418, Test loss: 0.509, Test accuracy: 79.90
Round  79, Train loss: 0.425, Test loss: 0.512, Test accuracy: 80.17
Round  80, Train loss: 0.518, Test loss: 0.507, Test accuracy: 80.25
Round  81, Train loss: 0.464, Test loss: 0.516, Test accuracy: 80.00
Round  82, Train loss: 0.370, Test loss: 0.517, Test accuracy: 79.53
Round  83, Train loss: 0.499, Test loss: 0.513, Test accuracy: 79.65
Round  84, Train loss: 0.486, Test loss: 0.508, Test accuracy: 79.70
Round  85, Train loss: 0.531, Test loss: 0.507, Test accuracy: 80.00
Round  86, Train loss: 0.429, Test loss: 0.514, Test accuracy: 79.80
Round  87, Train loss: 0.478, Test loss: 0.509, Test accuracy: 80.43
Round  88, Train loss: 0.579, Test loss: 0.514, Test accuracy: 79.83
Round  89, Train loss: 0.427, Test loss: 0.507, Test accuracy: 80.63
Round  90, Train loss: 0.419, Test loss: 0.500, Test accuracy: 80.77
Round  91, Train loss: 0.350, Test loss: 0.504, Test accuracy: 80.75
Round  92, Train loss: 0.436, Test loss: 0.506, Test accuracy: 80.28
Round  93, Train loss: 0.386, Test loss: 0.502, Test accuracy: 80.45
Round  94, Train loss: 0.448, Test loss: 0.504, Test accuracy: 80.43
Round  95, Train loss: 0.409, Test loss: 0.507, Test accuracy: 80.45
Round  96, Train loss: 0.344, Test loss: 0.503, Test accuracy: 80.20
Round  97, Train loss: 0.387, Test loss: 0.506, Test accuracy: 80.83
Round  98, Train loss: 0.462, Test loss: 0.509, Test accuracy: 80.43
Round  99, Train loss: 0.400, Test loss: 0.505, Test accuracy: 80.68
Final Round, Train loss: 0.354, Test loss: 0.506, Test accuracy: 80.68
Average accuracy final 10 rounds: 80.52833333333332
688.6601107120514
[1.1691157817840576, 1.9979603290557861, 2.831696033477783, 3.664173126220703, 4.500782251358032, 5.331850051879883, 6.157818794250488, 6.993872404098511, 7.834314584732056, 8.67222285270691, 9.497871160507202, 10.32653522491455, 11.15910816192627, 11.961764335632324, 12.784971714019775, 13.609886646270752, 14.438775777816772, 15.24964165687561, 16.08417773246765, 16.91118574142456, 17.7290096282959, 18.54952597618103, 19.379664659500122, 20.203872203826904, 21.025602340698242, 21.849006414413452, 22.667400121688843, 23.484631538391113, 24.29987144470215, 25.129433155059814, 25.958770036697388, 26.77833318710327, 27.608477115631104, 28.434661388397217, 29.253166437149048, 30.062192916870117, 30.889089107513428, 31.704120874404907, 32.51961803436279, 33.333245038986206, 34.15559101104736, 34.98052144050598, 35.79866623878479, 36.62315487861633, 37.456432819366455, 38.28151273727417, 39.10568380355835, 39.92973756790161, 40.75503993034363, 41.58558654785156, 42.386687994003296, 43.21142506599426, 44.018826961517334, 44.83460307121277, 45.653441190719604, 46.47588610649109, 47.29243564605713, 48.10516858100891, 48.932780027389526, 49.7567937374115, 50.56644034385681, 51.404484272003174, 52.24587392807007, 53.0948965549469, 53.927457094192505, 54.7616400718689, 55.58040452003479, 56.39995288848877, 57.238916635513306, 58.08391809463501, 58.9140989780426, 59.7456533908844, 60.56824588775635, 61.40465497970581, 62.23969030380249, 63.07215857505798, 63.902127504348755, 64.73194217681885, 65.5460786819458, 66.3782889842987, 67.21392321586609, 68.04000949859619, 68.87662291526794, 69.71227765083313, 70.53985166549683, 71.37113690376282, 72.20140290260315, 73.0534029006958, 73.88813924789429, 74.70796751976013, 75.52906060218811, 76.35203075408936, 77.16549372673035, 77.98711895942688, 78.89609789848328, 79.75376343727112, 80.57970452308655, 81.41456961631775, 82.24317479133606, 83.08754205703735, 84.41073060035706]
[19.583333333333332, 36.38333333333333, 36.45, 44.916666666666664, 53.1, 51.53333333333333, 54.833333333333336, 57.43333333333333, 59.333333333333336, 65.68333333333334, 63.7, 65.33333333333333, 64.21666666666667, 68.88333333333334, 68.31666666666666, 70.23333333333333, 70.01666666666667, 70.91666666666667, 71.05, 71.21666666666667, 70.81666666666666, 71.58333333333333, 71.45, 72.06666666666666, 72.03333333333333, 72.8, 73.25, 73.26666666666667, 73.66666666666667, 74.13333333333334, 74.61666666666666, 74.43333333333334, 73.71666666666667, 74.66666666666667, 75.21666666666667, 75.26666666666667, 75.05, 74.6, 75.28333333333333, 75.48333333333333, 76.38333333333334, 76.06666666666666, 76.65, 76.9, 77.55, 77.25, 76.85, 77.06666666666666, 77.33333333333333, 77.2, 77.75, 77.8, 78.05, 78.41666666666667, 77.76666666666667, 77.9, 77.51666666666667, 78.33333333333333, 78.26666666666667, 78.31666666666666, 78.38333333333334, 78.93333333333334, 78.93333333333334, 78.91666666666667, 79.25, 79.05, 79.45, 78.98333333333333, 79.36666666666666, 79.8, 79.4, 79.25, 79.93333333333334, 79.81666666666666, 79.73333333333333, 79.51666666666667, 79.66666666666667, 79.16666666666667, 79.9, 80.16666666666667, 80.25, 80.0, 79.53333333333333, 79.65, 79.7, 80.0, 79.8, 80.43333333333334, 79.83333333333333, 80.63333333333334, 80.76666666666667, 80.75, 80.28333333333333, 80.45, 80.43333333333334, 80.45, 80.2, 80.83333333333333, 80.43333333333334, 80.68333333333334, 80.68333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.2000 
   Client 1, noise    level: 0.2000 
   Client 3, noise    level: 0.2000 
   Client 9, noise    level: 0.2000 
   Client 17, noise    level: 0.2000 
   Client 10, noise    level: 0.2000 
   Client 0, noise    level: 0.2000 
   Client 7, noise    level: 0.2000 
   Client 16, noise    level: 0.2000 
   Client 4, noise    level: 0.2000 
   Client 11, noise    level: 0.2000 
   Client 6, noise    level: 0.2000 
   Client 2, noise    level: 0.2000 
   Client 5, noise    level: 0.2000 
   Client 14, noise    level: 0.2000 
   Client 13, noise    level: 0.2000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.734, Test loss: 2.202, Test accuracy: 21.77
Round   1, Train loss: 1.164, Test loss: 1.978, Test accuracy: 32.90
Round   2, Train loss: 1.065, Test loss: 1.631, Test accuracy: 34.28
Round   3, Train loss: 0.996, Test loss: 1.321, Test accuracy: 43.63
Round   4, Train loss: 0.952, Test loss: 1.157, Test accuracy: 53.30
Round   5, Train loss: 0.858, Test loss: 1.214, Test accuracy: 54.02
Round   6, Train loss: 0.936, Test loss: 1.142, Test accuracy: 56.78
Round   7, Train loss: 0.905, Test loss: 0.974, Test accuracy: 60.33
Round   8, Train loss: 0.957, Test loss: 1.023, Test accuracy: 61.12
Round   9, Train loss: 0.919, Test loss: 0.818, Test accuracy: 66.47
Round  10, Train loss: 0.865, Test loss: 0.861, Test accuracy: 64.63
Round  11, Train loss: 0.837, Test loss: 0.822, Test accuracy: 67.17
Round  12, Train loss: 0.781, Test loss: 0.842, Test accuracy: 65.70
Round  13, Train loss: 0.802, Test loss: 0.724, Test accuracy: 68.72
Round  14, Train loss: 0.831, Test loss: 0.720, Test accuracy: 69.53
Round  15, Train loss: 0.685, Test loss: 0.702, Test accuracy: 69.63
Round  16, Train loss: 0.748, Test loss: 0.690, Test accuracy: 70.38
Round  17, Train loss: 0.800, Test loss: 0.687, Test accuracy: 70.90
Round  18, Train loss: 0.798, Test loss: 0.673, Test accuracy: 73.03
Round  19, Train loss: 0.652, Test loss: 0.651, Test accuracy: 73.25
Round  20, Train loss: 0.669, Test loss: 0.655, Test accuracy: 72.70
Round  21, Train loss: 0.749, Test loss: 0.645, Test accuracy: 72.32
Round  22, Train loss: 0.677, Test loss: 0.639, Test accuracy: 72.93
Round  23, Train loss: 0.636, Test loss: 0.643, Test accuracy: 72.88
Round  24, Train loss: 0.733, Test loss: 0.643, Test accuracy: 73.68
Round  25, Train loss: 0.735, Test loss: 0.633, Test accuracy: 74.27
Round  26, Train loss: 0.684, Test loss: 0.642, Test accuracy: 73.93
Round  27, Train loss: 0.616, Test loss: 0.623, Test accuracy: 73.82
Round  28, Train loss: 0.648, Test loss: 0.622, Test accuracy: 74.57
Round  29, Train loss: 0.581, Test loss: 0.613, Test accuracy: 74.90
Round  30, Train loss: 0.632, Test loss: 0.599, Test accuracy: 75.12
Round  31, Train loss: 0.604, Test loss: 0.591, Test accuracy: 75.43
Round  32, Train loss: 0.675, Test loss: 0.591, Test accuracy: 76.18
Round  33, Train loss: 0.594, Test loss: 0.578, Test accuracy: 76.27
Round  34, Train loss: 0.546, Test loss: 0.583, Test accuracy: 75.85
Round  35, Train loss: 0.623, Test loss: 0.563, Test accuracy: 76.87
Round  36, Train loss: 0.606, Test loss: 0.563, Test accuracy: 76.33
Round  37, Train loss: 0.544, Test loss: 0.566, Test accuracy: 76.15
Round  38, Train loss: 0.564, Test loss: 0.566, Test accuracy: 77.00
Round  39, Train loss: 0.540, Test loss: 0.576, Test accuracy: 76.58
Round  40, Train loss: 0.552, Test loss: 0.558, Test accuracy: 76.52
Round  41, Train loss: 0.646, Test loss: 0.557, Test accuracy: 77.30
Round  42, Train loss: 0.572, Test loss: 0.554, Test accuracy: 77.52
Round  43, Train loss: 0.591, Test loss: 0.547, Test accuracy: 78.03
Round  44, Train loss: 0.537, Test loss: 0.540, Test accuracy: 78.07
Round  45, Train loss: 0.563, Test loss: 0.547, Test accuracy: 78.13
Round  46, Train loss: 0.528, Test loss: 0.539, Test accuracy: 78.30
Round  47, Train loss: 0.574, Test loss: 0.533, Test accuracy: 78.17
Round  48, Train loss: 0.487, Test loss: 0.526, Test accuracy: 78.60
Round  49, Train loss: 0.528, Test loss: 0.531, Test accuracy: 78.67
Round  50, Train loss: 0.591, Test loss: 0.530, Test accuracy: 78.53
Round  51, Train loss: 0.585, Test loss: 0.523, Test accuracy: 78.78
Round  52, Train loss: 0.564, Test loss: 0.522, Test accuracy: 79.15
Round  53, Train loss: 0.496, Test loss: 0.518, Test accuracy: 79.35
Round  54, Train loss: 0.466, Test loss: 0.527, Test accuracy: 79.15
Round  55, Train loss: 0.473, Test loss: 0.513, Test accuracy: 79.67
Round  56, Train loss: 0.423, Test loss: 0.528, Test accuracy: 78.75
Round  57, Train loss: 0.529, Test loss: 0.518, Test accuracy: 79.27
Round  58, Train loss: 0.439, Test loss: 0.518, Test accuracy: 79.42
Round  59, Train loss: 0.609, Test loss: 0.509, Test accuracy: 79.57
Round  60, Train loss: 0.554, Test loss: 0.514, Test accuracy: 79.52
Round  61, Train loss: 0.465, Test loss: 0.506, Test accuracy: 79.85
Round  62, Train loss: 0.481, Test loss: 0.508, Test accuracy: 79.77
Round  63, Train loss: 0.532, Test loss: 0.518, Test accuracy: 79.22
Round  64, Train loss: 0.444, Test loss: 0.510, Test accuracy: 79.53
Round  65, Train loss: 0.386, Test loss: 0.504, Test accuracy: 80.03
Round  66, Train loss: 0.511, Test loss: 0.505, Test accuracy: 80.02
Round  67, Train loss: 0.422, Test loss: 0.497, Test accuracy: 80.48
Round  68, Train loss: 0.525, Test loss: 0.493, Test accuracy: 80.12
Round  69, Train loss: 0.558, Test loss: 0.493, Test accuracy: 80.43
Round  70, Train loss: 0.437, Test loss: 0.488, Test accuracy: 80.60
Round  71, Train loss: 0.366, Test loss: 0.487, Test accuracy: 80.72
Round  72, Train loss: 0.372, Test loss: 0.496, Test accuracy: 80.43
Round  73, Train loss: 0.396, Test loss: 0.493, Test accuracy: 80.20
Round  74, Train loss: 0.456, Test loss: 0.498, Test accuracy: 80.52
Round  75, Train loss: 0.497, Test loss: 0.494, Test accuracy: 80.52
Round  76, Train loss: 0.419, Test loss: 0.492, Test accuracy: 80.93
Round  77, Train loss: 0.414, Test loss: 0.491, Test accuracy: 80.75
Round  78, Train loss: 0.446, Test loss: 0.489, Test accuracy: 81.10
Round  79, Train loss: 0.458, Test loss: 0.486, Test accuracy: 81.27
Round  80, Train loss: 0.423, Test loss: 0.486, Test accuracy: 80.97
Round  81, Train loss: 0.456, Test loss: 0.479, Test accuracy: 81.35
Round  82, Train loss: 0.367, Test loss: 0.481, Test accuracy: 81.32
Round  83, Train loss: 0.476, Test loss: 0.483, Test accuracy: 81.35
Round  84, Train loss: 0.430, Test loss: 0.478, Test accuracy: 81.03
Round  85, Train loss: 0.404, Test loss: 0.479, Test accuracy: 81.12
Round  86, Train loss: 0.462, Test loss: 0.483, Test accuracy: 81.23
Round  87, Train loss: 0.410, Test loss: 0.490, Test accuracy: 80.92
Round  88, Train loss: 0.500, Test loss: 0.481, Test accuracy: 81.03
Round  89, Train loss: 0.383, Test loss: 0.477, Test accuracy: 81.08
Round  90, Train loss: 0.367, Test loss: 0.480, Test accuracy: 81.38
Round  91, Train loss: 0.339, Test loss: 0.482, Test accuracy: 81.67
Round  92, Train loss: 0.359, Test loss: 0.480, Test accuracy: 81.45
Round  93, Train loss: 0.320, Test loss: 0.483, Test accuracy: 80.88
Round  94, Train loss: 0.465, Test loss: 0.480, Test accuracy: 81.15
Round  95, Train loss: 0.417, Test loss: 0.482, Test accuracy: 81.22
Round  96, Train loss: 0.397, Test loss: 0.487, Test accuracy: 81.20
Round  97, Train loss: 0.359, Test loss: 0.479, Test accuracy: 81.50
Round  98, Train loss: 0.459, Test loss: 0.485, Test accuracy: 81.40
Round  99, Train loss: 0.400, Test loss: 0.480, Test accuracy: 81.27
Final Round, Train loss: 0.331, Test loss: 0.480, Test accuracy: 81.47
Average accuracy final 10 rounds: 81.31166666666668
1078.5384075641632
[1.1923658847808838, 2.0289721488952637, 2.8485374450683594, 3.6735596656799316, 4.492810010910034, 5.310914993286133, 6.125667095184326, 6.932551622390747, 7.750828504562378, 8.565242052078247, 9.348085880279541, 10.159742593765259, 10.987051486968994, 11.79127287864685, 12.610710620880127, 13.427132844924927, 14.229363918304443, 15.037867546081543, 15.854552745819092, 16.647887468338013, 17.458050966262817, 19.217230558395386, 20.971129179000854, 22.7450053691864, 24.489388942718506, 26.246572971343994, 28.015793323516846, 29.778822422027588, 31.445617198944092, 33.1856849193573, 34.946863889694214, 36.70699906349182, 38.42791152000427, 40.19145131111145, 41.95219159126282, 43.64753842353821, 45.382402420043945, 47.149441957473755, 48.895772218704224, 50.675607442855835, 52.43831825256348, 54.24166440963745, 55.98554587364197, 57.76456928253174, 59.5096480846405, 61.268083810806274, 63.025408029556274, 64.80804944038391, 66.46384572982788, 68.22936606407166, 69.96008348464966, 71.69924068450928, 73.45357584953308, 75.2360053062439, 76.95639824867249, 78.69195675849915, 80.39082551002502, 82.15075588226318, 83.9138731956482, 85.65148830413818, 87.37288904190063, 89.12867259979248, 90.80139708518982, 92.53228425979614, 94.13422513008118, 95.75514149665833, 97.34909415245056, 98.95040154457092, 100.52788162231445, 102.11509609222412, 103.80723094940186, 105.50020217895508, 107.18513107299805, 108.85906386375427, 110.51090145111084, 112.17032504081726, 113.77305245399475, 115.52565622329712, 117.27353477478027, 118.96651482582092, 120.71192026138306, 122.39167881011963, 124.10475587844849, 125.82170677185059, 127.48728108406067, 129.22392797470093, 130.89324116706848, 132.58308362960815, 134.27593517303467, 135.99119901657104, 137.7360873222351, 139.43758010864258, 141.17503952980042, 142.84650301933289, 144.54147863388062, 146.24455451965332, 147.90877485275269, 149.63873481750488, 151.34063911437988, 153.04491519927979, 154.3334264755249]
[21.766666666666666, 32.9, 34.28333333333333, 43.63333333333333, 53.3, 54.016666666666666, 56.78333333333333, 60.333333333333336, 61.11666666666667, 66.46666666666667, 64.63333333333334, 67.16666666666667, 65.7, 68.71666666666667, 69.53333333333333, 69.63333333333334, 70.38333333333334, 70.9, 73.03333333333333, 73.25, 72.7, 72.31666666666666, 72.93333333333334, 72.88333333333334, 73.68333333333334, 74.26666666666667, 73.93333333333334, 73.81666666666666, 74.56666666666666, 74.9, 75.11666666666666, 75.43333333333334, 76.18333333333334, 76.26666666666667, 75.85, 76.86666666666666, 76.33333333333333, 76.15, 77.0, 76.58333333333333, 76.51666666666667, 77.3, 77.51666666666667, 78.03333333333333, 78.06666666666666, 78.13333333333334, 78.3, 78.16666666666667, 78.6, 78.66666666666667, 78.53333333333333, 78.78333333333333, 79.15, 79.35, 79.15, 79.66666666666667, 78.75, 79.26666666666667, 79.41666666666667, 79.56666666666666, 79.51666666666667, 79.85, 79.76666666666667, 79.21666666666667, 79.53333333333333, 80.03333333333333, 80.01666666666667, 80.48333333333333, 80.11666666666666, 80.43333333333334, 80.6, 80.71666666666667, 80.43333333333334, 80.2, 80.51666666666667, 80.51666666666667, 80.93333333333334, 80.75, 81.1, 81.26666666666667, 80.96666666666667, 81.35, 81.31666666666666, 81.35, 81.03333333333333, 81.11666666666666, 81.23333333333333, 80.91666666666667, 81.03333333333333, 81.08333333333333, 81.38333333333334, 81.66666666666667, 81.45, 80.88333333333334, 81.15, 81.21666666666667, 81.2, 81.5, 81.4, 81.26666666666667, 81.46666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.235, Test loss: 2.166, Test accuracy: 26.13
Round   0, Global train loss: 1.235, Global test loss: 2.455, Global test accuracy: 20.00
Round   1, Train loss: 1.096, Test loss: 1.797, Test accuracy: 32.47
Round   1, Global train loss: 1.096, Global test loss: 2.398, Global test accuracy: 20.60
Round   2, Train loss: 1.156, Test loss: 1.456, Test accuracy: 38.53
Round   2, Global train loss: 1.156, Global test loss: 2.312, Global test accuracy: 16.83
Round   3, Train loss: 1.022, Test loss: 1.353, Test accuracy: 44.02
Round   3, Global train loss: 1.022, Global test loss: 2.153, Global test accuracy: 32.23
Round   4, Train loss: 1.041, Test loss: 1.335, Test accuracy: 46.30
Round   4, Global train loss: 1.041, Global test loss: 2.446, Global test accuracy: 26.07
Round   5, Train loss: 0.956, Test loss: 1.269, Test accuracy: 48.45
Round   5, Global train loss: 0.956, Global test loss: 2.267, Global test accuracy: 24.83
Round   6, Train loss: 1.013, Test loss: 1.168, Test accuracy: 52.13
Round   6, Global train loss: 1.013, Global test loss: 2.262, Global test accuracy: 30.58
Round   7, Train loss: 1.151, Test loss: 1.061, Test accuracy: 52.80
Round   7, Global train loss: 1.151, Global test loss: 2.386, Global test accuracy: 21.05
Round   8, Train loss: 1.096, Test loss: 0.925, Test accuracy: 57.52
Round   8, Global train loss: 1.096, Global test loss: 2.197, Global test accuracy: 20.00
Round   9, Train loss: 1.040, Test loss: 0.917, Test accuracy: 58.70
Round   9, Global train loss: 1.040, Global test loss: 2.235, Global test accuracy: 29.28
Round  10, Train loss: 0.960, Test loss: 0.921, Test accuracy: 58.00
Round  10, Global train loss: 0.960, Global test loss: 2.443, Global test accuracy: 22.42
Round  11, Train loss: 1.048, Test loss: 0.915, Test accuracy: 57.83
Round  11, Global train loss: 1.048, Global test loss: 2.207, Global test accuracy: 26.25
Round  12, Train loss: 0.858, Test loss: 0.924, Test accuracy: 58.92
Round  12, Global train loss: 0.858, Global test loss: 2.142, Global test accuracy: 31.48
Round  13, Train loss: 0.979, Test loss: 0.899, Test accuracy: 61.63
Round  13, Global train loss: 0.979, Global test loss: 2.154, Global test accuracy: 28.60
Round  14, Train loss: 0.847, Test loss: 0.885, Test accuracy: 62.08
Round  14, Global train loss: 0.847, Global test loss: 2.205, Global test accuracy: 26.67
Round  15, Train loss: 0.983, Test loss: 0.882, Test accuracy: 61.58
Round  15, Global train loss: 0.983, Global test loss: 2.470, Global test accuracy: 23.67
Round  16, Train loss: 1.011, Test loss: 0.893, Test accuracy: 60.18
Round  16, Global train loss: 1.011, Global test loss: 2.119, Global test accuracy: 30.47
Round  17, Train loss: 0.920, Test loss: 0.887, Test accuracy: 60.88
Round  17, Global train loss: 0.920, Global test loss: 2.075, Global test accuracy: 28.82
Round  18, Train loss: 0.912, Test loss: 0.891, Test accuracy: 61.60
Round  18, Global train loss: 0.912, Global test loss: 2.148, Global test accuracy: 25.48
Round  19, Train loss: 0.924, Test loss: 0.871, Test accuracy: 64.25
Round  19, Global train loss: 0.924, Global test loss: 2.414, Global test accuracy: 30.40
Round  20, Train loss: 1.012, Test loss: 0.879, Test accuracy: 63.77
Round  20, Global train loss: 1.012, Global test loss: 2.147, Global test accuracy: 22.57
Round  21, Train loss: 0.834, Test loss: 0.875, Test accuracy: 63.77
Round  21, Global train loss: 0.834, Global test loss: 2.180, Global test accuracy: 27.73
Round  22, Train loss: 0.887, Test loss: 0.869, Test accuracy: 63.67
Round  22, Global train loss: 0.887, Global test loss: 2.367, Global test accuracy: 23.37
Round  23, Train loss: 1.002, Test loss: 0.866, Test accuracy: 63.15
Round  23, Global train loss: 1.002, Global test loss: 2.278, Global test accuracy: 29.35
Round  24, Train loss: 0.842, Test loss: 0.876, Test accuracy: 62.93
Round  24, Global train loss: 0.842, Global test loss: 2.248, Global test accuracy: 26.73
Round  25, Train loss: 0.855, Test loss: 0.866, Test accuracy: 63.75
Round  25, Global train loss: 0.855, Global test loss: 2.140, Global test accuracy: 26.22
Round  26, Train loss: 0.815, Test loss: 0.875, Test accuracy: 63.22
Round  26, Global train loss: 0.815, Global test loss: 2.113, Global test accuracy: 22.52
Round  27, Train loss: 0.856, Test loss: 0.865, Test accuracy: 63.62
Round  27, Global train loss: 0.856, Global test loss: 2.175, Global test accuracy: 27.23
Round  28, Train loss: 0.881, Test loss: 0.873, Test accuracy: 62.98
Round  28, Global train loss: 0.881, Global test loss: 2.260, Global test accuracy: 25.23
Round  29, Train loss: 0.889, Test loss: 0.883, Test accuracy: 62.65
Round  29, Global train loss: 0.889, Global test loss: 2.317, Global test accuracy: 27.43
Round  30, Train loss: 0.912, Test loss: 0.880, Test accuracy: 63.55
Round  30, Global train loss: 0.912, Global test loss: 2.207, Global test accuracy: 29.12
Round  31, Train loss: 0.842, Test loss: 0.877, Test accuracy: 64.27
Round  31, Global train loss: 0.842, Global test loss: 2.101, Global test accuracy: 29.55
Round  32, Train loss: 0.885, Test loss: 0.885, Test accuracy: 63.27
Round  32, Global train loss: 0.885, Global test loss: 2.053, Global test accuracy: 32.63
Round  33, Train loss: 0.878, Test loss: 0.890, Test accuracy: 63.45
Round  33, Global train loss: 0.878, Global test loss: 2.381, Global test accuracy: 18.23
Round  34, Train loss: 0.683, Test loss: 0.884, Test accuracy: 63.42
Round  34, Global train loss: 0.683, Global test loss: 2.127, Global test accuracy: 30.00
Round  35, Train loss: 0.894, Test loss: 0.873, Test accuracy: 64.32
Round  35, Global train loss: 0.894, Global test loss: 2.305, Global test accuracy: 26.40
Round  36, Train loss: 0.783, Test loss: 0.879, Test accuracy: 63.92
Round  36, Global train loss: 0.783, Global test loss: 2.176, Global test accuracy: 25.08
Round  37, Train loss: 0.805, Test loss: 0.887, Test accuracy: 64.30
Round  37, Global train loss: 0.805, Global test loss: 2.066, Global test accuracy: 28.27
Round  38, Train loss: 0.732, Test loss: 0.887, Test accuracy: 64.15
Round  38, Global train loss: 0.732, Global test loss: 2.187, Global test accuracy: 24.95
Round  39, Train loss: 0.815, Test loss: 0.880, Test accuracy: 64.07
Round  39, Global train loss: 0.815, Global test loss: 2.145, Global test accuracy: 30.28
Round  40, Train loss: 0.749, Test loss: 0.888, Test accuracy: 63.40
Round  40, Global train loss: 0.749, Global test loss: 2.031, Global test accuracy: 33.33
Round  41, Train loss: 0.751, Test loss: 0.900, Test accuracy: 62.57
Round  41, Global train loss: 0.751, Global test loss: 2.112, Global test accuracy: 30.95
Round  42, Train loss: 0.736, Test loss: 0.891, Test accuracy: 63.33
Round  42, Global train loss: 0.736, Global test loss: 2.502, Global test accuracy: 20.00
Round  43, Train loss: 0.616, Test loss: 0.886, Test accuracy: 64.18
Round  43, Global train loss: 0.616, Global test loss: 2.090, Global test accuracy: 31.20
Round  44, Train loss: 0.669, Test loss: 0.911, Test accuracy: 62.93
Round  44, Global train loss: 0.669, Global test loss: 2.123, Global test accuracy: 25.68
Round  45, Train loss: 0.642, Test loss: 0.918, Test accuracy: 61.95
Round  45, Global train loss: 0.642, Global test loss: 2.109, Global test accuracy: 25.95
Round  46, Train loss: 0.591, Test loss: 0.909, Test accuracy: 62.37
Round  46, Global train loss: 0.591, Global test loss: 2.079, Global test accuracy: 29.43
Round  47, Train loss: 0.627, Test loss: 0.909, Test accuracy: 63.07
Round  47, Global train loss: 0.627, Global test loss: 2.399, Global test accuracy: 24.58
Round  48, Train loss: 0.511, Test loss: 0.937, Test accuracy: 62.65
Round  48, Global train loss: 0.511, Global test loss: 2.082, Global test accuracy: 28.55
Round  49, Train loss: 0.597, Test loss: 0.965, Test accuracy: 62.67
Round  49, Global train loss: 0.597, Global test loss: 2.284, Global test accuracy: 25.18
Round  50, Train loss: 0.627, Test loss: 0.982, Test accuracy: 61.68
Round  50, Global train loss: 0.627, Global test loss: 2.055, Global test accuracy: 32.85
Round  51, Train loss: 0.480, Test loss: 0.993, Test accuracy: 61.52
Round  51, Global train loss: 0.480, Global test loss: 2.089, Global test accuracy: 28.97
Round  52, Train loss: 0.597, Test loss: 0.989, Test accuracy: 61.98
Round  52, Global train loss: 0.597, Global test loss: 2.116, Global test accuracy: 24.83
Round  53, Train loss: 0.595, Test loss: 0.975, Test accuracy: 62.48
Round  53, Global train loss: 0.595, Global test loss: 2.232, Global test accuracy: 20.52
Round  54, Train loss: 0.586, Test loss: 1.042, Test accuracy: 61.72
Round  54, Global train loss: 0.586, Global test loss: 2.190, Global test accuracy: 34.45
Round  55, Train loss: 0.673, Test loss: 1.032, Test accuracy: 62.10
Round  55, Global train loss: 0.673, Global test loss: 2.115, Global test accuracy: 27.27
Round  56, Train loss: 0.571, Test loss: 1.030, Test accuracy: 61.52
Round  56, Global train loss: 0.571, Global test loss: 2.174, Global test accuracy: 20.03
Round  57, Train loss: 0.526, Test loss: 1.051, Test accuracy: 61.20
Round  57, Global train loss: 0.526, Global test loss: 2.187, Global test accuracy: 23.15
Round  58, Train loss: 0.521, Test loss: 1.055, Test accuracy: 61.08
Round  58, Global train loss: 0.521, Global test loss: 2.113, Global test accuracy: 31.72
Round  59, Train loss: 0.567, Test loss: 1.045, Test accuracy: 61.28
Round  59, Global train loss: 0.567, Global test loss: 2.179, Global test accuracy: 26.37
Round  60, Train loss: 0.533, Test loss: 1.041, Test accuracy: 61.02
Round  60, Global train loss: 0.533, Global test loss: 2.092, Global test accuracy: 30.12
Round  61, Train loss: 0.558, Test loss: 1.064, Test accuracy: 61.12
Round  61, Global train loss: 0.558, Global test loss: 2.162, Global test accuracy: 27.33
Round  62, Train loss: 0.460, Test loss: 1.067, Test accuracy: 61.18
Round  62, Global train loss: 0.460, Global test loss: 2.141, Global test accuracy: 28.90
Round  63, Train loss: 0.386, Test loss: 1.078, Test accuracy: 61.65
Round  63, Global train loss: 0.386, Global test loss: 2.233, Global test accuracy: 22.80
Round  64, Train loss: 0.481, Test loss: 1.099, Test accuracy: 61.40
Round  64, Global train loss: 0.481, Global test loss: 2.199, Global test accuracy: 30.00
Round  65, Train loss: 0.592, Test loss: 1.120, Test accuracy: 61.23
Round  65, Global train loss: 0.592, Global test loss: 2.127, Global test accuracy: 26.43
Round  66, Train loss: 0.387, Test loss: 1.159, Test accuracy: 60.88
Round  66, Global train loss: 0.387, Global test loss: 2.075, Global test accuracy: 26.85
Round  67, Train loss: 0.473, Test loss: 1.186, Test accuracy: 60.60
Round  67, Global train loss: 0.473, Global test loss: 2.118, Global test accuracy: 27.80
Round  68, Train loss: 0.485, Test loss: 1.207, Test accuracy: 60.15
Round  68, Global train loss: 0.485, Global test loss: 2.068, Global test accuracy: 29.93
Round  69, Train loss: 0.439, Test loss: 1.189, Test accuracy: 60.38
Round  69, Global train loss: 0.439, Global test loss: 2.049, Global test accuracy: 30.53
Round  70, Train loss: 0.443, Test loss: 1.220, Test accuracy: 59.70
Round  70, Global train loss: 0.443, Global test loss: 2.096, Global test accuracy: 31.13
Round  71, Train loss: 0.395, Test loss: 1.245, Test accuracy: 60.28
Round  71, Global train loss: 0.395, Global test loss: 2.074, Global test accuracy: 30.47
Round  72, Train loss: 0.344, Test loss: 1.235, Test accuracy: 60.17
Round  72, Global train loss: 0.344, Global test loss: 2.093, Global test accuracy: 31.67
Round  73, Train loss: 0.410, Test loss: 1.272, Test accuracy: 59.55
Round  73, Global train loss: 0.410, Global test loss: 2.177, Global test accuracy: 27.12
Round  74, Train loss: 0.435, Test loss: 1.264, Test accuracy: 60.20
Round  74, Global train loss: 0.435, Global test loss: 2.426, Global test accuracy: 29.78
Round  75, Train loss: 0.343, Test loss: 1.289, Test accuracy: 59.97
Round  75, Global train loss: 0.343, Global test loss: 2.136, Global test accuracy: 27.70
Round  76, Train loss: 0.347, Test loss: 1.337, Test accuracy: 59.85
Round  76, Global train loss: 0.347, Global test loss: 2.192, Global test accuracy: 27.60
Round  77, Train loss: 0.406, Test loss: 1.364, Test accuracy: 59.57
Round  77, Global train loss: 0.406, Global test loss: 2.092, Global test accuracy: 30.12
Round  78, Train loss: 0.376, Test loss: 1.362, Test accuracy: 59.83
Round  78, Global train loss: 0.376, Global test loss: 2.079, Global test accuracy: 29.02
Round  79, Train loss: 0.366, Test loss: 1.374, Test accuracy: 58.95
Round  79, Global train loss: 0.366, Global test loss: 2.155, Global test accuracy: 27.58
Round  80, Train loss: 0.308, Test loss: 1.372, Test accuracy: 59.85
Round  80, Global train loss: 0.308, Global test loss: 2.143, Global test accuracy: 27.13
Round  81, Train loss: 0.342, Test loss: 1.367, Test accuracy: 59.73
Round  81, Global train loss: 0.342, Global test loss: 2.092, Global test accuracy: 31.07
Round  82, Train loss: 0.329, Test loss: 1.390, Test accuracy: 58.92
Round  82, Global train loss: 0.329, Global test loss: 2.064, Global test accuracy: 27.07
Round  83, Train loss: 0.286, Test loss: 1.391, Test accuracy: 59.38
Round  83, Global train loss: 0.286, Global test loss: 2.131, Global test accuracy: 27.85
Round  84, Train loss: 0.275, Test loss: 1.402, Test accuracy: 59.45
Round  84, Global train loss: 0.275, Global test loss: 2.048, Global test accuracy: 33.60
Round  85, Train loss: 0.257, Test loss: 1.463, Test accuracy: 59.00
Round  85, Global train loss: 0.257, Global test loss: 2.089, Global test accuracy: 30.65
Round  86, Train loss: 0.358, Test loss: 1.451, Test accuracy: 59.77
Round  86, Global train loss: 0.358, Global test loss: 2.120, Global test accuracy: 28.05
Round  87, Train loss: 0.290, Test loss: 1.442, Test accuracy: 59.60
Round  87, Global train loss: 0.290, Global test loss: 2.170, Global test accuracy: 24.52
Round  88, Train loss: 0.239, Test loss: 1.479, Test accuracy: 59.20
Round  88, Global train loss: 0.239, Global test loss: 2.180, Global test accuracy: 26.82
Round  89, Train loss: 0.300, Test loss: 1.486, Test accuracy: 59.12
Round  89, Global train loss: 0.300, Global test loss: 2.148, Global test accuracy: 26.70
Round  90, Train loss: 0.279, Test loss: 1.517, Test accuracy: 59.82
Round  90, Global train loss: 0.279, Global test loss: 2.080, Global test accuracy: 33.18
Round  91, Train loss: 0.283, Test loss: 1.550, Test accuracy: 59.33
Round  91, Global train loss: 0.283, Global test loss: 2.113, Global test accuracy: 28.03
Round  92, Train loss: 0.258, Test loss: 1.593, Test accuracy: 59.10
Round  92, Global train loss: 0.258, Global test loss: 2.022, Global test accuracy: 32.93
Round  93, Train loss: 0.194, Test loss: 1.570, Test accuracy: 59.78
Round  93, Global train loss: 0.194, Global test loss: 2.042, Global test accuracy: 31.62
Round  94, Train loss: 0.205, Test loss: 1.564, Test accuracy: 60.12
Round  94, Global train loss: 0.205, Global test loss: 2.077, Global test accuracy: 32.25
Round  95, Train loss: 0.232, Test loss: 1.619, Test accuracy: 60.10
Round  95, Global train loss: 0.232, Global test loss: 2.153, Global test accuracy: 31.83
Round  96, Train loss: 0.209, Test loss: 1.632, Test accuracy: 60.32
Round  96, Global train loss: 0.209, Global test loss: 2.074, Global test accuracy: 29.70
Round  97, Train loss: 0.241, Test loss: 1.663, Test accuracy: 60.03
Round  97, Global train loss: 0.241, Global test loss: 2.110, Global test accuracy: 30.83
Round  98, Train loss: 0.240, Test loss: 1.614, Test accuracy: 60.02
Round  98, Global train loss: 0.240, Global test loss: 2.080, Global test accuracy: 26.60
Round  99, Train loss: 0.197, Test loss: 1.624, Test accuracy: 60.60
Round  99, Global train loss: 0.197, Global test loss: 2.080, Global test accuracy: 31.80
Final Round, Train loss: 0.196, Test loss: 1.796, Test accuracy: 58.77
Final Round, Global train loss: 0.196, Global test loss: 2.080, Global test accuracy: 31.80
Average accuracy final 10 rounds: 59.92166666666667 

Average global accuracy final 10 rounds: 30.87833333333333 

885.9959774017334
[1.0071678161621094, 2.0143356323242188, 2.721331834793091, 3.428328037261963, 4.087444067001343, 4.746560096740723, 5.395206689834595, 6.043853282928467, 6.69838285446167, 7.352912425994873, 8.008028030395508, 8.663143634796143, 9.320222854614258, 9.977302074432373, 10.638810157775879, 11.300318241119385, 11.952118873596191, 12.603919506072998, 13.2571542263031, 13.910388946533203, 14.563039541244507, 15.21569013595581, 15.870235443115234, 16.524780750274658, 17.180042028427124, 17.83530330657959, 18.490284204483032, 19.145265102386475, 19.793439865112305, 20.441614627838135, 21.09288477897644, 21.744154930114746, 22.395247220993042, 23.046339511871338, 23.700353622436523, 24.35436773300171, 25.00448513031006, 25.654602527618408, 26.297224044799805, 26.9398455619812, 27.577697038650513, 28.215548515319824, 28.848039150238037, 29.48052978515625, 30.114011526107788, 30.747493267059326, 31.39227867126465, 32.03706407546997, 32.68728494644165, 33.33750581741333, 33.98706555366516, 34.63662528991699, 35.28565335273743, 35.93468141555786, 36.59404802322388, 37.25341463088989, 37.88081359863281, 38.50821256637573, 39.214637756347656, 39.92106294631958, 40.54584097862244, 41.17061901092529, 41.81186294555664, 42.45310688018799, 43.11120915412903, 43.76931142807007, 44.402841091156006, 45.03637075424194, 45.74044227600098, 46.44451379776001, 47.11353278160095, 47.782551765441895, 48.41892337799072, 49.05529499053955, 49.67478919029236, 50.294283390045166, 50.92755961418152, 51.56083583831787, 52.19122385978699, 52.8216118812561, 53.464179277420044, 54.106746673583984, 54.73416256904602, 55.36157846450806, 56.00998497009277, 56.65839147567749, 57.31096076965332, 57.96353006362915, 58.60107135772705, 59.23861265182495, 59.87561368942261, 60.512614727020264, 61.13716268539429, 61.76171064376831, 62.40232729911804, 63.04294395446777, 63.69155144691467, 64.34015893936157, 64.98676991462708, 65.63338088989258, 66.2829978466034, 66.93261480331421, 67.57744812965393, 68.22228145599365, 68.85787868499756, 69.49347591400146, 70.13996362686157, 70.78645133972168, 71.43594241142273, 72.08543348312378, 72.72642350196838, 73.36741352081299, 74.0170829296112, 74.66675233840942, 75.31517815589905, 75.96360397338867, 76.61672043800354, 77.26983690261841, 77.92055320739746, 78.57126951217651, 79.22022581100464, 79.86918210983276, 80.51936721801758, 81.16955232620239, 81.81758141517639, 82.46561050415039, 83.1017119884491, 83.7378134727478, 84.37883925437927, 85.01986503601074, 85.66662454605103, 86.31338405609131, 86.96268773078918, 87.61199140548706, 88.25573229789734, 88.89947319030762, 89.53622198104858, 90.17297077178955, 90.81907272338867, 91.4651746749878, 92.11087131500244, 92.75656795501709, 93.40714836120605, 94.05772876739502, 94.70818495750427, 95.35864114761353, 96.00449872016907, 96.65035629272461, 97.29104471206665, 97.93173313140869, 98.57803678512573, 99.22434043884277, 99.85738039016724, 100.4904203414917, 101.13238883018494, 101.77435731887817, 102.41771674156189, 103.0610761642456, 103.68884348869324, 104.31661081314087, 104.96337676048279, 105.6101427078247, 106.25097489356995, 106.89180707931519, 107.54128980636597, 108.19077253341675, 108.83832573890686, 109.48587894439697, 110.13878846168518, 110.79169797897339, 111.43209910392761, 112.07250022888184, 112.71787905693054, 113.36325788497925, 113.99594926834106, 114.62864065170288, 115.2858350276947, 115.94302940368652, 116.59572958946228, 117.24842977523804, 117.8903591632843, 118.53228855133057, 119.18141841888428, 119.83054828643799, 120.47042059898376, 121.11029291152954, 121.76028442382812, 122.41027593612671, 123.03851175308228, 123.66674757003784, 124.3122968673706, 124.95784616470337, 125.60566568374634, 126.2534852027893, 126.89442014694214, 127.53535509109497, 128.19074201583862, 128.84612894058228, 129.49658608436584, 130.1470432281494, 131.45163249969482, 132.75622177124023]
[26.133333333333333, 26.133333333333333, 32.46666666666667, 32.46666666666667, 38.53333333333333, 38.53333333333333, 44.016666666666666, 44.016666666666666, 46.3, 46.3, 48.45, 48.45, 52.13333333333333, 52.13333333333333, 52.8, 52.8, 57.516666666666666, 57.516666666666666, 58.7, 58.7, 58.0, 58.0, 57.833333333333336, 57.833333333333336, 58.916666666666664, 58.916666666666664, 61.63333333333333, 61.63333333333333, 62.083333333333336, 62.083333333333336, 61.583333333333336, 61.583333333333336, 60.18333333333333, 60.18333333333333, 60.88333333333333, 60.88333333333333, 61.6, 61.6, 64.25, 64.25, 63.766666666666666, 63.766666666666666, 63.766666666666666, 63.766666666666666, 63.666666666666664, 63.666666666666664, 63.15, 63.15, 62.93333333333333, 62.93333333333333, 63.75, 63.75, 63.21666666666667, 63.21666666666667, 63.61666666666667, 63.61666666666667, 62.983333333333334, 62.983333333333334, 62.65, 62.65, 63.55, 63.55, 64.26666666666667, 64.26666666666667, 63.266666666666666, 63.266666666666666, 63.45, 63.45, 63.416666666666664, 63.416666666666664, 64.31666666666666, 64.31666666666666, 63.916666666666664, 63.916666666666664, 64.3, 64.3, 64.15, 64.15, 64.06666666666666, 64.06666666666666, 63.4, 63.4, 62.56666666666667, 62.56666666666667, 63.333333333333336, 63.333333333333336, 64.18333333333334, 64.18333333333334, 62.93333333333333, 62.93333333333333, 61.95, 61.95, 62.36666666666667, 62.36666666666667, 63.06666666666667, 63.06666666666667, 62.65, 62.65, 62.666666666666664, 62.666666666666664, 61.68333333333333, 61.68333333333333, 61.516666666666666, 61.516666666666666, 61.983333333333334, 61.983333333333334, 62.483333333333334, 62.483333333333334, 61.71666666666667, 61.71666666666667, 62.1, 62.1, 61.516666666666666, 61.516666666666666, 61.2, 61.2, 61.083333333333336, 61.083333333333336, 61.28333333333333, 61.28333333333333, 61.016666666666666, 61.016666666666666, 61.11666666666667, 61.11666666666667, 61.18333333333333, 61.18333333333333, 61.65, 61.65, 61.4, 61.4, 61.233333333333334, 61.233333333333334, 60.88333333333333, 60.88333333333333, 60.6, 60.6, 60.15, 60.15, 60.38333333333333, 60.38333333333333, 59.7, 59.7, 60.28333333333333, 60.28333333333333, 60.166666666666664, 60.166666666666664, 59.55, 59.55, 60.2, 60.2, 59.96666666666667, 59.96666666666667, 59.85, 59.85, 59.56666666666667, 59.56666666666667, 59.833333333333336, 59.833333333333336, 58.95, 58.95, 59.85, 59.85, 59.733333333333334, 59.733333333333334, 58.916666666666664, 58.916666666666664, 59.38333333333333, 59.38333333333333, 59.45, 59.45, 59.0, 59.0, 59.766666666666666, 59.766666666666666, 59.6, 59.6, 59.2, 59.2, 59.11666666666667, 59.11666666666667, 59.81666666666667, 59.81666666666667, 59.333333333333336, 59.333333333333336, 59.1, 59.1, 59.78333333333333, 59.78333333333333, 60.11666666666667, 60.11666666666667, 60.1, 60.1, 60.31666666666667, 60.31666666666667, 60.03333333333333, 60.03333333333333, 60.016666666666666, 60.016666666666666, 60.6, 60.6, 58.766666666666666, 58.766666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.170, Test loss: 2.026, Test accuracy: 30.38
Round   0, Global train loss: 1.170, Global test loss: 2.305, Global test accuracy: 23.75
Round   1, Train loss: 1.006, Test loss: 1.740, Test accuracy: 38.38
Round   1, Global train loss: 1.006, Global test loss: 2.408, Global test accuracy: 25.28
Round   2, Train loss: 0.910, Test loss: 1.382, Test accuracy: 48.72
Round   2, Global train loss: 0.910, Global test loss: 2.217, Global test accuracy: 28.90
Round   3, Train loss: 0.880, Test loss: 1.205, Test accuracy: 51.42
Round   3, Global train loss: 0.880, Global test loss: 1.985, Global test accuracy: 31.37
Round   4, Train loss: 0.863, Test loss: 1.171, Test accuracy: 55.13
Round   4, Global train loss: 0.863, Global test loss: 2.252, Global test accuracy: 32.27
Round   5, Train loss: 0.763, Test loss: 1.094, Test accuracy: 57.83
Round   5, Global train loss: 0.763, Global test loss: 2.049, Global test accuracy: 37.05
Round   6, Train loss: 0.794, Test loss: 0.950, Test accuracy: 63.48
Round   6, Global train loss: 0.794, Global test loss: 2.012, Global test accuracy: 37.37
Round   7, Train loss: 0.823, Test loss: 0.851, Test accuracy: 65.63
Round   7, Global train loss: 0.823, Global test loss: 2.119, Global test accuracy: 29.93
Round   8, Train loss: 0.769, Test loss: 0.735, Test accuracy: 69.32
Round   8, Global train loss: 0.769, Global test loss: 1.969, Global test accuracy: 38.37
Round   9, Train loss: 0.689, Test loss: 0.722, Test accuracy: 69.87
Round   9, Global train loss: 0.689, Global test loss: 1.985, Global test accuracy: 36.52
Round  10, Train loss: 0.661, Test loss: 0.709, Test accuracy: 70.53
Round  10, Global train loss: 0.661, Global test loss: 2.045, Global test accuracy: 36.18
Round  11, Train loss: 0.725, Test loss: 0.679, Test accuracy: 72.03
Round  11, Global train loss: 0.725, Global test loss: 1.661, Global test accuracy: 40.50
Round  12, Train loss: 0.679, Test loss: 0.668, Test accuracy: 73.17
Round  12, Global train loss: 0.679, Global test loss: 1.667, Global test accuracy: 43.05
Round  13, Train loss: 0.676, Test loss: 0.657, Test accuracy: 73.92
Round  13, Global train loss: 0.676, Global test loss: 1.658, Global test accuracy: 44.48
Round  14, Train loss: 0.748, Test loss: 0.652, Test accuracy: 73.65
Round  14, Global train loss: 0.748, Global test loss: 1.768, Global test accuracy: 44.80
Round  15, Train loss: 0.664, Test loss: 0.637, Test accuracy: 74.57
Round  15, Global train loss: 0.664, Global test loss: 1.972, Global test accuracy: 38.22
Round  16, Train loss: 0.694, Test loss: 0.628, Test accuracy: 75.17
Round  16, Global train loss: 0.694, Global test loss: 1.624, Global test accuracy: 44.73
Round  17, Train loss: 0.725, Test loss: 0.631, Test accuracy: 75.30
Round  17, Global train loss: 0.725, Global test loss: 1.558, Global test accuracy: 46.95
Round  18, Train loss: 0.643, Test loss: 0.614, Test accuracy: 76.35
Round  18, Global train loss: 0.643, Global test loss: 1.556, Global test accuracy: 44.90
Round  19, Train loss: 0.577, Test loss: 0.618, Test accuracy: 76.42
Round  19, Global train loss: 0.577, Global test loss: 1.962, Global test accuracy: 38.38
Round  20, Train loss: 0.587, Test loss: 0.635, Test accuracy: 75.58
Round  20, Global train loss: 0.587, Global test loss: 1.542, Global test accuracy: 49.52
Round  21, Train loss: 0.684, Test loss: 0.622, Test accuracy: 76.07
Round  21, Global train loss: 0.684, Global test loss: 1.658, Global test accuracy: 44.50
Round  22, Train loss: 0.517, Test loss: 0.617, Test accuracy: 76.12
Round  22, Global train loss: 0.517, Global test loss: 1.730, Global test accuracy: 45.33
Round  23, Train loss: 0.527, Test loss: 0.597, Test accuracy: 77.03
Round  23, Global train loss: 0.527, Global test loss: 1.637, Global test accuracy: 45.57
Round  24, Train loss: 0.540, Test loss: 0.619, Test accuracy: 76.32
Round  24, Global train loss: 0.540, Global test loss: 1.611, Global test accuracy: 45.30
Round  25, Train loss: 0.664, Test loss: 0.614, Test accuracy: 76.17
Round  25, Global train loss: 0.664, Global test loss: 1.479, Global test accuracy: 47.27
Round  26, Train loss: 0.495, Test loss: 0.580, Test accuracy: 77.55
Round  26, Global train loss: 0.495, Global test loss: 1.365, Global test accuracy: 52.88
Round  27, Train loss: 0.463, Test loss: 0.589, Test accuracy: 77.40
Round  27, Global train loss: 0.463, Global test loss: 1.395, Global test accuracy: 51.53
Round  28, Train loss: 0.544, Test loss: 0.584, Test accuracy: 77.30
Round  28, Global train loss: 0.544, Global test loss: 1.714, Global test accuracy: 46.52
Round  29, Train loss: 0.627, Test loss: 0.561, Test accuracy: 78.03
Round  29, Global train loss: 0.627, Global test loss: 1.702, Global test accuracy: 44.75
Round  30, Train loss: 0.479, Test loss: 0.549, Test accuracy: 78.40
Round  30, Global train loss: 0.479, Global test loss: 1.542, Global test accuracy: 49.78
Round  31, Train loss: 0.570, Test loss: 0.558, Test accuracy: 78.18
Round  31, Global train loss: 0.570, Global test loss: 1.400, Global test accuracy: 53.55
Round  32, Train loss: 0.513, Test loss: 0.572, Test accuracy: 77.72
Round  32, Global train loss: 0.513, Global test loss: 1.388, Global test accuracy: 52.72
Round  33, Train loss: 0.552, Test loss: 0.582, Test accuracy: 77.93
Round  33, Global train loss: 0.552, Global test loss: 1.621, Global test accuracy: 42.70
Round  34, Train loss: 0.583, Test loss: 0.582, Test accuracy: 77.52
Round  34, Global train loss: 0.583, Global test loss: 1.519, Global test accuracy: 51.85
Round  35, Train loss: 0.510, Test loss: 0.561, Test accuracy: 78.30
Round  35, Global train loss: 0.510, Global test loss: 1.570, Global test accuracy: 47.80
Round  36, Train loss: 0.473, Test loss: 0.560, Test accuracy: 78.53
Round  36, Global train loss: 0.473, Global test loss: 1.414, Global test accuracy: 52.43
Round  37, Train loss: 0.582, Test loss: 0.566, Test accuracy: 78.42
Round  37, Global train loss: 0.582, Global test loss: 1.446, Global test accuracy: 50.80
Round  38, Train loss: 0.541, Test loss: 0.560, Test accuracy: 78.72
Round  38, Global train loss: 0.541, Global test loss: 1.415, Global test accuracy: 50.03
Round  39, Train loss: 0.425, Test loss: 0.566, Test accuracy: 78.95
Round  39, Global train loss: 0.425, Global test loss: 1.570, Global test accuracy: 48.25
Round  40, Train loss: 0.471, Test loss: 0.600, Test accuracy: 77.67
Round  40, Global train loss: 0.471, Global test loss: 1.221, Global test accuracy: 57.72
Round  41, Train loss: 0.438, Test loss: 0.550, Test accuracy: 79.15
Round  41, Global train loss: 0.438, Global test loss: 1.434, Global test accuracy: 50.40
Round  42, Train loss: 0.432, Test loss: 0.539, Test accuracy: 79.18
Round  42, Global train loss: 0.432, Global test loss: 1.757, Global test accuracy: 51.62
Round  43, Train loss: 0.447, Test loss: 0.542, Test accuracy: 79.65
Round  43, Global train loss: 0.447, Global test loss: 1.345, Global test accuracy: 53.50
Round  44, Train loss: 0.346, Test loss: 0.546, Test accuracy: 79.83
Round  44, Global train loss: 0.346, Global test loss: 1.394, Global test accuracy: 54.47
Round  45, Train loss: 0.519, Test loss: 0.534, Test accuracy: 80.40
Round  45, Global train loss: 0.519, Global test loss: 1.351, Global test accuracy: 54.75
Round  46, Train loss: 0.417, Test loss: 0.536, Test accuracy: 80.63
Round  46, Global train loss: 0.417, Global test loss: 1.245, Global test accuracy: 56.63
Round  47, Train loss: 0.417, Test loss: 0.531, Test accuracy: 80.88
Round  47, Global train loss: 0.417, Global test loss: 1.633, Global test accuracy: 51.23
Round  48, Train loss: 0.413, Test loss: 0.535, Test accuracy: 81.02
Round  48, Global train loss: 0.413, Global test loss: 1.323, Global test accuracy: 56.62
Round  49, Train loss: 0.466, Test loss: 0.533, Test accuracy: 81.00
Round  49, Global train loss: 0.466, Global test loss: 1.599, Global test accuracy: 49.75
Round  50, Train loss: 0.434, Test loss: 0.544, Test accuracy: 80.68
Round  50, Global train loss: 0.434, Global test loss: 1.243, Global test accuracy: 57.70
Round  51, Train loss: 0.375, Test loss: 0.550, Test accuracy: 80.32
Round  51, Global train loss: 0.375, Global test loss: 1.347, Global test accuracy: 54.20
Round  52, Train loss: 0.468, Test loss: 0.565, Test accuracy: 79.18
Round  52, Global train loss: 0.468, Global test loss: 1.319, Global test accuracy: 55.32
Round  53, Train loss: 0.339, Test loss: 0.548, Test accuracy: 79.52
Round  53, Global train loss: 0.339, Global test loss: 1.558, Global test accuracy: 53.57
Round  54, Train loss: 0.298, Test loss: 0.537, Test accuracy: 79.93
Round  54, Global train loss: 0.298, Global test loss: 1.602, Global test accuracy: 52.13
Round  55, Train loss: 0.459, Test loss: 0.553, Test accuracy: 80.12
Round  55, Global train loss: 0.459, Global test loss: 1.357, Global test accuracy: 53.97
Round  56, Train loss: 0.457, Test loss: 0.565, Test accuracy: 79.77
Round  56, Global train loss: 0.457, Global test loss: 1.484, Global test accuracy: 53.87
Round  57, Train loss: 0.374, Test loss: 0.567, Test accuracy: 79.77
Round  57, Global train loss: 0.374, Global test loss: 1.436, Global test accuracy: 53.68
Round  58, Train loss: 0.397, Test loss: 0.551, Test accuracy: 80.07
Round  58, Global train loss: 0.397, Global test loss: 1.455, Global test accuracy: 53.82
Round  59, Train loss: 0.385, Test loss: 0.577, Test accuracy: 79.70
Round  59, Global train loss: 0.385, Global test loss: 1.366, Global test accuracy: 56.53
Round  60, Train loss: 0.387, Test loss: 0.566, Test accuracy: 80.10
Round  60, Global train loss: 0.387, Global test loss: 1.349, Global test accuracy: 56.70
Round  61, Train loss: 0.355, Test loss: 0.554, Test accuracy: 80.42
Round  61, Global train loss: 0.355, Global test loss: 1.463, Global test accuracy: 54.83
Round  62, Train loss: 0.398, Test loss: 0.567, Test accuracy: 79.80
Round  62, Global train loss: 0.398, Global test loss: 1.491, Global test accuracy: 52.12
Round  63, Train loss: 0.340, Test loss: 0.574, Test accuracy: 79.50
Round  63, Global train loss: 0.340, Global test loss: 1.592, Global test accuracy: 54.27
Round  64, Train loss: 0.324, Test loss: 0.562, Test accuracy: 79.62
Round  64, Global train loss: 0.324, Global test loss: 1.759, Global test accuracy: 50.17
Round  65, Train loss: 0.437, Test loss: 0.535, Test accuracy: 81.07
Round  65, Global train loss: 0.437, Global test loss: 1.549, Global test accuracy: 53.47
Round  66, Train loss: 0.354, Test loss: 0.511, Test accuracy: 82.02
Round  66, Global train loss: 0.354, Global test loss: 1.381, Global test accuracy: 58.75
Round  67, Train loss: 0.389, Test loss: 0.538, Test accuracy: 80.82
Round  67, Global train loss: 0.389, Global test loss: 1.237, Global test accuracy: 58.80
Round  68, Train loss: 0.351, Test loss: 0.543, Test accuracy: 80.62
Round  68, Global train loss: 0.351, Global test loss: 1.313, Global test accuracy: 57.20
Round  69, Train loss: 0.376, Test loss: 0.541, Test accuracy: 81.65
Round  69, Global train loss: 0.376, Global test loss: 1.326, Global test accuracy: 58.32
Round  70, Train loss: 0.303, Test loss: 0.545, Test accuracy: 81.55
Round  70, Global train loss: 0.303, Global test loss: 1.456, Global test accuracy: 55.45
Round  71, Train loss: 0.311, Test loss: 0.551, Test accuracy: 81.40
Round  71, Global train loss: 0.311, Global test loss: 1.311, Global test accuracy: 58.57
Round  72, Train loss: 0.311, Test loss: 0.544, Test accuracy: 81.70
Round  72, Global train loss: 0.311, Global test loss: 1.332, Global test accuracy: 57.83
Round  73, Train loss: 0.283, Test loss: 0.536, Test accuracy: 82.60
Round  73, Global train loss: 0.283, Global test loss: 1.428, Global test accuracy: 56.68
Round  74, Train loss: 0.291, Test loss: 0.531, Test accuracy: 82.75
Round  74, Global train loss: 0.291, Global test loss: 1.893, Global test accuracy: 51.75
Round  75, Train loss: 0.342, Test loss: 0.539, Test accuracy: 82.75
Round  75, Global train loss: 0.342, Global test loss: 1.491, Global test accuracy: 54.85
Round  76, Train loss: 0.389, Test loss: 0.542, Test accuracy: 82.57
Round  76, Global train loss: 0.389, Global test loss: 1.536, Global test accuracy: 57.23
Round  77, Train loss: 0.274, Test loss: 0.538, Test accuracy: 82.47
Round  77, Global train loss: 0.274, Global test loss: 1.310, Global test accuracy: 58.78
Round  78, Train loss: 0.394, Test loss: 0.538, Test accuracy: 82.57
Round  78, Global train loss: 0.394, Global test loss: 1.369, Global test accuracy: 57.63
Round  79, Train loss: 0.298, Test loss: 0.540, Test accuracy: 82.83
Round  79, Global train loss: 0.298, Global test loss: 1.443, Global test accuracy: 56.52
Round  80, Train loss: 0.257, Test loss: 0.553, Test accuracy: 82.43
Round  80, Global train loss: 0.257, Global test loss: 1.610, Global test accuracy: 51.68
Round  81, Train loss: 0.271, Test loss: 0.560, Test accuracy: 81.97
Round  81, Global train loss: 0.271, Global test loss: 1.377, Global test accuracy: 58.27
Round  82, Train loss: 0.316, Test loss: 0.581, Test accuracy: 81.33
Round  82, Global train loss: 0.316, Global test loss: 1.421, Global test accuracy: 55.80
Round  83, Train loss: 0.200, Test loss: 0.569, Test accuracy: 81.55
Round  83, Global train loss: 0.200, Global test loss: 1.536, Global test accuracy: 56.75
Round  84, Train loss: 0.282, Test loss: 0.559, Test accuracy: 81.63
Round  84, Global train loss: 0.282, Global test loss: 1.174, Global test accuracy: 61.68
Round  85, Train loss: 0.366, Test loss: 0.549, Test accuracy: 82.57
Round  85, Global train loss: 0.366, Global test loss: 1.426, Global test accuracy: 57.00
Round  86, Train loss: 0.302, Test loss: 0.546, Test accuracy: 82.43
Round  86, Global train loss: 0.302, Global test loss: 1.250, Global test accuracy: 60.28
Round  87, Train loss: 0.247, Test loss: 0.551, Test accuracy: 81.95
Round  87, Global train loss: 0.247, Global test loss: 1.358, Global test accuracy: 59.27
Round  88, Train loss: 0.232, Test loss: 0.533, Test accuracy: 82.38
Round  88, Global train loss: 0.232, Global test loss: 1.578, Global test accuracy: 57.55
Round  89, Train loss: 0.217, Test loss: 0.527, Test accuracy: 82.53
Round  89, Global train loss: 0.217, Global test loss: 1.521, Global test accuracy: 56.75
Round  90, Train loss: 0.259, Test loss: 0.541, Test accuracy: 82.55
Round  90, Global train loss: 0.259, Global test loss: 1.393, Global test accuracy: 58.63
Round  91, Train loss: 0.246, Test loss: 0.558, Test accuracy: 82.03
Round  91, Global train loss: 0.246, Global test loss: 1.408, Global test accuracy: 57.63
Round  92, Train loss: 0.299, Test loss: 0.560, Test accuracy: 81.27
Round  92, Global train loss: 0.299, Global test loss: 1.320, Global test accuracy: 59.17
Round  93, Train loss: 0.286, Test loss: 0.563, Test accuracy: 81.20
Round  93, Global train loss: 0.286, Global test loss: 1.315, Global test accuracy: 58.80
Round  94, Train loss: 0.266, Test loss: 0.561, Test accuracy: 80.95
Round  94, Global train loss: 0.266, Global test loss: 1.259, Global test accuracy: 59.80
Round  95, Train loss: 0.208, Test loss: 0.590, Test accuracy: 80.57
Round  95, Global train loss: 0.208, Global test loss: 1.689, Global test accuracy: 55.05
Round  96, Train loss: 0.286, Test loss: 0.580, Test accuracy: 81.28
Round  96, Global train loss: 0.286, Global test loss: 1.305, Global test accuracy: 59.37
Round  97, Train loss: 0.254, Test loss: 0.585, Test accuracy: 81.32
Round  97, Global train loss: 0.254, Global test loss: 1.435, Global test accuracy: 57.92
Round  98, Train loss: 0.292, Test loss: 0.581, Test accuracy: 82.07
Round  98, Global train loss: 0.292, Global test loss: 1.426, Global test accuracy: 58.98
Round  99, Train loss: 0.292, Test loss: 0.594, Test accuracy: 81.97
Round  99, Global train loss: 0.292, Global test loss: 1.344, Global test accuracy: 58.57
Final Round, Train loss: 0.197, Test loss: 0.624, Test accuracy: 82.40
Final Round, Global train loss: 0.197, Global test loss: 1.344, Global test accuracy: 58.57
Average accuracy final 10 rounds: 81.52 

Average global accuracy final 10 rounds: 58.391666666666666 

895.1717524528503
[1.002209186553955, 2.00441837310791, 2.650801658630371, 3.297184944152832, 3.952162265777588, 4.607139587402344, 5.259080648422241, 5.911021709442139, 6.559096813201904, 7.20717191696167, 7.83782172203064, 8.46847152709961, 9.11629867553711, 9.76412582397461, 10.417792081832886, 11.071458339691162, 11.730491876602173, 12.389525413513184, 13.04404902458191, 13.698572635650635, 14.36190128326416, 15.025229930877686, 15.69236946105957, 16.359508991241455, 17.01688575744629, 17.674262523651123, 18.347373008728027, 19.02048349380493, 19.686654806137085, 20.35282611846924, 21.0118887424469, 21.67095136642456, 22.326740264892578, 22.982529163360596, 23.645598888397217, 24.308668613433838, 24.97312903404236, 25.63758945465088, 26.296075105667114, 26.95456075668335, 27.618568181991577, 28.282575607299805, 28.947551012039185, 29.612526416778564, 30.277811765670776, 30.94309711456299, 31.604970693588257, 32.266844272613525, 32.925970792770386, 33.585097312927246, 34.249468088150024, 34.9138388633728, 35.55693745613098, 36.20003604888916, 36.852108001708984, 37.50417995452881, 38.175037145614624, 38.84589433670044, 39.50445771217346, 40.163021087646484, 40.82383847236633, 41.48465585708618, 42.13711476325989, 42.789573669433594, 43.44959568977356, 44.109617710113525, 44.761127948760986, 45.41263818740845, 46.07989764213562, 46.74715709686279, 47.4410936832428, 48.1350302696228, 48.82381057739258, 49.51259088516235, 50.18455648422241, 50.85652208328247, 51.50753855705261, 52.158555030822754, 52.81856918334961, 53.478583335876465, 54.13988494873047, 54.80118656158447, 55.44148778915405, 56.08178901672363, 56.731036901474, 57.380284786224365, 58.04327344894409, 58.70626211166382, 59.37381410598755, 60.04136610031128, 60.699689626693726, 61.35801315307617, 62.01792097091675, 62.677828788757324, 63.33475399017334, 63.991679191589355, 64.64406728744507, 65.29645538330078, 65.95094203948975, 66.60542869567871, 67.26975011825562, 67.93407154083252, 68.60326886177063, 69.27246618270874, 69.91950058937073, 70.56653499603271, 71.22619295120239, 71.88585090637207, 72.55372190475464, 73.2215929031372, 73.88081192970276, 74.54003095626831, 75.18536138534546, 75.83069181442261, 76.49165058135986, 77.15260934829712, 77.82185292243958, 78.49109649658203, 79.14053106307983, 79.78996562957764, 80.44679570198059, 81.10362577438354, 81.77285480499268, 82.4420838356018, 83.10788774490356, 83.77369165420532, 84.43465232849121, 85.0956130027771, 85.76255297660828, 86.42949295043945, 87.09074258804321, 87.75199222564697, 88.4178376197815, 89.08368301391602, 89.73482346534729, 90.38596391677856, 91.04734683036804, 91.70872974395752, 92.37514352798462, 93.04155731201172, 93.70312261581421, 94.3646879196167, 95.02496433258057, 95.68524074554443, 96.33110332489014, 96.97696590423584, 97.63913321495056, 98.30130052566528, 98.93562054634094, 99.5699405670166, 100.22917461395264, 100.88840866088867, 101.55229425430298, 102.21617984771729, 102.87598133087158, 103.53578281402588, 104.19027614593506, 104.84476947784424, 105.50744819641113, 106.17012691497803, 106.83367204666138, 107.49721717834473, 108.16211342811584, 108.82700967788696, 109.4822506904602, 110.13749170303345, 110.7910087108612, 111.44452571868896, 112.10995674133301, 112.77538776397705, 113.43195080757141, 114.08851385116577, 114.7485420703888, 115.40857028961182, 116.06359767913818, 116.71862506866455, 117.37555718421936, 118.03248929977417, 118.68490648269653, 119.3373236656189, 119.99339699745178, 120.64947032928467, 121.30651140213013, 121.96355247497559, 122.60733318328857, 123.25111389160156, 123.90749382972717, 124.56387376785278, 125.2266571521759, 125.88944053649902, 126.55877709388733, 127.22811365127563, 127.8728814125061, 128.51764917373657, 129.17643284797668, 129.8352165222168, 130.49388146400452, 131.15254640579224, 131.81994819641113, 132.48734998703003, 133.81455969810486, 135.1417694091797]
[30.383333333333333, 30.383333333333333, 38.38333333333333, 38.38333333333333, 48.71666666666667, 48.71666666666667, 51.416666666666664, 51.416666666666664, 55.13333333333333, 55.13333333333333, 57.833333333333336, 57.833333333333336, 63.483333333333334, 63.483333333333334, 65.63333333333334, 65.63333333333334, 69.31666666666666, 69.31666666666666, 69.86666666666666, 69.86666666666666, 70.53333333333333, 70.53333333333333, 72.03333333333333, 72.03333333333333, 73.16666666666667, 73.16666666666667, 73.91666666666667, 73.91666666666667, 73.65, 73.65, 74.56666666666666, 74.56666666666666, 75.16666666666667, 75.16666666666667, 75.3, 75.3, 76.35, 76.35, 76.41666666666667, 76.41666666666667, 75.58333333333333, 75.58333333333333, 76.06666666666666, 76.06666666666666, 76.11666666666666, 76.11666666666666, 77.03333333333333, 77.03333333333333, 76.31666666666666, 76.31666666666666, 76.16666666666667, 76.16666666666667, 77.55, 77.55, 77.4, 77.4, 77.3, 77.3, 78.03333333333333, 78.03333333333333, 78.4, 78.4, 78.18333333333334, 78.18333333333334, 77.71666666666667, 77.71666666666667, 77.93333333333334, 77.93333333333334, 77.51666666666667, 77.51666666666667, 78.3, 78.3, 78.53333333333333, 78.53333333333333, 78.41666666666667, 78.41666666666667, 78.71666666666667, 78.71666666666667, 78.95, 78.95, 77.66666666666667, 77.66666666666667, 79.15, 79.15, 79.18333333333334, 79.18333333333334, 79.65, 79.65, 79.83333333333333, 79.83333333333333, 80.4, 80.4, 80.63333333333334, 80.63333333333334, 80.88333333333334, 80.88333333333334, 81.01666666666667, 81.01666666666667, 81.0, 81.0, 80.68333333333334, 80.68333333333334, 80.31666666666666, 80.31666666666666, 79.18333333333334, 79.18333333333334, 79.51666666666667, 79.51666666666667, 79.93333333333334, 79.93333333333334, 80.11666666666666, 80.11666666666666, 79.76666666666667, 79.76666666666667, 79.76666666666667, 79.76666666666667, 80.06666666666666, 80.06666666666666, 79.7, 79.7, 80.1, 80.1, 80.41666666666667, 80.41666666666667, 79.8, 79.8, 79.5, 79.5, 79.61666666666666, 79.61666666666666, 81.06666666666666, 81.06666666666666, 82.01666666666667, 82.01666666666667, 80.81666666666666, 80.81666666666666, 80.61666666666666, 80.61666666666666, 81.65, 81.65, 81.55, 81.55, 81.4, 81.4, 81.7, 81.7, 82.6, 82.6, 82.75, 82.75, 82.75, 82.75, 82.56666666666666, 82.56666666666666, 82.46666666666667, 82.46666666666667, 82.56666666666666, 82.56666666666666, 82.83333333333333, 82.83333333333333, 82.43333333333334, 82.43333333333334, 81.96666666666667, 81.96666666666667, 81.33333333333333, 81.33333333333333, 81.55, 81.55, 81.63333333333334, 81.63333333333334, 82.56666666666666, 82.56666666666666, 82.43333333333334, 82.43333333333334, 81.95, 81.95, 82.38333333333334, 82.38333333333334, 82.53333333333333, 82.53333333333333, 82.55, 82.55, 82.03333333333333, 82.03333333333333, 81.26666666666667, 81.26666666666667, 81.2, 81.2, 80.95, 80.95, 80.56666666666666, 80.56666666666666, 81.28333333333333, 81.28333333333333, 81.31666666666666, 81.31666666666666, 82.06666666666666, 82.06666666666666, 81.96666666666667, 81.96666666666667, 82.4, 82.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 12, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.308, Test loss: 1.966, Test accuracy: 29.90
Round   0, Global train loss: 1.308, Global test loss: 2.229, Global test accuracy: 24.70
Round   1, Train loss: 1.048, Test loss: 1.672, Test accuracy: 39.52
Round   1, Global train loss: 1.048, Global test loss: 2.245, Global test accuracy: 28.05
Round   2, Train loss: 0.943, Test loss: 1.385, Test accuracy: 48.40
Round   2, Global train loss: 0.943, Global test loss: 2.209, Global test accuracy: 29.47
Round   3, Train loss: 0.857, Test loss: 1.266, Test accuracy: 50.90
Round   3, Global train loss: 0.857, Global test loss: 2.013, Global test accuracy: 31.65
Round   4, Train loss: 0.923, Test loss: 1.256, Test accuracy: 54.58
Round   4, Global train loss: 0.923, Global test loss: 2.396, Global test accuracy: 31.83
Round   5, Train loss: 0.872, Test loss: 1.169, Test accuracy: 56.00
Round   5, Global train loss: 0.872, Global test loss: 2.156, Global test accuracy: 35.30
Round   6, Train loss: 0.865, Test loss: 1.039, Test accuracy: 61.07
Round   6, Global train loss: 0.865, Global test loss: 2.073, Global test accuracy: 37.65
Round   7, Train loss: 0.890, Test loss: 0.899, Test accuracy: 64.38
Round   7, Global train loss: 0.890, Global test loss: 2.109, Global test accuracy: 32.57
Round   8, Train loss: 0.833, Test loss: 0.763, Test accuracy: 67.70
Round   8, Global train loss: 0.833, Global test loss: 1.926, Global test accuracy: 39.35
Round   9, Train loss: 0.755, Test loss: 0.792, Test accuracy: 66.58
Round   9, Global train loss: 0.755, Global test loss: 2.011, Global test accuracy: 35.92
Round  10, Train loss: 0.780, Test loss: 0.731, Test accuracy: 68.72
Round  10, Global train loss: 0.780, Global test loss: 1.954, Global test accuracy: 39.20
Round  11, Train loss: 0.799, Test loss: 0.724, Test accuracy: 69.30
Round  11, Global train loss: 0.799, Global test loss: 1.714, Global test accuracy: 38.18
Round  12, Train loss: 0.724, Test loss: 0.709, Test accuracy: 71.37
Round  12, Global train loss: 0.724, Global test loss: 1.767, Global test accuracy: 42.85
Round  13, Train loss: 0.730, Test loss: 0.674, Test accuracy: 72.88
Round  13, Global train loss: 0.730, Global test loss: 1.763, Global test accuracy: 41.88
Round  14, Train loss: 0.730, Test loss: 0.664, Test accuracy: 73.05
Round  14, Global train loss: 0.730, Global test loss: 1.780, Global test accuracy: 44.45
Round  15, Train loss: 0.718, Test loss: 0.669, Test accuracy: 73.42
Round  15, Global train loss: 0.718, Global test loss: 1.930, Global test accuracy: 38.57
Round  16, Train loss: 0.780, Test loss: 0.669, Test accuracy: 73.65
Round  16, Global train loss: 0.780, Global test loss: 1.662, Global test accuracy: 43.25
Round  17, Train loss: 0.707, Test loss: 0.663, Test accuracy: 74.03
Round  17, Global train loss: 0.707, Global test loss: 1.542, Global test accuracy: 46.78
Round  18, Train loss: 0.677, Test loss: 0.643, Test accuracy: 75.12
Round  18, Global train loss: 0.677, Global test loss: 1.534, Global test accuracy: 45.32
Round  19, Train loss: 0.698, Test loss: 0.637, Test accuracy: 75.73
Round  19, Global train loss: 0.698, Global test loss: 1.862, Global test accuracy: 39.98
Round  20, Train loss: 0.738, Test loss: 0.648, Test accuracy: 75.42
Round  20, Global train loss: 0.738, Global test loss: 1.624, Global test accuracy: 48.02
Round  21, Train loss: 0.772, Test loss: 0.628, Test accuracy: 76.20
Round  21, Global train loss: 0.772, Global test loss: 1.551, Global test accuracy: 47.82
Round  22, Train loss: 0.621, Test loss: 0.632, Test accuracy: 76.00
Round  22, Global train loss: 0.621, Global test loss: 1.814, Global test accuracy: 43.60
Round  23, Train loss: 0.634, Test loss: 0.611, Test accuracy: 77.05
Round  23, Global train loss: 0.634, Global test loss: 1.727, Global test accuracy: 42.68
Round  24, Train loss: 0.688, Test loss: 0.613, Test accuracy: 77.07
Round  24, Global train loss: 0.688, Global test loss: 1.766, Global test accuracy: 41.77
Round  25, Train loss: 0.724, Test loss: 0.603, Test accuracy: 77.88
Round  25, Global train loss: 0.724, Global test loss: 1.449, Global test accuracy: 51.58
Round  26, Train loss: 0.603, Test loss: 0.610, Test accuracy: 77.18
Round  26, Global train loss: 0.603, Global test loss: 1.447, Global test accuracy: 51.17
Round  27, Train loss: 0.557, Test loss: 0.617, Test accuracy: 77.05
Round  27, Global train loss: 0.557, Global test loss: 1.578, Global test accuracy: 47.95
Round  28, Train loss: 0.641, Test loss: 0.635, Test accuracy: 76.20
Round  28, Global train loss: 0.641, Global test loss: 1.686, Global test accuracy: 45.77
Round  29, Train loss: 0.683, Test loss: 0.627, Test accuracy: 76.53
Round  29, Global train loss: 0.683, Global test loss: 1.575, Global test accuracy: 47.88
Round  30, Train loss: 0.659, Test loss: 0.615, Test accuracy: 77.37
Round  30, Global train loss: 0.659, Global test loss: 1.596, Global test accuracy: 48.93
Round  31, Train loss: 0.633, Test loss: 0.601, Test accuracy: 77.58
Round  31, Global train loss: 0.633, Global test loss: 1.499, Global test accuracy: 51.25
Round  32, Train loss: 0.559, Test loss: 0.594, Test accuracy: 77.60
Round  32, Global train loss: 0.559, Global test loss: 1.405, Global test accuracy: 52.67
Round  33, Train loss: 0.609, Test loss: 0.593, Test accuracy: 77.62
Round  33, Global train loss: 0.609, Global test loss: 1.691, Global test accuracy: 44.35
Round  34, Train loss: 0.561, Test loss: 0.616, Test accuracy: 76.70
Round  34, Global train loss: 0.561, Global test loss: 1.496, Global test accuracy: 51.23
Round  35, Train loss: 0.540, Test loss: 0.625, Test accuracy: 76.83
Round  35, Global train loss: 0.540, Global test loss: 1.618, Global test accuracy: 48.27
Round  36, Train loss: 0.593, Test loss: 0.627, Test accuracy: 76.82
Round  36, Global train loss: 0.593, Global test loss: 1.372, Global test accuracy: 53.72
Round  37, Train loss: 0.570, Test loss: 0.620, Test accuracy: 77.25
Round  37, Global train loss: 0.570, Global test loss: 1.374, Global test accuracy: 53.52
Round  38, Train loss: 0.610, Test loss: 0.614, Test accuracy: 77.70
Round  38, Global train loss: 0.610, Global test loss: 1.449, Global test accuracy: 51.73
Round  39, Train loss: 0.512, Test loss: 0.610, Test accuracy: 77.80
Round  39, Global train loss: 0.512, Global test loss: 1.544, Global test accuracy: 49.25
Round  40, Train loss: 0.498, Test loss: 0.601, Test accuracy: 78.65
Round  40, Global train loss: 0.498, Global test loss: 1.344, Global test accuracy: 56.15
Round  41, Train loss: 0.449, Test loss: 0.600, Test accuracy: 78.65
Round  41, Global train loss: 0.449, Global test loss: 1.550, Global test accuracy: 50.98
Round  42, Train loss: 0.521, Test loss: 0.580, Test accuracy: 79.52
Round  42, Global train loss: 0.521, Global test loss: 1.863, Global test accuracy: 47.75
Round  43, Train loss: 0.423, Test loss: 0.589, Test accuracy: 79.10
Round  43, Global train loss: 0.423, Global test loss: 1.356, Global test accuracy: 55.05
Round  44, Train loss: 0.485, Test loss: 0.581, Test accuracy: 79.42
Round  44, Global train loss: 0.485, Global test loss: 1.412, Global test accuracy: 53.33
Round  45, Train loss: 0.547, Test loss: 0.563, Test accuracy: 80.20
Round  45, Global train loss: 0.547, Global test loss: 1.322, Global test accuracy: 56.33
Round  46, Train loss: 0.483, Test loss: 0.579, Test accuracy: 79.73
Round  46, Global train loss: 0.483, Global test loss: 1.311, Global test accuracy: 56.78
Round  47, Train loss: 0.521, Test loss: 0.589, Test accuracy: 78.97
Round  47, Global train loss: 0.521, Global test loss: 1.570, Global test accuracy: 50.48
Round  48, Train loss: 0.440, Test loss: 0.575, Test accuracy: 79.47
Round  48, Global train loss: 0.440, Global test loss: 1.420, Global test accuracy: 54.88
Round  49, Train loss: 0.495, Test loss: 0.563, Test accuracy: 80.07
Round  49, Global train loss: 0.495, Global test loss: 1.572, Global test accuracy: 49.60
Round  50, Train loss: 0.470, Test loss: 0.550, Test accuracy: 80.73
Round  50, Global train loss: 0.470, Global test loss: 1.360, Global test accuracy: 56.80
Round  51, Train loss: 0.359, Test loss: 0.560, Test accuracy: 80.47
Round  51, Global train loss: 0.359, Global test loss: 1.524, Global test accuracy: 52.43
Round  52, Train loss: 0.462, Test loss: 0.557, Test accuracy: 80.83
Round  52, Global train loss: 0.462, Global test loss: 1.270, Global test accuracy: 57.50
Round  53, Train loss: 0.447, Test loss: 0.555, Test accuracy: 81.02
Round  53, Global train loss: 0.447, Global test loss: 1.627, Global test accuracy: 52.63
Round  54, Train loss: 0.421, Test loss: 0.571, Test accuracy: 80.08
Round  54, Global train loss: 0.421, Global test loss: 1.702, Global test accuracy: 50.15
Round  55, Train loss: 0.485, Test loss: 0.570, Test accuracy: 80.10
Round  55, Global train loss: 0.485, Global test loss: 1.380, Global test accuracy: 54.55
Round  56, Train loss: 0.483, Test loss: 0.582, Test accuracy: 79.88
Round  56, Global train loss: 0.483, Global test loss: 1.379, Global test accuracy: 55.08
Round  57, Train loss: 0.439, Test loss: 0.579, Test accuracy: 79.98
Round  57, Global train loss: 0.439, Global test loss: 1.454, Global test accuracy: 53.18
Round  58, Train loss: 0.428, Test loss: 0.589, Test accuracy: 80.05
Round  58, Global train loss: 0.428, Global test loss: 1.593, Global test accuracy: 51.80
Round  59, Train loss: 0.514, Test loss: 0.580, Test accuracy: 80.45
Round  59, Global train loss: 0.514, Global test loss: 1.434, Global test accuracy: 54.65
Round  60, Train loss: 0.450, Test loss: 0.583, Test accuracy: 80.20
Round  60, Global train loss: 0.450, Global test loss: 1.342, Global test accuracy: 55.80
Round  61, Train loss: 0.408, Test loss: 0.585, Test accuracy: 80.10
Round  61, Global train loss: 0.408, Global test loss: 1.541, Global test accuracy: 53.85
Round  62, Train loss: 0.451, Test loss: 0.589, Test accuracy: 79.83
Round  62, Global train loss: 0.451, Global test loss: 1.459, Global test accuracy: 54.05
Round  63, Train loss: 0.410, Test loss: 0.585, Test accuracy: 79.45
Round  63, Global train loss: 0.410, Global test loss: 1.640, Global test accuracy: 53.13
Round  64, Train loss: 0.435, Test loss: 0.593, Test accuracy: 79.75
Round  64, Global train loss: 0.435, Global test loss: 1.724, Global test accuracy: 50.63
Round  65, Train loss: 0.452, Test loss: 0.612, Test accuracy: 79.00
Round  65, Global train loss: 0.452, Global test loss: 1.753, Global test accuracy: 49.98
Round  66, Train loss: 0.394, Test loss: 0.610, Test accuracy: 79.08
Round  66, Global train loss: 0.394, Global test loss: 1.534, Global test accuracy: 55.38
Round  67, Train loss: 0.377, Test loss: 0.591, Test accuracy: 79.63
Round  67, Global train loss: 0.377, Global test loss: 1.354, Global test accuracy: 57.45
Round  68, Train loss: 0.388, Test loss: 0.595, Test accuracy: 79.97
Round  68, Global train loss: 0.388, Global test loss: 1.307, Global test accuracy: 57.47
Round  69, Train loss: 0.377, Test loss: 0.602, Test accuracy: 80.00
Round  69, Global train loss: 0.377, Global test loss: 1.401, Global test accuracy: 56.88
Round  70, Train loss: 0.396, Test loss: 0.606, Test accuracy: 79.87
Round  70, Global train loss: 0.396, Global test loss: 1.480, Global test accuracy: 56.12
Round  71, Train loss: 0.435, Test loss: 0.615, Test accuracy: 79.72
Round  71, Global train loss: 0.435, Global test loss: 1.349, Global test accuracy: 58.73
Round  72, Train loss: 0.350, Test loss: 0.608, Test accuracy: 80.15
Round  72, Global train loss: 0.350, Global test loss: 1.445, Global test accuracy: 55.97
Round  73, Train loss: 0.354, Test loss: 0.582, Test accuracy: 80.65
Round  73, Global train loss: 0.354, Global test loss: 1.374, Global test accuracy: 56.62
Round  74, Train loss: 0.319, Test loss: 0.583, Test accuracy: 80.98
Round  74, Global train loss: 0.319, Global test loss: 2.014, Global test accuracy: 48.83
Round  75, Train loss: 0.369, Test loss: 0.594, Test accuracy: 80.62
Round  75, Global train loss: 0.369, Global test loss: 1.475, Global test accuracy: 56.28
Round  76, Train loss: 0.343, Test loss: 0.583, Test accuracy: 80.80
Round  76, Global train loss: 0.343, Global test loss: 1.506, Global test accuracy: 56.52
Round  77, Train loss: 0.376, Test loss: 0.621, Test accuracy: 80.20
Round  77, Global train loss: 0.376, Global test loss: 1.434, Global test accuracy: 56.97
Round  78, Train loss: 0.382, Test loss: 0.599, Test accuracy: 80.85
Round  78, Global train loss: 0.382, Global test loss: 1.304, Global test accuracy: 58.65
Round  79, Train loss: 0.308, Test loss: 0.608, Test accuracy: 80.63
Round  79, Global train loss: 0.308, Global test loss: 1.446, Global test accuracy: 56.68
Round  80, Train loss: 0.351, Test loss: 0.572, Test accuracy: 81.50
Round  80, Global train loss: 0.351, Global test loss: 1.594, Global test accuracy: 52.02
Round  81, Train loss: 0.319, Test loss: 0.589, Test accuracy: 80.78
Round  81, Global train loss: 0.319, Global test loss: 1.400, Global test accuracy: 56.67
Round  82, Train loss: 0.370, Test loss: 0.580, Test accuracy: 80.98
Round  82, Global train loss: 0.370, Global test loss: 1.329, Global test accuracy: 58.45
Round  83, Train loss: 0.330, Test loss: 0.590, Test accuracy: 80.43
Round  83, Global train loss: 0.330, Global test loss: 1.580, Global test accuracy: 54.13
Round  84, Train loss: 0.366, Test loss: 0.568, Test accuracy: 81.07
Round  84, Global train loss: 0.366, Global test loss: 1.231, Global test accuracy: 60.70
Round  85, Train loss: 0.440, Test loss: 0.600, Test accuracy: 80.50
Round  85, Global train loss: 0.440, Global test loss: 1.363, Global test accuracy: 56.02
Round  86, Train loss: 0.322, Test loss: 0.616, Test accuracy: 80.47
Round  86, Global train loss: 0.322, Global test loss: 1.250, Global test accuracy: 60.30
Round  87, Train loss: 0.353, Test loss: 0.598, Test accuracy: 81.58
Round  87, Global train loss: 0.353, Global test loss: 1.441, Global test accuracy: 56.15
Round  88, Train loss: 0.379, Test loss: 0.592, Test accuracy: 81.13
Round  88, Global train loss: 0.379, Global test loss: 1.667, Global test accuracy: 55.38
Round  89, Train loss: 0.324, Test loss: 0.597, Test accuracy: 80.80
Round  89, Global train loss: 0.324, Global test loss: 1.600, Global test accuracy: 54.58
Round  90, Train loss: 0.343, Test loss: 0.596, Test accuracy: 80.82
Round  90, Global train loss: 0.343, Global test loss: 1.383, Global test accuracy: 58.38
Round  91, Train loss: 0.319, Test loss: 0.596, Test accuracy: 80.97
Round  91, Global train loss: 0.319, Global test loss: 1.503, Global test accuracy: 55.58
Round  92, Train loss: 0.288, Test loss: 0.592, Test accuracy: 80.85
Round  92, Global train loss: 0.288, Global test loss: 1.381, Global test accuracy: 59.12
Round  93, Train loss: 0.290, Test loss: 0.599, Test accuracy: 80.73
Round  93, Global train loss: 0.290, Global test loss: 1.410, Global test accuracy: 57.98
Round  94, Train loss: 0.290, Test loss: 0.619, Test accuracy: 80.78
Round  94, Global train loss: 0.290, Global test loss: 1.412, Global test accuracy: 58.85
Round  95, Train loss: 0.312, Test loss: 0.607, Test accuracy: 81.20
Round  95, Global train loss: 0.312, Global test loss: 1.768, Global test accuracy: 51.90
Round  96, Train loss: 0.334, Test loss: 0.625, Test accuracy: 80.58
Round  96, Global train loss: 0.334, Global test loss: 1.338, Global test accuracy: 58.00
Round  97, Train loss: 0.286, Test loss: 0.637, Test accuracy: 80.28
Round  97, Global train loss: 0.286, Global test loss: 1.458, Global test accuracy: 57.50
Round  98, Train loss: 0.349, Test loss: 0.620, Test accuracy: 80.67
Round  98, Global train loss: 0.349, Global test loss: 1.387, Global test accuracy: 58.48
Round  99, Train loss: 0.286, Test loss: 0.604, Test accuracy: 81.13
Round  99, Global train loss: 0.286, Global test loss: 1.415, Global test accuracy: 56.97
Final Round, Train loss: 0.244, Test loss: 0.633, Test accuracy: 81.97
Final Round, Global train loss: 0.244, Global test loss: 1.415, Global test accuracy: 56.97
Average accuracy final 10 rounds: 80.80166666666668 

Average global accuracy final 10 rounds: 57.276666666666664 

931.8233156204224
[1.063119888305664, 2.126239776611328, 2.832463026046753, 3.5386862754821777, 4.26095724105835, 4.9832282066345215, 5.674587726593018, 6.365947246551514, 7.115089178085327, 7.864231109619141, 8.578971862792969, 9.293712615966797, 9.994239330291748, 10.6947660446167, 11.402199745178223, 12.109633445739746, 12.819587469100952, 13.529541492462158, 14.24317455291748, 14.956807613372803, 15.65394377708435, 16.3510799407959, 17.05525016784668, 17.75942039489746, 18.474369287490845, 19.18931818008423, 19.895913124084473, 20.602508068084717, 21.310149669647217, 22.017791271209717, 22.724281549453735, 23.430771827697754, 24.1805260181427, 24.930280208587646, 25.63452672958374, 26.338773250579834, 27.049878120422363, 27.760982990264893, 28.465317487716675, 29.169651985168457, 29.87393093109131, 30.57820987701416, 31.275594234466553, 31.972978591918945, 32.75666642189026, 33.54035425186157, 34.25494861602783, 34.96954298019409, 35.66661763191223, 36.36369228363037, 37.05854678153992, 37.75340127944946, 38.46449828147888, 39.1755952835083, 39.88117003440857, 40.58674478530884, 41.28947973251343, 41.99221467971802, 42.69870471954346, 43.4051947593689, 44.11627221107483, 44.82734966278076, 45.53882932662964, 46.250308990478516, 46.953556537628174, 47.65680408477783, 48.368725299835205, 49.08064651489258, 49.7934045791626, 50.50616264343262, 51.21380138397217, 51.92144012451172, 52.63439631462097, 53.347352504730225, 54.05885028839111, 54.770348072052, 55.47851300239563, 56.18667793273926, 56.900646924972534, 57.61461591720581, 58.33899903297424, 59.063382148742676, 59.769794940948486, 60.4762077331543, 61.18249154090881, 61.88877534866333, 62.60120153427124, 63.31362771987915, 64.02598667144775, 64.73834562301636, 65.4573061466217, 66.17626667022705, 66.87995219230652, 67.58363771438599, 68.29228115081787, 69.00092458724976, 69.71134638786316, 70.42176818847656, 71.12405776977539, 71.82634735107422, 72.53345704078674, 73.24056673049927, 73.93860816955566, 74.63664960861206, 75.3487753868103, 76.06090116500854, 76.75641083717346, 77.45192050933838, 78.16092014312744, 78.8699197769165, 79.58445405960083, 80.29898834228516, 81.00389409065247, 81.70879983901978, 82.41084837913513, 83.11289691925049, 83.81827020645142, 84.52364349365234, 85.23795342445374, 85.95226335525513, 86.6588807106018, 87.36549806594849, 88.07239508628845, 88.77929210662842, 89.48696255683899, 90.19463300704956, 90.88964867591858, 91.5846643447876, 92.28327441215515, 92.9818844795227, 93.71711921691895, 94.45235395431519, 95.16421222686768, 95.87607049942017, 96.57283902168274, 97.26960754394531, 97.97759437561035, 98.68558120727539, 99.40002226829529, 100.11446332931519, 100.82462573051453, 101.53478813171387, 102.23736763000488, 102.9399471282959, 103.64953470230103, 104.35912227630615, 105.0745153427124, 105.78990840911865, 106.493891954422, 107.19787549972534, 107.89730763435364, 108.59673976898193, 109.30338096618652, 110.01002216339111, 110.72508263587952, 111.44014310836792, 112.13797092437744, 112.83579874038696, 113.53559994697571, 114.23540115356445, 114.93579602241516, 115.63619089126587, 116.34434652328491, 117.05250215530396, 117.7587149143219, 118.46492767333984, 119.18267607688904, 119.90042448043823, 120.61675214767456, 121.33307981491089, 122.02936720848083, 122.72565460205078, 123.4398455619812, 124.15403652191162, 124.8701241016388, 125.58621168136597, 126.28980684280396, 126.99340200424194, 127.69654679298401, 128.39969158172607, 129.10996675491333, 129.8202419281006, 130.52641081809998, 131.23257970809937, 131.91775107383728, 132.6029224395752, 133.31651878356934, 134.03011512756348, 134.7476851940155, 135.46525526046753, 136.16336393356323, 136.86147260665894, 137.56424832344055, 138.26702404022217, 138.98793506622314, 139.70884609222412, 140.42642760276794, 141.14400911331177, 141.8451030254364, 142.54619693756104, 143.970782995224, 145.39536905288696]
[29.9, 29.9, 39.516666666666666, 39.516666666666666, 48.4, 48.4, 50.9, 50.9, 54.583333333333336, 54.583333333333336, 56.0, 56.0, 61.06666666666667, 61.06666666666667, 64.38333333333334, 64.38333333333334, 67.7, 67.7, 66.58333333333333, 66.58333333333333, 68.71666666666667, 68.71666666666667, 69.3, 69.3, 71.36666666666666, 71.36666666666666, 72.88333333333334, 72.88333333333334, 73.05, 73.05, 73.41666666666667, 73.41666666666667, 73.65, 73.65, 74.03333333333333, 74.03333333333333, 75.11666666666666, 75.11666666666666, 75.73333333333333, 75.73333333333333, 75.41666666666667, 75.41666666666667, 76.2, 76.2, 76.0, 76.0, 77.05, 77.05, 77.06666666666666, 77.06666666666666, 77.88333333333334, 77.88333333333334, 77.18333333333334, 77.18333333333334, 77.05, 77.05, 76.2, 76.2, 76.53333333333333, 76.53333333333333, 77.36666666666666, 77.36666666666666, 77.58333333333333, 77.58333333333333, 77.6, 77.6, 77.61666666666666, 77.61666666666666, 76.7, 76.7, 76.83333333333333, 76.83333333333333, 76.81666666666666, 76.81666666666666, 77.25, 77.25, 77.7, 77.7, 77.8, 77.8, 78.65, 78.65, 78.65, 78.65, 79.51666666666667, 79.51666666666667, 79.1, 79.1, 79.41666666666667, 79.41666666666667, 80.2, 80.2, 79.73333333333333, 79.73333333333333, 78.96666666666667, 78.96666666666667, 79.46666666666667, 79.46666666666667, 80.06666666666666, 80.06666666666666, 80.73333333333333, 80.73333333333333, 80.46666666666667, 80.46666666666667, 80.83333333333333, 80.83333333333333, 81.01666666666667, 81.01666666666667, 80.08333333333333, 80.08333333333333, 80.1, 80.1, 79.88333333333334, 79.88333333333334, 79.98333333333333, 79.98333333333333, 80.05, 80.05, 80.45, 80.45, 80.2, 80.2, 80.1, 80.1, 79.83333333333333, 79.83333333333333, 79.45, 79.45, 79.75, 79.75, 79.0, 79.0, 79.08333333333333, 79.08333333333333, 79.63333333333334, 79.63333333333334, 79.96666666666667, 79.96666666666667, 80.0, 80.0, 79.86666666666666, 79.86666666666666, 79.71666666666667, 79.71666666666667, 80.15, 80.15, 80.65, 80.65, 80.98333333333333, 80.98333333333333, 80.61666666666666, 80.61666666666666, 80.8, 80.8, 80.2, 80.2, 80.85, 80.85, 80.63333333333334, 80.63333333333334, 81.5, 81.5, 80.78333333333333, 80.78333333333333, 80.98333333333333, 80.98333333333333, 80.43333333333334, 80.43333333333334, 81.06666666666666, 81.06666666666666, 80.5, 80.5, 80.46666666666667, 80.46666666666667, 81.58333333333333, 81.58333333333333, 81.13333333333334, 81.13333333333334, 80.8, 80.8, 80.81666666666666, 80.81666666666666, 80.96666666666667, 80.96666666666667, 80.85, 80.85, 80.73333333333333, 80.73333333333333, 80.78333333333333, 80.78333333333333, 81.2, 81.2, 80.58333333333333, 80.58333333333333, 80.28333333333333, 80.28333333333333, 80.66666666666667, 80.66666666666667, 81.13333333333334, 81.13333333333334, 81.96666666666667, 81.96666666666667]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.723, Test loss: 2.092, Test accuracy: 28.15
Round   1, Train loss: 1.174, Test loss: 1.917, Test accuracy: 37.82
Round   2, Train loss: 1.012, Test loss: 1.531, Test accuracy: 45.68
Round   3, Train loss: 0.832, Test loss: 1.319, Test accuracy: 50.62
Round   4, Train loss: 0.963, Test loss: 1.318, Test accuracy: 54.47
Round   5, Train loss: 0.849, Test loss: 1.263, Test accuracy: 57.00
Round   6, Train loss: 0.823, Test loss: 1.099, Test accuracy: 61.13
Round   7, Train loss: 0.908, Test loss: 0.959, Test accuracy: 64.33
Round   8, Train loss: 0.831, Test loss: 0.754, Test accuracy: 70.00
Round   9, Train loss: 0.909, Test loss: 0.755, Test accuracy: 69.85
Round  10, Train loss: 0.686, Test loss: 0.746, Test accuracy: 70.98
Round  11, Train loss: 0.844, Test loss: 0.732, Test accuracy: 71.28
Round  12, Train loss: 0.643, Test loss: 0.702, Test accuracy: 72.03
Round  13, Train loss: 0.695, Test loss: 0.677, Test accuracy: 72.73
Round  14, Train loss: 0.632, Test loss: 0.660, Test accuracy: 73.52
Round  15, Train loss: 0.876, Test loss: 0.649, Test accuracy: 73.20
Round  16, Train loss: 0.811, Test loss: 0.638, Test accuracy: 73.72
Round  17, Train loss: 0.726, Test loss: 0.626, Test accuracy: 74.65
Round  18, Train loss: 0.748, Test loss: 0.627, Test accuracy: 75.27
Round  19, Train loss: 0.743, Test loss: 0.633, Test accuracy: 74.98
Round  20, Train loss: 0.660, Test loss: 0.632, Test accuracy: 75.08
Round  21, Train loss: 0.746, Test loss: 0.625, Test accuracy: 75.88
Round  22, Train loss: 0.728, Test loss: 0.603, Test accuracy: 76.23
Round  23, Train loss: 0.582, Test loss: 0.593, Test accuracy: 75.80
Round  24, Train loss: 0.602, Test loss: 0.591, Test accuracy: 75.70
Round  25, Train loss: 0.736, Test loss: 0.576, Test accuracy: 77.20
Round  26, Train loss: 0.614, Test loss: 0.579, Test accuracy: 77.15
Round  27, Train loss: 0.538, Test loss: 0.574, Test accuracy: 77.50
Round  28, Train loss: 0.556, Test loss: 0.571, Test accuracy: 77.60
Round  29, Train loss: 0.668, Test loss: 0.566, Test accuracy: 78.10
Round  30, Train loss: 0.648, Test loss: 0.577, Test accuracy: 77.65
Round  31, Train loss: 0.521, Test loss: 0.558, Test accuracy: 78.25
Round  32, Train loss: 0.602, Test loss: 0.551, Test accuracy: 78.85
Round  33, Train loss: 0.623, Test loss: 0.550, Test accuracy: 78.60
Round  34, Train loss: 0.474, Test loss: 0.542, Test accuracy: 78.98
Round  35, Train loss: 0.634, Test loss: 0.541, Test accuracy: 78.97
Round  36, Train loss: 0.630, Test loss: 0.538, Test accuracy: 79.15
Round  37, Train loss: 0.603, Test loss: 0.544, Test accuracy: 78.60
Round  38, Train loss: 0.651, Test loss: 0.525, Test accuracy: 79.40
Round  39, Train loss: 0.447, Test loss: 0.537, Test accuracy: 79.03
Round  40, Train loss: 0.495, Test loss: 0.527, Test accuracy: 79.27
Round  41, Train loss: 0.519, Test loss: 0.521, Test accuracy: 79.95
Round  42, Train loss: 0.592, Test loss: 0.512, Test accuracy: 80.27
Round  43, Train loss: 0.524, Test loss: 0.509, Test accuracy: 80.10
Round  44, Train loss: 0.433, Test loss: 0.503, Test accuracy: 80.48
Round  45, Train loss: 0.425, Test loss: 0.495, Test accuracy: 80.77
Round  46, Train loss: 0.675, Test loss: 0.490, Test accuracy: 81.32
Round  47, Train loss: 0.553, Test loss: 0.487, Test accuracy: 81.25
Round  48, Train loss: 0.494, Test loss: 0.492, Test accuracy: 81.00
Round  49, Train loss: 0.477, Test loss: 0.484, Test accuracy: 81.85
Round  50, Train loss: 0.439, Test loss: 0.490, Test accuracy: 81.45
Round  51, Train loss: 0.430, Test loss: 0.488, Test accuracy: 81.43
Round  52, Train loss: 0.512, Test loss: 0.492, Test accuracy: 81.22
Round  53, Train loss: 0.452, Test loss: 0.486, Test accuracy: 81.37
Round  54, Train loss: 0.479, Test loss: 0.492, Test accuracy: 81.72
Round  55, Train loss: 0.505, Test loss: 0.494, Test accuracy: 81.48
Round  56, Train loss: 0.476, Test loss: 0.480, Test accuracy: 82.13
Round  57, Train loss: 0.428, Test loss: 0.488, Test accuracy: 81.17
Round  58, Train loss: 0.550, Test loss: 0.481, Test accuracy: 81.92
Round  59, Train loss: 0.446, Test loss: 0.486, Test accuracy: 81.70
Round  60, Train loss: 0.512, Test loss: 0.478, Test accuracy: 82.23
Round  61, Train loss: 0.492, Test loss: 0.479, Test accuracy: 82.18
Round  62, Train loss: 0.451, Test loss: 0.480, Test accuracy: 81.75
Round  63, Train loss: 0.404, Test loss: 0.475, Test accuracy: 82.12
Round  64, Train loss: 0.446, Test loss: 0.489, Test accuracy: 81.80
Round  65, Train loss: 0.457, Test loss: 0.477, Test accuracy: 82.02
Round  66, Train loss: 0.327, Test loss: 0.470, Test accuracy: 82.45
Round  67, Train loss: 0.466, Test loss: 0.466, Test accuracy: 82.33
Round  68, Train loss: 0.486, Test loss: 0.470, Test accuracy: 82.27
Round  69, Train loss: 0.389, Test loss: 0.466, Test accuracy: 82.57
Round  70, Train loss: 0.412, Test loss: 0.469, Test accuracy: 82.68
Round  71, Train loss: 0.363, Test loss: 0.460, Test accuracy: 82.93
Round  72, Train loss: 0.414, Test loss: 0.458, Test accuracy: 82.92
Round  73, Train loss: 0.477, Test loss: 0.453, Test accuracy: 83.13
Round  74, Train loss: 0.384, Test loss: 0.456, Test accuracy: 83.15
Round  75, Train loss: 0.452, Test loss: 0.460, Test accuracy: 82.88
Round  76, Train loss: 0.372, Test loss: 0.445, Test accuracy: 83.72
Round  77, Train loss: 0.454, Test loss: 0.446, Test accuracy: 83.37
Round  78, Train loss: 0.416, Test loss: 0.447, Test accuracy: 83.83
Round  79, Train loss: 0.422, Test loss: 0.453, Test accuracy: 83.12
Round  80, Train loss: 0.392, Test loss: 0.443, Test accuracy: 83.78
Round  81, Train loss: 0.535, Test loss: 0.445, Test accuracy: 83.80
Round  82, Train loss: 0.322, Test loss: 0.436, Test accuracy: 84.25
Round  83, Train loss: 0.406, Test loss: 0.441, Test accuracy: 84.32
Round  84, Train loss: 0.438, Test loss: 0.436, Test accuracy: 83.87
Round  85, Train loss: 0.489, Test loss: 0.440, Test accuracy: 83.78
Round  86, Train loss: 0.352, Test loss: 0.444, Test accuracy: 83.50
Round  87, Train loss: 0.427, Test loss: 0.438, Test accuracy: 83.97
Round  88, Train loss: 0.425, Test loss: 0.433, Test accuracy: 84.05
Round  89, Train loss: 0.259, Test loss: 0.434, Test accuracy: 83.83
Round  90, Train loss: 0.258, Test loss: 0.442, Test accuracy: 83.97
Round  91, Train loss: 0.468, Test loss: 0.436, Test accuracy: 83.75
Round  92, Train loss: 0.239, Test loss: 0.438, Test accuracy: 83.65
Round  93, Train loss: 0.314, Test loss: 0.439, Test accuracy: 83.82
Round  94, Train loss: 0.291, Test loss: 0.444, Test accuracy: 84.02
Round  95, Train loss: 0.344, Test loss: 0.442, Test accuracy: 83.90
Round  96, Train loss: 0.408, Test loss: 0.454, Test accuracy: 83.32
Round  97, Train loss: 0.394, Test loss: 0.454, Test accuracy: 83.05
Round  98, Train loss: 0.368, Test loss: 0.447, Test accuracy: 83.32
Round  99, Train loss: 0.348, Test loss: 0.447, Test accuracy: 84.03
Final Round, Train loss: 0.310, Test loss: 0.436, Test accuracy: 84.27
Average accuracy final 10 rounds: 83.68166666666666
655.2352387905121
[1.145857334136963, 1.9573101997375488, 2.761979579925537, 3.5502982139587402, 4.329897880554199, 5.1363630294799805, 5.950213670730591, 6.753110885620117, 7.497219562530518, 8.292932510375977, 9.097499370574951, 9.90281367301941, 10.70059084892273, 11.49166464805603, 12.281116724014282, 13.083654165267944, 13.879070520401001, 14.670826196670532, 15.46579909324646, 16.256208419799805, 17.05897092819214, 17.83449935913086, 18.61129903793335, 19.374660968780518, 20.16112494468689, 20.944034099578857, 21.74222469329834, 22.5386962890625, 23.319615125656128, 24.1108078956604, 24.90156102180481, 25.708823204040527, 26.50894045829773, 27.30688762664795, 28.073526859283447, 28.863151788711548, 29.661530017852783, 30.464049100875854, 31.245309352874756, 32.01960730552673, 32.81598258018494, 33.62729811668396, 34.42362451553345, 35.163331508636475, 35.96511507034302, 36.770992279052734, 37.55818796157837, 38.32915449142456, 39.09993553161621, 39.86727213859558, 40.6568386554718, 41.432297468185425, 42.25213932991028, 43.06619906425476, 43.854816913604736, 44.64294409751892, 45.43431305885315, 46.246432304382324, 47.05958437919617, 47.85937285423279, 48.6417932510376, 49.46965289115906, 50.283998250961304, 51.09922909736633, 51.87496089935303, 52.67046070098877, 53.48211359977722, 54.303128719329834, 55.090550899505615, 55.86276721954346, 56.662336587905884, 57.482720613479614, 58.28228259086609, 59.074387311935425, 59.87009882926941, 60.67832851409912, 61.480775356292725, 62.270063400268555, 63.07245993614197, 63.84079194068909, 64.6376223564148, 65.43898558616638, 66.22651433944702, 67.0293083190918, 67.82693243026733, 68.60172152519226, 69.43702936172485, 70.26913475990295, 71.08742451667786, 71.86721229553223, 72.64632892608643, 73.46671032905579, 74.27995419502258, 75.09092164039612, 75.86481666564941, 76.66690254211426, 77.48532199859619, 78.30043911933899, 79.0993173122406, 79.89197659492493, 81.20490050315857]
[28.15, 37.81666666666667, 45.68333333333333, 50.61666666666667, 54.46666666666667, 57.0, 61.13333333333333, 64.33333333333333, 70.0, 69.85, 70.98333333333333, 71.28333333333333, 72.03333333333333, 72.73333333333333, 73.51666666666667, 73.2, 73.71666666666667, 74.65, 75.26666666666667, 74.98333333333333, 75.08333333333333, 75.88333333333334, 76.23333333333333, 75.8, 75.7, 77.2, 77.15, 77.5, 77.6, 78.1, 77.65, 78.25, 78.85, 78.6, 78.98333333333333, 78.96666666666667, 79.15, 78.6, 79.4, 79.03333333333333, 79.26666666666667, 79.95, 80.26666666666667, 80.1, 80.48333333333333, 80.76666666666667, 81.31666666666666, 81.25, 81.0, 81.85, 81.45, 81.43333333333334, 81.21666666666667, 81.36666666666666, 81.71666666666667, 81.48333333333333, 82.13333333333334, 81.16666666666667, 81.91666666666667, 81.7, 82.23333333333333, 82.18333333333334, 81.75, 82.11666666666666, 81.8, 82.01666666666667, 82.45, 82.33333333333333, 82.26666666666667, 82.56666666666666, 82.68333333333334, 82.93333333333334, 82.91666666666667, 83.13333333333334, 83.15, 82.88333333333334, 83.71666666666667, 83.36666666666666, 83.83333333333333, 83.11666666666666, 83.78333333333333, 83.8, 84.25, 84.31666666666666, 83.86666666666666, 83.78333333333333, 83.5, 83.96666666666667, 84.05, 83.83333333333333, 83.96666666666667, 83.75, 83.65, 83.81666666666666, 84.01666666666667, 83.9, 83.31666666666666, 83.05, 83.31666666666666, 84.03333333333333, 84.26666666666667]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  16.2300
Round 1 global test acc  15.0500
Round 2 global test acc  15.8300
Round 3 global test acc  17.1600
Round 4 global test acc  13.4500
Round 5 global test acc  20.5200
Round 6 global test acc  26.6900
Round 7 global test acc  17.9500
Round 8 global test acc  25.5400
Round 9 global test acc  22.6200
Round 10 global test acc  26.0300
Round 11 global test acc  27.1000
Round 12 global test acc  20.6300
Round 13 global test acc  25.2500
Round 14 global test acc  22.9400
Round 15 global test acc  24.6500
Round 16 global test acc  26.3700
Round 17 global test acc  27.5100
Round 18 global test acc  22.9500
Round 19 global test acc  29.6900
Round 20 global test acc  20.7300
Round 21 global test acc  31.6000
Round 22 global test acc  32.0000
Round 23 global test acc  27.8400
Round 24 global test acc  25.6800
Round 25 global test acc  26.1400
Round 26 global test acc  31.1400
Round 27 global test acc  27.1000
Round 28 global test acc  26.5000
Round 29 global test acc  30.5500
Round 30 global test acc  33.3400
Round 31 global test acc  24.6700
Round 32 global test acc  25.7700
Round 33 global test acc  26.9500
Round 34 global test acc  35.2800
Round 35 global test acc  30.7900
Round 36 global test acc  24.7800
Round 37 global test acc  29.5600
Round 38 global test acc  19.6600
Round 39 global test acc  20.6800
Round 40 global test acc  24.8200
Round 41 global test acc  33.4400
Round 42 global test acc  31.4100
Round 43 global test acc  28.2300
Round 44 global test acc  27.1900
Round 45 global test acc  32.9700
Round 46 global test acc  36.5500
Round 47 global test acc  36.7600
Round 48 global test acc  24.5800
Round 49 global test acc  26.7500
Round 50 global test acc  32.2500
Round 51 global test acc  28.6100
Round 52 global test acc  35.9700
Round 53 global test acc  29.3400
Round 54 global test acc  37.3900
Round 55 global test acc  32.0600
Round 56 global test acc  26.7900
Round 57 global test acc  30.7600
Round 58 global test acc  34.5300
Round 59 global test acc  20.6300
Round 60 global test acc  36.0000
Round 61 global test acc  24.7400
Round 62 global test acc  24.5300
Round 63 global test acc  29.2400
Round 64 global test acc  33.0500
Round 65 global test acc  24.9100
Round 66 global test acc  30.5700
Round 67 global test acc  26.3800
Round 68 global test acc  22.7000
Round 69 global test acc  24.8000
Round 70 global test acc  36.3700
Round 71 global test acc  26.7900
Round 72 global test acc  30.7100
Round 73 global test acc  26.4900
Round 74 global test acc  33.2900
Round 75 global test acc  39.4700
Round 76 global test acc  32.4200
Round 77 global test acc  32.2200
Round 78 global test acc  32.7400
Round 79 global test acc  37.3500
Round 80 global test acc  33.9000
Round 81 global test acc  32.3300
Round 82 global test acc  31.9100
Round 83 global test acc  31.0500
Round 84 global test acc  29.7900
Round 85 global test acc  28.2200
Round 86 global test acc  27.4000
Round 87 global test acc  26.1300
Round 88 global test acc  24.8300
Round 89 global test acc  22.3300
Round 90 global test acc  20.7200
Round 91 global test acc  21.0200
Round 92 global test acc  20.8400
Round 93 global test acc  20.1300
Round 94 global test acc  19.0700
Round 95 global test acc  18.6800
Round 96 global test acc  17.9700
Round 97 global test acc  17.7000
Round 98 global test acc  17.9400
Round 99 global test acc  17.7500
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.753, Test loss: 2.086, Test accuracy: 28.52
Round   1, Train loss: 1.112, Test loss: 1.846, Test accuracy: 39.13
Round   2, Train loss: 1.024, Test loss: 1.486, Test accuracy: 47.47
Round   3, Train loss: 0.892, Test loss: 1.292, Test accuracy: 50.27
Round   4, Train loss: 0.845, Test loss: 1.322, Test accuracy: 53.67
Round   5, Train loss: 0.771, Test loss: 1.260, Test accuracy: 55.60
Round   6, Train loss: 0.806, Test loss: 1.157, Test accuracy: 55.92
Round   7, Train loss: 0.908, Test loss: 1.036, Test accuracy: 58.37
Round   8, Train loss: 0.722, Test loss: 0.852, Test accuracy: 61.90
Round   9, Train loss: 0.768, Test loss: 0.779, Test accuracy: 66.52
Round  10, Train loss: 0.756, Test loss: 0.750, Test accuracy: 69.20
Round  11, Train loss: 0.860, Test loss: 0.751, Test accuracy: 69.12
Round  12, Train loss: 0.710, Test loss: 0.698, Test accuracy: 71.55
Round  13, Train loss: 0.774, Test loss: 0.676, Test accuracy: 72.75
Round  14, Train loss: 0.630, Test loss: 0.659, Test accuracy: 73.72
Round  15, Train loss: 0.792, Test loss: 0.653, Test accuracy: 73.20
Round  16, Train loss: 0.869, Test loss: 0.668, Test accuracy: 72.25
Round  17, Train loss: 0.763, Test loss: 0.652, Test accuracy: 73.57
Round  18, Train loss: 0.783, Test loss: 0.641, Test accuracy: 74.07
Round  19, Train loss: 0.698, Test loss: 0.636, Test accuracy: 74.32
Round  20, Train loss: 0.676, Test loss: 0.620, Test accuracy: 74.68
Round  21, Train loss: 0.663, Test loss: 0.606, Test accuracy: 75.87
Round  22, Train loss: 0.603, Test loss: 0.595, Test accuracy: 76.07
Round  23, Train loss: 0.703, Test loss: 0.595, Test accuracy: 76.53
Round  24, Train loss: 0.668, Test loss: 0.597, Test accuracy: 76.70
Round  25, Train loss: 0.685, Test loss: 0.581, Test accuracy: 77.08
Round  26, Train loss: 0.529, Test loss: 0.579, Test accuracy: 77.35
Round  27, Train loss: 0.547, Test loss: 0.571, Test accuracy: 77.88
Round  28, Train loss: 0.527, Test loss: 0.562, Test accuracy: 78.22
Round  29, Train loss: 0.582, Test loss: 0.556, Test accuracy: 78.30
Round  30, Train loss: 0.568, Test loss: 0.554, Test accuracy: 78.60
Round  31, Train loss: 0.576, Test loss: 0.544, Test accuracy: 79.00
Round  32, Train loss: 0.474, Test loss: 0.544, Test accuracy: 79.42
Round  33, Train loss: 0.624, Test loss: 0.536, Test accuracy: 79.05
Round  34, Train loss: 0.462, Test loss: 0.530, Test accuracy: 79.40
Round  35, Train loss: 0.609, Test loss: 0.525, Test accuracy: 79.67
Round  36, Train loss: 0.554, Test loss: 0.526, Test accuracy: 79.60
Round  37, Train loss: 0.592, Test loss: 0.527, Test accuracy: 80.02
Round  38, Train loss: 0.727, Test loss: 0.514, Test accuracy: 80.50
Round  39, Train loss: 0.560, Test loss: 0.510, Test accuracy: 80.78
Round  40, Train loss: 0.516, Test loss: 0.506, Test accuracy: 80.77
Round  41, Train loss: 0.469, Test loss: 0.502, Test accuracy: 80.90
Round  42, Train loss: 0.460, Test loss: 0.492, Test accuracy: 81.23
Round  43, Train loss: 0.539, Test loss: 0.497, Test accuracy: 81.07
Round  44, Train loss: 0.440, Test loss: 0.495, Test accuracy: 81.02
Round  45, Train loss: 0.476, Test loss: 0.493, Test accuracy: 81.38
Round  46, Train loss: 0.564, Test loss: 0.492, Test accuracy: 81.08
Round  47, Train loss: 0.419, Test loss: 0.494, Test accuracy: 81.18
Round  48, Train loss: 0.398, Test loss: 0.496, Test accuracy: 80.97
Round  49, Train loss: 0.429, Test loss: 0.485, Test accuracy: 81.67
Round  50, Train loss: 0.491, Test loss: 0.496, Test accuracy: 81.48
Round  51, Train loss: 0.434, Test loss: 0.489, Test accuracy: 81.65
Round  52, Train loss: 0.488, Test loss: 0.484, Test accuracy: 81.47
Round  53, Train loss: 0.409, Test loss: 0.474, Test accuracy: 82.08
Round  54, Train loss: 0.399, Test loss: 0.485, Test accuracy: 81.30
Round  55, Train loss: 0.462, Test loss: 0.479, Test accuracy: 81.98
Round  56, Train loss: 0.425, Test loss: 0.470, Test accuracy: 82.65
Round  57, Train loss: 0.442, Test loss: 0.468, Test accuracy: 82.43
Round  58, Train loss: 0.470, Test loss: 0.475, Test accuracy: 81.92
Round  59, Train loss: 0.521, Test loss: 0.475, Test accuracy: 81.90
Round  60, Train loss: 0.543, Test loss: 0.466, Test accuracy: 82.42
Round  61, Train loss: 0.403, Test loss: 0.469, Test accuracy: 82.30
Round  62, Train loss: 0.368, Test loss: 0.465, Test accuracy: 82.32
Round  63, Train loss: 0.432, Test loss: 0.469, Test accuracy: 81.98
Round  64, Train loss: 0.465, Test loss: 0.457, Test accuracy: 82.85
Round  65, Train loss: 0.405, Test loss: 0.456, Test accuracy: 82.92
Round  66, Train loss: 0.331, Test loss: 0.452, Test accuracy: 82.72
Round  67, Train loss: 0.372, Test loss: 0.450, Test accuracy: 82.98
Round  68, Train loss: 0.509, Test loss: 0.451, Test accuracy: 82.93
Round  69, Train loss: 0.384, Test loss: 0.451, Test accuracy: 83.22
Round  70, Train loss: 0.420, Test loss: 0.446, Test accuracy: 83.32
Round  71, Train loss: 0.405, Test loss: 0.451, Test accuracy: 83.15
Round  72, Train loss: 0.328, Test loss: 0.446, Test accuracy: 83.03
Round  73, Train loss: 0.394, Test loss: 0.449, Test accuracy: 83.47
Round  74, Train loss: 0.396, Test loss: 0.441, Test accuracy: 83.33
Round  75, Train loss: 0.398, Test loss: 0.442, Test accuracy: 83.87
Round  76, Train loss: 0.333, Test loss: 0.440, Test accuracy: 83.38
Round  77, Train loss: 0.407, Test loss: 0.447, Test accuracy: 83.37
Round  78, Train loss: 0.434, Test loss: 0.443, Test accuracy: 83.62
Round  79, Train loss: 0.384, Test loss: 0.439, Test accuracy: 83.77
Round  80, Train loss: 0.347, Test loss: 0.444, Test accuracy: 83.72
Round  81, Train loss: 0.416, Test loss: 0.432, Test accuracy: 83.78
Round  82, Train loss: 0.366, Test loss: 0.437, Test accuracy: 84.07
Round  83, Train loss: 0.291, Test loss: 0.429, Test accuracy: 84.27
Round  84, Train loss: 0.416, Test loss: 0.429, Test accuracy: 84.18
Round  85, Train loss: 0.410, Test loss: 0.430, Test accuracy: 84.12
Round  86, Train loss: 0.357, Test loss: 0.437, Test accuracy: 83.78
Round  87, Train loss: 0.347, Test loss: 0.440, Test accuracy: 83.43
Round  88, Train loss: 0.352, Test loss: 0.436, Test accuracy: 84.07
Round  89, Train loss: 0.370, Test loss: 0.437, Test accuracy: 83.73
Round  90, Train loss: 0.295, Test loss: 0.438, Test accuracy: 83.67
Round  91, Train loss: 0.402, Test loss: 0.427, Test accuracy: 84.03
Round  92, Train loss: 0.284, Test loss: 0.423, Test accuracy: 84.38
Round  93, Train loss: 0.324, Test loss: 0.425, Test accuracy: 84.35
Round  94, Train loss: 0.340, Test loss: 0.436, Test accuracy: 83.88
Round  95, Train loss: 0.311, Test loss: 0.428, Test accuracy: 84.00
Round  96, Train loss: 0.424, Test loss: 0.432, Test accuracy: 83.92
Round  97, Train loss: 0.365, Test loss: 0.432, Test accuracy: 84.15
Round  98, Train loss: 0.278, Test loss: 0.430, Test accuracy: 84.23
Round  99, Train loss: 0.363, Test loss: 0.441, Test accuracy: 83.70
Final Round, Train loss: 0.296, Test loss: 0.428, Test accuracy: 84.13
Average accuracy final 10 rounds: 84.03166666666667
636.7554831504822
[1.1049070358276367, 1.890688180923462, 2.643894672393799, 3.437654972076416, 4.2229626178741455, 4.994010925292969, 5.739714622497559, 6.502683401107788, 7.295958757400513, 8.086012125015259, 8.862564086914062, 9.63218879699707, 10.389538526535034, 11.176448822021484, 11.951937675476074, 12.709423303604126, 13.494187355041504, 14.281572341918945, 15.05986499786377, 15.816936492919922, 16.599233627319336, 17.371999740600586, 18.133429765701294, 18.882147073745728, 19.68026876449585, 20.466760635375977, 21.248966217041016, 22.006540775299072, 22.763317584991455, 23.570387840270996, 24.383058309555054, 25.150002002716064, 25.877776622772217, 26.660493850708008, 27.438785076141357, 28.229284048080444, 28.98991322517395, 29.743422269821167, 30.522037744522095, 31.304189920425415, 32.07824087142944, 32.84836030006409, 33.61736798286438, 34.42110061645508, 35.19412064552307, 35.96528172492981, 36.74662232398987, 37.509989738464355, 38.290765047073364, 39.04315137863159, 39.82344937324524, 40.58931517601013, 41.36241126060486, 42.10710549354553, 42.86650276184082, 43.62795805931091, 44.402037620544434, 45.134291887283325, 45.88308835029602, 46.66087341308594, 47.422269344329834, 48.17954444885254, 48.90687394142151, 49.71973419189453, 50.514904737472534, 51.30508470535278, 52.06718993186951, 52.8330442905426, 53.635051012039185, 54.40984106063843, 55.1584312915802, 55.91118884086609, 56.676414489746094, 57.449220418930054, 58.22006821632385, 58.98249292373657, 59.756097078323364, 60.51878356933594, 61.2687828540802, 62.0123176574707, 62.828612327575684, 63.61157512664795, 64.39595365524292, 65.13916540145874, 65.92732214927673, 66.72621488571167, 67.53211379051208, 68.28886866569519, 69.04195880889893, 69.84249067306519, 70.65007472038269, 71.44603657722473, 72.22009420394897, 73.00215578079224, 73.78510427474976, 74.56888318061829, 75.35930061340332, 76.14989471435547, 76.93047142028809, 77.74614834785461, 79.01744437217712]
[28.516666666666666, 39.13333333333333, 47.46666666666667, 50.266666666666666, 53.666666666666664, 55.6, 55.916666666666664, 58.36666666666667, 61.9, 66.51666666666667, 69.2, 69.11666666666666, 71.55, 72.75, 73.71666666666667, 73.2, 72.25, 73.56666666666666, 74.06666666666666, 74.31666666666666, 74.68333333333334, 75.86666666666666, 76.06666666666666, 76.53333333333333, 76.7, 77.08333333333333, 77.35, 77.88333333333334, 78.21666666666667, 78.3, 78.6, 79.0, 79.41666666666667, 79.05, 79.4, 79.66666666666667, 79.6, 80.01666666666667, 80.5, 80.78333333333333, 80.76666666666667, 80.9, 81.23333333333333, 81.06666666666666, 81.01666666666667, 81.38333333333334, 81.08333333333333, 81.18333333333334, 80.96666666666667, 81.66666666666667, 81.48333333333333, 81.65, 81.46666666666667, 82.08333333333333, 81.3, 81.98333333333333, 82.65, 82.43333333333334, 81.91666666666667, 81.9, 82.41666666666667, 82.3, 82.31666666666666, 81.98333333333333, 82.85, 82.91666666666667, 82.71666666666667, 82.98333333333333, 82.93333333333334, 83.21666666666667, 83.31666666666666, 83.15, 83.03333333333333, 83.46666666666667, 83.33333333333333, 83.86666666666666, 83.38333333333334, 83.36666666666666, 83.61666666666666, 83.76666666666667, 83.71666666666667, 83.78333333333333, 84.06666666666666, 84.26666666666667, 84.18333333333334, 84.11666666666666, 83.78333333333333, 83.43333333333334, 84.06666666666666, 83.73333333333333, 83.66666666666667, 84.03333333333333, 84.38333333333334, 84.35, 83.88333333333334, 84.0, 83.91666666666667, 84.15, 84.23333333333333, 83.7, 84.13333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 12, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.692, Test loss: 2.146, Test accuracy: 27.92
Round   1, Train loss: 1.111, Test loss: 1.800, Test accuracy: 37.15
Round   2, Train loss: 1.029, Test loss: 1.512, Test accuracy: 44.73
Round   3, Train loss: 0.906, Test loss: 1.323, Test accuracy: 49.17
Round   4, Train loss: 0.926, Test loss: 1.302, Test accuracy: 52.35
Round   5, Train loss: 0.861, Test loss: 1.172, Test accuracy: 53.75
Round   6, Train loss: 0.818, Test loss: 1.074, Test accuracy: 60.48
Round   7, Train loss: 0.938, Test loss: 0.911, Test accuracy: 63.98
Round   8, Train loss: 0.739, Test loss: 0.752, Test accuracy: 67.28
Round   9, Train loss: 0.703, Test loss: 0.742, Test accuracy: 68.30
Round  10, Train loss: 0.788, Test loss: 0.730, Test accuracy: 68.68
Round  11, Train loss: 0.738, Test loss: 0.714, Test accuracy: 69.92
Round  12, Train loss: 0.694, Test loss: 0.672, Test accuracy: 71.90
Round  13, Train loss: 0.735, Test loss: 0.655, Test accuracy: 72.42
Round  14, Train loss: 0.646, Test loss: 0.643, Test accuracy: 73.67
Round  15, Train loss: 0.674, Test loss: 0.616, Test accuracy: 75.07
Round  16, Train loss: 0.746, Test loss: 0.620, Test accuracy: 75.27
Round  17, Train loss: 0.709, Test loss: 0.607, Test accuracy: 75.82
Round  18, Train loss: 0.783, Test loss: 0.606, Test accuracy: 75.18
Round  19, Train loss: 0.580, Test loss: 0.598, Test accuracy: 75.48
Round  20, Train loss: 0.646, Test loss: 0.605, Test accuracy: 75.15
Round  21, Train loss: 0.637, Test loss: 0.607, Test accuracy: 75.82
Round  22, Train loss: 0.611, Test loss: 0.586, Test accuracy: 76.67
Round  23, Train loss: 0.584, Test loss: 0.566, Test accuracy: 77.00
Round  24, Train loss: 0.591, Test loss: 0.582, Test accuracy: 76.73
Round  25, Train loss: 0.610, Test loss: 0.571, Test accuracy: 77.47
Round  26, Train loss: 0.549, Test loss: 0.574, Test accuracy: 77.98
Round  27, Train loss: 0.528, Test loss: 0.565, Test accuracy: 78.02
Round  28, Train loss: 0.464, Test loss: 0.559, Test accuracy: 77.47
Round  29, Train loss: 0.647, Test loss: 0.533, Test accuracy: 78.90
Round  30, Train loss: 0.560, Test loss: 0.539, Test accuracy: 78.83
Round  31, Train loss: 0.591, Test loss: 0.525, Test accuracy: 79.03
Round  32, Train loss: 0.466, Test loss: 0.528, Test accuracy: 78.67
Round  33, Train loss: 0.689, Test loss: 0.524, Test accuracy: 79.47
Round  34, Train loss: 0.494, Test loss: 0.510, Test accuracy: 79.85
Round  35, Train loss: 0.603, Test loss: 0.526, Test accuracy: 79.42
Round  36, Train loss: 0.542, Test loss: 0.511, Test accuracy: 79.88
Round  37, Train loss: 0.579, Test loss: 0.510, Test accuracy: 79.85
Round  38, Train loss: 0.736, Test loss: 0.516, Test accuracy: 80.32
Round  39, Train loss: 0.521, Test loss: 0.501, Test accuracy: 80.42
Round  40, Train loss: 0.496, Test loss: 0.506, Test accuracy: 80.63
Round  41, Train loss: 0.461, Test loss: 0.504, Test accuracy: 80.42
Round  42, Train loss: 0.526, Test loss: 0.501, Test accuracy: 80.55
Round  43, Train loss: 0.496, Test loss: 0.490, Test accuracy: 80.75
Round  44, Train loss: 0.414, Test loss: 0.496, Test accuracy: 80.22
Round  45, Train loss: 0.530, Test loss: 0.488, Test accuracy: 81.17
Round  46, Train loss: 0.490, Test loss: 0.477, Test accuracy: 81.63
Round  47, Train loss: 0.504, Test loss: 0.477, Test accuracy: 81.47
Round  48, Train loss: 0.473, Test loss: 0.475, Test accuracy: 81.12
Round  49, Train loss: 0.424, Test loss: 0.478, Test accuracy: 81.13
Round  50, Train loss: 0.530, Test loss: 0.471, Test accuracy: 81.57
Round  51, Train loss: 0.490, Test loss: 0.477, Test accuracy: 81.27
Round  52, Train loss: 0.433, Test loss: 0.478, Test accuracy: 80.65
Round  53, Train loss: 0.433, Test loss: 0.471, Test accuracy: 81.42
Round  54, Train loss: 0.402, Test loss: 0.479, Test accuracy: 81.30
Round  55, Train loss: 0.496, Test loss: 0.474, Test accuracy: 81.60
Round  56, Train loss: 0.420, Test loss: 0.467, Test accuracy: 81.85
Round  57, Train loss: 0.413, Test loss: 0.469, Test accuracy: 81.73
Round  58, Train loss: 0.448, Test loss: 0.466, Test accuracy: 82.08
Round  59, Train loss: 0.452, Test loss: 0.460, Test accuracy: 82.15
Round  60, Train loss: 0.502, Test loss: 0.459, Test accuracy: 82.47
Round  61, Train loss: 0.482, Test loss: 0.450, Test accuracy: 82.75
Round  62, Train loss: 0.436, Test loss: 0.453, Test accuracy: 82.45
Round  63, Train loss: 0.367, Test loss: 0.455, Test accuracy: 82.47
Round  64, Train loss: 0.400, Test loss: 0.454, Test accuracy: 82.32
Round  65, Train loss: 0.488, Test loss: 0.454, Test accuracy: 82.52
Round  66, Train loss: 0.305, Test loss: 0.447, Test accuracy: 82.58
Round  67, Train loss: 0.418, Test loss: 0.441, Test accuracy: 83.15
Round  68, Train loss: 0.492, Test loss: 0.441, Test accuracy: 83.22
Round  69, Train loss: 0.375, Test loss: 0.443, Test accuracy: 82.68
Round  70, Train loss: 0.482, Test loss: 0.448, Test accuracy: 82.87
Round  71, Train loss: 0.431, Test loss: 0.442, Test accuracy: 83.08
Round  72, Train loss: 0.353, Test loss: 0.434, Test accuracy: 83.50
Round  73, Train loss: 0.337, Test loss: 0.437, Test accuracy: 82.97
Round  74, Train loss: 0.298, Test loss: 0.432, Test accuracy: 83.47
Round  75, Train loss: 0.508, Test loss: 0.438, Test accuracy: 83.17
Round  76, Train loss: 0.348, Test loss: 0.435, Test accuracy: 83.07
Round  77, Train loss: 0.336, Test loss: 0.435, Test accuracy: 83.45
Round  78, Train loss: 0.408, Test loss: 0.437, Test accuracy: 83.17
Round  79, Train loss: 0.367, Test loss: 0.436, Test accuracy: 83.33
Round  80, Train loss: 0.413, Test loss: 0.434, Test accuracy: 83.50
Round  81, Train loss: 0.355, Test loss: 0.430, Test accuracy: 83.90
Round  82, Train loss: 0.447, Test loss: 0.428, Test accuracy: 84.02
Round  83, Train loss: 0.268, Test loss: 0.430, Test accuracy: 83.73
Round  84, Train loss: 0.395, Test loss: 0.432, Test accuracy: 83.55
Round  85, Train loss: 0.440, Test loss: 0.429, Test accuracy: 83.35
Round  86, Train loss: 0.403, Test loss: 0.424, Test accuracy: 83.80
Round  87, Train loss: 0.326, Test loss: 0.422, Test accuracy: 83.90
Round  88, Train loss: 0.361, Test loss: 0.427, Test accuracy: 83.83
Round  89, Train loss: 0.299, Test loss: 0.431, Test accuracy: 83.90
Round  90, Train loss: 0.256, Test loss: 0.438, Test accuracy: 83.53
Round  91, Train loss: 0.370, Test loss: 0.429, Test accuracy: 83.60
Round  92, Train loss: 0.288, Test loss: 0.420, Test accuracy: 83.92
Round  93, Train loss: 0.427, Test loss: 0.423, Test accuracy: 84.23
Round  94, Train loss: 0.411, Test loss: 0.424, Test accuracy: 84.10
Round  95, Train loss: 0.290, Test loss: 0.430, Test accuracy: 83.75
Round  96, Train loss: 0.375, Test loss: 0.428, Test accuracy: 83.60
Round  97, Train loss: 0.357, Test loss: 0.423, Test accuracy: 84.18
Round  98, Train loss: 0.355, Test loss: 0.428, Test accuracy: 83.78
Round  99, Train loss: 0.320, Test loss: 0.421, Test accuracy: 83.98
Final Round, Train loss: 0.292, Test loss: 0.424, Test accuracy: 84.18
Average accuracy final 10 rounds: 83.86833333333334
1044.820270061493
[1.143904209136963, 1.9706568717956543, 2.783928871154785, 3.5836472511291504, 4.392460823059082, 5.21039342880249, 6.0295586585998535, 6.84679651260376, 7.6450231075286865, 8.473746061325073, 9.31544303894043, 10.140517234802246, 10.952420949935913, 11.741018056869507, 12.593883991241455, 13.415882587432861, 14.22007966041565, 15.002847909927368, 15.813424587249756, 16.638402938842773, 17.462802171707153, 19.107342958450317, 20.807393550872803, 22.457946062088013, 24.13491654396057, 25.770439863204956, 27.481817960739136, 29.099058866500854, 30.724790811538696, 32.417600870132446, 34.019646406173706, 35.70768857002258, 37.379642724990845, 38.98029398918152, 40.62385439872742, 42.226370334625244, 43.895490884780884, 45.578213691711426, 47.156715869903564, 48.8096809387207, 50.39790153503418, 52.047483682632446, 53.6284704208374, 55.305561542510986, 56.98121166229248, 58.57151460647583, 60.248547315597534, 61.83125376701355, 63.54514765739441, 65.17580771446228, 66.7377119064331, 68.42812061309814, 70.03992438316345, 71.61744379997253, 73.29692125320435, 74.9753041267395, 76.58165097236633, 78.19221353530884, 79.90753078460693, 81.52487516403198, 83.20172023773193, 84.87205815315247, 86.53352475166321, 88.21830153465271, 89.78738355636597, 91.47662901878357, 93.15862226486206, 94.6755952835083, 96.34700679779053, 97.92985439300537, 99.53187274932861, 101.1328489780426, 102.81775236129761, 104.41224646568298, 106.08711862564087, 107.79483556747437, 109.36213874816895, 111.05742239952087, 112.74127984046936, 114.41856908798218, 116.11451506614685, 117.71960949897766, 119.36605167388916, 121.05441951751709, 122.66397452354431, 124.34286856651306, 126.01195430755615, 127.6837706565857, 129.26852416992188, 130.93105220794678, 132.51634287834167, 134.17214918136597, 135.86723709106445, 137.41835927963257, 139.10362005233765, 140.8095247745514, 142.42122840881348, 144.0803849697113, 145.67951560020447, 147.36449432373047, 148.65538930892944]
[27.916666666666668, 37.15, 44.733333333333334, 49.166666666666664, 52.35, 53.75, 60.483333333333334, 63.983333333333334, 67.28333333333333, 68.3, 68.68333333333334, 69.91666666666667, 71.9, 72.41666666666667, 73.66666666666667, 75.06666666666666, 75.26666666666667, 75.81666666666666, 75.18333333333334, 75.48333333333333, 75.15, 75.81666666666666, 76.66666666666667, 77.0, 76.73333333333333, 77.46666666666667, 77.98333333333333, 78.01666666666667, 77.46666666666667, 78.9, 78.83333333333333, 79.03333333333333, 78.66666666666667, 79.46666666666667, 79.85, 79.41666666666667, 79.88333333333334, 79.85, 80.31666666666666, 80.41666666666667, 80.63333333333334, 80.41666666666667, 80.55, 80.75, 80.21666666666667, 81.16666666666667, 81.63333333333334, 81.46666666666667, 81.11666666666666, 81.13333333333334, 81.56666666666666, 81.26666666666667, 80.65, 81.41666666666667, 81.3, 81.6, 81.85, 81.73333333333333, 82.08333333333333, 82.15, 82.46666666666667, 82.75, 82.45, 82.46666666666667, 82.31666666666666, 82.51666666666667, 82.58333333333333, 83.15, 83.21666666666667, 82.68333333333334, 82.86666666666666, 83.08333333333333, 83.5, 82.96666666666667, 83.46666666666667, 83.16666666666667, 83.06666666666666, 83.45, 83.16666666666667, 83.33333333333333, 83.5, 83.9, 84.01666666666667, 83.73333333333333, 83.55, 83.35, 83.8, 83.9, 83.83333333333333, 83.9, 83.53333333333333, 83.6, 83.91666666666667, 84.23333333333333, 84.1, 83.75, 83.6, 84.18333333333334, 83.78333333333333, 83.98333333333333, 84.18333333333334]
