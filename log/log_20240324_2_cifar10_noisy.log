nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.724, Test loss: 2.307, Test accuracy: 15.67
Round   1, Train loss: 1.215, Test loss: 1.894, Test accuracy: 32.63
Round   2, Train loss: 0.986, Test loss: 1.489, Test accuracy: 42.77
Round   3, Train loss: 0.950, Test loss: 1.490, Test accuracy: 49.10
Round   4, Train loss: 0.889, Test loss: 1.076, Test accuracy: 57.53
Round   5, Train loss: 0.891, Test loss: 1.082, Test accuracy: 60.73
Round   6, Train loss: 0.803, Test loss: 1.159, Test accuracy: 59.60
Round   7, Train loss: 0.753, Test loss: 0.871, Test accuracy: 63.77
Round   8, Train loss: 0.772, Test loss: 1.155, Test accuracy: 61.93
Round   9, Train loss: 0.773, Test loss: 0.924, Test accuracy: 62.33
Round  10, Train loss: 0.716, Test loss: 0.991, Test accuracy: 65.70
Round  11, Train loss: 0.868, Test loss: 0.930, Test accuracy: 61.63
Round  12, Train loss: 0.746, Test loss: 0.781, Test accuracy: 66.77
Round  13, Train loss: 0.679, Test loss: 0.673, Test accuracy: 72.20
Round  14, Train loss: 0.783, Test loss: 0.681, Test accuracy: 71.60
Round  15, Train loss: 0.686, Test loss: 0.682, Test accuracy: 71.50
Round  16, Train loss: 0.662, Test loss: 0.678, Test accuracy: 71.43
Round  17, Train loss: 0.697, Test loss: 0.666, Test accuracy: 72.33
Round  18, Train loss: 0.585, Test loss: 0.658, Test accuracy: 72.63
Round  19, Train loss: 0.648, Test loss: 0.667, Test accuracy: 71.80
Round  20, Train loss: 0.670, Test loss: 0.644, Test accuracy: 73.73
Round  21, Train loss: 0.637, Test loss: 0.652, Test accuracy: 73.33
Round  22, Train loss: 0.627, Test loss: 0.658, Test accuracy: 72.37
Round  23, Train loss: 0.671, Test loss: 0.627, Test accuracy: 73.97
Round  24, Train loss: 0.713, Test loss: 0.645, Test accuracy: 72.60
Round  25, Train loss: 0.502, Test loss: 0.635, Test accuracy: 72.63
Round  26, Train loss: 0.542, Test loss: 0.622, Test accuracy: 73.37
Round  27, Train loss: 0.681, Test loss: 0.623, Test accuracy: 73.43
Round  28, Train loss: 0.579, Test loss: 0.599, Test accuracy: 74.57
Round  29, Train loss: 0.549, Test loss: 0.592, Test accuracy: 75.73
Round  30, Train loss: 0.479, Test loss: 0.586, Test accuracy: 75.60
Round  31, Train loss: 0.682, Test loss: 0.597, Test accuracy: 76.03
Round  32, Train loss: 0.658, Test loss: 0.608, Test accuracy: 75.73
Round  33, Train loss: 0.574, Test loss: 0.593, Test accuracy: 75.83
Round  34, Train loss: 0.536, Test loss: 0.591, Test accuracy: 75.83
Round  35, Train loss: 0.459, Test loss: 0.580, Test accuracy: 76.30
Round  36, Train loss: 0.408, Test loss: 0.573, Test accuracy: 76.47
Round  37, Train loss: 0.509, Test loss: 0.579, Test accuracy: 76.17
Round  38, Train loss: 0.637, Test loss: 0.566, Test accuracy: 76.50
Round  39, Train loss: 0.474, Test loss: 0.576, Test accuracy: 75.83
Round  40, Train loss: 0.606, Test loss: 0.580, Test accuracy: 75.93
Round  41, Train loss: 0.455, Test loss: 0.555, Test accuracy: 77.40
Round  42, Train loss: 0.606, Test loss: 0.567, Test accuracy: 76.80
Round  43, Train loss: 0.401, Test loss: 0.574, Test accuracy: 76.73
Round  44, Train loss: 0.479, Test loss: 0.561, Test accuracy: 76.90
Round  45, Train loss: 0.608, Test loss: 0.534, Test accuracy: 77.77
Round  46, Train loss: 0.525, Test loss: 0.537, Test accuracy: 77.17
Round  47, Train loss: 0.471, Test loss: 0.543, Test accuracy: 77.27
Round  48, Train loss: 0.482, Test loss: 0.560, Test accuracy: 75.90
Round  49, Train loss: 0.385, Test loss: 0.565, Test accuracy: 76.13
Round  50, Train loss: 0.610, Test loss: 0.542, Test accuracy: 77.47
Round  51, Train loss: 0.450, Test loss: 0.535, Test accuracy: 77.80
Round  52, Train loss: 0.350, Test loss: 0.550, Test accuracy: 77.80
Round  53, Train loss: 0.490, Test loss: 0.544, Test accuracy: 77.87
Round  54, Train loss: 0.478, Test loss: 0.553, Test accuracy: 76.83
Round  55, Train loss: 0.436, Test loss: 0.545, Test accuracy: 77.93
Round  56, Train loss: 0.560, Test loss: 0.538, Test accuracy: 78.03
Round  57, Train loss: 0.433, Test loss: 0.538, Test accuracy: 77.93
Round  58, Train loss: 0.415, Test loss: 0.514, Test accuracy: 79.23
Round  59, Train loss: 0.467, Test loss: 0.517, Test accuracy: 78.77
Round  60, Train loss: 0.394, Test loss: 0.527, Test accuracy: 78.57
Round  61, Train loss: 0.380, Test loss: 0.539, Test accuracy: 77.50
Round  62, Train loss: 0.415, Test loss: 0.543, Test accuracy: 77.80
Round  63, Train loss: 0.332, Test loss: 0.544, Test accuracy: 77.70
Round  64, Train loss: 0.458, Test loss: 0.529, Test accuracy: 78.17
Round  65, Train loss: 0.451, Test loss: 0.517, Test accuracy: 79.43
Round  66, Train loss: 0.376, Test loss: 0.525, Test accuracy: 79.07
Round  67, Train loss: 0.420, Test loss: 0.519, Test accuracy: 78.33
Round  68, Train loss: 0.479, Test loss: 0.525, Test accuracy: 78.43
Round  69, Train loss: 0.357, Test loss: 0.526, Test accuracy: 78.13
Round  70, Train loss: 0.334, Test loss: 0.522, Test accuracy: 78.63
Round  71, Train loss: 0.356, Test loss: 0.540, Test accuracy: 78.57
Round  72, Train loss: 0.345, Test loss: 0.527, Test accuracy: 78.60
Round  73, Train loss: 0.313, Test loss: 0.530, Test accuracy: 78.07
Round  74, Train loss: 0.254, Test loss: 0.527, Test accuracy: 78.77
Round  75, Train loss: 0.380, Test loss: 0.510, Test accuracy: 79.27
Round  76, Train loss: 0.378, Test loss: 0.511, Test accuracy: 79.67
Round  77, Train loss: 0.247, Test loss: 0.511, Test accuracy: 79.67
Round  78, Train loss: 0.249, Test loss: 0.523, Test accuracy: 79.37
Round  79, Train loss: 0.279, Test loss: 0.533, Test accuracy: 79.07
Round  80, Train loss: 0.364, Test loss: 0.528, Test accuracy: 79.47
Round  81, Train loss: 0.345, Test loss: 0.527, Test accuracy: 79.03
Round  82, Train loss: 0.252, Test loss: 0.520, Test accuracy: 79.60
Round  83, Train loss: 0.355, Test loss: 0.509, Test accuracy: 80.07
Round  84, Train loss: 0.298, Test loss: 0.543, Test accuracy: 79.10
Round  85, Train loss: 0.401, Test loss: 0.527, Test accuracy: 79.47
Round  86, Train loss: 0.294, Test loss: 0.523, Test accuracy: 79.37
Round  87, Train loss: 0.315, Test loss: 0.519, Test accuracy: 79.70
Round  88, Train loss: 0.265, Test loss: 0.520, Test accuracy: 79.97
Round  89, Train loss: 0.292, Test loss: 0.517, Test accuracy: 80.13
Round  90, Train loss: 0.242, Test loss: 0.511, Test accuracy: 80.07
Round  91, Train loss: 0.331, Test loss: 0.517, Test accuracy: 79.73
Round  92, Train loss: 0.238, Test loss: 0.516, Test accuracy: 80.23
Round  93, Train loss: 0.352, Test loss: 0.520, Test accuracy: 78.93
Round  94, Train loss: 0.312, Test loss: 0.510, Test accuracy: 80.27
Round  95, Train loss: 0.223, Test loss: 0.529, Test accuracy: 79.73
Round  96, Train loss: 0.254, Test loss: 0.515, Test accuracy: 80.60
Round  97, Train loss: 0.270, Test loss: 0.532, Test accuracy: 79.70
Round  98, Train loss: 0.189, Test loss: 0.541, Test accuracy: 79.20
Round  99, Train loss: 0.320, Test loss: 0.537, Test accuracy: 79.47
Final Round, Train loss: 0.213, Test loss: 0.524, Test accuracy: 80.07
Average accuracy final 10 rounds: 79.79333333333334
319.0959622859955
[1.115886926651001, 1.9088008403778076, 2.7056164741516113, 3.504650592803955, 4.2923057079315186, 5.077472686767578, 5.871111154556274, 6.675972938537598, 7.464538335800171, 8.262553215026855, 9.054293394088745, 9.843059539794922, 10.632925271987915, 11.422794580459595, 12.2173330783844, 13.008305549621582, 13.792176485061646, 14.582010269165039, 15.37508773803711, 16.159175395965576, 16.947880744934082, 17.74306011199951, 18.544520378112793, 19.3294415473938, 20.12478232383728, 20.920013189315796, 21.708194971084595, 22.497437715530396, 23.28389596939087, 24.078802347183228, 24.867366313934326, 25.654890298843384, 26.449549436569214, 27.241597175598145, 28.026254415512085, 28.822511672973633, 29.618207216262817, 30.40284299850464, 31.204509019851685, 32.01044273376465, 32.81074380874634, 33.6072256565094, 34.40136766433716, 35.20271635055542, 35.99688911437988, 36.79170227050781, 37.5973014831543, 38.38792943954468, 39.16804385185242, 39.951590061187744, 40.73785853385925, 41.52427625656128, 42.307387590408325, 43.09925055503845, 43.88981223106384, 44.670602321624756, 45.45260143280029, 46.23698163032532, 47.02560567855835, 47.814372539520264, 48.59430742263794, 49.376657009124756, 50.15770506858826, 50.94591426849365, 51.72982931137085, 52.521790981292725, 53.30979251861572, 54.09491515159607, 54.88187384605408, 55.66173720359802, 56.447672843933105, 57.23275661468506, 58.02475333213806, 58.81112551689148, 59.59105062484741, 60.36100363731384, 61.128915548324585, 61.90266156196594, 62.670812368392944, 63.43871808052063, 64.21125030517578, 64.98185610771179, 65.74775075912476, 66.5184235572815, 67.28917217254639, 68.06348896026611, 68.83366656303406, 69.60423517227173, 70.37682604789734, 71.14475107192993, 71.91531372070312, 72.68922638893127, 73.45683455467224, 74.2233612537384, 74.99840974807739, 75.7694251537323, 76.54206275939941, 77.31002187728882, 78.08242917060852, 78.85365986824036, 80.04690361022949]
[15.666666666666666, 32.63333333333333, 42.766666666666666, 49.1, 57.53333333333333, 60.733333333333334, 59.6, 63.766666666666666, 61.93333333333333, 62.333333333333336, 65.7, 61.63333333333333, 66.76666666666667, 72.2, 71.6, 71.5, 71.43333333333334, 72.33333333333333, 72.63333333333334, 71.8, 73.73333333333333, 73.33333333333333, 72.36666666666666, 73.96666666666667, 72.6, 72.63333333333334, 73.36666666666666, 73.43333333333334, 74.56666666666666, 75.73333333333333, 75.6, 76.03333333333333, 75.73333333333333, 75.83333333333333, 75.83333333333333, 76.3, 76.46666666666667, 76.16666666666667, 76.5, 75.83333333333333, 75.93333333333334, 77.4, 76.8, 76.73333333333333, 76.9, 77.76666666666667, 77.16666666666667, 77.26666666666667, 75.9, 76.13333333333334, 77.46666666666667, 77.8, 77.8, 77.86666666666666, 76.83333333333333, 77.93333333333334, 78.03333333333333, 77.93333333333334, 79.23333333333333, 78.76666666666667, 78.56666666666666, 77.5, 77.8, 77.7, 78.16666666666667, 79.43333333333334, 79.06666666666666, 78.33333333333333, 78.43333333333334, 78.13333333333334, 78.63333333333334, 78.56666666666666, 78.6, 78.06666666666666, 78.76666666666667, 79.26666666666667, 79.66666666666667, 79.66666666666667, 79.36666666666666, 79.06666666666666, 79.46666666666667, 79.03333333333333, 79.6, 80.06666666666666, 79.1, 79.46666666666667, 79.36666666666666, 79.7, 79.96666666666667, 80.13333333333334, 80.06666666666666, 79.73333333333333, 80.23333333333333, 78.93333333333334, 80.26666666666667, 79.73333333333333, 80.6, 79.7, 79.2, 79.46666666666667, 80.06666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.324, Test loss: 1.363, Test accuracy: 39.83
Round   1, Train loss: 0.925, Test loss: 0.939, Test accuracy: 57.83
Round   2, Train loss: 0.820, Test loss: 0.857, Test accuracy: 60.90
Round   3, Train loss: 0.758, Test loss: 0.765, Test accuracy: 68.00
Round   4, Train loss: 0.713, Test loss: 0.748, Test accuracy: 67.50
Round   5, Train loss: 0.678, Test loss: 0.719, Test accuracy: 68.63
Round   6, Train loss: 0.654, Test loss: 0.669, Test accuracy: 71.87
Round   7, Train loss: 0.632, Test loss: 0.666, Test accuracy: 72.20
Round   8, Train loss: 0.608, Test loss: 0.641, Test accuracy: 72.80
Round   9, Train loss: 0.591, Test loss: 0.623, Test accuracy: 73.97
Round  10, Train loss: 0.572, Test loss: 0.640, Test accuracy: 72.43
Round  11, Train loss: 0.550, Test loss: 0.609, Test accuracy: 74.67
Round  12, Train loss: 0.536, Test loss: 0.594, Test accuracy: 76.13
Round  13, Train loss: 0.517, Test loss: 0.578, Test accuracy: 76.00
Round  14, Train loss: 0.498, Test loss: 0.579, Test accuracy: 76.07
Round  15, Train loss: 0.482, Test loss: 0.554, Test accuracy: 77.73
Round  16, Train loss: 0.470, Test loss: 0.574, Test accuracy: 75.83
Round  17, Train loss: 0.458, Test loss: 0.553, Test accuracy: 76.30
Round  18, Train loss: 0.444, Test loss: 0.577, Test accuracy: 76.50
Round  19, Train loss: 0.430, Test loss: 0.553, Test accuracy: 76.93
Round  20, Train loss: 0.373, Test loss: 0.572, Test accuracy: 76.93
Round  21, Train loss: 0.397, Test loss: 0.563, Test accuracy: 76.67
Round  22, Train loss: 0.328, Test loss: 0.571, Test accuracy: 77.53
Round  23, Train loss: 0.350, Test loss: 0.569, Test accuracy: 77.00
Round  24, Train loss: 0.325, Test loss: 0.578, Test accuracy: 76.83
Round  25, Train loss: 0.412, Test loss: 0.597, Test accuracy: 75.67
Round  26, Train loss: 0.378, Test loss: 0.574, Test accuracy: 76.80
Round  27, Train loss: 0.454, Test loss: 0.550, Test accuracy: 78.13
Round  28, Train loss: 0.265, Test loss: 0.553, Test accuracy: 77.60
Round  29, Train loss: 0.420, Test loss: 0.579, Test accuracy: 77.30
Round  30, Train loss: 0.420, Test loss: 0.554, Test accuracy: 79.17
Round  31, Train loss: 0.341, Test loss: 0.589, Test accuracy: 77.23
Round  32, Train loss: 0.354, Test loss: 0.607, Test accuracy: 77.20
Round  33, Train loss: 0.399, Test loss: 0.556, Test accuracy: 78.67
Round  34, Train loss: 0.271, Test loss: 0.588, Test accuracy: 77.27
Round  35, Train loss: 0.306, Test loss: 0.597, Test accuracy: 77.60
Round  36, Train loss: 0.256, Test loss: 0.559, Test accuracy: 78.73
Round  37, Train loss: 0.298, Test loss: 0.554, Test accuracy: 78.73
Round  38, Train loss: 0.227, Test loss: 0.586, Test accuracy: 77.80
Round  39, Train loss: 0.271, Test loss: 0.560, Test accuracy: 79.07
Round  40, Train loss: 0.337, Test loss: 0.588, Test accuracy: 78.27
Round  41, Train loss: 0.283, Test loss: 0.566, Test accuracy: 78.37
Round  42, Train loss: 0.188, Test loss: 0.574, Test accuracy: 79.17
Round  43, Train loss: 0.193, Test loss: 0.595, Test accuracy: 78.73
Round  44, Train loss: 0.131, Test loss: 0.570, Test accuracy: 79.67
Round  45, Train loss: 0.150, Test loss: 0.582, Test accuracy: 79.07
Round  46, Train loss: 0.210, Test loss: 0.582, Test accuracy: 79.67
Round  47, Train loss: 0.247, Test loss: 0.572, Test accuracy: 79.43
Round  48, Train loss: 0.151, Test loss: 0.609, Test accuracy: 79.67
Round  49, Train loss: 0.296, Test loss: 0.576, Test accuracy: 79.33
Round  50, Train loss: 0.161, Test loss: 0.591, Test accuracy: 78.93
Round  51, Train loss: 0.279, Test loss: 0.625, Test accuracy: 78.53
Round  52, Train loss: 0.244, Test loss: 0.610, Test accuracy: 79.17
Round  53, Train loss: 0.169, Test loss: 0.616, Test accuracy: 78.27
Round  54, Train loss: 0.201, Test loss: 0.596, Test accuracy: 80.37
Round  55, Train loss: 0.193, Test loss: 0.597, Test accuracy: 79.30
Round  56, Train loss: 0.136, Test loss: 0.595, Test accuracy: 79.67
Round  57, Train loss: 0.205, Test loss: 0.603, Test accuracy: 79.17
Round  58, Train loss: 0.130, Test loss: 0.591, Test accuracy: 80.03
Round  59, Train loss: 0.102, Test loss: 0.615, Test accuracy: 79.37
Round  60, Train loss: 0.140, Test loss: 0.621, Test accuracy: 79.13
Round  61, Train loss: 0.162, Test loss: 0.604, Test accuracy: 79.03
Round  62, Train loss: 0.113, Test loss: 0.611, Test accuracy: 79.27
Round  63, Train loss: 0.103, Test loss: 0.606, Test accuracy: 79.40
Round  64, Train loss: 0.151, Test loss: 0.615, Test accuracy: 79.03
Round  65, Train loss: 0.167, Test loss: 0.605, Test accuracy: 80.10
Round  66, Train loss: 0.121, Test loss: 0.605, Test accuracy: 79.07
Round  67, Train loss: 0.160, Test loss: 0.614, Test accuracy: 79.87
Round  68, Train loss: 0.143, Test loss: 0.607, Test accuracy: 79.93
Round  69, Train loss: 0.121, Test loss: 0.620, Test accuracy: 80.13
Round  70, Train loss: 0.072, Test loss: 0.625, Test accuracy: 79.70
Round  71, Train loss: 0.104, Test loss: 0.639, Test accuracy: 79.07
Round  72, Train loss: 0.130, Test loss: 0.663, Test accuracy: 79.00
Round  73, Train loss: 0.134, Test loss: 0.618, Test accuracy: 79.57
Round  74, Train loss: 0.111, Test loss: 0.628, Test accuracy: 79.47
Round  75, Train loss: 0.090, Test loss: 0.635, Test accuracy: 79.23
Round  76, Train loss: 0.163, Test loss: 0.626, Test accuracy: 79.07
Round  77, Train loss: 0.092, Test loss: 0.607, Test accuracy: 80.13
Round  78, Train loss: 0.072, Test loss: 0.622, Test accuracy: 79.70
Round  79, Train loss: 0.097, Test loss: 0.638, Test accuracy: 79.50
Round  80, Train loss: 0.108, Test loss: 0.605, Test accuracy: 80.67
Round  81, Train loss: 0.095, Test loss: 0.617, Test accuracy: 80.50
Round  82, Train loss: 0.091, Test loss: 0.602, Test accuracy: 81.07
Round  83, Train loss: 0.091, Test loss: 0.613, Test accuracy: 80.70
Round  84, Train loss: 0.088, Test loss: 0.605, Test accuracy: 80.40
Round  85, Train loss: 0.076, Test loss: 0.609, Test accuracy: 80.97
Round  86, Train loss: 0.073, Test loss: 0.609, Test accuracy: 81.00
Round  87, Train loss: 0.080, Test loss: 0.612, Test accuracy: 80.63
Round  88, Train loss: 0.079, Test loss: 0.619, Test accuracy: 80.87
Round  89, Train loss: 0.070, Test loss: 0.618, Test accuracy: 80.83
Round  90, Train loss: 0.072, Test loss: 0.634, Test accuracy: 80.40
Round  91, Train loss: 0.067, Test loss: 0.638, Test accuracy: 80.80
Round  92, Train loss: 0.068, Test loss: 0.647, Test accuracy: 80.47
Round  93, Train loss: 0.068, Test loss: 0.643, Test accuracy: 81.00
Round  94, Train loss: 0.064, Test loss: 0.642, Test accuracy: 80.47
Round  95, Train loss: 0.069, Test loss: 0.642, Test accuracy: 80.37
Round  96, Train loss: 0.060, Test loss: 0.651, Test accuracy: 80.63
Round  97, Train loss: 0.060, Test loss: 0.647, Test accuracy: 80.77
Round  98, Train loss: 0.053, Test loss: 0.644, Test accuracy: 81.43
Round  99, Train loss: 0.060, Test loss: 0.673, Test accuracy: 80.50
Final Round, Train loss: 0.043, Test loss: 0.664, Test accuracy: 80.70
Average accuracy final 10 rounds: 80.68333333333332
954.5627906322479
[1.8834311962127686, 3.4541852474212646, 5.022083044052124, 6.591005325317383, 8.140509605407715, 9.689646482467651, 11.237728118896484, 12.796525478363037, 14.35977053642273, 15.920918703079224, 17.480654001235962, 19.041322708129883, 20.618549823760986, 22.202094078063965, 23.786251544952393, 25.354084253311157, 26.91717290878296, 28.475035190582275, 30.04284954071045, 31.5971040725708, 33.149768114089966, 34.70371651649475, 36.256279945373535, 37.80541920661926, 39.35113573074341, 40.89818501472473, 42.46037721633911, 44.017951250076294, 45.59077739715576, 47.16954183578491, 48.72968363761902, 50.2985622882843, 51.84640884399414, 53.410919189453125, 54.968727827072144, 56.53115272521973, 58.0936005115509, 59.656079053878784, 61.21899938583374, 62.772438526153564, 64.31456327438354, 65.89392971992493, 67.31607937812805, 68.72616362571716, 70.13960719108582, 71.54201126098633, 72.95361471176147, 74.35689806938171, 75.76824188232422, 77.17910146713257, 78.57908630371094, 79.99029970169067, 81.39781951904297, 82.80957007408142, 84.22043323516846, 85.62052369117737, 87.03122401237488, 88.43685460090637, 89.84482073783875, 91.25152516365051, 92.65250015258789, 94.09894371032715, 95.51152849197388, 96.92861080169678, 98.34021925926208, 99.73320579528809, 101.14087009429932, 102.5478093624115, 103.96208333969116, 105.38526678085327, 106.81253051757812, 108.23572301864624, 109.65877842903137, 111.08175873756409, 112.50418972969055, 113.91990518569946, 115.34345316886902, 116.75025463104248, 118.17011094093323, 119.5918037891388, 121.01889610290527, 122.44886088371277, 123.87120914459229, 125.298011302948, 126.74331712722778, 128.1788637638092, 129.61899280548096, 131.05846786499023, 132.50056886672974, 133.94847226142883, 135.38304162025452, 136.8303997516632, 138.2768201828003, 139.71994638442993, 141.16070365905762, 142.59492468833923, 144.03890895843506, 145.48652529716492, 146.92957067489624, 148.38316702842712, 150.74652528762817]
[39.833333333333336, 57.833333333333336, 60.9, 68.0, 67.5, 68.63333333333334, 71.86666666666666, 72.2, 72.8, 73.96666666666667, 72.43333333333334, 74.66666666666667, 76.13333333333334, 76.0, 76.06666666666666, 77.73333333333333, 75.83333333333333, 76.3, 76.5, 76.93333333333334, 76.93333333333334, 76.66666666666667, 77.53333333333333, 77.0, 76.83333333333333, 75.66666666666667, 76.8, 78.13333333333334, 77.6, 77.3, 79.16666666666667, 77.23333333333333, 77.2, 78.66666666666667, 77.26666666666667, 77.6, 78.73333333333333, 78.73333333333333, 77.8, 79.06666666666666, 78.26666666666667, 78.36666666666666, 79.16666666666667, 78.73333333333333, 79.66666666666667, 79.06666666666666, 79.66666666666667, 79.43333333333334, 79.66666666666667, 79.33333333333333, 78.93333333333334, 78.53333333333333, 79.16666666666667, 78.26666666666667, 80.36666666666666, 79.3, 79.66666666666667, 79.16666666666667, 80.03333333333333, 79.36666666666666, 79.13333333333334, 79.03333333333333, 79.26666666666667, 79.4, 79.03333333333333, 80.1, 79.06666666666666, 79.86666666666666, 79.93333333333334, 80.13333333333334, 79.7, 79.06666666666666, 79.0, 79.56666666666666, 79.46666666666667, 79.23333333333333, 79.06666666666666, 80.13333333333334, 79.7, 79.5, 80.66666666666667, 80.5, 81.06666666666666, 80.7, 80.4, 80.96666666666667, 81.0, 80.63333333333334, 80.86666666666666, 80.83333333333333, 80.4, 80.8, 80.46666666666667, 81.0, 80.46666666666667, 80.36666666666666, 80.63333333333334, 80.76666666666667, 81.43333333333334, 80.5, 80.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.340, Test loss: 1.438, Test accuracy: 36.83
Round   1, Train loss: 0.950, Test loss: 0.962, Test accuracy: 56.10
Round   2, Train loss: 0.843, Test loss: 0.848, Test accuracy: 64.47
Round   3, Train loss: 0.775, Test loss: 0.817, Test accuracy: 62.80
Round   4, Train loss: 0.722, Test loss: 0.730, Test accuracy: 69.93
Round   5, Train loss: 0.690, Test loss: 0.712, Test accuracy: 69.70
Round   6, Train loss: 0.662, Test loss: 0.677, Test accuracy: 71.63
Round   7, Train loss: 0.634, Test loss: 0.656, Test accuracy: 72.87
Round   8, Train loss: 0.604, Test loss: 0.645, Test accuracy: 73.50
Round   9, Train loss: 0.590, Test loss: 0.639, Test accuracy: 73.73
Round  10, Train loss: 0.574, Test loss: 0.614, Test accuracy: 74.43
Round  11, Train loss: 0.554, Test loss: 0.609, Test accuracy: 75.00
Round  12, Train loss: 0.542, Test loss: 0.629, Test accuracy: 73.80
Round  13, Train loss: 0.526, Test loss: 0.586, Test accuracy: 76.03
Round  14, Train loss: 0.503, Test loss: 0.574, Test accuracy: 76.60
Round  15, Train loss: 0.496, Test loss: 0.592, Test accuracy: 76.17
Round  16, Train loss: 0.480, Test loss: 0.570, Test accuracy: 77.40
Round  17, Train loss: 0.466, Test loss: 0.565, Test accuracy: 77.40
Round  18, Train loss: 0.446, Test loss: 0.573, Test accuracy: 76.70
Round  19, Train loss: 0.436, Test loss: 0.570, Test accuracy: 76.50
Round  20, Train loss: 0.475, Test loss: 0.572, Test accuracy: 76.23
Round  21, Train loss: 0.392, Test loss: 0.593, Test accuracy: 76.07
Round  22, Train loss: 0.475, Test loss: 0.625, Test accuracy: 74.33
Round  23, Train loss: 0.373, Test loss: 0.656, Test accuracy: 74.17
Round  24, Train loss: 0.456, Test loss: 0.602, Test accuracy: 76.27
Round  25, Train loss: 0.321, Test loss: 0.612, Test accuracy: 75.67
Round  26, Train loss: 0.296, Test loss: 0.593, Test accuracy: 76.33
Round  27, Train loss: 0.373, Test loss: 0.585, Test accuracy: 76.30
Round  28, Train loss: 0.333, Test loss: 0.575, Test accuracy: 77.40
Round  29, Train loss: 0.332, Test loss: 0.594, Test accuracy: 76.93
Round  30, Train loss: 0.306, Test loss: 0.607, Test accuracy: 75.63
Round  31, Train loss: 0.302, Test loss: 0.604, Test accuracy: 76.60
Round  32, Train loss: 0.254, Test loss: 0.592, Test accuracy: 76.67
Round  33, Train loss: 0.296, Test loss: 0.576, Test accuracy: 77.33
Round  34, Train loss: 0.282, Test loss: 0.576, Test accuracy: 77.10
Round  35, Train loss: 0.374, Test loss: 0.552, Test accuracy: 79.27
Round  36, Train loss: 0.384, Test loss: 0.589, Test accuracy: 77.40
Round  37, Train loss: 0.245, Test loss: 0.585, Test accuracy: 77.07
Round  38, Train loss: 0.340, Test loss: 0.591, Test accuracy: 77.57
Round  39, Train loss: 0.245, Test loss: 0.604, Test accuracy: 76.57
Round  40, Train loss: 0.322, Test loss: 0.580, Test accuracy: 78.03
Round  41, Train loss: 0.335, Test loss: 0.592, Test accuracy: 77.47
Round  42, Train loss: 0.247, Test loss: 0.589, Test accuracy: 77.30
Round  43, Train loss: 0.218, Test loss: 0.592, Test accuracy: 78.07
Round  44, Train loss: 0.305, Test loss: 0.594, Test accuracy: 77.43
Round  45, Train loss: 0.284, Test loss: 0.624, Test accuracy: 78.10
Round  46, Train loss: 0.243, Test loss: 0.626, Test accuracy: 77.63
Round  47, Train loss: 0.220, Test loss: 0.625, Test accuracy: 77.27
Round  48, Train loss: 0.211, Test loss: 0.608, Test accuracy: 78.03
Round  49, Train loss: 0.251, Test loss: 0.613, Test accuracy: 77.07
Round  50, Train loss: 0.190, Test loss: 0.639, Test accuracy: 78.03
Round  51, Train loss: 0.220, Test loss: 0.614, Test accuracy: 78.50
Round  52, Train loss: 0.123, Test loss: 0.618, Test accuracy: 78.43
Round  53, Train loss: 0.218, Test loss: 0.588, Test accuracy: 78.73
Round  54, Train loss: 0.170, Test loss: 0.598, Test accuracy: 78.47
Round  55, Train loss: 0.218, Test loss: 0.602, Test accuracy: 78.80
Round  56, Train loss: 0.175, Test loss: 0.618, Test accuracy: 79.17
Round  57, Train loss: 0.156, Test loss: 0.629, Test accuracy: 78.70
Round  58, Train loss: 0.107, Test loss: 0.628, Test accuracy: 79.10
Round  59, Train loss: 0.156, Test loss: 0.632, Test accuracy: 79.40
Round  60, Train loss: 0.194, Test loss: 0.622, Test accuracy: 79.10
Round  61, Train loss: 0.134, Test loss: 0.619, Test accuracy: 78.73
Round  62, Train loss: 0.203, Test loss: 0.616, Test accuracy: 78.20
Round  63, Train loss: 0.165, Test loss: 0.651, Test accuracy: 78.53
Round  64, Train loss: 0.161, Test loss: 0.667, Test accuracy: 78.03
Round  65, Train loss: 0.180, Test loss: 0.649, Test accuracy: 78.73
Round  66, Train loss: 0.181, Test loss: 0.671, Test accuracy: 78.77
Round  67, Train loss: 0.127, Test loss: 0.654, Test accuracy: 79.13
Round  68, Train loss: 0.157, Test loss: 0.638, Test accuracy: 78.43
Round  69, Train loss: 0.123, Test loss: 0.641, Test accuracy: 78.80
Round  70, Train loss: 0.156, Test loss: 0.643, Test accuracy: 78.53
Round  71, Train loss: 0.169, Test loss: 0.662, Test accuracy: 78.27
Round  72, Train loss: 0.124, Test loss: 0.665, Test accuracy: 78.43
Round  73, Train loss: 0.138, Test loss: 0.657, Test accuracy: 78.63
Round  74, Train loss: 0.099, Test loss: 0.646, Test accuracy: 78.47
Round  75, Train loss: 0.105, Test loss: 0.667, Test accuracy: 76.93
Round  76, Train loss: 0.093, Test loss: 0.653, Test accuracy: 78.90
Round  77, Train loss: 0.142, Test loss: 0.682, Test accuracy: 77.77
Round  78, Train loss: 0.130, Test loss: 0.670, Test accuracy: 78.03
Round  79, Train loss: 0.109, Test loss: 0.655, Test accuracy: 78.27
Round  80, Train loss: 0.106, Test loss: 0.643, Test accuracy: 78.83
Round  81, Train loss: 0.088, Test loss: 0.644, Test accuracy: 78.97
Round  82, Train loss: 0.089, Test loss: 0.634, Test accuracy: 79.67
Round  83, Train loss: 0.088, Test loss: 0.646, Test accuracy: 79.60
Round  84, Train loss: 0.080, Test loss: 0.643, Test accuracy: 80.40
Round  85, Train loss: 0.082, Test loss: 0.648, Test accuracy: 79.40
Round  86, Train loss: 0.080, Test loss: 0.645, Test accuracy: 79.53
Round  87, Train loss: 0.073, Test loss: 0.649, Test accuracy: 79.83
Round  88, Train loss: 0.065, Test loss: 0.654, Test accuracy: 80.00
Round  89, Train loss: 0.078, Test loss: 0.658, Test accuracy: 79.67
Round  90, Train loss: 0.065, Test loss: 0.675, Test accuracy: 79.50
Round  91, Train loss: 0.064, Test loss: 0.665, Test accuracy: 79.60
Round  92, Train loss: 0.065, Test loss: 0.654, Test accuracy: 79.70
Round  93, Train loss: 0.065, Test loss: 0.667, Test accuracy: 79.53
Round  94, Train loss: 0.056, Test loss: 0.668, Test accuracy: 79.57
Round  95, Train loss: 0.059, Test loss: 0.665, Test accuracy: 79.40
Round  96, Train loss: 0.063, Test loss: 0.677, Test accuracy: 79.63
Round  97, Train loss: 0.055, Test loss: 0.673, Test accuracy: 80.00
Round  98, Train loss: 0.051, Test loss: 0.678, Test accuracy: 79.57
Round  99, Train loss: 0.056, Test loss: 0.680, Test accuracy: 79.50
Final Round, Train loss: 0.038, Test loss: 0.689, Test accuracy: 79.50
Average accuracy final 10 rounds: 79.6
1460.5836281776428
[1.8888423442840576, 3.4891977310180664, 5.0877320766448975, 6.667662143707275, 8.244869470596313, 9.826631784439087, 11.404378175735474, 12.979869842529297, 14.558624982833862, 16.132843255996704, 17.707399606704712, 19.2978732585907, 20.89455556869507, 22.473337650299072, 23.899354457855225, 25.323694229125977, 26.74870777130127, 28.174031972885132, 29.59754753112793, 31.023470401763916, 32.44890999794006, 35.38769268989563, 38.29968476295471, 41.226940631866455, 43.94849252700806, 46.86750340461731, 49.77542042732239, 52.47192192077637, 55.39736580848694, 58.19099402427673, 60.99945640563965, 63.91904854774475, 66.82981944084167, 69.70005106925964, 72.47453832626343, 75.39046573638916, 78.30364394187927, 81.20011353492737, 84.12091255187988, 86.94822573661804, 89.85451459884644, 92.77911305427551, 95.54494452476501, 98.46788191795349, 101.35893487930298, 104.26729226112366, 107.17596125602722, 110.11222958564758, 113.02131605148315, 115.95699334144592, 118.72590446472168, 121.64339518547058, 124.56227421760559, 127.28695678710938, 130.21334266662598, 133.07434391975403, 135.8395335674286, 138.77861762046814, 141.70242929458618, 144.5818293094635, 147.47297644615173, 150.29720973968506, 153.2212631702423, 156.07408499717712, 158.99429416656494, 161.89942121505737, 164.8259060382843, 167.73931789398193, 170.5334849357605, 173.4462594985962, 176.36792993545532, 179.29771661758423, 182.22068858146667, 185.09616684913635, 188.014475107193, 190.93961215019226, 193.66348099708557, 196.58817219734192, 199.51226258277893, 202.30700874328613, 205.23525094985962, 208.163161277771, 211.08208632469177, 214.00144720077515, 216.91741156578064, 219.8505425453186, 222.78069686889648, 225.7157382965088, 228.6365556716919, 231.5628170967102, 234.47835111618042, 237.4038746356964, 240.3256058692932, 243.25919556617737, 246.1841287612915, 249.1083071231842, 252.0302357673645, 254.95546865463257, 257.87735629081726, 260.7967686653137, 263.11947441101074]
[36.833333333333336, 56.1, 64.46666666666667, 62.8, 69.93333333333334, 69.7, 71.63333333333334, 72.86666666666666, 73.5, 73.73333333333333, 74.43333333333334, 75.0, 73.8, 76.03333333333333, 76.6, 76.16666666666667, 77.4, 77.4, 76.7, 76.5, 76.23333333333333, 76.06666666666666, 74.33333333333333, 74.16666666666667, 76.26666666666667, 75.66666666666667, 76.33333333333333, 76.3, 77.4, 76.93333333333334, 75.63333333333334, 76.6, 76.66666666666667, 77.33333333333333, 77.1, 79.26666666666667, 77.4, 77.06666666666666, 77.56666666666666, 76.56666666666666, 78.03333333333333, 77.46666666666667, 77.3, 78.06666666666666, 77.43333333333334, 78.1, 77.63333333333334, 77.26666666666667, 78.03333333333333, 77.06666666666666, 78.03333333333333, 78.5, 78.43333333333334, 78.73333333333333, 78.46666666666667, 78.8, 79.16666666666667, 78.7, 79.1, 79.4, 79.1, 78.73333333333333, 78.2, 78.53333333333333, 78.03333333333333, 78.73333333333333, 78.76666666666667, 79.13333333333334, 78.43333333333334, 78.8, 78.53333333333333, 78.26666666666667, 78.43333333333334, 78.63333333333334, 78.46666666666667, 76.93333333333334, 78.9, 77.76666666666667, 78.03333333333333, 78.26666666666667, 78.83333333333333, 78.96666666666667, 79.66666666666667, 79.6, 80.4, 79.4, 79.53333333333333, 79.83333333333333, 80.0, 79.66666666666667, 79.5, 79.6, 79.7, 79.53333333333333, 79.56666666666666, 79.4, 79.63333333333334, 80.0, 79.56666666666666, 79.5, 79.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.339, Test loss: 1.320, Test accuracy: 48.33
Round   1, Train loss: 0.915, Test loss: 0.939, Test accuracy: 56.20
Round   2, Train loss: 0.811, Test loss: 0.827, Test accuracy: 62.00
Round   3, Train loss: 0.750, Test loss: 0.781, Test accuracy: 63.67
Round   4, Train loss: 0.705, Test loss: 0.745, Test accuracy: 67.23
Round   5, Train loss: 0.675, Test loss: 0.729, Test accuracy: 69.00
Round   6, Train loss: 0.651, Test loss: 0.690, Test accuracy: 70.33
Round   7, Train loss: 0.631, Test loss: 0.664, Test accuracy: 71.53
Round   8, Train loss: 0.612, Test loss: 0.645, Test accuracy: 72.13
Round   9, Train loss: 0.588, Test loss: 0.634, Test accuracy: 72.57
Round  10, Train loss: 0.572, Test loss: 0.619, Test accuracy: 73.63
Round  11, Train loss: 0.558, Test loss: 0.620, Test accuracy: 73.93
Round  12, Train loss: 0.533, Test loss: 0.594, Test accuracy: 75.50
Round  13, Train loss: 0.517, Test loss: 0.584, Test accuracy: 75.93
Round  14, Train loss: 0.504, Test loss: 0.598, Test accuracy: 74.47
Round  15, Train loss: 0.489, Test loss: 0.574, Test accuracy: 75.87
Round  16, Train loss: 0.472, Test loss: 0.582, Test accuracy: 75.37
Round  17, Train loss: 0.460, Test loss: 0.572, Test accuracy: 76.17
Round  18, Train loss: 0.442, Test loss: 0.569, Test accuracy: 76.17
Round  19, Train loss: 0.433, Test loss: 0.568, Test accuracy: 76.33
Round  20, Train loss: 0.414, Test loss: 0.589, Test accuracy: 76.00
Round  21, Train loss: 0.367, Test loss: 0.602, Test accuracy: 75.70
Round  22, Train loss: 0.398, Test loss: 0.573, Test accuracy: 76.17
Round  23, Train loss: 0.426, Test loss: 0.574, Test accuracy: 76.10
Round  24, Train loss: 0.343, Test loss: 0.584, Test accuracy: 76.80
Round  25, Train loss: 0.384, Test loss: 0.594, Test accuracy: 75.67
Round  26, Train loss: 0.307, Test loss: 0.590, Test accuracy: 75.83
Round  27, Train loss: 0.379, Test loss: 0.555, Test accuracy: 77.33
Round  28, Train loss: 0.468, Test loss: 0.567, Test accuracy: 77.47
Round  29, Train loss: 0.445, Test loss: 0.582, Test accuracy: 77.37
Round  30, Train loss: 0.426, Test loss: 0.585, Test accuracy: 77.20
Round  31, Train loss: 0.262, Test loss: 0.585, Test accuracy: 77.70
Round  32, Train loss: 0.400, Test loss: 0.596, Test accuracy: 77.03
Round  33, Train loss: 0.231, Test loss: 0.585, Test accuracy: 78.23
Round  34, Train loss: 0.269, Test loss: 0.602, Test accuracy: 76.90
Round  35, Train loss: 0.261, Test loss: 0.587, Test accuracy: 77.43
Round  36, Train loss: 0.230, Test loss: 0.600, Test accuracy: 77.70
Round  37, Train loss: 0.162, Test loss: 0.605, Test accuracy: 76.87
Round  38, Train loss: 0.354, Test loss: 0.604, Test accuracy: 77.73
Round  39, Train loss: 0.361, Test loss: 0.590, Test accuracy: 78.07
Round  40, Train loss: 0.250, Test loss: 0.564, Test accuracy: 77.60
Round  41, Train loss: 0.150, Test loss: 0.578, Test accuracy: 78.67
Round  42, Train loss: 0.246, Test loss: 0.590, Test accuracy: 77.93
Round  43, Train loss: 0.185, Test loss: 0.560, Test accuracy: 78.97
Round  44, Train loss: 0.234, Test loss: 0.582, Test accuracy: 78.20
Round  45, Train loss: 0.196, Test loss: 0.615, Test accuracy: 78.07
Round  46, Train loss: 0.131, Test loss: 0.619, Test accuracy: 78.70
Round  47, Train loss: 0.212, Test loss: 0.574, Test accuracy: 79.17
Round  48, Train loss: 0.164, Test loss: 0.599, Test accuracy: 77.93
Round  49, Train loss: 0.176, Test loss: 0.574, Test accuracy: 78.80
Round  50, Train loss: 0.325, Test loss: 0.581, Test accuracy: 78.70
Round  51, Train loss: 0.168, Test loss: 0.589, Test accuracy: 78.43
Round  52, Train loss: 0.220, Test loss: 0.585, Test accuracy: 78.77
Round  53, Train loss: 0.217, Test loss: 0.605, Test accuracy: 78.17
Round  54, Train loss: 0.184, Test loss: 0.592, Test accuracy: 78.50
Round  55, Train loss: 0.168, Test loss: 0.598, Test accuracy: 78.77
Round  56, Train loss: 0.125, Test loss: 0.600, Test accuracy: 79.43
Round  57, Train loss: 0.152, Test loss: 0.604, Test accuracy: 78.57
Round  58, Train loss: 0.220, Test loss: 0.597, Test accuracy: 78.73
Round  59, Train loss: 0.115, Test loss: 0.624, Test accuracy: 78.47
Round  60, Train loss: 0.139, Test loss: 0.599, Test accuracy: 78.30
Round  61, Train loss: 0.240, Test loss: 0.607, Test accuracy: 78.27
Round  62, Train loss: 0.150, Test loss: 0.613, Test accuracy: 78.80
Round  63, Train loss: 0.132, Test loss: 0.609, Test accuracy: 78.93
Round  64, Train loss: 0.135, Test loss: 0.614, Test accuracy: 79.13
Round  65, Train loss: 0.090, Test loss: 0.649, Test accuracy: 77.63
Round  66, Train loss: 0.254, Test loss: 0.657, Test accuracy: 77.77
Round  67, Train loss: 0.100, Test loss: 0.630, Test accuracy: 79.37
Round  68, Train loss: 0.201, Test loss: 0.667, Test accuracy: 78.20
Round  69, Train loss: 0.177, Test loss: 0.671, Test accuracy: 78.30
Round  70, Train loss: 0.150, Test loss: 0.670, Test accuracy: 78.30
Round  71, Train loss: 0.153, Test loss: 0.673, Test accuracy: 78.97
Round  72, Train loss: 0.101, Test loss: 0.650, Test accuracy: 78.80
Round  73, Train loss: 0.180, Test loss: 0.669, Test accuracy: 78.90
Round  74, Train loss: 0.156, Test loss: 0.651, Test accuracy: 77.90
Round  75, Train loss: 0.126, Test loss: 0.650, Test accuracy: 78.57
Round  76, Train loss: 0.114, Test loss: 0.633, Test accuracy: 78.67
Round  77, Train loss: 0.115, Test loss: 0.639, Test accuracy: 78.03
Round  78, Train loss: 0.084, Test loss: 0.651, Test accuracy: 78.87
Round  79, Train loss: 0.101, Test loss: 0.654, Test accuracy: 79.03
Round  80, Train loss: 0.102, Test loss: 0.628, Test accuracy: 80.70
Round  81, Train loss: 0.101, Test loss: 0.639, Test accuracy: 79.97
Round  82, Train loss: 0.094, Test loss: 0.629, Test accuracy: 80.17
Round  83, Train loss: 0.084, Test loss: 0.642, Test accuracy: 80.73
Round  84, Train loss: 0.093, Test loss: 0.648, Test accuracy: 79.47
Round  85, Train loss: 0.095, Test loss: 0.634, Test accuracy: 79.90
Round  86, Train loss: 0.080, Test loss: 0.639, Test accuracy: 80.33
Round  87, Train loss: 0.074, Test loss: 0.643, Test accuracy: 80.40
Round  88, Train loss: 0.076, Test loss: 0.646, Test accuracy: 80.37
Round  89, Train loss: 0.071, Test loss: 0.642, Test accuracy: 80.83
Round  90, Train loss: 0.074, Test loss: 0.647, Test accuracy: 79.97
Round  91, Train loss: 0.075, Test loss: 0.642, Test accuracy: 80.30
Round  92, Train loss: 0.065, Test loss: 0.653, Test accuracy: 79.83
Round  93, Train loss: 0.073, Test loss: 0.655, Test accuracy: 79.83
Round  94, Train loss: 0.064, Test loss: 0.658, Test accuracy: 79.87
Round  95, Train loss: 0.061, Test loss: 0.650, Test accuracy: 80.13
Round  96, Train loss: 0.057, Test loss: 0.670, Test accuracy: 80.27
Round  97, Train loss: 0.062, Test loss: 0.665, Test accuracy: 79.97
Round  98, Train loss: 0.053, Test loss: 0.663, Test accuracy: 80.23
Round  99, Train loss: 0.065, Test loss: 0.678, Test accuracy: 80.07
Final Round, Train loss: 0.043, Test loss: 0.673, Test accuracy: 80.33
Average accuracy final 10 rounds: 80.04666666666665
1405.7935767173767
[1.868948221206665, 3.4860196113586426, 5.1165924072265625, 6.733319282531738, 8.363576173782349, 9.983994960784912, 11.591382026672363, 13.187943458557129, 14.77546215057373, 16.35817265510559, 17.936842441558838, 19.651965856552124, 21.105099201202393, 22.562222242355347, 24.02567982673645, 25.48920774459839, 26.950867414474487, 28.411558866500854, 29.88045334815979, 31.346139669418335, 32.81555676460266, 35.50369215011597, 38.19951891899109, 40.87262153625488, 43.55043983459473, 46.22921299934387, 48.90689444541931, 51.59168338775635, 54.279263973236084, 56.940651655197144, 59.59655046463013, 62.25260782241821, 64.94601678848267, 67.64560055732727, 70.27011942863464, 72.96226334571838, 75.64931511878967, 78.32871675491333, 81.01950430870056, 83.69874691963196, 86.38633060455322, 89.07093238830566, 91.74770545959473, 94.41117238998413, 97.06919121742249, 99.7341365814209, 102.41003823280334, 105.09396529197693, 107.77621269226074, 110.4585030078888, 113.14320206642151, 115.83043241500854, 118.48064923286438, 121.16489744186401, 123.81708478927612, 126.49036741256714, 129.16137266159058, 131.8589527606964, 134.48434567451477, 137.14600920677185, 139.82033586502075, 142.478839635849, 145.12039136886597, 147.7768430709839, 150.40718746185303, 153.04986548423767, 155.7028706073761, 158.34615468978882, 161.046541929245, 163.70139527320862, 166.3203628063202, 168.97846865653992, 171.61511898040771, 174.2646985054016, 176.9124345779419, 179.55772995948792, 182.2291865348816, 184.8993628025055, 187.56539726257324, 190.19550609588623, 192.86146211624146, 195.5255889892578, 198.23277926445007, 200.93186235427856, 203.6048617362976, 206.27795433998108, 208.96405744552612, 211.6365189552307, 214.32942175865173, 217.00424599647522, 219.66203618049622, 222.3468885421753, 225.00344133377075, 227.69703459739685, 230.3537871837616, 233.0249433517456, 235.69044828414917, 238.37544226646423, 241.04605841636658, 243.70747590065002, 246.09065508842468]
[48.333333333333336, 56.2, 62.0, 63.666666666666664, 67.23333333333333, 69.0, 70.33333333333333, 71.53333333333333, 72.13333333333334, 72.56666666666666, 73.63333333333334, 73.93333333333334, 75.5, 75.93333333333334, 74.46666666666667, 75.86666666666666, 75.36666666666666, 76.16666666666667, 76.16666666666667, 76.33333333333333, 76.0, 75.7, 76.16666666666667, 76.1, 76.8, 75.66666666666667, 75.83333333333333, 77.33333333333333, 77.46666666666667, 77.36666666666666, 77.2, 77.7, 77.03333333333333, 78.23333333333333, 76.9, 77.43333333333334, 77.7, 76.86666666666666, 77.73333333333333, 78.06666666666666, 77.6, 78.66666666666667, 77.93333333333334, 78.96666666666667, 78.2, 78.06666666666666, 78.7, 79.16666666666667, 77.93333333333334, 78.8, 78.7, 78.43333333333334, 78.76666666666667, 78.16666666666667, 78.5, 78.76666666666667, 79.43333333333334, 78.56666666666666, 78.73333333333333, 78.46666666666667, 78.3, 78.26666666666667, 78.8, 78.93333333333334, 79.13333333333334, 77.63333333333334, 77.76666666666667, 79.36666666666666, 78.2, 78.3, 78.3, 78.96666666666667, 78.8, 78.9, 77.9, 78.56666666666666, 78.66666666666667, 78.03333333333333, 78.86666666666666, 79.03333333333333, 80.7, 79.96666666666667, 80.16666666666667, 80.73333333333333, 79.46666666666667, 79.9, 80.33333333333333, 80.4, 80.36666666666666, 80.83333333333333, 79.96666666666667, 80.3, 79.83333333333333, 79.83333333333333, 79.86666666666666, 80.13333333333334, 80.26666666666667, 79.96666666666667, 80.23333333333333, 80.06666666666666, 80.33333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.715, Test loss: 2.290, Test accuracy: 21.77
Round   1, Train loss: 1.143, Test loss: 2.303, Test accuracy: 31.40
Round   2, Train loss: 1.064, Test loss: 1.322, Test accuracy: 47.73
Round   3, Train loss: 1.023, Test loss: 1.251, Test accuracy: 51.87
Round   4, Train loss: 1.060, Test loss: 0.926, Test accuracy: 57.27
Round   5, Train loss: 0.938, Test loss: 0.915, Test accuracy: 58.53
Round   6, Train loss: 0.940, Test loss: 0.891, Test accuracy: 60.37
Round   7, Train loss: 0.902, Test loss: 0.854, Test accuracy: 62.43
Round   8, Train loss: 0.799, Test loss: 0.806, Test accuracy: 64.73
Round   9, Train loss: 0.810, Test loss: 0.802, Test accuracy: 65.60
Round  10, Train loss: 0.869, Test loss: 0.781, Test accuracy: 66.97
Round  11, Train loss: 0.832, Test loss: 0.782, Test accuracy: 66.27
Round  12, Train loss: 0.775, Test loss: 0.754, Test accuracy: 67.60
Round  13, Train loss: 0.770, Test loss: 0.731, Test accuracy: 69.03
Round  14, Train loss: 0.815, Test loss: 0.715, Test accuracy: 70.80
Round  15, Train loss: 0.647, Test loss: 0.697, Test accuracy: 70.60
Round  16, Train loss: 0.790, Test loss: 0.712, Test accuracy: 69.90
Round  17, Train loss: 0.751, Test loss: 0.707, Test accuracy: 72.77
Round  18, Train loss: 0.695, Test loss: 0.691, Test accuracy: 71.87
Round  19, Train loss: 0.833, Test loss: 0.669, Test accuracy: 72.30
Round  20, Train loss: 0.873, Test loss: 0.681, Test accuracy: 71.53
Round  21, Train loss: 0.626, Test loss: 0.674, Test accuracy: 71.97
Round  22, Train loss: 0.849, Test loss: 0.657, Test accuracy: 72.80
Round  23, Train loss: 0.753, Test loss: 0.672, Test accuracy: 71.80
Round  24, Train loss: 0.595, Test loss: 0.661, Test accuracy: 72.23
Round  25, Train loss: 0.642, Test loss: 0.659, Test accuracy: 73.53
Round  26, Train loss: 0.653, Test loss: 0.647, Test accuracy: 74.07
Round  27, Train loss: 0.645, Test loss: 0.645, Test accuracy: 73.63
Round  28, Train loss: 0.768, Test loss: 0.648, Test accuracy: 74.23
Round  29, Train loss: 0.595, Test loss: 0.634, Test accuracy: 75.10
Round  30, Train loss: 0.686, Test loss: 0.640, Test accuracy: 74.20
Round  31, Train loss: 0.621, Test loss: 0.641, Test accuracy: 73.50
Round  32, Train loss: 0.550, Test loss: 0.630, Test accuracy: 74.50
Round  33, Train loss: 0.766, Test loss: 0.645, Test accuracy: 74.40
Round  34, Train loss: 0.674, Test loss: 0.635, Test accuracy: 74.57
Round  35, Train loss: 0.662, Test loss: 0.639, Test accuracy: 75.40
Round  36, Train loss: 0.720, Test loss: 0.625, Test accuracy: 75.43
Round  37, Train loss: 0.708, Test loss: 0.609, Test accuracy: 76.20
Round  38, Train loss: 0.644, Test loss: 0.608, Test accuracy: 76.53
Round  39, Train loss: 0.685, Test loss: 0.639, Test accuracy: 74.80
Round  40, Train loss: 0.579, Test loss: 0.616, Test accuracy: 76.00
Round  41, Train loss: 0.446, Test loss: 0.589, Test accuracy: 77.20
Round  42, Train loss: 0.484, Test loss: 0.589, Test accuracy: 76.67
Round  43, Train loss: 0.609, Test loss: 0.596, Test accuracy: 76.30
Round  44, Train loss: 0.755, Test loss: 0.588, Test accuracy: 76.17
Round  45, Train loss: 0.584, Test loss: 0.606, Test accuracy: 75.77
Round  46, Train loss: 0.638, Test loss: 0.604, Test accuracy: 75.50
Round  47, Train loss: 0.592, Test loss: 0.593, Test accuracy: 76.77
Round  48, Train loss: 0.575, Test loss: 0.585, Test accuracy: 75.97
Round  49, Train loss: 0.705, Test loss: 0.612, Test accuracy: 76.13
Round  50, Train loss: 0.564, Test loss: 0.598, Test accuracy: 77.10
Round  51, Train loss: 0.674, Test loss: 0.591, Test accuracy: 77.23
Round  52, Train loss: 0.629, Test loss: 0.585, Test accuracy: 77.37
Round  53, Train loss: 0.395, Test loss: 0.566, Test accuracy: 77.77
Round  54, Train loss: 0.603, Test loss: 0.567, Test accuracy: 77.87
Round  55, Train loss: 0.436, Test loss: 0.579, Test accuracy: 76.77
Round  56, Train loss: 0.605, Test loss: 0.576, Test accuracy: 77.47
Round  57, Train loss: 0.417, Test loss: 0.580, Test accuracy: 77.17
Round  58, Train loss: 0.550, Test loss: 0.574, Test accuracy: 77.43
Round  59, Train loss: 0.473, Test loss: 0.578, Test accuracy: 77.30
Round  60, Train loss: 0.653, Test loss: 0.562, Test accuracy: 77.80
Round  61, Train loss: 0.470, Test loss: 0.580, Test accuracy: 77.90
Round  62, Train loss: 0.471, Test loss: 0.589, Test accuracy: 76.53
Round  63, Train loss: 0.649, Test loss: 0.582, Test accuracy: 76.97
Round  64, Train loss: 0.510, Test loss: 0.573, Test accuracy: 77.33
Round  65, Train loss: 0.597, Test loss: 0.602, Test accuracy: 76.57
Round  66, Train loss: 0.470, Test loss: 0.584, Test accuracy: 77.87
Round  67, Train loss: 0.565, Test loss: 0.571, Test accuracy: 77.90
Round  68, Train loss: 0.521, Test loss: 0.583, Test accuracy: 77.03
Round  69, Train loss: 0.457, Test loss: 0.562, Test accuracy: 78.00
Round  70, Train loss: 0.450, Test loss: 0.576, Test accuracy: 77.17
Round  71, Train loss: 0.461, Test loss: 0.585, Test accuracy: 77.03
Round  72, Train loss: 0.429, Test loss: 0.581, Test accuracy: 77.60
Round  73, Train loss: 0.406, Test loss: 0.579, Test accuracy: 77.50
Round  74, Train loss: 0.406, Test loss: 0.569, Test accuracy: 78.03
Round  75, Train loss: 0.423, Test loss: 0.551, Test accuracy: 78.70
Round  76, Train loss: 0.409, Test loss: 0.561, Test accuracy: 78.23
Round  77, Train loss: 0.515, Test loss: 0.568, Test accuracy: 78.17
Round  78, Train loss: 0.536, Test loss: 0.581, Test accuracy: 77.40
Round  79, Train loss: 0.361, Test loss: 0.559, Test accuracy: 78.30
Round  80, Train loss: 0.465, Test loss: 0.562, Test accuracy: 78.43
Round  81, Train loss: 0.466, Test loss: 0.566, Test accuracy: 78.13
Round  82, Train loss: 0.338, Test loss: 0.584, Test accuracy: 77.83
Round  83, Train loss: 0.357, Test loss: 0.579, Test accuracy: 77.27
Round  84, Train loss: 0.396, Test loss: 0.571, Test accuracy: 77.73
Round  85, Train loss: 0.312, Test loss: 0.577, Test accuracy: 77.63
Round  86, Train loss: 0.492, Test loss: 0.585, Test accuracy: 76.63
Round  87, Train loss: 0.315, Test loss: 0.604, Test accuracy: 76.53
Round  88, Train loss: 0.263, Test loss: 0.591, Test accuracy: 76.93
Round  89, Train loss: 0.320, Test loss: 0.609, Test accuracy: 76.47
Round  90, Train loss: 0.377, Test loss: 0.579, Test accuracy: 78.50
Round  91, Train loss: 0.303, Test loss: 0.598, Test accuracy: 77.47
Round  92, Train loss: 0.224, Test loss: 0.591, Test accuracy: 76.70
Round  93, Train loss: 0.199, Test loss: 0.590, Test accuracy: 77.30
Round  94, Train loss: 0.314, Test loss: 0.597, Test accuracy: 77.43
Round  95, Train loss: 0.266, Test loss: 0.593, Test accuracy: 77.50
Round  96, Train loss: 0.401, Test loss: 0.589, Test accuracy: 77.27
Round  97, Train loss: 0.224, Test loss: 0.593, Test accuracy: 77.83
Round  98, Train loss: 0.475, Test loss: 0.596, Test accuracy: 77.33
Round  99, Train loss: 0.389, Test loss: 0.605, Test accuracy: 77.27
Final Round, Train loss: 0.301, Test loss: 0.595, Test accuracy: 78.17
Average accuracy final 10 rounds: 77.46000000000001
313.73570704460144
[1.1822736263275146, 2.028017520904541, 2.8665215969085693, 3.717907428741455, 4.5541112422943115, 5.395137786865234, 6.238111257553101, 7.073570251464844, 7.909592866897583, 8.74463963508606, 9.58465838432312, 10.428946018218994, 11.269717693328857, 12.107445001602173, 12.945329189300537, 13.783732891082764, 14.616425514221191, 15.45386004447937, 16.29550051689148, 17.141467571258545, 17.989464282989502, 18.82141399383545, 19.603189706802368, 20.389198064804077, 21.173030614852905, 21.9604754447937, 22.73878502845764, 23.526514291763306, 24.311177730560303, 25.095391750335693, 25.88639211654663, 26.676153421401978, 27.453986883163452, 28.241891145706177, 29.022940635681152, 29.802622318267822, 30.585036516189575, 31.420374393463135, 32.2619092464447, 33.098856925964355, 33.93640160560608, 34.773231506347656, 35.61853742599487, 36.464871644973755, 37.308454513549805, 38.14464974403381, 38.97731804847717, 39.812432527542114, 40.64923095703125, 41.36368155479431, 42.08224606513977, 42.79826068878174, 43.514755964279175, 44.22995615005493, 44.940683364868164, 45.64927411079407, 46.3610475063324, 47.07741618156433, 47.792712450027466, 48.50817513465881, 49.22594666481018, 49.936991691589355, 50.64372158050537, 51.36022329330444, 52.07889246940613, 52.7930588722229, 53.509624004364014, 54.22049069404602, 54.92705798149109, 55.64470982551575, 56.39140248298645, 57.107097864151, 57.82478308677673, 58.54286575317383, 59.25267672538757, 59.98425364494324, 60.69803810119629, 61.41275501251221, 62.13125920295715, 62.84749221801758, 63.55922794342041, 64.26780700683594, 64.98502254486084, 65.70151901245117, 66.4185049533844, 67.13441514968872, 67.84794402122498, 68.55673122406006, 69.2649712562561, 69.98100662231445, 70.70060849189758, 71.41774702072144, 72.13425779342651, 72.84249949455261, 73.55267190933228, 74.26222515106201, 74.97524523735046, 75.68729186058044, 76.3961935043335, 77.10554003715515, 78.26476287841797]
[21.766666666666666, 31.4, 47.733333333333334, 51.86666666666667, 57.266666666666666, 58.53333333333333, 60.36666666666667, 62.43333333333333, 64.73333333333333, 65.6, 66.96666666666667, 66.26666666666667, 67.6, 69.03333333333333, 70.8, 70.6, 69.9, 72.76666666666667, 71.86666666666666, 72.3, 71.53333333333333, 71.96666666666667, 72.8, 71.8, 72.23333333333333, 73.53333333333333, 74.06666666666666, 73.63333333333334, 74.23333333333333, 75.1, 74.2, 73.5, 74.5, 74.4, 74.56666666666666, 75.4, 75.43333333333334, 76.2, 76.53333333333333, 74.8, 76.0, 77.2, 76.66666666666667, 76.3, 76.16666666666667, 75.76666666666667, 75.5, 76.76666666666667, 75.96666666666667, 76.13333333333334, 77.1, 77.23333333333333, 77.36666666666666, 77.76666666666667, 77.86666666666666, 76.76666666666667, 77.46666666666667, 77.16666666666667, 77.43333333333334, 77.3, 77.8, 77.9, 76.53333333333333, 76.96666666666667, 77.33333333333333, 76.56666666666666, 77.86666666666666, 77.9, 77.03333333333333, 78.0, 77.16666666666667, 77.03333333333333, 77.6, 77.5, 78.03333333333333, 78.7, 78.23333333333333, 78.16666666666667, 77.4, 78.3, 78.43333333333334, 78.13333333333334, 77.83333333333333, 77.26666666666667, 77.73333333333333, 77.63333333333334, 76.63333333333334, 76.53333333333333, 76.93333333333334, 76.46666666666667, 78.5, 77.46666666666667, 76.7, 77.3, 77.43333333333334, 77.5, 77.26666666666667, 77.83333333333333, 77.33333333333333, 77.26666666666667, 78.16666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.398, Test loss: 1.412, Test accuracy: 41.53
Round   1, Train loss: 0.988, Test loss: 0.990, Test accuracy: 52.23
Round   2, Train loss: 0.893, Test loss: 0.894, Test accuracy: 57.20
Round   3, Train loss: 0.838, Test loss: 0.816, Test accuracy: 63.30
Round   4, Train loss: 0.800, Test loss: 0.777, Test accuracy: 64.50
Round   5, Train loss: 0.765, Test loss: 0.748, Test accuracy: 68.13
Round   6, Train loss: 0.739, Test loss: 0.729, Test accuracy: 69.57
Round   7, Train loss: 0.727, Test loss: 0.711, Test accuracy: 68.50
Round   8, Train loss: 0.701, Test loss: 0.681, Test accuracy: 71.77
Round   9, Train loss: 0.684, Test loss: 0.683, Test accuracy: 71.80
Round  10, Train loss: 0.667, Test loss: 0.657, Test accuracy: 74.17
Round  11, Train loss: 0.650, Test loss: 0.644, Test accuracy: 74.73
Round  12, Train loss: 0.633, Test loss: 0.646, Test accuracy: 74.43
Round  13, Train loss: 0.619, Test loss: 0.656, Test accuracy: 72.33
Round  14, Train loss: 0.601, Test loss: 0.621, Test accuracy: 75.07
Round  15, Train loss: 0.581, Test loss: 0.601, Test accuracy: 75.43
Round  16, Train loss: 0.567, Test loss: 0.628, Test accuracy: 74.43
Round  17, Train loss: 0.563, Test loss: 0.601, Test accuracy: 75.47
Round  18, Train loss: 0.544, Test loss: 0.618, Test accuracy: 75.07
Round  19, Train loss: 0.531, Test loss: 0.615, Test accuracy: 75.20
Round  20, Train loss: 0.646, Test loss: 0.653, Test accuracy: 73.63
Round  21, Train loss: 0.386, Test loss: 0.618, Test accuracy: 74.87
Round  22, Train loss: 0.528, Test loss: 0.622, Test accuracy: 75.00
Round  23, Train loss: 0.686, Test loss: 0.609, Test accuracy: 75.23
Round  24, Train loss: 0.383, Test loss: 0.578, Test accuracy: 77.13
Round  25, Train loss: 0.529, Test loss: 0.633, Test accuracy: 75.13
Round  26, Train loss: 0.394, Test loss: 0.593, Test accuracy: 76.73
Round  27, Train loss: 0.435, Test loss: 0.602, Test accuracy: 76.27
Round  28, Train loss: 0.345, Test loss: 0.582, Test accuracy: 77.07
Round  29, Train loss: 0.349, Test loss: 0.590, Test accuracy: 76.67
Round  30, Train loss: 0.302, Test loss: 0.587, Test accuracy: 77.03
Round  31, Train loss: 0.340, Test loss: 0.599, Test accuracy: 76.20
Round  32, Train loss: 0.292, Test loss: 0.578, Test accuracy: 77.80
Round  33, Train loss: 0.704, Test loss: 0.615, Test accuracy: 75.47
Round  34, Train loss: 0.393, Test loss: 0.608, Test accuracy: 76.10
Round  35, Train loss: 0.372, Test loss: 0.630, Test accuracy: 74.87
Round  36, Train loss: 0.424, Test loss: 0.633, Test accuracy: 75.27
Round  37, Train loss: 0.454, Test loss: 0.632, Test accuracy: 75.07
Round  38, Train loss: 0.362, Test loss: 0.633, Test accuracy: 74.57
Round  39, Train loss: 0.314, Test loss: 0.647, Test accuracy: 75.37
Round  40, Train loss: 0.200, Test loss: 0.636, Test accuracy: 76.40
Round  41, Train loss: 0.364, Test loss: 0.619, Test accuracy: 76.50
Round  42, Train loss: 0.193, Test loss: 0.628, Test accuracy: 75.97
Round  43, Train loss: 0.351, Test loss: 0.616, Test accuracy: 76.37
Round  44, Train loss: 0.293, Test loss: 0.614, Test accuracy: 77.60
Round  45, Train loss: 0.262, Test loss: 0.675, Test accuracy: 75.40
Round  46, Train loss: 0.356, Test loss: 0.668, Test accuracy: 75.77
Round  47, Train loss: 0.311, Test loss: 0.657, Test accuracy: 75.87
Round  48, Train loss: 0.176, Test loss: 0.651, Test accuracy: 76.83
Round  49, Train loss: 0.339, Test loss: 0.710, Test accuracy: 74.67
Round  50, Train loss: 0.360, Test loss: 0.687, Test accuracy: 74.37
Round  51, Train loss: 0.270, Test loss: 0.696, Test accuracy: 74.40
Round  52, Train loss: 0.281, Test loss: 0.678, Test accuracy: 75.03
Round  53, Train loss: 0.300, Test loss: 0.664, Test accuracy: 75.63
Round  54, Train loss: 0.181, Test loss: 0.668, Test accuracy: 76.63
Round  55, Train loss: 0.175, Test loss: 0.664, Test accuracy: 75.90
Round  56, Train loss: 0.291, Test loss: 0.676, Test accuracy: 76.27
Round  57, Train loss: 0.155, Test loss: 0.687, Test accuracy: 75.57
Round  58, Train loss: 0.256, Test loss: 0.721, Test accuracy: 73.50
Round  59, Train loss: 0.253, Test loss: 0.746, Test accuracy: 73.17
Round  60, Train loss: 0.229, Test loss: 0.757, Test accuracy: 72.97
Round  61, Train loss: 0.099, Test loss: 0.736, Test accuracy: 74.23
Round  62, Train loss: 0.138, Test loss: 0.752, Test accuracy: 74.33
Round  63, Train loss: 0.272, Test loss: 0.750, Test accuracy: 73.50
Round  64, Train loss: 0.229, Test loss: 0.718, Test accuracy: 74.27
Round  65, Train loss: 0.229, Test loss: 0.745, Test accuracy: 73.67
Round  66, Train loss: 0.140, Test loss: 0.777, Test accuracy: 73.73
Round  67, Train loss: 0.193, Test loss: 0.773, Test accuracy: 74.43
Round  68, Train loss: 0.106, Test loss: 0.783, Test accuracy: 74.30
Round  69, Train loss: 0.237, Test loss: 0.728, Test accuracy: 74.53
Round  70, Train loss: 0.179, Test loss: 0.756, Test accuracy: 73.93
Round  71, Train loss: 0.187, Test loss: 0.782, Test accuracy: 74.43
Round  72, Train loss: 0.239, Test loss: 0.781, Test accuracy: 73.97
Round  73, Train loss: 0.218, Test loss: 0.764, Test accuracy: 74.93
Round  74, Train loss: 0.192, Test loss: 0.794, Test accuracy: 73.57
Round  75, Train loss: 0.130, Test loss: 0.745, Test accuracy: 75.13
Round  76, Train loss: 0.193, Test loss: 0.759, Test accuracy: 75.40
Round  77, Train loss: 0.121, Test loss: 0.751, Test accuracy: 74.93
Round  78, Train loss: 0.159, Test loss: 0.787, Test accuracy: 74.17
Round  79, Train loss: 0.118, Test loss: 0.771, Test accuracy: 74.43
Round  80, Train loss: 0.152, Test loss: 0.747, Test accuracy: 74.47
Round  81, Train loss: 0.137, Test loss: 0.745, Test accuracy: 74.70
Round  82, Train loss: 0.124, Test loss: 0.748, Test accuracy: 74.53
Round  83, Train loss: 0.118, Test loss: 0.761, Test accuracy: 74.50
Round  84, Train loss: 0.117, Test loss: 0.764, Test accuracy: 75.40
Round  85, Train loss: 0.116, Test loss: 0.782, Test accuracy: 74.73
Round  86, Train loss: 0.122, Test loss: 0.767, Test accuracy: 75.70
Round  87, Train loss: 0.103, Test loss: 0.768, Test accuracy: 75.03
Round  88, Train loss: 0.113, Test loss: 0.762, Test accuracy: 75.20
Round  89, Train loss: 0.105, Test loss: 0.795, Test accuracy: 75.37
Round  90, Train loss: 0.103, Test loss: 0.752, Test accuracy: 75.60
Round  91, Train loss: 0.089, Test loss: 0.782, Test accuracy: 75.10
Round  92, Train loss: 0.099, Test loss: 0.772, Test accuracy: 75.17
Round  93, Train loss: 0.098, Test loss: 0.774, Test accuracy: 74.63
Round  94, Train loss: 0.095, Test loss: 0.782, Test accuracy: 74.90
Round  95, Train loss: 0.097, Test loss: 0.769, Test accuracy: 74.83
Round  96, Train loss: 0.089, Test loss: 0.789, Test accuracy: 75.63
Round  97, Train loss: 0.098, Test loss: 0.778, Test accuracy: 75.17
Round  98, Train loss: 0.077, Test loss: 0.819, Test accuracy: 74.93
Round  99, Train loss: 0.076, Test loss: 0.805, Test accuracy: 75.17
Final Round, Train loss: 0.064, Test loss: 0.816, Test accuracy: 75.43
Average accuracy final 10 rounds: 75.11333333333333
978.3195292949677
[2.037217378616333, 3.7238073348999023, 5.412790298461914, 7.098910093307495, 8.784444808959961, 10.47766661643982, 12.164273977279663, 13.847532749176025, 15.536211013793945, 17.22397541999817, 18.906299591064453, 20.59317660331726, 22.282594442367554, 23.972394466400146, 25.66106939315796, 27.349793672561646, 29.044661283493042, 30.734994173049927, 32.42337679862976, 34.11012601852417, 35.782742738723755, 37.21229863166809, 38.65420961380005, 40.093348026275635, 41.534926652908325, 42.970428228378296, 44.41254734992981, 45.84932327270508, 47.28107047080994, 48.713072061538696, 50.14962816238403, 51.58464336395264, 53.021921157836914, 54.46312737464905, 55.90187358856201, 57.33398413658142, 58.77341604232788, 60.20874905586243, 61.645999908447266, 63.07993674278259, 64.51258492469788, 65.95291113853455, 67.3949613571167, 68.83154392242432, 70.27207469940186, 71.70588660240173, 73.14315390586853, 74.57881164550781, 76.01339983940125, 77.45122957229614, 78.89174771308899, 80.32499766349792, 81.75854182243347, 83.20019698143005, 84.63753747940063, 86.07676076889038, 87.5407874584198, 88.97416853904724, 90.41710472106934, 91.85797953605652, 93.29897475242615, 94.74179363250732, 96.20051217079163, 97.64313769340515, 99.09181261062622, 100.5312008857727, 101.96890044212341, 103.39946722984314, 104.83730697631836, 106.27331280708313, 107.71471858024597, 109.1521246433258, 110.59320449829102, 112.03576827049255, 113.47514295578003, 114.9119246006012, 116.35507535934448, 117.78236937522888, 119.22014832496643, 120.65820217132568, 122.10318541526794, 123.58443784713745, 125.02374601364136, 126.46721267700195, 127.90371537208557, 129.34604668617249, 130.78513979911804, 132.22755074501038, 133.66873836517334, 135.1085171699524, 136.55023288726807, 137.99144005775452, 139.43357276916504, 140.87680387496948, 142.31739711761475, 143.7578740119934, 145.19587182998657, 146.6376359462738, 148.0814187526703, 149.52128672599792, 151.87327313423157]
[41.53333333333333, 52.233333333333334, 57.2, 63.3, 64.5, 68.13333333333334, 69.56666666666666, 68.5, 71.76666666666667, 71.8, 74.16666666666667, 74.73333333333333, 74.43333333333334, 72.33333333333333, 75.06666666666666, 75.43333333333334, 74.43333333333334, 75.46666666666667, 75.06666666666666, 75.2, 73.63333333333334, 74.86666666666666, 75.0, 75.23333333333333, 77.13333333333334, 75.13333333333334, 76.73333333333333, 76.26666666666667, 77.06666666666666, 76.66666666666667, 77.03333333333333, 76.2, 77.8, 75.46666666666667, 76.1, 74.86666666666666, 75.26666666666667, 75.06666666666666, 74.56666666666666, 75.36666666666666, 76.4, 76.5, 75.96666666666667, 76.36666666666666, 77.6, 75.4, 75.76666666666667, 75.86666666666666, 76.83333333333333, 74.66666666666667, 74.36666666666666, 74.4, 75.03333333333333, 75.63333333333334, 76.63333333333334, 75.9, 76.26666666666667, 75.56666666666666, 73.5, 73.16666666666667, 72.96666666666667, 74.23333333333333, 74.33333333333333, 73.5, 74.26666666666667, 73.66666666666667, 73.73333333333333, 74.43333333333334, 74.3, 74.53333333333333, 73.93333333333334, 74.43333333333334, 73.96666666666667, 74.93333333333334, 73.56666666666666, 75.13333333333334, 75.4, 74.93333333333334, 74.16666666666667, 74.43333333333334, 74.46666666666667, 74.7, 74.53333333333333, 74.5, 75.4, 74.73333333333333, 75.7, 75.03333333333333, 75.2, 75.36666666666666, 75.6, 75.1, 75.16666666666667, 74.63333333333334, 74.9, 74.83333333333333, 75.63333333333334, 75.16666666666667, 74.93333333333334, 75.16666666666667, 75.43333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.398, Test loss: 1.452, Test accuracy: 38.13
Round   1, Train loss: 0.999, Test loss: 0.971, Test accuracy: 54.93
Round   2, Train loss: 0.901, Test loss: 0.913, Test accuracy: 58.53
Round   3, Train loss: 0.845, Test loss: 0.842, Test accuracy: 62.50
Round   4, Train loss: 0.799, Test loss: 0.808, Test accuracy: 64.87
Round   5, Train loss: 0.765, Test loss: 0.737, Test accuracy: 69.03
Round   6, Train loss: 0.738, Test loss: 0.733, Test accuracy: 68.73
Round   7, Train loss: 0.719, Test loss: 0.711, Test accuracy: 69.63
Round   8, Train loss: 0.695, Test loss: 0.704, Test accuracy: 70.37
Round   9, Train loss: 0.674, Test loss: 0.676, Test accuracy: 71.53
Round  10, Train loss: 0.661, Test loss: 0.682, Test accuracy: 71.23
Round  11, Train loss: 0.639, Test loss: 0.667, Test accuracy: 72.80
Round  12, Train loss: 0.626, Test loss: 0.624, Test accuracy: 74.70
Round  13, Train loss: 0.607, Test loss: 0.627, Test accuracy: 74.07
Round  14, Train loss: 0.597, Test loss: 0.615, Test accuracy: 74.97
Round  15, Train loss: 0.574, Test loss: 0.618, Test accuracy: 74.80
Round  16, Train loss: 0.563, Test loss: 0.617, Test accuracy: 74.47
Round  17, Train loss: 0.548, Test loss: 0.612, Test accuracy: 74.87
Round  18, Train loss: 0.536, Test loss: 0.605, Test accuracy: 75.57
Round  19, Train loss: 0.522, Test loss: 0.610, Test accuracy: 74.70
Round  20, Train loss: 0.662, Test loss: 0.678, Test accuracy: 72.03
Round  21, Train loss: 0.418, Test loss: 0.639, Test accuracy: 73.97
Round  22, Train loss: 0.657, Test loss: 0.647, Test accuracy: 73.73
Round  23, Train loss: 0.530, Test loss: 0.645, Test accuracy: 73.07
Round  24, Train loss: 0.397, Test loss: 0.635, Test accuracy: 74.30
Round  25, Train loss: 0.398, Test loss: 0.614, Test accuracy: 75.57
Round  26, Train loss: 0.410, Test loss: 0.639, Test accuracy: 74.43
Round  27, Train loss: 0.421, Test loss: 0.641, Test accuracy: 74.47
Round  28, Train loss: 0.472, Test loss: 0.659, Test accuracy: 72.63
Round  29, Train loss: 0.377, Test loss: 0.623, Test accuracy: 74.47
Round  30, Train loss: 0.410, Test loss: 0.637, Test accuracy: 73.87
Round  31, Train loss: 0.353, Test loss: 0.599, Test accuracy: 75.30
Round  32, Train loss: 0.305, Test loss: 0.613, Test accuracy: 76.37
Round  33, Train loss: 0.544, Test loss: 0.611, Test accuracy: 76.13
Round  34, Train loss: 0.366, Test loss: 0.635, Test accuracy: 75.77
Round  35, Train loss: 0.398, Test loss: 0.630, Test accuracy: 75.37
Round  36, Train loss: 0.425, Test loss: 0.660, Test accuracy: 74.57
Round  37, Train loss: 0.466, Test loss: 0.626, Test accuracy: 75.87
Round  38, Train loss: 0.360, Test loss: 0.626, Test accuracy: 76.27
Round  39, Train loss: 0.418, Test loss: 0.677, Test accuracy: 74.00
Round  40, Train loss: 0.317, Test loss: 0.679, Test accuracy: 73.80
Round  41, Train loss: 0.237, Test loss: 0.667, Test accuracy: 75.70
Round  42, Train loss: 0.237, Test loss: 0.672, Test accuracy: 75.40
Round  43, Train loss: 0.345, Test loss: 0.622, Test accuracy: 76.37
Round  44, Train loss: 0.413, Test loss: 0.661, Test accuracy: 74.33
Round  45, Train loss: 0.295, Test loss: 0.670, Test accuracy: 75.07
Round  46, Train loss: 0.355, Test loss: 0.694, Test accuracy: 75.20
Round  47, Train loss: 0.302, Test loss: 0.707, Test accuracy: 74.37
Round  48, Train loss: 0.289, Test loss: 0.672, Test accuracy: 74.70
Round  49, Train loss: 0.354, Test loss: 0.684, Test accuracy: 74.87
Round  50, Train loss: 0.256, Test loss: 0.690, Test accuracy: 74.23
Round  51, Train loss: 0.371, Test loss: 0.687, Test accuracy: 74.80
Round  52, Train loss: 0.311, Test loss: 0.690, Test accuracy: 74.80
Round  53, Train loss: 0.190, Test loss: 0.697, Test accuracy: 75.67
Round  54, Train loss: 0.275, Test loss: 0.744, Test accuracy: 74.13
Round  55, Train loss: 0.187, Test loss: 0.712, Test accuracy: 75.00
Round  56, Train loss: 0.260, Test loss: 0.721, Test accuracy: 74.30
Round  57, Train loss: 0.153, Test loss: 0.708, Test accuracy: 74.87
Round  58, Train loss: 0.230, Test loss: 0.714, Test accuracy: 74.37
Round  59, Train loss: 0.175, Test loss: 0.762, Test accuracy: 74.97
Round  60, Train loss: 0.281, Test loss: 0.784, Test accuracy: 74.33
Round  61, Train loss: 0.158, Test loss: 0.777, Test accuracy: 74.73
Round  62, Train loss: 0.174, Test loss: 0.769, Test accuracy: 74.27
Round  63, Train loss: 0.282, Test loss: 0.759, Test accuracy: 73.00
Round  64, Train loss: 0.253, Test loss: 0.736, Test accuracy: 75.47
Round  65, Train loss: 0.254, Test loss: 0.753, Test accuracy: 74.43
Round  66, Train loss: 0.140, Test loss: 0.732, Test accuracy: 75.30
Round  67, Train loss: 0.256, Test loss: 0.746, Test accuracy: 74.93
Round  68, Train loss: 0.172, Test loss: 0.761, Test accuracy: 74.50
Round  69, Train loss: 0.185, Test loss: 0.747, Test accuracy: 74.50
Round  70, Train loss: 0.191, Test loss: 0.760, Test accuracy: 75.73
Round  71, Train loss: 0.188, Test loss: 0.811, Test accuracy: 75.10
Round  72, Train loss: 0.175, Test loss: 0.753, Test accuracy: 74.97
Round  73, Train loss: 0.148, Test loss: 0.789, Test accuracy: 74.23
Round  74, Train loss: 0.164, Test loss: 0.770, Test accuracy: 74.90
Round  75, Train loss: 0.161, Test loss: 0.790, Test accuracy: 74.17
Round  76, Train loss: 0.172, Test loss: 0.805, Test accuracy: 74.27
Round  77, Train loss: 0.196, Test loss: 0.785, Test accuracy: 74.47
Round  78, Train loss: 0.196, Test loss: 0.805, Test accuracy: 73.30
Round  79, Train loss: 0.145, Test loss: 0.766, Test accuracy: 74.63
Round  80, Train loss: 0.142, Test loss: 0.743, Test accuracy: 76.13
Round  81, Train loss: 0.133, Test loss: 0.756, Test accuracy: 75.57
Round  82, Train loss: 0.123, Test loss: 0.754, Test accuracy: 75.90
Round  83, Train loss: 0.121, Test loss: 0.771, Test accuracy: 74.67
Round  84, Train loss: 0.121, Test loss: 0.763, Test accuracy: 75.33
Round  85, Train loss: 0.108, Test loss: 0.768, Test accuracy: 75.33
Round  86, Train loss: 0.106, Test loss: 0.779, Test accuracy: 75.27
Round  87, Train loss: 0.103, Test loss: 0.795, Test accuracy: 74.50
Round  88, Train loss: 0.108, Test loss: 0.793, Test accuracy: 75.40
Round  89, Train loss: 0.109, Test loss: 0.799, Test accuracy: 74.63
Round  90, Train loss: 0.101, Test loss: 0.801, Test accuracy: 74.70
Round  91, Train loss: 0.103, Test loss: 0.796, Test accuracy: 75.73
Round  92, Train loss: 0.090, Test loss: 0.812, Test accuracy: 75.53
Round  93, Train loss: 0.088, Test loss: 0.795, Test accuracy: 74.83
Round  94, Train loss: 0.094, Test loss: 0.796, Test accuracy: 75.63
Round  95, Train loss: 0.090, Test loss: 0.813, Test accuracy: 75.43
Round  96, Train loss: 0.089, Test loss: 0.824, Test accuracy: 75.30
Round  97, Train loss: 0.091, Test loss: 0.830, Test accuracy: 75.33
Round  98, Train loss: 0.079, Test loss: 0.819, Test accuracy: 75.17
Round  99, Train loss: 0.079, Test loss: 0.811, Test accuracy: 75.67
Final Round, Train loss: 0.068, Test loss: 0.823, Test accuracy: 75.90
Average accuracy final 10 rounds: 75.33333333333333
1506.5006868839264
[1.8313848972320557, 3.4192473888397217, 5.00721001625061, 6.5910351276397705, 8.176533937454224, 9.76998233795166, 11.354974746704102, 12.939666271209717, 14.525846719741821, 16.110214710235596, 17.69852638244629, 19.285244941711426, 20.880133628845215, 22.465976238250732, 24.0535945892334, 25.622504472732544, 27.195199728012085, 28.76188635826111, 30.328917264938354, 31.87852120399475, 33.42601156234741, 36.16804385185242, 38.91993832588196, 41.673139333724976, 44.42242670059204, 47.15423941612244, 49.89815163612366, 52.647891998291016, 55.3982355594635, 58.14987778663635, 60.89659857749939, 63.61373591423035, 66.36247086524963, 69.10960650444031, 71.86147713661194, 74.60480070114136, 77.36075496673584, 80.10595631599426, 82.8617331981659, 85.6128499507904, 88.3667197227478, 91.12071418762207, 93.88227820396423, 96.63270854949951, 99.3892433643341, 102.11842656135559, 104.86655402183533, 107.62311935424805, 110.36847972869873, 113.11315822601318, 115.85519313812256, 118.6016321182251, 121.34904336929321, 124.27903723716736, 127.20470666885376, 130.12638115882874, 133.04062056541443, 135.96519589424133, 138.88230156898499, 141.79989743232727, 144.71886324882507, 147.63981986045837, 150.55483746528625, 153.47152519226074, 156.3938283920288, 159.32146883010864, 162.26418256759644, 165.21099877357483, 168.1534776687622, 171.09288597106934, 174.04487800598145, 176.9402391910553, 179.88113021850586, 182.83105969429016, 185.78313446044922, 188.73071575164795, 191.6753706932068, 194.6198046207428, 197.57841992378235, 200.51845693588257, 203.46123933792114, 206.40960669517517, 209.36679792404175, 212.31285190582275, 215.2542688846588, 218.20564126968384, 221.14794898033142, 224.096617937088, 227.20025300979614, 230.31005239486694, 233.41882061958313, 236.51469159126282, 239.62277054786682, 242.73213291168213, 245.83262848854065, 248.93773651123047, 252.04607939720154, 255.1573247909546, 258.25785303115845, 261.36458587646484, 263.84505224227905]
[38.13333333333333, 54.93333333333333, 58.53333333333333, 62.5, 64.86666666666666, 69.03333333333333, 68.73333333333333, 69.63333333333334, 70.36666666666666, 71.53333333333333, 71.23333333333333, 72.8, 74.7, 74.06666666666666, 74.96666666666667, 74.8, 74.46666666666667, 74.86666666666666, 75.56666666666666, 74.7, 72.03333333333333, 73.96666666666667, 73.73333333333333, 73.06666666666666, 74.3, 75.56666666666666, 74.43333333333334, 74.46666666666667, 72.63333333333334, 74.46666666666667, 73.86666666666666, 75.3, 76.36666666666666, 76.13333333333334, 75.76666666666667, 75.36666666666666, 74.56666666666666, 75.86666666666666, 76.26666666666667, 74.0, 73.8, 75.7, 75.4, 76.36666666666666, 74.33333333333333, 75.06666666666666, 75.2, 74.36666666666666, 74.7, 74.86666666666666, 74.23333333333333, 74.8, 74.8, 75.66666666666667, 74.13333333333334, 75.0, 74.3, 74.86666666666666, 74.36666666666666, 74.96666666666667, 74.33333333333333, 74.73333333333333, 74.26666666666667, 73.0, 75.46666666666667, 74.43333333333334, 75.3, 74.93333333333334, 74.5, 74.5, 75.73333333333333, 75.1, 74.96666666666667, 74.23333333333333, 74.9, 74.16666666666667, 74.26666666666667, 74.46666666666667, 73.3, 74.63333333333334, 76.13333333333334, 75.56666666666666, 75.9, 74.66666666666667, 75.33333333333333, 75.33333333333333, 75.26666666666667, 74.5, 75.4, 74.63333333333334, 74.7, 75.73333333333333, 75.53333333333333, 74.83333333333333, 75.63333333333334, 75.43333333333334, 75.3, 75.33333333333333, 75.16666666666667, 75.66666666666667, 75.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 5, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.395, Test loss: 1.427, Test accuracy: 43.03
Round   1, Train loss: 0.973, Test loss: 0.967, Test accuracy: 53.17
Round   2, Train loss: 0.885, Test loss: 0.886, Test accuracy: 57.80
Round   3, Train loss: 0.838, Test loss: 0.843, Test accuracy: 61.20
Round   4, Train loss: 0.795, Test loss: 0.802, Test accuracy: 63.30
Round   5, Train loss: 0.766, Test loss: 0.763, Test accuracy: 66.83
Round   6, Train loss: 0.736, Test loss: 0.744, Test accuracy: 69.17
Round   7, Train loss: 0.715, Test loss: 0.726, Test accuracy: 70.03
Round   8, Train loss: 0.698, Test loss: 0.706, Test accuracy: 70.13
Round   9, Train loss: 0.680, Test loss: 0.679, Test accuracy: 72.03
Round  10, Train loss: 0.666, Test loss: 0.680, Test accuracy: 72.70
Round  11, Train loss: 0.642, Test loss: 0.659, Test accuracy: 72.60
Round  12, Train loss: 0.631, Test loss: 0.645, Test accuracy: 73.73
Round  13, Train loss: 0.613, Test loss: 0.655, Test accuracy: 73.30
Round  14, Train loss: 0.601, Test loss: 0.647, Test accuracy: 73.10
Round  15, Train loss: 0.584, Test loss: 0.622, Test accuracy: 74.60
Round  16, Train loss: 0.571, Test loss: 0.618, Test accuracy: 74.40
Round  17, Train loss: 0.555, Test loss: 0.611, Test accuracy: 75.23
Round  18, Train loss: 0.542, Test loss: 0.618, Test accuracy: 75.20
Round  19, Train loss: 0.529, Test loss: 0.628, Test accuracy: 74.33
Round  20, Train loss: 0.522, Test loss: 0.670, Test accuracy: 72.27
Round  21, Train loss: 0.534, Test loss: 0.635, Test accuracy: 74.60
Round  22, Train loss: 0.392, Test loss: 0.640, Test accuracy: 73.73
Round  23, Train loss: 0.543, Test loss: 0.617, Test accuracy: 75.43
Round  24, Train loss: 0.510, Test loss: 0.646, Test accuracy: 73.53
Round  25, Train loss: 0.511, Test loss: 0.626, Test accuracy: 74.87
Round  26, Train loss: 0.530, Test loss: 0.644, Test accuracy: 73.97
Round  27, Train loss: 0.421, Test loss: 0.650, Test accuracy: 74.00
Round  28, Train loss: 0.353, Test loss: 0.644, Test accuracy: 74.53
Round  29, Train loss: 0.603, Test loss: 0.677, Test accuracy: 72.57
Round  30, Train loss: 0.414, Test loss: 0.678, Test accuracy: 72.80
Round  31, Train loss: 0.476, Test loss: 0.670, Test accuracy: 72.83
Round  32, Train loss: 0.416, Test loss: 0.657, Test accuracy: 73.60
Round  33, Train loss: 0.429, Test loss: 0.599, Test accuracy: 75.37
Round  34, Train loss: 0.265, Test loss: 0.636, Test accuracy: 74.83
Round  35, Train loss: 0.381, Test loss: 0.617, Test accuracy: 76.07
Round  36, Train loss: 0.290, Test loss: 0.641, Test accuracy: 75.27
Round  37, Train loss: 0.453, Test loss: 0.652, Test accuracy: 74.47
Round  38, Train loss: 0.473, Test loss: 0.639, Test accuracy: 75.00
Round  39, Train loss: 0.313, Test loss: 0.680, Test accuracy: 73.33
Round  40, Train loss: 0.404, Test loss: 0.676, Test accuracy: 73.77
Round  41, Train loss: 0.336, Test loss: 0.670, Test accuracy: 73.40
Round  42, Train loss: 0.307, Test loss: 0.662, Test accuracy: 74.27
Round  43, Train loss: 0.429, Test loss: 0.649, Test accuracy: 74.63
Round  44, Train loss: 0.315, Test loss: 0.645, Test accuracy: 75.70
Round  45, Train loss: 0.273, Test loss: 0.654, Test accuracy: 75.27
Round  46, Train loss: 0.326, Test loss: 0.663, Test accuracy: 74.73
Round  47, Train loss: 0.205, Test loss: 0.677, Test accuracy: 74.63
Round  48, Train loss: 0.194, Test loss: 0.654, Test accuracy: 75.27
Round  49, Train loss: 0.261, Test loss: 0.686, Test accuracy: 74.63
Round  50, Train loss: 0.224, Test loss: 0.689, Test accuracy: 74.60
Round  51, Train loss: 0.287, Test loss: 0.690, Test accuracy: 75.13
Round  52, Train loss: 0.305, Test loss: 0.693, Test accuracy: 75.07
Round  53, Train loss: 0.355, Test loss: 0.700, Test accuracy: 74.70
Round  54, Train loss: 0.265, Test loss: 0.682, Test accuracy: 73.87
Round  55, Train loss: 0.325, Test loss: 0.725, Test accuracy: 73.07
Round  56, Train loss: 0.207, Test loss: 0.696, Test accuracy: 74.63
Round  57, Train loss: 0.291, Test loss: 0.728, Test accuracy: 73.67
Round  58, Train loss: 0.181, Test loss: 0.740, Test accuracy: 73.27
Round  59, Train loss: 0.175, Test loss: 0.733, Test accuracy: 73.43
Round  60, Train loss: 0.144, Test loss: 0.735, Test accuracy: 74.17
Round  61, Train loss: 0.176, Test loss: 0.764, Test accuracy: 72.60
Round  62, Train loss: 0.224, Test loss: 0.758, Test accuracy: 74.03
Round  63, Train loss: 0.215, Test loss: 0.733, Test accuracy: 74.00
Round  64, Train loss: 0.233, Test loss: 0.719, Test accuracy: 75.07
Round  65, Train loss: 0.163, Test loss: 0.757, Test accuracy: 74.93
Round  66, Train loss: 0.129, Test loss: 0.775, Test accuracy: 75.03
Round  67, Train loss: 0.269, Test loss: 0.759, Test accuracy: 74.37
Round  68, Train loss: 0.117, Test loss: 0.752, Test accuracy: 74.80
Round  69, Train loss: 0.152, Test loss: 0.704, Test accuracy: 75.17
Round  70, Train loss: 0.191, Test loss: 0.696, Test accuracy: 75.90
Round  71, Train loss: 0.133, Test loss: 0.690, Test accuracy: 75.83
Round  72, Train loss: 0.147, Test loss: 0.703, Test accuracy: 75.40
Round  73, Train loss: 0.162, Test loss: 0.713, Test accuracy: 74.77
Round  74, Train loss: 0.193, Test loss: 0.717, Test accuracy: 75.53
Round  75, Train loss: 0.228, Test loss: 0.774, Test accuracy: 74.13
Round  76, Train loss: 0.164, Test loss: 0.803, Test accuracy: 72.10
Round  77, Train loss: 0.131, Test loss: 0.778, Test accuracy: 73.57
Round  78, Train loss: 0.150, Test loss: 0.766, Test accuracy: 73.57
Round  79, Train loss: 0.117, Test loss: 0.752, Test accuracy: 74.17
Round  80, Train loss: 0.156, Test loss: 0.748, Test accuracy: 74.87
Round  81, Train loss: 0.140, Test loss: 0.747, Test accuracy: 74.93
Round  82, Train loss: 0.129, Test loss: 0.749, Test accuracy: 75.20
Round  83, Train loss: 0.118, Test loss: 0.757, Test accuracy: 75.07
Round  84, Train loss: 0.116, Test loss: 0.747, Test accuracy: 74.87
Round  85, Train loss: 0.118, Test loss: 0.744, Test accuracy: 74.90
Round  86, Train loss: 0.113, Test loss: 0.769, Test accuracy: 74.53
Round  87, Train loss: 0.103, Test loss: 0.761, Test accuracy: 74.80
Round  88, Train loss: 0.108, Test loss: 0.758, Test accuracy: 75.43
Round  89, Train loss: 0.103, Test loss: 0.783, Test accuracy: 74.63
Round  90, Train loss: 0.102, Test loss: 0.767, Test accuracy: 75.27
Round  91, Train loss: 0.105, Test loss: 0.773, Test accuracy: 75.27
Round  92, Train loss: 0.103, Test loss: 0.783, Test accuracy: 75.07
Round  93, Train loss: 0.087, Test loss: 0.780, Test accuracy: 75.20
Round  94, Train loss: 0.097, Test loss: 0.786, Test accuracy: 75.47
Round  95, Train loss: 0.094, Test loss: 0.790, Test accuracy: 75.17
Round  96, Train loss: 0.087, Test loss: 0.788, Test accuracy: 75.53
Round  97, Train loss: 0.084, Test loss: 0.788, Test accuracy: 75.60
Round  98, Train loss: 0.080, Test loss: 0.803, Test accuracy: 75.63
Round  99, Train loss: 0.096, Test loss: 0.818, Test accuracy: 75.20
Final Round, Train loss: 0.070, Test loss: 0.810, Test accuracy: 75.47
Average accuracy final 10 rounds: 75.34
1525.8788311481476
[1.9460327625274658, 3.600417137145996, 5.2047295570373535, 6.812168598175049, 8.418080568313599, 10.026253938674927, 11.633986711502075, 13.260907649993896, 14.883225202560425, 16.504802703857422, 18.125276803970337, 19.747620820999146, 21.370277881622314, 22.991366863250732, 24.61463189125061, 26.233807802200317, 27.84158205986023, 29.463793992996216, 31.092869758605957, 32.71275997161865, 34.3366219997406, 37.45355772972107, 40.50467896461487, 43.62551164627075, 46.74565839767456, 49.85686254501343, 52.96940636634827, 56.082032680511475, 59.203245401382446, 62.330251693725586, 65.44460678100586, 68.43735003471375, 71.54984259605408, 74.67281198501587, 77.80134320259094, 80.88478255271912, 83.99752473831177, 87.11647582054138, 90.23197913169861, 93.32594203948975, 96.43280029296875, 99.52892112731934, 102.63567447662354, 105.68242692947388, 108.77391815185547, 111.86663484573364, 114.96221470832825, 117.9573426246643, 121.05693054199219, 124.14097809791565, 127.23670983314514, 130.24575686454773, 133.31694078445435, 136.41731595993042, 139.50565457344055, 142.6006019115448, 145.69409704208374, 148.79616522789001, 151.8798849582672, 154.9446587562561, 157.89869332313538, 160.99019145965576, 164.07669305801392, 167.14448380470276, 170.25756359100342, 173.36798930168152, 176.46928000450134, 179.57824993133545, 182.4925606250763, 185.4027533531189, 188.32653045654297, 191.2514307498932, 194.0843014717102, 197.01520586013794, 199.94246459007263, 202.85083031654358, 205.75268983840942, 208.6626923084259, 211.59605932235718, 214.51274824142456, 217.45292472839355, 220.38982009887695, 223.3334743976593, 226.2628092765808, 229.20049047470093, 232.14608359336853, 235.07114505767822, 238.01871156692505, 240.95596647262573, 243.89558506011963, 246.83944725990295, 249.77520108222961, 252.71986508369446, 255.654310464859, 258.6064236164093, 261.54555559158325, 264.47709703445435, 267.4280321598053, 270.35712003707886, 273.2931640148163, 275.6312851905823]
[43.03333333333333, 53.166666666666664, 57.8, 61.2, 63.3, 66.83333333333333, 69.16666666666667, 70.03333333333333, 70.13333333333334, 72.03333333333333, 72.7, 72.6, 73.73333333333333, 73.3, 73.1, 74.6, 74.4, 75.23333333333333, 75.2, 74.33333333333333, 72.26666666666667, 74.6, 73.73333333333333, 75.43333333333334, 73.53333333333333, 74.86666666666666, 73.96666666666667, 74.0, 74.53333333333333, 72.56666666666666, 72.8, 72.83333333333333, 73.6, 75.36666666666666, 74.83333333333333, 76.06666666666666, 75.26666666666667, 74.46666666666667, 75.0, 73.33333333333333, 73.76666666666667, 73.4, 74.26666666666667, 74.63333333333334, 75.7, 75.26666666666667, 74.73333333333333, 74.63333333333334, 75.26666666666667, 74.63333333333334, 74.6, 75.13333333333334, 75.06666666666666, 74.7, 73.86666666666666, 73.06666666666666, 74.63333333333334, 73.66666666666667, 73.26666666666667, 73.43333333333334, 74.16666666666667, 72.6, 74.03333333333333, 74.0, 75.06666666666666, 74.93333333333334, 75.03333333333333, 74.36666666666666, 74.8, 75.16666666666667, 75.9, 75.83333333333333, 75.4, 74.76666666666667, 75.53333333333333, 74.13333333333334, 72.1, 73.56666666666666, 73.56666666666666, 74.16666666666667, 74.86666666666666, 74.93333333333334, 75.2, 75.06666666666666, 74.86666666666666, 74.9, 74.53333333333333, 74.8, 75.43333333333334, 74.63333333333334, 75.26666666666667, 75.26666666666667, 75.06666666666666, 75.2, 75.46666666666667, 75.16666666666667, 75.53333333333333, 75.6, 75.63333333333334, 75.2, 75.46666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.666, Test loss: 2.422, Test accuracy: 17.87
Round   1, Train loss: 1.075, Test loss: 1.805, Test accuracy: 32.33
Round   2, Train loss: 0.909, Test loss: 1.478, Test accuracy: 40.57
Round   3, Train loss: 1.027, Test loss: 1.321, Test accuracy: 46.33
Round   4, Train loss: 0.950, Test loss: 1.238, Test accuracy: 49.77
Round   5, Train loss: 0.963, Test loss: 0.963, Test accuracy: 54.27
Round   6, Train loss: 0.930, Test loss: 0.917, Test accuracy: 55.77
Round   7, Train loss: 0.831, Test loss: 0.873, Test accuracy: 58.90
Round   8, Train loss: 0.792, Test loss: 0.853, Test accuracy: 60.13
Round   9, Train loss: 0.907, Test loss: 0.844, Test accuracy: 60.73
Round  10, Train loss: 0.781, Test loss: 0.815, Test accuracy: 62.57
Round  11, Train loss: 0.947, Test loss: 0.807, Test accuracy: 63.50
Round  12, Train loss: 1.016, Test loss: 0.799, Test accuracy: 64.27
Round  13, Train loss: 0.756, Test loss: 0.783, Test accuracy: 63.90
Round  14, Train loss: 0.801, Test loss: 0.770, Test accuracy: 64.13
Round  15, Train loss: 0.676, Test loss: 0.750, Test accuracy: 65.63
Round  16, Train loss: 0.685, Test loss: 0.735, Test accuracy: 67.07
Round  17, Train loss: 0.996, Test loss: 0.729, Test accuracy: 67.90
Round  18, Train loss: 0.797, Test loss: 0.720, Test accuracy: 68.53
Round  19, Train loss: 0.808, Test loss: 0.713, Test accuracy: 69.50
Round  20, Train loss: 0.887, Test loss: 0.714, Test accuracy: 68.83
Round  21, Train loss: 0.602, Test loss: 0.705, Test accuracy: 69.70
Round  22, Train loss: 0.587, Test loss: 0.710, Test accuracy: 69.03
Round  23, Train loss: 0.763, Test loss: 0.699, Test accuracy: 69.03
Round  24, Train loss: 0.813, Test loss: 0.689, Test accuracy: 69.27
Round  25, Train loss: 0.525, Test loss: 0.691, Test accuracy: 69.30
Round  26, Train loss: 0.844, Test loss: 0.683, Test accuracy: 69.60
Round  27, Train loss: 0.760, Test loss: 0.694, Test accuracy: 69.37
Round  28, Train loss: 0.840, Test loss: 0.695, Test accuracy: 69.50
Round  29, Train loss: 0.776, Test loss: 0.678, Test accuracy: 70.57
Round  30, Train loss: 0.689, Test loss: 0.678, Test accuracy: 70.43
Round  31, Train loss: 0.853, Test loss: 0.689, Test accuracy: 70.10
Round  32, Train loss: 0.573, Test loss: 0.683, Test accuracy: 71.40
Round  33, Train loss: 0.734, Test loss: 0.671, Test accuracy: 71.07
Round  34, Train loss: 0.501, Test loss: 0.664, Test accuracy: 71.57
Round  35, Train loss: 0.668, Test loss: 0.661, Test accuracy: 71.70
Round  36, Train loss: 0.691, Test loss: 0.674, Test accuracy: 71.30
Round  37, Train loss: 0.720, Test loss: 0.667, Test accuracy: 71.20
Round  38, Train loss: 0.669, Test loss: 0.653, Test accuracy: 71.80
Round  39, Train loss: 0.688, Test loss: 0.651, Test accuracy: 72.20
Round  40, Train loss: 0.713, Test loss: 0.649, Test accuracy: 72.53
Round  41, Train loss: 0.534, Test loss: 0.647, Test accuracy: 72.57
Round  42, Train loss: 0.505, Test loss: 0.643, Test accuracy: 72.20
Round  43, Train loss: 0.451, Test loss: 0.631, Test accuracy: 73.53
Round  44, Train loss: 0.600, Test loss: 0.627, Test accuracy: 74.23
Round  45, Train loss: 0.470, Test loss: 0.637, Test accuracy: 73.47
Round  46, Train loss: 0.669, Test loss: 0.637, Test accuracy: 72.60
Round  47, Train loss: 0.581, Test loss: 0.632, Test accuracy: 73.37
Round  48, Train loss: 0.603, Test loss: 0.627, Test accuracy: 73.23
Round  49, Train loss: 0.604, Test loss: 0.631, Test accuracy: 72.87
Round  50, Train loss: 0.595, Test loss: 0.617, Test accuracy: 74.13
Round  51, Train loss: 0.592, Test loss: 0.645, Test accuracy: 72.63
Round  52, Train loss: 0.360, Test loss: 0.631, Test accuracy: 72.90
Round  53, Train loss: 0.495, Test loss: 0.610, Test accuracy: 74.10
Round  54, Train loss: 0.753, Test loss: 0.618, Test accuracy: 73.30
Round  55, Train loss: 0.442, Test loss: 0.616, Test accuracy: 73.93
Round  56, Train loss: 0.683, Test loss: 0.646, Test accuracy: 72.10
Round  57, Train loss: 0.768, Test loss: 0.630, Test accuracy: 73.03
Round  58, Train loss: 0.620, Test loss: 0.622, Test accuracy: 73.57
Round  59, Train loss: 0.443, Test loss: 0.623, Test accuracy: 73.40
Round  60, Train loss: 0.541, Test loss: 0.653, Test accuracy: 72.47
Round  61, Train loss: 0.733, Test loss: 0.635, Test accuracy: 73.30
Round  62, Train loss: 0.574, Test loss: 0.667, Test accuracy: 70.67
Round  63, Train loss: 0.764, Test loss: 0.644, Test accuracy: 71.97
Round  64, Train loss: 0.532, Test loss: 0.613, Test accuracy: 74.03
Round  65, Train loss: 0.435, Test loss: 0.612, Test accuracy: 74.60
Round  66, Train loss: 0.547, Test loss: 0.656, Test accuracy: 72.67
Round  67, Train loss: 0.500, Test loss: 0.641, Test accuracy: 72.37
Round  68, Train loss: 0.502, Test loss: 0.647, Test accuracy: 72.37
Round  69, Train loss: 0.600, Test loss: 0.632, Test accuracy: 73.23
Round  70, Train loss: 0.379, Test loss: 0.612, Test accuracy: 73.63
Round  71, Train loss: 0.341, Test loss: 0.611, Test accuracy: 74.00
Round  72, Train loss: 0.265, Test loss: 0.642, Test accuracy: 73.47
Round  73, Train loss: 0.388, Test loss: 0.647, Test accuracy: 73.00
Round  74, Train loss: 0.381, Test loss: 0.616, Test accuracy: 74.03
Round  75, Train loss: 0.383, Test loss: 0.601, Test accuracy: 74.20
Round  76, Train loss: 0.685, Test loss: 0.628, Test accuracy: 73.20
Round  77, Train loss: 0.283, Test loss: 0.638, Test accuracy: 72.80
Round  78, Train loss: 0.362, Test loss: 0.623, Test accuracy: 72.87
Round  79, Train loss: 0.362, Test loss: 0.630, Test accuracy: 73.53
Round  80, Train loss: 0.392, Test loss: 0.625, Test accuracy: 73.70
Round  81, Train loss: 0.495, Test loss: 0.631, Test accuracy: 73.63
Round  82, Train loss: 0.545, Test loss: 0.630, Test accuracy: 72.83
Round  83, Train loss: 0.311, Test loss: 0.629, Test accuracy: 72.80
Round  84, Train loss: 0.307, Test loss: 0.641, Test accuracy: 73.37
Round  85, Train loss: 0.282, Test loss: 0.635, Test accuracy: 73.20
Round  86, Train loss: 0.281, Test loss: 0.627, Test accuracy: 73.30
Round  87, Train loss: 0.411, Test loss: 0.653, Test accuracy: 73.03
Round  88, Train loss: 0.418, Test loss: 0.637, Test accuracy: 73.73
Round  89, Train loss: 0.307, Test loss: 0.628, Test accuracy: 73.37
Round  90, Train loss: 0.241, Test loss: 0.642, Test accuracy: 73.73
Round  91, Train loss: 0.388, Test loss: 0.630, Test accuracy: 74.23
Round  92, Train loss: 0.476, Test loss: 0.643, Test accuracy: 74.23
Round  93, Train loss: 0.406, Test loss: 0.662, Test accuracy: 72.93
Round  94, Train loss: 0.234, Test loss: 0.656, Test accuracy: 73.37
Round  95, Train loss: 0.297, Test loss: 0.645, Test accuracy: 73.27
Round  96, Train loss: 0.441, Test loss: 0.645, Test accuracy: 72.83
Round  97, Train loss: 0.216, Test loss: 0.646, Test accuracy: 72.77
Round  98, Train loss: 0.252, Test loss: 0.642, Test accuracy: 73.53
Round  99, Train loss: 0.263, Test loss: 0.638, Test accuracy: 73.83
Final Round, Train loss: 0.307, Test loss: 0.656, Test accuracy: 73.93
Average accuracy final 10 rounds: 73.47333333333333
324.4132797718048
[1.0909245014190674, 1.8536269664764404, 2.6231229305267334, 3.397915840148926, 4.169163227081299, 4.9440696239471436, 5.7178754806518555, 6.488767147064209, 7.259209394454956, 8.029423713684082, 8.804009675979614, 9.576647996902466, 10.350679397583008, 11.125593662261963, 11.894704341888428, 12.671838521957397, 13.434834480285645, 14.194348573684692, 14.962255001068115, 15.732322931289673, 16.511255502700806, 17.28057336807251, 18.05495524406433, 18.827759265899658, 19.59913206100464, 20.370206832885742, 21.140504121780396, 21.915339946746826, 22.685594081878662, 23.46068787574768, 24.237186670303345, 24.996596336364746, 25.7662456035614, 26.540613412857056, 27.308618545532227, 28.086305618286133, 28.858152866363525, 29.65307116508484, 30.457594633102417, 31.245421648025513, 32.05826807022095, 32.87659978866577, 33.69520282745361, 34.5130558013916, 35.32542610168457, 36.12309408187866, 36.91883945465088, 37.734561920166016, 38.55227828025818, 39.369431495666504, 40.184598207473755, 40.99990677833557, 41.8129985332489, 42.63212251663208, 43.445377826690674, 44.25839972496033, 45.06424927711487, 45.87355852127075, 46.68308401107788, 47.468236446380615, 48.258538246154785, 49.06442666053772, 49.87246918678284, 50.68185806274414, 51.491273164749146, 52.30156373977661, 53.114938259124756, 53.92376160621643, 54.73738765716553, 55.546919107437134, 56.35540771484375, 57.167755126953125, 57.97794771194458, 58.78445219993591, 59.578248739242554, 60.38180422782898, 61.18906807899475, 61.99988412857056, 62.807750940322876, 63.61807179450989, 64.40592741966248, 65.20588183403015, 66.01618242263794, 66.82335209846497, 67.62768864631653, 68.43520927429199, 69.24314332008362, 70.05491757392883, 70.84775805473328, 71.63711929321289, 72.44530177116394, 73.26160049438477, 74.07016897201538, 74.87941479682922, 75.68889474868774, 76.49974465370178, 77.3093523979187, 78.11391305923462, 78.92392468452454, 79.72282409667969, 80.9700059890747]
[17.866666666666667, 32.333333333333336, 40.56666666666667, 46.333333333333336, 49.766666666666666, 54.266666666666666, 55.766666666666666, 58.9, 60.13333333333333, 60.733333333333334, 62.56666666666667, 63.5, 64.26666666666667, 63.9, 64.13333333333334, 65.63333333333334, 67.06666666666666, 67.9, 68.53333333333333, 69.5, 68.83333333333333, 69.7, 69.03333333333333, 69.03333333333333, 69.26666666666667, 69.3, 69.6, 69.36666666666666, 69.5, 70.56666666666666, 70.43333333333334, 70.1, 71.4, 71.06666666666666, 71.56666666666666, 71.7, 71.3, 71.2, 71.8, 72.2, 72.53333333333333, 72.56666666666666, 72.2, 73.53333333333333, 74.23333333333333, 73.46666666666667, 72.6, 73.36666666666666, 73.23333333333333, 72.86666666666666, 74.13333333333334, 72.63333333333334, 72.9, 74.1, 73.3, 73.93333333333334, 72.1, 73.03333333333333, 73.56666666666666, 73.4, 72.46666666666667, 73.3, 70.66666666666667, 71.96666666666667, 74.03333333333333, 74.6, 72.66666666666667, 72.36666666666666, 72.36666666666666, 73.23333333333333, 73.63333333333334, 74.0, 73.46666666666667, 73.0, 74.03333333333333, 74.2, 73.2, 72.8, 72.86666666666666, 73.53333333333333, 73.7, 73.63333333333334, 72.83333333333333, 72.8, 73.36666666666666, 73.2, 73.3, 73.03333333333333, 73.73333333333333, 73.36666666666666, 73.73333333333333, 74.23333333333333, 74.23333333333333, 72.93333333333334, 73.36666666666666, 73.26666666666667, 72.83333333333333, 72.76666666666667, 73.53333333333333, 73.83333333333333, 73.93333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 5, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.483, Test loss: 1.554, Test accuracy: 34.67
Round   1, Train loss: 1.130, Test loss: 1.120, Test accuracy: 38.20
Round   2, Train loss: 1.071, Test loss: 1.082, Test accuracy: 42.70
Round   3, Train loss: 1.049, Test loss: 1.064, Test accuracy: 40.13
Round   4, Train loss: 1.031, Test loss: 1.035, Test accuracy: 47.70
Round   5, Train loss: 1.017, Test loss: 1.021, Test accuracy: 47.97
Round   6, Train loss: 1.005, Test loss: 1.012, Test accuracy: 47.67
Round   7, Train loss: 0.996, Test loss: 0.980, Test accuracy: 46.77
Round   8, Train loss: 0.984, Test loss: 0.965, Test accuracy: 51.20
Round   9, Train loss: 0.977, Test loss: 0.977, Test accuracy: 50.10
Round  10, Train loss: 0.972, Test loss: 0.959, Test accuracy: 53.00
Round  11, Train loss: 0.962, Test loss: 0.951, Test accuracy: 52.57
Round  12, Train loss: 0.954, Test loss: 0.939, Test accuracy: 54.47
Round  13, Train loss: 0.945, Test loss: 0.947, Test accuracy: 53.47
Round  14, Train loss: 0.938, Test loss: 0.941, Test accuracy: 54.37
Round  15, Train loss: 0.929, Test loss: 0.930, Test accuracy: 53.60
Round  16, Train loss: 0.923, Test loss: 0.937, Test accuracy: 52.80
Round  17, Train loss: 0.908, Test loss: 0.931, Test accuracy: 54.63
Round  18, Train loss: 0.903, Test loss: 0.934, Test accuracy: 53.60
Round  19, Train loss: 0.893, Test loss: 0.940, Test accuracy: 54.20
Round  20, Train loss: 0.986, Test loss: 0.946, Test accuracy: 51.93
Round  21, Train loss: 0.814, Test loss: 0.937, Test accuracy: 51.97
Round  22, Train loss: 0.794, Test loss: 0.931, Test accuracy: 52.43
Round  23, Train loss: 0.774, Test loss: 0.928, Test accuracy: 53.93
Round  24, Train loss: 1.012, Test loss: 0.967, Test accuracy: 51.70
Round  25, Train loss: 0.958, Test loss: 0.988, Test accuracy: 49.97
Round  26, Train loss: 0.744, Test loss: 0.969, Test accuracy: 53.50
Round  27, Train loss: 0.799, Test loss: 0.962, Test accuracy: 53.67
Round  28, Train loss: 0.939, Test loss: 0.983, Test accuracy: 51.97
Round  29, Train loss: 0.708, Test loss: 0.971, Test accuracy: 52.67
Round  30, Train loss: 0.936, Test loss: 0.989, Test accuracy: 51.07
Round  31, Train loss: 0.736, Test loss: 0.984, Test accuracy: 51.60
Round  32, Train loss: 0.738, Test loss: 0.972, Test accuracy: 53.13
Round  33, Train loss: 0.437, Test loss: 0.955, Test accuracy: 53.70
Round  34, Train loss: 0.633, Test loss: 0.954, Test accuracy: 53.90
Round  35, Train loss: 0.473, Test loss: 0.961, Test accuracy: 55.27
Round  36, Train loss: 0.909, Test loss: 0.990, Test accuracy: 53.53
Round  37, Train loss: 0.901, Test loss: 0.967, Test accuracy: 53.40
Round  38, Train loss: 0.601, Test loss: 0.989, Test accuracy: 51.20
Round  39, Train loss: 0.676, Test loss: 1.002, Test accuracy: 54.13
Round  40, Train loss: 0.881, Test loss: 1.038, Test accuracy: 52.27
Round  41, Train loss: 0.832, Test loss: 1.025, Test accuracy: 51.47
Round  42, Train loss: 0.572, Test loss: 1.032, Test accuracy: 51.33
Round  43, Train loss: 0.628, Test loss: 1.034, Test accuracy: 51.50
Round  44, Train loss: 0.538, Test loss: 1.075, Test accuracy: 50.13
Round  45, Train loss: 0.573, Test loss: 1.051, Test accuracy: 51.43
Round  46, Train loss: 0.567, Test loss: 1.068, Test accuracy: 52.03
Round  47, Train loss: 0.349, Test loss: 1.041, Test accuracy: 52.80
Round  48, Train loss: 0.616, Test loss: 1.050, Test accuracy: 51.67
Round  49, Train loss: 0.761, Test loss: 1.114, Test accuracy: 49.43
Round  50, Train loss: 0.667, Test loss: 1.153, Test accuracy: 49.33
Round  51, Train loss: 0.694, Test loss: 1.160, Test accuracy: 48.57
Round  52, Train loss: 0.554, Test loss: 1.118, Test accuracy: 50.13
Round  53, Train loss: 0.678, Test loss: 1.173, Test accuracy: 49.53
Round  54, Train loss: 0.587, Test loss: 1.207, Test accuracy: 48.30
Round  55, Train loss: 0.590, Test loss: 1.176, Test accuracy: 49.50
Round  56, Train loss: 0.325, Test loss: 1.114, Test accuracy: 50.80
Round  57, Train loss: 0.637, Test loss: 1.209, Test accuracy: 50.47
Round  58, Train loss: 0.675, Test loss: 1.232, Test accuracy: 49.40
Round  59, Train loss: 0.409, Test loss: 1.208, Test accuracy: 49.17
Round  60, Train loss: 0.664, Test loss: 1.284, Test accuracy: 48.90
Round  61, Train loss: 0.553, Test loss: 1.264, Test accuracy: 48.90
Round  62, Train loss: 0.415, Test loss: 1.234, Test accuracy: 49.77
Round  63, Train loss: 0.392, Test loss: 1.262, Test accuracy: 48.13
Round  64, Train loss: 0.467, Test loss: 1.214, Test accuracy: 50.63
Round  65, Train loss: 0.425, Test loss: 1.243, Test accuracy: 52.13
Round  66, Train loss: 0.527, Test loss: 1.312, Test accuracy: 50.33
Round  67, Train loss: 0.433, Test loss: 1.284, Test accuracy: 48.70
Round  68, Train loss: 0.446, Test loss: 1.328, Test accuracy: 49.57
Round  69, Train loss: 0.319, Test loss: 1.329, Test accuracy: 49.27
Round  70, Train loss: 0.442, Test loss: 1.365, Test accuracy: 49.70
Round  71, Train loss: 0.458, Test loss: 1.410, Test accuracy: 48.97
Round  72, Train loss: 0.385, Test loss: 1.359, Test accuracy: 49.80
Round  73, Train loss: 0.368, Test loss: 1.440, Test accuracy: 47.20
Round  74, Train loss: 0.341, Test loss: 1.558, Test accuracy: 45.83
Round  75, Train loss: 0.385, Test loss: 1.554, Test accuracy: 46.13
Round  76, Train loss: 0.338, Test loss: 1.507, Test accuracy: 46.73
Round  77, Train loss: 0.530, Test loss: 1.528, Test accuracy: 48.07
Round  78, Train loss: 0.473, Test loss: 1.511, Test accuracy: 47.53
Round  79, Train loss: 0.365, Test loss: 1.537, Test accuracy: 47.20
Round  80, Train loss: 0.364, Test loss: 1.539, Test accuracy: 47.30
Round  81, Train loss: 0.334, Test loss: 1.501, Test accuracy: 48.20
Round  82, Train loss: 0.309, Test loss: 1.531, Test accuracy: 47.90
Round  83, Train loss: 0.311, Test loss: 1.518, Test accuracy: 48.03
Round  84, Train loss: 0.302, Test loss: 1.527, Test accuracy: 49.10
Round  85, Train loss: 0.284, Test loss: 1.538, Test accuracy: 48.97
Round  86, Train loss: 0.283, Test loss: 1.531, Test accuracy: 48.73
Round  87, Train loss: 0.294, Test loss: 1.549, Test accuracy: 48.70
Round  88, Train loss: 0.278, Test loss: 1.623, Test accuracy: 47.93
Round  89, Train loss: 0.280, Test loss: 1.626, Test accuracy: 48.10
Round  90, Train loss: 0.262, Test loss: 1.612, Test accuracy: 48.60
Round  91, Train loss: 0.263, Test loss: 1.635, Test accuracy: 48.13
Round  92, Train loss: 0.248, Test loss: 1.634, Test accuracy: 48.03
Round  93, Train loss: 0.251, Test loss: 1.654, Test accuracy: 48.27
Round  94, Train loss: 0.238, Test loss: 1.686, Test accuracy: 47.70
Round  95, Train loss: 0.247, Test loss: 1.694, Test accuracy: 47.90
Round  96, Train loss: 0.236, Test loss: 1.695, Test accuracy: 48.47
Round  97, Train loss: 0.224, Test loss: 1.726, Test accuracy: 47.20
Round  98, Train loss: 0.231, Test loss: 1.737, Test accuracy: 48.27
Round  99, Train loss: 0.238, Test loss: 1.746, Test accuracy: 48.30
Final Round, Train loss: 0.178, Test loss: 1.741, Test accuracy: 48.30
Average accuracy final 10 rounds: 48.086666666666666
1017.5867455005646
[1.9432170391082764, 3.5407869815826416, 5.144011974334717, 6.750781536102295, 8.352452516555786, 9.9571533203125, 11.55961012840271, 13.17279863357544, 14.789434671401978, 16.404452562332153, 18.015812158584595, 19.630717515945435, 21.24611210823059, 22.855578422546387, 24.469653367996216, 26.078857898712158, 27.675955772399902, 29.26805281639099, 30.858664512634277, 32.451104164123535, 34.03592300415039, 35.62754535675049, 37.20604348182678, 38.79055595397949, 40.37297201156616, 41.96528959274292, 43.55454683303833, 45.14816999435425, 46.74520015716553, 48.34310293197632, 49.93682265281677, 51.52546668052673, 53.089627265930176, 54.67245650291443, 56.26298713684082, 57.8434944152832, 59.420159339904785, 61.002605676651, 62.5858154296875, 64.17737364768982, 65.7575478553772, 67.34550762176514, 68.93532299995422, 70.51103281974792, 72.10282111167908, 73.69656014442444, 75.29145503044128, 76.88866019248962, 78.49546790122986, 80.09111666679382, 81.68850874900818, 83.28112530708313, 84.87843203544617, 86.47278308868408, 88.06416821479797, 89.65640258789062, 91.24809265136719, 92.82968235015869, 94.4251594543457, 96.01138496398926, 97.60668802261353, 99.1928563117981, 100.76613306999207, 102.35262179374695, 103.94562983512878, 105.51397156715393, 107.1117308139801, 108.70205569267273, 110.28985571861267, 111.88284873962402, 113.46389389038086, 115.04852485656738, 116.6355049610138, 118.23230385780334, 119.83927416801453, 121.42115306854248, 123.01505827903748, 124.62321710586548, 126.22100400924683, 127.82121062278748, 129.43379163742065, 131.02837800979614, 132.6265652179718, 134.22099709510803, 135.80051612854004, 137.39108681678772, 138.9791281223297, 140.57348680496216, 142.18383717536926, 143.80259561538696, 145.4062144756317, 147.00751638412476, 148.60595297813416, 150.215163230896, 151.82146310806274, 153.42782473564148, 155.01717138290405, 156.60894465446472, 158.20456671714783, 159.79998326301575, 162.26279401779175]
[34.666666666666664, 38.2, 42.7, 40.13333333333333, 47.7, 47.96666666666667, 47.666666666666664, 46.766666666666666, 51.2, 50.1, 53.0, 52.56666666666667, 54.46666666666667, 53.46666666666667, 54.36666666666667, 53.6, 52.8, 54.63333333333333, 53.6, 54.2, 51.93333333333333, 51.96666666666667, 52.43333333333333, 53.93333333333333, 51.7, 49.96666666666667, 53.5, 53.666666666666664, 51.96666666666667, 52.666666666666664, 51.06666666666667, 51.6, 53.13333333333333, 53.7, 53.9, 55.266666666666666, 53.53333333333333, 53.4, 51.2, 54.13333333333333, 52.266666666666666, 51.46666666666667, 51.333333333333336, 51.5, 50.13333333333333, 51.43333333333333, 52.03333333333333, 52.8, 51.666666666666664, 49.43333333333333, 49.333333333333336, 48.56666666666667, 50.13333333333333, 49.53333333333333, 48.3, 49.5, 50.8, 50.46666666666667, 49.4, 49.166666666666664, 48.9, 48.9, 49.766666666666666, 48.13333333333333, 50.63333333333333, 52.13333333333333, 50.333333333333336, 48.7, 49.56666666666667, 49.266666666666666, 49.7, 48.96666666666667, 49.8, 47.2, 45.833333333333336, 46.13333333333333, 46.733333333333334, 48.06666666666667, 47.53333333333333, 47.2, 47.3, 48.2, 47.9, 48.03333333333333, 49.1, 48.96666666666667, 48.733333333333334, 48.7, 47.93333333333333, 48.1, 48.6, 48.13333333333333, 48.03333333333333, 48.266666666666666, 47.7, 47.9, 48.46666666666667, 47.2, 48.266666666666666, 48.3, 48.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.426, Test loss: 1.481, Test accuracy: 33.33
Round   1, Train loss: 1.098, Test loss: 1.098, Test accuracy: 41.33
Round   2, Train loss: 1.046, Test loss: 1.028, Test accuracy: 49.43
Round   3, Train loss: 1.030, Test loss: 1.010, Test accuracy: 49.17
Round   4, Train loss: 1.020, Test loss: 0.996, Test accuracy: 50.97
Round   5, Train loss: 1.010, Test loss: 1.032, Test accuracy: 47.23
Round   6, Train loss: 0.999, Test loss: 0.957, Test accuracy: 51.67
Round   7, Train loss: 0.990, Test loss: 0.962, Test accuracy: 49.27
Round   8, Train loss: 0.984, Test loss: 0.939, Test accuracy: 53.50
Round   9, Train loss: 0.973, Test loss: 0.927, Test accuracy: 56.33
Round  10, Train loss: 0.966, Test loss: 0.923, Test accuracy: 57.40
Round  11, Train loss: 0.957, Test loss: 0.917, Test accuracy: 58.07
Round  12, Train loss: 0.950, Test loss: 0.896, Test accuracy: 60.10
Round  13, Train loss: 0.941, Test loss: 0.906, Test accuracy: 56.73
Round  14, Train loss: 0.934, Test loss: 0.900, Test accuracy: 57.27
Round  15, Train loss: 0.928, Test loss: 0.895, Test accuracy: 59.17
Round  16, Train loss: 0.921, Test loss: 0.877, Test accuracy: 58.87
Round  17, Train loss: 0.908, Test loss: 0.880, Test accuracy: 60.67
Round  18, Train loss: 0.898, Test loss: 0.884, Test accuracy: 57.50
Round  19, Train loss: 0.894, Test loss: 0.902, Test accuracy: 58.77
Round  20, Train loss: 0.624, Test loss: 0.841, Test accuracy: 62.17
Round  21, Train loss: 1.002, Test loss: 0.871, Test accuracy: 58.37
Round  22, Train loss: 0.973, Test loss: 0.888, Test accuracy: 58.40
Round  23, Train loss: 0.982, Test loss: 0.877, Test accuracy: 58.83
Round  24, Train loss: 0.824, Test loss: 0.872, Test accuracy: 60.10
Round  25, Train loss: 0.754, Test loss: 0.870, Test accuracy: 61.60
Round  26, Train loss: 0.772, Test loss: 0.902, Test accuracy: 59.00
Round  27, Train loss: 0.756, Test loss: 0.859, Test accuracy: 62.03
Round  28, Train loss: 0.724, Test loss: 0.890, Test accuracy: 58.77
Round  29, Train loss: 0.730, Test loss: 0.906, Test accuracy: 57.70
Round  30, Train loss: 0.882, Test loss: 0.919, Test accuracy: 56.50
Round  31, Train loss: 0.924, Test loss: 0.930, Test accuracy: 55.27
Round  32, Train loss: 0.881, Test loss: 0.903, Test accuracy: 55.97
Round  33, Train loss: 0.677, Test loss: 0.901, Test accuracy: 56.97
Round  34, Train loss: 0.639, Test loss: 0.900, Test accuracy: 58.73
Round  35, Train loss: 0.846, Test loss: 0.922, Test accuracy: 55.10
Round  36, Train loss: 0.870, Test loss: 0.950, Test accuracy: 52.83
Round  37, Train loss: 0.812, Test loss: 0.949, Test accuracy: 54.23
Round  38, Train loss: 0.650, Test loss: 0.977, Test accuracy: 54.63
Round  39, Train loss: 0.813, Test loss: 0.978, Test accuracy: 52.80
Round  40, Train loss: 0.642, Test loss: 0.942, Test accuracy: 55.63
Round  41, Train loss: 0.619, Test loss: 0.948, Test accuracy: 55.33
Round  42, Train loss: 0.567, Test loss: 0.922, Test accuracy: 57.23
Round  43, Train loss: 0.763, Test loss: 0.935, Test accuracy: 56.90
Round  44, Train loss: 0.696, Test loss: 1.002, Test accuracy: 55.63
Round  45, Train loss: 0.664, Test loss: 1.027, Test accuracy: 54.63
Round  46, Train loss: 0.680, Test loss: 1.068, Test accuracy: 52.67
Round  47, Train loss: 0.625, Test loss: 1.080, Test accuracy: 52.13
Round  48, Train loss: 0.556, Test loss: 1.027, Test accuracy: 54.80
Round  49, Train loss: 0.415, Test loss: 0.980, Test accuracy: 57.27
Round  50, Train loss: 0.639, Test loss: 1.063, Test accuracy: 54.03
Round  51, Train loss: 0.642, Test loss: 1.035, Test accuracy: 55.20
Round  52, Train loss: 0.517, Test loss: 1.021, Test accuracy: 55.60
Round  53, Train loss: 0.486, Test loss: 1.034, Test accuracy: 56.27
Round  54, Train loss: 0.428, Test loss: 1.067, Test accuracy: 55.97
Round  55, Train loss: 0.539, Test loss: 1.068, Test accuracy: 54.50
Round  56, Train loss: 0.556, Test loss: 1.140, Test accuracy: 51.90
Round  57, Train loss: 0.587, Test loss: 1.237, Test accuracy: 50.47
Round  58, Train loss: 0.482, Test loss: 1.107, Test accuracy: 55.37
Round  59, Train loss: 0.406, Test loss: 1.118, Test accuracy: 55.43
Round  60, Train loss: 0.593, Test loss: 1.172, Test accuracy: 51.53
Round  61, Train loss: 0.496, Test loss: 1.210, Test accuracy: 51.53
Round  62, Train loss: 0.399, Test loss: 1.146, Test accuracy: 51.73
Round  63, Train loss: 0.402, Test loss: 1.145, Test accuracy: 51.70
Round  64, Train loss: 0.541, Test loss: 1.251, Test accuracy: 50.43
Round  65, Train loss: 0.490, Test loss: 1.247, Test accuracy: 51.87
Round  66, Train loss: 0.472, Test loss: 1.332, Test accuracy: 48.40
Round  67, Train loss: 0.329, Test loss: 1.158, Test accuracy: 52.77
Round  68, Train loss: 0.335, Test loss: 1.222, Test accuracy: 52.20
Round  69, Train loss: 0.325, Test loss: 1.225, Test accuracy: 52.00
Round  70, Train loss: 0.313, Test loss: 1.232, Test accuracy: 53.60
Round  71, Train loss: 0.394, Test loss: 1.322, Test accuracy: 51.60
Round  72, Train loss: 0.431, Test loss: 1.347, Test accuracy: 51.13
Round  73, Train loss: 0.270, Test loss: 1.319, Test accuracy: 52.87
Round  74, Train loss: 0.266, Test loss: 1.328, Test accuracy: 52.13
Round  75, Train loss: 0.348, Test loss: 1.433, Test accuracy: 49.63
Round  76, Train loss: 0.266, Test loss: 1.319, Test accuracy: 50.63
Round  77, Train loss: 0.454, Test loss: 1.352, Test accuracy: 49.97
Round  78, Train loss: 0.312, Test loss: 1.303, Test accuracy: 52.50
Round  79, Train loss: 0.284, Test loss: 1.285, Test accuracy: 53.60
Round  80, Train loss: 0.333, Test loss: 1.315, Test accuracy: 52.87
Round  81, Train loss: 0.299, Test loss: 1.293, Test accuracy: 53.23
Round  82, Train loss: 0.295, Test loss: 1.330, Test accuracy: 52.60
Round  83, Train loss: 0.282, Test loss: 1.379, Test accuracy: 51.90
Round  84, Train loss: 0.286, Test loss: 1.355, Test accuracy: 52.90
Round  85, Train loss: 0.278, Test loss: 1.369, Test accuracy: 52.53
Round  86, Train loss: 0.274, Test loss: 1.361, Test accuracy: 52.57
Round  87, Train loss: 0.272, Test loss: 1.398, Test accuracy: 52.20
Round  88, Train loss: 0.260, Test loss: 1.396, Test accuracy: 51.63
Round  89, Train loss: 0.252, Test loss: 1.437, Test accuracy: 51.90
Round  90, Train loss: 0.247, Test loss: 1.447, Test accuracy: 51.97
Round  91, Train loss: 0.242, Test loss: 1.461, Test accuracy: 51.60
Round  92, Train loss: 0.254, Test loss: 1.462, Test accuracy: 49.90
Round  93, Train loss: 0.235, Test loss: 1.526, Test accuracy: 50.27
Round  94, Train loss: 0.242, Test loss: 1.520, Test accuracy: 50.70
Round  95, Train loss: 0.227, Test loss: 1.499, Test accuracy: 52.07
Round  96, Train loss: 0.219, Test loss: 1.524, Test accuracy: 50.50
Round  97, Train loss: 0.226, Test loss: 1.527, Test accuracy: 52.03
Round  98, Train loss: 0.219, Test loss: 1.563, Test accuracy: 50.73
Round  99, Train loss: 0.220, Test loss: 1.537, Test accuracy: 50.63
Final Round, Train loss: 0.190, Test loss: 1.583, Test accuracy: 51.33
Average accuracy final 10 rounds: 51.04
1479.8417811393738
[1.9586224555969238, 3.5733540058135986, 5.197113990783691, 6.823416471481323, 8.449049711227417, 10.077771425247192, 11.699719190597534, 13.32463550567627, 14.947351694107056, 16.558053970336914, 18.18595576286316, 19.811557292938232, 21.439940452575684, 23.064244031906128, 24.6931369304657, 26.318061113357544, 27.940016269683838, 29.544281244277954, 31.148152112960815, 32.623610973358154, 34.071661710739136, 37.02243995666504, 39.97031378746033, 42.91923761367798, 45.868377923965454, 48.79522657394409, 51.59428882598877, 54.381569385528564, 57.177081823349, 59.98470759391785, 62.77036452293396, 65.55315375328064, 68.35688471794128, 71.15265727043152, 73.89479780197144, 76.68877863883972, 79.50497388839722, 82.4454116821289, 85.26836442947388, 88.0886013507843, 90.91460347175598, 93.72462964057922, 96.5450279712677, 99.36657929420471, 102.185227394104, 105.00193548202515, 107.82387447357178, 110.65750193595886, 113.48180747032166, 116.30236721038818, 119.12028074264526, 121.93900036811829, 124.763423204422, 127.583425283432, 130.39405798912048, 133.21124958992004, 136.03423929214478, 138.84689331054688, 141.66619086265564, 144.47334933280945, 147.29730486869812, 150.1179337501526, 152.92456722259521, 155.68656587600708, 158.51034283638, 161.3247561454773, 164.15436840057373, 166.96417379379272, 169.78202939033508, 172.59915494918823, 175.42509603500366, 178.24300408363342, 181.06275177001953, 183.87342762947083, 186.70869326591492, 189.5273721218109, 192.34447169303894, 195.1596281528473, 197.8767454624176, 200.70795464515686, 203.53804278373718, 206.3743076324463, 209.20927238464355, 212.0433051586151, 214.8608820438385, 217.6849021911621, 220.50707721710205, 223.33471822738647, 226.17840003967285, 229.021630525589, 231.84661984443665, 234.6706187725067, 237.49207854270935, 240.3199179172516, 243.13659191131592, 245.96112060546875, 248.79024052619934, 251.70826983451843, 254.68027710914612, 257.6383261680603, 260.02767729759216]
[33.333333333333336, 41.333333333333336, 49.43333333333333, 49.166666666666664, 50.96666666666667, 47.233333333333334, 51.666666666666664, 49.266666666666666, 53.5, 56.333333333333336, 57.4, 58.06666666666667, 60.1, 56.733333333333334, 57.266666666666666, 59.166666666666664, 58.86666666666667, 60.666666666666664, 57.5, 58.766666666666666, 62.166666666666664, 58.36666666666667, 58.4, 58.833333333333336, 60.1, 61.6, 59.0, 62.03333333333333, 58.766666666666666, 57.7, 56.5, 55.266666666666666, 55.96666666666667, 56.96666666666667, 58.733333333333334, 55.1, 52.833333333333336, 54.233333333333334, 54.63333333333333, 52.8, 55.63333333333333, 55.333333333333336, 57.233333333333334, 56.9, 55.63333333333333, 54.63333333333333, 52.666666666666664, 52.13333333333333, 54.8, 57.266666666666666, 54.03333333333333, 55.2, 55.6, 56.266666666666666, 55.96666666666667, 54.5, 51.9, 50.46666666666667, 55.36666666666667, 55.43333333333333, 51.53333333333333, 51.53333333333333, 51.733333333333334, 51.7, 50.43333333333333, 51.86666666666667, 48.4, 52.766666666666666, 52.2, 52.0, 53.6, 51.6, 51.13333333333333, 52.86666666666667, 52.13333333333333, 49.63333333333333, 50.63333333333333, 49.96666666666667, 52.5, 53.6, 52.86666666666667, 53.233333333333334, 52.6, 51.9, 52.9, 52.53333333333333, 52.56666666666667, 52.2, 51.63333333333333, 51.9, 51.96666666666667, 51.6, 49.9, 50.266666666666666, 50.7, 52.06666666666667, 50.5, 52.03333333333333, 50.733333333333334, 50.63333333333333, 51.333333333333336]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.438, Test loss: 1.423, Test accuracy: 35.47
Round   1, Train loss: 1.120, Test loss: 1.117, Test accuracy: 39.23
Round   2, Train loss: 1.077, Test loss: 1.102, Test accuracy: 42.57
Round   3, Train loss: 1.058, Test loss: 1.052, Test accuracy: 46.50
Round   4, Train loss: 1.045, Test loss: 1.027, Test accuracy: 50.00
Round   5, Train loss: 1.034, Test loss: 1.020, Test accuracy: 48.70
Round   6, Train loss: 1.024, Test loss: 1.020, Test accuracy: 50.20
Round   7, Train loss: 1.014, Test loss: 0.983, Test accuracy: 53.33
Round   8, Train loss: 1.003, Test loss: 0.982, Test accuracy: 54.53
Round   9, Train loss: 0.996, Test loss: 0.960, Test accuracy: 56.83
Round  10, Train loss: 0.986, Test loss: 0.953, Test accuracy: 53.20
Round  11, Train loss: 0.978, Test loss: 0.939, Test accuracy: 55.10
Round  12, Train loss: 0.966, Test loss: 0.932, Test accuracy: 56.67
Round  13, Train loss: 0.959, Test loss: 0.953, Test accuracy: 55.67
Round  14, Train loss: 0.949, Test loss: 0.944, Test accuracy: 53.70
Round  15, Train loss: 0.941, Test loss: 0.947, Test accuracy: 54.83
Round  16, Train loss: 0.934, Test loss: 0.921, Test accuracy: 59.00
Round  17, Train loss: 0.922, Test loss: 0.922, Test accuracy: 57.67
Round  18, Train loss: 0.914, Test loss: 0.898, Test accuracy: 59.10
Round  19, Train loss: 0.900, Test loss: 0.904, Test accuracy: 58.90
Round  20, Train loss: 0.975, Test loss: 0.922, Test accuracy: 57.53
Round  21, Train loss: 0.702, Test loss: 0.905, Test accuracy: 58.83
Round  22, Train loss: 0.781, Test loss: 0.910, Test accuracy: 57.27
Round  23, Train loss: 0.961, Test loss: 0.940, Test accuracy: 55.93
Round  24, Train loss: 0.864, Test loss: 0.942, Test accuracy: 55.70
Round  25, Train loss: 0.920, Test loss: 0.961, Test accuracy: 53.50
Round  26, Train loss: 0.743, Test loss: 0.916, Test accuracy: 56.23
Round  27, Train loss: 0.913, Test loss: 0.940, Test accuracy: 55.10
Round  28, Train loss: 0.860, Test loss: 0.974, Test accuracy: 52.53
Round  29, Train loss: 0.900, Test loss: 0.993, Test accuracy: 52.50
Round  30, Train loss: 0.853, Test loss: 1.007, Test accuracy: 51.53
Round  31, Train loss: 0.717, Test loss: 0.964, Test accuracy: 54.77
Round  32, Train loss: 0.727, Test loss: 0.951, Test accuracy: 54.17
Round  33, Train loss: 0.630, Test loss: 0.953, Test accuracy: 55.07
Round  34, Train loss: 0.789, Test loss: 0.977, Test accuracy: 53.87
Round  35, Train loss: 0.632, Test loss: 0.985, Test accuracy: 55.07
Round  36, Train loss: 0.850, Test loss: 1.006, Test accuracy: 52.80
Round  37, Train loss: 0.664, Test loss: 0.983, Test accuracy: 53.87
Round  38, Train loss: 0.620, Test loss: 0.986, Test accuracy: 54.67
Round  39, Train loss: 0.669, Test loss: 1.005, Test accuracy: 55.03
Round  40, Train loss: 0.841, Test loss: 1.035, Test accuracy: 52.67
Round  41, Train loss: 0.817, Test loss: 1.047, Test accuracy: 53.40
Round  42, Train loss: 0.686, Test loss: 1.067, Test accuracy: 52.27
Round  43, Train loss: 0.583, Test loss: 1.032, Test accuracy: 54.53
Round  44, Train loss: 0.545, Test loss: 1.031, Test accuracy: 53.73
Round  45, Train loss: 0.501, Test loss: 1.025, Test accuracy: 53.63
Round  46, Train loss: 0.393, Test loss: 1.015, Test accuracy: 55.70
Round  47, Train loss: 0.470, Test loss: 1.044, Test accuracy: 53.07
Round  48, Train loss: 0.581, Test loss: 1.067, Test accuracy: 53.13
Round  49, Train loss: 0.706, Test loss: 1.168, Test accuracy: 49.83
Round  50, Train loss: 0.620, Test loss: 1.137, Test accuracy: 50.13
Round  51, Train loss: 0.630, Test loss: 1.158, Test accuracy: 51.00
Round  52, Train loss: 0.644, Test loss: 1.255, Test accuracy: 48.87
Round  53, Train loss: 0.615, Test loss: 1.244, Test accuracy: 50.37
Round  54, Train loss: 0.548, Test loss: 1.264, Test accuracy: 47.37
Round  55, Train loss: 0.453, Test loss: 1.213, Test accuracy: 50.50
Round  56, Train loss: 0.435, Test loss: 1.155, Test accuracy: 52.87
Round  57, Train loss: 0.469, Test loss: 1.163, Test accuracy: 52.83
Round  58, Train loss: 0.608, Test loss: 1.219, Test accuracy: 50.80
Round  59, Train loss: 0.386, Test loss: 1.239, Test accuracy: 50.43
Round  60, Train loss: 0.462, Test loss: 1.222, Test accuracy: 51.83
Round  61, Train loss: 0.510, Test loss: 1.235, Test accuracy: 50.93
Round  62, Train loss: 0.401, Test loss: 1.291, Test accuracy: 49.87
Round  63, Train loss: 0.480, Test loss: 1.327, Test accuracy: 49.20
Round  64, Train loss: 0.412, Test loss: 1.254, Test accuracy: 49.80
Round  65, Train loss: 0.407, Test loss: 1.263, Test accuracy: 52.20
Round  66, Train loss: 0.356, Test loss: 1.272, Test accuracy: 51.30
Round  67, Train loss: 0.505, Test loss: 1.353, Test accuracy: 51.07
Round  68, Train loss: 0.435, Test loss: 1.372, Test accuracy: 48.50
Round  69, Train loss: 0.309, Test loss: 1.366, Test accuracy: 50.60
Round  70, Train loss: 0.386, Test loss: 1.387, Test accuracy: 49.57
Round  71, Train loss: 0.406, Test loss: 1.399, Test accuracy: 49.23
Round  72, Train loss: 0.363, Test loss: 1.317, Test accuracy: 50.50
Round  73, Train loss: 0.333, Test loss: 1.398, Test accuracy: 47.97
Round  74, Train loss: 0.333, Test loss: 1.442, Test accuracy: 48.37
Round  75, Train loss: 0.363, Test loss: 1.476, Test accuracy: 47.97
Round  76, Train loss: 0.288, Test loss: 1.506, Test accuracy: 47.43
Round  77, Train loss: 0.368, Test loss: 1.467, Test accuracy: 48.87
Round  78, Train loss: 0.424, Test loss: 1.520, Test accuracy: 48.20
Round  79, Train loss: 0.357, Test loss: 1.501, Test accuracy: 48.67
Round  80, Train loss: 0.335, Test loss: 1.490, Test accuracy: 48.43
Round  81, Train loss: 0.304, Test loss: 1.469, Test accuracy: 49.50
Round  82, Train loss: 0.301, Test loss: 1.467, Test accuracy: 49.73
Round  83, Train loss: 0.290, Test loss: 1.457, Test accuracy: 50.50
Round  84, Train loss: 0.276, Test loss: 1.469, Test accuracy: 50.07
Round  85, Train loss: 0.269, Test loss: 1.458, Test accuracy: 51.23
Round  86, Train loss: 0.262, Test loss: 1.476, Test accuracy: 50.43
Round  87, Train loss: 0.259, Test loss: 1.504, Test accuracy: 49.17
Round  88, Train loss: 0.274, Test loss: 1.513, Test accuracy: 49.40
Round  89, Train loss: 0.242, Test loss: 1.577, Test accuracy: 49.10
Round  90, Train loss: 0.248, Test loss: 1.582, Test accuracy: 49.37
Round  91, Train loss: 0.246, Test loss: 1.598, Test accuracy: 48.90
Round  92, Train loss: 0.251, Test loss: 1.536, Test accuracy: 48.40
Round  93, Train loss: 0.237, Test loss: 1.549, Test accuracy: 48.60
Round  94, Train loss: 0.230, Test loss: 1.593, Test accuracy: 48.97
Round  95, Train loss: 0.223, Test loss: 1.572, Test accuracy: 49.40
Round  96, Train loss: 0.218, Test loss: 1.584, Test accuracy: 49.37
Round  97, Train loss: 0.223, Test loss: 1.603, Test accuracy: 49.07
Round  98, Train loss: 0.211, Test loss: 1.605, Test accuracy: 49.57
Round  99, Train loss: 0.209, Test loss: 1.611, Test accuracy: 48.93
Final Round, Train loss: 0.177, Test loss: 1.689, Test accuracy: 48.27
Average accuracy final 10 rounds: 49.05666666666666
1440.797283411026
[1.9038798809051514, 3.4758238792419434, 5.0617029666900635, 6.626265287399292, 8.191423416137695, 9.758868217468262, 11.31903862953186, 12.870313882827759, 14.431646347045898, 15.914972066879272, 17.45209288597107, 18.99462628364563, 20.538379669189453, 22.084285020828247, 23.628282070159912, 25.16950225830078, 26.71215510368347, 28.257702827453613, 29.801403999328613, 31.34732484817505, 32.88533973693848, 35.73858046531677, 38.548757791519165, 41.34955978393555, 44.19796323776245, 47.06330108642578, 49.90402007102966, 52.74170398712158, 55.54838275909424, 58.39724683761597, 61.26344633102417, 64.08055853843689, 66.92909574508667, 69.78849601745605, 72.58563804626465, 75.40085053443909, 78.271901845932, 81.0672857761383, 83.88436770439148, 86.7050461769104, 89.55250382423401, 92.41229319572449, 95.26194834709167, 98.08205699920654, 100.8869354724884, 103.6961522102356, 106.52615571022034, 109.38684248924255, 112.24488091468811, 115.06816983222961, 117.92395401000977, 120.77826118469238, 123.58288240432739, 126.40641713142395, 129.26942324638367, 132.10792517662048, 134.9302361011505, 137.78873085975647, 140.63850808143616, 143.43338012695312, 146.25751972198486, 149.07062315940857, 151.92250061035156, 154.7593846321106, 157.54750275611877, 160.4005823135376, 163.234228849411, 166.03710269927979, 168.87756490707397, 171.6791636943817, 174.53111219406128, 177.40512704849243, 180.21216297149658, 183.02898788452148, 185.8811571598053, 188.66671347618103, 191.45442414283752, 194.3137867450714, 197.16915464401245, 199.99010682106018, 202.83530616760254, 205.65190625190735, 208.45626378059387, 211.13243651390076, 213.80689764022827, 216.48817658424377, 219.15299820899963, 221.8636929988861, 224.57240295410156, 227.29606699943542, 229.99201464653015, 232.6836440563202, 235.40144276618958, 238.25388407707214, 241.09307599067688, 243.92625737190247, 246.79633259773254, 249.60156345367432, 252.417804479599, 255.27872681617737, 257.59577894210815]
[35.46666666666667, 39.233333333333334, 42.56666666666667, 46.5, 50.0, 48.7, 50.2, 53.333333333333336, 54.53333333333333, 56.833333333333336, 53.2, 55.1, 56.666666666666664, 55.666666666666664, 53.7, 54.833333333333336, 59.0, 57.666666666666664, 59.1, 58.9, 57.53333333333333, 58.833333333333336, 57.266666666666666, 55.93333333333333, 55.7, 53.5, 56.233333333333334, 55.1, 52.53333333333333, 52.5, 51.53333333333333, 54.766666666666666, 54.166666666666664, 55.06666666666667, 53.86666666666667, 55.06666666666667, 52.8, 53.86666666666667, 54.666666666666664, 55.03333333333333, 52.666666666666664, 53.4, 52.266666666666666, 54.53333333333333, 53.733333333333334, 53.63333333333333, 55.7, 53.06666666666667, 53.13333333333333, 49.833333333333336, 50.13333333333333, 51.0, 48.86666666666667, 50.36666666666667, 47.36666666666667, 50.5, 52.86666666666667, 52.833333333333336, 50.8, 50.43333333333333, 51.833333333333336, 50.93333333333333, 49.86666666666667, 49.2, 49.8, 52.2, 51.3, 51.06666666666667, 48.5, 50.6, 49.56666666666667, 49.233333333333334, 50.5, 47.96666666666667, 48.36666666666667, 47.96666666666667, 47.43333333333333, 48.86666666666667, 48.2, 48.666666666666664, 48.43333333333333, 49.5, 49.733333333333334, 50.5, 50.06666666666667, 51.233333333333334, 50.43333333333333, 49.166666666666664, 49.4, 49.1, 49.36666666666667, 48.9, 48.4, 48.6, 48.96666666666667, 49.4, 49.36666666666667, 49.06666666666667, 49.56666666666667, 48.93333333333333, 48.266666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.704, Test loss: 2.543, Test accuracy: 19.37
Round   1, Train loss: 1.146, Test loss: 1.804, Test accuracy: 30.50
Round   2, Train loss: 1.020, Test loss: 1.567, Test accuracy: 36.40
Round   3, Train loss: 1.083, Test loss: 1.378, Test accuracy: 44.87
Round   4, Train loss: 1.030, Test loss: 1.228, Test accuracy: 53.37
Round   5, Train loss: 1.023, Test loss: 0.970, Test accuracy: 56.47
Round   6, Train loss: 1.071, Test loss: 0.925, Test accuracy: 57.23
Round   7, Train loss: 0.916, Test loss: 0.882, Test accuracy: 59.63
Round   8, Train loss: 0.884, Test loss: 0.850, Test accuracy: 62.33
Round   9, Train loss: 0.990, Test loss: 0.851, Test accuracy: 63.00
Round  10, Train loss: 0.886, Test loss: 0.821, Test accuracy: 64.37
Round  11, Train loss: 0.806, Test loss: 0.797, Test accuracy: 65.67
Round  12, Train loss: 0.859, Test loss: 0.780, Test accuracy: 66.10
Round  13, Train loss: 0.628, Test loss: 0.746, Test accuracy: 68.03
Round  14, Train loss: 0.716, Test loss: 0.732, Test accuracy: 68.40
Round  15, Train loss: 0.944, Test loss: 0.764, Test accuracy: 66.47
Round  16, Train loss: 0.897, Test loss: 0.752, Test accuracy: 67.67
Round  17, Train loss: 0.886, Test loss: 0.739, Test accuracy: 68.13
Round  18, Train loss: 0.846, Test loss: 0.750, Test accuracy: 68.00
Round  19, Train loss: 0.885, Test loss: 0.760, Test accuracy: 67.10
Round  20, Train loss: 0.680, Test loss: 0.716, Test accuracy: 68.90
Round  21, Train loss: 0.824, Test loss: 0.745, Test accuracy: 66.57
Round  22, Train loss: 0.826, Test loss: 0.779, Test accuracy: 64.80
Round  23, Train loss: 0.723, Test loss: 0.739, Test accuracy: 67.17
Round  24, Train loss: 0.847, Test loss: 0.744, Test accuracy: 69.10
Round  25, Train loss: 0.643, Test loss: 0.709, Test accuracy: 70.50
Round  26, Train loss: 0.787, Test loss: 0.699, Test accuracy: 71.77
Round  27, Train loss: 0.792, Test loss: 0.694, Test accuracy: 72.53
Round  28, Train loss: 0.625, Test loss: 0.695, Test accuracy: 72.33
Round  29, Train loss: 0.798, Test loss: 0.689, Test accuracy: 71.33
Round  30, Train loss: 0.717, Test loss: 0.703, Test accuracy: 71.03
Round  31, Train loss: 0.718, Test loss: 0.686, Test accuracy: 72.33
Round  32, Train loss: 0.668, Test loss: 0.661, Test accuracy: 73.03
Round  33, Train loss: 0.775, Test loss: 0.680, Test accuracy: 73.17
Round  34, Train loss: 0.513, Test loss: 0.674, Test accuracy: 72.43
Round  35, Train loss: 0.505, Test loss: 0.702, Test accuracy: 70.90
Round  36, Train loss: 0.756, Test loss: 0.683, Test accuracy: 73.37
Round  37, Train loss: 0.737, Test loss: 0.664, Test accuracy: 72.97
Round  38, Train loss: 0.790, Test loss: 0.651, Test accuracy: 74.33
Round  39, Train loss: 0.711, Test loss: 0.661, Test accuracy: 72.77
Round  40, Train loss: 0.755, Test loss: 0.672, Test accuracy: 71.50
Round  41, Train loss: 0.660, Test loss: 0.656, Test accuracy: 72.47
Round  42, Train loss: 0.623, Test loss: 0.662, Test accuracy: 72.90
Round  43, Train loss: 0.704, Test loss: 0.658, Test accuracy: 73.20
Round  44, Train loss: 0.863, Test loss: 0.644, Test accuracy: 74.73
Round  45, Train loss: 0.730, Test loss: 0.656, Test accuracy: 73.53
Round  46, Train loss: 0.708, Test loss: 0.660, Test accuracy: 73.17
Round  47, Train loss: 0.808, Test loss: 0.646, Test accuracy: 73.80
Round  48, Train loss: 0.527, Test loss: 0.627, Test accuracy: 74.23
Round  49, Train loss: 0.539, Test loss: 0.618, Test accuracy: 75.27
Round  50, Train loss: 0.555, Test loss: 0.615, Test accuracy: 75.47
Round  51, Train loss: 0.523, Test loss: 0.634, Test accuracy: 73.97
Round  52, Train loss: 0.499, Test loss: 0.623, Test accuracy: 75.30
Round  53, Train loss: 0.759, Test loss: 0.657, Test accuracy: 72.97
Round  54, Train loss: 0.480, Test loss: 0.622, Test accuracy: 74.33
Round  55, Train loss: 0.609, Test loss: 0.615, Test accuracy: 75.27
Round  56, Train loss: 0.502, Test loss: 0.605, Test accuracy: 76.47
Round  57, Train loss: 0.629, Test loss: 0.609, Test accuracy: 75.37
Round  58, Train loss: 0.707, Test loss: 0.623, Test accuracy: 75.10
Round  59, Train loss: 0.720, Test loss: 0.621, Test accuracy: 74.80
Round  60, Train loss: 0.591, Test loss: 0.618, Test accuracy: 74.63
Round  61, Train loss: 0.483, Test loss: 0.623, Test accuracy: 74.83
Round  62, Train loss: 0.498, Test loss: 0.611, Test accuracy: 75.37
Round  63, Train loss: 0.593, Test loss: 0.611, Test accuracy: 74.40
Round  64, Train loss: 0.751, Test loss: 0.613, Test accuracy: 75.43
Round  65, Train loss: 0.726, Test loss: 0.620, Test accuracy: 75.03
Round  66, Train loss: 0.595, Test loss: 0.609, Test accuracy: 75.53
Round  67, Train loss: 0.598, Test loss: 0.621, Test accuracy: 75.43
Round  68, Train loss: 0.599, Test loss: 0.615, Test accuracy: 75.67
Round  69, Train loss: 0.523, Test loss: 0.611, Test accuracy: 76.57
Round  70, Train loss: 0.542, Test loss: 0.599, Test accuracy: 76.43
Round  71, Train loss: 0.618, Test loss: 0.621, Test accuracy: 75.03
Round  72, Train loss: 0.462, Test loss: 0.617, Test accuracy: 74.90
Round  73, Train loss: 0.398, Test loss: 0.608, Test accuracy: 75.37
Round  74, Train loss: 0.491, Test loss: 0.612, Test accuracy: 75.47
Round  75, Train loss: 0.635, Test loss: 0.630, Test accuracy: 74.97
Round  76, Train loss: 0.548, Test loss: 0.613, Test accuracy: 75.03
Round  77, Train loss: 0.440, Test loss: 0.618, Test accuracy: 75.77
Round  78, Train loss: 0.367, Test loss: 0.614, Test accuracy: 75.57
Round  79, Train loss: 0.481, Test loss: 0.608, Test accuracy: 75.30
Round  80, Train loss: 0.500, Test loss: 0.620, Test accuracy: 75.87
Round  81, Train loss: 0.464, Test loss: 0.617, Test accuracy: 76.57
Round  82, Train loss: 0.596, Test loss: 0.629, Test accuracy: 75.60
Round  83, Train loss: 0.594, Test loss: 0.632, Test accuracy: 74.37
Round  84, Train loss: 0.590, Test loss: 0.636, Test accuracy: 74.57
Round  85, Train loss: 0.556, Test loss: 0.662, Test accuracy: 73.33
Round  86, Train loss: 0.561, Test loss: 0.653, Test accuracy: 73.43
Round  87, Train loss: 0.496, Test loss: 0.635, Test accuracy: 74.40
Round  88, Train loss: 0.380, Test loss: 0.617, Test accuracy: 75.17
Round  89, Train loss: 0.563, Test loss: 0.635, Test accuracy: 74.80
Round  90, Train loss: 0.632, Test loss: 0.674, Test accuracy: 72.57
Round  91, Train loss: 0.463, Test loss: 0.640, Test accuracy: 73.73
Round  92, Train loss: 0.650, Test loss: 0.661, Test accuracy: 73.00
Round  93, Train loss: 0.601, Test loss: 0.671, Test accuracy: 72.93
Round  94, Train loss: 0.384, Test loss: 0.652, Test accuracy: 72.73
Round  95, Train loss: 0.421, Test loss: 0.640, Test accuracy: 74.23
Round  96, Train loss: 0.613, Test loss: 0.649, Test accuracy: 73.93
Round  97, Train loss: 0.574, Test loss: 0.668, Test accuracy: 73.23
Round  98, Train loss: 0.465, Test loss: 0.662, Test accuracy: 73.83
Round  99, Train loss: 0.512, Test loss: 0.660, Test accuracy: 73.20
Final Round, Train loss: 0.389, Test loss: 0.667, Test accuracy: 73.57
Average accuracy final 10 rounds: 73.34
323.4959170818329
[1.1604132652282715, 1.9559893608093262, 2.7550010681152344, 3.5520477294921875, 4.349609851837158, 5.143442869186401, 5.943025350570679, 6.735459566116333, 7.5175580978393555, 8.307513952255249, 9.09469723701477, 9.886693239212036, 10.687730550765991, 11.478873014450073, 12.269671201705933, 13.055948495864868, 13.850926876068115, 14.646660804748535, 15.439284801483154, 16.237087965011597, 17.02989101409912, 17.82298707962036, 18.619885444641113, 19.4062397480011, 20.19691514968872, 20.99494194984436, 21.79532814025879, 22.597958087921143, 23.395198106765747, 24.193061351776123, 24.994165420532227, 25.79524326324463, 26.60153341293335, 27.39609408378601, 28.190863847732544, 28.991244077682495, 29.789812088012695, 30.585670232772827, 31.38158416748047, 32.18415951728821, 32.97916221618652, 33.77464938163757, 34.57387900352478, 35.37639760971069, 36.17594313621521, 36.97597122192383, 37.77240824699402, 38.57293176651001, 39.36989450454712, 40.17070198059082, 40.96989870071411, 41.767077922821045, 42.55710411071777, 43.34880518913269, 44.14483118057251, 44.94313645362854, 45.74368643760681, 46.540119886398315, 47.33407497406006, 48.13685488700867, 48.93223786354065, 49.73092746734619, 50.53162741661072, 51.327688694000244, 52.125338077545166, 52.922945737838745, 53.715715169906616, 54.51075315475464, 55.30838584899902, 56.10732364654541, 56.91192936897278, 57.71134924888611, 58.51226234436035, 59.31003284454346, 60.11248230934143, 60.920291900634766, 61.722222089767456, 62.522457122802734, 63.334688663482666, 64.13477826118469, 64.94236469268799, 65.75512456893921, 66.56369543075562, 67.36730480194092, 68.15067172050476, 68.94990134239197, 69.75624132156372, 70.55693697929382, 71.37114548683167, 72.1752119064331, 72.98411250114441, 73.79938983917236, 74.60768747329712, 75.41128253936768, 76.19851756095886, 76.98629570007324, 77.79288125038147, 78.5961446762085, 79.39620757102966, 80.21090722084045, 81.48609018325806]
[19.366666666666667, 30.5, 36.4, 44.86666666666667, 53.36666666666667, 56.46666666666667, 57.233333333333334, 59.63333333333333, 62.333333333333336, 63.0, 64.36666666666666, 65.66666666666667, 66.1, 68.03333333333333, 68.4, 66.46666666666667, 67.66666666666667, 68.13333333333334, 68.0, 67.1, 68.9, 66.56666666666666, 64.8, 67.16666666666667, 69.1, 70.5, 71.76666666666667, 72.53333333333333, 72.33333333333333, 71.33333333333333, 71.03333333333333, 72.33333333333333, 73.03333333333333, 73.16666666666667, 72.43333333333334, 70.9, 73.36666666666666, 72.96666666666667, 74.33333333333333, 72.76666666666667, 71.5, 72.46666666666667, 72.9, 73.2, 74.73333333333333, 73.53333333333333, 73.16666666666667, 73.8, 74.23333333333333, 75.26666666666667, 75.46666666666667, 73.96666666666667, 75.3, 72.96666666666667, 74.33333333333333, 75.26666666666667, 76.46666666666667, 75.36666666666666, 75.1, 74.8, 74.63333333333334, 74.83333333333333, 75.36666666666666, 74.4, 75.43333333333334, 75.03333333333333, 75.53333333333333, 75.43333333333334, 75.66666666666667, 76.56666666666666, 76.43333333333334, 75.03333333333333, 74.9, 75.36666666666666, 75.46666666666667, 74.96666666666667, 75.03333333333333, 75.76666666666667, 75.56666666666666, 75.3, 75.86666666666666, 76.56666666666666, 75.6, 74.36666666666666, 74.56666666666666, 73.33333333333333, 73.43333333333334, 74.4, 75.16666666666667, 74.8, 72.56666666666666, 73.73333333333333, 73.0, 72.93333333333334, 72.73333333333333, 74.23333333333333, 73.93333333333334, 73.23333333333333, 73.83333333333333, 73.2, 73.56666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.375, Test loss: 1.378, Test accuracy: 35.80
Round   1, Train loss: 1.013, Test loss: 0.981, Test accuracy: 54.60
Round   2, Train loss: 0.935, Test loss: 0.944, Test accuracy: 55.30
Round   3, Train loss: 0.889, Test loss: 0.867, Test accuracy: 60.53
Round   4, Train loss: 0.849, Test loss: 0.840, Test accuracy: 62.30
Round   5, Train loss: 0.816, Test loss: 0.781, Test accuracy: 65.23
Round   6, Train loss: 0.792, Test loss: 0.769, Test accuracy: 67.17
Round   7, Train loss: 0.770, Test loss: 0.727, Test accuracy: 69.27
Round   8, Train loss: 0.751, Test loss: 0.716, Test accuracy: 69.83
Round   9, Train loss: 0.737, Test loss: 0.706, Test accuracy: 70.37
Round  10, Train loss: 0.724, Test loss: 0.713, Test accuracy: 69.57
Round  11, Train loss: 0.706, Test loss: 0.698, Test accuracy: 70.60
Round  12, Train loss: 0.693, Test loss: 0.692, Test accuracy: 70.33
Round  13, Train loss: 0.682, Test loss: 0.701, Test accuracy: 69.10
Round  14, Train loss: 0.662, Test loss: 0.658, Test accuracy: 73.63
Round  15, Train loss: 0.654, Test loss: 0.658, Test accuracy: 72.73
Round  16, Train loss: 0.642, Test loss: 0.677, Test accuracy: 71.87
Round  17, Train loss: 0.630, Test loss: 0.648, Test accuracy: 73.63
Round  18, Train loss: 0.615, Test loss: 0.659, Test accuracy: 73.63
Round  19, Train loss: 0.600, Test loss: 0.615, Test accuracy: 74.87
Round  20, Train loss: 0.594, Test loss: 0.643, Test accuracy: 74.03
Round  21, Train loss: 0.638, Test loss: 0.649, Test accuracy: 73.40
Round  22, Train loss: 0.635, Test loss: 0.641, Test accuracy: 74.07
Round  23, Train loss: 0.656, Test loss: 0.705, Test accuracy: 70.87
Round  24, Train loss: 0.512, Test loss: 0.658, Test accuracy: 73.47
Round  25, Train loss: 0.604, Test loss: 0.665, Test accuracy: 72.90
Round  26, Train loss: 0.650, Test loss: 0.659, Test accuracy: 73.77
Round  27, Train loss: 0.347, Test loss: 0.653, Test accuracy: 73.80
Round  28, Train loss: 0.528, Test loss: 0.676, Test accuracy: 72.63
Round  29, Train loss: 0.466, Test loss: 0.672, Test accuracy: 73.73
Round  30, Train loss: 0.501, Test loss: 0.701, Test accuracy: 72.53
Round  31, Train loss: 0.346, Test loss: 0.682, Test accuracy: 74.23
Round  32, Train loss: 0.465, Test loss: 0.682, Test accuracy: 72.90
Round  33, Train loss: 0.367, Test loss: 0.681, Test accuracy: 73.83
Round  34, Train loss: 0.549, Test loss: 0.699, Test accuracy: 72.27
Round  35, Train loss: 0.367, Test loss: 0.729, Test accuracy: 71.43
Round  36, Train loss: 0.348, Test loss: 0.690, Test accuracy: 73.50
Round  37, Train loss: 0.600, Test loss: 0.705, Test accuracy: 72.37
Round  38, Train loss: 0.603, Test loss: 0.685, Test accuracy: 73.37
Round  39, Train loss: 0.537, Test loss: 0.720, Test accuracy: 72.27
Round  40, Train loss: 0.395, Test loss: 0.727, Test accuracy: 71.93
Round  41, Train loss: 0.541, Test loss: 0.719, Test accuracy: 72.83
Round  42, Train loss: 0.436, Test loss: 0.734, Test accuracy: 71.47
Round  43, Train loss: 0.348, Test loss: 0.688, Test accuracy: 72.97
Round  44, Train loss: 0.508, Test loss: 0.693, Test accuracy: 73.20
Round  45, Train loss: 0.421, Test loss: 0.755, Test accuracy: 71.93
Round  46, Train loss: 0.288, Test loss: 0.764, Test accuracy: 71.40
Round  47, Train loss: 0.419, Test loss: 0.754, Test accuracy: 72.20
Round  48, Train loss: 0.277, Test loss: 0.774, Test accuracy: 71.93
Round  49, Train loss: 0.299, Test loss: 0.751, Test accuracy: 72.67
Round  50, Train loss: 0.315, Test loss: 0.724, Test accuracy: 73.73
Round  51, Train loss: 0.327, Test loss: 0.789, Test accuracy: 71.83
Round  52, Train loss: 0.356, Test loss: 0.753, Test accuracy: 72.17
Round  53, Train loss: 0.307, Test loss: 0.726, Test accuracy: 72.57
Round  54, Train loss: 0.328, Test loss: 0.764, Test accuracy: 72.57
Round  55, Train loss: 0.402, Test loss: 0.799, Test accuracy: 70.97
Round  56, Train loss: 0.311, Test loss: 0.759, Test accuracy: 72.33
Round  57, Train loss: 0.227, Test loss: 0.739, Test accuracy: 73.30
Round  58, Train loss: 0.321, Test loss: 0.731, Test accuracy: 73.97
Round  59, Train loss: 0.273, Test loss: 0.727, Test accuracy: 73.07
Round  60, Train loss: 0.286, Test loss: 0.772, Test accuracy: 72.37
Round  61, Train loss: 0.185, Test loss: 0.744, Test accuracy: 73.90
Round  62, Train loss: 0.131, Test loss: 0.767, Test accuracy: 73.70
Round  63, Train loss: 0.251, Test loss: 0.745, Test accuracy: 73.77
Round  64, Train loss: 0.357, Test loss: 0.791, Test accuracy: 71.93
Round  65, Train loss: 0.251, Test loss: 0.788, Test accuracy: 72.03
Round  66, Train loss: 0.140, Test loss: 0.797, Test accuracy: 72.43
Round  67, Train loss: 0.113, Test loss: 0.789, Test accuracy: 73.73
Round  68, Train loss: 0.177, Test loss: 0.776, Test accuracy: 73.00
Round  69, Train loss: 0.199, Test loss: 0.789, Test accuracy: 73.63
Round  70, Train loss: 0.304, Test loss: 0.803, Test accuracy: 73.13
Round  71, Train loss: 0.134, Test loss: 0.782, Test accuracy: 73.97
Round  72, Train loss: 0.300, Test loss: 0.844, Test accuracy: 71.33
Round  73, Train loss: 0.255, Test loss: 0.891, Test accuracy: 70.00
Round  74, Train loss: 0.268, Test loss: 0.863, Test accuracy: 70.83
Round  75, Train loss: 0.193, Test loss: 0.845, Test accuracy: 71.33
Round  76, Train loss: 0.181, Test loss: 0.865, Test accuracy: 71.70
Round  77, Train loss: 0.208, Test loss: 0.847, Test accuracy: 72.13
Round  78, Train loss: 0.247, Test loss: 0.869, Test accuracy: 70.70
Round  79, Train loss: 0.179, Test loss: 0.867, Test accuracy: 70.93
Round  80, Train loss: 0.200, Test loss: 0.811, Test accuracy: 72.53
Round  81, Train loss: 0.180, Test loss: 0.850, Test accuracy: 71.93
Round  82, Train loss: 0.165, Test loss: 0.852, Test accuracy: 71.50
Round  83, Train loss: 0.167, Test loss: 0.840, Test accuracy: 72.13
Round  84, Train loss: 0.164, Test loss: 0.859, Test accuracy: 71.73
Round  85, Train loss: 0.155, Test loss: 0.846, Test accuracy: 72.40
Round  86, Train loss: 0.155, Test loss: 0.864, Test accuracy: 72.97
Round  87, Train loss: 0.150, Test loss: 0.850, Test accuracy: 72.27
Round  88, Train loss: 0.150, Test loss: 0.880, Test accuracy: 71.87
Round  89, Train loss: 0.135, Test loss: 0.884, Test accuracy: 72.10
Round  90, Train loss: 0.132, Test loss: 0.901, Test accuracy: 72.20
Round  91, Train loss: 0.128, Test loss: 0.883, Test accuracy: 72.13
Round  92, Train loss: 0.137, Test loss: 0.896, Test accuracy: 72.10
Round  93, Train loss: 0.121, Test loss: 0.889, Test accuracy: 72.60
Round  94, Train loss: 0.122, Test loss: 0.902, Test accuracy: 72.70
Round  95, Train loss: 0.123, Test loss: 0.924, Test accuracy: 71.97
Round  96, Train loss: 0.123, Test loss: 0.913, Test accuracy: 71.70
Round  97, Train loss: 0.119, Test loss: 0.887, Test accuracy: 72.10
Round  98, Train loss: 0.124, Test loss: 0.891, Test accuracy: 72.13
Round  99, Train loss: 0.117, Test loss: 0.894, Test accuracy: 72.03
Final Round, Train loss: 0.095, Test loss: 0.920, Test accuracy: 72.13
Average accuracy final 10 rounds: 72.16666666666667
1021.372270822525
[1.9390408992767334, 3.5326836109161377, 5.13666844367981, 6.74205470085144, 8.35985541343689, 9.972596406936646, 11.58345341682434, 13.170379638671875, 14.757739782333374, 16.34682059288025, 17.962934732437134, 19.578141927719116, 21.19535994529724, 22.8059504032135, 24.416930675506592, 26.02678108215332, 27.65545344352722, 29.274307012557983, 30.889731645584106, 32.512263774871826, 34.13230776786804, 35.74727153778076, 37.35561180114746, 38.96976828575134, 40.57961654663086, 42.19497752189636, 43.812499046325684, 45.42153859138489, 47.047358989715576, 48.6588180065155, 50.27333092689514, 51.89338684082031, 53.504833459854126, 55.12181067466736, 56.73309874534607, 58.34377455711365, 59.948158264160156, 61.56691646575928, 63.175076961517334, 64.77702641487122, 66.37891054153442, 67.98377895355225, 69.55783295631409, 71.13913607597351, 72.73271322250366, 74.30755376815796, 75.89527082443237, 77.49335646629333, 79.10125803947449, 80.71538758277893, 82.31095385551453, 83.89696478843689, 85.48882293701172, 87.06425881385803, 88.64961957931519, 90.23188805580139, 91.8112964630127, 93.39056396484375, 94.97192573547363, 96.54033136367798, 98.10437345504761, 99.6813976764679, 101.25739121437073, 102.84376263618469, 104.42163062095642, 105.98192048072815, 107.57285785675049, 109.15145349502563, 110.7451856136322, 112.32154321670532, 113.89681696891785, 115.45764422416687, 117.03374361991882, 118.60442876815796, 120.18293833732605, 121.7579391002655, 123.33509182929993, 124.91009545326233, 126.50602436065674, 128.10928773880005, 129.7230100631714, 131.33506178855896, 132.95117211341858, 134.56654047966003, 136.17084908485413, 137.78013110160828, 139.394268989563, 141.0127055644989, 142.62720918655396, 144.24184155464172, 145.853173494339, 147.46513605117798, 149.07796049118042, 150.70008373260498, 152.32203245162964, 153.93338227272034, 155.55129289627075, 157.14817309379578, 158.7353208065033, 160.3169023990631, 162.73901963233948]
[35.8, 54.6, 55.3, 60.53333333333333, 62.3, 65.23333333333333, 67.16666666666667, 69.26666666666667, 69.83333333333333, 70.36666666666666, 69.56666666666666, 70.6, 70.33333333333333, 69.1, 73.63333333333334, 72.73333333333333, 71.86666666666666, 73.63333333333334, 73.63333333333334, 74.86666666666666, 74.03333333333333, 73.4, 74.06666666666666, 70.86666666666666, 73.46666666666667, 72.9, 73.76666666666667, 73.8, 72.63333333333334, 73.73333333333333, 72.53333333333333, 74.23333333333333, 72.9, 73.83333333333333, 72.26666666666667, 71.43333333333334, 73.5, 72.36666666666666, 73.36666666666666, 72.26666666666667, 71.93333333333334, 72.83333333333333, 71.46666666666667, 72.96666666666667, 73.2, 71.93333333333334, 71.4, 72.2, 71.93333333333334, 72.66666666666667, 73.73333333333333, 71.83333333333333, 72.16666666666667, 72.56666666666666, 72.56666666666666, 70.96666666666667, 72.33333333333333, 73.3, 73.96666666666667, 73.06666666666666, 72.36666666666666, 73.9, 73.7, 73.76666666666667, 71.93333333333334, 72.03333333333333, 72.43333333333334, 73.73333333333333, 73.0, 73.63333333333334, 73.13333333333334, 73.96666666666667, 71.33333333333333, 70.0, 70.83333333333333, 71.33333333333333, 71.7, 72.13333333333334, 70.7, 70.93333333333334, 72.53333333333333, 71.93333333333334, 71.5, 72.13333333333334, 71.73333333333333, 72.4, 72.96666666666667, 72.26666666666667, 71.86666666666666, 72.1, 72.2, 72.13333333333334, 72.1, 72.6, 72.7, 71.96666666666667, 71.7, 72.1, 72.13333333333334, 72.03333333333333, 72.13333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.394, Test loss: 1.396, Test accuracy: 43.20
Round   1, Train loss: 1.016, Test loss: 0.977, Test accuracy: 54.63
Round   2, Train loss: 0.933, Test loss: 0.912, Test accuracy: 57.47
Round   3, Train loss: 0.888, Test loss: 0.857, Test accuracy: 64.20
Round   4, Train loss: 0.853, Test loss: 0.792, Test accuracy: 66.33
Round   5, Train loss: 0.825, Test loss: 0.796, Test accuracy: 65.53
Round   6, Train loss: 0.805, Test loss: 0.726, Test accuracy: 71.13
Round   7, Train loss: 0.781, Test loss: 0.729, Test accuracy: 70.07
Round   8, Train loss: 0.769, Test loss: 0.709, Test accuracy: 72.67
Round   9, Train loss: 0.752, Test loss: 0.697, Test accuracy: 73.30
Round  10, Train loss: 0.739, Test loss: 0.695, Test accuracy: 72.47
Round  11, Train loss: 0.721, Test loss: 0.677, Test accuracy: 73.47
Round  12, Train loss: 0.709, Test loss: 0.695, Test accuracy: 72.23
Round  13, Train loss: 0.695, Test loss: 0.683, Test accuracy: 72.33
Round  14, Train loss: 0.677, Test loss: 0.653, Test accuracy: 75.07
Round  15, Train loss: 0.661, Test loss: 0.652, Test accuracy: 73.67
Round  16, Train loss: 0.647, Test loss: 0.652, Test accuracy: 74.80
Round  17, Train loss: 0.635, Test loss: 0.638, Test accuracy: 75.27
Round  18, Train loss: 0.621, Test loss: 0.648, Test accuracy: 73.10
Round  19, Train loss: 0.608, Test loss: 0.630, Test accuracy: 74.70
Round  20, Train loss: 0.466, Test loss: 0.642, Test accuracy: 74.27
Round  21, Train loss: 0.541, Test loss: 0.653, Test accuracy: 72.33
Round  22, Train loss: 0.672, Test loss: 0.672, Test accuracy: 72.13
Round  23, Train loss: 0.518, Test loss: 0.664, Test accuracy: 73.10
Round  24, Train loss: 0.620, Test loss: 0.654, Test accuracy: 72.33
Round  25, Train loss: 0.594, Test loss: 0.666, Test accuracy: 72.93
Round  26, Train loss: 0.526, Test loss: 0.645, Test accuracy: 73.00
Round  27, Train loss: 0.566, Test loss: 0.643, Test accuracy: 73.23
Round  28, Train loss: 0.524, Test loss: 0.647, Test accuracy: 74.47
Round  29, Train loss: 0.463, Test loss: 0.631, Test accuracy: 74.27
Round  30, Train loss: 0.610, Test loss: 0.673, Test accuracy: 72.57
Round  31, Train loss: 0.428, Test loss: 0.673, Test accuracy: 72.23
Round  32, Train loss: 0.541, Test loss: 0.695, Test accuracy: 71.43
Round  33, Train loss: 0.450, Test loss: 0.704, Test accuracy: 71.57
Round  34, Train loss: 0.400, Test loss: 0.688, Test accuracy: 72.33
Round  35, Train loss: 0.357, Test loss: 0.683, Test accuracy: 72.70
Round  36, Train loss: 0.442, Test loss: 0.699, Test accuracy: 71.97
Round  37, Train loss: 0.388, Test loss: 0.651, Test accuracy: 74.13
Round  38, Train loss: 0.392, Test loss: 0.629, Test accuracy: 74.60
Round  39, Train loss: 0.308, Test loss: 0.648, Test accuracy: 74.13
Round  40, Train loss: 0.288, Test loss: 0.663, Test accuracy: 74.40
Round  41, Train loss: 0.515, Test loss: 0.667, Test accuracy: 72.97
Round  42, Train loss: 0.337, Test loss: 0.681, Test accuracy: 72.83
Round  43, Train loss: 0.565, Test loss: 0.713, Test accuracy: 72.33
Round  44, Train loss: 0.420, Test loss: 0.686, Test accuracy: 72.87
Round  45, Train loss: 0.331, Test loss: 0.675, Test accuracy: 73.40
Round  46, Train loss: 0.375, Test loss: 0.691, Test accuracy: 72.97
Round  47, Train loss: 0.309, Test loss: 0.705, Test accuracy: 72.97
Round  48, Train loss: 0.351, Test loss: 0.730, Test accuracy: 71.93
Round  49, Train loss: 0.360, Test loss: 0.725, Test accuracy: 73.07
Round  50, Train loss: 0.311, Test loss: 0.714, Test accuracy: 72.97
Round  51, Train loss: 0.312, Test loss: 0.758, Test accuracy: 72.03
Round  52, Train loss: 0.324, Test loss: 0.750, Test accuracy: 72.13
Round  53, Train loss: 0.309, Test loss: 0.744, Test accuracy: 71.57
Round  54, Train loss: 0.219, Test loss: 0.720, Test accuracy: 73.30
Round  55, Train loss: 0.299, Test loss: 0.766, Test accuracy: 70.73
Round  56, Train loss: 0.208, Test loss: 0.725, Test accuracy: 73.43
Round  57, Train loss: 0.292, Test loss: 0.726, Test accuracy: 73.80
Round  58, Train loss: 0.305, Test loss: 0.730, Test accuracy: 73.47
Round  59, Train loss: 0.259, Test loss: 0.739, Test accuracy: 72.83
Round  60, Train loss: 0.254, Test loss: 0.734, Test accuracy: 73.23
Round  61, Train loss: 0.158, Test loss: 0.748, Test accuracy: 73.90
Round  62, Train loss: 0.196, Test loss: 0.811, Test accuracy: 72.27
Round  63, Train loss: 0.180, Test loss: 0.772, Test accuracy: 72.83
Round  64, Train loss: 0.289, Test loss: 0.755, Test accuracy: 73.17
Round  65, Train loss: 0.299, Test loss: 0.756, Test accuracy: 72.90
Round  66, Train loss: 0.245, Test loss: 0.815, Test accuracy: 70.83
Round  67, Train loss: 0.228, Test loss: 0.774, Test accuracy: 71.97
Round  68, Train loss: 0.222, Test loss: 0.855, Test accuracy: 70.93
Round  69, Train loss: 0.213, Test loss: 0.795, Test accuracy: 72.20
Round  70, Train loss: 0.280, Test loss: 0.832, Test accuracy: 71.57
Round  71, Train loss: 0.209, Test loss: 0.806, Test accuracy: 71.97
Round  72, Train loss: 0.236, Test loss: 0.835, Test accuracy: 71.73
Round  73, Train loss: 0.200, Test loss: 0.843, Test accuracy: 70.97
Round  74, Train loss: 0.198, Test loss: 0.858, Test accuracy: 70.87
Round  75, Train loss: 0.195, Test loss: 0.816, Test accuracy: 72.57
Round  76, Train loss: 0.244, Test loss: 0.812, Test accuracy: 72.10
Round  77, Train loss: 0.164, Test loss: 0.791, Test accuracy: 73.00
Round  78, Train loss: 0.179, Test loss: 0.805, Test accuracy: 72.10
Round  79, Train loss: 0.142, Test loss: 0.807, Test accuracy: 72.17
Round  80, Train loss: 0.177, Test loss: 0.793, Test accuracy: 72.53
Round  81, Train loss: 0.153, Test loss: 0.800, Test accuracy: 72.10
Round  82, Train loss: 0.146, Test loss: 0.791, Test accuracy: 73.23
Round  83, Train loss: 0.148, Test loss: 0.804, Test accuracy: 72.40
Round  84, Train loss: 0.138, Test loss: 0.794, Test accuracy: 73.33
Round  85, Train loss: 0.135, Test loss: 0.798, Test accuracy: 73.17
Round  86, Train loss: 0.133, Test loss: 0.815, Test accuracy: 73.17
Round  87, Train loss: 0.132, Test loss: 0.811, Test accuracy: 72.30
Round  88, Train loss: 0.129, Test loss: 0.806, Test accuracy: 72.73
Round  89, Train loss: 0.132, Test loss: 0.807, Test accuracy: 73.07
Round  90, Train loss: 0.111, Test loss: 0.821, Test accuracy: 72.77
Round  91, Train loss: 0.121, Test loss: 0.818, Test accuracy: 72.47
Round  92, Train loss: 0.120, Test loss: 0.838, Test accuracy: 72.07
Round  93, Train loss: 0.109, Test loss: 0.853, Test accuracy: 72.27
Round  94, Train loss: 0.107, Test loss: 0.852, Test accuracy: 71.87
Round  95, Train loss: 0.102, Test loss: 0.851, Test accuracy: 71.87
Round  96, Train loss: 0.113, Test loss: 0.846, Test accuracy: 72.50
Round  97, Train loss: 0.095, Test loss: 0.840, Test accuracy: 72.47
Round  98, Train loss: 0.098, Test loss: 0.860, Test accuracy: 71.93
Round  99, Train loss: 0.087, Test loss: 0.865, Test accuracy: 72.40
Final Round, Train loss: 0.081, Test loss: 0.882, Test accuracy: 72.17
Average accuracy final 10 rounds: 72.25999999999999
1486.3433501720428
[1.9262480735778809, 3.5041191577911377, 5.075030326843262, 6.597467422485352, 8.105612516403198, 9.624986410140991, 11.1294105052948, 12.7220618724823, 14.318153858184814, 15.91532588005066, 17.502537727355957, 19.109753847122192, 20.704155921936035, 22.31389284133911, 23.917463541030884, 25.508476734161377, 27.09788727760315, 28.689112901687622, 30.287558794021606, 31.868118047714233, 33.45569682121277, 36.35982894897461, 39.19509410858154, 42.059723138809204, 44.93312048912048, 47.79020380973816, 50.68198847770691, 53.54482913017273, 56.41447877883911, 59.27622699737549, 62.15426993370056, 65.01881814002991, 67.89846277236938, 70.751549243927, 73.6422107219696, 76.54740619659424, 79.41900515556335, 82.31652593612671, 85.14904689788818, 88.04531931877136, 90.91386771202087, 93.81321167945862, 96.69968605041504, 99.57416105270386, 102.40082049369812, 105.27808427810669, 108.12599062919617, 110.97999119758606, 113.87675619125366, 116.73182392120361, 119.62613534927368, 122.52312469482422, 125.38748049736023, 128.26211619377136, 131.12087869644165, 133.98693561553955, 136.87940669059753, 139.77628993988037, 142.64131999015808, 145.52282309532166, 148.355215549469, 151.21631383895874, 154.089777469635, 156.95153832435608, 159.83957982063293, 162.71793174743652, 165.5743808746338, 168.45605611801147, 171.3243384361267, 174.1924765110016, 177.06791758537292, 179.96412181854248, 182.89465379714966, 185.79987025260925, 188.67973613739014, 191.60587239265442, 194.50982189178467, 197.43009686470032, 200.44269824028015, 203.43442821502686, 206.4419023990631, 209.487407207489, 212.5065836906433, 215.5357894897461, 218.58324790000916, 221.60535430908203, 224.56576871871948, 227.40204787254333, 230.27924990653992, 233.12330389022827, 235.99046349525452, 238.8518533706665, 241.68965649604797, 244.55776047706604, 247.43646240234375, 250.29060220718384, 253.11928796768188, 255.97901344299316, 258.83140873908997, 261.70870423316956, 264.04567790031433]
[43.2, 54.63333333333333, 57.46666666666667, 64.2, 66.33333333333333, 65.53333333333333, 71.13333333333334, 70.06666666666666, 72.66666666666667, 73.3, 72.46666666666667, 73.46666666666667, 72.23333333333333, 72.33333333333333, 75.06666666666666, 73.66666666666667, 74.8, 75.26666666666667, 73.1, 74.7, 74.26666666666667, 72.33333333333333, 72.13333333333334, 73.1, 72.33333333333333, 72.93333333333334, 73.0, 73.23333333333333, 74.46666666666667, 74.26666666666667, 72.56666666666666, 72.23333333333333, 71.43333333333334, 71.56666666666666, 72.33333333333333, 72.7, 71.96666666666667, 74.13333333333334, 74.6, 74.13333333333334, 74.4, 72.96666666666667, 72.83333333333333, 72.33333333333333, 72.86666666666666, 73.4, 72.96666666666667, 72.96666666666667, 71.93333333333334, 73.06666666666666, 72.96666666666667, 72.03333333333333, 72.13333333333334, 71.56666666666666, 73.3, 70.73333333333333, 73.43333333333334, 73.8, 73.46666666666667, 72.83333333333333, 73.23333333333333, 73.9, 72.26666666666667, 72.83333333333333, 73.16666666666667, 72.9, 70.83333333333333, 71.96666666666667, 70.93333333333334, 72.2, 71.56666666666666, 71.96666666666667, 71.73333333333333, 70.96666666666667, 70.86666666666666, 72.56666666666666, 72.1, 73.0, 72.1, 72.16666666666667, 72.53333333333333, 72.1, 73.23333333333333, 72.4, 73.33333333333333, 73.16666666666667, 73.16666666666667, 72.3, 72.73333333333333, 73.06666666666666, 72.76666666666667, 72.46666666666667, 72.06666666666666, 72.26666666666667, 71.86666666666666, 71.86666666666666, 72.5, 72.46666666666667, 71.93333333333334, 72.4, 72.16666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.385, Test loss: 1.432, Test accuracy: 40.07
Round   1, Train loss: 1.002, Test loss: 0.980, Test accuracy: 52.23
Round   2, Train loss: 0.913, Test loss: 0.890, Test accuracy: 58.83
Round   3, Train loss: 0.865, Test loss: 0.844, Test accuracy: 62.63
Round   4, Train loss: 0.830, Test loss: 0.817, Test accuracy: 61.77
Round   5, Train loss: 0.808, Test loss: 0.801, Test accuracy: 66.13
Round   6, Train loss: 0.784, Test loss: 0.757, Test accuracy: 67.10
Round   7, Train loss: 0.764, Test loss: 0.737, Test accuracy: 69.30
Round   8, Train loss: 0.751, Test loss: 0.726, Test accuracy: 70.13
Round   9, Train loss: 0.732, Test loss: 0.726, Test accuracy: 68.87
Round  10, Train loss: 0.716, Test loss: 0.714, Test accuracy: 71.33
Round  11, Train loss: 0.704, Test loss: 0.669, Test accuracy: 73.97
Round  12, Train loss: 0.687, Test loss: 0.682, Test accuracy: 71.80
Round  13, Train loss: 0.675, Test loss: 0.667, Test accuracy: 73.27
Round  14, Train loss: 0.663, Test loss: 0.656, Test accuracy: 72.80
Round  15, Train loss: 0.652, Test loss: 0.677, Test accuracy: 73.03
Round  16, Train loss: 0.634, Test loss: 0.638, Test accuracy: 73.73
Round  17, Train loss: 0.621, Test loss: 0.658, Test accuracy: 72.37
Round  18, Train loss: 0.610, Test loss: 0.633, Test accuracy: 74.13
Round  19, Train loss: 0.597, Test loss: 0.647, Test accuracy: 74.20
Round  20, Train loss: 0.615, Test loss: 0.647, Test accuracy: 73.33
Round  21, Train loss: 0.539, Test loss: 0.674, Test accuracy: 72.93
Round  22, Train loss: 0.395, Test loss: 0.634, Test accuracy: 75.17
Round  23, Train loss: 0.771, Test loss: 0.666, Test accuracy: 73.17
Round  24, Train loss: 0.605, Test loss: 0.635, Test accuracy: 73.57
Round  25, Train loss: 0.616, Test loss: 0.650, Test accuracy: 72.97
Round  26, Train loss: 0.740, Test loss: 0.660, Test accuracy: 73.03
Round  27, Train loss: 0.477, Test loss: 0.640, Test accuracy: 74.10
Round  28, Train loss: 0.393, Test loss: 0.636, Test accuracy: 74.57
Round  29, Train loss: 0.480, Test loss: 0.660, Test accuracy: 72.90
Round  30, Train loss: 0.376, Test loss: 0.668, Test accuracy: 72.53
Round  31, Train loss: 0.463, Test loss: 0.685, Test accuracy: 71.43
Round  32, Train loss: 0.435, Test loss: 0.661, Test accuracy: 71.53
Round  33, Train loss: 0.455, Test loss: 0.702, Test accuracy: 71.40
Round  34, Train loss: 0.522, Test loss: 0.698, Test accuracy: 71.60
Round  35, Train loss: 0.328, Test loss: 0.690, Test accuracy: 72.80
Round  36, Train loss: 0.551, Test loss: 0.715, Test accuracy: 70.27
Round  37, Train loss: 0.515, Test loss: 0.726, Test accuracy: 70.60
Round  38, Train loss: 0.575, Test loss: 0.690, Test accuracy: 72.23
Round  39, Train loss: 0.439, Test loss: 0.707, Test accuracy: 71.37
Round  40, Train loss: 0.378, Test loss: 0.722, Test accuracy: 71.50
Round  41, Train loss: 0.537, Test loss: 0.701, Test accuracy: 72.07
Round  42, Train loss: 0.315, Test loss: 0.690, Test accuracy: 73.70
Round  43, Train loss: 0.253, Test loss: 0.680, Test accuracy: 73.13
Round  44, Train loss: 0.410, Test loss: 0.706, Test accuracy: 72.70
Round  45, Train loss: 0.348, Test loss: 0.729, Test accuracy: 71.23
Round  46, Train loss: 0.350, Test loss: 0.750, Test accuracy: 71.77
Round  47, Train loss: 0.346, Test loss: 0.720, Test accuracy: 73.00
Round  48, Train loss: 0.202, Test loss: 0.702, Test accuracy: 73.50
Round  49, Train loss: 0.308, Test loss: 0.693, Test accuracy: 73.30
Round  50, Train loss: 0.321, Test loss: 0.708, Test accuracy: 73.27
Round  51, Train loss: 0.319, Test loss: 0.723, Test accuracy: 72.83
Round  52, Train loss: 0.385, Test loss: 0.719, Test accuracy: 73.30
Round  53, Train loss: 0.288, Test loss: 0.715, Test accuracy: 73.00
Round  54, Train loss: 0.326, Test loss: 0.750, Test accuracy: 71.97
Round  55, Train loss: 0.389, Test loss: 0.754, Test accuracy: 71.27
Round  56, Train loss: 0.336, Test loss: 0.778, Test accuracy: 71.50
Round  57, Train loss: 0.327, Test loss: 0.750, Test accuracy: 72.53
Round  58, Train loss: 0.304, Test loss: 0.775, Test accuracy: 70.63
Round  59, Train loss: 0.247, Test loss: 0.760, Test accuracy: 72.20
Round  60, Train loss: 0.381, Test loss: 0.853, Test accuracy: 69.00
Round  61, Train loss: 0.227, Test loss: 0.852, Test accuracy: 69.40
Round  62, Train loss: 0.262, Test loss: 0.814, Test accuracy: 70.37
Round  63, Train loss: 0.181, Test loss: 0.800, Test accuracy: 70.43
Round  64, Train loss: 0.300, Test loss: 0.811, Test accuracy: 70.77
Round  65, Train loss: 0.248, Test loss: 0.782, Test accuracy: 70.73
Round  66, Train loss: 0.199, Test loss: 0.792, Test accuracy: 71.20
Round  67, Train loss: 0.169, Test loss: 0.798, Test accuracy: 71.20
Round  68, Train loss: 0.223, Test loss: 0.822, Test accuracy: 70.47
Round  69, Train loss: 0.216, Test loss: 0.819, Test accuracy: 69.73
Round  70, Train loss: 0.212, Test loss: 0.792, Test accuracy: 71.93
Round  71, Train loss: 0.229, Test loss: 0.822, Test accuracy: 71.03
Round  72, Train loss: 0.230, Test loss: 0.833, Test accuracy: 71.60
Round  73, Train loss: 0.234, Test loss: 0.824, Test accuracy: 72.23
Round  74, Train loss: 0.199, Test loss: 0.815, Test accuracy: 71.90
Round  75, Train loss: 0.182, Test loss: 0.825, Test accuracy: 71.23
Round  76, Train loss: 0.248, Test loss: 0.840, Test accuracy: 70.83
Round  77, Train loss: 0.227, Test loss: 0.873, Test accuracy: 69.70
Round  78, Train loss: 0.213, Test loss: 0.831, Test accuracy: 71.27
Round  79, Train loss: 0.235, Test loss: 0.892, Test accuracy: 70.00
Round  80, Train loss: 0.200, Test loss: 0.855, Test accuracy: 71.33
Round  81, Train loss: 0.171, Test loss: 0.847, Test accuracy: 70.60
Round  82, Train loss: 0.166, Test loss: 0.848, Test accuracy: 70.00
Round  83, Train loss: 0.165, Test loss: 0.871, Test accuracy: 70.73
Round  84, Train loss: 0.151, Test loss: 0.858, Test accuracy: 70.83
Round  85, Train loss: 0.148, Test loss: 0.852, Test accuracy: 71.10
Round  86, Train loss: 0.142, Test loss: 0.861, Test accuracy: 71.20
Round  87, Train loss: 0.144, Test loss: 0.855, Test accuracy: 72.10
Round  88, Train loss: 0.138, Test loss: 0.848, Test accuracy: 71.80
Round  89, Train loss: 0.132, Test loss: 0.872, Test accuracy: 71.03
Round  90, Train loss: 0.131, Test loss: 0.898, Test accuracy: 70.83
Round  91, Train loss: 0.128, Test loss: 0.893, Test accuracy: 71.17
Round  92, Train loss: 0.138, Test loss: 0.891, Test accuracy: 71.03
Round  93, Train loss: 0.123, Test loss: 0.897, Test accuracy: 70.97
Round  94, Train loss: 0.123, Test loss: 0.888, Test accuracy: 71.33
Round  95, Train loss: 0.112, Test loss: 0.898, Test accuracy: 71.53
Round  96, Train loss: 0.119, Test loss: 0.903, Test accuracy: 70.63
Round  97, Train loss: 0.121, Test loss: 0.895, Test accuracy: 71.37
Round  98, Train loss: 0.112, Test loss: 0.906, Test accuracy: 70.67
Round  99, Train loss: 0.105, Test loss: 0.918, Test accuracy: 70.77
Final Round, Train loss: 0.086, Test loss: 0.944, Test accuracy: 71.27
Average accuracy final 10 rounds: 71.03
1469.7452006340027
[1.901566982269287, 3.4796335697174072, 5.041537523269653, 6.605513334274292, 8.171855688095093, 9.740307331085205, 11.309345960617065, 12.89518117904663, 14.459254741668701, 16.050744771957397, 17.60489058494568, 19.1648006439209, 20.730149269104004, 22.29889440536499, 23.867969274520874, 25.43867588043213, 27.012294054031372, 28.57607626914978, 30.11257004737854, 31.65683627128601, 33.192224740982056, 35.96734547615051, 38.72368407249451, 41.4915976524353, 44.24624490737915, 47.02169704437256, 49.83629322052002, 52.6060094833374, 55.43351697921753, 58.24843502044678, 61.03118181228638, 63.84251379966736, 66.65480041503906, 69.47427701950073, 72.32561874389648, 75.15488743782043, 77.99215388298035, 80.85992550849915, 83.65189242362976, 86.4907898902893, 89.29252171516418, 92.06332993507385, 94.89462971687317, 97.72482395172119, 100.55005168914795, 103.3471782207489, 106.18775057792664, 109.02838015556335, 111.83156776428223, 114.67775058746338, 117.53592371940613, 120.35405492782593, 123.20173764228821, 126.05398511886597, 128.83603978157043, 131.6747329235077, 134.48291301727295, 137.29882669448853, 140.12788605690002, 142.9352321624756, 145.7478425502777, 148.5420684814453, 151.36501741409302, 154.22172570228577, 157.06517243385315, 159.92075085639954, 162.7831790447235, 165.6492805480957, 168.49842500686646, 171.34292602539062, 174.19120049476624, 177.02149486541748, 179.8675401210785, 182.73078680038452, 185.49995946884155, 188.33226013183594, 191.16103982925415, 194.00371742248535, 196.8027048110962, 199.6251916885376, 202.50250840187073, 205.36156487464905, 208.20754432678223, 211.09243178367615, 213.97212529182434, 216.83320236206055, 219.70252561569214, 222.5782287120819, 225.4131305217743, 228.25211548805237, 231.0911819934845, 233.95844340324402, 236.83251428604126, 239.68321061134338, 242.64891505241394, 245.61675763130188, 248.59179043769836, 251.59271883964539, 254.5805025100708, 257.5340955257416, 259.9633414745331]
[40.06666666666667, 52.233333333333334, 58.833333333333336, 62.63333333333333, 61.766666666666666, 66.13333333333334, 67.1, 69.3, 70.13333333333334, 68.86666666666666, 71.33333333333333, 73.96666666666667, 71.8, 73.26666666666667, 72.8, 73.03333333333333, 73.73333333333333, 72.36666666666666, 74.13333333333334, 74.2, 73.33333333333333, 72.93333333333334, 75.16666666666667, 73.16666666666667, 73.56666666666666, 72.96666666666667, 73.03333333333333, 74.1, 74.56666666666666, 72.9, 72.53333333333333, 71.43333333333334, 71.53333333333333, 71.4, 71.6, 72.8, 70.26666666666667, 70.6, 72.23333333333333, 71.36666666666666, 71.5, 72.06666666666666, 73.7, 73.13333333333334, 72.7, 71.23333333333333, 71.76666666666667, 73.0, 73.5, 73.3, 73.26666666666667, 72.83333333333333, 73.3, 73.0, 71.96666666666667, 71.26666666666667, 71.5, 72.53333333333333, 70.63333333333334, 72.2, 69.0, 69.4, 70.36666666666666, 70.43333333333334, 70.76666666666667, 70.73333333333333, 71.2, 71.2, 70.46666666666667, 69.73333333333333, 71.93333333333334, 71.03333333333333, 71.6, 72.23333333333333, 71.9, 71.23333333333333, 70.83333333333333, 69.7, 71.26666666666667, 70.0, 71.33333333333333, 70.6, 70.0, 70.73333333333333, 70.83333333333333, 71.1, 71.2, 72.1, 71.8, 71.03333333333333, 70.83333333333333, 71.16666666666667, 71.03333333333333, 70.96666666666667, 71.33333333333333, 71.53333333333333, 70.63333333333334, 71.36666666666666, 70.66666666666667, 70.76666666666667, 71.26666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.725, Test loss: 2.206, Test accuracy: 14.50
Round   1, Train loss: 1.216, Test loss: 2.416, Test accuracy: 19.83
Round   2, Train loss: 1.205, Test loss: 2.051, Test accuracy: 26.67
Round   3, Train loss: 1.071, Test loss: 1.544, Test accuracy: 40.67
Round   4, Train loss: 1.109, Test loss: 1.461, Test accuracy: 41.73
Round   5, Train loss: 0.980, Test loss: 1.427, Test accuracy: 44.30
Round   6, Train loss: 1.053, Test loss: 1.425, Test accuracy: 43.63
Round   7, Train loss: 0.995, Test loss: 1.460, Test accuracy: 48.40
Round   8, Train loss: 0.944, Test loss: 1.292, Test accuracy: 50.03
Round   9, Train loss: 0.773, Test loss: 1.223, Test accuracy: 53.27
Round  10, Train loss: 0.842, Test loss: 1.122, Test accuracy: 53.33
Round  11, Train loss: 1.107, Test loss: 1.056, Test accuracy: 54.37
Round  12, Train loss: 0.719, Test loss: 1.391, Test accuracy: 55.27
Round  13, Train loss: 0.953, Test loss: 0.810, Test accuracy: 64.20
Round  14, Train loss: 0.957, Test loss: 0.816, Test accuracy: 63.23
Round  15, Train loss: 0.820, Test loss: 0.786, Test accuracy: 62.67
Round  16, Train loss: 0.822, Test loss: 0.782, Test accuracy: 64.43
Round  17, Train loss: 0.924, Test loss: 0.791, Test accuracy: 64.03
Round  18, Train loss: 0.950, Test loss: 0.788, Test accuracy: 64.53
Round  19, Train loss: 0.791, Test loss: 0.770, Test accuracy: 66.13
Round  20, Train loss: 0.920, Test loss: 0.762, Test accuracy: 64.60
Round  21, Train loss: 0.788, Test loss: 0.764, Test accuracy: 66.00
Round  22, Train loss: 0.800, Test loss: 0.763, Test accuracy: 66.10
Round  23, Train loss: 0.954, Test loss: 0.761, Test accuracy: 65.23
Round  24, Train loss: 0.795, Test loss: 0.762, Test accuracy: 65.53
Round  25, Train loss: 0.962, Test loss: 0.773, Test accuracy: 64.77
Round  26, Train loss: 0.921, Test loss: 0.758, Test accuracy: 66.53
Round  27, Train loss: 0.788, Test loss: 0.761, Test accuracy: 65.87
Round  28, Train loss: 1.067, Test loss: 0.764, Test accuracy: 64.97
Round  29, Train loss: 0.770, Test loss: 0.766, Test accuracy: 65.60
Round  30, Train loss: 0.898, Test loss: 0.733, Test accuracy: 66.93
Round  31, Train loss: 0.711, Test loss: 0.723, Test accuracy: 67.17
Round  32, Train loss: 0.774, Test loss: 0.743, Test accuracy: 67.03
Round  33, Train loss: 0.725, Test loss: 0.719, Test accuracy: 68.37
Round  34, Train loss: 0.882, Test loss: 0.725, Test accuracy: 67.17
Round  35, Train loss: 0.897, Test loss: 0.739, Test accuracy: 67.17
Round  36, Train loss: 0.701, Test loss: 0.747, Test accuracy: 66.37
Round  37, Train loss: 0.866, Test loss: 0.722, Test accuracy: 68.57
Round  38, Train loss: 0.866, Test loss: 0.709, Test accuracy: 69.13
Round  39, Train loss: 0.889, Test loss: 0.733, Test accuracy: 67.63
Round  40, Train loss: 0.684, Test loss: 0.720, Test accuracy: 67.93
Round  41, Train loss: 0.719, Test loss: 0.714, Test accuracy: 68.40
Round  42, Train loss: 0.662, Test loss: 0.719, Test accuracy: 67.80
Round  43, Train loss: 0.655, Test loss: 0.713, Test accuracy: 66.83
Round  44, Train loss: 0.652, Test loss: 0.720, Test accuracy: 66.97
Round  45, Train loss: 0.532, Test loss: 0.708, Test accuracy: 68.00
Round  46, Train loss: 0.703, Test loss: 0.712, Test accuracy: 67.37
Round  47, Train loss: 0.832, Test loss: 0.711, Test accuracy: 68.07
Round  48, Train loss: 0.836, Test loss: 0.725, Test accuracy: 67.40
Round  49, Train loss: 0.686, Test loss: 0.716, Test accuracy: 68.80
Round  50, Train loss: 0.812, Test loss: 0.718, Test accuracy: 68.53
Round  51, Train loss: 0.787, Test loss: 0.729, Test accuracy: 67.50
Round  52, Train loss: 0.494, Test loss: 0.705, Test accuracy: 68.17
Round  53, Train loss: 0.851, Test loss: 0.708, Test accuracy: 67.87
Round  54, Train loss: 0.839, Test loss: 0.722, Test accuracy: 67.53
Round  55, Train loss: 0.422, Test loss: 0.719, Test accuracy: 67.97
Round  56, Train loss: 0.615, Test loss: 0.716, Test accuracy: 68.63
Round  57, Train loss: 0.597, Test loss: 0.712, Test accuracy: 68.60
Round  58, Train loss: 0.639, Test loss: 0.709, Test accuracy: 68.70
Round  59, Train loss: 0.804, Test loss: 0.712, Test accuracy: 69.23
Round  60, Train loss: 0.582, Test loss: 0.719, Test accuracy: 68.50
Round  61, Train loss: 0.662, Test loss: 0.714, Test accuracy: 67.70
Round  62, Train loss: 0.569, Test loss: 0.688, Test accuracy: 69.07
Round  63, Train loss: 0.589, Test loss: 0.705, Test accuracy: 69.00
Round  64, Train loss: 0.568, Test loss: 0.691, Test accuracy: 69.43
Round  65, Train loss: 0.642, Test loss: 0.687, Test accuracy: 69.00
Round  66, Train loss: 0.776, Test loss: 0.699, Test accuracy: 68.57
Round  67, Train loss: 0.803, Test loss: 0.702, Test accuracy: 69.23
Round  68, Train loss: 0.572, Test loss: 0.704, Test accuracy: 68.00
Round  69, Train loss: 0.770, Test loss: 0.705, Test accuracy: 68.10
Round  70, Train loss: 0.753, Test loss: 0.695, Test accuracy: 68.53
Round  71, Train loss: 0.536, Test loss: 0.708, Test accuracy: 67.87
Round  72, Train loss: 0.415, Test loss: 0.691, Test accuracy: 68.50
Round  73, Train loss: 0.344, Test loss: 0.696, Test accuracy: 68.37
Round  74, Train loss: 0.751, Test loss: 0.701, Test accuracy: 69.00
Round  75, Train loss: 0.539, Test loss: 0.697, Test accuracy: 68.77
Round  76, Train loss: 0.329, Test loss: 0.711, Test accuracy: 68.30
Round  77, Train loss: 0.781, Test loss: 0.713, Test accuracy: 68.43
Round  78, Train loss: 0.732, Test loss: 0.705, Test accuracy: 68.60
Round  79, Train loss: 0.492, Test loss: 0.716, Test accuracy: 68.93
Round  80, Train loss: 0.336, Test loss: 0.701, Test accuracy: 69.30
Round  81, Train loss: 0.519, Test loss: 0.700, Test accuracy: 69.53
Round  82, Train loss: 0.492, Test loss: 0.704, Test accuracy: 68.70
Round  83, Train loss: 0.272, Test loss: 0.707, Test accuracy: 69.67
Round  84, Train loss: 0.507, Test loss: 0.710, Test accuracy: 68.87
Round  85, Train loss: 0.502, Test loss: 0.703, Test accuracy: 68.63
Round  86, Train loss: 0.472, Test loss: 0.710, Test accuracy: 68.77
Round  87, Train loss: 0.511, Test loss: 0.721, Test accuracy: 68.47
Round  88, Train loss: 0.708, Test loss: 0.724, Test accuracy: 68.77
Round  89, Train loss: 0.653, Test loss: 0.727, Test accuracy: 68.60
Round  90, Train loss: 0.495, Test loss: 0.716, Test accuracy: 69.27
Round  91, Train loss: 0.504, Test loss: 0.724, Test accuracy: 68.37
Round  92, Train loss: 0.470, Test loss: 0.722, Test accuracy: 68.30
Round  93, Train loss: 0.669, Test loss: 0.738, Test accuracy: 67.37
Round  94, Train loss: 0.839, Test loss: 0.749, Test accuracy: 67.23
Round  95, Train loss: 0.442, Test loss: 0.760, Test accuracy: 67.50
Round  96, Train loss: 0.236, Test loss: 0.772, Test accuracy: 67.03
Round  97, Train loss: 0.223, Test loss: 0.743, Test accuracy: 67.97
Round  98, Train loss: 0.494, Test loss: 0.716, Test accuracy: 68.07
Round  99, Train loss: 0.522, Test loss: 0.745, Test accuracy: 67.23
Final Round, Train loss: 0.460, Test loss: 0.752, Test accuracy: 67.33
Average accuracy final 10 rounds: 67.83333333333333
320.3653793334961
[1.138270616531372, 1.9324078559875488, 2.73270845413208, 3.526545286178589, 4.3233537673950195, 5.12266993522644, 5.9109039306640625, 6.697603464126587, 7.4708428382873535, 8.264176368713379, 9.052886247634888, 9.843698501586914, 10.624967813491821, 11.415853500366211, 12.205471515655518, 12.989878416061401, 13.77402400970459, 14.559300661087036, 15.34448528289795, 16.132676124572754, 16.90397572517395, 17.68650221824646, 18.47578239440918, 19.263636589050293, 20.05596661567688, 20.838277578353882, 21.628089904785156, 22.418601512908936, 23.19977593421936, 23.978596687316895, 24.76713228225708, 25.55406093597412, 26.331626415252686, 27.111778020858765, 27.884562253952026, 28.67206835746765, 29.461631059646606, 30.248772621154785, 31.03447198867798, 31.817626953125, 32.595980405807495, 33.383193492889404, 34.16514301300049, 34.952518701553345, 35.736592531204224, 36.51943826675415, 37.31328201293945, 38.104297399520874, 38.886411905288696, 39.66651773452759, 40.44085359573364, 41.22871208190918, 42.01129150390625, 42.79899716377258, 43.592458963394165, 44.37527632713318, 45.158989906311035, 45.9443519115448, 46.72802209854126, 47.50677299499512, 48.297943353652954, 49.08611845970154, 49.87432813644409, 50.666117429733276, 51.45737814903259, 52.254409074783325, 53.03697919845581, 53.82920789718628, 54.61997699737549, 55.41934156417847, 56.21141862869263, 56.99971413612366, 57.791027307510376, 58.581913232803345, 59.382522106170654, 60.16977405548096, 60.9584755897522, 61.75450301170349, 62.54535222053528, 63.33532166481018, 64.11214232444763, 64.90619850158691, 65.69804668426514, 66.48985195159912, 67.2820291519165, 68.07484126091003, 68.8720920085907, 69.66396999359131, 70.4594452381134, 71.25386691093445, 72.04659461975098, 72.83621907234192, 73.62877488136292, 74.42758464813232, 75.21855282783508, 76.01655650138855, 76.80613255500793, 77.60210657119751, 78.40063977241516, 79.1953444480896, 80.42468237876892]
[14.5, 19.833333333333332, 26.666666666666668, 40.666666666666664, 41.733333333333334, 44.3, 43.63333333333333, 48.4, 50.03333333333333, 53.266666666666666, 53.333333333333336, 54.36666666666667, 55.266666666666666, 64.2, 63.233333333333334, 62.666666666666664, 64.43333333333334, 64.03333333333333, 64.53333333333333, 66.13333333333334, 64.6, 66.0, 66.1, 65.23333333333333, 65.53333333333333, 64.76666666666667, 66.53333333333333, 65.86666666666666, 64.96666666666667, 65.6, 66.93333333333334, 67.16666666666667, 67.03333333333333, 68.36666666666666, 67.16666666666667, 67.16666666666667, 66.36666666666666, 68.56666666666666, 69.13333333333334, 67.63333333333334, 67.93333333333334, 68.4, 67.8, 66.83333333333333, 66.96666666666667, 68.0, 67.36666666666666, 68.06666666666666, 67.4, 68.8, 68.53333333333333, 67.5, 68.16666666666667, 67.86666666666666, 67.53333333333333, 67.96666666666667, 68.63333333333334, 68.6, 68.7, 69.23333333333333, 68.5, 67.7, 69.06666666666666, 69.0, 69.43333333333334, 69.0, 68.56666666666666, 69.23333333333333, 68.0, 68.1, 68.53333333333333, 67.86666666666666, 68.5, 68.36666666666666, 69.0, 68.76666666666667, 68.3, 68.43333333333334, 68.6, 68.93333333333334, 69.3, 69.53333333333333, 68.7, 69.66666666666667, 68.86666666666666, 68.63333333333334, 68.76666666666667, 68.46666666666667, 68.76666666666667, 68.6, 69.26666666666667, 68.36666666666666, 68.3, 67.36666666666666, 67.23333333333333, 67.5, 67.03333333333333, 67.96666666666667, 68.06666666666666, 67.23333333333333, 67.33333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.394, Test loss: 1.441, Test accuracy: 44.70
Round   1, Train loss: 1.013, Test loss: 0.970, Test accuracy: 54.57
Round   2, Train loss: 0.935, Test loss: 0.946, Test accuracy: 52.33
Round   3, Train loss: 0.899, Test loss: 0.900, Test accuracy: 56.23
Round   4, Train loss: 0.874, Test loss: 0.866, Test accuracy: 59.90
Round   5, Train loss: 0.850, Test loss: 0.841, Test accuracy: 61.47
Round   6, Train loss: 0.828, Test loss: 0.859, Test accuracy: 61.20
Round   7, Train loss: 0.819, Test loss: 0.810, Test accuracy: 65.83
Round   8, Train loss: 0.800, Test loss: 0.785, Test accuracy: 67.43
Round   9, Train loss: 0.786, Test loss: 0.806, Test accuracy: 64.83
Round  10, Train loss: 0.780, Test loss: 0.801, Test accuracy: 61.33
Round  11, Train loss: 0.762, Test loss: 0.778, Test accuracy: 65.63
Round  12, Train loss: 0.754, Test loss: 0.754, Test accuracy: 67.93
Round  13, Train loss: 0.740, Test loss: 0.765, Test accuracy: 67.87
Round  14, Train loss: 0.726, Test loss: 0.769, Test accuracy: 66.27
Round  15, Train loss: 0.714, Test loss: 0.747, Test accuracy: 68.63
Round  16, Train loss: 0.706, Test loss: 0.762, Test accuracy: 66.83
Round  17, Train loss: 0.698, Test loss: 0.745, Test accuracy: 68.03
Round  18, Train loss: 0.681, Test loss: 0.726, Test accuracy: 67.53
Round  19, Train loss: 0.673, Test loss: 0.742, Test accuracy: 67.50
Round  20, Train loss: 0.421, Test loss: 0.709, Test accuracy: 68.63
Round  21, Train loss: 0.629, Test loss: 0.716, Test accuracy: 69.17
Round  22, Train loss: 0.804, Test loss: 0.747, Test accuracy: 67.47
Round  23, Train loss: 0.652, Test loss: 0.728, Test accuracy: 68.30
Round  24, Train loss: 0.758, Test loss: 0.797, Test accuracy: 64.07
Round  25, Train loss: 0.814, Test loss: 0.785, Test accuracy: 66.10
Round  26, Train loss: 0.376, Test loss: 0.746, Test accuracy: 66.90
Round  27, Train loss: 0.684, Test loss: 0.755, Test accuracy: 67.40
Round  28, Train loss: 0.374, Test loss: 0.772, Test accuracy: 66.77
Round  29, Train loss: 0.642, Test loss: 0.778, Test accuracy: 67.50
Round  30, Train loss: 0.504, Test loss: 0.763, Test accuracy: 67.53
Round  31, Train loss: 0.480, Test loss: 0.744, Test accuracy: 68.63
Round  32, Train loss: 0.451, Test loss: 0.748, Test accuracy: 67.03
Round  33, Train loss: 0.463, Test loss: 0.775, Test accuracy: 67.13
Round  34, Train loss: 0.461, Test loss: 0.802, Test accuracy: 66.73
Round  35, Train loss: 0.726, Test loss: 0.797, Test accuracy: 65.77
Round  36, Train loss: 0.628, Test loss: 0.807, Test accuracy: 66.43
Round  37, Train loss: 0.284, Test loss: 0.775, Test accuracy: 66.63
Round  38, Train loss: 0.348, Test loss: 0.762, Test accuracy: 67.97
Round  39, Train loss: 0.487, Test loss: 0.767, Test accuracy: 68.00
Round  40, Train loss: 0.365, Test loss: 0.767, Test accuracy: 67.83
Round  41, Train loss: 0.512, Test loss: 0.773, Test accuracy: 67.13
Round  42, Train loss: 0.277, Test loss: 0.758, Test accuracy: 68.70
Round  43, Train loss: 0.246, Test loss: 0.780, Test accuracy: 67.20
Round  44, Train loss: 0.476, Test loss: 0.796, Test accuracy: 66.63
Round  45, Train loss: 0.528, Test loss: 0.798, Test accuracy: 66.63
Round  46, Train loss: 0.664, Test loss: 0.856, Test accuracy: 64.87
Round  47, Train loss: 0.279, Test loss: 0.821, Test accuracy: 66.77
Round  48, Train loss: 0.189, Test loss: 0.820, Test accuracy: 67.17
Round  49, Train loss: 0.569, Test loss: 0.827, Test accuracy: 66.53
Round  50, Train loss: 0.237, Test loss: 0.804, Test accuracy: 67.63
Round  51, Train loss: 0.189, Test loss: 0.840, Test accuracy: 67.90
Round  52, Train loss: 0.663, Test loss: 0.885, Test accuracy: 65.43
Round  53, Train loss: 0.307, Test loss: 0.846, Test accuracy: 66.67
Round  54, Train loss: 0.545, Test loss: 0.879, Test accuracy: 66.73
Round  55, Train loss: 0.308, Test loss: 0.865, Test accuracy: 66.73
Round  56, Train loss: 0.430, Test loss: 0.916, Test accuracy: 64.73
Round  57, Train loss: 0.484, Test loss: 0.927, Test accuracy: 65.07
Round  58, Train loss: 0.268, Test loss: 0.883, Test accuracy: 65.70
Round  59, Train loss: 0.168, Test loss: 0.854, Test accuracy: 67.13
Round  60, Train loss: 0.448, Test loss: 0.921, Test accuracy: 66.17
Round  61, Train loss: 0.324, Test loss: 0.925, Test accuracy: 65.23
Round  62, Train loss: 0.287, Test loss: 0.974, Test accuracy: 64.33
Round  63, Train loss: 0.390, Test loss: 1.018, Test accuracy: 62.87
Round  64, Train loss: 0.265, Test loss: 0.933, Test accuracy: 66.07
Round  65, Train loss: 0.326, Test loss: 0.878, Test accuracy: 65.63
Round  66, Train loss: 0.355, Test loss: 0.959, Test accuracy: 66.30
Round  67, Train loss: 0.223, Test loss: 0.970, Test accuracy: 65.93
Round  68, Train loss: 0.410, Test loss: 0.965, Test accuracy: 64.87
Round  69, Train loss: 0.252, Test loss: 0.995, Test accuracy: 65.90
Round  70, Train loss: 0.281, Test loss: 1.012, Test accuracy: 65.30
Round  71, Train loss: 0.303, Test loss: 1.010, Test accuracy: 64.27
Round  72, Train loss: 0.261, Test loss: 0.979, Test accuracy: 64.47
Round  73, Train loss: 0.296, Test loss: 1.073, Test accuracy: 63.37
Round  74, Train loss: 0.227, Test loss: 1.030, Test accuracy: 64.83
Round  75, Train loss: 0.314, Test loss: 1.009, Test accuracy: 64.80
Round  76, Train loss: 0.202, Test loss: 1.046, Test accuracy: 64.73
Round  77, Train loss: 0.335, Test loss: 1.040, Test accuracy: 64.00
Round  78, Train loss: 0.274, Test loss: 1.062, Test accuracy: 65.07
Round  79, Train loss: 0.270, Test loss: 1.104, Test accuracy: 64.40
Round  80, Train loss: 0.220, Test loss: 1.025, Test accuracy: 65.23
Round  81, Train loss: 0.191, Test loss: 1.023, Test accuracy: 65.87
Round  82, Train loss: 0.186, Test loss: 1.045, Test accuracy: 65.87
Round  83, Train loss: 0.176, Test loss: 1.070, Test accuracy: 65.17
Round  84, Train loss: 0.172, Test loss: 1.061, Test accuracy: 65.47
Round  85, Train loss: 0.157, Test loss: 1.062, Test accuracy: 66.73
Round  86, Train loss: 0.167, Test loss: 1.074, Test accuracy: 65.23
Round  87, Train loss: 0.158, Test loss: 1.046, Test accuracy: 65.43
Round  88, Train loss: 0.152, Test loss: 1.073, Test accuracy: 66.70
Round  89, Train loss: 0.160, Test loss: 1.069, Test accuracy: 65.10
Round  90, Train loss: 0.156, Test loss: 1.074, Test accuracy: 66.10
Round  91, Train loss: 0.149, Test loss: 1.086, Test accuracy: 66.43
Round  92, Train loss: 0.149, Test loss: 1.073, Test accuracy: 66.63
Round  93, Train loss: 0.135, Test loss: 1.079, Test accuracy: 67.03
Round  94, Train loss: 0.137, Test loss: 1.103, Test accuracy: 67.53
Round  95, Train loss: 0.153, Test loss: 1.088, Test accuracy: 66.37
Round  96, Train loss: 0.142, Test loss: 1.076, Test accuracy: 66.50
Round  97, Train loss: 0.128, Test loss: 1.112, Test accuracy: 66.83
Round  98, Train loss: 0.134, Test loss: 1.101, Test accuracy: 67.10
Round  99, Train loss: 0.128, Test loss: 1.107, Test accuracy: 66.37
Final Round, Train loss: 0.099, Test loss: 1.122, Test accuracy: 66.57
Average accuracy final 10 rounds: 66.69
949.2971136569977
[1.921919822692871, 3.4934093952178955, 5.064434051513672, 6.618542432785034, 8.18014144897461, 9.772185564041138, 11.35256814956665, 12.934000730514526, 14.519079446792603, 16.106029987335205, 17.69369864463806, 19.270885705947876, 20.829823970794678, 22.39715576171875, 23.98149275779724, 25.576377391815186, 27.159099340438843, 28.71686339378357, 30.151273250579834, 31.584028005599976, 32.999107837677, 34.42034459114075, 35.84253191947937, 37.24854302406311, 38.65643835067749, 40.07401466369629, 41.50035262107849, 42.928977727890015, 44.34731721878052, 45.76339769363403, 47.182955503463745, 48.58623218536377, 50.003657817840576, 51.410480260849, 52.80573844909668, 54.21743869781494, 55.627854347229004, 57.04647636413574, 58.45130753517151, 59.87580370903015, 61.286893367767334, 62.704052209854126, 64.12190794944763, 65.54398322105408, 66.95166540145874, 68.35384964942932, 69.76692318916321, 71.19061732292175, 72.61010146141052, 74.0348162651062, 75.4486174583435, 76.8653073310852, 78.28633904457092, 79.7091703414917, 81.13237380981445, 82.56168937683105, 83.98980355262756, 85.41533660888672, 86.8349916934967, 88.25973868370056, 89.67708134651184, 91.0823438167572, 92.49620747566223, 93.92104053497314, 95.34778928756714, 96.76553869247437, 98.18022084236145, 99.58296704292297, 101.00278973579407, 102.40704417228699, 103.82484102249146, 105.2594690322876, 106.66306924819946, 108.0827534198761, 109.50370812416077, 110.93233799934387, 112.35829329490662, 113.77442836761475, 115.20611572265625, 116.62247705459595, 118.04926037788391, 119.46407628059387, 120.88135695457458, 122.2970814704895, 123.72183346748352, 125.1363935470581, 126.55596041679382, 127.99177265167236, 129.42094492912292, 130.84601974487305, 132.2700972557068, 133.70171475410461, 135.11820721626282, 136.53407979011536, 138.09291887283325, 139.6666784286499, 141.21942377090454, 142.78387475013733, 144.35081672668457, 145.9298665523529, 148.35711669921875]
[44.7, 54.56666666666667, 52.333333333333336, 56.233333333333334, 59.9, 61.46666666666667, 61.2, 65.83333333333333, 67.43333333333334, 64.83333333333333, 61.333333333333336, 65.63333333333334, 67.93333333333334, 67.86666666666666, 66.26666666666667, 68.63333333333334, 66.83333333333333, 68.03333333333333, 67.53333333333333, 67.5, 68.63333333333334, 69.16666666666667, 67.46666666666667, 68.3, 64.06666666666666, 66.1, 66.9, 67.4, 66.76666666666667, 67.5, 67.53333333333333, 68.63333333333334, 67.03333333333333, 67.13333333333334, 66.73333333333333, 65.76666666666667, 66.43333333333334, 66.63333333333334, 67.96666666666667, 68.0, 67.83333333333333, 67.13333333333334, 68.7, 67.2, 66.63333333333334, 66.63333333333334, 64.86666666666666, 66.76666666666667, 67.16666666666667, 66.53333333333333, 67.63333333333334, 67.9, 65.43333333333334, 66.66666666666667, 66.73333333333333, 66.73333333333333, 64.73333333333333, 65.06666666666666, 65.7, 67.13333333333334, 66.16666666666667, 65.23333333333333, 64.33333333333333, 62.86666666666667, 66.06666666666666, 65.63333333333334, 66.3, 65.93333333333334, 64.86666666666666, 65.9, 65.3, 64.26666666666667, 64.46666666666667, 63.36666666666667, 64.83333333333333, 64.8, 64.73333333333333, 64.0, 65.06666666666666, 64.4, 65.23333333333333, 65.86666666666666, 65.86666666666666, 65.16666666666667, 65.46666666666667, 66.73333333333333, 65.23333333333333, 65.43333333333334, 66.7, 65.1, 66.1, 66.43333333333334, 66.63333333333334, 67.03333333333333, 67.53333333333333, 66.36666666666666, 66.5, 66.83333333333333, 67.1, 66.36666666666666, 66.56666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.394, Test loss: 1.452, Test accuracy: 36.27
Round   1, Train loss: 1.040, Test loss: 1.033, Test accuracy: 49.03
Round   2, Train loss: 0.965, Test loss: 0.965, Test accuracy: 54.53
Round   3, Train loss: 0.927, Test loss: 0.927, Test accuracy: 57.07
Round   4, Train loss: 0.901, Test loss: 0.895, Test accuracy: 56.97
Round   5, Train loss: 0.877, Test loss: 0.863, Test accuracy: 62.87
Round   6, Train loss: 0.855, Test loss: 0.835, Test accuracy: 64.73
Round   7, Train loss: 0.840, Test loss: 0.840, Test accuracy: 62.23
Round   8, Train loss: 0.826, Test loss: 0.800, Test accuracy: 65.53
Round   9, Train loss: 0.815, Test loss: 0.835, Test accuracy: 61.87
Round  10, Train loss: 0.799, Test loss: 0.811, Test accuracy: 64.20
Round  11, Train loss: 0.783, Test loss: 0.769, Test accuracy: 69.23
Round  12, Train loss: 0.766, Test loss: 0.751, Test accuracy: 70.20
Round  13, Train loss: 0.758, Test loss: 0.755, Test accuracy: 69.87
Round  14, Train loss: 0.744, Test loss: 0.760, Test accuracy: 68.17
Round  15, Train loss: 0.730, Test loss: 0.750, Test accuracy: 69.67
Round  16, Train loss: 0.718, Test loss: 0.738, Test accuracy: 68.97
Round  17, Train loss: 0.701, Test loss: 0.738, Test accuracy: 67.43
Round  18, Train loss: 0.693, Test loss: 0.754, Test accuracy: 65.93
Round  19, Train loss: 0.677, Test loss: 0.750, Test accuracy: 67.97
Round  20, Train loss: 0.634, Test loss: 0.750, Test accuracy: 67.23
Round  21, Train loss: 0.695, Test loss: 0.751, Test accuracy: 67.30
Round  22, Train loss: 0.464, Test loss: 0.763, Test accuracy: 66.23
Round  23, Train loss: 0.480, Test loss: 0.767, Test accuracy: 66.23
Round  24, Train loss: 0.570, Test loss: 0.740, Test accuracy: 68.37
Round  25, Train loss: 0.624, Test loss: 0.766, Test accuracy: 67.47
Round  26, Train loss: 0.575, Test loss: 0.775, Test accuracy: 66.70
Round  27, Train loss: 0.335, Test loss: 0.755, Test accuracy: 67.73
Round  28, Train loss: 0.371, Test loss: 0.751, Test accuracy: 68.33
Round  29, Train loss: 0.304, Test loss: 0.750, Test accuracy: 68.73
Round  30, Train loss: 0.703, Test loss: 0.773, Test accuracy: 66.97
Round  31, Train loss: 0.654, Test loss: 0.801, Test accuracy: 65.97
Round  32, Train loss: 0.264, Test loss: 0.779, Test accuracy: 67.17
Round  33, Train loss: 0.260, Test loss: 0.789, Test accuracy: 66.67
Round  34, Train loss: 0.655, Test loss: 0.805, Test accuracy: 65.80
Round  35, Train loss: 0.518, Test loss: 0.829, Test accuracy: 66.50
Round  36, Train loss: 0.439, Test loss: 0.823, Test accuracy: 65.87
Round  37, Train loss: 0.492, Test loss: 0.810, Test accuracy: 65.97
Round  38, Train loss: 0.561, Test loss: 0.797, Test accuracy: 66.13
Round  39, Train loss: 0.443, Test loss: 0.805, Test accuracy: 66.30
Round  40, Train loss: 0.202, Test loss: 0.786, Test accuracy: 66.73
Round  41, Train loss: 0.227, Test loss: 0.787, Test accuracy: 67.50
Round  42, Train loss: 0.444, Test loss: 0.799, Test accuracy: 66.97
Round  43, Train loss: 0.427, Test loss: 0.823, Test accuracy: 66.97
Round  44, Train loss: 0.629, Test loss: 0.874, Test accuracy: 63.00
Round  45, Train loss: 0.451, Test loss: 0.814, Test accuracy: 64.93
Round  46, Train loss: 0.380, Test loss: 0.856, Test accuracy: 64.37
Round  47, Train loss: 0.466, Test loss: 0.857, Test accuracy: 64.27
Round  48, Train loss: 0.373, Test loss: 0.855, Test accuracy: 64.97
Round  49, Train loss: 0.411, Test loss: 0.879, Test accuracy: 64.93
Round  50, Train loss: 0.381, Test loss: 0.912, Test accuracy: 65.17
Round  51, Train loss: 0.352, Test loss: 0.909, Test accuracy: 65.10
Round  52, Train loss: 0.392, Test loss: 0.887, Test accuracy: 64.43
Round  53, Train loss: 0.190, Test loss: 0.868, Test accuracy: 65.30
Round  54, Train loss: 0.483, Test loss: 0.885, Test accuracy: 63.77
Round  55, Train loss: 0.504, Test loss: 0.943, Test accuracy: 61.47
Round  56, Train loss: 0.456, Test loss: 0.941, Test accuracy: 61.83
Round  57, Train loss: 0.553, Test loss: 0.988, Test accuracy: 60.83
Round  58, Train loss: 0.277, Test loss: 0.947, Test accuracy: 62.63
Round  59, Train loss: 0.306, Test loss: 0.969, Test accuracy: 62.03
Round  60, Train loss: 0.521, Test loss: 1.025, Test accuracy: 60.47
Round  61, Train loss: 0.198, Test loss: 0.959, Test accuracy: 63.87
Round  62, Train loss: 0.378, Test loss: 1.002, Test accuracy: 62.37
Round  63, Train loss: 0.413, Test loss: 1.001, Test accuracy: 62.30
Round  64, Train loss: 0.259, Test loss: 1.022, Test accuracy: 62.00
Round  65, Train loss: 0.241, Test loss: 0.961, Test accuracy: 64.00
Round  66, Train loss: 0.261, Test loss: 0.983, Test accuracy: 63.73
Round  67, Train loss: 0.139, Test loss: 0.971, Test accuracy: 64.93
Round  68, Train loss: 0.352, Test loss: 1.027, Test accuracy: 62.43
Round  69, Train loss: 0.184, Test loss: 0.994, Test accuracy: 64.13
Round  70, Train loss: 0.260, Test loss: 0.972, Test accuracy: 63.30
Round  71, Train loss: 0.192, Test loss: 0.990, Test accuracy: 64.17
Round  72, Train loss: 0.298, Test loss: 1.017, Test accuracy: 62.60
Round  73, Train loss: 0.292, Test loss: 1.082, Test accuracy: 60.73
Round  74, Train loss: 0.299, Test loss: 1.069, Test accuracy: 61.60
Round  75, Train loss: 0.268, Test loss: 1.076, Test accuracy: 61.70
Round  76, Train loss: 0.206, Test loss: 1.057, Test accuracy: 62.37
Round  77, Train loss: 0.238, Test loss: 1.022, Test accuracy: 62.63
Round  78, Train loss: 0.190, Test loss: 1.033, Test accuracy: 64.97
Round  79, Train loss: 0.212, Test loss: 1.097, Test accuracy: 61.83
Round  80, Train loss: 0.219, Test loss: 1.083, Test accuracy: 61.93
Round  81, Train loss: 0.199, Test loss: 1.097, Test accuracy: 62.23
Round  82, Train loss: 0.192, Test loss: 1.085, Test accuracy: 62.10
Round  83, Train loss: 0.177, Test loss: 1.105, Test accuracy: 62.00
Round  84, Train loss: 0.183, Test loss: 1.090, Test accuracy: 63.00
Round  85, Train loss: 0.170, Test loss: 1.105, Test accuracy: 63.00
Round  86, Train loss: 0.171, Test loss: 1.145, Test accuracy: 62.23
Round  87, Train loss: 0.163, Test loss: 1.125, Test accuracy: 62.27
Round  88, Train loss: 0.159, Test loss: 1.147, Test accuracy: 61.83
Round  89, Train loss: 0.164, Test loss: 1.129, Test accuracy: 62.97
Round  90, Train loss: 0.150, Test loss: 1.145, Test accuracy: 62.57
Round  91, Train loss: 0.151, Test loss: 1.187, Test accuracy: 62.07
Round  92, Train loss: 0.143, Test loss: 1.195, Test accuracy: 62.73
Round  93, Train loss: 0.160, Test loss: 1.181, Test accuracy: 62.50
Round  94, Train loss: 0.150, Test loss: 1.212, Test accuracy: 61.27
Round  95, Train loss: 0.144, Test loss: 1.188, Test accuracy: 61.63
Round  96, Train loss: 0.130, Test loss: 1.204, Test accuracy: 61.40
Round  97, Train loss: 0.132, Test loss: 1.221, Test accuracy: 61.47
Round  98, Train loss: 0.122, Test loss: 1.213, Test accuracy: 61.70
Round  99, Train loss: 0.135, Test loss: 1.234, Test accuracy: 61.53
Final Round, Train loss: 0.101, Test loss: 1.259, Test accuracy: 62.27
Average accuracy final 10 rounds: 61.88666666666668
1417.7626814842224
[1.8403806686401367, 3.2865939140319824, 4.731618404388428, 6.173516035079956, 7.6253743171691895, 9.072944402694702, 10.515762329101562, 11.959357500076294, 13.40181827545166, 14.846267223358154, 16.288860082626343, 17.728548049926758, 19.166393756866455, 20.607402086257935, 22.051342248916626, 23.49710726737976, 24.937971115112305, 26.379440307617188, 27.82490086555481, 29.27982234954834, 30.72397518157959, 33.43690228462219, 36.173805236816406, 38.81316566467285, 41.5813353061676, 44.34679865837097, 47.10412001609802, 49.81059694290161, 52.55819845199585, 55.30465269088745, 58.02195072174072, 60.69629883766174, 63.48068141937256, 66.43519902229309, 69.36651873588562, 72.30091762542725, 75.24053835868835, 78.1583001613617, 80.98066091537476, 83.71888875961304, 86.45326828956604, 89.24288773536682, 91.98022842407227, 94.77011013031006, 97.52370119094849, 100.25919818878174, 103.01572394371033, 105.78344964981079, 108.52145862579346, 111.30751848220825, 114.04997777938843, 116.81789565086365, 119.58432865142822, 122.25796627998352, 125.00261378288269, 127.6987509727478, 130.4481611251831, 133.21328997612, 135.982563495636, 138.77059984207153, 141.4956750869751, 144.243332862854, 146.94833254814148, 149.74418354034424, 152.47371006011963, 155.2530701160431, 158.0080008506775, 160.72559642791748, 163.49146342277527, 166.24719071388245, 169.04370307922363, 171.79686617851257, 174.5337474346161, 177.2693226337433, 179.9830014705658, 182.72653532028198, 185.4918806552887, 188.28125286102295, 191.04505896568298, 193.76819467544556, 196.55514812469482, 199.30388736724854, 202.05877447128296, 204.8362855911255, 207.6202836036682, 210.38321685791016, 213.14332151412964, 215.91489148139954, 218.69384479522705, 221.45023131370544, 224.21515035629272, 226.99449038505554, 229.74828553199768, 232.4700071811676, 235.27137851715088, 238.03789496421814, 240.83025336265564, 243.58103561401367, 246.39063906669617, 249.17520809173584, 251.53602957725525]
[36.266666666666666, 49.03333333333333, 54.53333333333333, 57.06666666666667, 56.96666666666667, 62.86666666666667, 64.73333333333333, 62.233333333333334, 65.53333333333333, 61.86666666666667, 64.2, 69.23333333333333, 70.2, 69.86666666666666, 68.16666666666667, 69.66666666666667, 68.96666666666667, 67.43333333333334, 65.93333333333334, 67.96666666666667, 67.23333333333333, 67.3, 66.23333333333333, 66.23333333333333, 68.36666666666666, 67.46666666666667, 66.7, 67.73333333333333, 68.33333333333333, 68.73333333333333, 66.96666666666667, 65.96666666666667, 67.16666666666667, 66.66666666666667, 65.8, 66.5, 65.86666666666666, 65.96666666666667, 66.13333333333334, 66.3, 66.73333333333333, 67.5, 66.96666666666667, 66.96666666666667, 63.0, 64.93333333333334, 64.36666666666666, 64.26666666666667, 64.96666666666667, 64.93333333333334, 65.16666666666667, 65.1, 64.43333333333334, 65.3, 63.766666666666666, 61.46666666666667, 61.833333333333336, 60.833333333333336, 62.63333333333333, 62.03333333333333, 60.46666666666667, 63.86666666666667, 62.36666666666667, 62.3, 62.0, 64.0, 63.733333333333334, 64.93333333333334, 62.43333333333333, 64.13333333333334, 63.3, 64.16666666666667, 62.6, 60.733333333333334, 61.6, 61.7, 62.36666666666667, 62.63333333333333, 64.96666666666667, 61.833333333333336, 61.93333333333333, 62.233333333333334, 62.1, 62.0, 63.0, 63.0, 62.233333333333334, 62.266666666666666, 61.833333333333336, 62.96666666666667, 62.56666666666667, 62.06666666666667, 62.733333333333334, 62.5, 61.266666666666666, 61.63333333333333, 61.4, 61.46666666666667, 61.7, 61.53333333333333, 62.266666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.396, Test loss: 1.378, Test accuracy: 45.63
Round   1, Train loss: 1.028, Test loss: 1.004, Test accuracy: 49.60
Round   2, Train loss: 0.965, Test loss: 0.959, Test accuracy: 55.93
Round   3, Train loss: 0.935, Test loss: 0.918, Test accuracy: 57.23
Round   4, Train loss: 0.913, Test loss: 0.922, Test accuracy: 55.77
Round   5, Train loss: 0.889, Test loss: 0.884, Test accuracy: 57.00
Round   6, Train loss: 0.876, Test loss: 0.876, Test accuracy: 57.87
Round   7, Train loss: 0.858, Test loss: 0.840, Test accuracy: 63.70
Round   8, Train loss: 0.843, Test loss: 0.827, Test accuracy: 65.63
Round   9, Train loss: 0.832, Test loss: 0.815, Test accuracy: 66.77
Round  10, Train loss: 0.822, Test loss: 0.798, Test accuracy: 67.47
Round  11, Train loss: 0.809, Test loss: 0.812, Test accuracy: 64.80
Round  12, Train loss: 0.795, Test loss: 0.785, Test accuracy: 67.83
Round  13, Train loss: 0.786, Test loss: 0.790, Test accuracy: 66.03
Round  14, Train loss: 0.772, Test loss: 0.781, Test accuracy: 65.67
Round  15, Train loss: 0.764, Test loss: 0.781, Test accuracy: 67.37
Round  16, Train loss: 0.749, Test loss: 0.780, Test accuracy: 64.33
Round  17, Train loss: 0.737, Test loss: 0.779, Test accuracy: 66.50
Round  18, Train loss: 0.726, Test loss: 0.795, Test accuracy: 66.37
Round  19, Train loss: 0.715, Test loss: 0.741, Test accuracy: 68.37
Round  20, Train loss: 0.786, Test loss: 0.763, Test accuracy: 67.20
Round  21, Train loss: 0.842, Test loss: 0.760, Test accuracy: 66.33
Round  22, Train loss: 0.640, Test loss: 0.757, Test accuracy: 66.50
Round  23, Train loss: 0.649, Test loss: 0.765, Test accuracy: 66.53
Round  24, Train loss: 0.762, Test loss: 0.788, Test accuracy: 65.90
Round  25, Train loss: 0.572, Test loss: 0.756, Test accuracy: 68.10
Round  26, Train loss: 0.577, Test loss: 0.765, Test accuracy: 67.17
Round  27, Train loss: 0.556, Test loss: 0.775, Test accuracy: 66.67
Round  28, Train loss: 0.725, Test loss: 0.812, Test accuracy: 64.07
Round  29, Train loss: 0.495, Test loss: 0.805, Test accuracy: 64.90
Round  30, Train loss: 0.801, Test loss: 0.834, Test accuracy: 63.43
Round  31, Train loss: 0.637, Test loss: 0.828, Test accuracy: 63.33
Round  32, Train loss: 0.419, Test loss: 0.822, Test accuracy: 64.17
Round  33, Train loss: 0.418, Test loss: 0.841, Test accuracy: 63.53
Round  34, Train loss: 0.712, Test loss: 0.847, Test accuracy: 62.83
Round  35, Train loss: 0.489, Test loss: 0.809, Test accuracy: 65.67
Round  36, Train loss: 0.386, Test loss: 0.812, Test accuracy: 66.13
Round  37, Train loss: 0.570, Test loss: 0.855, Test accuracy: 63.77
Round  38, Train loss: 0.712, Test loss: 0.855, Test accuracy: 63.03
Round  39, Train loss: 0.396, Test loss: 0.801, Test accuracy: 65.30
Round  40, Train loss: 0.325, Test loss: 0.851, Test accuracy: 65.13
Round  41, Train loss: 0.349, Test loss: 0.845, Test accuracy: 65.10
Round  42, Train loss: 0.463, Test loss: 0.868, Test accuracy: 63.73
Round  43, Train loss: 0.255, Test loss: 0.855, Test accuracy: 64.90
Round  44, Train loss: 0.486, Test loss: 0.847, Test accuracy: 64.23
Round  45, Train loss: 0.463, Test loss: 0.880, Test accuracy: 63.67
Round  46, Train loss: 0.351, Test loss: 0.875, Test accuracy: 66.20
Round  47, Train loss: 0.447, Test loss: 0.862, Test accuracy: 64.17
Round  48, Train loss: 0.482, Test loss: 0.892, Test accuracy: 63.20
Round  49, Train loss: 0.431, Test loss: 0.879, Test accuracy: 62.87
Round  50, Train loss: 0.390, Test loss: 0.915, Test accuracy: 62.77
Round  51, Train loss: 0.324, Test loss: 0.957, Test accuracy: 61.60
Round  52, Train loss: 0.430, Test loss: 0.923, Test accuracy: 63.47
Round  53, Train loss: 0.411, Test loss: 0.971, Test accuracy: 61.97
Round  54, Train loss: 0.542, Test loss: 0.950, Test accuracy: 61.87
Round  55, Train loss: 0.378, Test loss: 0.918, Test accuracy: 64.27
Round  56, Train loss: 0.409, Test loss: 0.986, Test accuracy: 63.30
Round  57, Train loss: 0.535, Test loss: 1.029, Test accuracy: 60.53
Round  58, Train loss: 0.365, Test loss: 1.007, Test accuracy: 59.53
Round  59, Train loss: 0.266, Test loss: 1.005, Test accuracy: 61.23
Round  60, Train loss: 0.410, Test loss: 0.975, Test accuracy: 63.00
Round  61, Train loss: 0.234, Test loss: 0.921, Test accuracy: 64.33
Round  62, Train loss: 0.459, Test loss: 1.046, Test accuracy: 60.37
Round  63, Train loss: 0.289, Test loss: 0.944, Test accuracy: 64.33
Round  64, Train loss: 0.256, Test loss: 0.986, Test accuracy: 62.97
Round  65, Train loss: 0.364, Test loss: 0.957, Test accuracy: 63.67
Round  66, Train loss: 0.235, Test loss: 0.947, Test accuracy: 64.20
Round  67, Train loss: 0.202, Test loss: 1.001, Test accuracy: 62.97
Round  68, Train loss: 0.369, Test loss: 0.982, Test accuracy: 63.43
Round  69, Train loss: 0.315, Test loss: 1.000, Test accuracy: 63.60
Round  70, Train loss: 0.443, Test loss: 1.080, Test accuracy: 59.77
Round  71, Train loss: 0.274, Test loss: 1.074, Test accuracy: 61.10
Round  72, Train loss: 0.198, Test loss: 0.979, Test accuracy: 64.73
Round  73, Train loss: 0.238, Test loss: 1.038, Test accuracy: 63.30
Round  74, Train loss: 0.239, Test loss: 1.027, Test accuracy: 62.40
Round  75, Train loss: 0.279, Test loss: 1.017, Test accuracy: 62.03
Round  76, Train loss: 0.131, Test loss: 1.012, Test accuracy: 63.37
Round  77, Train loss: 0.310, Test loss: 1.114, Test accuracy: 61.70
Round  78, Train loss: 0.192, Test loss: 1.021, Test accuracy: 63.40
Round  79, Train loss: 0.213, Test loss: 1.057, Test accuracy: 61.00
Round  80, Train loss: 0.232, Test loss: 1.064, Test accuracy: 62.03
Round  81, Train loss: 0.232, Test loss: 1.068, Test accuracy: 61.77
Round  82, Train loss: 0.207, Test loss: 1.105, Test accuracy: 61.57
Round  83, Train loss: 0.212, Test loss: 1.086, Test accuracy: 62.20
Round  84, Train loss: 0.196, Test loss: 1.108, Test accuracy: 62.13
Round  85, Train loss: 0.199, Test loss: 1.138, Test accuracy: 61.70
Round  86, Train loss: 0.191, Test loss: 1.138, Test accuracy: 61.87
Round  87, Train loss: 0.186, Test loss: 1.143, Test accuracy: 62.07
Round  88, Train loss: 0.192, Test loss: 1.152, Test accuracy: 61.57
Round  89, Train loss: 0.185, Test loss: 1.149, Test accuracy: 61.47
Round  90, Train loss: 0.176, Test loss: 1.129, Test accuracy: 61.67
Round  91, Train loss: 0.187, Test loss: 1.140, Test accuracy: 61.77
Round  92, Train loss: 0.185, Test loss: 1.159, Test accuracy: 62.10
Round  93, Train loss: 0.170, Test loss: 1.144, Test accuracy: 61.47
Round  94, Train loss: 0.171, Test loss: 1.169, Test accuracy: 61.77
Round  95, Train loss: 0.163, Test loss: 1.206, Test accuracy: 61.43
Round  96, Train loss: 0.158, Test loss: 1.183, Test accuracy: 61.67
Round  97, Train loss: 0.165, Test loss: 1.151, Test accuracy: 62.27
Round  98, Train loss: 0.165, Test loss: 1.182, Test accuracy: 62.27
Round  99, Train loss: 0.151, Test loss: 1.181, Test accuracy: 62.33
Final Round, Train loss: 0.127, Test loss: 1.220, Test accuracy: 62.53
Average accuracy final 10 rounds: 61.873333333333335
1441.2231314182281
[1.8972997665405273, 3.6024396419525146, 5.3015570640563965, 7.005840063095093, 8.722007751464844, 10.432244777679443, 12.145398616790771, 13.846062421798706, 15.558253526687622, 17.252306938171387, 18.9482159614563, 20.63690423965454, 22.33301305770874, 24.02875065803528, 25.722716331481934, 27.4180965423584, 29.112921476364136, 30.811338424682617, 32.51313853263855, 34.2098274230957, 35.89814901351929, 38.897958517074585, 41.91383075714111, 44.909531593322754, 47.92193531990051, 50.92734408378601, 53.91945266723633, 56.92070150375366, 59.93915677070618, 62.940595626831055, 65.88945865631104, 68.9048182964325, 71.89658093452454, 74.86620688438416, 77.87559533119202, 80.66100883483887, 83.34928393363953, 86.1043848991394, 88.85188293457031, 91.61703276634216, 94.39193749427795, 97.08720421791077, 99.8200147151947, 102.57048106193542, 105.32804727554321, 108.08990836143494, 110.77067589759827, 113.51797270774841, 116.28593349456787, 118.99862241744995, 121.74351811408997, 124.48025012016296, 127.20139789581299, 129.9719488620758, 132.71682357788086, 135.45953965187073, 138.20159816741943, 140.89535760879517, 143.64672541618347, 146.3723258972168, 149.0869300365448, 151.78079438209534, 154.4939000606537, 157.2139437198639, 159.96375918388367, 162.6874532699585, 165.44231247901917, 168.14140796661377, 170.8622145652771, 173.6174840927124, 176.3751242160797, 179.0619761943817, 181.780131816864, 184.5215277671814, 187.31123232841492, 190.07103824615479, 192.78540587425232, 195.5220537185669, 198.08379316329956, 200.64939093589783, 203.2272436618805, 205.80747246742249, 208.42705607414246, 211.09215354919434, 213.76099705696106, 216.44216799736023, 219.1069152355194, 221.73161005973816, 224.36048412322998, 226.99204778671265, 229.60755562782288, 232.23692321777344, 234.8685998916626, 237.49610137939453, 240.1333565711975, 242.74986743927002, 245.37707209587097, 248.005220413208, 250.61760473251343, 253.25067806243896, 255.57962274551392]
[45.63333333333333, 49.6, 55.93333333333333, 57.233333333333334, 55.766666666666666, 57.0, 57.86666666666667, 63.7, 65.63333333333334, 66.76666666666667, 67.46666666666667, 64.8, 67.83333333333333, 66.03333333333333, 65.66666666666667, 67.36666666666666, 64.33333333333333, 66.5, 66.36666666666666, 68.36666666666666, 67.2, 66.33333333333333, 66.5, 66.53333333333333, 65.9, 68.1, 67.16666666666667, 66.66666666666667, 64.06666666666666, 64.9, 63.43333333333333, 63.333333333333336, 64.16666666666667, 63.53333333333333, 62.833333333333336, 65.66666666666667, 66.13333333333334, 63.766666666666666, 63.03333333333333, 65.3, 65.13333333333334, 65.1, 63.733333333333334, 64.9, 64.23333333333333, 63.666666666666664, 66.2, 64.16666666666667, 63.2, 62.86666666666667, 62.766666666666666, 61.6, 63.46666666666667, 61.96666666666667, 61.86666666666667, 64.26666666666667, 63.3, 60.53333333333333, 59.53333333333333, 61.233333333333334, 63.0, 64.33333333333333, 60.36666666666667, 64.33333333333333, 62.96666666666667, 63.666666666666664, 64.2, 62.96666666666667, 63.43333333333333, 63.6, 59.766666666666666, 61.1, 64.73333333333333, 63.3, 62.4, 62.03333333333333, 63.36666666666667, 61.7, 63.4, 61.0, 62.03333333333333, 61.766666666666666, 61.56666666666667, 62.2, 62.13333333333333, 61.7, 61.86666666666667, 62.06666666666667, 61.56666666666667, 61.46666666666667, 61.666666666666664, 61.766666666666666, 62.1, 61.46666666666667, 61.766666666666666, 61.43333333333333, 61.666666666666664, 62.266666666666666, 62.266666666666666, 62.333333333333336, 62.53333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.673, Test loss: 2.278, Test accuracy: 18.37
Round   1, Train loss: 1.132, Test loss: 2.559, Test accuracy: 21.47
Round   2, Train loss: 1.136, Test loss: 1.811, Test accuracy: 33.97
Round   3, Train loss: 1.027, Test loss: 1.904, Test accuracy: 31.13
Round   4, Train loss: 1.017, Test loss: 1.885, Test accuracy: 40.50
Round   5, Train loss: 1.037, Test loss: 1.770, Test accuracy: 41.93
Round   6, Train loss: 1.101, Test loss: 1.539, Test accuracy: 45.17
Round   7, Train loss: 0.995, Test loss: 1.018, Test accuracy: 57.63
Round   8, Train loss: 1.012, Test loss: 1.213, Test accuracy: 59.13
Round   9, Train loss: 0.899, Test loss: 0.959, Test accuracy: 59.90
Round  10, Train loss: 1.009, Test loss: 1.093, Test accuracy: 59.60
Round  11, Train loss: 0.954, Test loss: 1.060, Test accuracy: 57.83
Round  12, Train loss: 0.977, Test loss: 1.104, Test accuracy: 56.23
Round  13, Train loss: 0.947, Test loss: 0.840, Test accuracy: 63.67
Round  14, Train loss: 0.936, Test loss: 0.829, Test accuracy: 63.60
Round  15, Train loss: 0.849, Test loss: 0.806, Test accuracy: 64.47
Round  16, Train loss: 0.912, Test loss: 0.804, Test accuracy: 65.47
Round  17, Train loss: 0.822, Test loss: 0.795, Test accuracy: 66.67
Round  18, Train loss: 0.844, Test loss: 0.778, Test accuracy: 67.57
Round  19, Train loss: 0.925, Test loss: 0.777, Test accuracy: 69.87
Round  20, Train loss: 0.823, Test loss: 0.730, Test accuracy: 71.07
Round  21, Train loss: 0.961, Test loss: 0.750, Test accuracy: 71.73
Round  22, Train loss: 0.793, Test loss: 0.711, Test accuracy: 71.50
Round  23, Train loss: 0.956, Test loss: 0.734, Test accuracy: 70.60
Round  24, Train loss: 0.784, Test loss: 0.717, Test accuracy: 71.60
Round  25, Train loss: 0.731, Test loss: 0.700, Test accuracy: 71.97
Round  26, Train loss: 0.868, Test loss: 0.714, Test accuracy: 71.77
Round  27, Train loss: 0.893, Test loss: 0.712, Test accuracy: 71.30
Round  28, Train loss: 0.841, Test loss: 0.707, Test accuracy: 72.20
Round  29, Train loss: 0.937, Test loss: 0.711, Test accuracy: 72.07
Round  30, Train loss: 0.757, Test loss: 0.699, Test accuracy: 72.53
Round  31, Train loss: 0.889, Test loss: 0.705, Test accuracy: 73.00
Round  32, Train loss: 0.880, Test loss: 0.704, Test accuracy: 72.03
Round  33, Train loss: 0.875, Test loss: 0.721, Test accuracy: 72.43
Round  34, Train loss: 0.766, Test loss: 0.707, Test accuracy: 73.60
Round  35, Train loss: 0.719, Test loss: 0.691, Test accuracy: 72.90
Round  36, Train loss: 0.743, Test loss: 0.682, Test accuracy: 73.40
Round  37, Train loss: 0.833, Test loss: 0.682, Test accuracy: 72.97
Round  38, Train loss: 0.880, Test loss: 0.709, Test accuracy: 71.40
Round  39, Train loss: 0.675, Test loss: 0.707, Test accuracy: 71.57
Round  40, Train loss: 0.785, Test loss: 0.680, Test accuracy: 73.03
Round  41, Train loss: 0.872, Test loss: 0.694, Test accuracy: 73.40
Round  42, Train loss: 0.719, Test loss: 0.671, Test accuracy: 74.03
Round  43, Train loss: 0.808, Test loss: 0.686, Test accuracy: 74.13
Round  44, Train loss: 0.885, Test loss: 0.670, Test accuracy: 74.13
Round  45, Train loss: 0.772, Test loss: 0.674, Test accuracy: 73.27
Round  46, Train loss: 0.821, Test loss: 0.669, Test accuracy: 73.77
Round  47, Train loss: 0.722, Test loss: 0.660, Test accuracy: 73.73
Round  48, Train loss: 0.783, Test loss: 0.674, Test accuracy: 73.77
Round  49, Train loss: 0.761, Test loss: 0.657, Test accuracy: 74.33
Round  50, Train loss: 0.772, Test loss: 0.655, Test accuracy: 74.90
Round  51, Train loss: 0.694, Test loss: 0.693, Test accuracy: 73.13
Round  52, Train loss: 0.747, Test loss: 0.679, Test accuracy: 74.00
Round  53, Train loss: 0.692, Test loss: 0.663, Test accuracy: 73.27
Round  54, Train loss: 0.698, Test loss: 0.667, Test accuracy: 73.63
Round  55, Train loss: 0.811, Test loss: 0.668, Test accuracy: 74.30
Round  56, Train loss: 0.672, Test loss: 0.679, Test accuracy: 73.90
Round  57, Train loss: 0.774, Test loss: 0.698, Test accuracy: 72.47
Round  58, Train loss: 0.631, Test loss: 0.661, Test accuracy: 74.23
Round  59, Train loss: 0.544, Test loss: 0.648, Test accuracy: 75.40
Round  60, Train loss: 0.638, Test loss: 0.643, Test accuracy: 75.20
Round  61, Train loss: 0.747, Test loss: 0.676, Test accuracy: 74.00
Round  62, Train loss: 0.790, Test loss: 0.678, Test accuracy: 72.57
Round  63, Train loss: 0.639, Test loss: 0.673, Test accuracy: 73.93
Round  64, Train loss: 0.640, Test loss: 0.669, Test accuracy: 73.50
Round  65, Train loss: 0.827, Test loss: 0.667, Test accuracy: 73.87
Round  66, Train loss: 0.662, Test loss: 0.665, Test accuracy: 74.47
Round  67, Train loss: 0.581, Test loss: 0.665, Test accuracy: 73.80
Round  68, Train loss: 0.599, Test loss: 0.686, Test accuracy: 72.97
Round  69, Train loss: 0.665, Test loss: 0.662, Test accuracy: 74.73
Round  70, Train loss: 0.511, Test loss: 0.645, Test accuracy: 74.27
Round  71, Train loss: 0.629, Test loss: 0.665, Test accuracy: 73.60
Round  72, Train loss: 0.672, Test loss: 0.664, Test accuracy: 73.90
Round  73, Train loss: 0.619, Test loss: 0.636, Test accuracy: 74.47
Round  74, Train loss: 0.654, Test loss: 0.632, Test accuracy: 75.03
Round  75, Train loss: 0.700, Test loss: 0.652, Test accuracy: 74.23
Round  76, Train loss: 0.628, Test loss: 0.662, Test accuracy: 73.40
Round  77, Train loss: 0.604, Test loss: 0.643, Test accuracy: 74.17
Round  78, Train loss: 0.569, Test loss: 0.671, Test accuracy: 71.73
Round  79, Train loss: 0.626, Test loss: 0.679, Test accuracy: 72.27
Round  80, Train loss: 0.593, Test loss: 0.658, Test accuracy: 73.50
Round  81, Train loss: 0.661, Test loss: 0.666, Test accuracy: 73.03
Round  82, Train loss: 0.579, Test loss: 0.652, Test accuracy: 73.10
Round  83, Train loss: 0.680, Test loss: 0.674, Test accuracy: 72.47
Round  84, Train loss: 0.662, Test loss: 0.691, Test accuracy: 71.70
Round  85, Train loss: 0.536, Test loss: 0.680, Test accuracy: 72.40
Round  86, Train loss: 0.507, Test loss: 0.666, Test accuracy: 72.77
Round  87, Train loss: 0.525, Test loss: 0.653, Test accuracy: 74.10
Round  88, Train loss: 0.478, Test loss: 0.661, Test accuracy: 73.20
Round  89, Train loss: 0.594, Test loss: 0.661, Test accuracy: 73.20
Round  90, Train loss: 0.522, Test loss: 0.647, Test accuracy: 73.47
Round  91, Train loss: 0.606, Test loss: 0.678, Test accuracy: 72.10
Round  92, Train loss: 0.512, Test loss: 0.664, Test accuracy: 72.07
Round  93, Train loss: 0.622, Test loss: 0.667, Test accuracy: 71.87
Round  94, Train loss: 0.481, Test loss: 0.670, Test accuracy: 72.80
Round  95, Train loss: 0.516, Test loss: 0.661, Test accuracy: 72.63
Round  96, Train loss: 0.641, Test loss: 0.679, Test accuracy: 71.20
Round  97, Train loss: 0.592, Test loss: 0.685, Test accuracy: 70.53
Round  98, Train loss: 0.498, Test loss: 0.717, Test accuracy: 69.50
Round  99, Train loss: 0.336, Test loss: 0.669, Test accuracy: 71.57
Final Round, Train loss: 0.460, Test loss: 0.680, Test accuracy: 71.60
Average accuracy final 10 rounds: 71.77333333333333
300.73545956611633
[1.1967055797576904, 1.9719886779785156, 2.6979613304138184, 3.4222068786621094, 4.1396870613098145, 4.8548195362091064, 5.56721830368042, 6.27744722366333, 7.008633136749268, 7.728113651275635, 8.44433879852295, 9.163625478744507, 9.876898288726807, 10.597533941268921, 11.320034980773926, 12.039664506912231, 12.753700494766235, 13.46679139137268, 14.180600643157959, 14.899635553359985, 15.618010997772217, 16.331154584884644, 17.044482707977295, 17.76022481918335, 18.476369380950928, 19.19784665107727, 19.911842346191406, 20.62687659263611, 21.344531774520874, 22.058592796325684, 22.774330139160156, 23.487895011901855, 24.201250076293945, 24.920063734054565, 25.64030408859253, 26.369759559631348, 27.084094047546387, 27.798803091049194, 28.519768714904785, 29.240662574768066, 29.962421894073486, 30.676557302474976, 31.392855644226074, 32.109004735946655, 32.8288209438324, 33.55042862892151, 34.270166873931885, 34.98635149002075, 35.69962549209595, 36.417139530181885, 37.13606023788452, 37.856372356414795, 38.57075762748718, 39.2878839969635, 40.006802558898926, 40.72258424758911, 41.43878769874573, 42.15224838256836, 42.86672019958496, 43.620949268341064, 44.33824801445007, 45.05191969871521, 45.77006435394287, 46.485652446746826, 47.2060432434082, 47.92712712287903, 48.64438080787659, 49.358826637268066, 50.07437300682068, 50.79349660873413, 51.51491117477417, 52.23445773124695, 52.94744086265564, 53.66149044036865, 54.37759590148926, 55.09582567214966, 55.817617416381836, 56.53158783912659, 57.244863986968994, 57.96000003814697, 58.675148725509644, 59.39146685600281, 60.10821008682251, 60.8226056098938, 61.541921615600586, 62.26189422607422, 62.980576038360596, 63.69647669792175, 64.41074991226196, 65.12542867660522, 65.84678816795349, 66.56428718566895, 67.27994728088379, 67.99443221092224, 68.7087345123291, 69.42793273925781, 70.15006995201111, 70.87131071090698, 71.58562660217285, 72.30190515518188, 73.4751615524292]
[18.366666666666667, 21.466666666666665, 33.96666666666667, 31.133333333333333, 40.5, 41.93333333333333, 45.166666666666664, 57.63333333333333, 59.13333333333333, 59.9, 59.6, 57.833333333333336, 56.233333333333334, 63.666666666666664, 63.6, 64.46666666666667, 65.46666666666667, 66.66666666666667, 67.56666666666666, 69.86666666666666, 71.06666666666666, 71.73333333333333, 71.5, 70.6, 71.6, 71.96666666666667, 71.76666666666667, 71.3, 72.2, 72.06666666666666, 72.53333333333333, 73.0, 72.03333333333333, 72.43333333333334, 73.6, 72.9, 73.4, 72.96666666666667, 71.4, 71.56666666666666, 73.03333333333333, 73.4, 74.03333333333333, 74.13333333333334, 74.13333333333334, 73.26666666666667, 73.76666666666667, 73.73333333333333, 73.76666666666667, 74.33333333333333, 74.9, 73.13333333333334, 74.0, 73.26666666666667, 73.63333333333334, 74.3, 73.9, 72.46666666666667, 74.23333333333333, 75.4, 75.2, 74.0, 72.56666666666666, 73.93333333333334, 73.5, 73.86666666666666, 74.46666666666667, 73.8, 72.96666666666667, 74.73333333333333, 74.26666666666667, 73.6, 73.9, 74.46666666666667, 75.03333333333333, 74.23333333333333, 73.4, 74.16666666666667, 71.73333333333333, 72.26666666666667, 73.5, 73.03333333333333, 73.1, 72.46666666666667, 71.7, 72.4, 72.76666666666667, 74.1, 73.2, 73.2, 73.46666666666667, 72.1, 72.06666666666666, 71.86666666666666, 72.8, 72.63333333333334, 71.2, 70.53333333333333, 69.5, 71.56666666666666, 71.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.400, Test loss: 1.406, Test accuracy: 43.27
Round   1, Train loss: 1.036, Test loss: 0.999, Test accuracy: 52.30
Round   2, Train loss: 0.969, Test loss: 0.941, Test accuracy: 56.20
Round   3, Train loss: 0.933, Test loss: 0.885, Test accuracy: 59.90
Round   4, Train loss: 0.904, Test loss: 0.836, Test accuracy: 63.50
Round   5, Train loss: 0.881, Test loss: 0.800, Test accuracy: 67.27
Round   6, Train loss: 0.862, Test loss: 0.790, Test accuracy: 67.77
Round   7, Train loss: 0.845, Test loss: 0.787, Test accuracy: 65.07
Round   8, Train loss: 0.833, Test loss: 0.763, Test accuracy: 68.93
Round   9, Train loss: 0.817, Test loss: 0.753, Test accuracy: 69.53
Round  10, Train loss: 0.806, Test loss: 0.745, Test accuracy: 70.43
Round  11, Train loss: 0.790, Test loss: 0.738, Test accuracy: 70.77
Round  12, Train loss: 0.780, Test loss: 0.731, Test accuracy: 70.97
Round  13, Train loss: 0.765, Test loss: 0.716, Test accuracy: 72.67
Round  14, Train loss: 0.754, Test loss: 0.730, Test accuracy: 70.30
Round  15, Train loss: 0.742, Test loss: 0.706, Test accuracy: 70.50
Round  16, Train loss: 0.730, Test loss: 0.693, Test accuracy: 72.00
Round  17, Train loss: 0.713, Test loss: 0.706, Test accuracy: 69.97
Round  18, Train loss: 0.705, Test loss: 0.712, Test accuracy: 71.37
Round  19, Train loss: 0.688, Test loss: 0.683, Test accuracy: 72.43
Round  20, Train loss: 0.474, Test loss: 0.716, Test accuracy: 69.40
Round  21, Train loss: 0.783, Test loss: 0.709, Test accuracy: 70.33
Round  22, Train loss: 0.602, Test loss: 0.700, Test accuracy: 71.13
Round  23, Train loss: 0.688, Test loss: 0.713, Test accuracy: 69.33
Round  24, Train loss: 0.573, Test loss: 0.704, Test accuracy: 71.47
Round  25, Train loss: 0.376, Test loss: 0.682, Test accuracy: 71.80
Round  26, Train loss: 0.664, Test loss: 0.717, Test accuracy: 69.93
Round  27, Train loss: 0.666, Test loss: 0.707, Test accuracy: 70.67
Round  28, Train loss: 0.442, Test loss: 0.696, Test accuracy: 71.70
Round  29, Train loss: 0.642, Test loss: 0.693, Test accuracy: 72.60
Round  30, Train loss: 0.524, Test loss: 0.704, Test accuracy: 71.33
Round  31, Train loss: 0.608, Test loss: 0.725, Test accuracy: 70.00
Round  32, Train loss: 0.629, Test loss: 0.757, Test accuracy: 69.30
Round  33, Train loss: 0.583, Test loss: 0.724, Test accuracy: 70.63
Round  34, Train loss: 0.669, Test loss: 0.707, Test accuracy: 71.20
Round  35, Train loss: 0.435, Test loss: 0.727, Test accuracy: 69.97
Round  36, Train loss: 0.577, Test loss: 0.733, Test accuracy: 70.20
Round  37, Train loss: 0.385, Test loss: 0.754, Test accuracy: 70.13
Round  38, Train loss: 0.456, Test loss: 0.755, Test accuracy: 69.13
Round  39, Train loss: 0.459, Test loss: 0.752, Test accuracy: 69.03
Round  40, Train loss: 0.374, Test loss: 0.733, Test accuracy: 70.50
Round  41, Train loss: 0.456, Test loss: 0.767, Test accuracy: 70.23
Round  42, Train loss: 0.336, Test loss: 0.728, Test accuracy: 71.20
Round  43, Train loss: 0.479, Test loss: 0.767, Test accuracy: 69.30
Round  44, Train loss: 0.581, Test loss: 0.817, Test accuracy: 68.27
Round  45, Train loss: 0.576, Test loss: 0.813, Test accuracy: 68.60
Round  46, Train loss: 0.479, Test loss: 0.814, Test accuracy: 68.17
Round  47, Train loss: 0.290, Test loss: 0.776, Test accuracy: 70.67
Round  48, Train loss: 0.403, Test loss: 0.789, Test accuracy: 69.07
Round  49, Train loss: 0.356, Test loss: 0.839, Test accuracy: 68.57
Round  50, Train loss: 0.405, Test loss: 0.833, Test accuracy: 68.10
Round  51, Train loss: 0.253, Test loss: 0.859, Test accuracy: 68.23
Round  52, Train loss: 0.440, Test loss: 0.771, Test accuracy: 69.97
Round  53, Train loss: 0.312, Test loss: 0.771, Test accuracy: 70.27
Round  54, Train loss: 0.241, Test loss: 0.801, Test accuracy: 70.47
Round  55, Train loss: 0.319, Test loss: 0.840, Test accuracy: 68.20
Round  56, Train loss: 0.206, Test loss: 0.841, Test accuracy: 69.37
Round  57, Train loss: 0.330, Test loss: 0.816, Test accuracy: 69.80
Round  58, Train loss: 0.245, Test loss: 0.830, Test accuracy: 68.20
Round  59, Train loss: 0.271, Test loss: 0.844, Test accuracy: 68.50
Round  60, Train loss: 0.299, Test loss: 0.851, Test accuracy: 67.97
Round  61, Train loss: 0.274, Test loss: 0.844, Test accuracy: 68.60
Round  62, Train loss: 0.382, Test loss: 0.855, Test accuracy: 67.40
Round  63, Train loss: 0.335, Test loss: 0.877, Test accuracy: 67.23
Round  64, Train loss: 0.239, Test loss: 0.827, Test accuracy: 69.83
Round  65, Train loss: 0.402, Test loss: 0.912, Test accuracy: 68.10
Round  66, Train loss: 0.366, Test loss: 0.936, Test accuracy: 65.90
Round  67, Train loss: 0.250, Test loss: 0.924, Test accuracy: 66.40
Round  68, Train loss: 0.183, Test loss: 0.899, Test accuracy: 67.50
Round  69, Train loss: 0.357, Test loss: 0.947, Test accuracy: 67.47
Round  70, Train loss: 0.259, Test loss: 0.927, Test accuracy: 68.30
Round  71, Train loss: 0.303, Test loss: 0.939, Test accuracy: 67.67
Round  72, Train loss: 0.290, Test loss: 0.935, Test accuracy: 67.30
Round  73, Train loss: 0.221, Test loss: 0.917, Test accuracy: 67.63
Round  74, Train loss: 0.294, Test loss: 0.923, Test accuracy: 67.90
Round  75, Train loss: 0.227, Test loss: 0.937, Test accuracy: 67.97
Round  76, Train loss: 0.251, Test loss: 0.946, Test accuracy: 68.00
Round  77, Train loss: 0.254, Test loss: 0.979, Test accuracy: 66.80
Round  78, Train loss: 0.177, Test loss: 1.008, Test accuracy: 67.40
Round  79, Train loss: 0.253, Test loss: 0.992, Test accuracy: 67.20
Round  80, Train loss: 0.222, Test loss: 0.975, Test accuracy: 67.47
Round  81, Train loss: 0.201, Test loss: 0.953, Test accuracy: 67.93
Round  82, Train loss: 0.199, Test loss: 0.999, Test accuracy: 66.87
Round  83, Train loss: 0.185, Test loss: 0.982, Test accuracy: 67.57
Round  84, Train loss: 0.182, Test loss: 0.969, Test accuracy: 68.67
Round  85, Train loss: 0.173, Test loss: 0.988, Test accuracy: 68.33
Round  86, Train loss: 0.177, Test loss: 0.985, Test accuracy: 67.27
Round  87, Train loss: 0.159, Test loss: 1.002, Test accuracy: 67.10
Round  88, Train loss: 0.157, Test loss: 1.007, Test accuracy: 67.40
Round  89, Train loss: 0.162, Test loss: 1.028, Test accuracy: 67.67
Round  90, Train loss: 0.157, Test loss: 1.025, Test accuracy: 67.77
Round  91, Train loss: 0.154, Test loss: 1.012, Test accuracy: 67.80
Round  92, Train loss: 0.153, Test loss: 1.031, Test accuracy: 67.93
Round  93, Train loss: 0.135, Test loss: 1.042, Test accuracy: 67.43
Round  94, Train loss: 0.148, Test loss: 1.038, Test accuracy: 67.17
Round  95, Train loss: 0.134, Test loss: 1.053, Test accuracy: 67.10
Round  96, Train loss: 0.155, Test loss: 1.054, Test accuracy: 67.47
Round  97, Train loss: 0.147, Test loss: 1.054, Test accuracy: 67.67
Round  98, Train loss: 0.136, Test loss: 1.041, Test accuracy: 67.53
Round  99, Train loss: 0.121, Test loss: 1.070, Test accuracy: 67.50
Final Round, Train loss: 0.110, Test loss: 1.090, Test accuracy: 67.37
Average accuracy final 10 rounds: 67.53666666666666
1012.3220994472504
[1.891735315322876, 3.5926458835601807, 5.277913808822632, 6.9671008586883545, 8.64746904373169, 10.326371669769287, 12.01262092590332, 13.699786186218262, 15.383171558380127, 17.071231365203857, 18.76160740852356, 20.461172342300415, 22.159619569778442, 23.8584725856781, 25.558671474456787, 27.251051425933838, 28.94441843032837, 30.645060539245605, 32.34271192550659, 34.03557753562927, 35.73496103286743, 37.4265034198761, 39.111897468566895, 40.81260323524475, 42.510990381240845, 44.19628095626831, 45.88448977470398, 47.560370206832886, 49.24717354774475, 50.93970799446106, 52.619332790374756, 54.29929780960083, 55.96058893203735, 57.62236666679382, 59.27855610847473, 60.92590522766113, 62.57392430305481, 64.21618413925171, 65.66354131698608, 67.11002087593079, 68.55457067489624, 69.99950814247131, 71.45124650001526, 72.89686226844788, 74.34092903137207, 75.78171634674072, 77.21809577941895, 78.662113904953, 80.09530591964722, 81.52423453330994, 82.9772560596466, 84.42022681236267, 85.85917639732361, 87.3098030090332, 88.74354314804077, 90.17257046699524, 91.60596036911011, 93.04295897483826, 94.48288679122925, 95.92742490768433, 97.37281084060669, 98.81485199928284, 100.26185965538025, 101.70329642295837, 103.15313172340393, 104.5968930721283, 106.03971815109253, 107.48530125617981, 109.13336658477783, 110.79304027557373, 112.44379377365112, 114.08498525619507, 115.71695590019226, 117.38189458847046, 119.04533123970032, 120.61031484603882, 122.04492712020874, 123.47984099388123, 124.91804599761963, 126.35057783126831, 127.79718494415283, 129.23844838142395, 130.67924666404724, 132.1226453781128, 133.5640206336975, 135.01014828681946, 136.45963382720947, 137.8989074230194, 139.33752942085266, 140.7720685005188, 142.21663451194763, 143.84900784492493, 145.48207926750183, 147.11233115196228, 148.75028347969055, 150.3892412185669, 152.028400182724, 153.67427968978882, 155.3107624053955, 156.94939923286438, 159.39546918869019]
[43.266666666666666, 52.3, 56.2, 59.9, 63.5, 67.26666666666667, 67.76666666666667, 65.06666666666666, 68.93333333333334, 69.53333333333333, 70.43333333333334, 70.76666666666667, 70.96666666666667, 72.66666666666667, 70.3, 70.5, 72.0, 69.96666666666667, 71.36666666666666, 72.43333333333334, 69.4, 70.33333333333333, 71.13333333333334, 69.33333333333333, 71.46666666666667, 71.8, 69.93333333333334, 70.66666666666667, 71.7, 72.6, 71.33333333333333, 70.0, 69.3, 70.63333333333334, 71.2, 69.96666666666667, 70.2, 70.13333333333334, 69.13333333333334, 69.03333333333333, 70.5, 70.23333333333333, 71.2, 69.3, 68.26666666666667, 68.6, 68.16666666666667, 70.66666666666667, 69.06666666666666, 68.56666666666666, 68.1, 68.23333333333333, 69.96666666666667, 70.26666666666667, 70.46666666666667, 68.2, 69.36666666666666, 69.8, 68.2, 68.5, 67.96666666666667, 68.6, 67.4, 67.23333333333333, 69.83333333333333, 68.1, 65.9, 66.4, 67.5, 67.46666666666667, 68.3, 67.66666666666667, 67.3, 67.63333333333334, 67.9, 67.96666666666667, 68.0, 66.8, 67.4, 67.2, 67.46666666666667, 67.93333333333334, 66.86666666666666, 67.56666666666666, 68.66666666666667, 68.33333333333333, 67.26666666666667, 67.1, 67.4, 67.66666666666667, 67.76666666666667, 67.8, 67.93333333333334, 67.43333333333334, 67.16666666666667, 67.1, 67.46666666666667, 67.66666666666667, 67.53333333333333, 67.5, 67.36666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.415, Test loss: 1.446, Test accuracy: 37.43
Round   1, Train loss: 1.048, Test loss: 1.007, Test accuracy: 53.00
Round   2, Train loss: 0.962, Test loss: 0.923, Test accuracy: 59.40
Round   3, Train loss: 0.924, Test loss: 0.890, Test accuracy: 58.90
Round   4, Train loss: 0.887, Test loss: 0.858, Test accuracy: 62.17
Round   5, Train loss: 0.864, Test loss: 0.792, Test accuracy: 66.93
Round   6, Train loss: 0.842, Test loss: 0.789, Test accuracy: 66.20
Round   7, Train loss: 0.827, Test loss: 0.760, Test accuracy: 69.77
Round   8, Train loss: 0.807, Test loss: 0.751, Test accuracy: 68.43
Round   9, Train loss: 0.795, Test loss: 0.732, Test accuracy: 69.63
Round  10, Train loss: 0.779, Test loss: 0.718, Test accuracy: 70.60
Round  11, Train loss: 0.768, Test loss: 0.737, Test accuracy: 70.13
Round  12, Train loss: 0.754, Test loss: 0.725, Test accuracy: 70.83
Round  13, Train loss: 0.742, Test loss: 0.716, Test accuracy: 70.70
Round  14, Train loss: 0.726, Test loss: 0.721, Test accuracy: 70.70
Round  15, Train loss: 0.716, Test loss: 0.681, Test accuracy: 73.07
Round  16, Train loss: 0.703, Test loss: 0.699, Test accuracy: 71.03
Round  17, Train loss: 0.689, Test loss: 0.699, Test accuracy: 70.83
Round  18, Train loss: 0.677, Test loss: 0.678, Test accuracy: 73.13
Round  19, Train loss: 0.664, Test loss: 0.663, Test accuracy: 73.13
Round  20, Train loss: 0.486, Test loss: 0.675, Test accuracy: 72.33
Round  21, Train loss: 0.731, Test loss: 0.683, Test accuracy: 72.23
Round  22, Train loss: 0.735, Test loss: 0.715, Test accuracy: 70.27
Round  23, Train loss: 0.577, Test loss: 0.678, Test accuracy: 72.20
Round  24, Train loss: 0.634, Test loss: 0.687, Test accuracy: 71.80
Round  25, Train loss: 0.511, Test loss: 0.692, Test accuracy: 71.90
Round  26, Train loss: 0.425, Test loss: 0.666, Test accuracy: 72.77
Round  27, Train loss: 0.593, Test loss: 0.683, Test accuracy: 72.50
Round  28, Train loss: 0.494, Test loss: 0.644, Test accuracy: 73.90
Round  29, Train loss: 0.508, Test loss: 0.667, Test accuracy: 73.00
Round  30, Train loss: 0.700, Test loss: 0.728, Test accuracy: 69.60
Round  31, Train loss: 0.443, Test loss: 0.677, Test accuracy: 72.77
Round  32, Train loss: 0.404, Test loss: 0.686, Test accuracy: 72.90
Round  33, Train loss: 0.536, Test loss: 0.682, Test accuracy: 72.63
Round  34, Train loss: 0.657, Test loss: 0.705, Test accuracy: 71.97
Round  35, Train loss: 0.456, Test loss: 0.697, Test accuracy: 71.17
Round  36, Train loss: 0.485, Test loss: 0.712, Test accuracy: 70.77
Round  37, Train loss: 0.301, Test loss: 0.714, Test accuracy: 71.37
Round  38, Train loss: 0.401, Test loss: 0.687, Test accuracy: 72.87
Round  39, Train loss: 0.384, Test loss: 0.687, Test accuracy: 73.27
Round  40, Train loss: 0.395, Test loss: 0.686, Test accuracy: 71.70
Round  41, Train loss: 0.350, Test loss: 0.735, Test accuracy: 70.67
Round  42, Train loss: 0.488, Test loss: 0.742, Test accuracy: 70.13
Round  43, Train loss: 0.388, Test loss: 0.739, Test accuracy: 71.00
Round  44, Train loss: 0.495, Test loss: 0.767, Test accuracy: 70.53
Round  45, Train loss: 0.490, Test loss: 0.760, Test accuracy: 70.27
Round  46, Train loss: 0.452, Test loss: 0.732, Test accuracy: 72.20
Round  47, Train loss: 0.337, Test loss: 0.745, Test accuracy: 71.73
Round  48, Train loss: 0.335, Test loss: 0.730, Test accuracy: 71.73
Round  49, Train loss: 0.289, Test loss: 0.747, Test accuracy: 71.80
Round  50, Train loss: 0.345, Test loss: 0.743, Test accuracy: 71.70
Round  51, Train loss: 0.177, Test loss: 0.717, Test accuracy: 73.33
Round  52, Train loss: 0.444, Test loss: 0.735, Test accuracy: 72.50
Round  53, Train loss: 0.408, Test loss: 0.767, Test accuracy: 70.33
Round  54, Train loss: 0.256, Test loss: 0.753, Test accuracy: 70.97
Round  55, Train loss: 0.260, Test loss: 0.744, Test accuracy: 72.07
Round  56, Train loss: 0.218, Test loss: 0.770, Test accuracy: 71.53
Round  57, Train loss: 0.378, Test loss: 0.781, Test accuracy: 71.10
Round  58, Train loss: 0.300, Test loss: 0.764, Test accuracy: 71.77
Round  59, Train loss: 0.299, Test loss: 0.771, Test accuracy: 70.33
Round  60, Train loss: 0.317, Test loss: 0.823, Test accuracy: 68.53
Round  61, Train loss: 0.340, Test loss: 0.815, Test accuracy: 68.67
Round  62, Train loss: 0.413, Test loss: 0.838, Test accuracy: 68.07
Round  63, Train loss: 0.386, Test loss: 0.891, Test accuracy: 66.63
Round  64, Train loss: 0.297, Test loss: 0.816, Test accuracy: 69.20
Round  65, Train loss: 0.349, Test loss: 0.870, Test accuracy: 68.73
Round  66, Train loss: 0.404, Test loss: 0.897, Test accuracy: 67.53
Round  67, Train loss: 0.291, Test loss: 0.865, Test accuracy: 68.07
Round  68, Train loss: 0.189, Test loss: 0.865, Test accuracy: 69.00
Round  69, Train loss: 0.390, Test loss: 0.946, Test accuracy: 66.93
Round  70, Train loss: 0.384, Test loss: 0.960, Test accuracy: 64.70
Round  71, Train loss: 0.321, Test loss: 0.937, Test accuracy: 66.03
Round  72, Train loss: 0.297, Test loss: 0.904, Test accuracy: 67.23
Round  73, Train loss: 0.252, Test loss: 0.918, Test accuracy: 67.70
Round  74, Train loss: 0.312, Test loss: 0.912, Test accuracy: 67.40
Round  75, Train loss: 0.238, Test loss: 0.960, Test accuracy: 68.50
Round  76, Train loss: 0.201, Test loss: 0.865, Test accuracy: 68.33
Round  77, Train loss: 0.260, Test loss: 0.940, Test accuracy: 67.73
Round  78, Train loss: 0.224, Test loss: 0.972, Test accuracy: 66.90
Round  79, Train loss: 0.231, Test loss: 0.915, Test accuracy: 67.80
Round  80, Train loss: 0.246, Test loss: 0.896, Test accuracy: 68.83
Round  81, Train loss: 0.222, Test loss: 0.908, Test accuracy: 69.17
Round  82, Train loss: 0.201, Test loss: 0.910, Test accuracy: 68.97
Round  83, Train loss: 0.201, Test loss: 0.922, Test accuracy: 68.63
Round  84, Train loss: 0.209, Test loss: 0.941, Test accuracy: 67.93
Round  85, Train loss: 0.196, Test loss: 0.930, Test accuracy: 69.20
Round  86, Train loss: 0.182, Test loss: 0.966, Test accuracy: 68.43
Round  87, Train loss: 0.184, Test loss: 0.964, Test accuracy: 67.77
Round  88, Train loss: 0.184, Test loss: 0.977, Test accuracy: 68.23
Round  89, Train loss: 0.186, Test loss: 0.974, Test accuracy: 67.97
Round  90, Train loss: 0.164, Test loss: 0.982, Test accuracy: 68.10
Round  91, Train loss: 0.167, Test loss: 0.983, Test accuracy: 67.33
Round  92, Train loss: 0.158, Test loss: 0.983, Test accuracy: 67.60
Round  93, Train loss: 0.159, Test loss: 0.979, Test accuracy: 67.37
Round  94, Train loss: 0.156, Test loss: 0.993, Test accuracy: 67.63
Round  95, Train loss: 0.162, Test loss: 0.983, Test accuracy: 67.97
Round  96, Train loss: 0.150, Test loss: 0.990, Test accuracy: 67.67
Round  97, Train loss: 0.153, Test loss: 1.008, Test accuracy: 67.73
Round  98, Train loss: 0.145, Test loss: 1.006, Test accuracy: 67.67
Round  99, Train loss: 0.140, Test loss: 1.015, Test accuracy: 68.03
Final Round, Train loss: 0.118, Test loss: 1.034, Test accuracy: 67.70
Average accuracy final 10 rounds: 67.71
1442.1731224060059
[1.9070558547973633, 3.453331470489502, 4.99866247177124, 6.542535066604614, 8.089797735214233, 9.643859148025513, 11.199984312057495, 12.754937171936035, 14.31075119972229, 15.869279384613037, 17.42929744720459, 18.986544132232666, 20.54386067390442, 22.085204362869263, 23.578673124313354, 25.069780349731445, 26.5620059967041, 28.10820245742798, 29.656183004379272, 31.200932502746582, 32.73823571205139, 35.53274846076965, 38.28699994087219, 41.04694652557373, 43.85120177268982, 46.636215686798096, 49.408674240112305, 52.257631063461304, 55.07239007949829, 57.87305045127869, 60.72882914543152, 63.540759801864624, 66.34965705871582, 69.17130494117737, 71.96617436408997, 74.69711112976074, 77.54464364051819, 80.32567095756531, 83.14699983596802, 85.99473524093628, 88.79483461380005, 91.63206958770752, 94.42071223258972, 97.24818015098572, 100.06847715377808, 102.92292952537537, 105.69799852371216, 108.46699786186218, 111.2898440361023, 114.04551601409912, 116.80118823051453, 119.62557721138, 122.44011306762695, 125.22612023353577, 128.06672310829163, 130.861319065094, 133.67359232902527, 136.45625519752502, 139.23683524131775, 141.98215579986572, 144.78370022773743, 147.60867643356323, 150.41704845428467, 153.19391870498657, 156.01864433288574, 158.80374336242676, 161.60002160072327, 164.43222641944885, 167.1949634552002, 170.01659107208252, 172.8004710674286, 175.61793613433838, 178.43454384803772, 181.1949384212494, 183.97746300697327, 186.7993757724762, 189.5882408618927, 192.3711495399475, 195.16708278656006, 197.95415329933167, 200.79028797149658, 203.59796357154846, 206.43122577667236, 209.2648708820343, 212.08178210258484, 214.90935516357422, 217.70885038375854, 220.52478170394897, 223.33397841453552, 226.14227056503296, 228.9621250629425, 231.78192687034607, 234.5919964313507, 237.39763522148132, 240.22717094421387, 243.04638171195984, 245.86136627197266, 248.64653038978577, 251.32354021072388, 254.00087714195251, 256.2757363319397]
[37.43333333333333, 53.0, 59.4, 58.9, 62.166666666666664, 66.93333333333334, 66.2, 69.76666666666667, 68.43333333333334, 69.63333333333334, 70.6, 70.13333333333334, 70.83333333333333, 70.7, 70.7, 73.06666666666666, 71.03333333333333, 70.83333333333333, 73.13333333333334, 73.13333333333334, 72.33333333333333, 72.23333333333333, 70.26666666666667, 72.2, 71.8, 71.9, 72.76666666666667, 72.5, 73.9, 73.0, 69.6, 72.76666666666667, 72.9, 72.63333333333334, 71.96666666666667, 71.16666666666667, 70.76666666666667, 71.36666666666666, 72.86666666666666, 73.26666666666667, 71.7, 70.66666666666667, 70.13333333333334, 71.0, 70.53333333333333, 70.26666666666667, 72.2, 71.73333333333333, 71.73333333333333, 71.8, 71.7, 73.33333333333333, 72.5, 70.33333333333333, 70.96666666666667, 72.06666666666666, 71.53333333333333, 71.1, 71.76666666666667, 70.33333333333333, 68.53333333333333, 68.66666666666667, 68.06666666666666, 66.63333333333334, 69.2, 68.73333333333333, 67.53333333333333, 68.06666666666666, 69.0, 66.93333333333334, 64.7, 66.03333333333333, 67.23333333333333, 67.7, 67.4, 68.5, 68.33333333333333, 67.73333333333333, 66.9, 67.8, 68.83333333333333, 69.16666666666667, 68.96666666666667, 68.63333333333334, 67.93333333333334, 69.2, 68.43333333333334, 67.76666666666667, 68.23333333333333, 67.96666666666667, 68.1, 67.33333333333333, 67.6, 67.36666666666666, 67.63333333333334, 67.96666666666667, 67.66666666666667, 67.73333333333333, 67.66666666666667, 68.03333333333333, 67.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.433, Test loss: 1.474, Test accuracy: 40.23
Round   1, Train loss: 1.040, Test loss: 1.002, Test accuracy: 54.03
Round   2, Train loss: 0.957, Test loss: 0.920, Test accuracy: 58.23
Round   3, Train loss: 0.911, Test loss: 0.883, Test accuracy: 59.33
Round   4, Train loss: 0.881, Test loss: 0.858, Test accuracy: 62.73
Round   5, Train loss: 0.856, Test loss: 0.798, Test accuracy: 67.10
Round   6, Train loss: 0.833, Test loss: 0.810, Test accuracy: 63.70
Round   7, Train loss: 0.817, Test loss: 0.767, Test accuracy: 68.83
Round   8, Train loss: 0.798, Test loss: 0.739, Test accuracy: 69.87
Round   9, Train loss: 0.784, Test loss: 0.747, Test accuracy: 68.13
Round  10, Train loss: 0.774, Test loss: 0.718, Test accuracy: 70.10
Round  11, Train loss: 0.758, Test loss: 0.731, Test accuracy: 69.97
Round  12, Train loss: 0.744, Test loss: 0.710, Test accuracy: 70.93
Round  13, Train loss: 0.734, Test loss: 0.706, Test accuracy: 71.70
Round  14, Train loss: 0.725, Test loss: 0.703, Test accuracy: 70.90
Round  15, Train loss: 0.708, Test loss: 0.699, Test accuracy: 71.33
Round  16, Train loss: 0.697, Test loss: 0.687, Test accuracy: 71.60
Round  17, Train loss: 0.683, Test loss: 0.704, Test accuracy: 71.07
Round  18, Train loss: 0.671, Test loss: 0.687, Test accuracy: 71.47
Round  19, Train loss: 0.657, Test loss: 0.674, Test accuracy: 72.20
Round  20, Train loss: 0.480, Test loss: 0.689, Test accuracy: 71.27
Round  21, Train loss: 0.838, Test loss: 0.688, Test accuracy: 71.23
Round  22, Train loss: 0.629, Test loss: 0.705, Test accuracy: 69.87
Round  23, Train loss: 0.788, Test loss: 0.703, Test accuracy: 70.00
Round  24, Train loss: 0.489, Test loss: 0.699, Test accuracy: 71.57
Round  25, Train loss: 0.512, Test loss: 0.684, Test accuracy: 71.53
Round  26, Train loss: 0.500, Test loss: 0.687, Test accuracy: 71.50
Round  27, Train loss: 0.625, Test loss: 0.695, Test accuracy: 70.57
Round  28, Train loss: 0.630, Test loss: 0.703, Test accuracy: 70.63
Round  29, Train loss: 0.709, Test loss: 0.697, Test accuracy: 70.97
Round  30, Train loss: 0.584, Test loss: 0.699, Test accuracy: 70.90
Round  31, Train loss: 0.526, Test loss: 0.691, Test accuracy: 71.57
Round  32, Train loss: 0.504, Test loss: 0.712, Test accuracy: 70.93
Round  33, Train loss: 0.538, Test loss: 0.729, Test accuracy: 69.90
Round  34, Train loss: 0.511, Test loss: 0.734, Test accuracy: 69.83
Round  35, Train loss: 0.424, Test loss: 0.732, Test accuracy: 70.40
Round  36, Train loss: 0.375, Test loss: 0.704, Test accuracy: 71.53
Round  37, Train loss: 0.429, Test loss: 0.726, Test accuracy: 70.63
Round  38, Train loss: 0.570, Test loss: 0.761, Test accuracy: 69.30
Round  39, Train loss: 0.259, Test loss: 0.744, Test accuracy: 71.13
Round  40, Train loss: 0.528, Test loss: 0.738, Test accuracy: 70.63
Round  41, Train loss: 0.544, Test loss: 0.761, Test accuracy: 71.00
Round  42, Train loss: 0.474, Test loss: 0.734, Test accuracy: 70.37
Round  43, Train loss: 0.493, Test loss: 0.744, Test accuracy: 70.37
Round  44, Train loss: 0.593, Test loss: 0.786, Test accuracy: 69.27
Round  45, Train loss: 0.432, Test loss: 0.823, Test accuracy: 68.60
Round  46, Train loss: 0.482, Test loss: 0.782, Test accuracy: 69.20
Round  47, Train loss: 0.354, Test loss: 0.804, Test accuracy: 69.70
Round  48, Train loss: 0.422, Test loss: 0.801, Test accuracy: 69.27
Round  49, Train loss: 0.383, Test loss: 0.797, Test accuracy: 69.80
Round  50, Train loss: 0.387, Test loss: 0.816, Test accuracy: 69.43
Round  51, Train loss: 0.259, Test loss: 0.824, Test accuracy: 69.53
Round  52, Train loss: 0.461, Test loss: 0.851, Test accuracy: 67.47
Round  53, Train loss: 0.370, Test loss: 0.830, Test accuracy: 69.03
Round  54, Train loss: 0.355, Test loss: 0.825, Test accuracy: 68.93
Round  55, Train loss: 0.358, Test loss: 0.877, Test accuracy: 69.20
Round  56, Train loss: 0.298, Test loss: 0.872, Test accuracy: 67.03
Round  57, Train loss: 0.462, Test loss: 0.863, Test accuracy: 66.70
Round  58, Train loss: 0.226, Test loss: 0.828, Test accuracy: 69.07
Round  59, Train loss: 0.207, Test loss: 0.827, Test accuracy: 68.53
Round  60, Train loss: 0.261, Test loss: 0.856, Test accuracy: 68.23
Round  61, Train loss: 0.402, Test loss: 0.860, Test accuracy: 67.27
Round  62, Train loss: 0.433, Test loss: 0.897, Test accuracy: 66.87
Round  63, Train loss: 0.310, Test loss: 0.907, Test accuracy: 67.30
Round  64, Train loss: 0.281, Test loss: 0.847, Test accuracy: 68.40
Round  65, Train loss: 0.418, Test loss: 0.884, Test accuracy: 67.57
Round  66, Train loss: 0.306, Test loss: 0.890, Test accuracy: 67.63
Round  67, Train loss: 0.224, Test loss: 0.908, Test accuracy: 66.77
Round  68, Train loss: 0.217, Test loss: 0.873, Test accuracy: 68.47
Round  69, Train loss: 0.324, Test loss: 0.892, Test accuracy: 68.10
Round  70, Train loss: 0.224, Test loss: 0.861, Test accuracy: 68.17
Round  71, Train loss: 0.232, Test loss: 0.868, Test accuracy: 69.50
Round  72, Train loss: 0.320, Test loss: 0.858, Test accuracy: 68.07
Round  73, Train loss: 0.270, Test loss: 0.907, Test accuracy: 67.67
Round  74, Train loss: 0.287, Test loss: 0.865, Test accuracy: 68.97
Round  75, Train loss: 0.310, Test loss: 0.954, Test accuracy: 66.73
Round  76, Train loss: 0.197, Test loss: 0.913, Test accuracy: 68.23
Round  77, Train loss: 0.236, Test loss: 0.923, Test accuracy: 67.20
Round  78, Train loss: 0.182, Test loss: 0.952, Test accuracy: 68.33
Round  79, Train loss: 0.232, Test loss: 0.919, Test accuracy: 68.03
Round  80, Train loss: 0.217, Test loss: 0.896, Test accuracy: 68.87
Round  81, Train loss: 0.203, Test loss: 0.920, Test accuracy: 68.93
Round  82, Train loss: 0.186, Test loss: 0.905, Test accuracy: 68.87
Round  83, Train loss: 0.178, Test loss: 0.921, Test accuracy: 68.50
Round  84, Train loss: 0.186, Test loss: 0.940, Test accuracy: 68.37
Round  85, Train loss: 0.173, Test loss: 0.939, Test accuracy: 68.17
Round  86, Train loss: 0.171, Test loss: 0.954, Test accuracy: 67.57
Round  87, Train loss: 0.163, Test loss: 0.955, Test accuracy: 67.67
Round  88, Train loss: 0.158, Test loss: 0.989, Test accuracy: 67.23
Round  89, Train loss: 0.157, Test loss: 0.969, Test accuracy: 67.80
Round  90, Train loss: 0.154, Test loss: 0.960, Test accuracy: 67.60
Round  91, Train loss: 0.157, Test loss: 0.946, Test accuracy: 67.60
Round  92, Train loss: 0.150, Test loss: 0.959, Test accuracy: 68.17
Round  93, Train loss: 0.149, Test loss: 0.963, Test accuracy: 68.30
Round  94, Train loss: 0.141, Test loss: 0.970, Test accuracy: 68.63
Round  95, Train loss: 0.149, Test loss: 0.982, Test accuracy: 67.30
Round  96, Train loss: 0.134, Test loss: 0.997, Test accuracy: 67.10
Round  97, Train loss: 0.124, Test loss: 1.014, Test accuracy: 68.00
Round  98, Train loss: 0.138, Test loss: 1.010, Test accuracy: 67.43
Round  99, Train loss: 0.134, Test loss: 1.008, Test accuracy: 67.23
Final Round, Train loss: 0.110, Test loss: 1.028, Test accuracy: 67.63
Average accuracy final 10 rounds: 67.73666666666666
1388.4925909042358
[1.9380133152008057, 3.516226291656494, 4.948262691497803, 6.3802995681762695, 7.8106114864349365, 9.240373849868774, 10.683582305908203, 12.120672941207886, 13.566380977630615, 15.01002836227417, 16.453742742538452, 17.891135454177856, 19.33484673500061, 20.777863264083862, 22.224387884140015, 23.660192012786865, 25.10310649871826, 26.543193101882935, 27.985474586486816, 29.427845001220703, 30.851181507110596, 33.55016374588013, 36.22819995880127, 38.91029405593872, 41.5906035900116, 44.22699451446533, 46.93948006629944, 49.621042251586914, 52.348236083984375, 55.00416278839111, 57.63358783721924, 60.33534789085388, 62.98082208633423, 65.70346593856812, 68.36315178871155, 71.03295564651489, 73.72045993804932, 76.3500599861145, 79.07425212860107, 81.72062587738037, 84.3827166557312, 87.06182885169983, 89.7393786907196, 92.43100166320801, 95.12605261802673, 97.7759051322937, 100.45586276054382, 103.12496638298035, 105.80500555038452, 108.50400638580322, 111.12097692489624, 113.81290578842163, 116.4854588508606, 119.1846776008606, 121.89097332954407, 124.48483896255493, 127.199627161026, 129.88117337226868, 132.5824372768402, 135.2873251438141, 137.94389033317566, 140.63246774673462, 143.25955057144165, 145.98042058944702, 148.6574568748474, 151.35607504844666, 154.02208280563354, 156.6050000190735, 159.32748675346375, 161.95339226722717, 164.67408061027527, 167.37666988372803, 170.10582041740417, 172.80373239517212, 175.41381525993347, 178.12992930412292, 180.72637701034546, 183.4417748451233, 186.13582277297974, 188.78545880317688, 191.47836828231812, 194.16209435462952, 196.8812198638916, 199.58739042282104, 202.28804659843445, 205.00572514533997, 207.80351400375366, 210.6094789505005, 213.41720986366272, 216.22023963928223, 219.01448106765747, 221.8064432144165, 224.5969202518463, 227.388418674469, 230.17983174324036, 232.96917271614075, 235.76069951057434, 238.5501742362976, 241.33003211021423, 244.1246781349182, 246.4598729610443]
[40.233333333333334, 54.03333333333333, 58.233333333333334, 59.333333333333336, 62.733333333333334, 67.1, 63.7, 68.83333333333333, 69.86666666666666, 68.13333333333334, 70.1, 69.96666666666667, 70.93333333333334, 71.7, 70.9, 71.33333333333333, 71.6, 71.06666666666666, 71.46666666666667, 72.2, 71.26666666666667, 71.23333333333333, 69.86666666666666, 70.0, 71.56666666666666, 71.53333333333333, 71.5, 70.56666666666666, 70.63333333333334, 70.96666666666667, 70.9, 71.56666666666666, 70.93333333333334, 69.9, 69.83333333333333, 70.4, 71.53333333333333, 70.63333333333334, 69.3, 71.13333333333334, 70.63333333333334, 71.0, 70.36666666666666, 70.36666666666666, 69.26666666666667, 68.6, 69.2, 69.7, 69.26666666666667, 69.8, 69.43333333333334, 69.53333333333333, 67.46666666666667, 69.03333333333333, 68.93333333333334, 69.2, 67.03333333333333, 66.7, 69.06666666666666, 68.53333333333333, 68.23333333333333, 67.26666666666667, 66.86666666666666, 67.3, 68.4, 67.56666666666666, 67.63333333333334, 66.76666666666667, 68.46666666666667, 68.1, 68.16666666666667, 69.5, 68.06666666666666, 67.66666666666667, 68.96666666666667, 66.73333333333333, 68.23333333333333, 67.2, 68.33333333333333, 68.03333333333333, 68.86666666666666, 68.93333333333334, 68.86666666666666, 68.5, 68.36666666666666, 68.16666666666667, 67.56666666666666, 67.66666666666667, 67.23333333333333, 67.8, 67.6, 67.6, 68.16666666666667, 68.3, 68.63333333333334, 67.3, 67.1, 68.0, 67.43333333333334, 67.23333333333333, 67.63333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.728, Test loss: 2.298, Test accuracy: 17.20
Round   1, Train loss: 1.212, Test loss: 1.941, Test accuracy: 21.17
Round   2, Train loss: 1.141, Test loss: 1.849, Test accuracy: 31.03
Round   3, Train loss: 1.170, Test loss: 1.772, Test accuracy: 36.87
Round   4, Train loss: 1.088, Test loss: 1.487, Test accuracy: 40.43
Round   5, Train loss: 1.110, Test loss: 1.464, Test accuracy: 43.83
Round   6, Train loss: 1.062, Test loss: 1.257, Test accuracy: 46.07
Round   7, Train loss: 1.051, Test loss: 1.084, Test accuracy: 52.33
Round   8, Train loss: 1.016, Test loss: 1.048, Test accuracy: 49.80
Round   9, Train loss: 1.064, Test loss: 0.987, Test accuracy: 51.37
Round  10, Train loss: 0.975, Test loss: 0.965, Test accuracy: 51.60
Round  11, Train loss: 1.019, Test loss: 0.968, Test accuracy: 52.77
Round  12, Train loss: 0.990, Test loss: 0.950, Test accuracy: 55.27
Round  13, Train loss: 0.970, Test loss: 0.934, Test accuracy: 55.03
Round  14, Train loss: 0.986, Test loss: 0.926, Test accuracy: 56.03
Round  15, Train loss: 0.816, Test loss: 0.926, Test accuracy: 54.43
Round  16, Train loss: 1.006, Test loss: 0.922, Test accuracy: 58.13
Round  17, Train loss: 0.839, Test loss: 0.910, Test accuracy: 58.50
Round  18, Train loss: 1.061, Test loss: 0.908, Test accuracy: 58.00
Round  19, Train loss: 0.897, Test loss: 0.911, Test accuracy: 56.90
Round  20, Train loss: 0.943, Test loss: 0.892, Test accuracy: 60.07
Round  21, Train loss: 0.935, Test loss: 0.885, Test accuracy: 61.90
Round  22, Train loss: 0.888, Test loss: 0.878, Test accuracy: 59.57
Round  23, Train loss: 0.741, Test loss: 0.874, Test accuracy: 58.47
Round  24, Train loss: 0.963, Test loss: 0.878, Test accuracy: 57.43
Round  25, Train loss: 0.909, Test loss: 0.879, Test accuracy: 58.70
Round  26, Train loss: 0.917, Test loss: 0.869, Test accuracy: 62.53
Round  27, Train loss: 0.717, Test loss: 0.862, Test accuracy: 63.43
Round  28, Train loss: 0.910, Test loss: 0.871, Test accuracy: 61.47
Round  29, Train loss: 1.085, Test loss: 0.896, Test accuracy: 57.83
Round  30, Train loss: 0.672, Test loss: 0.876, Test accuracy: 60.17
Round  31, Train loss: 1.022, Test loss: 0.873, Test accuracy: 58.87
Round  32, Train loss: 1.071, Test loss: 0.877, Test accuracy: 61.43
Round  33, Train loss: 1.058, Test loss: 0.872, Test accuracy: 61.27
Round  34, Train loss: 1.003, Test loss: 0.890, Test accuracy: 61.33
Round  35, Train loss: 0.776, Test loss: 0.870, Test accuracy: 63.00
Round  36, Train loss: 0.724, Test loss: 0.848, Test accuracy: 64.23
Round  37, Train loss: 0.885, Test loss: 0.854, Test accuracy: 62.27
Round  38, Train loss: 0.991, Test loss: 0.854, Test accuracy: 61.97
Round  39, Train loss: 0.800, Test loss: 0.853, Test accuracy: 61.60
Round  40, Train loss: 0.844, Test loss: 0.861, Test accuracy: 61.47
Round  41, Train loss: 0.823, Test loss: 0.864, Test accuracy: 61.20
Round  42, Train loss: 0.927, Test loss: 0.871, Test accuracy: 60.40
Round  43, Train loss: 0.758, Test loss: 0.841, Test accuracy: 64.10
Round  44, Train loss: 1.040, Test loss: 0.849, Test accuracy: 62.13
Round  45, Train loss: 1.026, Test loss: 0.857, Test accuracy: 62.57
Round  46, Train loss: 0.839, Test loss: 0.862, Test accuracy: 61.80
Round  47, Train loss: 1.033, Test loss: 0.872, Test accuracy: 60.27
Round  48, Train loss: 1.021, Test loss: 0.868, Test accuracy: 60.03
Round  49, Train loss: 0.832, Test loss: 0.868, Test accuracy: 60.63
Round  50, Train loss: 0.850, Test loss: 0.845, Test accuracy: 62.80
Round  51, Train loss: 0.967, Test loss: 0.860, Test accuracy: 62.40
Round  52, Train loss: 0.872, Test loss: 0.841, Test accuracy: 63.10
Round  53, Train loss: 0.831, Test loss: 0.831, Test accuracy: 63.53
Round  54, Train loss: 0.655, Test loss: 0.832, Test accuracy: 63.47
Round  55, Train loss: 1.006, Test loss: 0.840, Test accuracy: 62.73
Round  56, Train loss: 1.006, Test loss: 0.843, Test accuracy: 61.90
Round  57, Train loss: 0.911, Test loss: 0.852, Test accuracy: 60.93
Round  58, Train loss: 0.806, Test loss: 0.858, Test accuracy: 60.20
Round  59, Train loss: 0.984, Test loss: 0.865, Test accuracy: 59.53
Round  60, Train loss: 0.814, Test loss: 0.845, Test accuracy: 61.90
Round  61, Train loss: 0.851, Test loss: 0.839, Test accuracy: 61.73
Round  62, Train loss: 0.883, Test loss: 0.858, Test accuracy: 60.33
Round  63, Train loss: 0.687, Test loss: 0.836, Test accuracy: 62.13
Round  64, Train loss: 0.577, Test loss: 0.825, Test accuracy: 62.00
Round  65, Train loss: 0.834, Test loss: 0.839, Test accuracy: 61.57
Round  66, Train loss: 0.796, Test loss: 0.841, Test accuracy: 60.70
Round  67, Train loss: 0.805, Test loss: 0.853, Test accuracy: 59.00
Round  68, Train loss: 0.765, Test loss: 0.849, Test accuracy: 61.07
Round  69, Train loss: 0.869, Test loss: 0.859, Test accuracy: 60.80
Round  70, Train loss: 0.784, Test loss: 0.849, Test accuracy: 60.80
Round  71, Train loss: 0.887, Test loss: 0.859, Test accuracy: 61.07
Round  72, Train loss: 0.760, Test loss: 0.848, Test accuracy: 61.50
Round  73, Train loss: 0.745, Test loss: 0.839, Test accuracy: 62.50
Round  74, Train loss: 0.956, Test loss: 0.862, Test accuracy: 61.83
Round  75, Train loss: 0.805, Test loss: 0.858, Test accuracy: 60.70
Round  76, Train loss: 0.694, Test loss: 0.831, Test accuracy: 61.77
Round  77, Train loss: 0.698, Test loss: 0.837, Test accuracy: 62.37
Round  78, Train loss: 0.552, Test loss: 0.827, Test accuracy: 62.23
Round  79, Train loss: 0.742, Test loss: 0.853, Test accuracy: 61.40
Round  80, Train loss: 0.588, Test loss: 0.835, Test accuracy: 61.83
Round  81, Train loss: 0.538, Test loss: 0.843, Test accuracy: 61.97
Round  82, Train loss: 0.504, Test loss: 0.854, Test accuracy: 61.50
Round  83, Train loss: 0.703, Test loss: 0.872, Test accuracy: 59.27
Round  84, Train loss: 0.841, Test loss: 0.876, Test accuracy: 58.37
Round  85, Train loss: 0.542, Test loss: 0.865, Test accuracy: 59.90
Round  86, Train loss: 0.515, Test loss: 0.838, Test accuracy: 62.13
Round  87, Train loss: 0.457, Test loss: 0.864, Test accuracy: 61.73
Round  88, Train loss: 0.645, Test loss: 0.861, Test accuracy: 61.10
Round  89, Train loss: 0.781, Test loss: 0.864, Test accuracy: 60.93
Round  90, Train loss: 0.703, Test loss: 0.889, Test accuracy: 59.83
Round  91, Train loss: 0.690, Test loss: 0.883, Test accuracy: 59.97
Round  92, Train loss: 0.594, Test loss: 0.889, Test accuracy: 58.80
Round  93, Train loss: 0.805, Test loss: 0.899, Test accuracy: 58.20
Round  94, Train loss: 0.836, Test loss: 0.905, Test accuracy: 58.60
Round  95, Train loss: 0.445, Test loss: 0.893, Test accuracy: 58.67
Round  96, Train loss: 0.648, Test loss: 0.922, Test accuracy: 58.73
Round  97, Train loss: 0.738, Test loss: 0.916, Test accuracy: 58.27
Round  98, Train loss: 0.657, Test loss: 0.897, Test accuracy: 59.17
Round  99, Train loss: 0.798, Test loss: 0.935, Test accuracy: 57.23
Final Round, Train loss: 0.590, Test loss: 0.933, Test accuracy: 58.30
Average accuracy final 10 rounds: 58.74666666666667
317.9532980918884
[1.1310884952545166, 1.9134771823883057, 2.695819139480591, 3.482792377471924, 4.266760587692261, 5.051716566085815, 5.840516567230225, 6.615819454193115, 7.400161266326904, 8.181030988693237, 8.966695308685303, 9.755136489868164, 10.5352623462677, 11.316938400268555, 12.09715986251831, 12.866569519042969, 13.652836561203003, 14.440701007843018, 15.226540327072144, 16.013587713241577, 16.79231834411621, 17.573781728744507, 18.356325387954712, 19.140414237976074, 19.930525541305542, 20.71674132347107, 21.50147271156311, 22.27909803390503, 23.05816125869751, 23.83586549758911, 24.620990753173828, 25.405278205871582, 26.184453010559082, 26.968544244766235, 27.74444580078125, 28.523959636688232, 29.30725383758545, 30.091569662094116, 30.877424001693726, 31.65786623954773, 32.43377470970154, 33.21080684661865, 33.98851537704468, 34.77212858200073, 35.55776858329773, 36.337687253952026, 37.12249565124512, 37.89903426170349, 38.67679953575134, 39.45118761062622, 40.22891592979431, 41.01187491416931, 41.80114507675171, 42.58474612236023, 43.365999937057495, 44.14663362503052, 44.93366718292236, 45.71737027168274, 46.501784801483154, 47.283544301986694, 48.05978989601135, 48.841901540756226, 49.62260413169861, 50.40800642967224, 51.19306826591492, 51.97116041183472, 52.75689148902893, 53.53951978683472, 54.319244623184204, 55.10588526725769, 55.88195252418518, 56.66604471206665, 57.45033550262451, 58.23000741004944, 59.01189661026001, 59.788187742233276, 60.57361316680908, 61.360259771347046, 62.14360499382019, 62.93094253540039, 63.71075701713562, 64.49024772644043, 65.27202010154724, 66.05598306655884, 66.83836674690247, 67.62214589118958, 68.40715646743774, 69.18588519096375, 69.963552236557, 70.7463891506195, 71.52736735343933, 72.31163501739502, 73.09590125083923, 73.8762755393982, 74.66131544113159, 75.45392990112305, 76.24521589279175, 77.03560519218445, 77.82233929634094, 78.61363554000854, 79.83405041694641]
[17.2, 21.166666666666668, 31.033333333333335, 36.86666666666667, 40.43333333333333, 43.833333333333336, 46.06666666666667, 52.333333333333336, 49.8, 51.36666666666667, 51.6, 52.766666666666666, 55.266666666666666, 55.03333333333333, 56.03333333333333, 54.43333333333333, 58.13333333333333, 58.5, 58.0, 56.9, 60.06666666666667, 61.9, 59.56666666666667, 58.46666666666667, 57.43333333333333, 58.7, 62.53333333333333, 63.43333333333333, 61.46666666666667, 57.833333333333336, 60.166666666666664, 58.86666666666667, 61.43333333333333, 61.266666666666666, 61.333333333333336, 63.0, 64.23333333333333, 62.266666666666666, 61.96666666666667, 61.6, 61.46666666666667, 61.2, 60.4, 64.1, 62.13333333333333, 62.56666666666667, 61.8, 60.266666666666666, 60.03333333333333, 60.63333333333333, 62.8, 62.4, 63.1, 63.53333333333333, 63.46666666666667, 62.733333333333334, 61.9, 60.93333333333333, 60.2, 59.53333333333333, 61.9, 61.733333333333334, 60.333333333333336, 62.13333333333333, 62.0, 61.56666666666667, 60.7, 59.0, 61.06666666666667, 60.8, 60.8, 61.06666666666667, 61.5, 62.5, 61.833333333333336, 60.7, 61.766666666666666, 62.36666666666667, 62.233333333333334, 61.4, 61.833333333333336, 61.96666666666667, 61.5, 59.266666666666666, 58.36666666666667, 59.9, 62.13333333333333, 61.733333333333334, 61.1, 60.93333333333333, 59.833333333333336, 59.96666666666667, 58.8, 58.2, 58.6, 58.666666666666664, 58.733333333333334, 58.266666666666666, 59.166666666666664, 57.233333333333334, 58.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.426, Test loss: 1.463, Test accuracy: 34.00
Round   1, Train loss: 1.081, Test loss: 1.100, Test accuracy: 44.40
Round   2, Train loss: 1.022, Test loss: 1.031, Test accuracy: 46.97
Round   3, Train loss: 0.993, Test loss: 0.997, Test accuracy: 49.10
Round   4, Train loss: 0.974, Test loss: 0.953, Test accuracy: 53.27
Round   5, Train loss: 0.953, Test loss: 0.947, Test accuracy: 53.00
Round   6, Train loss: 0.937, Test loss: 0.922, Test accuracy: 58.93
Round   7, Train loss: 0.928, Test loss: 0.895, Test accuracy: 59.57
Round   8, Train loss: 0.919, Test loss: 0.889, Test accuracy: 57.60
Round   9, Train loss: 0.901, Test loss: 0.873, Test accuracy: 61.60
Round  10, Train loss: 0.898, Test loss: 0.881, Test accuracy: 60.83
Round  11, Train loss: 0.886, Test loss: 0.864, Test accuracy: 60.37
Round  12, Train loss: 0.878, Test loss: 0.876, Test accuracy: 60.93
Round  13, Train loss: 0.865, Test loss: 0.872, Test accuracy: 63.97
Round  14, Train loss: 0.856, Test loss: 0.858, Test accuracy: 61.73
Round  15, Train loss: 0.844, Test loss: 0.838, Test accuracy: 61.43
Round  16, Train loss: 0.835, Test loss: 0.822, Test accuracy: 64.90
Round  17, Train loss: 0.827, Test loss: 0.849, Test accuracy: 58.37
Round  18, Train loss: 0.815, Test loss: 0.825, Test accuracy: 62.97
Round  19, Train loss: 0.801, Test loss: 0.826, Test accuracy: 62.27
Round  20, Train loss: 0.784, Test loss: 0.835, Test accuracy: 61.47
Round  21, Train loss: 0.873, Test loss: 0.827, Test accuracy: 62.17
Round  22, Train loss: 0.846, Test loss: 0.864, Test accuracy: 59.83
Round  23, Train loss: 0.823, Test loss: 0.851, Test accuracy: 60.90
Round  24, Train loss: 0.772, Test loss: 0.833, Test accuracy: 61.60
Round  25, Train loss: 0.847, Test loss: 0.830, Test accuracy: 61.83
Round  26, Train loss: 0.581, Test loss: 0.846, Test accuracy: 62.30
Round  27, Train loss: 0.902, Test loss: 0.883, Test accuracy: 60.17
Round  28, Train loss: 0.492, Test loss: 0.860, Test accuracy: 60.43
Round  29, Train loss: 0.512, Test loss: 0.889, Test accuracy: 58.67
Round  30, Train loss: 0.888, Test loss: 0.892, Test accuracy: 58.00
Round  31, Train loss: 0.902, Test loss: 0.907, Test accuracy: 58.10
Round  32, Train loss: 0.384, Test loss: 0.880, Test accuracy: 57.90
Round  33, Train loss: 0.335, Test loss: 0.828, Test accuracy: 61.93
Round  34, Train loss: 0.883, Test loss: 0.872, Test accuracy: 60.07
Round  35, Train loss: 0.704, Test loss: 0.868, Test accuracy: 59.67
Round  36, Train loss: 0.637, Test loss: 0.894, Test accuracy: 59.53
Round  37, Train loss: 0.489, Test loss: 0.884, Test accuracy: 61.17
Round  38, Train loss: 0.496, Test loss: 0.875, Test accuracy: 61.63
Round  39, Train loss: 0.807, Test loss: 0.909, Test accuracy: 59.13
Round  40, Train loss: 0.575, Test loss: 0.952, Test accuracy: 56.63
Round  41, Train loss: 0.512, Test loss: 0.927, Test accuracy: 58.10
Round  42, Train loss: 0.485, Test loss: 0.911, Test accuracy: 57.97
Round  43, Train loss: 0.669, Test loss: 0.909, Test accuracy: 59.37
Round  44, Train loss: 0.322, Test loss: 0.894, Test accuracy: 60.73
Round  45, Train loss: 0.277, Test loss: 0.910, Test accuracy: 62.30
Round  46, Train loss: 0.614, Test loss: 0.910, Test accuracy: 61.23
Round  47, Train loss: 0.430, Test loss: 0.922, Test accuracy: 59.53
Round  48, Train loss: 0.418, Test loss: 0.924, Test accuracy: 59.83
Round  49, Train loss: 0.693, Test loss: 0.973, Test accuracy: 58.97
Round  50, Train loss: 0.389, Test loss: 0.945, Test accuracy: 60.03
Round  51, Train loss: 0.570, Test loss: 1.051, Test accuracy: 56.53
Round  52, Train loss: 0.533, Test loss: 0.996, Test accuracy: 57.70
Round  53, Train loss: 0.554, Test loss: 1.017, Test accuracy: 56.30
Round  54, Train loss: 0.442, Test loss: 1.036, Test accuracy: 56.93
Round  55, Train loss: 0.507, Test loss: 1.058, Test accuracy: 55.77
Round  56, Train loss: 0.325, Test loss: 1.050, Test accuracy: 56.47
Round  57, Train loss: 0.435, Test loss: 1.044, Test accuracy: 56.70
Round  58, Train loss: 0.421, Test loss: 1.065, Test accuracy: 54.67
Round  59, Train loss: 0.415, Test loss: 1.099, Test accuracy: 54.97
Round  60, Train loss: 0.337, Test loss: 1.057, Test accuracy: 56.53
Round  61, Train loss: 0.474, Test loss: 1.113, Test accuracy: 55.33
Round  62, Train loss: 0.380, Test loss: 1.086, Test accuracy: 55.80
Round  63, Train loss: 0.449, Test loss: 1.081, Test accuracy: 56.73
Round  64, Train loss: 0.382, Test loss: 1.092, Test accuracy: 56.37
Round  65, Train loss: 0.384, Test loss: 1.141, Test accuracy: 55.23
Round  66, Train loss: 0.383, Test loss: 1.188, Test accuracy: 54.80
Round  67, Train loss: 0.343, Test loss: 1.175, Test accuracy: 54.33
Round  68, Train loss: 0.402, Test loss: 1.176, Test accuracy: 54.57
Round  69, Train loss: 0.288, Test loss: 1.157, Test accuracy: 55.30
Round  70, Train loss: 0.342, Test loss: 1.128, Test accuracy: 55.33
Round  71, Train loss: 0.285, Test loss: 1.103, Test accuracy: 57.43
Round  72, Train loss: 0.332, Test loss: 1.183, Test accuracy: 55.97
Round  73, Train loss: 0.307, Test loss: 1.145, Test accuracy: 56.00
Round  74, Train loss: 0.189, Test loss: 1.131, Test accuracy: 57.27
Round  75, Train loss: 0.225, Test loss: 1.147, Test accuracy: 57.77
Round  76, Train loss: 0.325, Test loss: 1.223, Test accuracy: 55.30
Round  77, Train loss: 0.365, Test loss: 1.237, Test accuracy: 56.10
Round  78, Train loss: 0.268, Test loss: 1.205, Test accuracy: 56.93
Round  79, Train loss: 0.248, Test loss: 1.231, Test accuracy: 55.63
Round  80, Train loss: 0.282, Test loss: 1.213, Test accuracy: 55.83
Round  81, Train loss: 0.247, Test loss: 1.239, Test accuracy: 55.50
Round  82, Train loss: 0.247, Test loss: 1.252, Test accuracy: 55.53
Round  83, Train loss: 0.237, Test loss: 1.257, Test accuracy: 55.40
Round  84, Train loss: 0.239, Test loss: 1.264, Test accuracy: 55.33
Round  85, Train loss: 0.230, Test loss: 1.275, Test accuracy: 54.87
Round  86, Train loss: 0.238, Test loss: 1.253, Test accuracy: 56.13
Round  87, Train loss: 0.222, Test loss: 1.289, Test accuracy: 55.20
Round  88, Train loss: 0.213, Test loss: 1.317, Test accuracy: 55.90
Round  89, Train loss: 0.215, Test loss: 1.299, Test accuracy: 56.13
Round  90, Train loss: 0.209, Test loss: 1.332, Test accuracy: 55.13
Round  91, Train loss: 0.210, Test loss: 1.347, Test accuracy: 54.83
Round  92, Train loss: 0.186, Test loss: 1.371, Test accuracy: 54.33
Round  93, Train loss: 0.200, Test loss: 1.362, Test accuracy: 55.10
Round  94, Train loss: 0.186, Test loss: 1.356, Test accuracy: 56.30
Round  95, Train loss: 0.180, Test loss: 1.387, Test accuracy: 54.37
Round  96, Train loss: 0.174, Test loss: 1.402, Test accuracy: 55.47
Round  97, Train loss: 0.195, Test loss: 1.387, Test accuracy: 54.37
Round  98, Train loss: 0.177, Test loss: 1.409, Test accuracy: 54.23
Round  99, Train loss: 0.181, Test loss: 1.410, Test accuracy: 54.70
Final Round, Train loss: 0.143, Test loss: 1.449, Test accuracy: 55.30
Average accuracy final 10 rounds: 54.883333333333326
924.6961269378662
[1.9089813232421875, 3.4828293323516846, 5.053735017776489, 6.634009122848511, 8.18717622756958, 9.741293907165527, 11.287960767745972, 12.843124151229858, 14.351444482803345, 15.860422849655151, 17.369568347930908, 18.88486099243164, 20.39634895324707, 21.912269353866577, 23.427165508270264, 24.97559666633606, 26.382323265075684, 27.78623938560486, 29.1983540058136, 30.607194423675537, 32.004783391952515, 33.400627851486206, 34.791346073150635, 36.197165966033936, 37.60633945465088, 39.003180265426636, 40.39921855926514, 41.808931827545166, 43.2266526222229, 44.63276743888855, 46.028014183044434, 47.43342876434326, 48.84096717834473, 50.24385380744934, 51.64140439033508, 53.04906487464905, 54.45698547363281, 55.86596322059631, 57.25750374794006, 58.65473127365112, 60.055903911590576, 61.456951379776, 62.84447002410889, 64.239675283432, 65.64182448387146, 67.04747676849365, 68.43867611885071, 69.83283615112305, 71.23554944992065, 72.63510608673096, 74.02820158004761, 75.42404103279114, 76.82845425605774, 78.22196984291077, 79.611563205719, 81.00138592720032, 82.4048581123352, 83.80618286132812, 85.19460821151733, 86.59273409843445, 87.99846386909485, 89.40082883834839, 90.79351902008057, 92.17745089530945, 93.57558679580688, 94.97518420219421, 96.36749029159546, 97.75586771965027, 99.15496563911438, 100.5560405254364, 101.94694113731384, 103.33255982398987, 104.73928880691528, 106.14110541343689, 107.53422951698303, 108.92541146278381, 110.33218383789062, 111.73054552078247, 113.13496732711792, 114.52125763893127, 115.92325854301453, 117.32679176330566, 118.73123264312744, 120.1330087184906, 121.53855037689209, 122.94486546516418, 124.34970426559448, 125.75288271903992, 127.16109991073608, 128.5659577846527, 129.9701166152954, 131.37975668907166, 132.78737926483154, 134.19721508026123, 135.60405278205872, 137.0178816318512, 138.42650747299194, 139.8352198600769, 141.242032289505, 142.649897813797, 144.931001663208]
[34.0, 44.4, 46.96666666666667, 49.1, 53.266666666666666, 53.0, 58.93333333333333, 59.56666666666667, 57.6, 61.6, 60.833333333333336, 60.36666666666667, 60.93333333333333, 63.96666666666667, 61.733333333333334, 61.43333333333333, 64.9, 58.36666666666667, 62.96666666666667, 62.266666666666666, 61.46666666666667, 62.166666666666664, 59.833333333333336, 60.9, 61.6, 61.833333333333336, 62.3, 60.166666666666664, 60.43333333333333, 58.666666666666664, 58.0, 58.1, 57.9, 61.93333333333333, 60.06666666666667, 59.666666666666664, 59.53333333333333, 61.166666666666664, 61.63333333333333, 59.13333333333333, 56.63333333333333, 58.1, 57.96666666666667, 59.36666666666667, 60.733333333333334, 62.3, 61.233333333333334, 59.53333333333333, 59.833333333333336, 58.96666666666667, 60.03333333333333, 56.53333333333333, 57.7, 56.3, 56.93333333333333, 55.766666666666666, 56.46666666666667, 56.7, 54.666666666666664, 54.96666666666667, 56.53333333333333, 55.333333333333336, 55.8, 56.733333333333334, 56.36666666666667, 55.233333333333334, 54.8, 54.333333333333336, 54.56666666666667, 55.3, 55.333333333333336, 57.43333333333333, 55.96666666666667, 56.0, 57.266666666666666, 57.766666666666666, 55.3, 56.1, 56.93333333333333, 55.63333333333333, 55.833333333333336, 55.5, 55.53333333333333, 55.4, 55.333333333333336, 54.86666666666667, 56.13333333333333, 55.2, 55.9, 56.13333333333333, 55.13333333333333, 54.833333333333336, 54.333333333333336, 55.1, 56.3, 54.36666666666667, 55.46666666666667, 54.36666666666667, 54.233333333333334, 54.7, 55.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.402, Test loss: 1.347, Test accuracy: 40.50
Round   1, Train loss: 1.066, Test loss: 1.107, Test accuracy: 41.10
Round   2, Train loss: 1.018, Test loss: 1.055, Test accuracy: 45.57
Round   3, Train loss: 0.986, Test loss: 0.988, Test accuracy: 52.93
Round   4, Train loss: 0.968, Test loss: 0.945, Test accuracy: 55.10
Round   5, Train loss: 0.945, Test loss: 0.918, Test accuracy: 54.93
Round   6, Train loss: 0.932, Test loss: 0.892, Test accuracy: 57.40
Round   7, Train loss: 0.919, Test loss: 0.900, Test accuracy: 58.67
Round   8, Train loss: 0.908, Test loss: 0.890, Test accuracy: 57.73
Round   9, Train loss: 0.901, Test loss: 0.861, Test accuracy: 62.00
Round  10, Train loss: 0.889, Test loss: 0.889, Test accuracy: 61.53
Round  11, Train loss: 0.881, Test loss: 0.854, Test accuracy: 63.80
Round  12, Train loss: 0.866, Test loss: 0.863, Test accuracy: 63.17
Round  13, Train loss: 0.861, Test loss: 0.843, Test accuracy: 62.60
Round  14, Train loss: 0.851, Test loss: 0.837, Test accuracy: 62.73
Round  15, Train loss: 0.841, Test loss: 0.816, Test accuracy: 67.07
Round  16, Train loss: 0.834, Test loss: 0.862, Test accuracy: 59.40
Round  17, Train loss: 0.820, Test loss: 0.824, Test accuracy: 64.60
Round  18, Train loss: 0.811, Test loss: 0.837, Test accuracy: 64.73
Round  19, Train loss: 0.802, Test loss: 0.831, Test accuracy: 63.17
Round  20, Train loss: 0.979, Test loss: 0.860, Test accuracy: 60.07
Round  21, Train loss: 0.867, Test loss: 0.860, Test accuracy: 60.10
Round  22, Train loss: 0.861, Test loss: 0.875, Test accuracy: 60.07
Round  23, Train loss: 0.651, Test loss: 0.828, Test accuracy: 62.97
Round  24, Train loss: 0.954, Test loss: 0.862, Test accuracy: 59.77
Round  25, Train loss: 0.459, Test loss: 0.800, Test accuracy: 63.60
Round  26, Train loss: 0.795, Test loss: 0.818, Test accuracy: 63.30
Round  27, Train loss: 0.716, Test loss: 0.831, Test accuracy: 61.00
Round  28, Train loss: 0.913, Test loss: 0.873, Test accuracy: 60.00
Round  29, Train loss: 0.705, Test loss: 0.879, Test accuracy: 59.13
Round  30, Train loss: 0.698, Test loss: 0.860, Test accuracy: 59.97
Round  31, Train loss: 0.700, Test loss: 0.881, Test accuracy: 58.93
Round  32, Train loss: 0.754, Test loss: 0.896, Test accuracy: 58.23
Round  33, Train loss: 0.714, Test loss: 0.887, Test accuracy: 59.07
Round  34, Train loss: 0.668, Test loss: 0.887, Test accuracy: 59.40
Round  35, Train loss: 0.700, Test loss: 0.902, Test accuracy: 58.27
Round  36, Train loss: 0.626, Test loss: 0.906, Test accuracy: 58.20
Round  37, Train loss: 0.691, Test loss: 0.900, Test accuracy: 57.93
Round  38, Train loss: 0.672, Test loss: 0.914, Test accuracy: 59.37
Round  39, Train loss: 0.429, Test loss: 0.881, Test accuracy: 61.13
Round  40, Train loss: 0.592, Test loss: 0.908, Test accuracy: 58.60
Round  41, Train loss: 0.521, Test loss: 0.977, Test accuracy: 55.93
Round  42, Train loss: 0.652, Test loss: 0.933, Test accuracy: 57.53
Round  43, Train loss: 0.683, Test loss: 0.927, Test accuracy: 58.00
Round  44, Train loss: 0.502, Test loss: 0.929, Test accuracy: 57.87
Round  45, Train loss: 0.435, Test loss: 0.950, Test accuracy: 57.87
Round  46, Train loss: 0.623, Test loss: 0.976, Test accuracy: 57.77
Round  47, Train loss: 0.393, Test loss: 0.959, Test accuracy: 58.77
Round  48, Train loss: 0.544, Test loss: 1.006, Test accuracy: 56.90
Round  49, Train loss: 0.683, Test loss: 1.014, Test accuracy: 55.90
Round  50, Train loss: 0.545, Test loss: 1.027, Test accuracy: 55.67
Round  51, Train loss: 0.394, Test loss: 0.980, Test accuracy: 58.00
Round  52, Train loss: 0.532, Test loss: 1.009, Test accuracy: 57.00
Round  53, Train loss: 0.237, Test loss: 0.976, Test accuracy: 57.47
Round  54, Train loss: 0.443, Test loss: 1.023, Test accuracy: 57.50
Round  55, Train loss: 0.359, Test loss: 1.000, Test accuracy: 59.07
Round  56, Train loss: 0.279, Test loss: 1.035, Test accuracy: 57.80
Round  57, Train loss: 0.540, Test loss: 1.087, Test accuracy: 55.63
Round  58, Train loss: 0.428, Test loss: 1.091, Test accuracy: 56.53
Round  59, Train loss: 0.265, Test loss: 1.058, Test accuracy: 58.03
Round  60, Train loss: 0.451, Test loss: 1.085, Test accuracy: 56.03
Round  61, Train loss: 0.355, Test loss: 1.026, Test accuracy: 58.97
Round  62, Train loss: 0.469, Test loss: 1.127, Test accuracy: 56.70
Round  63, Train loss: 0.473, Test loss: 1.129, Test accuracy: 56.40
Round  64, Train loss: 0.391, Test loss: 1.173, Test accuracy: 56.00
Round  65, Train loss: 0.277, Test loss: 1.108, Test accuracy: 57.13
Round  66, Train loss: 0.325, Test loss: 1.135, Test accuracy: 56.53
Round  67, Train loss: 0.267, Test loss: 1.115, Test accuracy: 57.00
Round  68, Train loss: 0.267, Test loss: 1.109, Test accuracy: 58.03
Round  69, Train loss: 0.389, Test loss: 1.191, Test accuracy: 56.73
Round  70, Train loss: 0.354, Test loss: 1.235, Test accuracy: 54.60
Round  71, Train loss: 0.505, Test loss: 1.193, Test accuracy: 55.40
Round  72, Train loss: 0.343, Test loss: 1.210, Test accuracy: 54.47
Round  73, Train loss: 0.308, Test loss: 1.165, Test accuracy: 56.10
Round  74, Train loss: 0.300, Test loss: 1.173, Test accuracy: 56.73
Round  75, Train loss: 0.359, Test loss: 1.230, Test accuracy: 55.53
Round  76, Train loss: 0.286, Test loss: 1.195, Test accuracy: 55.67
Round  77, Train loss: 0.369, Test loss: 1.228, Test accuracy: 55.57
Round  78, Train loss: 0.379, Test loss: 1.271, Test accuracy: 54.57
Round  79, Train loss: 0.363, Test loss: 1.300, Test accuracy: 53.13
Round  80, Train loss: 0.280, Test loss: 1.259, Test accuracy: 55.03
Round  81, Train loss: 0.252, Test loss: 1.242, Test accuracy: 56.50
Round  82, Train loss: 0.245, Test loss: 1.242, Test accuracy: 56.23
Round  83, Train loss: 0.247, Test loss: 1.250, Test accuracy: 56.80
Round  84, Train loss: 0.236, Test loss: 1.268, Test accuracy: 56.43
Round  85, Train loss: 0.223, Test loss: 1.308, Test accuracy: 55.50
Round  86, Train loss: 0.225, Test loss: 1.285, Test accuracy: 56.13
Round  87, Train loss: 0.228, Test loss: 1.304, Test accuracy: 55.90
Round  88, Train loss: 0.212, Test loss: 1.311, Test accuracy: 57.20
Round  89, Train loss: 0.194, Test loss: 1.343, Test accuracy: 56.90
Round  90, Train loss: 0.220, Test loss: 1.336, Test accuracy: 56.97
Round  91, Train loss: 0.200, Test loss: 1.361, Test accuracy: 56.10
Round  92, Train loss: 0.196, Test loss: 1.338, Test accuracy: 57.17
Round  93, Train loss: 0.196, Test loss: 1.357, Test accuracy: 56.57
Round  94, Train loss: 0.190, Test loss: 1.373, Test accuracy: 56.50
Round  95, Train loss: 0.194, Test loss: 1.388, Test accuracy: 55.73
Round  96, Train loss: 0.185, Test loss: 1.355, Test accuracy: 56.30
Round  97, Train loss: 0.181, Test loss: 1.386, Test accuracy: 56.00
Round  98, Train loss: 0.181, Test loss: 1.406, Test accuracy: 56.53
Round  99, Train loss: 0.161, Test loss: 1.455, Test accuracy: 54.90
Final Round, Train loss: 0.133, Test loss: 1.478, Test accuracy: 55.27
Average accuracy final 10 rounds: 56.27666666666667
1438.528734445572
[1.932863473892212, 3.525827646255493, 5.134598731994629, 6.743259906768799, 8.350643634796143, 9.960164785385132, 11.475894212722778, 12.988107919692993, 14.501595258712769, 16.08171272277832, 17.591979503631592, 19.101942777633667, 20.63908314704895, 22.30434560775757, 23.756226539611816, 25.200589418411255, 26.64809274673462, 28.101065397262573, 29.538713455200195, 30.97967553138733, 32.42845630645752, 35.00324463844299, 37.73028254508972, 40.42407727241516, 43.1258544921875, 45.72825217247009, 48.47291350364685, 51.196661949157715, 53.782825231552124, 56.491761207580566, 59.17060112953186, 61.92092275619507, 64.63282227516174, 67.35478186607361, 70.05351948738098, 72.63376355171204, 75.39179706573486, 78.28192019462585, 81.15855956077576, 83.96202111244202, 86.81000328063965, 89.57992243766785, 92.35000872612, 95.19888806343079, 98.09197306632996, 100.95125651359558, 103.72748279571533, 106.58139109611511, 109.42965149879456, 112.22899532318115, 115.07226538658142, 117.84133720397949, 120.73280096054077, 123.53149938583374, 126.36236119270325, 129.2279725074768, 132.06497383117676, 134.93022918701172, 137.7758674621582, 140.5030608177185, 143.35822987556458, 146.1541621685028, 148.98189187049866, 151.793151140213, 154.67534160614014, 157.5442283153534, 160.22332382202148, 163.10935163497925, 165.95027112960815, 168.73198461532593, 171.57947731018066, 174.41960740089417, 177.2625551223755, 179.98570322990417, 182.8378312587738, 185.71854257583618, 188.42107629776, 191.26450777053833, 194.1444857120514, 196.99881553649902, 199.87070655822754, 202.75082683563232, 205.63079690933228, 208.48392176628113, 211.36799502372742, 214.211749792099, 217.04987907409668, 219.9270179271698, 222.81545543670654, 225.70041799545288, 228.57857489585876, 231.44882011413574, 234.3385956287384, 237.20094776153564, 240.0789110660553, 242.94995379447937, 245.81643629074097, 248.67574548721313, 251.53525114059448, 254.40593099594116, 256.7482581138611]
[40.5, 41.1, 45.56666666666667, 52.93333333333333, 55.1, 54.93333333333333, 57.4, 58.666666666666664, 57.733333333333334, 62.0, 61.53333333333333, 63.8, 63.166666666666664, 62.6, 62.733333333333334, 67.06666666666666, 59.4, 64.6, 64.73333333333333, 63.166666666666664, 60.06666666666667, 60.1, 60.06666666666667, 62.96666666666667, 59.766666666666666, 63.6, 63.3, 61.0, 60.0, 59.13333333333333, 59.96666666666667, 58.93333333333333, 58.233333333333334, 59.06666666666667, 59.4, 58.266666666666666, 58.2, 57.93333333333333, 59.36666666666667, 61.13333333333333, 58.6, 55.93333333333333, 57.53333333333333, 58.0, 57.86666666666667, 57.86666666666667, 57.766666666666666, 58.766666666666666, 56.9, 55.9, 55.666666666666664, 58.0, 57.0, 57.46666666666667, 57.5, 59.06666666666667, 57.8, 55.63333333333333, 56.53333333333333, 58.03333333333333, 56.03333333333333, 58.96666666666667, 56.7, 56.4, 56.0, 57.13333333333333, 56.53333333333333, 57.0, 58.03333333333333, 56.733333333333334, 54.6, 55.4, 54.46666666666667, 56.1, 56.733333333333334, 55.53333333333333, 55.666666666666664, 55.56666666666667, 54.56666666666667, 53.13333333333333, 55.03333333333333, 56.5, 56.233333333333334, 56.8, 56.43333333333333, 55.5, 56.13333333333333, 55.9, 57.2, 56.9, 56.96666666666667, 56.1, 57.166666666666664, 56.56666666666667, 56.5, 55.733333333333334, 56.3, 56.0, 56.53333333333333, 54.9, 55.266666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.431, Test loss: 1.395, Test accuracy: 36.57
Round   1, Train loss: 1.081, Test loss: 1.094, Test accuracy: 43.77
Round   2, Train loss: 1.019, Test loss: 1.041, Test accuracy: 49.30
Round   3, Train loss: 0.989, Test loss: 0.964, Test accuracy: 50.20
Round   4, Train loss: 0.964, Test loss: 0.937, Test accuracy: 53.30
Round   5, Train loss: 0.944, Test loss: 0.925, Test accuracy: 54.37
Round   6, Train loss: 0.924, Test loss: 0.872, Test accuracy: 62.37
Round   7, Train loss: 0.906, Test loss: 0.880, Test accuracy: 60.30
Round   8, Train loss: 0.897, Test loss: 0.854, Test accuracy: 62.30
Round   9, Train loss: 0.881, Test loss: 0.873, Test accuracy: 60.87
Round  10, Train loss: 0.873, Test loss: 0.830, Test accuracy: 63.50
Round  11, Train loss: 0.865, Test loss: 0.840, Test accuracy: 65.20
Round  12, Train loss: 0.855, Test loss: 0.832, Test accuracy: 64.30
Round  13, Train loss: 0.841, Test loss: 0.826, Test accuracy: 63.10
Round  14, Train loss: 0.830, Test loss: 0.821, Test accuracy: 64.03
Round  15, Train loss: 0.818, Test loss: 0.818, Test accuracy: 65.27
Round  16, Train loss: 0.809, Test loss: 0.797, Test accuracy: 66.33
Round  17, Train loss: 0.799, Test loss: 0.811, Test accuracy: 64.13
Round  18, Train loss: 0.785, Test loss: 0.814, Test accuracy: 65.40
Round  19, Train loss: 0.777, Test loss: 0.832, Test accuracy: 62.57
Round  20, Train loss: 0.589, Test loss: 0.826, Test accuracy: 62.10
Round  21, Train loss: 0.877, Test loss: 0.806, Test accuracy: 62.50
Round  22, Train loss: 0.803, Test loss: 0.806, Test accuracy: 64.47
Round  23, Train loss: 0.576, Test loss: 0.798, Test accuracy: 65.43
Round  24, Train loss: 0.754, Test loss: 0.822, Test accuracy: 62.77
Round  25, Train loss: 0.604, Test loss: 0.813, Test accuracy: 64.73
Round  26, Train loss: 0.542, Test loss: 0.815, Test accuracy: 64.20
Round  27, Train loss: 0.516, Test loss: 0.796, Test accuracy: 65.67
Round  28, Train loss: 0.510, Test loss: 0.800, Test accuracy: 65.67
Round  29, Train loss: 0.703, Test loss: 0.800, Test accuracy: 63.87
Round  30, Train loss: 0.515, Test loss: 0.816, Test accuracy: 63.93
Round  31, Train loss: 0.918, Test loss: 0.857, Test accuracy: 60.00
Round  32, Train loss: 0.566, Test loss: 0.798, Test accuracy: 64.23
Round  33, Train loss: 0.667, Test loss: 0.846, Test accuracy: 61.63
Round  34, Train loss: 0.883, Test loss: 0.881, Test accuracy: 59.43
Round  35, Train loss: 0.673, Test loss: 0.859, Test accuracy: 59.97
Round  36, Train loss: 0.612, Test loss: 0.874, Test accuracy: 58.80
Round  37, Train loss: 0.514, Test loss: 0.877, Test accuracy: 59.43
Round  38, Train loss: 0.837, Test loss: 0.917, Test accuracy: 58.10
Round  39, Train loss: 0.620, Test loss: 0.890, Test accuracy: 60.10
Round  40, Train loss: 0.427, Test loss: 0.942, Test accuracy: 58.97
Round  41, Train loss: 0.367, Test loss: 0.912, Test accuracy: 60.03
Round  42, Train loss: 0.618, Test loss: 0.927, Test accuracy: 59.03
Round  43, Train loss: 0.515, Test loss: 0.892, Test accuracy: 60.20
Round  44, Train loss: 0.625, Test loss: 0.911, Test accuracy: 60.43
Round  45, Train loss: 0.560, Test loss: 0.950, Test accuracy: 58.13
Round  46, Train loss: 0.754, Test loss: 0.974, Test accuracy: 58.80
Round  47, Train loss: 0.520, Test loss: 0.972, Test accuracy: 58.40
Round  48, Train loss: 0.556, Test loss: 0.985, Test accuracy: 56.67
Round  49, Train loss: 0.730, Test loss: 1.007, Test accuracy: 57.23
Round  50, Train loss: 0.386, Test loss: 0.971, Test accuracy: 57.93
Round  51, Train loss: 0.571, Test loss: 0.984, Test accuracy: 58.17
Round  52, Train loss: 0.648, Test loss: 1.056, Test accuracy: 56.57
Round  53, Train loss: 0.396, Test loss: 1.002, Test accuracy: 58.53
Round  54, Train loss: 0.435, Test loss: 1.008, Test accuracy: 59.00
Round  55, Train loss: 0.593, Test loss: 1.128, Test accuracy: 55.77
Round  56, Train loss: 0.422, Test loss: 1.061, Test accuracy: 56.53
Round  57, Train loss: 0.558, Test loss: 1.129, Test accuracy: 55.50
Round  58, Train loss: 0.293, Test loss: 1.104, Test accuracy: 57.53
Round  59, Train loss: 0.396, Test loss: 1.104, Test accuracy: 56.27
Round  60, Train loss: 0.310, Test loss: 1.030, Test accuracy: 58.07
Round  61, Train loss: 0.562, Test loss: 1.109, Test accuracy: 57.33
Round  62, Train loss: 0.492, Test loss: 1.165, Test accuracy: 56.40
Round  63, Train loss: 0.336, Test loss: 1.125, Test accuracy: 58.07
Round  64, Train loss: 0.240, Test loss: 1.074, Test accuracy: 59.13
Round  65, Train loss: 0.379, Test loss: 1.085, Test accuracy: 58.47
Round  66, Train loss: 0.373, Test loss: 1.125, Test accuracy: 57.10
Round  67, Train loss: 0.405, Test loss: 1.182, Test accuracy: 55.53
Round  68, Train loss: 0.279, Test loss: 1.145, Test accuracy: 58.43
Round  69, Train loss: 0.387, Test loss: 1.183, Test accuracy: 57.23
Round  70, Train loss: 0.430, Test loss: 1.207, Test accuracy: 56.90
Round  71, Train loss: 0.393, Test loss: 1.144, Test accuracy: 56.70
Round  72, Train loss: 0.245, Test loss: 1.202, Test accuracy: 57.20
Round  73, Train loss: 0.286, Test loss: 1.193, Test accuracy: 56.87
Round  74, Train loss: 0.247, Test loss: 1.124, Test accuracy: 59.50
Round  75, Train loss: 0.297, Test loss: 1.180, Test accuracy: 58.33
Round  76, Train loss: 0.287, Test loss: 1.235, Test accuracy: 57.27
Round  77, Train loss: 0.303, Test loss: 1.233, Test accuracy: 58.10
Round  78, Train loss: 0.266, Test loss: 1.221, Test accuracy: 59.30
Round  79, Train loss: 0.192, Test loss: 1.191, Test accuracy: 58.83
Round  80, Train loss: 0.272, Test loss: 1.210, Test accuracy: 58.20
Round  81, Train loss: 0.237, Test loss: 1.233, Test accuracy: 58.83
Round  82, Train loss: 0.234, Test loss: 1.210, Test accuracy: 58.03
Round  83, Train loss: 0.233, Test loss: 1.249, Test accuracy: 57.90
Round  84, Train loss: 0.219, Test loss: 1.253, Test accuracy: 58.10
Round  85, Train loss: 0.218, Test loss: 1.285, Test accuracy: 57.37
Round  86, Train loss: 0.213, Test loss: 1.315, Test accuracy: 57.87
Round  87, Train loss: 0.203, Test loss: 1.343, Test accuracy: 57.13
Round  88, Train loss: 0.205, Test loss: 1.353, Test accuracy: 57.63
Round  89, Train loss: 0.210, Test loss: 1.304, Test accuracy: 57.43
Round  90, Train loss: 0.188, Test loss: 1.326, Test accuracy: 58.13
Round  91, Train loss: 0.191, Test loss: 1.335, Test accuracy: 57.93
Round  92, Train loss: 0.184, Test loss: 1.380, Test accuracy: 58.00
Round  93, Train loss: 0.208, Test loss: 1.369, Test accuracy: 56.53
Round  94, Train loss: 0.180, Test loss: 1.375, Test accuracy: 58.10
Round  95, Train loss: 0.185, Test loss: 1.415, Test accuracy: 56.73
Round  96, Train loss: 0.181, Test loss: 1.401, Test accuracy: 56.90
Round  97, Train loss: 0.177, Test loss: 1.398, Test accuracy: 56.43
Round  98, Train loss: 0.173, Test loss: 1.391, Test accuracy: 57.87
Round  99, Train loss: 0.160, Test loss: 1.411, Test accuracy: 57.23
Final Round, Train loss: 0.136, Test loss: 1.465, Test accuracy: 57.57
Average accuracy final 10 rounds: 57.38666666666666
1539.1947021484375
[1.9572649002075195, 3.639441728591919, 5.323750734329224, 7.017876148223877, 8.698067665100098, 10.37596321105957, 12.064959287643433, 13.734668731689453, 15.426568508148193, 17.106088161468506, 18.791990756988525, 20.48245120048523, 22.171891927719116, 23.860396146774292, 25.546489000320435, 27.23307156562805, 28.917219638824463, 30.61090660095215, 32.293639183044434, 33.9818069934845, 35.66264319419861, 38.637365102767944, 41.73496723175049, 44.81241536140442, 47.85683751106262, 50.96318197250366, 54.069631576538086, 57.0978798866272, 60.12403845787048, 63.22283744812012, 66.23581600189209, 69.34179663658142, 72.44425225257874, 75.43735933303833, 78.52878093719482, 81.63751196861267, 84.7353446483612, 87.69143557548523, 90.7677493095398, 93.85727429389954, 96.89186358451843, 100.00869607925415, 103.0551655292511, 106.11701774597168, 109.13825035095215, 112.2458143234253, 115.2470715045929, 118.36055254936218, 121.45399212837219, 124.44038963317871, 127.54746961593628, 130.63277745246887, 133.71935081481934, 136.72737622261047, 139.83528971672058, 142.94708514213562, 146.02327799797058, 149.14214897155762, 152.15795612335205, 155.27867436408997, 158.34982752799988, 161.43848395347595, 164.42861151695251, 167.40080523490906, 170.3309509754181, 173.20885372161865, 176.15896797180176, 179.13155579566956, 182.04606223106384, 184.98746609687805, 187.93532633781433, 190.8508677482605, 193.81131386756897, 196.7560658454895, 199.6414692401886, 202.55131340026855, 205.51401257514954, 208.48961305618286, 211.43359518051147, 214.34385323524475, 217.30531072616577, 220.2467007637024, 223.21257543563843, 226.15858602523804, 229.12503814697266, 232.10678219795227, 235.0817575454712, 238.0584011077881, 241.01040720939636, 243.9810700416565, 246.93809175491333, 249.90507435798645, 252.8704218864441, 255.8363835811615, 258.79773139953613, 261.750275850296, 264.7189955711365, 267.677458524704, 270.6438858509064, 273.5787854194641, 276.05282330513]
[36.56666666666667, 43.766666666666666, 49.3, 50.2, 53.3, 54.36666666666667, 62.36666666666667, 60.3, 62.3, 60.86666666666667, 63.5, 65.2, 64.3, 63.1, 64.03333333333333, 65.26666666666667, 66.33333333333333, 64.13333333333334, 65.4, 62.56666666666667, 62.1, 62.5, 64.46666666666667, 65.43333333333334, 62.766666666666666, 64.73333333333333, 64.2, 65.66666666666667, 65.66666666666667, 63.86666666666667, 63.93333333333333, 60.0, 64.23333333333333, 61.63333333333333, 59.43333333333333, 59.96666666666667, 58.8, 59.43333333333333, 58.1, 60.1, 58.96666666666667, 60.03333333333333, 59.03333333333333, 60.2, 60.43333333333333, 58.13333333333333, 58.8, 58.4, 56.666666666666664, 57.233333333333334, 57.93333333333333, 58.166666666666664, 56.56666666666667, 58.53333333333333, 59.0, 55.766666666666666, 56.53333333333333, 55.5, 57.53333333333333, 56.266666666666666, 58.06666666666667, 57.333333333333336, 56.4, 58.06666666666667, 59.13333333333333, 58.46666666666667, 57.1, 55.53333333333333, 58.43333333333333, 57.233333333333334, 56.9, 56.7, 57.2, 56.86666666666667, 59.5, 58.333333333333336, 57.266666666666666, 58.1, 59.3, 58.833333333333336, 58.2, 58.833333333333336, 58.03333333333333, 57.9, 58.1, 57.36666666666667, 57.86666666666667, 57.13333333333333, 57.63333333333333, 57.43333333333333, 58.13333333333333, 57.93333333333333, 58.0, 56.53333333333333, 58.1, 56.733333333333334, 56.9, 56.43333333333333, 57.86666666666667, 57.233333333333334, 57.56666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.712, Test loss: 2.239, Test accuracy: 13.33
Round   1, Train loss: 1.210, Test loss: 2.373, Test accuracy: 25.33
Round   2, Train loss: 1.190, Test loss: 1.923, Test accuracy: 35.33
Round   3, Train loss: 1.121, Test loss: 1.581, Test accuracy: 39.37
Round   4, Train loss: 1.088, Test loss: 1.495, Test accuracy: 41.43
Round   5, Train loss: 1.046, Test loss: 1.450, Test accuracy: 41.53
Round   6, Train loss: 1.030, Test loss: 1.473, Test accuracy: 42.47
Round   7, Train loss: 1.037, Test loss: 1.498, Test accuracy: 47.77
Round   8, Train loss: 1.002, Test loss: 1.300, Test accuracy: 50.10
Round   9, Train loss: 0.956, Test loss: 1.269, Test accuracy: 52.40
Round  10, Train loss: 0.937, Test loss: 1.158, Test accuracy: 54.23
Round  11, Train loss: 1.067, Test loss: 1.068, Test accuracy: 53.87
Round  12, Train loss: 0.853, Test loss: 1.430, Test accuracy: 55.43
Round  13, Train loss: 1.020, Test loss: 0.860, Test accuracy: 62.97
Round  14, Train loss: 1.030, Test loss: 0.855, Test accuracy: 64.57
Round  15, Train loss: 0.998, Test loss: 0.855, Test accuracy: 63.03
Round  16, Train loss: 0.935, Test loss: 0.843, Test accuracy: 63.47
Round  17, Train loss: 1.002, Test loss: 0.848, Test accuracy: 61.10
Round  18, Train loss: 1.015, Test loss: 0.846, Test accuracy: 63.90
Round  19, Train loss: 0.904, Test loss: 0.815, Test accuracy: 66.80
Round  20, Train loss: 1.006, Test loss: 0.814, Test accuracy: 67.53
Round  21, Train loss: 0.909, Test loss: 0.832, Test accuracy: 66.83
Round  22, Train loss: 0.909, Test loss: 0.806, Test accuracy: 67.60
Round  23, Train loss: 0.902, Test loss: 0.804, Test accuracy: 66.23
Round  24, Train loss: 0.767, Test loss: 0.799, Test accuracy: 69.07
Round  25, Train loss: 0.905, Test loss: 0.778, Test accuracy: 68.87
Round  26, Train loss: 0.985, Test loss: 0.778, Test accuracy: 71.10
Round  27, Train loss: 0.880, Test loss: 0.795, Test accuracy: 70.27
Round  28, Train loss: 0.980, Test loss: 0.794, Test accuracy: 69.90
Round  29, Train loss: 0.859, Test loss: 0.794, Test accuracy: 71.50
Round  30, Train loss: 0.970, Test loss: 0.791, Test accuracy: 70.87
Round  31, Train loss: 0.836, Test loss: 0.776, Test accuracy: 69.37
Round  32, Train loss: 0.850, Test loss: 0.772, Test accuracy: 70.43
Round  33, Train loss: 0.936, Test loss: 0.762, Test accuracy: 71.83
Round  34, Train loss: 0.951, Test loss: 0.771, Test accuracy: 71.67
Round  35, Train loss: 0.974, Test loss: 0.749, Test accuracy: 71.10
Round  36, Train loss: 0.948, Test loss: 0.760, Test accuracy: 70.50
Round  37, Train loss: 0.957, Test loss: 0.759, Test accuracy: 71.67
Round  38, Train loss: 0.944, Test loss: 0.730, Test accuracy: 72.43
Round  39, Train loss: 0.949, Test loss: 0.735, Test accuracy: 71.90
Round  40, Train loss: 0.901, Test loss: 0.748, Test accuracy: 71.37
Round  41, Train loss: 0.816, Test loss: 0.751, Test accuracy: 73.07
Round  42, Train loss: 0.912, Test loss: 0.770, Test accuracy: 71.47
Round  43, Train loss: 0.908, Test loss: 0.760, Test accuracy: 70.07
Round  44, Train loss: 0.794, Test loss: 0.746, Test accuracy: 69.50
Round  45, Train loss: 0.805, Test loss: 0.732, Test accuracy: 72.43
Round  46, Train loss: 0.821, Test loss: 0.734, Test accuracy: 70.67
Round  47, Train loss: 0.931, Test loss: 0.750, Test accuracy: 69.30
Round  48, Train loss: 0.874, Test loss: 0.751, Test accuracy: 71.73
Round  49, Train loss: 0.659, Test loss: 0.729, Test accuracy: 71.10
Round  50, Train loss: 0.908, Test loss: 0.720, Test accuracy: 71.47
Round  51, Train loss: 0.877, Test loss: 0.745, Test accuracy: 69.03
Round  52, Train loss: 0.662, Test loss: 0.738, Test accuracy: 69.57
Round  53, Train loss: 0.786, Test loss: 0.730, Test accuracy: 70.80
Round  54, Train loss: 0.769, Test loss: 0.719, Test accuracy: 69.40
Round  55, Train loss: 0.872, Test loss: 0.719, Test accuracy: 71.70
Round  56, Train loss: 0.879, Test loss: 0.725, Test accuracy: 69.87
Round  57, Train loss: 0.730, Test loss: 0.705, Test accuracy: 70.63
Round  58, Train loss: 0.724, Test loss: 0.721, Test accuracy: 71.23
Round  59, Train loss: 0.846, Test loss: 0.747, Test accuracy: 69.90
Round  60, Train loss: 0.745, Test loss: 0.705, Test accuracy: 71.50
Round  61, Train loss: 0.736, Test loss: 0.704, Test accuracy: 71.97
Round  62, Train loss: 0.678, Test loss: 0.707, Test accuracy: 72.57
Round  63, Train loss: 0.880, Test loss: 0.698, Test accuracy: 72.47
Round  64, Train loss: 0.800, Test loss: 0.706, Test accuracy: 71.33
Round  65, Train loss: 0.769, Test loss: 0.703, Test accuracy: 72.47
Round  66, Train loss: 0.835, Test loss: 0.720, Test accuracy: 71.40
Round  67, Train loss: 0.681, Test loss: 0.715, Test accuracy: 71.63
Round  68, Train loss: 0.714, Test loss: 0.704, Test accuracy: 71.43
Round  69, Train loss: 0.820, Test loss: 0.734, Test accuracy: 69.90
Round  70, Train loss: 0.685, Test loss: 0.716, Test accuracy: 70.60
Round  71, Train loss: 0.639, Test loss: 0.710, Test accuracy: 70.67
Round  72, Train loss: 0.730, Test loss: 0.695, Test accuracy: 72.50
Round  73, Train loss: 0.519, Test loss: 0.692, Test accuracy: 71.33
Round  74, Train loss: 0.835, Test loss: 0.706, Test accuracy: 71.00
Round  75, Train loss: 0.656, Test loss: 0.713, Test accuracy: 71.20
Round  76, Train loss: 0.789, Test loss: 0.737, Test accuracy: 68.73
Round  77, Train loss: 0.724, Test loss: 0.709, Test accuracy: 70.90
Round  78, Train loss: 0.773, Test loss: 0.713, Test accuracy: 70.33
Round  79, Train loss: 0.579, Test loss: 0.710, Test accuracy: 69.97
Round  80, Train loss: 0.676, Test loss: 0.721, Test accuracy: 70.10
Round  81, Train loss: 0.669, Test loss: 0.730, Test accuracy: 68.73
Round  82, Train loss: 0.742, Test loss: 0.721, Test accuracy: 69.60
Round  83, Train loss: 0.570, Test loss: 0.715, Test accuracy: 70.17
Round  84, Train loss: 0.732, Test loss: 0.741, Test accuracy: 67.97
Round  85, Train loss: 0.744, Test loss: 0.736, Test accuracy: 69.07
Round  86, Train loss: 0.584, Test loss: 0.710, Test accuracy: 69.70
Round  87, Train loss: 0.782, Test loss: 0.719, Test accuracy: 69.70
Round  88, Train loss: 0.781, Test loss: 0.725, Test accuracy: 69.90
Round  89, Train loss: 0.680, Test loss: 0.730, Test accuracy: 69.37
Round  90, Train loss: 0.759, Test loss: 0.725, Test accuracy: 69.70
Round  91, Train loss: 0.487, Test loss: 0.713, Test accuracy: 70.53
Round  92, Train loss: 0.411, Test loss: 0.707, Test accuracy: 70.50
Round  93, Train loss: 0.711, Test loss: 0.742, Test accuracy: 68.17
Round  94, Train loss: 0.676, Test loss: 0.760, Test accuracy: 67.83
Round  95, Train loss: 0.584, Test loss: 0.731, Test accuracy: 69.63
Round  96, Train loss: 0.563, Test loss: 0.750, Test accuracy: 68.50
Round  97, Train loss: 0.525, Test loss: 0.726, Test accuracy: 69.83
Round  98, Train loss: 0.575, Test loss: 0.735, Test accuracy: 69.30
Round  99, Train loss: 0.629, Test loss: 0.747, Test accuracy: 68.67
Final Round, Train loss: 0.564, Test loss: 0.741, Test accuracy: 69.07
Average accuracy final 10 rounds: 69.26666666666667
303.2115910053253
[1.1144533157348633, 1.9078989028930664, 2.6884827613830566, 3.4650673866271973, 4.240668058395386, 5.021918058395386, 5.805088520050049, 6.601820945739746, 7.3884055614471436, 8.179261684417725, 8.967097043991089, 9.748056888580322, 10.519006252288818, 11.297748804092407, 12.07771110534668, 12.861555337905884, 13.651641845703125, 14.445964813232422, 15.22711706161499, 16.019084692001343, 16.802760124206543, 17.579493761062622, 18.36646032333374, 19.138569831848145, 19.888192176818848, 20.643357038497925, 21.40112829208374, 22.156287670135498, 22.91069769859314, 23.66838240623474, 24.41264057159424, 25.161286115646362, 25.909682989120483, 26.709815979003906, 27.49195146560669, 28.265170335769653, 29.04309105873108, 29.851818323135376, 30.637635469436646, 31.42236304283142, 32.21182155609131, 32.989093542099, 33.77009105682373, 34.55584716796875, 35.2587788105011, 35.958983421325684, 36.65096068382263, 37.35001850128174, 38.05403757095337, 38.75565505027771, 39.45782732963562, 40.15893912315369, 40.86025953292847, 41.56085705757141, 42.266014099121094, 42.966434478759766, 43.668272733688354, 44.37342095375061, 45.07206082344055, 45.773903608322144, 46.47596549987793, 47.17711663246155, 47.87836241722107, 48.58405089378357, 49.28481411933899, 49.97897267341614, 50.72114062309265, 51.447937965393066, 52.15009164810181, 52.85255813598633, 53.55360651016235, 54.255682945251465, 54.97061729431152, 55.676140785217285, 56.37947225570679, 57.08076214790344, 57.778324842453, 58.47794699668884, 59.17902708053589, 59.87899589538574, 60.578097105026245, 61.28136897087097, 61.981849193573, 62.67806434631348, 63.37028241157532, 64.07285404205322, 64.78118062019348, 65.48803520202637, 66.1873893737793, 66.88375115394592, 67.59232759475708, 68.2955265045166, 69.00040125846863, 69.70642495155334, 70.41273808479309, 71.11165428161621, 71.81233596801758, 72.51807451248169, 73.22107410430908, 73.92576241493225, 75.09509086608887]
[13.333333333333334, 25.333333333333332, 35.333333333333336, 39.36666666666667, 41.43333333333333, 41.53333333333333, 42.46666666666667, 47.766666666666666, 50.1, 52.4, 54.233333333333334, 53.86666666666667, 55.43333333333333, 62.96666666666667, 64.56666666666666, 63.03333333333333, 63.46666666666667, 61.1, 63.9, 66.8, 67.53333333333333, 66.83333333333333, 67.6, 66.23333333333333, 69.06666666666666, 68.86666666666666, 71.1, 70.26666666666667, 69.9, 71.5, 70.86666666666666, 69.36666666666666, 70.43333333333334, 71.83333333333333, 71.66666666666667, 71.1, 70.5, 71.66666666666667, 72.43333333333334, 71.9, 71.36666666666666, 73.06666666666666, 71.46666666666667, 70.06666666666666, 69.5, 72.43333333333334, 70.66666666666667, 69.3, 71.73333333333333, 71.1, 71.46666666666667, 69.03333333333333, 69.56666666666666, 70.8, 69.4, 71.7, 69.86666666666666, 70.63333333333334, 71.23333333333333, 69.9, 71.5, 71.96666666666667, 72.56666666666666, 72.46666666666667, 71.33333333333333, 72.46666666666667, 71.4, 71.63333333333334, 71.43333333333334, 69.9, 70.6, 70.66666666666667, 72.5, 71.33333333333333, 71.0, 71.2, 68.73333333333333, 70.9, 70.33333333333333, 69.96666666666667, 70.1, 68.73333333333333, 69.6, 70.16666666666667, 67.96666666666667, 69.06666666666666, 69.7, 69.7, 69.9, 69.36666666666666, 69.7, 70.53333333333333, 70.5, 68.16666666666667, 67.83333333333333, 69.63333333333334, 68.5, 69.83333333333333, 69.3, 68.66666666666667, 69.06666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.388, Test loss: 1.349, Test accuracy: 37.97
Round   1, Train loss: 1.053, Test loss: 1.035, Test accuracy: 51.27
Round   2, Train loss: 0.999, Test loss: 0.978, Test accuracy: 47.03
Round   3, Train loss: 0.972, Test loss: 0.936, Test accuracy: 53.20
Round   4, Train loss: 0.948, Test loss: 0.905, Test accuracy: 59.90
Round   5, Train loss: 0.930, Test loss: 0.850, Test accuracy: 64.17
Round   6, Train loss: 0.916, Test loss: 0.829, Test accuracy: 65.80
Round   7, Train loss: 0.900, Test loss: 0.823, Test accuracy: 64.33
Round   8, Train loss: 0.886, Test loss: 0.810, Test accuracy: 64.63
Round   9, Train loss: 0.875, Test loss: 0.797, Test accuracy: 67.03
Round  10, Train loss: 0.863, Test loss: 0.776, Test accuracy: 67.23
Round  11, Train loss: 0.854, Test loss: 0.786, Test accuracy: 66.47
Round  12, Train loss: 0.847, Test loss: 0.776, Test accuracy: 66.03
Round  13, Train loss: 0.839, Test loss: 0.755, Test accuracy: 68.30
Round  14, Train loss: 0.822, Test loss: 0.765, Test accuracy: 68.57
Round  15, Train loss: 0.812, Test loss: 0.736, Test accuracy: 70.67
Round  16, Train loss: 0.797, Test loss: 0.724, Test accuracy: 70.73
Round  17, Train loss: 0.789, Test loss: 0.729, Test accuracy: 70.23
Round  18, Train loss: 0.781, Test loss: 0.718, Test accuracy: 70.97
Round  19, Train loss: 0.768, Test loss: 0.736, Test accuracy: 69.10
Round  20, Train loss: 0.681, Test loss: 0.745, Test accuracy: 68.27
Round  21, Train loss: 0.695, Test loss: 0.749, Test accuracy: 68.13
Round  22, Train loss: 0.790, Test loss: 0.739, Test accuracy: 69.00
Round  23, Train loss: 0.806, Test loss: 0.752, Test accuracy: 68.20
Round  24, Train loss: 0.787, Test loss: 0.754, Test accuracy: 68.17
Round  25, Train loss: 0.843, Test loss: 0.742, Test accuracy: 68.30
Round  26, Train loss: 0.666, Test loss: 0.728, Test accuracy: 68.77
Round  27, Train loss: 0.695, Test loss: 0.757, Test accuracy: 66.97
Round  28, Train loss: 0.732, Test loss: 0.797, Test accuracy: 64.20
Round  29, Train loss: 0.624, Test loss: 0.786, Test accuracy: 64.33
Round  30, Train loss: 0.616, Test loss: 0.763, Test accuracy: 64.93
Round  31, Train loss: 0.556, Test loss: 0.754, Test accuracy: 66.50
Round  32, Train loss: 0.622, Test loss: 0.798, Test accuracy: 65.20
Round  33, Train loss: 0.615, Test loss: 0.805, Test accuracy: 64.97
Round  34, Train loss: 0.542, Test loss: 0.759, Test accuracy: 67.27
Round  35, Train loss: 0.748, Test loss: 0.782, Test accuracy: 65.77
Round  36, Train loss: 0.673, Test loss: 0.797, Test accuracy: 65.40
Round  37, Train loss: 0.486, Test loss: 0.774, Test accuracy: 65.87
Round  38, Train loss: 0.567, Test loss: 0.784, Test accuracy: 65.50
Round  39, Train loss: 0.693, Test loss: 0.810, Test accuracy: 65.53
Round  40, Train loss: 0.502, Test loss: 0.829, Test accuracy: 64.50
Round  41, Train loss: 0.474, Test loss: 0.847, Test accuracy: 62.87
Round  42, Train loss: 0.509, Test loss: 0.820, Test accuracy: 65.37
Round  43, Train loss: 0.463, Test loss: 0.801, Test accuracy: 66.13
Round  44, Train loss: 0.532, Test loss: 0.812, Test accuracy: 66.40
Round  45, Train loss: 0.436, Test loss: 0.807, Test accuracy: 66.20
Round  46, Train loss: 0.524, Test loss: 0.868, Test accuracy: 64.33
Round  47, Train loss: 0.482, Test loss: 0.829, Test accuracy: 65.17
Round  48, Train loss: 0.358, Test loss: 0.838, Test accuracy: 64.53
Round  49, Train loss: 0.515, Test loss: 0.874, Test accuracy: 64.07
Round  50, Train loss: 0.389, Test loss: 0.873, Test accuracy: 64.00
Round  51, Train loss: 0.347, Test loss: 0.879, Test accuracy: 64.20
Round  52, Train loss: 0.530, Test loss: 0.908, Test accuracy: 63.87
Round  53, Train loss: 0.404, Test loss: 0.940, Test accuracy: 62.23
Round  54, Train loss: 0.523, Test loss: 0.919, Test accuracy: 63.53
Round  55, Train loss: 0.287, Test loss: 0.858, Test accuracy: 65.17
Round  56, Train loss: 0.371, Test loss: 0.883, Test accuracy: 65.17
Round  57, Train loss: 0.410, Test loss: 0.874, Test accuracy: 65.50
Round  58, Train loss: 0.280, Test loss: 0.895, Test accuracy: 64.13
Round  59, Train loss: 0.282, Test loss: 0.907, Test accuracy: 65.17
Round  60, Train loss: 0.374, Test loss: 0.917, Test accuracy: 65.33
Round  61, Train loss: 0.434, Test loss: 0.955, Test accuracy: 62.60
Round  62, Train loss: 0.289, Test loss: 0.899, Test accuracy: 65.33
Round  63, Train loss: 0.341, Test loss: 0.938, Test accuracy: 64.73
Round  64, Train loss: 0.244, Test loss: 0.930, Test accuracy: 63.93
Round  65, Train loss: 0.478, Test loss: 0.978, Test accuracy: 62.53
Round  66, Train loss: 0.360, Test loss: 1.021, Test accuracy: 61.53
Round  67, Train loss: 0.286, Test loss: 1.021, Test accuracy: 61.80
Round  68, Train loss: 0.444, Test loss: 1.022, Test accuracy: 62.13
Round  69, Train loss: 0.368, Test loss: 1.031, Test accuracy: 61.90
Round  70, Train loss: 0.347, Test loss: 1.052, Test accuracy: 60.37
Round  71, Train loss: 0.254, Test loss: 1.063, Test accuracy: 61.63
Round  72, Train loss: 0.338, Test loss: 0.981, Test accuracy: 62.83
Round  73, Train loss: 0.244, Test loss: 1.002, Test accuracy: 62.63
Round  74, Train loss: 0.236, Test loss: 1.017, Test accuracy: 63.97
Round  75, Train loss: 0.325, Test loss: 1.076, Test accuracy: 61.83
Round  76, Train loss: 0.250, Test loss: 1.030, Test accuracy: 64.13
Round  77, Train loss: 0.355, Test loss: 1.080, Test accuracy: 62.37
Round  78, Train loss: 0.287, Test loss: 1.082, Test accuracy: 61.80
Round  79, Train loss: 0.259, Test loss: 1.063, Test accuracy: 62.70
Round  80, Train loss: 0.253, Test loss: 1.023, Test accuracy: 63.00
Round  81, Train loss: 0.218, Test loss: 1.034, Test accuracy: 63.43
Round  82, Train loss: 0.207, Test loss: 1.045, Test accuracy: 64.17
Round  83, Train loss: 0.207, Test loss: 1.078, Test accuracy: 63.47
Round  84, Train loss: 0.194, Test loss: 1.062, Test accuracy: 63.13
Round  85, Train loss: 0.202, Test loss: 1.058, Test accuracy: 64.00
Round  86, Train loss: 0.195, Test loss: 1.094, Test accuracy: 63.40
Round  87, Train loss: 0.191, Test loss: 1.071, Test accuracy: 63.67
Round  88, Train loss: 0.183, Test loss: 1.081, Test accuracy: 63.57
Round  89, Train loss: 0.167, Test loss: 1.084, Test accuracy: 63.77
Round  90, Train loss: 0.180, Test loss: 1.137, Test accuracy: 62.20
Round  91, Train loss: 0.159, Test loss: 1.113, Test accuracy: 62.90
Round  92, Train loss: 0.166, Test loss: 1.098, Test accuracy: 63.23
Round  93, Train loss: 0.160, Test loss: 1.122, Test accuracy: 63.73
Round  94, Train loss: 0.163, Test loss: 1.116, Test accuracy: 62.93
Round  95, Train loss: 0.149, Test loss: 1.159, Test accuracy: 63.10
Round  96, Train loss: 0.160, Test loss: 1.115, Test accuracy: 63.40
Round  97, Train loss: 0.164, Test loss: 1.114, Test accuracy: 64.03
Round  98, Train loss: 0.153, Test loss: 1.140, Test accuracy: 63.27
Round  99, Train loss: 0.163, Test loss: 1.117, Test accuracy: 63.10
Final Round, Train loss: 0.120, Test loss: 1.151, Test accuracy: 63.17
Average accuracy final 10 rounds: 63.19000000000001
946.7581686973572
[1.9004249572753906, 3.470548629760742, 5.034317970275879, 6.591427326202393, 8.146916389465332, 9.70714282989502, 11.262842416763306, 12.839400291442871, 14.412379264831543, 15.983541011810303, 17.57628059387207, 19.16752791404724, 20.75347065925598, 22.33262848854065, 23.92024540901184, 25.51194953918457, 27.104936122894287, 28.70042324066162, 30.293961763381958, 31.8824725151062, 33.46593761444092, 35.05175304412842, 36.63831353187561, 38.20765924453735, 39.78143382072449, 41.333584785461426, 42.89287757873535, 44.44846057891846, 46.038267850875854, 47.62330865859985, 49.20705699920654, 50.79069542884827, 52.20111608505249, 53.61524224281311, 55.02546405792236, 56.43172574043274, 57.84153342247009, 59.25748872756958, 60.66561985015869, 62.075321674346924, 63.4876983165741, 64.89714193344116, 66.3007435798645, 67.70923519134521, 69.12213492393494, 70.52698636054993, 71.93728303909302, 73.34789490699768, 74.7631459236145, 76.17504024505615, 77.5934829711914, 79.10755586624146, 80.51622295379639, 81.9288694858551, 83.34186339378357, 84.748131275177, 86.16076397895813, 87.5721538066864, 88.98805284500122, 90.42868137359619, 91.84366345405579, 93.25848484039307, 94.66211199760437, 96.0741810798645, 97.48683738708496, 98.93923020362854, 100.34423089027405, 101.75547170639038, 103.16633558273315, 104.57327699661255, 105.98522472381592, 107.39401865005493, 108.79603004455566, 110.20172762870789, 111.61043667793274, 113.01271295547485, 114.41969347000122, 115.8264708518982, 117.24482417106628, 118.6564667224884, 120.07882499694824, 121.49709129333496, 122.91595482826233, 124.32886481285095, 125.74446511268616, 127.16152215003967, 128.57543182373047, 129.9918975830078, 131.40745854377747, 132.83008790016174, 134.24540376663208, 135.65210556983948, 137.0564887523651, 138.45940589904785, 139.86304759979248, 141.26401543617249, 142.6690583229065, 144.0694124698639, 145.47029900550842, 146.89117908477783, 149.184809923172]
[37.96666666666667, 51.266666666666666, 47.03333333333333, 53.2, 59.9, 64.16666666666667, 65.8, 64.33333333333333, 64.63333333333334, 67.03333333333333, 67.23333333333333, 66.46666666666667, 66.03333333333333, 68.3, 68.56666666666666, 70.66666666666667, 70.73333333333333, 70.23333333333333, 70.96666666666667, 69.1, 68.26666666666667, 68.13333333333334, 69.0, 68.2, 68.16666666666667, 68.3, 68.76666666666667, 66.96666666666667, 64.2, 64.33333333333333, 64.93333333333334, 66.5, 65.2, 64.96666666666667, 67.26666666666667, 65.76666666666667, 65.4, 65.86666666666666, 65.5, 65.53333333333333, 64.5, 62.86666666666667, 65.36666666666666, 66.13333333333334, 66.4, 66.2, 64.33333333333333, 65.16666666666667, 64.53333333333333, 64.06666666666666, 64.0, 64.2, 63.86666666666667, 62.233333333333334, 63.53333333333333, 65.16666666666667, 65.16666666666667, 65.5, 64.13333333333334, 65.16666666666667, 65.33333333333333, 62.6, 65.33333333333333, 64.73333333333333, 63.93333333333333, 62.53333333333333, 61.53333333333333, 61.8, 62.13333333333333, 61.9, 60.36666666666667, 61.63333333333333, 62.833333333333336, 62.63333333333333, 63.96666666666667, 61.833333333333336, 64.13333333333334, 62.36666666666667, 61.8, 62.7, 63.0, 63.43333333333333, 64.16666666666667, 63.46666666666667, 63.13333333333333, 64.0, 63.4, 63.666666666666664, 63.56666666666667, 63.766666666666666, 62.2, 62.9, 63.233333333333334, 63.733333333333334, 62.93333333333333, 63.1, 63.4, 64.03333333333333, 63.266666666666666, 63.1, 63.166666666666664]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.439, Test loss: 1.442, Test accuracy: 40.30
Round   1, Train loss: 1.071, Test loss: 1.046, Test accuracy: 47.37
Round   2, Train loss: 1.000, Test loss: 0.930, Test accuracy: 58.30
Round   3, Train loss: 0.968, Test loss: 0.915, Test accuracy: 58.50
Round   4, Train loss: 0.942, Test loss: 0.874, Test accuracy: 61.30
Round   5, Train loss: 0.924, Test loss: 0.878, Test accuracy: 59.20
Round   6, Train loss: 0.904, Test loss: 0.840, Test accuracy: 61.93
Round   7, Train loss: 0.889, Test loss: 0.822, Test accuracy: 65.37
Round   8, Train loss: 0.871, Test loss: 0.815, Test accuracy: 63.33
Round   9, Train loss: 0.866, Test loss: 0.796, Test accuracy: 66.53
Round  10, Train loss: 0.853, Test loss: 0.782, Test accuracy: 68.77
Round  11, Train loss: 0.842, Test loss: 0.778, Test accuracy: 68.60
Round  12, Train loss: 0.830, Test loss: 0.754, Test accuracy: 70.07
Round  13, Train loss: 0.823, Test loss: 0.764, Test accuracy: 68.10
Round  14, Train loss: 0.812, Test loss: 0.740, Test accuracy: 69.53
Round  15, Train loss: 0.798, Test loss: 0.749, Test accuracy: 68.83
Round  16, Train loss: 0.790, Test loss: 0.742, Test accuracy: 69.70
Round  17, Train loss: 0.776, Test loss: 0.740, Test accuracy: 69.53
Round  18, Train loss: 0.763, Test loss: 0.730, Test accuracy: 70.77
Round  19, Train loss: 0.752, Test loss: 0.731, Test accuracy: 70.63
Round  20, Train loss: 0.656, Test loss: 0.746, Test accuracy: 68.47
Round  21, Train loss: 0.724, Test loss: 0.731, Test accuracy: 69.27
Round  22, Train loss: 0.711, Test loss: 0.727, Test accuracy: 69.50
Round  23, Train loss: 0.694, Test loss: 0.753, Test accuracy: 68.67
Round  24, Train loss: 0.626, Test loss: 0.756, Test accuracy: 68.70
Round  25, Train loss: 0.721, Test loss: 0.747, Test accuracy: 68.57
Round  26, Train loss: 0.618, Test loss: 0.729, Test accuracy: 69.30
Round  27, Train loss: 0.603, Test loss: 0.758, Test accuracy: 68.73
Round  28, Train loss: 0.698, Test loss: 0.774, Test accuracy: 67.83
Round  29, Train loss: 0.551, Test loss: 0.769, Test accuracy: 68.07
Round  30, Train loss: 0.714, Test loss: 0.775, Test accuracy: 67.37
Round  31, Train loss: 0.519, Test loss: 0.752, Test accuracy: 68.27
Round  32, Train loss: 0.508, Test loss: 0.772, Test accuracy: 66.73
Round  33, Train loss: 0.606, Test loss: 0.802, Test accuracy: 65.47
Round  34, Train loss: 0.646, Test loss: 0.814, Test accuracy: 65.37
Round  35, Train loss: 0.748, Test loss: 0.796, Test accuracy: 67.00
Round  36, Train loss: 0.659, Test loss: 0.816, Test accuracy: 66.43
Round  37, Train loss: 0.490, Test loss: 0.783, Test accuracy: 68.13
Round  38, Train loss: 0.684, Test loss: 0.799, Test accuracy: 66.23
Round  39, Train loss: 0.645, Test loss: 0.825, Test accuracy: 66.00
Round  40, Train loss: 0.513, Test loss: 0.848, Test accuracy: 65.00
Round  41, Train loss: 0.415, Test loss: 0.854, Test accuracy: 64.57
Round  42, Train loss: 0.588, Test loss: 0.850, Test accuracy: 64.77
Round  43, Train loss: 0.441, Test loss: 0.842, Test accuracy: 65.33
Round  44, Train loss: 0.503, Test loss: 0.822, Test accuracy: 66.80
Round  45, Train loss: 0.504, Test loss: 0.816, Test accuracy: 65.50
Round  46, Train loss: 0.492, Test loss: 0.802, Test accuracy: 67.07
Round  47, Train loss: 0.483, Test loss: 0.812, Test accuracy: 67.10
Round  48, Train loss: 0.448, Test loss: 0.851, Test accuracy: 65.70
Round  49, Train loss: 0.458, Test loss: 0.846, Test accuracy: 65.77
Round  50, Train loss: 0.408, Test loss: 0.849, Test accuracy: 66.23
Round  51, Train loss: 0.340, Test loss: 0.858, Test accuracy: 67.23
Round  52, Train loss: 0.478, Test loss: 0.829, Test accuracy: 68.53
Round  53, Train loss: 0.351, Test loss: 0.839, Test accuracy: 66.37
Round  54, Train loss: 0.493, Test loss: 0.892, Test accuracy: 64.53
Round  55, Train loss: 0.420, Test loss: 0.863, Test accuracy: 66.73
Round  56, Train loss: 0.481, Test loss: 0.928, Test accuracy: 64.10
Round  57, Train loss: 0.474, Test loss: 0.951, Test accuracy: 64.00
Round  58, Train loss: 0.302, Test loss: 0.899, Test accuracy: 65.77
Round  59, Train loss: 0.299, Test loss: 0.912, Test accuracy: 65.80
Round  60, Train loss: 0.386, Test loss: 0.961, Test accuracy: 63.53
Round  61, Train loss: 0.388, Test loss: 0.892, Test accuracy: 66.53
Round  62, Train loss: 0.335, Test loss: 0.946, Test accuracy: 65.87
Round  63, Train loss: 0.376, Test loss: 0.928, Test accuracy: 65.70
Round  64, Train loss: 0.345, Test loss: 0.951, Test accuracy: 64.83
Round  65, Train loss: 0.451, Test loss: 0.902, Test accuracy: 66.47
Round  66, Train loss: 0.360, Test loss: 0.979, Test accuracy: 65.20
Round  67, Train loss: 0.241, Test loss: 0.952, Test accuracy: 65.87
Round  68, Train loss: 0.432, Test loss: 0.969, Test accuracy: 65.33
Round  69, Train loss: 0.368, Test loss: 0.977, Test accuracy: 65.13
Round  70, Train loss: 0.346, Test loss: 0.982, Test accuracy: 64.83
Round  71, Train loss: 0.271, Test loss: 1.016, Test accuracy: 64.23
Round  72, Train loss: 0.307, Test loss: 0.902, Test accuracy: 67.33
Round  73, Train loss: 0.207, Test loss: 0.883, Test accuracy: 67.83
Round  74, Train loss: 0.249, Test loss: 0.969, Test accuracy: 66.47
Round  75, Train loss: 0.328, Test loss: 1.029, Test accuracy: 64.97
Round  76, Train loss: 0.258, Test loss: 0.983, Test accuracy: 66.17
Round  77, Train loss: 0.329, Test loss: 0.997, Test accuracy: 65.13
Round  78, Train loss: 0.302, Test loss: 1.012, Test accuracy: 65.20
Round  79, Train loss: 0.245, Test loss: 1.088, Test accuracy: 63.63
Round  80, Train loss: 0.261, Test loss: 1.045, Test accuracy: 64.50
Round  81, Train loss: 0.232, Test loss: 1.029, Test accuracy: 65.67
Round  82, Train loss: 0.231, Test loss: 1.037, Test accuracy: 65.00
Round  83, Train loss: 0.219, Test loss: 1.043, Test accuracy: 66.00
Round  84, Train loss: 0.220, Test loss: 1.043, Test accuracy: 65.77
Round  85, Train loss: 0.208, Test loss: 1.076, Test accuracy: 64.33
Round  86, Train loss: 0.233, Test loss: 1.066, Test accuracy: 64.70
Round  87, Train loss: 0.197, Test loss: 1.036, Test accuracy: 66.53
Round  88, Train loss: 0.194, Test loss: 1.055, Test accuracy: 65.90
Round  89, Train loss: 0.191, Test loss: 1.086, Test accuracy: 65.87
Round  90, Train loss: 0.178, Test loss: 1.104, Test accuracy: 65.33
Round  91, Train loss: 0.198, Test loss: 1.123, Test accuracy: 64.87
Round  92, Train loss: 0.186, Test loss: 1.094, Test accuracy: 64.30
Round  93, Train loss: 0.164, Test loss: 1.101, Test accuracy: 65.67
Round  94, Train loss: 0.187, Test loss: 1.092, Test accuracy: 65.53
Round  95, Train loss: 0.180, Test loss: 1.111, Test accuracy: 64.63
Round  96, Train loss: 0.161, Test loss: 1.096, Test accuracy: 64.63
Round  97, Train loss: 0.159, Test loss: 1.117, Test accuracy: 65.43
Round  98, Train loss: 0.172, Test loss: 1.142, Test accuracy: 64.77
Round  99, Train loss: 0.161, Test loss: 1.130, Test accuracy: 65.47
Final Round, Train loss: 0.141, Test loss: 1.141, Test accuracy: 65.27
Average accuracy final 10 rounds: 65.06333333333333
1391.8015217781067
[1.8670377731323242, 3.4055211544036865, 4.943153619766235, 6.477514266967773, 8.010669946670532, 9.54980993270874, 11.05098557472229, 12.45245909690857, 13.856839418411255, 15.25165843963623, 16.650115251541138, 18.04855728149414, 19.44631052017212, 20.85101342201233, 22.24628496170044, 23.653428316116333, 25.051695823669434, 26.451151847839355, 27.853161811828613, 29.25340723991394, 30.64594268798828, 33.196001052856445, 35.765766859054565, 38.332690715789795, 40.897625207901, 43.438836336135864, 45.9909029006958, 48.567235231399536, 51.12676024436951, 53.69371032714844, 56.277809143066406, 58.87144756317139, 61.46166706085205, 64.05225944519043, 66.65285468101501, 69.2291054725647, 71.79982900619507, 74.38142251968384, 76.97553181648254, 79.5694510936737, 82.13324189186096, 84.7209997177124, 87.30476021766663, 89.88999485969543, 92.48162579536438, 95.06736445426941, 97.64714050292969, 100.22250747680664, 102.81042289733887, 105.29844188690186, 108.02229523658752, 110.72300601005554, 113.44043850898743, 116.1504967212677, 118.85370540618896, 121.5508542060852, 124.2487051486969, 126.93670558929443, 129.6358766555786, 132.33878993988037, 135.03389501571655, 137.73238921165466, 140.43337225914001, 143.13646054267883, 145.84312629699707, 148.55003309249878, 151.2536427974701, 153.9545612335205, 156.66367053985596, 159.35446405410767, 162.05632948875427, 164.76540756225586, 167.48275136947632, 170.188410282135, 172.8955216407776, 175.61538362503052, 178.31522631645203, 181.02505445480347, 183.73464798927307, 186.44095420837402, 189.16214537620544, 191.87646460533142, 194.5946443080902, 197.3138346672058, 200.02756667137146, 202.74314188957214, 205.45479321479797, 208.1816508769989, 210.90300726890564, 213.62686967849731, 216.3436267375946, 219.05981755256653, 221.78247594833374, 224.44369316101074, 227.19210839271545, 229.9353141784668, 232.69067454338074, 235.48517441749573, 238.38990902900696, 241.30139327049255, 243.70701384544373]
[40.3, 47.36666666666667, 58.3, 58.5, 61.3, 59.2, 61.93333333333333, 65.36666666666666, 63.333333333333336, 66.53333333333333, 68.76666666666667, 68.6, 70.06666666666666, 68.1, 69.53333333333333, 68.83333333333333, 69.7, 69.53333333333333, 70.76666666666667, 70.63333333333334, 68.46666666666667, 69.26666666666667, 69.5, 68.66666666666667, 68.7, 68.56666666666666, 69.3, 68.73333333333333, 67.83333333333333, 68.06666666666666, 67.36666666666666, 68.26666666666667, 66.73333333333333, 65.46666666666667, 65.36666666666666, 67.0, 66.43333333333334, 68.13333333333334, 66.23333333333333, 66.0, 65.0, 64.56666666666666, 64.76666666666667, 65.33333333333333, 66.8, 65.5, 67.06666666666666, 67.1, 65.7, 65.76666666666667, 66.23333333333333, 67.23333333333333, 68.53333333333333, 66.36666666666666, 64.53333333333333, 66.73333333333333, 64.1, 64.0, 65.76666666666667, 65.8, 63.53333333333333, 66.53333333333333, 65.86666666666666, 65.7, 64.83333333333333, 66.46666666666667, 65.2, 65.86666666666666, 65.33333333333333, 65.13333333333334, 64.83333333333333, 64.23333333333333, 67.33333333333333, 67.83333333333333, 66.46666666666667, 64.96666666666667, 66.16666666666667, 65.13333333333334, 65.2, 63.63333333333333, 64.5, 65.66666666666667, 65.0, 66.0, 65.76666666666667, 64.33333333333333, 64.7, 66.53333333333333, 65.9, 65.86666666666666, 65.33333333333333, 64.86666666666666, 64.3, 65.66666666666667, 65.53333333333333, 64.63333333333334, 64.63333333333334, 65.43333333333334, 64.76666666666667, 65.46666666666667, 65.26666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.424, Test loss: 1.438, Test accuracy: 40.17
Round   1, Train loss: 1.062, Test loss: 1.023, Test accuracy: 51.37
Round   2, Train loss: 0.995, Test loss: 0.945, Test accuracy: 55.80
Round   3, Train loss: 0.965, Test loss: 0.920, Test accuracy: 57.77
Round   4, Train loss: 0.945, Test loss: 0.876, Test accuracy: 62.77
Round   5, Train loss: 0.927, Test loss: 0.871, Test accuracy: 62.10
Round   6, Train loss: 0.910, Test loss: 0.840, Test accuracy: 63.90
Round   7, Train loss: 0.895, Test loss: 0.811, Test accuracy: 66.53
Round   8, Train loss: 0.881, Test loss: 0.798, Test accuracy: 67.80
Round   9, Train loss: 0.872, Test loss: 0.784, Test accuracy: 67.13
Round  10, Train loss: 0.856, Test loss: 0.775, Test accuracy: 67.57
Round  11, Train loss: 0.846, Test loss: 0.779, Test accuracy: 68.57
Round  12, Train loss: 0.838, Test loss: 0.762, Test accuracy: 69.10
Round  13, Train loss: 0.827, Test loss: 0.753, Test accuracy: 69.60
Round  14, Train loss: 0.812, Test loss: 0.751, Test accuracy: 68.93
Round  15, Train loss: 0.800, Test loss: 0.732, Test accuracy: 70.07
Round  16, Train loss: 0.792, Test loss: 0.748, Test accuracy: 68.73
Round  17, Train loss: 0.780, Test loss: 0.727, Test accuracy: 70.40
Round  18, Train loss: 0.770, Test loss: 0.712, Test accuracy: 70.47
Round  19, Train loss: 0.757, Test loss: 0.736, Test accuracy: 68.93
Round  20, Train loss: 0.674, Test loss: 0.755, Test accuracy: 67.33
Round  21, Train loss: 0.833, Test loss: 0.762, Test accuracy: 67.17
Round  22, Train loss: 0.803, Test loss: 0.766, Test accuracy: 67.23
Round  23, Train loss: 0.707, Test loss: 0.741, Test accuracy: 67.97
Round  24, Train loss: 0.612, Test loss: 0.743, Test accuracy: 68.73
Round  25, Train loss: 0.713, Test loss: 0.741, Test accuracy: 67.53
Round  26, Train loss: 0.520, Test loss: 0.724, Test accuracy: 69.63
Round  27, Train loss: 0.577, Test loss: 0.734, Test accuracy: 68.70
Round  28, Train loss: 0.493, Test loss: 0.724, Test accuracy: 69.67
Round  29, Train loss: 0.534, Test loss: 0.727, Test accuracy: 69.07
Round  30, Train loss: 0.640, Test loss: 0.741, Test accuracy: 69.33
Round  31, Train loss: 0.551, Test loss: 0.731, Test accuracy: 69.70
Round  32, Train loss: 0.485, Test loss: 0.760, Test accuracy: 68.10
Round  33, Train loss: 0.525, Test loss: 0.728, Test accuracy: 69.50
Round  34, Train loss: 0.595, Test loss: 0.730, Test accuracy: 69.57
Round  35, Train loss: 0.648, Test loss: 0.729, Test accuracy: 69.97
Round  36, Train loss: 0.665, Test loss: 0.759, Test accuracy: 69.50
Round  37, Train loss: 0.561, Test loss: 0.740, Test accuracy: 69.70
Round  38, Train loss: 0.613, Test loss: 0.730, Test accuracy: 70.07
Round  39, Train loss: 0.558, Test loss: 0.742, Test accuracy: 71.07
Round  40, Train loss: 0.452, Test loss: 0.763, Test accuracy: 71.03
Round  41, Train loss: 0.415, Test loss: 0.756, Test accuracy: 69.97
Round  42, Train loss: 0.521, Test loss: 0.748, Test accuracy: 69.53
Round  43, Train loss: 0.462, Test loss: 0.736, Test accuracy: 69.67
Round  44, Train loss: 0.528, Test loss: 0.761, Test accuracy: 68.67
Round  45, Train loss: 0.580, Test loss: 0.802, Test accuracy: 67.63
Round  46, Train loss: 0.543, Test loss: 0.831, Test accuracy: 67.60
Round  47, Train loss: 0.536, Test loss: 0.780, Test accuracy: 67.77
Round  48, Train loss: 0.350, Test loss: 0.758, Test accuracy: 69.00
Round  49, Train loss: 0.439, Test loss: 0.784, Test accuracy: 68.57
Round  50, Train loss: 0.462, Test loss: 0.771, Test accuracy: 69.63
Round  51, Train loss: 0.390, Test loss: 0.828, Test accuracy: 68.63
Round  52, Train loss: 0.515, Test loss: 0.836, Test accuracy: 67.40
Round  53, Train loss: 0.346, Test loss: 0.827, Test accuracy: 68.03
Round  54, Train loss: 0.449, Test loss: 0.802, Test accuracy: 68.40
Round  55, Train loss: 0.526, Test loss: 0.852, Test accuracy: 66.50
Round  56, Train loss: 0.500, Test loss: 0.880, Test accuracy: 66.50
Round  57, Train loss: 0.484, Test loss: 0.882, Test accuracy: 65.80
Round  58, Train loss: 0.304, Test loss: 0.844, Test accuracy: 67.37
Round  59, Train loss: 0.276, Test loss: 0.815, Test accuracy: 68.63
Round  60, Train loss: 0.451, Test loss: 0.870, Test accuracy: 67.33
Round  61, Train loss: 0.377, Test loss: 0.855, Test accuracy: 67.17
Round  62, Train loss: 0.318, Test loss: 0.890, Test accuracy: 65.60
Round  63, Train loss: 0.424, Test loss: 0.940, Test accuracy: 64.83
Round  64, Train loss: 0.313, Test loss: 0.864, Test accuracy: 66.23
Round  65, Train loss: 0.483, Test loss: 0.912, Test accuracy: 64.77
Round  66, Train loss: 0.325, Test loss: 0.927, Test accuracy: 64.93
Round  67, Train loss: 0.201, Test loss: 0.878, Test accuracy: 67.33
Round  68, Train loss: 0.429, Test loss: 0.907, Test accuracy: 66.13
Round  69, Train loss: 0.329, Test loss: 0.923, Test accuracy: 65.90
Round  70, Train loss: 0.305, Test loss: 0.929, Test accuracy: 65.97
Round  71, Train loss: 0.231, Test loss: 0.925, Test accuracy: 66.53
Round  72, Train loss: 0.391, Test loss: 0.936, Test accuracy: 65.77
Round  73, Train loss: 0.287, Test loss: 0.978, Test accuracy: 64.43
Round  74, Train loss: 0.280, Test loss: 0.939, Test accuracy: 65.93
Round  75, Train loss: 0.351, Test loss: 1.014, Test accuracy: 63.57
Round  76, Train loss: 0.296, Test loss: 1.007, Test accuracy: 65.50
Round  77, Train loss: 0.373, Test loss: 1.015, Test accuracy: 63.30
Round  78, Train loss: 0.259, Test loss: 1.038, Test accuracy: 62.80
Round  79, Train loss: 0.242, Test loss: 1.000, Test accuracy: 65.97
Round  80, Train loss: 0.277, Test loss: 0.979, Test accuracy: 64.33
Round  81, Train loss: 0.243, Test loss: 0.973, Test accuracy: 65.07
Round  82, Train loss: 0.243, Test loss: 1.043, Test accuracy: 63.80
Round  83, Train loss: 0.236, Test loss: 1.023, Test accuracy: 64.20
Round  84, Train loss: 0.220, Test loss: 1.007, Test accuracy: 64.67
Round  85, Train loss: 0.224, Test loss: 1.023, Test accuracy: 64.77
Round  86, Train loss: 0.212, Test loss: 1.021, Test accuracy: 64.60
Round  87, Train loss: 0.217, Test loss: 1.051, Test accuracy: 64.47
Round  88, Train loss: 0.205, Test loss: 1.093, Test accuracy: 64.07
Round  89, Train loss: 0.198, Test loss: 1.075, Test accuracy: 63.70
Round  90, Train loss: 0.195, Test loss: 1.057, Test accuracy: 63.90
Round  91, Train loss: 0.201, Test loss: 1.086, Test accuracy: 63.90
Round  92, Train loss: 0.191, Test loss: 1.058, Test accuracy: 64.67
Round  93, Train loss: 0.183, Test loss: 1.078, Test accuracy: 64.43
Round  94, Train loss: 0.189, Test loss: 1.058, Test accuracy: 64.13
Round  95, Train loss: 0.176, Test loss: 1.078, Test accuracy: 64.37
Round  96, Train loss: 0.169, Test loss: 1.108, Test accuracy: 64.07
Round  97, Train loss: 0.184, Test loss: 1.097, Test accuracy: 64.07
Round  98, Train loss: 0.168, Test loss: 1.101, Test accuracy: 64.23
Round  99, Train loss: 0.170, Test loss: 1.104, Test accuracy: 64.20
Final Round, Train loss: 0.135, Test loss: 1.136, Test accuracy: 64.00
Average accuracy final 10 rounds: 64.19666666666666
1463.4140615463257
[1.8895199298858643, 3.462674140930176, 5.027530193328857, 6.4479217529296875, 7.873668909072876, 9.29396653175354, 10.710677146911621, 12.1298348903656, 13.55272626876831, 15.004593849182129, 16.456693649291992, 17.909114599227905, 19.362260580062866, 20.81483268737793, 22.2556471824646, 23.70940375328064, 25.1611647605896, 26.60118317604065, 28.035672187805176, 29.488991260528564, 30.936073064804077, 33.81237983703613, 36.76650142669678, 39.689303159713745, 42.45939016342163, 45.41223740577698, 48.33520817756653, 51.253681898117065, 54.176955223083496, 57.10263156890869, 60.0329704284668, 62.95374059677124, 65.9006884098053, 68.8332896232605, 71.63467788696289, 74.56489753723145, 77.53047513961792, 80.43875217437744, 83.37346172332764, 86.31731653213501, 89.26398730278015, 92.19041657447815, 95.13909387588501, 98.06809854507446, 100.97716999053955, 103.9176185131073, 106.86596512794495, 109.60352087020874, 112.53807377815247, 115.45792269706726, 118.36241412162781, 121.21919584274292, 124.15246057510376, 127.082275390625, 129.96993112564087, 132.88927602767944, 135.74102210998535, 138.57628440856934, 141.48416018486023, 144.4234504699707, 147.3526246547699, 150.28187012672424, 153.21232891082764, 156.14780807495117, 159.0516004562378, 161.9682981967926, 164.89236068725586, 167.6825294494629, 170.60237646102905, 173.53307223320007, 176.27025365829468, 179.1876573562622, 182.116140127182, 185.0236692428589, 187.7270565032959, 190.6509075164795, 193.59074521064758, 196.3962562084198, 199.3372187614441, 202.2245740890503, 205.18078541755676, 208.14623069763184, 211.1031835079193, 214.03450322151184, 216.98124027252197, 219.90769863128662, 222.85882830619812, 225.81045007705688, 228.7621614933014, 231.70327734947205, 234.64442110061646, 237.5849106311798, 240.531343460083, 243.48496913909912, 246.43224263191223, 249.38525247573853, 252.33662843704224, 255.26902389526367, 258.2082612514496, 261.15990686416626, 263.53266406059265]
[40.166666666666664, 51.36666666666667, 55.8, 57.766666666666666, 62.766666666666666, 62.1, 63.9, 66.53333333333333, 67.8, 67.13333333333334, 67.56666666666666, 68.56666666666666, 69.1, 69.6, 68.93333333333334, 70.06666666666666, 68.73333333333333, 70.4, 70.46666666666667, 68.93333333333334, 67.33333333333333, 67.16666666666667, 67.23333333333333, 67.96666666666667, 68.73333333333333, 67.53333333333333, 69.63333333333334, 68.7, 69.66666666666667, 69.06666666666666, 69.33333333333333, 69.7, 68.1, 69.5, 69.56666666666666, 69.96666666666667, 69.5, 69.7, 70.06666666666666, 71.06666666666666, 71.03333333333333, 69.96666666666667, 69.53333333333333, 69.66666666666667, 68.66666666666667, 67.63333333333334, 67.6, 67.76666666666667, 69.0, 68.56666666666666, 69.63333333333334, 68.63333333333334, 67.4, 68.03333333333333, 68.4, 66.5, 66.5, 65.8, 67.36666666666666, 68.63333333333334, 67.33333333333333, 67.16666666666667, 65.6, 64.83333333333333, 66.23333333333333, 64.76666666666667, 64.93333333333334, 67.33333333333333, 66.13333333333334, 65.9, 65.96666666666667, 66.53333333333333, 65.76666666666667, 64.43333333333334, 65.93333333333334, 63.56666666666667, 65.5, 63.3, 62.8, 65.96666666666667, 64.33333333333333, 65.06666666666666, 63.8, 64.2, 64.66666666666667, 64.76666666666667, 64.6, 64.46666666666667, 64.06666666666666, 63.7, 63.9, 63.9, 64.66666666666667, 64.43333333333334, 64.13333333333334, 64.36666666666666, 64.06666666666666, 64.06666666666666, 64.23333333333333, 64.2, 64.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.705, Test loss: 2.622, Test accuracy: 10.00
Round   1, Train loss: 1.203, Test loss: 2.472, Test accuracy: 29.37
Round   2, Train loss: 1.117, Test loss: 2.310, Test accuracy: 32.40
Round   3, Train loss: 1.145, Test loss: 1.578, Test accuracy: 40.70
Round   4, Train loss: 1.136, Test loss: 1.527, Test accuracy: 43.97
Round   5, Train loss: 1.101, Test loss: 1.205, Test accuracy: 48.73
Round   6, Train loss: 1.149, Test loss: 1.041, Test accuracy: 50.53
Round   7, Train loss: 1.053, Test loss: 1.010, Test accuracy: 54.17
Round   8, Train loss: 1.110, Test loss: 1.020, Test accuracy: 53.23
Round   9, Train loss: 1.111, Test loss: 1.015, Test accuracy: 54.10
Round  10, Train loss: 1.048, Test loss: 1.001, Test accuracy: 51.07
Round  11, Train loss: 1.099, Test loss: 1.009, Test accuracy: 52.63
Round  12, Train loss: 1.037, Test loss: 1.009, Test accuracy: 52.97
Round  13, Train loss: 1.107, Test loss: 1.019, Test accuracy: 49.57
Round  14, Train loss: 1.025, Test loss: 1.010, Test accuracy: 51.27
Round  15, Train loss: 1.096, Test loss: 1.006, Test accuracy: 52.60
Round  16, Train loss: 1.101, Test loss: 0.996, Test accuracy: 51.27
Round  17, Train loss: 1.011, Test loss: 0.990, Test accuracy: 51.63
Round  18, Train loss: 1.014, Test loss: 0.965, Test accuracy: 54.23
Round  19, Train loss: 1.093, Test loss: 0.969, Test accuracy: 55.37
Round  20, Train loss: 1.090, Test loss: 0.970, Test accuracy: 55.87
Round  21, Train loss: 0.992, Test loss: 0.964, Test accuracy: 57.00
Round  22, Train loss: 0.885, Test loss: 0.959, Test accuracy: 55.13
Round  23, Train loss: 1.074, Test loss: 0.959, Test accuracy: 55.97
Round  24, Train loss: 1.096, Test loss: 0.967, Test accuracy: 55.07
Round  25, Train loss: 0.980, Test loss: 0.950, Test accuracy: 55.83
Round  26, Train loss: 0.952, Test loss: 0.949, Test accuracy: 54.27
Round  27, Train loss: 0.975, Test loss: 0.945, Test accuracy: 55.23
Round  28, Train loss: 0.970, Test loss: 0.950, Test accuracy: 57.13
Round  29, Train loss: 1.075, Test loss: 0.945, Test accuracy: 58.57
Round  30, Train loss: 0.962, Test loss: 0.941, Test accuracy: 58.13
Round  31, Train loss: 0.947, Test loss: 0.934, Test accuracy: 57.73
Round  32, Train loss: 0.956, Test loss: 0.933, Test accuracy: 57.87
Round  33, Train loss: 0.918, Test loss: 0.911, Test accuracy: 58.07
Round  34, Train loss: 1.059, Test loss: 0.923, Test accuracy: 55.77
Round  35, Train loss: 0.899, Test loss: 0.922, Test accuracy: 56.33
Round  36, Train loss: 1.072, Test loss: 0.919, Test accuracy: 59.03
Round  37, Train loss: 0.953, Test loss: 0.929, Test accuracy: 57.50
Round  38, Train loss: 0.903, Test loss: 0.926, Test accuracy: 57.00
Round  39, Train loss: 1.070, Test loss: 0.928, Test accuracy: 56.80
Round  40, Train loss: 1.074, Test loss: 0.927, Test accuracy: 58.93
Round  41, Train loss: 1.056, Test loss: 0.921, Test accuracy: 59.63
Round  42, Train loss: 1.043, Test loss: 0.927, Test accuracy: 57.97
Round  43, Train loss: 0.775, Test loss: 0.915, Test accuracy: 57.40
Round  44, Train loss: 0.876, Test loss: 0.909, Test accuracy: 57.70
Round  45, Train loss: 0.736, Test loss: 0.892, Test accuracy: 58.17
Round  46, Train loss: 0.859, Test loss: 0.900, Test accuracy: 57.73
Round  47, Train loss: 0.840, Test loss: 0.917, Test accuracy: 55.67
Round  48, Train loss: 0.843, Test loss: 0.903, Test accuracy: 58.47
Round  49, Train loss: 1.047, Test loss: 0.912, Test accuracy: 57.23
Round  50, Train loss: 1.031, Test loss: 0.915, Test accuracy: 54.50
Round  51, Train loss: 0.924, Test loss: 0.930, Test accuracy: 55.27
Round  52, Train loss: 1.029, Test loss: 0.928, Test accuracy: 56.07
Round  53, Train loss: 0.911, Test loss: 0.908, Test accuracy: 56.50
Round  54, Train loss: 1.014, Test loss: 0.912, Test accuracy: 55.43
Round  55, Train loss: 0.845, Test loss: 0.895, Test accuracy: 58.03
Round  56, Train loss: 0.813, Test loss: 0.900, Test accuracy: 58.00
Round  57, Train loss: 1.027, Test loss: 0.895, Test accuracy: 57.23
Round  58, Train loss: 0.909, Test loss: 0.896, Test accuracy: 58.43
Round  59, Train loss: 0.821, Test loss: 0.904, Test accuracy: 57.03
Round  60, Train loss: 0.889, Test loss: 0.898, Test accuracy: 57.77
Round  61, Train loss: 1.013, Test loss: 0.903, Test accuracy: 57.23
Round  62, Train loss: 0.795, Test loss: 0.895, Test accuracy: 58.90
Round  63, Train loss: 0.993, Test loss: 0.906, Test accuracy: 57.43
Round  64, Train loss: 1.014, Test loss: 0.911, Test accuracy: 56.73
Round  65, Train loss: 0.655, Test loss: 0.891, Test accuracy: 57.33
Round  66, Train loss: 0.990, Test loss: 0.893, Test accuracy: 58.03
Round  67, Train loss: 1.008, Test loss: 0.893, Test accuracy: 58.10
Round  68, Train loss: 0.980, Test loss: 0.900, Test accuracy: 57.03
Round  69, Train loss: 0.751, Test loss: 0.901, Test accuracy: 56.83
Round  70, Train loss: 0.816, Test loss: 0.895, Test accuracy: 57.10
Round  71, Train loss: 0.819, Test loss: 0.894, Test accuracy: 57.67
Round  72, Train loss: 0.633, Test loss: 0.894, Test accuracy: 58.27
Round  73, Train loss: 0.782, Test loss: 0.890, Test accuracy: 57.23
Round  74, Train loss: 0.926, Test loss: 0.900, Test accuracy: 57.63
Round  75, Train loss: 0.954, Test loss: 0.910, Test accuracy: 56.83
Round  76, Train loss: 0.898, Test loss: 0.912, Test accuracy: 56.57
Round  77, Train loss: 0.987, Test loss: 0.921, Test accuracy: 55.63
Round  78, Train loss: 0.975, Test loss: 0.920, Test accuracy: 56.83
Round  79, Train loss: 0.784, Test loss: 0.920, Test accuracy: 56.80
Round  80, Train loss: 0.596, Test loss: 0.917, Test accuracy: 55.43
Round  81, Train loss: 0.976, Test loss: 0.905, Test accuracy: 55.70
Round  82, Train loss: 0.979, Test loss: 0.920, Test accuracy: 54.83
Round  83, Train loss: 0.789, Test loss: 0.918, Test accuracy: 54.87
Round  84, Train loss: 0.758, Test loss: 0.920, Test accuracy: 54.83
Round  85, Train loss: 0.773, Test loss: 0.916, Test accuracy: 54.83
Round  86, Train loss: 0.744, Test loss: 0.914, Test accuracy: 54.60
Round  87, Train loss: 0.533, Test loss: 0.922, Test accuracy: 55.30
Round  88, Train loss: 0.665, Test loss: 0.930, Test accuracy: 54.33
Round  89, Train loss: 0.887, Test loss: 0.937, Test accuracy: 54.40
Round  90, Train loss: 0.760, Test loss: 0.935, Test accuracy: 54.63
Round  91, Train loss: 0.470, Test loss: 0.948, Test accuracy: 53.97
Round  92, Train loss: 0.923, Test loss: 0.952, Test accuracy: 54.60
Round  93, Train loss: 0.875, Test loss: 0.956, Test accuracy: 53.40
Round  94, Train loss: 0.463, Test loss: 0.946, Test accuracy: 54.80
Round  95, Train loss: 0.877, Test loss: 0.962, Test accuracy: 53.83
Round  96, Train loss: 0.682, Test loss: 0.953, Test accuracy: 54.60
Round  97, Train loss: 0.841, Test loss: 0.974, Test accuracy: 53.23
Round  98, Train loss: 0.931, Test loss: 0.963, Test accuracy: 53.03
Round  99, Train loss: 0.435, Test loss: 0.961, Test accuracy: 54.57
Final Round, Train loss: 0.704, Test loss: 0.982, Test accuracy: 53.23
Average accuracy final 10 rounds: 54.06666666666666
321.66639518737793
[1.1376261711120605, 1.9312610626220703, 2.7259573936462402, 3.5222764015197754, 4.300745964050293, 5.089030504226685, 5.8828284740448, 6.6596643924713135, 7.434035778045654, 8.221887350082397, 9.011369943618774, 9.79877495765686, 10.587906837463379, 11.381576299667358, 12.171841621398926, 12.963365077972412, 13.751410961151123, 14.520316123962402, 15.297340393066406, 16.0882351398468, 16.88507866859436, 17.681398630142212, 18.478698253631592, 19.27652597427368, 20.070714235305786, 20.860496520996094, 21.64424419403076, 22.42225193977356, 23.208630561828613, 24.00788426399231, 24.798012495040894, 25.58667254447937, 26.385995388031006, 27.180537462234497, 27.97101330757141, 28.76384449005127, 29.549537658691406, 30.327675342559814, 31.123685598373413, 31.920459985733032, 32.72175121307373, 33.519561767578125, 34.316696643829346, 35.11174702644348, 35.89299249649048, 36.67323160171509, 37.45266532897949, 38.24548673629761, 39.036444425582886, 39.826982259750366, 40.617825746536255, 41.408294439315796, 42.200931549072266, 42.99704122543335, 43.789979219436646, 44.56811261177063, 45.34782314300537, 46.128170013427734, 46.92088174819946, 47.71484422683716, 48.506181716918945, 49.29793357849121, 50.09346652030945, 50.88483142852783, 51.66226601600647, 52.44142413139343, 53.2428765296936, 54.04024577140808, 54.839324951171875, 55.63422155380249, 56.42040944099426, 57.21921443939209, 58.013603925704956, 58.81166672706604, 59.59260439872742, 60.38112258911133, 61.17039752006531, 61.96252918243408, 62.757739543914795, 63.54718470573425, 64.34030818939209, 65.13105082511902, 65.92531323432922, 66.70058941841125, 67.47927832603455, 68.27638030052185, 69.07457685470581, 69.87478160858154, 70.67059445381165, 71.46759510040283, 72.2630934715271, 73.05357027053833, 73.84399271011353, 74.62541341781616, 75.40573978424072, 76.19662404060364, 76.97749471664429, 77.7547013759613, 78.53474569320679, 79.31640291213989, 80.54763841629028]
[10.0, 29.366666666666667, 32.4, 40.7, 43.96666666666667, 48.733333333333334, 50.53333333333333, 54.166666666666664, 53.233333333333334, 54.1, 51.06666666666667, 52.63333333333333, 52.96666666666667, 49.56666666666667, 51.266666666666666, 52.6, 51.266666666666666, 51.63333333333333, 54.233333333333334, 55.36666666666667, 55.86666666666667, 57.0, 55.13333333333333, 55.96666666666667, 55.06666666666667, 55.833333333333336, 54.266666666666666, 55.233333333333334, 57.13333333333333, 58.56666666666667, 58.13333333333333, 57.733333333333334, 57.86666666666667, 58.06666666666667, 55.766666666666666, 56.333333333333336, 59.03333333333333, 57.5, 57.0, 56.8, 58.93333333333333, 59.63333333333333, 57.96666666666667, 57.4, 57.7, 58.166666666666664, 57.733333333333334, 55.666666666666664, 58.46666666666667, 57.233333333333334, 54.5, 55.266666666666666, 56.06666666666667, 56.5, 55.43333333333333, 58.03333333333333, 58.0, 57.233333333333334, 58.43333333333333, 57.03333333333333, 57.766666666666666, 57.233333333333334, 58.9, 57.43333333333333, 56.733333333333334, 57.333333333333336, 58.03333333333333, 58.1, 57.03333333333333, 56.833333333333336, 57.1, 57.666666666666664, 58.266666666666666, 57.233333333333334, 57.63333333333333, 56.833333333333336, 56.56666666666667, 55.63333333333333, 56.833333333333336, 56.8, 55.43333333333333, 55.7, 54.833333333333336, 54.86666666666667, 54.833333333333336, 54.833333333333336, 54.6, 55.3, 54.333333333333336, 54.4, 54.63333333333333, 53.96666666666667, 54.6, 53.4, 54.8, 53.833333333333336, 54.6, 53.233333333333334, 53.03333333333333, 54.56666666666667, 53.233333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.427, Test loss: 1.408, Test accuracy: 34.57
Round   1, Train loss: 1.098, Test loss: 1.105, Test accuracy: 42.67
Round   2, Train loss: 1.054, Test loss: 1.035, Test accuracy: 48.43
Round   3, Train loss: 1.039, Test loss: 1.032, Test accuracy: 46.53
Round   4, Train loss: 1.028, Test loss: 0.999, Test accuracy: 50.97
Round   5, Train loss: 1.023, Test loss: 0.993, Test accuracy: 48.30
Round   6, Train loss: 1.013, Test loss: 0.992, Test accuracy: 49.40
Round   7, Train loss: 1.008, Test loss: 0.971, Test accuracy: 52.53
Round   8, Train loss: 1.001, Test loss: 0.991, Test accuracy: 49.10
Round   9, Train loss: 0.995, Test loss: 0.962, Test accuracy: 50.97
Round  10, Train loss: 0.987, Test loss: 0.965, Test accuracy: 54.47
Round  11, Train loss: 0.982, Test loss: 0.953, Test accuracy: 50.87
Round  12, Train loss: 0.975, Test loss: 0.939, Test accuracy: 56.27
Round  13, Train loss: 0.970, Test loss: 0.953, Test accuracy: 53.10
Round  14, Train loss: 0.964, Test loss: 0.957, Test accuracy: 50.77
Round  15, Train loss: 0.958, Test loss: 0.934, Test accuracy: 54.93
Round  16, Train loss: 0.952, Test loss: 0.941, Test accuracy: 53.53
Round  17, Train loss: 0.944, Test loss: 0.925, Test accuracy: 57.27
Round  18, Train loss: 0.936, Test loss: 0.920, Test accuracy: 56.77
Round  19, Train loss: 0.929, Test loss: 0.920, Test accuracy: 57.10
Round  20, Train loss: 0.806, Test loss: 0.920, Test accuracy: 57.80
Round  21, Train loss: 0.901, Test loss: 0.917, Test accuracy: 57.40
Round  22, Train loss: 0.878, Test loss: 0.913, Test accuracy: 57.60
Round  23, Train loss: 1.000, Test loss: 0.930, Test accuracy: 54.50
Round  24, Train loss: 1.019, Test loss: 0.940, Test accuracy: 53.10
Round  25, Train loss: 0.967, Test loss: 0.949, Test accuracy: 52.70
Round  26, Train loss: 0.978, Test loss: 0.957, Test accuracy: 52.37
Round  27, Train loss: 0.807, Test loss: 0.924, Test accuracy: 54.80
Round  28, Train loss: 0.959, Test loss: 0.953, Test accuracy: 52.63
Round  29, Train loss: 0.810, Test loss: 0.940, Test accuracy: 53.87
Round  30, Train loss: 0.809, Test loss: 0.953, Test accuracy: 52.47
Round  31, Train loss: 0.963, Test loss: 0.981, Test accuracy: 52.57
Round  32, Train loss: 0.931, Test loss: 1.003, Test accuracy: 50.53
Round  33, Train loss: 0.879, Test loss: 1.024, Test accuracy: 48.77
Round  34, Train loss: 0.727, Test loss: 0.973, Test accuracy: 52.33
Round  35, Train loss: 0.884, Test loss: 0.997, Test accuracy: 50.90
Round  36, Train loss: 0.907, Test loss: 1.030, Test accuracy: 50.17
Round  37, Train loss: 0.879, Test loss: 1.057, Test accuracy: 49.60
Round  38, Train loss: 0.715, Test loss: 1.011, Test accuracy: 50.50
Round  39, Train loss: 0.858, Test loss: 1.053, Test accuracy: 48.40
Round  40, Train loss: 0.578, Test loss: 0.991, Test accuracy: 52.33
Round  41, Train loss: 0.532, Test loss: 0.971, Test accuracy: 52.93
Round  42, Train loss: 0.759, Test loss: 1.029, Test accuracy: 50.00
Round  43, Train loss: 0.821, Test loss: 1.044, Test accuracy: 48.43
Round  44, Train loss: 0.629, Test loss: 1.043, Test accuracy: 50.00
Round  45, Train loss: 0.733, Test loss: 1.083, Test accuracy: 48.17
Round  46, Train loss: 0.727, Test loss: 1.108, Test accuracy: 47.13
Round  47, Train loss: 0.569, Test loss: 1.078, Test accuracy: 49.43
Round  48, Train loss: 0.569, Test loss: 1.079, Test accuracy: 49.33
Round  49, Train loss: 0.586, Test loss: 1.091, Test accuracy: 49.90
Round  50, Train loss: 0.558, Test loss: 1.102, Test accuracy: 49.40
Round  51, Train loss: 0.609, Test loss: 1.088, Test accuracy: 50.53
Round  52, Train loss: 0.528, Test loss: 1.114, Test accuracy: 49.00
Round  53, Train loss: 0.683, Test loss: 1.141, Test accuracy: 48.50
Round  54, Train loss: 0.494, Test loss: 1.133, Test accuracy: 50.23
Round  55, Train loss: 0.586, Test loss: 1.112, Test accuracy: 50.00
Round  56, Train loss: 0.600, Test loss: 1.163, Test accuracy: 48.83
Round  57, Train loss: 0.544, Test loss: 1.160, Test accuracy: 48.97
Round  58, Train loss: 0.509, Test loss: 1.190, Test accuracy: 48.77
Round  59, Train loss: 0.467, Test loss: 1.151, Test accuracy: 49.57
Round  60, Train loss: 0.644, Test loss: 1.224, Test accuracy: 48.10
Round  61, Train loss: 0.450, Test loss: 1.232, Test accuracy: 47.40
Round  62, Train loss: 0.533, Test loss: 1.258, Test accuracy: 46.23
Round  63, Train loss: 0.507, Test loss: 1.288, Test accuracy: 46.87
Round  64, Train loss: 0.583, Test loss: 1.262, Test accuracy: 47.23
Round  65, Train loss: 0.544, Test loss: 1.277, Test accuracy: 46.93
Round  66, Train loss: 0.508, Test loss: 1.384, Test accuracy: 46.70
Round  67, Train loss: 0.446, Test loss: 1.276, Test accuracy: 47.60
Round  68, Train loss: 0.380, Test loss: 1.279, Test accuracy: 49.57
Round  69, Train loss: 0.394, Test loss: 1.345, Test accuracy: 47.93
Round  70, Train loss: 0.429, Test loss: 1.391, Test accuracy: 45.27
Round  71, Train loss: 0.368, Test loss: 1.385, Test accuracy: 47.57
Round  72, Train loss: 0.460, Test loss: 1.419, Test accuracy: 45.93
Round  73, Train loss: 0.339, Test loss: 1.443, Test accuracy: 46.03
Round  74, Train loss: 0.290, Test loss: 1.395, Test accuracy: 46.57
Round  75, Train loss: 0.316, Test loss: 1.463, Test accuracy: 46.70
Round  76, Train loss: 0.318, Test loss: 1.475, Test accuracy: 46.10
Round  77, Train loss: 0.500, Test loss: 1.537, Test accuracy: 45.93
Round  78, Train loss: 0.336, Test loss: 1.478, Test accuracy: 48.23
Round  79, Train loss: 0.345, Test loss: 1.493, Test accuracy: 47.43
Round  80, Train loss: 0.361, Test loss: 1.456, Test accuracy: 48.33
Round  81, Train loss: 0.328, Test loss: 1.418, Test accuracy: 48.23
Round  82, Train loss: 0.310, Test loss: 1.454, Test accuracy: 49.13
Round  83, Train loss: 0.305, Test loss: 1.519, Test accuracy: 47.43
Round  84, Train loss: 0.293, Test loss: 1.499, Test accuracy: 47.50
Round  85, Train loss: 0.296, Test loss: 1.508, Test accuracy: 47.17
Round  86, Train loss: 0.300, Test loss: 1.500, Test accuracy: 46.33
Round  87, Train loss: 0.282, Test loss: 1.529, Test accuracy: 47.20
Round  88, Train loss: 0.269, Test loss: 1.569, Test accuracy: 47.87
Round  89, Train loss: 0.280, Test loss: 1.519, Test accuracy: 47.50
Round  90, Train loss: 0.267, Test loss: 1.523, Test accuracy: 47.07
Round  91, Train loss: 0.255, Test loss: 1.573, Test accuracy: 47.00
Round  92, Train loss: 0.259, Test loss: 1.583, Test accuracy: 47.47
Round  93, Train loss: 0.249, Test loss: 1.591, Test accuracy: 46.90
Round  94, Train loss: 0.244, Test loss: 1.622, Test accuracy: 47.87
Round  95, Train loss: 0.240, Test loss: 1.606, Test accuracy: 47.13
Round  96, Train loss: 0.252, Test loss: 1.584, Test accuracy: 47.67
Round  97, Train loss: 0.215, Test loss: 1.620, Test accuracy: 47.57
Round  98, Train loss: 0.232, Test loss: 1.631, Test accuracy: 47.00
Round  99, Train loss: 0.232, Test loss: 1.674, Test accuracy: 47.40
Final Round, Train loss: 0.193, Test loss: 1.694, Test accuracy: 47.67
Average accuracy final 10 rounds: 47.30666666666667
1003.6537804603577
[1.9098477363586426, 3.4944236278533936, 5.070470809936523, 6.64112663269043, 8.218158483505249, 9.809865236282349, 11.407343864440918, 13.001270055770874, 14.59167766571045, 16.184183597564697, 17.775681257247925, 19.369065284729004, 20.96485662460327, 22.550527095794678, 24.146212100982666, 25.73474407196045, 27.329489707946777, 28.916821002960205, 30.505077600479126, 32.096266984939575, 33.687209129333496, 35.26754856109619, 36.83197522163391, 38.4247088432312, 40.01230478286743, 41.59949254989624, 43.19168162345886, 44.773263454437256, 46.32402992248535, 47.901268005371094, 49.47445368766785, 51.04858922958374, 52.6155903339386, 54.1653265953064, 55.726338148117065, 57.294599533081055, 58.85313844680786, 60.42429304122925, 61.98617720603943, 63.55487012863159, 65.1201593875885, 66.68852472305298, 68.25580644607544, 69.82681131362915, 71.36305522918701, 72.93379306793213, 74.50427341461182, 76.06871843338013, 77.63750863075256, 79.20394396781921, 80.7662615776062, 82.32812857627869, 83.89130687713623, 85.45949745178223, 87.02496194839478, 88.57332229614258, 90.1456036567688, 91.71597528457642, 93.28974890708923, 94.84802412986755, 96.39497947692871, 97.96572041511536, 99.53771758079529, 101.10462689399719, 102.67600274085999, 104.23807191848755, 105.79813361167908, 107.36274909973145, 108.93329644203186, 110.50527667999268, 112.07677817344666, 113.61651062965393, 115.18187880516052, 116.76022171974182, 118.33909916877747, 119.90581107139587, 121.46384811401367, 123.01895070075989, 124.58698964118958, 126.1528730392456, 127.72141194343567, 129.2941644191742, 130.86957788467407, 132.43979215621948, 134.0030710697174, 135.56913828849792, 137.13045167922974, 138.7015483379364, 140.24825024604797, 141.7990972995758, 143.35326862335205, 144.90372848510742, 146.46826887130737, 148.03284001350403, 149.59598469734192, 151.1544008255005, 152.7270724773407, 154.29870748519897, 155.86868405342102, 157.44680309295654, 159.86363577842712]
[34.56666666666667, 42.666666666666664, 48.43333333333333, 46.53333333333333, 50.96666666666667, 48.3, 49.4, 52.53333333333333, 49.1, 50.96666666666667, 54.46666666666667, 50.86666666666667, 56.266666666666666, 53.1, 50.766666666666666, 54.93333333333333, 53.53333333333333, 57.266666666666666, 56.766666666666666, 57.1, 57.8, 57.4, 57.6, 54.5, 53.1, 52.7, 52.36666666666667, 54.8, 52.63333333333333, 53.86666666666667, 52.46666666666667, 52.56666666666667, 50.53333333333333, 48.766666666666666, 52.333333333333336, 50.9, 50.166666666666664, 49.6, 50.5, 48.4, 52.333333333333336, 52.93333333333333, 50.0, 48.43333333333333, 50.0, 48.166666666666664, 47.13333333333333, 49.43333333333333, 49.333333333333336, 49.9, 49.4, 50.53333333333333, 49.0, 48.5, 50.233333333333334, 50.0, 48.833333333333336, 48.96666666666667, 48.766666666666666, 49.56666666666667, 48.1, 47.4, 46.233333333333334, 46.86666666666667, 47.233333333333334, 46.93333333333333, 46.7, 47.6, 49.56666666666667, 47.93333333333333, 45.266666666666666, 47.56666666666667, 45.93333333333333, 46.03333333333333, 46.56666666666667, 46.7, 46.1, 45.93333333333333, 48.233333333333334, 47.43333333333333, 48.333333333333336, 48.233333333333334, 49.13333333333333, 47.43333333333333, 47.5, 47.166666666666664, 46.333333333333336, 47.2, 47.86666666666667, 47.5, 47.06666666666667, 47.0, 47.46666666666667, 46.9, 47.86666666666667, 47.13333333333333, 47.666666666666664, 47.56666666666667, 47.0, 47.4, 47.666666666666664]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.457, Test loss: 1.488, Test accuracy: 34.77
Round   1, Train loss: 1.120, Test loss: 1.125, Test accuracy: 40.03
Round   2, Train loss: 1.070, Test loss: 1.071, Test accuracy: 40.57
Round   3, Train loss: 1.052, Test loss: 1.042, Test accuracy: 45.10
Round   4, Train loss: 1.038, Test loss: 0.997, Test accuracy: 52.23
Round   5, Train loss: 1.026, Test loss: 0.988, Test accuracy: 50.43
Round   6, Train loss: 1.016, Test loss: 0.986, Test accuracy: 50.93
Round   7, Train loss: 1.005, Test loss: 0.967, Test accuracy: 51.30
Round   8, Train loss: 1.001, Test loss: 0.966, Test accuracy: 52.17
Round   9, Train loss: 0.990, Test loss: 0.963, Test accuracy: 52.07
Round  10, Train loss: 0.981, Test loss: 0.946, Test accuracy: 54.03
Round  11, Train loss: 0.973, Test loss: 0.941, Test accuracy: 54.47
Round  12, Train loss: 0.964, Test loss: 0.932, Test accuracy: 56.60
Round  13, Train loss: 0.957, Test loss: 0.951, Test accuracy: 52.67
Round  14, Train loss: 0.950, Test loss: 0.930, Test accuracy: 56.77
Round  15, Train loss: 0.941, Test loss: 0.909, Test accuracy: 56.83
Round  16, Train loss: 0.932, Test loss: 0.912, Test accuracy: 55.87
Round  17, Train loss: 0.924, Test loss: 0.930, Test accuracy: 53.07
Round  18, Train loss: 0.913, Test loss: 0.920, Test accuracy: 55.97
Round  19, Train loss: 0.902, Test loss: 0.930, Test accuracy: 53.93
Round  20, Train loss: 0.992, Test loss: 0.935, Test accuracy: 53.53
Round  21, Train loss: 0.807, Test loss: 0.922, Test accuracy: 55.50
Round  22, Train loss: 0.647, Test loss: 0.910, Test accuracy: 55.23
Round  23, Train loss: 0.972, Test loss: 0.936, Test accuracy: 54.13
Round  24, Train loss: 0.998, Test loss: 0.937, Test accuracy: 54.67
Round  25, Train loss: 0.831, Test loss: 0.937, Test accuracy: 53.70
Round  26, Train loss: 0.749, Test loss: 0.930, Test accuracy: 54.70
Round  27, Train loss: 0.808, Test loss: 0.944, Test accuracy: 52.87
Round  28, Train loss: 0.778, Test loss: 0.946, Test accuracy: 52.40
Round  29, Train loss: 0.895, Test loss: 0.957, Test accuracy: 52.80
Round  30, Train loss: 0.742, Test loss: 0.953, Test accuracy: 53.13
Round  31, Train loss: 0.726, Test loss: 0.957, Test accuracy: 53.23
Round  32, Train loss: 0.734, Test loss: 0.954, Test accuracy: 52.13
Round  33, Train loss: 0.625, Test loss: 0.952, Test accuracy: 51.97
Round  34, Train loss: 0.785, Test loss: 0.975, Test accuracy: 50.67
Round  35, Train loss: 0.622, Test loss: 0.981, Test accuracy: 52.03
Round  36, Train loss: 0.892, Test loss: 0.992, Test accuracy: 50.30
Round  37, Train loss: 0.711, Test loss: 0.993, Test accuracy: 50.80
Round  38, Train loss: 0.612, Test loss: 0.977, Test accuracy: 52.00
Round  39, Train loss: 0.808, Test loss: 1.039, Test accuracy: 51.10
Round  40, Train loss: 0.839, Test loss: 1.065, Test accuracy: 49.80
Round  41, Train loss: 0.802, Test loss: 1.083, Test accuracy: 49.10
Round  42, Train loss: 0.698, Test loss: 1.100, Test accuracy: 47.87
Round  43, Train loss: 0.472, Test loss: 1.015, Test accuracy: 52.37
Round  44, Train loss: 0.519, Test loss: 1.025, Test accuracy: 52.00
Round  45, Train loss: 0.408, Test loss: 1.028, Test accuracy: 51.97
Round  46, Train loss: 0.518, Test loss: 1.025, Test accuracy: 51.80
Round  47, Train loss: 0.476, Test loss: 1.032, Test accuracy: 52.03
Round  48, Train loss: 0.587, Test loss: 1.048, Test accuracy: 52.23
Round  49, Train loss: 0.716, Test loss: 1.082, Test accuracy: 50.43
Round  50, Train loss: 0.630, Test loss: 1.139, Test accuracy: 49.20
Round  51, Train loss: 0.551, Test loss: 1.106, Test accuracy: 49.30
Round  52, Train loss: 0.636, Test loss: 1.178, Test accuracy: 48.87
Round  53, Train loss: 0.551, Test loss: 1.144, Test accuracy: 50.37
Round  54, Train loss: 0.550, Test loss: 1.185, Test accuracy: 48.93
Round  55, Train loss: 0.536, Test loss: 1.172, Test accuracy: 49.93
Round  56, Train loss: 0.445, Test loss: 1.188, Test accuracy: 49.60
Round  57, Train loss: 0.598, Test loss: 1.226, Test accuracy: 49.73
Round  58, Train loss: 0.512, Test loss: 1.242, Test accuracy: 50.07
Round  59, Train loss: 0.365, Test loss: 1.202, Test accuracy: 51.10
Round  60, Train loss: 0.503, Test loss: 1.224, Test accuracy: 50.77
Round  61, Train loss: 0.502, Test loss: 1.291, Test accuracy: 49.53
Round  62, Train loss: 0.380, Test loss: 1.265, Test accuracy: 49.60
Round  63, Train loss: 0.490, Test loss: 1.290, Test accuracy: 49.40
Round  64, Train loss: 0.503, Test loss: 1.315, Test accuracy: 48.77
Round  65, Train loss: 0.327, Test loss: 1.241, Test accuracy: 50.87
Round  66, Train loss: 0.480, Test loss: 1.339, Test accuracy: 49.10
Round  67, Train loss: 0.519, Test loss: 1.363, Test accuracy: 47.87
Round  68, Train loss: 0.416, Test loss: 1.397, Test accuracy: 46.77
Round  69, Train loss: 0.296, Test loss: 1.409, Test accuracy: 47.53
Round  70, Train loss: 0.334, Test loss: 1.380, Test accuracy: 48.43
Round  71, Train loss: 0.350, Test loss: 1.398, Test accuracy: 47.90
Round  72, Train loss: 0.293, Test loss: 1.384, Test accuracy: 49.83
Round  73, Train loss: 0.274, Test loss: 1.409, Test accuracy: 49.67
Round  74, Train loss: 0.329, Test loss: 1.401, Test accuracy: 48.10
Round  75, Train loss: 0.373, Test loss: 1.478, Test accuracy: 47.47
Round  76, Train loss: 0.350, Test loss: 1.423, Test accuracy: 46.47
Round  77, Train loss: 0.479, Test loss: 1.509, Test accuracy: 46.50
Round  78, Train loss: 0.430, Test loss: 1.521, Test accuracy: 46.60
Round  79, Train loss: 0.291, Test loss: 1.420, Test accuracy: 48.13
Round  80, Train loss: 0.333, Test loss: 1.454, Test accuracy: 48.37
Round  81, Train loss: 0.310, Test loss: 1.478, Test accuracy: 47.97
Round  82, Train loss: 0.301, Test loss: 1.484, Test accuracy: 48.47
Round  83, Train loss: 0.301, Test loss: 1.462, Test accuracy: 48.30
Round  84, Train loss: 0.292, Test loss: 1.495, Test accuracy: 48.20
Round  85, Train loss: 0.264, Test loss: 1.548, Test accuracy: 48.13
Round  86, Train loss: 0.269, Test loss: 1.508, Test accuracy: 47.27
Round  87, Train loss: 0.265, Test loss: 1.519, Test accuracy: 48.53
Round  88, Train loss: 0.265, Test loss: 1.530, Test accuracy: 48.77
Round  89, Train loss: 0.260, Test loss: 1.555, Test accuracy: 48.57
Round  90, Train loss: 0.259, Test loss: 1.543, Test accuracy: 48.73
Round  91, Train loss: 0.243, Test loss: 1.572, Test accuracy: 49.03
Round  92, Train loss: 0.243, Test loss: 1.620, Test accuracy: 48.27
Round  93, Train loss: 0.238, Test loss: 1.619, Test accuracy: 48.07
Round  94, Train loss: 0.226, Test loss: 1.591, Test accuracy: 48.37
Round  95, Train loss: 0.234, Test loss: 1.587, Test accuracy: 49.33
Round  96, Train loss: 0.219, Test loss: 1.646, Test accuracy: 49.37
Round  97, Train loss: 0.208, Test loss: 1.647, Test accuracy: 48.50
Round  98, Train loss: 0.215, Test loss: 1.631, Test accuracy: 48.90
Round  99, Train loss: 0.211, Test loss: 1.683, Test accuracy: 48.27
Final Round, Train loss: 0.172, Test loss: 1.729, Test accuracy: 48.23
Average accuracy final 10 rounds: 48.68333333333334
1500.732096672058
[1.9062526226043701, 3.494807720184326, 5.080744028091431, 6.654053688049316, 8.243723392486572, 9.831682205200195, 11.425452947616577, 13.013729810714722, 14.605224132537842, 16.196669340133667, 17.77122449874878, 19.346386194229126, 20.933099031448364, 22.51526689529419, 24.099077224731445, 25.68381404876709, 27.264881134033203, 28.844263553619385, 30.43056607246399, 32.0051691532135, 33.57687711715698, 36.50331091880798, 39.41397738456726, 42.32473850250244, 45.23016810417175, 48.13898777961731, 51.01351833343506, 53.91840600967407, 56.83047151565552, 59.743163108825684, 62.65524697303772, 65.56436967849731, 68.47297477722168, 71.38571691513062, 74.29555749893188, 77.18632984161377, 80.09669232368469, 83.00529980659485, 85.90699458122253, 88.82183885574341, 91.75984382629395, 94.66533589363098, 97.5783314704895, 100.47810935974121, 103.38308882713318, 106.28326678276062, 109.17681765556335, 112.08933520317078, 115.00039887428284, 117.87364912033081, 120.77885174751282, 123.68908023834229, 126.55737042427063, 129.46338486671448, 132.3712010383606, 135.27742743492126, 138.18511533737183, 141.09606218338013, 144.00708413124084, 146.92187237739563, 149.8109929561615, 152.71324586868286, 155.62738347053528, 158.5212903022766, 161.42429065704346, 164.3320677280426, 167.24224972724915, 170.1469349861145, 173.0608787536621, 175.99226689338684, 178.9400691986084, 181.86031794548035, 184.80173921585083, 187.72927045822144, 190.67816853523254, 193.61883687973022, 196.54338693618774, 199.48392701148987, 202.42517709732056, 205.3687708377838, 208.30828285217285, 211.25713968276978, 214.20030546188354, 217.13801980018616, 220.08534979820251, 223.02243399620056, 225.9630527496338, 228.89015293121338, 231.80979132652283, 234.73671889305115, 237.66931819915771, 240.59774231910706, 243.54568362236023, 246.48589420318604, 249.43391466140747, 252.38708424568176, 255.31802797317505, 258.05426359176636, 260.78309297561646, 263.5107650756836, 265.9062068462372]
[34.766666666666666, 40.03333333333333, 40.56666666666667, 45.1, 52.233333333333334, 50.43333333333333, 50.93333333333333, 51.3, 52.166666666666664, 52.06666666666667, 54.03333333333333, 54.46666666666667, 56.6, 52.666666666666664, 56.766666666666666, 56.833333333333336, 55.86666666666667, 53.06666666666667, 55.96666666666667, 53.93333333333333, 53.53333333333333, 55.5, 55.233333333333334, 54.13333333333333, 54.666666666666664, 53.7, 54.7, 52.86666666666667, 52.4, 52.8, 53.13333333333333, 53.233333333333334, 52.13333333333333, 51.96666666666667, 50.666666666666664, 52.03333333333333, 50.3, 50.8, 52.0, 51.1, 49.8, 49.1, 47.86666666666667, 52.36666666666667, 52.0, 51.96666666666667, 51.8, 52.03333333333333, 52.233333333333334, 50.43333333333333, 49.2, 49.3, 48.86666666666667, 50.36666666666667, 48.93333333333333, 49.93333333333333, 49.6, 49.733333333333334, 50.06666666666667, 51.1, 50.766666666666666, 49.53333333333333, 49.6, 49.4, 48.766666666666666, 50.86666666666667, 49.1, 47.86666666666667, 46.766666666666666, 47.53333333333333, 48.43333333333333, 47.9, 49.833333333333336, 49.666666666666664, 48.1, 47.46666666666667, 46.46666666666667, 46.5, 46.6, 48.13333333333333, 48.36666666666667, 47.96666666666667, 48.46666666666667, 48.3, 48.2, 48.13333333333333, 47.266666666666666, 48.53333333333333, 48.766666666666666, 48.56666666666667, 48.733333333333334, 49.03333333333333, 48.266666666666666, 48.06666666666667, 48.36666666666667, 49.333333333333336, 49.36666666666667, 48.5, 48.9, 48.266666666666666, 48.233333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 5, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.472, Test loss: 1.559, Test accuracy: 34.53
Round   1, Train loss: 1.143, Test loss: 1.135, Test accuracy: 37.23
Round   2, Train loss: 1.092, Test loss: 1.089, Test accuracy: 40.23
Round   3, Train loss: 1.077, Test loss: 1.068, Test accuracy: 44.10
Round   4, Train loss: 1.068, Test loss: 1.064, Test accuracy: 44.40
Round   5, Train loss: 1.059, Test loss: 1.029, Test accuracy: 48.73
Round   6, Train loss: 1.049, Test loss: 1.020, Test accuracy: 52.17
Round   7, Train loss: 1.042, Test loss: 1.028, Test accuracy: 48.87
Round   8, Train loss: 1.035, Test loss: 0.987, Test accuracy: 52.73
Round   9, Train loss: 1.028, Test loss: 0.986, Test accuracy: 53.40
Round  10, Train loss: 1.023, Test loss: 0.983, Test accuracy: 53.27
Round  11, Train loss: 1.015, Test loss: 0.982, Test accuracy: 52.70
Round  12, Train loss: 1.008, Test loss: 0.967, Test accuracy: 54.77
Round  13, Train loss: 1.003, Test loss: 0.977, Test accuracy: 52.33
Round  14, Train loss: 0.995, Test loss: 0.959, Test accuracy: 55.27
Round  15, Train loss: 0.985, Test loss: 0.963, Test accuracy: 54.53
Round  16, Train loss: 0.977, Test loss: 0.979, Test accuracy: 52.47
Round  17, Train loss: 0.973, Test loss: 0.954, Test accuracy: 55.83
Round  18, Train loss: 0.961, Test loss: 0.962, Test accuracy: 52.57
Round  19, Train loss: 0.955, Test loss: 0.955, Test accuracy: 53.87
Round  20, Train loss: 1.000, Test loss: 0.970, Test accuracy: 51.93
Round  21, Train loss: 1.019, Test loss: 0.972, Test accuracy: 52.67
Round  22, Train loss: 0.870, Test loss: 0.965, Test accuracy: 54.20
Round  23, Train loss: 0.992, Test loss: 0.991, Test accuracy: 52.00
Round  24, Train loss: 0.944, Test loss: 0.976, Test accuracy: 51.90
Round  25, Train loss: 0.842, Test loss: 0.981, Test accuracy: 50.67
Round  26, Train loss: 0.953, Test loss: 1.002, Test accuracy: 47.70
Round  27, Train loss: 0.840, Test loss: 0.974, Test accuracy: 51.13
Round  28, Train loss: 0.790, Test loss: 0.957, Test accuracy: 53.50
Round  29, Train loss: 0.923, Test loss: 0.992, Test accuracy: 50.07
Round  30, Train loss: 0.796, Test loss: 0.991, Test accuracy: 50.57
Round  31, Train loss: 0.860, Test loss: 1.004, Test accuracy: 51.40
Round  32, Train loss: 0.788, Test loss: 0.994, Test accuracy: 52.83
Round  33, Train loss: 0.857, Test loss: 0.999, Test accuracy: 51.40
Round  34, Train loss: 0.836, Test loss: 1.035, Test accuracy: 49.27
Round  35, Train loss: 0.769, Test loss: 1.030, Test accuracy: 49.97
Round  36, Train loss: 0.823, Test loss: 1.037, Test accuracy: 50.03
Round  37, Train loss: 0.753, Test loss: 1.012, Test accuracy: 52.30
Round  38, Train loss: 0.822, Test loss: 1.030, Test accuracy: 51.03
Round  39, Train loss: 0.753, Test loss: 1.088, Test accuracy: 48.57
Round  40, Train loss: 0.786, Test loss: 1.069, Test accuracy: 48.40
Round  41, Train loss: 0.844, Test loss: 1.097, Test accuracy: 47.43
Round  42, Train loss: 0.748, Test loss: 1.092, Test accuracy: 47.77
Round  43, Train loss: 0.617, Test loss: 1.054, Test accuracy: 49.07
Round  44, Train loss: 0.634, Test loss: 1.085, Test accuracy: 49.83
Round  45, Train loss: 0.606, Test loss: 1.071, Test accuracy: 49.43
Round  46, Train loss: 0.707, Test loss: 1.114, Test accuracy: 49.90
Round  47, Train loss: 0.653, Test loss: 1.143, Test accuracy: 48.53
Round  48, Train loss: 0.732, Test loss: 1.160, Test accuracy: 48.33
Round  49, Train loss: 0.751, Test loss: 1.178, Test accuracy: 48.90
Round  50, Train loss: 0.684, Test loss: 1.214, Test accuracy: 47.50
Round  51, Train loss: 0.507, Test loss: 1.133, Test accuracy: 49.73
Round  52, Train loss: 0.676, Test loss: 1.230, Test accuracy: 48.23
Round  53, Train loss: 0.517, Test loss: 1.143, Test accuracy: 49.67
Round  54, Train loss: 0.590, Test loss: 1.264, Test accuracy: 46.97
Round  55, Train loss: 0.699, Test loss: 1.275, Test accuracy: 45.30
Round  56, Train loss: 0.587, Test loss: 1.247, Test accuracy: 46.13
Round  57, Train loss: 0.621, Test loss: 1.296, Test accuracy: 46.77
Round  58, Train loss: 0.491, Test loss: 1.240, Test accuracy: 46.80
Round  59, Train loss: 0.524, Test loss: 1.295, Test accuracy: 47.33
Round  60, Train loss: 0.567, Test loss: 1.273, Test accuracy: 48.93
Round  61, Train loss: 0.499, Test loss: 1.305, Test accuracy: 47.13
Round  62, Train loss: 0.513, Test loss: 1.307, Test accuracy: 46.90
Round  63, Train loss: 0.543, Test loss: 1.299, Test accuracy: 46.43
Round  64, Train loss: 0.593, Test loss: 1.371, Test accuracy: 45.63
Round  65, Train loss: 0.391, Test loss: 1.262, Test accuracy: 48.87
Round  66, Train loss: 0.509, Test loss: 1.399, Test accuracy: 46.70
Round  67, Train loss: 0.537, Test loss: 1.398, Test accuracy: 46.20
Round  68, Train loss: 0.456, Test loss: 1.409, Test accuracy: 46.37
Round  69, Train loss: 0.408, Test loss: 1.371, Test accuracy: 46.37
Round  70, Train loss: 0.361, Test loss: 1.363, Test accuracy: 46.20
Round  71, Train loss: 0.370, Test loss: 1.361, Test accuracy: 47.00
Round  72, Train loss: 0.351, Test loss: 1.355, Test accuracy: 47.17
Round  73, Train loss: 0.277, Test loss: 1.393, Test accuracy: 47.20
Round  74, Train loss: 0.346, Test loss: 1.403, Test accuracy: 46.07
Round  75, Train loss: 0.330, Test loss: 1.440, Test accuracy: 46.57
Round  76, Train loss: 0.309, Test loss: 1.526, Test accuracy: 44.03
Round  77, Train loss: 0.442, Test loss: 1.569, Test accuracy: 44.80
Round  78, Train loss: 0.423, Test loss: 1.507, Test accuracy: 45.87
Round  79, Train loss: 0.335, Test loss: 1.434, Test accuracy: 45.20
Round  80, Train loss: 0.380, Test loss: 1.440, Test accuracy: 46.87
Round  81, Train loss: 0.348, Test loss: 1.497, Test accuracy: 45.83
Round  82, Train loss: 0.341, Test loss: 1.509, Test accuracy: 45.53
Round  83, Train loss: 0.328, Test loss: 1.534, Test accuracy: 45.30
Round  84, Train loss: 0.322, Test loss: 1.565, Test accuracy: 44.90
Round  85, Train loss: 0.305, Test loss: 1.593, Test accuracy: 45.00
Round  86, Train loss: 0.300, Test loss: 1.592, Test accuracy: 44.67
Round  87, Train loss: 0.321, Test loss: 1.636, Test accuracy: 46.27
Round  88, Train loss: 0.299, Test loss: 1.592, Test accuracy: 45.10
Round  89, Train loss: 0.288, Test loss: 1.618, Test accuracy: 44.90
Round  90, Train loss: 0.289, Test loss: 1.629, Test accuracy: 45.87
Round  91, Train loss: 0.284, Test loss: 1.655, Test accuracy: 45.30
Round  92, Train loss: 0.267, Test loss: 1.669, Test accuracy: 44.70
Round  93, Train loss: 0.263, Test loss: 1.668, Test accuracy: 45.10
Round  94, Train loss: 0.256, Test loss: 1.708, Test accuracy: 45.37
Round  95, Train loss: 0.262, Test loss: 1.705, Test accuracy: 46.20
Round  96, Train loss: 0.261, Test loss: 1.652, Test accuracy: 46.03
Round  97, Train loss: 0.251, Test loss: 1.678, Test accuracy: 46.90
Round  98, Train loss: 0.247, Test loss: 1.673, Test accuracy: 45.40
Round  99, Train loss: 0.251, Test loss: 1.702, Test accuracy: 45.90
Final Round, Train loss: 0.200, Test loss: 1.765, Test accuracy: 45.80
Average accuracy final 10 rounds: 45.67666666666666
1466.7391350269318
[1.9157016277313232, 3.493889808654785, 5.072756290435791, 6.658510446548462, 8.24058198928833, 9.840285301208496, 11.408789873123169, 12.970407724380493, 14.536982297897339, 16.100707530975342, 17.66059923171997, 19.245744466781616, 20.83556032180786, 22.42536997795105, 24.009523153305054, 25.59150218963623, 27.177197217941284, 28.74255633354187, 30.30738067626953, 31.883856058120728, 33.45669364929199, 36.197652101516724, 38.9394268989563, 41.68994164466858, 44.43718767166138, 47.16499900817871, 49.90567469596863, 52.63912558555603, 55.38074827194214, 58.107502937316895, 60.83668327331543, 63.56367611885071, 66.26476216316223, 68.9452223777771, 71.64300799369812, 74.35104870796204, 77.03944444656372, 79.7560224533081, 82.45721507072449, 85.15677738189697, 87.872061252594, 90.5666275024414, 93.28748154640198, 95.98765873908997, 98.7016658782959, 101.41446375846863, 104.09239363670349, 106.79367065429688, 109.49190545082092, 112.20572257041931, 114.9291775226593, 117.62301707267761, 120.32160115242004, 123.03150272369385, 125.6945550441742, 128.40295147895813, 131.12100434303284, 133.8412160873413, 136.52143168449402, 139.24461197853088, 141.964941740036, 144.68564248085022, 147.40403175354004, 150.11099696159363, 152.81744146347046, 155.54008865356445, 158.23965978622437, 160.95341300964355, 163.66557550430298, 166.36893939971924, 169.08277106285095, 171.80084371566772, 174.5342812538147, 177.24232602119446, 180.1269235610962, 183.0466604232788, 185.96719598770142, 188.797114610672, 191.72299528121948, 194.6210641860962, 197.5605754852295, 200.5018332004547, 203.4375786781311, 206.35938572883606, 209.28609323501587, 212.24004220962524, 215.18389701843262, 218.10656929016113, 221.02995085716248, 223.9775047302246, 226.88767075538635, 229.80943131446838, 232.72880148887634, 235.67106199264526, 238.5966956615448, 241.54295086860657, 244.4842939376831, 247.41981101036072, 250.32804560661316, 253.26621913909912, 255.72793412208557]
[34.53333333333333, 37.233333333333334, 40.233333333333334, 44.1, 44.4, 48.733333333333334, 52.166666666666664, 48.86666666666667, 52.733333333333334, 53.4, 53.266666666666666, 52.7, 54.766666666666666, 52.333333333333336, 55.266666666666666, 54.53333333333333, 52.46666666666667, 55.833333333333336, 52.56666666666667, 53.86666666666667, 51.93333333333333, 52.666666666666664, 54.2, 52.0, 51.9, 50.666666666666664, 47.7, 51.13333333333333, 53.5, 50.06666666666667, 50.56666666666667, 51.4, 52.833333333333336, 51.4, 49.266666666666666, 49.96666666666667, 50.03333333333333, 52.3, 51.03333333333333, 48.56666666666667, 48.4, 47.43333333333333, 47.766666666666666, 49.06666666666667, 49.833333333333336, 49.43333333333333, 49.9, 48.53333333333333, 48.333333333333336, 48.9, 47.5, 49.733333333333334, 48.233333333333334, 49.666666666666664, 46.96666666666667, 45.3, 46.13333333333333, 46.766666666666666, 46.8, 47.333333333333336, 48.93333333333333, 47.13333333333333, 46.9, 46.43333333333333, 45.63333333333333, 48.86666666666667, 46.7, 46.2, 46.36666666666667, 46.36666666666667, 46.2, 47.0, 47.166666666666664, 47.2, 46.06666666666667, 46.56666666666667, 44.03333333333333, 44.8, 45.86666666666667, 45.2, 46.86666666666667, 45.833333333333336, 45.53333333333333, 45.3, 44.9, 45.0, 44.666666666666664, 46.266666666666666, 45.1, 44.9, 45.86666666666667, 45.3, 44.7, 45.1, 45.36666666666667, 46.2, 46.03333333333333, 46.9, 45.4, 45.9, 45.8]
